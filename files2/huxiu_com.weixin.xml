<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>虎嗅网</title>
            <link>http://weixin.sogou.com/weixin?type=1&amp;s_from=input&amp;query=%E8%99%8E%E5%97%85%E7%BD%91</link>
            <description>有视角的商业资讯交流平台</description>
<item>
<guid>b3eaa2de9b9471308ecca6635efce838</guid>
<title>接管搜索、打造全能Agent，Google用AI重建帝国</title>
<link>http://weixin.sogou.com/weixin?type=2&amp;query=%E8%99%8E%E5%97%85%E7%BD%91+%E6%8E%A5%E7%AE%A1%E6%90%9C%E7%B4%A2%E3%80%81%E6%89%93%E9%80%A0%E5%85%A8%E8%83%BDAgent%EF%BC%8CGoogle%E7%94%A8AI%E9%87%8D%E5%BB%BA%E5%B8%9D%E5%9B%BD</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content&quot; id=&quot;js_content&quot;&gt;&lt;section start=&quot;start&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficdUzyusfMdumHnX533EiayQG5uESr3embXqo2ib6cialF6YEnh3Pfj9jgw/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;本文来自微信公众号：&lt;/span&gt;&lt;/span&gt;&lt;span href=&quot;http://mp.weixin.qq.com/s?__biz=MzkyNjU2ODM2NQ==&amp;amp;mid=2247613049&amp;amp;idx=1&amp;amp;sn=51c5fa250c352ac9b8e414b8ce0fa3e5&amp;amp;chksm=c313287a2edddf5a3d1f87cb5c6f47e8e8015b1d9cffb3572d0e49b91187fb168491312a55ed#rd&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;硅星人Pro （ID：gh_c0bb185caa8d）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，作者：王兆洋、Jessica、周一笑，原文标题：《Gemini接管搜索、全家桶秒变通用Agent ，以及Google Glass is so back！｜直击Google I/O》，题图来自：视觉中国&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谁也没想到，Google I/O现场的最高潮来自“复活”的Google Glass有些翻车了的实时demo。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2025年5月20日，Google的年度开发者大会Google I/O在加州山景城举办。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与去年在举办之前一天被OpenAI“狙击”不同，今年的Google I/O，剑拔弩张的氛围让位给了派对的氛围，在ChatGPT带来的狼狈之后，Google已经回到了自己的节奏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，它回到了饱和式发布的节奏。当天Google一口气发布了至少十多个AI相关的更新，而其中大多数和Gemini有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单说，Google主要做了四件事：展示Gemini在多模态上的遥遥领先；给Gemini AI助手做全方位的更新；让Gemini彻底接管搜索，并让全家桶变成通用Agent；以及令人兴奋的AI+AR眼镜。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些发布个个重要，但因为AI模型层面本身的进展在过去几年已经吊足了大家胃口，以及Google在此次大会之前已经发布了Gemini最新的大迭代，现场似乎显得平静。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到Google Glass的“复活”。它通过live demo彻底点燃了现场。&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;一、Google Glass is so back&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当天的Google I/O一共只有三四个Live demo，而最后出场的Android XR眼镜，是最让人兴奋的一个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在喧嚣的I/O后台，演示者Nishta戴上了这款看起来与普通眼镜无异的Android XR眼镜，为观众带来第一视角的体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;她先是对着镜子喝了一口咖啡，通过语音指令发送短信、设置手机静音，询问眼镜里内置的Gemini，她看到的墙壁上的乐队与这个剧场的关系，而这一切的答案和互动，都通过眼镜上实时悬浮显示，呈现在她眼前。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且，像极了故意对当年Google Glass太超前而被公众质疑的call back，当展示者戴着眼镜从后台出发，遇到的第一个人对她说：“你眼镜在闪烁，我是在直播里么？”然后很开心地参与了互动，而不是说“摘掉你的Google Glass”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，这一切都是为了展示眼镜里Gemini视觉记忆能力：当来到主舞台后，Nishta随口问起之前喝过的咖啡，Gemini竟然凭借杯子上模糊的印记，准确报出了咖啡店的名字“Blooms Giving”。接着咖啡店的图片、3D步行导航地图、给朋友发送的咖啡邀约，都通过很有Google特色的悬浮交互完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后他们甚至做了一个实时的“有风险出错”的演示——Nishta和台上的Shahram分别用印地语和波斯语进行对话，而两人镜片上实时滚动出英文的字幕。而在展示中，这部分的确卡顿了，但即便最终有些翻车，现场却依然一片掌声和欢呼。因为这基本就是接下来所有人期待的AI发展方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当Gemini的一切能力都可以跟现实世界，物理环境交互，并且通过视觉和语音的端到端的方式可以拥有记忆、执行和行动能力后，将解锁太多可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据Google介绍，Android XR智能眼镜将搭载Gemini Live AI助手，通过镜头、麦克风和可选的内置显示器，实现语音互动、拍照、地图导航、实时翻译等功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时它也将与Gentle Monster、Warby Parker等时尚品牌合作。目前没有公布价格和上市时间，但谷歌确认今年会开放平台，供开发者为XR生态构建应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;二、Gemini接管Google的一切&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在眼镜点燃现场之前，Google I/O更像是Google一个密集的AI军火展示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年坐在Google IO的圆形剧场里，你能非常直观感受到一年时间对于今天的AI来说，能发生多少事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当Google CEO Sundar Pichai站上当天的舞台，Google面前已经没有了OpenAI的偷袭搅局，Llama被DeepSeek彻底打乱阵脚，微软的Build仍让人担心它和OpenAI的关系，而Gemini自己的多模态能力则在一年的不停突破后站稳了领先，天天被念叨的搜索业务并未被Perplexity们冲垮，广告基本盘更是在最近财报里仍在超预期增长，归因也是“因为AI”。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficU447FCO7HrlcMqu2Z8qeyOXgEVGWWEdJxvKXs9GWPhHiauMLurcDpuQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;甚至人们都快忘了，在Google I/O上接过Pichai话筒的，已经是“诺贝尔化学奖得主”Demis Hassabis。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在当天的Google I/O上，Pichai的开场Keynote回到了久违的Google味儿，一切是Google自己的节奏而不是慌慌张张地应对。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“通常，在I/O大会召开前的几周，我们不会透露太多信息，因为总会把最重磅的模型留到大会上发布。”Pichai说。“然而在Gemini时代不同了。现在，我们很可能在IO前就发布了最智能的模型，或者提前一周公布像AlphaEvolve这样的突破。我们的目标是尽快将最出色的模型和产品交付到大家手中。我们速度前所未有的快。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Pichai的开场分享里，是一连串体现速度的数字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gemini应用月活跃用户超过4亿；Gemini应用中2.5 Pro使用量增长了45%；产品和API每月处理的token数从去年同期的9.7万亿增长到超过480万亿，增长了50倍；超过700万开发者正在利用Gemini进行构建，是去年同期的5倍；Vertex AI上Gemini使用量增长了40倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而模型上，Pichai甚至直接喊出Google已经遥遥领先。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自第一代Gemini Pro模型发布以来，它的Elo分数提升了300多分。&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（衡量大模型能力的ELO是一种通过模型之间两两匿名对比（类似下棋）的结果，来计算和更新各个模型相对实力排名的方法）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;；第七代TPU Ironwood比上一代性能提升了10倍。每个pod提供42.5 exaflops的计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI的渗透也带来Google产品的增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Search中的AI概览已覆盖超过15亿用户。目前已在200个国家和地区推出；在美国和印度等最大市场，推动显示它们的查询类型增长超过10%；AI mode早期测试者提出的查询长度是传统搜索的2到3倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年，Pichai就已经开始形容Google的员工已经是“geminier”，而今年的I/O当天正是Gemini&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（双子座）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;季节的第一天，他开玩笑形容在Google内部来说，每天都是Gemini季节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;甚至在他的演讲保留环节“统计AI出现次数”的环节，Gemini正式超过了AI成为他说得最多的单词。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic9AlJlvrwmdOibVB0n4W1wHMMU6LxyDf8rlLdficR93vDsKqTECGXz9Fg/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;对Google来说，走出ChatGPT猛攻之下的狼狈，一切都靠Gemini的反杀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而Demis Hassabis显然就是让这一切发生的那个人，当他出场，后面的AI生成的图像甚至都是一只山羊——GOAT&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（greatest of all time）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当天Hassabis的分享部分，其实更像是一场诺贝尔得主回家见面会，他回顾了他从最初痴迷用AI做乒乓球游戏，到Google的Transformer、AlphaGo，再到Gemini的历程。言外之意，向全AI界喊话，Google永远是你大爷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这位新晋诺奖得主也更加直白了，他表示他的最终目标是做出一个世界模型，而Gemini现在无比接近这个愿景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于更强的2.5 Pro，谷歌带来了一个全新的“深度思考模式”&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（Deep Think）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;，专门用来处理数学、编程这类复杂问题。它融合了最新的AI推理研究成果，包括并行思维技术，能在面对复杂问题时更像人一样“多角度思考”，给出更周到、更靠谱的答案。目前只开放给少数用户测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，一个比较新的功能是，谷歌正在为Gemini 2.5 Pro和2.5 Flash增添更自然对话体验的原生音频输出能力，而Gemini多模态可能接入的最新视频生成模型Veo 3，在视频质量上继续突破，且首次具备了原生音频生成能力，用户可以一句话生成匹配音效、背景环境声乃至角色对话的视频内容，并在文本理解、物理效果模拟和口型同步方面表现优异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在榜单方面，Gemini 2.5 Pro和Gemini 2.5 Flash Preview版本分别占据了大模型竞技场评测榜单的前两名。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficK4ubnLYeeH4Jicmpod5CSWic5eO8hDWEKYL4Lf0auiaic7zxKJgqpzibHqw/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;显然，Gemini坚持死磕原生多模态的技术路线，以及利用Google老本行搜索能力来增强模型研究能力的产品路线，含金量还在增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于Google来说，Gemini的模型能力+以Gemini app为核心的全能的单一AI通用助手+Gemini“接管”的Google全家桶，就是它此刻的AI战略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hassabis也对Gemini App提出了自己的终极想法：“我最终极的目标是让Gemini成为一个全能的助手。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而通往这个目标路上，最近的一个突破，是之前还只是展示阶段的AI Agent项目Project Astra开始正式进入现实世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“这是通往AGI的一个关键节点。”Hassabis说。“现在它的音频能力，记忆能力都得到了提升。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Project Astra以Gemini Live的新身份开始进入Gemini App。在现场，他展示了一个修理自行车的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户呼唤出Gemini，让她帮忙上网找到Huffy山地车的用户手册，并根据指令翻到刹车相关的特定页面；接着从YouTube上筛选出修复滑丝螺丝的教学视频，直接播放给你看。更厉害的是，Gemini Live甚至能翻阅你过去的邮件，从你和自行车店的聊天记录里找出那个让人头疼的六角螺母的准确尺寸，并在墙上工具箱里高亮出对应的型号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当发现还需要一个备用张力螺丝时，Gemini Live迅速遵照指令，给最近的自行车店打电话问有没有货。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演示中还有一个重要细节，当用户的一位朋友闪现在门口，喊他去吃午饭时，Gemini自动停止了说话，而等对方离开后，在用户提醒下，继续无缝衔接地汇报了自行车店的回电内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些技术的最终趋势，是让Gemini变得更加主动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在硅星人参加的一个小型沟通会上，Hassabis提到他对AI助手必须更加主动的看法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“如果你看看今天的工具，我会说它们大多是被动反应式的。也就是说，你通过查询或问题来输入，然后它做出回应。所以是你把所有的信息都投入到系统中。我们希望下一代和我们的AI助手能够做到的是，让它们具有预测性，能够提前提供帮助。例如，如果你要进行长途飞行，它可能会为你推荐一本适合在飞机上阅读的好书。或者，如果你有某种健身目标，它可能会主动提醒你今天要去跑步，或者建议你做一些与你长期目标相关的事情。所以我们认为，当这些主动型系统和代理系统能够预测你想要做什么时，它们的感觉会非常不同。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gemini app当天也宣布了大量更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;包括Gemini live功能的全面开放，它能更加实时，而且此前的小范围测试数据已经显示，人们比用打字会有5倍长的交互时间。同时，随着Project Astra变成成熟产品，摄像头实时互动和屏幕读取的能力也在Gemini里免费开放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gemini里的Deep Research模式接下来允许以用户自己上传资料，之后更是可以在Google全家桶里打通使用你的各种数据库。此外Canvas更新了更强的编程模式，最新的图像模型Imagen 4也接入Gemini。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而除了Gemini自己的app上的更多功能，Google能让Hassabis实现“统一的主动Agent”这个想法，更关键因为Google有它积攒了多年的强大的搜索+全家桶。而且，Hassabis已经为自己赢得了用Gemini更深入“接管”这些全家桶的权力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与Project Astra从实验室走向Gemini相似，此前Google的Project Mariner也变成了Gemini里的Agent mode。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“我们认为智能体&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（agents）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;是结合了高级AI模型智能和工具访问权限的系统，因此它们可以在您的控制下代表您执行操作。”Pichai说。Google引入了一种名为“教学与重复”的方法，即只需向它展示一次任务，它就能学习未来类似任务的计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“Agent mode可以同时完成多达十种不同的任务。这些智能体可以帮助您查找信息、进行预订、购买商品、做研究等等——所有这些都可以同时进行。”Hassabis说。“而且我们还会把它推广到更多产品，首先从浏览器开始。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当天Google宣布，Chrome将接入Gemini并拥有类似诸多通用Agent产品展示的功能，它能直接在你的浏览器页面中开始工作，帮你自动完成你指定的目标任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google通过API提供Agent Mode的能力，同时有它建立的开放的Agent2Agent协议，能让智能体之间相互通信，当天Google还宣布，它的Gemini API和SDK将兼容目前最流行的Agent与工具之间的协议MCP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一切都集齐了。那些基于Google的API做出来的AI浏览器、需要不停调用浏览器的通用Agent产品们，可能要想想自己如何和Google的亲儿子Chrome这样的产品竞争了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而Google接下来的计划是，它的全家桶都会在拥有了Computer use和Astra这样的Agent能力后的Gemini加持下，瞬间变成一个通用Agent。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Google的理解，Agent可能根本就不是一个单独产品，而是任何AI产品的基础功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;三、搜索彻底Gemini化&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google在OpenAI最初的冲击中，一度让人感觉英雄迟暮，而外界关注它能否转身成功的关键之一就是它是否能对自己躺着赚钱的基础——搜索业务动刀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而现在看来，它的动作还是很快的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“仅仅是一年时间，人们用搜索的方式已经深刻地改变了。”Google搜索负责人Elizabeth Reid说。“人们开始问更长的问题。因此我们把Gemini和搜索对世界信息的理解合并到一起。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当天全美的Google用户会看到Google多年来又一次大的改变，在首页的第一个tab的位置，变成了AI Mode。相比于小规模试验性质的AI Overview，这是又一个大的自我革新的动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI Mode的一个最大变化，其实是Gemini的AI能力和Google搜索的技术的更深入的融合，Google称在底层技术上，它使用查询扇出&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;(query fan-out)&lt;/span&gt;&lt;/span&gt;&lt;span&gt;技术，它会将问题分解为子主题，并同时替用户自动发出多个查询。这使得AI Mode能够比传统的Google搜索更深入地探索网络，帮助用户发现网络上更多的内容，找到更好的答案。此外，deep search模式也加入到AI Mode的选项里，可以在搜索里制作深度的报告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“这就是Google搜索的未来。从信息到智能。”Elizabeth Reid说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gemini对搜索核心业务的“接管”，也让Google此前一直想做但有所停滞的一些业务可以有新的做法。比如电商。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google shopping基本也是建立在搜索入口流量之上的业务，此前也不温不火，而此次基于Gemini的改造，它有了一个全新的交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在I/O现场，Shopping得到了少有的live demo机会。Google展示了一个虚拟试衣&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（Virtual Try-on）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;功能。现场掀起了一阵小高潮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以往我们线上购物时，只能看着模特图脑补自己穿上身的样子，生怕买了不合适。如今，只需上传一张自己的全身生活照，Google专门训练过的更了解人们身形和衣服褶皱的模型，会通过先进的身体映射和服装形变技术，将商品“穿”在你的数字分身上，褶皱、垂坠感都无比逼真，让人隔着屏幕也能清楚判断上身效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;挑中款式和尺码后，还可以设置期望价格，让Chrome的AI Agent去盯着价格，当低价出现后，agent自动下单，把支付界面推送给你由你最后操作支付。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google把所有最重要的入口位置都给了Gemini，当然也希望它能激活Google已有的各种业务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;四、Flow和彩蛋&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gemini系列模型在多模态上的疯狂进展，最直接惠及的就是创作者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google此次也更新了图像模型Imagen 4，和视频模型Veo 3。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频生成模型Veo 3懂物理规律、生成电影级的视频画面之外，还能同步创作出自然语音对话和逼真的环境音效。在制作一位饱经沧桑的男子独自在波涛汹涌的大海上航行的视频时，Veo 3除了完美渲染海浪动态、人物面部细微的情感变化，还为他配上了一段富有磁性的内心独白，意境十足。另一段森林中老猫头鹰和小獾的对话视频，更是活灵活现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些能力让Google特意单独又推出了一个app——Flow。它可以让普通人也能一句话轻松创作出有声音又对白有画面的专业级视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它融合了Google最顶尖的AI技术——视频生成模型Veo、图像生成模型Imagen以及强大的Gemini智能，在发布会当天已正式上线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这些背后是燃烧的token。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google也在Flow的展示后，公布了新的套餐定价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它将原本的AI Premium订阅正式更名为“谷歌AI Pro”，并推出了全新的高端版“谷歌AI Ultra”，月费高达249.99美元。Pro版月费仍为19.99美元。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficZCc8aqLANpkMSuMunEUC9NficIrgntYRPuPJPOrLovuLSR5Rib1Qo56Q/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;而就像一部大片一样，Google I/O也有诸多彩蛋，它并不是放在结尾，而是藏在了密集的发布之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个有意思的一带而过的彩蛋，是Gemini的Diffusion模型，它不是用在图片上，而是用在文本生成上。这让它的生成速度快得惊人。在现场的展示上，输入完成后，它几乎是瞬间完成了输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“传统的自回归语言模型一次生成一个词或者token。这种序列化的过程可能会很慢，并且会限制输出的质量和连贯性。扩散模型的工作方式则不同。它们并非直接预测文本，而是通过逐步优化噪声来学习生成输出。这意味着它们可以非常快速地对一个解决方案进行迭代，并在生成过程中纠正错误。这使得它们在编辑等任务中表现出色，包括在数学和代码相关的场景下。”Gemini团队介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而除了速度，这种尝试也在暗示着Gemini在模态融合之外，对模态生成和多模态推理融合的潜在的发力方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你现在可以在网站上加入waitlist来试用这个模型。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic0EetKMdUXoDribcKtWOZW1lXsXN4kzpguOSAOkQVibdKULU3d7rX6ZbQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这是一场信息量巨大的Google I/O，Google正在回到自己的节奏，这些强大的更新，和更清晰的思路，让人感觉可能真的是所有人努力半天，最终Google拿走AI胜利的游戏。&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系hezuo@huxiu.com&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;如对本稿件有异议或投诉，请联系tougao@huxiu.com&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;End&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;margin-bottom: 0px;&quot;&gt;&lt;section style=&quot;font-size: 16px;&quot;&gt;&lt;section style=&quot;margin: 10px 0%;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;想涨知识 关注虎嗅视频号！&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;/section&gt;&lt;p style=&quot;display: none;&quot;&gt;&lt;/p&gt;&lt;/div&gt;
    

    
    &lt;br /&gt;

    
        &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656093511&amp;amp;idx=3&amp;amp;sn=a361036d7f7e872b4acf3d1af6d20c78&amp;amp;chksm=671f2380b97fdadd15c2bb1e821ab885ee91a639e4dc4ff0a4a173f843e4cece4464f7045515&amp;amp;scene=0#rd&quot; style=&quot;color: blue;&quot; target=&quot;_blank&quot;&gt;文章原文&lt;/a&gt;
        &lt;br /&gt;
    

    

    &lt;img alt=&quot;&quot; class=&quot;&quot; height=&quot;1px&quot; src=&quot;http://www.jintiankansha.me/rss_static/82277/8mDmaw6Gec&quot; style=&quot;width: 1px; height: 1px; display: none;&quot; width=&quot;1px&quot; /&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
<pubDate>Wed, 21 May 2025 19:41:00 +0800</pubDate>
</item>
<item>
<guid>c512e87099915aa913244eb3688222c6</guid>
<title>大厂被裁后，我在西湖给老外讲段子</title>
<link>http://weixin.sogou.com/weixin?type=2&amp;query=%E8%99%8E%E5%97%85%E7%BD%91+%E5%A4%A7%E5%8E%82%E8%A2%AB%E8%A3%81%E5%90%8E%EF%BC%8C%E6%88%91%E5%9C%A8%E8%A5%BF%E6%B9%96%E7%BB%99%E8%80%81%E5%A4%96%E8%AE%B2%E6%AE%B5%E5%AD%90</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content&quot; id=&quot;js_content&quot;&gt;&lt;section start=&quot;start&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficfibGqgYibicDxmlz2HFaj03vdf54b2kY3hJLC1kW4sR57nkVwibWrh0VtQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;本文来自微信公众号：&lt;/span&gt;&lt;/span&gt;&lt;span href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1MzI0OTc3Ng==&amp;amp;mid=2247516595&amp;amp;idx=1&amp;amp;sn=7d79b111858a2c74e184975c8a56e66e&amp;amp;chksm=e8f4e715e6c0fc417079821bbe761e71e5da9ac80f81e181f99bc7a11bb4cafb831d76ef76ec#rd&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;旅界 （ID：tourismzonenews）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，作者：theodore熙少，题图来源：AI生成&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;01&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前几天，刷朋友圈，我看到一位老朋友朱亮发了一条状态：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他站在西湖断桥边，身后是一群金发碧眼的欧美游客，手里拿着讲解器，配文是：“今天讲了三个故事，收了一千块钱，不用写日报，不用被踢群，真香。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我愣了几秒，仔细看，确实是他，这兄弟曾经是杭州一家互联网大厂中层，典型985硕士，理工直男，技术扎实，英语口语也贼溜，但人际关系降智型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我记得他上次发朋友圈还是去年夏天离职时的吐槽贴，拍了一张公司茶水间的窗外，一片火烧云映在玻璃幕墙上，他自己窝在角落里，写了一句：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;“明天开始，不再是打工人。”&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;于是，我忍不住发微信问：“兄弟，你去当导游了？”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他回复：“是啊。导游，不用早会、不用复盘、还挺好玩。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;打开话匣子后，朱亮和我回忆这一年多的人生翻转故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2024年6月，他赶上业务线优化，整个项目组直接解散，他说自己拎着电脑包站在海创园站地铁口，一时间真不知道往哪走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那之后的几个月，他试过不少事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;投简历，没人搭理；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拍大厂离职Vlog，没人看；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试转行教编程，教了两节就放弃。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他妈看他天天在家窝着，干脆拉他去北京潭柘寺散心，结果景区导游讲得有点乱，他一时嘴快，开口给他妈“补课”：“这块传说治百病的‘石鱼’其实是清代落入潭柘寺一块含铜量很高的大陨石。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不少人侧着耳朵听，有人真问他：“你是不是专业讲解员？”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮说他那一刻突然意识到：自己还真有点讲故事的天赋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他回家查了一晚上，发现“全国导游资格考试”7月底开放报名，考试时间是11月，于是赶紧报名，开始备考，白天跟着一个做导游的老同学跑团学经验，晚上回家刷题做笔记，练表达，录语音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年4月，他顺利拿到了证书，那天他自己发了个朋友圈：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;“中年转型第一战，靠嘴拿证，合法上岗。”&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而我刷到他导游工作的那张朋友圈，正是他拿证上岗后一个多月带的第五个入境团。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说现在的工作比以前自由多了：早上九点出发，下午五点收团，中间就是讲讲历史、聊聊建筑、顺便安排点好吃的，“我现在带团比我之前开会还流程清晰。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“以前我是写架构的，现在我是讲文化的架构，场景从会议室换成了西湖边。”他笑着说，“我没转行，我只是重新上线了自己。”&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;02&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮不是个例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近半年，我朋友圈多了好几个“兼职导游”，有的是翻译下岗转行的，有的是语言类硕士刚毕业实习的，还有一个原本在高校教写作的老师，现在一边给媒体写稿一边带周末团。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导游这个职业，曾经在很多人印象里是吆喝、拍照、催上车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这两年，随着入境游恢复、自由团流行、英语小语种人才释放，它悄悄成了一个既能养活自己，又能稍微体面点的出路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个现实问题是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;现在的自由职业很卷，但导游这行暂时还没那么卷。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，门槛不高但门道不少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只要考下导游证、有旅行社挂靠或平台资质，就能开始接团；但要讲得好、带得好，真正能从文化里挖出内容、让游客听懂、笑出来、拍照发朋友圈，那是本事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，收入还行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在旅界搭建的行业社群里，数名业者和我指出，现在普通英语导游日薪在600～800元左右，小语种如西班牙语、法语能做到200美金一天，带欧美高端团如果再加上小费和佣金，一天收入过千并不稀奇。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficCV8P1oDQDMGx5e8WHBbnhM2lxzjPNkibialLmRL74Xb2wW5Mh32qUGeA/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;另有一位从翻译转行的朋友告诉我：“现在带法国团，讲完还要推荐他们去哪里喝咖啡、拍照，游客高兴就会多留些小费，有时还介绍买点茶叶、工艺品，提点佣金，虽然不多，但比原来接稿强。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更重要的是，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;导游的时间自由度，正在吸引一大批不想坐班的人。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们不一定一开始就想转行，而是试着做点新的兼职：周末跑一跑，节假日接个家庭团。如果喜欢，再考虑全职做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有个女孩子就和我说自己从教培离职之后，本来只是带几个在华生活的老外家庭出游做“陪翻”，结果客人说：“你讲得比我们之前参团导游还好。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，她干脆直接接自由团、制定线路、开票收款，从兼职地陪变成了独立IP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更何况，导游这个职业还有一点微妙的成就感：那就是你讲得好不好，现场反馈是立刻的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不像办公室里PPT没人看、日报没人批，导游只要讲得精彩，就能让一群陌生人全神贯注，甚至鼓掌拍照，这种正反馈，对很多转型者来说，是重新感受到被需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再说得远一点，中国的文化太多了，但能讲明白的人太少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的很多导游，尤其是入境英文团，不仅要讲清楚一段历史，还要能做跨文化“翻译”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说白了，你不能拿“嫦娥奔月”当真神话，也不能把佛教史讲得像教义课。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮称，“你要能把中国人情境化的逻辑变成外国人结构化的语言，你要能一边讲苏东坡一边说user persona&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（用户画像）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;，一边说《心经》一边比喻成算法递归。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这不是说导游一定要多有学问，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;而是说好导游其实是信息中介、服务高手、文化编剧的复合体。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也难怪越来越多的大厂离职员工在“躺不平”与“卷不赢”之间，开始尝试用一张嘴开辟一条新路。&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;03&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚开始的时候，朱亮也觉得这行挺轻松的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“大概去年，一个讲西湖、讲灵隐寺、讲南宋文化的英文导游，市场说得好的还不超过100个。”他笑说，“当时感觉自己像限量款。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但正式干了快俩月，他就明显感受到这行的“气温变化”：同行越来越多了，留学生回来的来了，语言类应届生也来搅局了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮苦笑说，关键是你管他们有证没证，这帮孩子英语好，嘴皮子利索，还年轻，重点是收得便宜，愿意先练经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有的旅行社甚至会直接去外语学院蹲点，发招聘广告：“兼职自由导游，日结600+，英语/日语/法语优先”，而学生也真愿意上，吃吃喝喝、聊聊天，比家教轻松多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，游客的预期也变了，特别是外国游客，他们越来越不满足于“到此一游”的讲解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们会提问、会打断、会Google核实你的说法，有些游客甚至已经做了功课，“你说错一个朝代，他都能当场纠正你。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮说自己有一次讲南宋词人时把张炎讲成了张孝祥，被一个美国学者毫不留情地当场指出，团里老外笑翻了，朱亮脸差点掉到断桥底下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，再往深里走，导游这个行当也开始出现服务结构的分化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一端是“低价跑量型”——平台导游、学生兼职、景区常驻讲解员，靠体力、模板和效率赚钱；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一端是“老实干活型”——自己挂靠旅行社等派单、踏踏实实讲解；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但最牛X的是“内容IP型”——本身有Tik Tok账号，在海外社交媒体是“小网红”的入境导游，他们打造风格、讲解像脱口秀，路线像文创产品，价格贵、用户还排队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮现在也发现，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;想要留住回头客，不能只靠“讲得多”，而要“讲得准、讲得新、讲得像个朋友”。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他开始琢磨内容怎么分级，路线怎么设计，像西湖这条线他拆成三个版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;入门版：适合第一次来杭州的外国人，讲历史背景+经典地标；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;进阶版：讲园林设计美学+诗词意象+建筑细节，适合文艺老外；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专业版：讲南宋文化系统、宗教影响与城市空间哲学，服务博主、学者、建筑从业者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说这套设计“比自己当年在大厂做中台产品还复杂，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;但带来的是成就感，不是KPI焦虑&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朱亮有点感慨：“导游这行是自由，但也不是轻松。要活下来，就得比游客更懂他们想听什么。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说自己现在不仅是入境导游，还是一个小小的中国文化IP创作者。他已经在考虑开设Tiktok账号，和老外分享他的旅行故事、文化解析和旅游攻略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，朱亮给了我一句话：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;“你不能改变环境，但你可以重新定义自己做什么。”&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这不仅是他转型的总结，也是入境导游这个行业未来的挑战与机遇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;本文受访者为化名。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系hezuo@huxiu.com&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;如对本稿件有异议或投诉，请联系tougao@huxiu.com&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;End&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;margin-bottom: 0px;&quot;&gt;&lt;section style=&quot;font-size: 16px;&quot;&gt;&lt;section style=&quot;margin: 10px 0%;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;想涨知识 关注虎嗅视频号！&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;/section&gt;&lt;p style=&quot;display: none;&quot;&gt;&lt;/p&gt;&lt;/div&gt;
    

    
    &lt;br /&gt;

    
        &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656093511&amp;amp;idx=4&amp;amp;sn=c581518a780832a620afcc55a50d9789&amp;amp;chksm=671ba3e8f7d457f13e1ef68d3839181f91dd88c7f1d9bd33dca5ec1e984178e234eb58cf73e3&amp;amp;scene=0#rd&quot; style=&quot;color: blue;&quot; target=&quot;_blank&quot;&gt;文章原文&lt;/a&gt;
        &lt;br /&gt;
    

    

    &lt;img alt=&quot;&quot; class=&quot;&quot; height=&quot;1px&quot; src=&quot;http://www.jintiankansha.me/rss_static/82277/qls5W0gnLu&quot; style=&quot;width: 1px; height: 1px; display: none;&quot; width=&quot;1px&quot; /&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
<pubDate>Wed, 21 May 2025 19:41:00 +0800</pubDate>
</item>
<item>
<guid>1df1cdc44d5186df922a32882751bfa5</guid>
<title>打工人疗养的终点：把社区医院当SPA平替</title>
<link>http://weixin.sogou.com/weixin?type=2&amp;query=%E8%99%8E%E5%97%85%E7%BD%91+%E6%89%93%E5%B7%A5%E4%BA%BA%E7%96%97%E5%85%BB%E7%9A%84%E7%BB%88%E7%82%B9%EF%BC%9A%E6%8A%8A%E7%A4%BE%E5%8C%BA%E5%8C%BB%E9%99%A2%E5%BD%93SPA%E5%B9%B3%E6%9B%BF</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content&quot; id=&quot;js_content&quot;&gt;&lt;section start=&quot;start&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vficd5PLIVf3J5xbebcEQ0JVxX24U97ErB6KNQVgFHzibuibnPCG0Y0kYIKA/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;本文来自微信公众号：&lt;/span&gt;&lt;/span&gt;&lt;span href=&quot;https://mp.weixin.qq.com/s/mIkvpvJckHMcUESDfVD6Bw&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;三联生活实验室&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，作者：碳酸狗，题图来自：视觉中国&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;都说“职场一年等于人间三年”，因此，身心俱疲的打工人，一有时间就想尽办法去疗工伤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如最近的打工人，索性直接去社区医院享清福了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家印象里的社区医院，就像是一个小诊所。但如今这群去社区医院过周末的打工人，想要的不是治病，而是享受。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“社区医院虽然治不了什么大病，但好在离家近，而且遍布在城市的每一根毛细血管里。不仅能在这里做上中医按摩、艾灸和推拿一条龙，有些项目甚至还可以刷医保。”&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic0eDWwsjulq0VTIxCPA4DVB32qzt2ngY8GiabhQE9B1FTGIdPQYzM6yg/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;“此外，去社区医院过周末，主打一个连吃带拿。光做艾灸和推拿还不够，如果当天有中医坐诊，还可以让医生给你开一些特色的中药代茶饮，或者泡脚包。拿回家把茶喝上，把脚泡上，美美在沙发上打个盹，才是最适合打工人宝宝体质的周末。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;打工人平时要么腰酸要么背痛，单独去一趟大医院不值当，但自己忍着又难受，社区医院就相当于一个过渡地带。“打工人的病大多不是实病，而是累病的。先去社区医院美美调养一番，如果调理好了则皆大欢喜，调理不好再去医院挂号也为时不晚。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于打工人而言，随处可见的社区医院，竞品不是三甲医院，而是SPA馆和按摩店。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“去按摩店找师傅按个一小时，怎么样也得花上一两百的价钱；但去社区医院按摩，给你按的都是专业的医生，不仅力道有分寸，而且价格也便宜多了。”&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;一、最近的年轻人，流行去社区医院享福&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你以为社区医院就是治个头疼脑热的小诊所，实际上如今大城市的社区医院，规模不输一个三甲医院的诊楼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“比如在北京， 朝阳区的社区医院几乎都有三四层楼，里面大到拍片子，小到测血压一应俱全，更重要的是不用排队，拍个片子10分钟就能出结果。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于年轻人来说，社区医院就像是一个隐秘的结界，自己只想远观，却从未有过踏足进去的念头。“社区医院里的大多数人，其实是老年人。他们没事儿就爱去社区医院测个血糖、血压或是体重，监测一下自己的身体状况，顺便跟老姐妹们唠会儿嗑。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今，社区医院却被一批打工人们攻占了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只不过他们不去跟老年人抢血压计和血氧仪，而是就挂社区医院的推拿科，让医生们给自己按摩，把这里爆改成了SPA馆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上周刚在国贸附近的一个社区医院，做完推拿理疗的北漂小柯，发现社区医院就是最适合打工人的按摩房。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“挂个中医科，就可以等着大夫来给你做按摩了，他们精通人体的穴位，绝不会像外面的按摩师傅们使蛮力，而且不会在耳边推销办卡，而是根据你的反应判断你是肾亏还是熬夜，叮嘱你要早点睡觉、多喝热水。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些注重养生的年轻人，也会把社区医院当成据点，专门来这里做艾灸治疗失眠，把自己盘成油光水滑的模样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“如果你最近压力很大，或是工作焦虑，与其去大几百的颂钵疗愈，不如直接来社区医院熏个艾。不仅能舒舒服服睡一觉，而且一顿操作下来身体也松快多了，比什么疗愈都强。”&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficgMGAduj3tQq8cXTXbUVk6lEfp8Gicic6U1yjrpS74AP0J3Us6E7pVrYQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;有人甚至发现，即使你不去社区医院，有时社区医院也会主动找上你。来自江苏的90后小伙小堂，上周就被社区医院打了电话，询问他的体重问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“就是因为上周去医院测了血糖，这周社区医院就打来电话关心了，让我报身高和体重。医生会问有没有人给你提供健康指导，用什么运动来减肥，还会让你定期去社区医院检查减重成果。他们不仅不会PUA我，而是提供保姆级的攻略，生怕我瘦不下来，比我妈还细心。”&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;二、为什么打工人开始涌入社区医院？&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;打工人去社区医院，除了可以享受按摩外，还把这里当成彻头彻尾的享福基地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多打工人的公司，每年都会组织体检，但是检查项目往往只包含血常规、肝肾功能之类的基础项目。想要额外加一些深度的专项检查，就得在体检中心自费五百到一千不等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但在社区医院，有一个科室专门负责体检。打工人刷医保就能做像肿瘤筛查之类的高阶体检项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年27岁的北漂小羊，去年发现自己嘴里出现了两颗龋齿后，一直非常纠结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“去牙科诊所倒是可以立刻治疗，可随便补颗牙就要八九百块钱。去公立三甲医院虽然可以刷医保，但因为看牙的人太多，很难抢号。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他抱着试一试的心态去了家门口的社区医院，没想到从挂号到治疗结束，全程居然只用了不到三小时就搞定了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“而且补两颗牙一共花了1000，报销后只自费了100元。四舍五入等于在社区医院，省出了半个月的房租。”&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficicOwz5PHVCI7BhDFsicYsWVmch0OQCYy5lCBDx4Zvc1WMcStg1Jf6Eibw/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;有人算过一笔账，发现去社区医院无论是按摩、看牙还是治些小病，都比去大医院更加划算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“因为医保定点医院也分为一二三级，不同等级对应不同的报销比例。社区医院属于一级医疗机构，是报销比例最高的一类。比如在北京和武汉，很多项目都可以报销90%，其他城市普遍也在85%左右。所以对打工人而言，去社区医院才算是真正的无痛享福。”&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vficxkt69LzUjPAOO4gqoeewFmHRicTQTm8Vicyw4k2cOYkRUhaTHRqzdKDQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;如今的社区医院，已经进化成了远超大部分人想象的模样。如今的社区医院，已经不再是一个小诊所，而是一个巨大的度假村。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“比如亦庄的某社区医院，治疗区输液的地方全是皮沙发，候诊区还贴心地划出了小孩专用玩耍区，乍一看和私立医院没什么两样。如果不看门口的牌子，朋友们甚至会以为你去的其实是某睦家。”&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;三、去社区医院的打工人，更懂爱自己了&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从今年被定为国家减肥年后，很多地方的社区医院，还新增了体重管理门诊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在打工人想减肥，不用再花上千元去办健身房月卡，也不用顿顿跑去网红轻食店吃七八十元一份的水煮鸡胸。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“只要走进社区医院，医生就会根据你的身体情况量身制定一份饮食计划，清清楚楚写在处方单上。顺便还会以‘你家住得近’为理由，要求你每周至少来随访一次。在这种强制打卡的监督力度下，大家减肥时想偷懒都难。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多人因为工作忙碌，平时身体不舒服的时候，总是会选择忍一忍再说。但自从发现社区医院的便利，就像是宝宝找到了奶嘴一样，一有不舒服就会火速前往寻求帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“因为社区医院网点比较多，分散在各个街道和小区周围。所以这里不会出现那种三甲医院里，全国各地患者都蜂拥而至的拥堵情况。直接把社区医院当成自己的专属疗愈基地了，像是回到了爷爷奶奶家，做个按摩再开点代用茶，一顿下来比去洗浴中心还舒服。”&lt;/span&gt;&lt;/p&gt;&lt;p label=&quot;大标题&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;三、结语&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家去社区医院，除了享福外，也是为了寻找一种被关爱的感觉。小羊从第一次走进社区医院开始，就感受到了截然不同的氛围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“这里的医生，每天接诊量没有三甲医院那么大，他们会更耐心地听你把话讲完。每次我去看病，说完自己哪里不舒服后，医生甚至还会和我拉几句家常，顺便安慰我一番。我本来只是想按摩一下肩颈，结果被医生一顿话疗后，连精神状态也被一起舒展了。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;text-decoration: none;&quot;&gt;本文来自微信公众号：&lt;/span&gt;&lt;span href=&quot;https://mp.weixin.qq.com/s/mIkvpvJckHMcUESDfVD6Bw&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;三联生活实验室&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，作者：碳酸狗&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系hezuo@huxiu.com&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;如对本稿件有异议或投诉，请联系tougao@huxiu.com&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;End&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span style=&quot;font-weight: bold;&quot;&gt;快来预约虎嗅【夏日漫游季】直播&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span style=&quot;font-weight: bold;&quot;&gt;美妆个护&amp;amp;清凉好物&amp;amp;办公神器，承包你的整个夏日&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;/section&gt;&lt;p style=&quot;display: none;&quot;&gt;&lt;/p&gt;&lt;/div&gt;
    

    
    &lt;br /&gt;

    
        &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656093511&amp;amp;idx=1&amp;amp;sn=7f587614b6ea72e9ca3997386b1fa9d7&amp;amp;chksm=67510cd477984758c32fd4171f49901d4401c2ba9364f0ab947e775f1df57ec4ac3c80fd4c78&amp;amp;scene=0#rd&quot; style=&quot;color: blue;&quot; target=&quot;_blank&quot;&gt;文章原文&lt;/a&gt;
        &lt;br /&gt;
    

    

    &lt;img alt=&quot;&quot; class=&quot;&quot; height=&quot;1px&quot; src=&quot;http://www.jintiankansha.me/rss_static/82277/Jpefy1jBAF&quot; style=&quot;width: 1px; height: 1px; display: none;&quot; width=&quot;1px&quot; /&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
<pubDate>Wed, 21 May 2025 19:41:00 +0800</pubDate>
</item>
<item>
<guid>ae7c26f0785e14bf4694fa2b1e51c70f</guid>
<title>华为是怎么让大模型提速的？</title>
<link>http://weixin.sogou.com/weixin?type=2&amp;query=%E8%99%8E%E5%97%85%E7%BD%91+%E5%8D%8E%E4%B8%BA%E6%98%AF%E6%80%8E%E4%B9%88%E8%AE%A9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%80%9F%E7%9A%84%EF%BC%9F</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content&quot; id=&quot;js_content&quot;&gt;&lt;section style=&quot;font-style: normal; font-weight: 400; text-align: justify; font-size: 16px; color: rgb(62, 62, 62);&quot;&gt;&lt;section style=&quot;text-align: center; margin-top: 10px; margin-bottom: 10px; line-height: 0;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficARTOHlGWI0sfa7uns9v3IasZrrqHXicozY4aAhn01erhw2bnFwZvMuQ/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;text-align: left; display: flex; margin: 10px 0px;&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; width: auto; vertical-align: middle; border-style: solid; border-width: 0px; border-left-color: rgb(109, 104, 247); padding: 0px; height: auto; line-height: 0.1;&quot;&gt;&lt;section style=&quot;display: flex; margin: 0px;&quot;&gt;&lt;section style=&quot;display: inline-block; vertical-align: top; width: auto; height: auto; padding: 0px 0px 0px 8px; background-color: rgb(148, 0, 0);&quot;&gt;&lt;section style=&quot;margin: 0px; text-align: center;&quot;&gt;&lt;section style=&quot;text-align: justify; line-height: 0.8; letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span style=&quot;color: rgb(255, 255, 255); font-size: 10px; text-align: center;&quot;&gt;&lt;span&gt;HUAWEI  X  HUXIU&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: top; width: auto; height: auto;&quot;&gt;&lt;section style=&quot;text-align: center;&quot;&gt;&lt;section style=&quot;display: inline-block; width: 0px; height: 0px; vertical-align: top; overflow: hidden; border-style: solid; border-width: 0px 0px 16px 9px; border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(148, 0, 0);&quot;&gt;&lt;section style=&quot;text-align: justify;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; height: auto;&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; width: 8px; height: 8px; vertical-align: top; overflow: hidden; border-radius: 182px; background-color: rgb(148, 0, 0);&quot;&gt;&lt;section style=&quot;text-align: justify;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;text-align: justify; padding: 0px 10px; font-family: PingFangSC-light;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;没有人不在期待大模型能够成为下一个电动车，作为代表中国的新兴产业，在世界范围内掀起狂澜。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;然而主流的MoE架构大模型，却苦于其结构上的“先天不足”：巨大的硬件成本与多重拖累效率的环节，使得中国企业在这场芯片堆砌与效率挖掘的苦径上难以提速。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;作为智能基础设施提供商，华为在这场战役中另辟蹊径，利用其在数学算法和工程领域的深厚积累，为DeepSeek显著提升了效率及用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;山就在那里，但中国企业找到了不一样的登顶之路。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;近期，虎嗅将打造《华为技术披露集》系列内容，全面揭秘超大规模MoE模型推理部署技术，通过一连串的技术报告，首次全面披露技术细节。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;希望本系列内容能为业界起到参考价值，也希望更多人能与华为一起，共同打造长期持续的开放协作生态环境，让昇腾生态在中国茁壮成长。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;display: flex; margin: 15px 0px; text-align: center;&quot;&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; height: auto;&quot;&gt;&lt;section style=&quot;display: flex;&quot;&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; border-width: 0px;&quot;&gt;&lt;section style=&quot;margin: 0.5em 0px;&quot;&gt;&lt;section style=&quot;border-top: 1px dashed rgb(62, 62, 62);&quot;&gt;&lt;svg viewBox=&quot;0 0 1 1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;/svg&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; line-height: 0; letter-spacing: 0px;&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; padding: 0px 10px;&quot;&gt;&lt;section style=&quot;color: rgb(62, 62, 62);&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;《华为技术披露集》系列&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;b&gt;&lt;span&gt;VOL.3 ：投机推理&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; height: auto;&quot;&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto;&quot;&gt;&lt;section style=&quot;margin: 0.5em 0px;&quot;&gt;&lt;section style=&quot;border-top: 1px dashed rgb(62, 62, 62);&quot;&gt;&lt;svg viewBox=&quot;0 0 1 1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;/svg&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; line-height: 0; letter-spacing: 0px;&quot;&gt;&lt;section&gt;&lt;section style=&quot;margin: 0px 0%;&quot;&gt;&lt;section&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;padding: 0px 15px; color: rgb(62, 62, 62); font-family: PingFangSC-light; line-height: 2; letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;随着以DeepSeek V3/R1为代表的超大规模MoE模型走向主流，如何对如此超高参数量的模型进行推理优化，成了业界普遍关注的议题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;作为目前普遍采用的大模型推理加速技术之一，投机推理为大模型生成推理草稿，一次生成多个token，但面临调度时延过高，算力浪费的问题，就此华为团队提出投机推理框架 FusionSpec，持续提升 MTP 投机在昇腾上的推理性能，使其调度耗时从10ms降为1ms。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;而作为另一加速推理的技术，量化技术是DeepSeek模型采用FP8进行训练的核心，而推理时采用Int8部署，亟需突破FP8到int8的无损量化，为此华为团队也提出了OptiQuant量化框架和算法，让INT8性能可以打平FP8。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;下面就分别介绍华为团队的这两个创新技术。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;margin: 10px 0% 0px;&quot;&gt;&lt;section style=&quot;font-size: 35px; color: rgb(148, 0, 0); text-align: center; line-height: 1; letter-spacing: 0px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; width: 50px; vertical-align: top; background-color: rgb(86, 86, 86); height: auto; line-height: 0; letter-spacing: 0px;&quot;&gt;&lt;section style=&quot;display: flex; width: 100%; height: auto;&quot;&gt;&lt;section style=&quot;margin: 0px 0%; line-height: 0; width: 100%;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; width: 100%; height: auto;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic5hAwuGqsYLiaDBjJXN2RLAtF4XsIficECEFPCaL4GybQVDnWmwUPARog/640?wx_fmt=gif&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;text-align: center; font-size: 17px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;高吞吐推理投机&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;昇腾超大规模MoE模型推理的加速利器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;padding: 0px 15px; color: rgb(62, 62, 62); font-family: PingFangSC-light; line-height: 2; letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;在大语言模型（LLMs）的应用中，推理速度是影响用户体验和应用效率的关键因素。（回想下你一直苦等结果的时候）&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;传统的自回归解码方式，每次仅能生成一个输出 token，且需将历史输出作为输入进行下一步解码，导致推理过程串行、效率低下。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;为解决这一问题，投机推理技术应运而生。投机推理（Speculative Inference），也被称为推测性解码，其核心思想是利用计算代价远低于大模型的小模型，先行对后续可能的输出进行猜测，然后由大模型对这些猜测结果进行验证，从而实现并行化推理，提升整体推理速度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;打个比方，就像你写作文时，先在草稿纸上列几个可能的句子（小模型猜测），再挑出合适的句子写到作文里（大模型验证），写错了就擦掉重写（回退修正）。这种 “先试错再优化” 的思路，让大模型能更快、更准地给出回答。现有的投机推理技术，为以下几种类型：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;独立草稿生成（Independent Drafting）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：在这种方式下，小模型独立运行，对大模型未来可能生成的多个 token 进行预测，形成候选序列。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;自我草稿生成（Self - Drafting）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：自我草稿生成是一种相对新颖的方式，它利用大模型自身的某些机制或中间层输出来生成候选 token。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;树形验证（Token Tree Verification）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：当小模型生成多个候选序列后，将这些序列组织成树形结构，可有效减少冗余存储开销。SpecInfer 提出的树形注意力（Tree Attention）计算方法是树形验证的典型代表。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;投机推理面临的困难，主要在于以下两方面：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;其一是推测准确性与草稿生成效率的权衡。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;小模型的主要任务是快速生成可能的输出，但这往往与生成结果的准确性相矛盾。需要在这两者之间找到最佳平衡点。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;其二是批处理推理场景的适配问题。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;在实际应用中，批处理推理可以提高系统的整体吞吐量。然而，投机推理技术在批处理场景下的应用并不简单。投机推理本质上来说是用空闲的算力换取更高的吞吐，需要处理好投机模型和投机框架引入的耗时，不然无法发挥投机推理在批处理场景下的加速潜力。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;针对投机推理在模型解码阶段的高计算密度、天然匹配昇腾高计算带宽比的特点，为了充分发挥这一优势，在低时延大并发场景下实现高吞吐，解决上面提到的诸多问题，华为团队提出了投机推理框架 FusionSpec 深度优化 MTP 在昇腾上的推理性能，框架耗时从10ms优化至小于1ms，其主要特性为：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;投机框架优化、投机场景算子优化。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;先看前者。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;为了充分发挥昇腾的计算能力，减少 NPU 的空闲时间，团队对投机推理的框架进行了优化：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;1. 考虑 DeepSeek 的模型架构，MTP 层需要主体模型的最后一层结果作为输入，将 MTP 层的执行直接排在主体模型执行之后。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;· 优化后的调度顺序避免了推理的步间数据传输&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;· 同时在 PD 分离的部署场景下也有效减少了节点间的数据传输。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span style=&quot;color: rgb(62, 62, 62);&quot;&gt;&lt;span&gt;2. 参考 MTP 层训练模式，将 MTP 层视为模型的一部分，注意力算子复用主体模型的控制参数。参数复用省去了控制参数的重新构造，降低了框架耗时。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;text-align: center; margin-top: 10px; margin-bottom: 10px; line-height: 0;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; margin-left: 8px; margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfice3ERUF11s7tVWJo4BT5e4WhnaibN9f937PmUftsia4iaank53MF6PXBrA/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;padding: 0px 15px; font-family: PingFangSC-light; line-height: 2; letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;通过优化点1和2，团队压缩了单步推理内主体模型与投机模型间的框架耗时，实现了较低时延下的高并发、大吞吐。为了进一步压缩框架内的前后处理耗时，无论是 Multi-step 还是前后处理全异步方案，都需要提供投机场景昇腾上的轻量步间准备能力。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;text-align: center; margin-top: 10px; margin-bottom: 10px; line-height: 0;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; margin-left: 8px; margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficeDtEvREBJz2oEkiaRO7PXg76TvM3lEeXnovD3o9Ribd3PQvBc9mQ4J0g/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;padding: 0px 15px; font-family: PingFangSC-light; line-height: 2; letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;3. 团队通过 NPU 上的轻量步间准备，实现了 MTP 场景下的 CPU 单次准备、NPU 多次推理，进一步降低了步间的框架耗时。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;再看另一点，投机场景算子优化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;为了在投机推理开启时进一步发挥昇腾的计算能力，压缩端到端时间，团队对采样操作以及投机场景的多头潜在注意力（MLA）计算进行了优化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;未来，投机推理的发展方向有三点。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;首先是多头投机。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;DeepSeek V3 在训练中使用了多层 MTP，并开源了第一层 MTP 的权重。团队利用轻量的算子，使用该层 MTP 权重，实现了对复数 token 的自回归预测。当然，也可以使用多层 MTP 进行复数 token 的投机，未来华为会对此进行支持。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;其次是拒绝采样的昇腾适配加速。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;投机 token 的接受率直接决定了投机推理的收益上限。在保证主体模型生成概率不变的情况下，提升投机的接受率是进一步提升 FusionSpec 的关键所在。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;当前 FusionSpec 采用直接判定主体生成的 token 与投机 token 是否一致这一基本方案。该方案的优势在于无需维护投机 token 的生成概率，但其接受率在模型的信息熵较大时较低。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;但事实上，只要投机模型的 token 生成概率接近主体模型的生成概率时，就应当尽可能接受投机 token 。Rejection Sampling 方案就基于投机模型的生成概率，提升了投机 token 的接受率，但也同时极大增加了 PD 分离场景下节点间的数据传输量和 decode 步骤间的数据维护量。为此，团队将进一步优化FusionSpec 框架：1）增量维护 decode 阶段的概率矩阵；2）优化昇腾算子提升计算效率。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;最后是采样优化。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;采样操作一般包含温度、TopK、TopP 三步，其中 TopK、TopP 朴素算法需对长度为词表大小（在 DeepSeek V3 模型中为 129280）的概率表进行排序、计算前缀和，是采样操作的瓶颈。未来可以采用流式过滤策略、利用昇腾归并排序API，优化TopK、TopP的计算，避免全量排序、全量前缀和。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;margin: 10px 0% 0px;&quot;&gt;&lt;section style=&quot;font-size: 35px; color: rgb(148, 0, 0); text-align: center; line-height: 1; letter-spacing: 0px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; width: 50px; vertical-align: top; background-color: rgb(86, 86, 86); height: auto; line-height: 0; letter-spacing: 0px;&quot;&gt;&lt;section style=&quot;display: flex; width: 100%; height: auto;&quot;&gt;&lt;section style=&quot;margin: 0px 0%; line-height: 0; width: 100%;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; width: 100%; height: auto;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic5hAwuGqsYLiaDBjJXN2RLAtF4XsIficECEFPCaL4GybQVDnWmwUPARog/640?wx_fmt=gif&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;text-align: center;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;OptiQuant量化框架和算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;加速昇腾大模型MoE推理性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;letter-spacing: 1px; padding: 0px 15px; color: rgb(62, 62, 62); font-family: PingFangSC-light; line-height: 2;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;大模型量化技术是一种用于减少AI模型大小和提高其运行效率的技术。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;通过量化，模型的权重从高精度的浮点数转换为比特数更少的整数或浮点数表示，从而减少模型的存储需求、带宽和计算量。将模型权重、激活值、以及KV cache量化为低精度格式（如INT4或INT8）成为缓解资源约束、优化部署效率的关键手段，能够在大幅压缩显存占用的同时尽量保留模型的原始能力，使得诸如DeepSeek类的大模型的高效部署成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;现有的大模型量化技术可以分为两类：&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;激活值无感的权重量化和激活值感知的量化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。经典的量化不需要使用校准技术，不依赖于大模型的输入数据及其分布，而直接对模型参数进行量化。Qserve提出一种双阶段量化策略，针对W4A8量化场景，基于截断范围参数和缩放系数优化int4参数；HQQ提出基于Lp-范数的稀疏优化模型调整量化的缩放系数和偏移量。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;激活值感知的权重量化算法需要通过校准集逐层生成对应的激活值。该激活值可以被用来分析异常值分布，进而设计量化算法及参数。在异常值抑制算法中，可以根据校准集的性质设计算法将校准集的激活数据平滑化，使真实数据的激活值更容易量化。由于校准集的统计特性反映了真实数据的统计特性，因此，校准集的选取至关重要。SmoothQuant通过构造数学等价变换，使能激活值的channel维度缩放。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;然而存在Channel维度的数值缩放无法充分抑制异常值，OstQuant采用了channel维度缩放和正交旋转相结合的异常值抑制技术。GPTQ通过二阶Hessian信息对剩余权重进行矫正，补偿量化引入的误差，从而最小化量化前后模型的输出差异。该方法存在泛化性能力不足的问题。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;为什么要研究大模型量化技术？&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;DeepSeek等大模型的出现给昇腾系统带来了新的问题：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;其一，基于BF16的DeepSeek需要1.3TB的显存空间，同时导致极大的算力和跨机通信开销。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;其二，校准集的泛化性缺失导致了在很多任务上难以达到与原有模型相近的精度水平，甚至在某些场景下精度下降十分严重。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;其三，如何设计昇腾亲和的量化算法，以发挥硬件性能。激活无感的权重量化导致参数量化时无法考虑激活的异常值分布，在低比特量化时造成了推理精度损失；激活感知的权重可以通过数据校准实现精度补偿，然而过度补偿导致了部分数据集精度偏高，部分数据集精度偏低。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;此外，一些伪量化算法的反量化实现在分离式架构上会导致多次访存，带来性能下降。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;为了应对上述挑战，团队提出了OptiQuant量化框架，并设计了创新算法和算子，在保证模型精度的同时显著提升推理效率：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;层间自动混精&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：基于模型权重的四分位极差统计，动态选择最优量化策略。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;混合校准&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：利用多样化校准数据增强泛化性，确保关键业务的高精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;离群值转移&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：通过数学等价变换，将激活中的导致量化误差的离群值转移到参数。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;可学习截断阈值&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：逐层最小化量化MSE，求解最优截断系数以降低整数量化误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;SSZW算法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：采用梯度下降法依次迭代优化缩放因子（s）、零点偏移（z）及量化权重（W）；&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;昇腾亲和的量化算子&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：根据昇腾Cube和Vector分离、内存总线、集群互联的硬件特征，设计相应的硬件友好的算子，极大发挥硬件计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;具体的解决方案如下：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;OptiQuant是一个基于华为昇腾芯片模型量化算法的精度解决方案。除了支持业界主流量化算法功能之外，它新增支持以下三个功能：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;1. 支持接入自定义量化算法和数值类型，可以将多种量化算法的自由组合搭配使用；&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;2. 支持业内主流评测数据集和用户自定义的数据校准集；&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;3. 支持数据并行和流水并行，针对不同大小的大语言模型实现精度验证性能加速。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;text-align: center; margin-top: 10px; margin-bottom: 10px; line-height: 0;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; margin-left: 8px; margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficzXc1iaIyMia0D8gVKuKYhLlkjHagnTjpibOggqoTgaVaU99FziaJTI5ynw/640?wx_fmt=png&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;font-size: 12px; color: rgb(160, 160, 160); text-align: center; letter-spacing: 1px; line-height: 2.5; padding: 0px 15px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;图：OptiQuant量化整体框架&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;letter-spacing: 1px; padding: 0px 15px; color: rgb(62, 62, 62); font-family: PingFangSC-light; line-height: 2;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;如图所示，OptiQuant框架主要由以下几个模块组成：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 量化类型和数值类型&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：OptiQuant支持了Int2/4/8和FP8/HiFloat8等数据类型，支持业界的Qserve，HQQ，LUT等量化方法，在此基础上提出了可学习截断和量化参数优化等算法，进一步减少了量化误差。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 多样化测试数据集和用户自定义校准集&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：OptiQuant支持了判断题，问答题，代码题和数学题等多种测试类别，语种上支持了十种常见语言。此外，OptiQuant支持用户自定义校准集，提升模型量化过程中的泛化性。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;3. 量化权重生成&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：OptiQuant提出了自适应层间混精算法，并且根据对应的量化配置生成对应的权重参数，通过去冗余技术减少参数保存的参数量；OptiQuant进一步提出了FlexSQ等算法，在数据校准过程中，对大模型激活异常值进行了平滑处理，有助于对激活做低比特量化。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;基于Atlas 800I A2服务器的精度测试结果如下：对于DeepSeek-V3-0324模型，W8A8C16和W4A8C16均采用Per-channel量化，实现推理精度与FP8-GPU持平。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;text-align: center; margin-top: 10px; margin-bottom: 10px; line-height: 0;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; margin-left: 8px; margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficFCaicicwjpnCb9OAR2UTpg3XiaibBQZu3uVgLecLA5mw4Hsa77aOdRibY2A/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;text-align: center; margin-top: 10px; margin-bottom: 10px; line-height: 0;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; margin-left: 8px; margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4VficecNbLPcKR7VnOeByxwjRG0cAx9O0bqkAjPl0UJeiadJhvXQHyshB6lg/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;letter-spacing: 1px; padding: 0px 15px; color: rgb(62, 62, 62); font-family: PingFangSC-light; line-height: 2;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;通过OptiQuant和相关优化算法，实现了W8A8C16/W4A8C16的模型精度持平FP8的模型精度，并充分发挥了昇腾硬件性能。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;在后续的研究中，团队将探索PD差异量化、KV cache量化、TopK专家剪枝、通用的等价变换建模、和量化微调等方向，实现更高效、更低比特的权重、激活和KV cache的量化模型推理技术：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;PD差异量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：由于大模型Prefill阶段和Decode阶段具有不同的计算和访存特性，并且对误差的容忍程度不同，可以对PD设计差异化的量化策略，极致平衡大模型的推理性能和精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;多维度异常值抑制算法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：对于前文所述的各类量化算法，如通道维度缩放、矩阵旋转变换、数值截断、量化参数寻优等，可通过上述模型进行合并和统一。基于逐层误差或端到端的量化误差作为训练损失函数，学习得到各策略下的最优参数值，可进一步提升方案的量化精度。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;KV cache/MLA全量化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：KV cache量化技术可以进一步降低显存，使能大batch场景，提升推理吞吐性能。然而，DeepSeek-V3架构的Cache共享机制使得上述量化方式失效。因此，需要设计切实可行的KV cache量化方案，进一步压缩Cache显存。此外，采用MLA全量化可以利用Cube-Core算力，降低推理时延。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;量化微调&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：量化微调是一类常用的量化保精方法，针对DeepSeek-V3架构，量化微调一方面需要解决相比后训练量化（PTQ）技术更加高效资源利用率，另一方面为了避免模型因过拟合部分任务而牺牲通用能力，需要构建更加全面的指令微调数据集，兼顾模型在各个领域上的能力。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;专家剪枝&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：在DeepSeek-V3架构下，可以设计合适的专家剪枝策略，在模型量化的基础上进一步提升参数压缩率，降低数据的通信量和计算量，提升推理性能。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;margin: 10px 0% 0px;&quot;&gt;&lt;section style=&quot;font-size: 35px; color: rgb(148, 0, 0); text-align: center; line-height: 1; letter-spacing: 0px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; width: 50px; vertical-align: top; background-color: rgb(86, 86, 86); height: auto; line-height: 0; letter-spacing: 0px;&quot;&gt;&lt;section style=&quot;display: flex; width: 100%; height: auto;&quot;&gt;&lt;section style=&quot;margin: 0px 0%; line-height: 0; width: 100%;&quot;&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; width: 100%; height: auto;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic5hAwuGqsYLiaDBjJXN2RLAtF4XsIficECEFPCaL4GybQVDnWmwUPARog/640?wx_fmt=gif&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;text-align: center;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;写在最后&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;padding: 0px 15px; color: rgb(62, 62, 62); font-family: PingFangSC-light; line-height: 2; letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;能够实现高吞吐的投机推理和低比特实现足够精度运算的量化技术，是超大规模MoE模型推理部署中的技术难点，华为团队通过推出基于昇腾的FusionSpec投机推理框架以及OptiQuant量化框架，给出了全新的解决方案和思路，相信这两个技术会对大模型推理技术的发展产生巨大的推动作用，同时给用户带来更流畅的体验。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;margin: 10px 0% 0px; text-align: left; display: flex; width: 100%; background-color: rgb(148, 0, 0); height: auto;&quot;&gt;&lt;section style=&quot;margin: 0px 0%; width: 100%;&quot;&gt;&lt;section style=&quot;color: rgb(255, 255, 255); font-size: 18px; width: 100%;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;    往期回顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;margin: 0px;&quot;&gt;&lt;section style=&quot;display: inline-block; width: 100%; border-width: 0px 6px 0px 0px; border-style: solid; border-left-color: transparent; border-right-color: transparent; padding: 0px; background-color: rgb(239, 239, 239);&quot;&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; vertical-align: middle; width: 40%; padding: 0px; height: auto;&quot;&gt;&lt;a href=&quot;http://www.jintiankansha.me/rss/href&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;/a&gt;&lt;section style=&quot;text-align: center; line-height: 0;&quot;&gt;&lt;a href=&quot;http://www.jintiankansha.me/rss/href&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;/a&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; width: 100%; height: auto;&quot;&gt;&lt;a href=&quot;http://www.jintiankansha.me/rss/href&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; style=&quot;width: 100%;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vfic9AKOgRjCZiaIzn0G2h4FYREOSO061g078dSsw1o5457icaIgqRFSaibXQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: middle; width: 60%; padding: 5px 0px; height: auto;&quot;&gt;&lt;section style=&quot;margin: 0px 0%; font-size: 14px;&quot;&gt;&lt;section style=&quot;padding: 0px 15px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;推理性能PK，&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;华为+DeepSeek&amp;gt;英伟达？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;margin: 0px 0px 10px;&quot;&gt;&lt;section style=&quot;display: inline-block; width: 100%; border-width: 0px 6px 0px 0px; border-style: solid; border-left-color: transparent; border-right-color: transparent; padding: 0px; background-color: rgb(239, 239, 239);&quot;&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; vertical-align: middle; width: 40%; padding: 0px; height: auto;&quot;&gt;&lt;a href=&quot;http://www.jintiankansha.me/rss/href&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;/a&gt;&lt;section style=&quot;text-align: center; line-height: 0;&quot;&gt;&lt;a href=&quot;http://www.jintiankansha.me/rss/href&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;/a&gt;&lt;section style=&quot;vertical-align: middle; display: inline-block; line-height: 0; width: 100%; height: auto;&quot;&gt;&lt;a href=&quot;http://www.jintiankansha.me/rss/href&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656092989&amp;amp;idx=2&amp;amp;sn=1125461f1f4984b44870de37dd1f65db&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656093320&amp;amp;idx=2&amp;amp;sn=c5026453524cb836e82cd1db01b309ff&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; style=&quot;width: 100%;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/b2YlTLuGbKBPRXcVqGSEoFIlDDeg4Vficib6AwDibwibf98IRhc7wM0RVQdxuUEtIgLhWH0byOq4zDxB4T6MDc4Lug/640?wx_fmt=jpeg&amp;amp;from=appmsg&quot; style=&quot;vertical-align: middle; width: 100%;&quot; /&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: middle; width: 60%; padding: 5px 0px; height: auto;&quot;&gt;&lt;section style=&quot;margin: 0px 0%; font-size: 14px;&quot;&gt;&lt;section style=&quot;padding: 0px 15px;&quot;&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;华为+DeepSeek，&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0px; padding: 0px;&quot;&gt;&lt;strong&gt;&lt;span&gt;终于不再“服务器繁忙”？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style=&quot;text-align: left; display: flex; margin: 10px 0px;&quot;&gt;&lt;section style=&quot;display: inline-block; vertical-align: middle; width: auto; height: auto;&quot;&gt;&lt;section style=&quot;margin: 0.5em 0px;&quot;&gt;&lt;section&gt;&lt;svg viewBox=&quot;0 0 1 1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;&lt;/svg&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: middle; width: auto; border-style: solid; border-width: 0px; border-left-color: rgb(109, 104, 247); padding: 0px 0px 0px 5px; height: auto; line-height: 0.1;&quot;&gt;&lt;section style=&quot;display: flex; margin: 0px;&quot;&gt;&lt;section style=&quot;display: inline-block; vertical-align: top; width: auto; height: auto; padding: 0px 0px 0px 8px; background-color: rgb(148, 0, 0);&quot;&gt;&lt;section style=&quot;margin: 0px; text-align: center;&quot;&gt;&lt;section style=&quot;text-align: justify; line-height: 0.8;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span style=&quot;color: rgb(255, 255, 255); font-size: 10px; text-align: center;&quot;&gt;&lt;span&gt;行业观察  &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: top; width: auto; height: auto;&quot;&gt;&lt;section style=&quot;text-align: center;&quot;&gt;&lt;section style=&quot;display: inline-block; width: 0px; height: 0px; vertical-align: top; overflow: hidden; border-style: solid; border-width: 0px 0px 16px 9px; border-color: rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgba(255, 255, 255, 0) rgb(148, 0, 0);&quot;&gt;&lt;section style=&quot;text-align: justify;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section style=&quot;display: inline-block; vertical-align: bottom; width: auto; height: auto;&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section style=&quot;display: inline-block; width: 8px; height: 8px; vertical-align: top; overflow: hidden; border-radius: 182px; background-color: rgb(148, 0, 0);&quot;&gt;&lt;section style=&quot;text-align: justify;&quot;&gt;&lt;p style=&quot;white-space: normal; margin: 0px; padding: 0px;&quot;&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/section&gt;&lt;p style=&quot;display: none;&quot;&gt;&lt;/p&gt;&lt;/div&gt;
    

    
    &lt;br /&gt;

    
        &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656093511&amp;amp;idx=2&amp;amp;sn=bdc62d918f8652944637795858d54217&amp;amp;chksm=6735ad824b695569ae7345ba8b91e1578645a4ae4e2b297ff6781da69ac67146e8017a337601&amp;amp;scene=0#rd&quot; style=&quot;color: blue;&quot; target=&quot;_blank&quot;&gt;文章原文&lt;/a&gt;
        &lt;br /&gt;
    

    

    &lt;img alt=&quot;&quot; class=&quot;&quot; height=&quot;1px&quot; src=&quot;http://www.jintiankansha.me/rss_static/82277/kZTkjF8j8N&quot; style=&quot;width: 1px; height: 1px; display: none;&quot; width=&quot;1px&quot; /&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
<pubDate>Wed, 21 May 2025 19:41:00 +0800</pubDate>
</item>
<item>
<guid>e8e5160e314a51783c464381522d3c8f</guid>
<title>DeepSeek们越来越聪明，却也越来越不听话了</title>
<link>http://weixin.sogou.com/weixin?type=2&amp;query=%E8%99%8E%E5%97%85%E7%BD%91+DeepSeek%E4%BB%AC%E8%B6%8A%E6%9D%A5%E8%B6%8A%E8%81%AA%E6%98%8E%EF%BC%8C%E5%8D%B4%E4%B9%9F%E8%B6%8A%E6%9D%A5%E8%B6%8A%E4%B8%8D%E5%90%AC%E8%AF%9D%E4%BA%86</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content&quot; id=&quot;js_content&quot;&gt;&lt;section start=&quot;start&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKCXh5aickzic1MdfWDLgWpNOvQJN9KevBLoH9PWMYUZ2kmmBoFE9RPTZm4BhqicOEeDdx8S1mjmBkSTw/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;本文来自微信公众号：&lt;/span&gt;&lt;/span&gt;&lt;span href=&quot;https://mp.weixin.qq.com/s/BOvXyrHOuTHwzeE2xO0OKg&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;数字生命卡兹克&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，作者：数字生命卡兹克，题图来源：AI生成&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年，DeepSeek R1火了之后，几乎快形成了一个共识，就是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI推理能力越强，执行任务时就应该越聪明。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从2022年Chain-of-Thought横空出世，到今天Gemini 2.5 Pro、OpenAI o3、DeepSeek-R1、Qwen3，这些旗舰模型的统治性表现，我们一直相信，让模型先想一想，是一个几乎不会出错的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，这种聪明，也会带来一些副作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是提示词遵循能力，变得越来越差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;换句话说，就是越来越不听你的话了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我在过年期间写DeepSeek的攻略文：《DeepSeek的提示词技巧，就是没有技巧》的时候，也提到了这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，这只是我自己使用中的感觉，它变得越来越聪明，但是感觉却越来越不听话了，以至于我现在，最常用的模型，开始变成了GPT4o，所有的推理模型，反而会用的越来越少了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，确实没有经历过验证，所以也不是特别敢说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到昨晚回来，在扒拉论文的时候，看到一篇提到这个话题的论文，我读完以后觉得，终于可以来聊聊这个事了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文叫，《When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs》。&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（网址在此：https://arxiv.org/abs/2505.11423）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKCXh5aickzic1MdfWDLgWpNOv4fGuiaYRVEqlZPM1TlxRHahsib5P9NG1r5nLib2gsBvAQvSF8ibaEoUJvQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;它用极其扎实的实验，验证了上述的论点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你让模型开始推理，它反而更容易违反你给出的指令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;当思考失败，这聪明的智商反而就变成了负担。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我尽量用人话，来给大家简单的科普一下论文中的实验和内容，再说说我的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先说论文本身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文的研究团队来自Harvard、Amazon和NYU，他们花了好几个月，干了一件特别简单却没人认真做过的事，就是把这个思考过程应用在一个最基础、最现实、最需要稳定性的场景上：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听懂人类指令，然后照做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们做了两组测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一组叫IFEval，一个标准的执行类任务测试集，每个任务都非常简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如“写400字以上”“必须提到AI三次”“输出格式必须是JSON”“句末不能有标点”等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的任务都有明确的可验证标准，要么做对要么做错，没有模糊地带。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二组叫ComplexBench，这就更有趣了，是那种“多约束、逻辑组合、顺序嵌套”的复杂指令，比如“先做A中的三选一，再加上B的格式要求，最后加上C的语言限制”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听起来好像推理模型在这种任务上应该更有优势？毕竟这不是随便一两句话就能糊弄过去的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，论文的结论惊人又统一：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;绝大多数模型在使用CoT推理后，执行准确率反而下降了。而且，下降得还不轻。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们一共测了15个模型，涵盖开源的&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（比如LLaMA、Mixtral、Qwen2.5、DeepSeek系列）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;和闭源的&lt;/span&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（GPT-4o-mini、Claude 3.5/3.7等等）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在IFEval上，14个模型中有13个使用CoT时准确率变低；在ComplexBench上，所有模型都在使用CoT后，表现变差。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKCXh5aickzic1MdfWDLgWpNOvnLRmpbarCDwKFacAao917Z4Hia1LxaufRSCcyUAttNUuMSbGmibkpticQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;甚至连像 LLaMA-3-70B-Instruct 这种参数量较大、训练完整的模型，在使用CoT时也会从85.6%的准确率掉到77.3%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8个点的损失，在工业级任务里其实非常恐怖了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有推理模型开不开推理的对比，典型的就是DeeSeek V3和R1，还有Claude 3.7这种混合模型。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKCXh5aickzic1MdfWDLgWpNOvibZ1mwRAKyoZb2mbr4HIOw3GcKpyRxJe5rAukV9Yv0XVJ4Tw5tzChaQ/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;会发现，几乎都有下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们手工扒拉了1500多个样本，看了所有的思维链，总结出来了原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们发现，当模型用了思维链条之后，它确实变聪明了，比如能更好地遵守格式、注意字数、精确用词，像是“必须用15个大写字母”这种题，靠CoT反而更稳。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKCXh5aickzic1MdfWDLgWpNOvibKXcm2vAial9iaHT5jIkVyVNKLEHTw0Wftk1qnOxHy8tFdL9r4xeow6A/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;但，它也变得神经质了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它开始自作主张，觉得自己懂了任务的深层含义，于是它会擅自删掉、修改，甚至加上有帮助的解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文里提到很多模型会在“只允许输出法语”的题目中，善意地补上一句“这是‘Bonjour’的英文翻译”，在“只能输出引号内容”的任务里，自动补充前情摘要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;它太想表现自己了，太想证明我真的理解你了，于是它忘了本该严格遵守的指令。这就是它学会推理之后的副作用。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了找出这个副作用的根源，他们引入了一个新概念：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;约束注意力&lt;/span&gt;&lt;/strong&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;（Constraint Attention）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们发现，不管是GPT-4o-mini，还是Claude 3.7，几乎所有模型在用了CoT思维链后，它们的注意力，也就是在生成答案时，关注任务描述中“关键限制”的那部分注意力，明显下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以理解为，当你要求一个人边想边说，他反而忘了原本你只要他复述句子的简单目标。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/b2YlTLuGbKCXh5aickzic1MdfWDLgWpNOvTb0WlGU4cqia8wuP5tX16RTe80T0oUeoT8d3HWRZ4KrDgLdwYyYNSxg/640?wx_fmt=png&amp;amp;from=appmsg&quot; /&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;更有趣的是，他们还测了一个我一直想知道的问题的答案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是CoT思考越长，准确率越高吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果是，几乎没有显著相关性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思考长度和是否做对，几乎没有直接联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，更努力≠更对。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，其实结论很简单，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;就是在要求非常规范、精准的大模型输出任务上，完全不需要使用推理模型或者思维链，直接上非推理模型，效果会更好。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，如果，就是非要用，希望提升整体指令遵循效果呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也基于自己的测试，给出了4种方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一种，是“Few-Shot少样本示例”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给模型提前看几个做对的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;效果一般般，问题在于输入太长，而且示例选自有模型，容易有偏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二种，是“Self-Reflection 自我反思”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型第一次输出之后，再自己复查一遍，“你刚才做对了吗？”然后再决定是否修改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这招对大模型效果很好，因为它们确实能自省，但小模型效果惨不忍睹，因为它们智力不够，就像个不知错的小孩，越反思越错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三种，是“Self-Selective Reasoning”。让模型自己判断这个任务是否需要推理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果是：它召回率很高，基本上只要推理有用它都能猜出来，但精确度很低，一言不合就开始推理，哪怕你只是让它改个词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四种是最有效的，“Classifier-Selective Reasoning”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直接训练一个小模型作为判断器，来帮主模型判断某个任务是否该启用CoT。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;效果显著，在两个测试集上几乎都能恢复失去的准确率，甚至有些模型比原始还高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点就是每个主模型都要单独训练一个判断器，成本太高……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文大概就是这样，对我自己非常有帮助，我看的论文不多，这篇是我自己看的，我认为对“CoT推理在执行任务中的潜在副作用”这个话题，比较完整的研究之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，我也想聊聊，这篇论文对我的启示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们总觉得，聪明，就意味着知道得多、分析得细、每个变量都不放过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但事实上，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;真正强大的智能，从来都不是把所有细节一股脑地扫过一遍，而是知道在哪一秒钟，把注意力放在哪个点上。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如我们小时候考试，很多人因为太想得高分，最后反而在最简单的题上丢分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;成年人做选择，明明已经知道该怎么做了，却非得做个SWOT分析表、拉个10页PPT讨论，最后被复杂困死。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公司做决策，明明方向明确，却因为分析得太多、风险评估太细，最后团队谁也不敢拍板，错过风口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI其实跟人很像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面很多CoT的验证，还有Constraint Attention，其实也证明了，大模型不是笨，而是思维资源错配了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你让它完成任务，它却跑去想着“怎么把这段话说得更优雅”、“这句话需不需要加个逻辑转折”、“前后是不是够自然”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你让它干活，它在脑子里脑补了几万种情节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;真正厉害的智能，其实应该是聚焦。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如你叫一个人帮你看一下一份报告有没有错，一个低阶执行者可能就只会一句句校对标点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而一个高阶智能，可能会反过来先问你，“你重点是要我看错字，还是看数据逻辑？”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你说清楚重点，他就能把80%的注意力锁死在正确位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而如果他啥都想看一点，最后很可能错得最离谱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们真正需要的，可能，是对“该想什么”有判断能力的智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像我们人类那些最令人敬畏的时刻，不是我们知道多少，而是我们能瞬间把注意力聚焦在关键节点上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;危机时刻，考场钟响，夜深人静一个念头浮上心头的时候，你知道的，你不能全看，你只能看准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那个“看准”，在我看来，可能就是智能真正的体现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一点，看似简单，却足够让AI从“聪明”，变成“智能”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是我读完论文之后，真正想跟大家分享的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们不缺思考的能力，我们缺的，是思考的分寸感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意力，不是撒网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而是出击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span label=&quot;备注&quot;&gt;&lt;span&gt;本文来自微信公众号：&lt;/span&gt;&lt;/span&gt;&lt;span href=&quot;https://mp.weixin.qq.com/s/BOvXyrHOuTHwzeE2xO0OKg&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;数字生命卡兹克&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，作者：数字生命卡兹克&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系hezuo@huxiu.com&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;如对本稿件有异议或投诉，请联系tougao@huxiu.com&lt;/span&gt;&lt;/p&gt;&lt;p start=&quot;start&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;End&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;/section&gt;&lt;p style=&quot;display: none;&quot;&gt;&lt;/p&gt;&lt;/div&gt;
    

    
    &lt;br /&gt;

    
        &lt;a class=&quot;media_tool_meta meta_primary&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MTQzMjE1NjQwMQ==&amp;amp;mid=2656093373&amp;amp;idx=3&amp;amp;sn=5d452f5f9300ee5c3ecb25ac2f7d848d&amp;amp;chksm=67253b5e3e71c62650b8039879e33763a8afbb7eaf758ae6cc54875eb957bf255eae8045ff5d&amp;amp;scene=0#rd&quot; style=&quot;color: blue;&quot; target=&quot;_blank&quot;&gt;文章原文&lt;/a&gt;
        &lt;br /&gt;
    

    

    &lt;img alt=&quot;&quot; class=&quot;&quot; height=&quot;1px&quot; src=&quot;http://www.jintiankansha.me/rss_static/82277/icj2seBnyK&quot; style=&quot;width: 1px; height: 1px; display: none;&quot; width=&quot;1px&quot; /&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
<pubDate>Wed, 21 May 2025 08:00:00 +0800</pubDate>
</item>
</channel></rss>