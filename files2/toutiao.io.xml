<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3cca7b50affea12754da844a038a9de9</guid>
<title>SPI 机制，「可插拔」的奥义所在</title>
<link>https://toutiao.io/k/wulnrhz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是小菜。一个希望能够成为 &lt;strong&gt;吹着牛X谈架构&lt;/strong&gt; 的男人！如果你也想成为我想成为的人，不然点个关注做个伴，让小菜不再孤单！&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本文主要介绍 &lt;code&gt;SPI 机制&lt;/code&gt;&lt;/p&gt;&lt;p&gt;如有需要，可以参考&lt;/p&gt;&lt;p&gt;如有帮助，不忘 &lt;strong&gt;点赞&lt;/strong&gt; ❥&lt;/p&gt;&lt;p&gt;微信公众号已开启，&lt;strong&gt;菜农曰&lt;/strong&gt;，没关注的同学们记得关注哦！&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们上篇文章讲到了 Java 中 Agent 用法，不少小伙伴都觉得该方式比较偏门，平常开发不常用（几乎没用）。其实不然，不常用是跟项目挂钩，项目不常用不代表该方法机制不常用，因此很多时候我们学习不能坐井观天，认为项目中没用到就可以不学，跟着项目成长往往不能成长~！&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;上篇跳转入口：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4ODA5MzUwOQ==&amp;amp;mid=2247487746&amp;amp;idx=1&amp;amp;sn=cf6b4e186e41a4e3c5991abfc4ab0a00&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Java 高级用法，写个代理侵入你？&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么这篇我们将继续讲 Java 中的另一个知识点，也就是 &lt;code&gt;SPI&lt;/code&gt; 机制，乍听感觉依然陌生，这时可别再打退堂鼓！往下看你就会发现原来平时开发中经常看到！&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;一、SPI&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们这篇文章以&lt;code&gt;问题&lt;/code&gt;作为导向，用问题来驱动学习，小菜先抛出几个问题，下面将针对这几个问题进行解释并扩展&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;什么是 SPI ？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;SPI 和 API 的区别？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;平常中有使用到 SPI 吗？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1、什么是 SPI&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;SPI 是三个单词的缩写 &lt;code&gt;S&lt;/code&gt;ervice &lt;code&gt;P&lt;/code&gt;rovider &lt;code&gt;I&lt;/code&gt;nterface，字面意思：服务提供接口。它是 Java 提供的一套用来被第三方实现或者扩展的接口，它可以用来启用框架&lt;code&gt;扩展和替换&lt;/code&gt;组件。具体作用便是为这些被扩展的 API 寻找服务实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而Java SPI 便是 JDK 内置的一种服务提供发现机制，常用于创建可扩展、可替换组件的应用程序，是java中&lt;code&gt;模块化&lt;/code&gt;与&lt;code&gt;插件化&lt;/code&gt;的关键。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们提到了两个概念，分别是 &lt;code&gt;模块化&lt;/code&gt;和&lt;code&gt;插件化&lt;/code&gt;。模块化很好理解，就是将一个项目分成多个模块，模块间可能存在相互依赖（也就是通过 maven 的方式），有使用微服务开发的同学就毫不陌生了，如果没有使用微服务开发也不打紧，单体项目中为了界定 control，service，repository层，也会将每个领域单独提取成模块，而不是以目录的方式~&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6918918918918919&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtaCPITnAibAfLvsXy322apkV5z80S9J8jEKEiad3nn8eYP2B6ibAMYHOictg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;185&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2、类加载机制&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面我们已经说到了 &lt;strong&gt;SPI&lt;/strong&gt; 较为粗浅的概念，小菜这里不打算直接深入 SPI，在深入 SPI 之前，我们先了解一下  Java 中的类加载机制。类加载机制可能实际开发中并不会去在意，但是它却无处不在，而这个也是面试的一大热点话题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在JVM中，类加载器默认是使用双亲委派原则，默认的类加载器包括&lt;code&gt;Bootstarp ClassLoader&lt;/code&gt;、&lt;code&gt;Extension ClassLoader&lt;/code&gt; 和 &lt;code&gt;System ClassLoader（Application ClassLoader）&lt;/code&gt;，当然可能还有自定义类加载器~自定义类加载器可以通过继承 &lt;strong&gt;java.lang.classloader&lt;/strong&gt; 来实现&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;各个类加载器作用范围如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Bootstrap ClassLoader：负责加载 JDK 自带的 rt.jar 包中的类文件，是所有类加载的父类&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Extension ClassLoader：负责加载 java 的扩展类库从 &lt;strong&gt;jre/lib/ect&lt;/strong&gt;或 &lt;strong&gt;java.ext.dirs&lt;/strong&gt; 系统属性指定的目录下加载类&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;System ClassLoader：负责从 classpath 环境变量中加载类文件&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;类加载继承关系图如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6229773462783171&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta2q8qBA6z5xaCw4CAOdfXrFw3gFrrwUovfJeIHbJI7ibibItoByxlicslQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;618&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1）双亲委派模型&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;什么是双亲委派模型？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当一个类加载器收到加载类的任务时，会先交给自己的父加载器去完成，一级一级往上，因此最后都会传递到 Bootstrap ClassLoader 进行加载，只有当父加载器无法完成加载任务的时候，才会尝试自己进行加载&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;为什么要这样设计呢？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、采用双亲委派原则可以避免相同类重复加载，每个加载器在进行类加载任务的时候都会委派给自己的父类加载器进行加载，如果父类加载无法加载才自己进行加载，避免重复加载的局面&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、可以保证类加载的安全性，不管是哪个加载器加载这个类，最终都是委托给顶层的加载器进行加载，保证任何加载器最终得到的都是同一个类对象&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加载过程如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7593014426727411&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtadFxdtdeiaC9wSo2CwYRkdrddibYQrsNxZZffrMombAI5jd6Vo9aicYkxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1317&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;这样做的缺陷？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;子类加载器可以使用父类加载器已经加载过的类，而父类加载器无法使用子类加载器加载过的类（类似继承的关系）。这里就可以扯到 Java SPI 了，Java 提供了很多服务提供者接口（SPI），它可以允许第三方为这些接口提供实现，比如数据库中的 SPI 服务 - JDBC，这些 SPI 的接口由Java核心类提供，实现者确实第三方，这样就会存在问题，提供者由 Bootstrap ClassLoader加载，而实现者是由第三方自定义类加载器加载，而这个时候顶层类加载就无法使用子类加载器加载过的类&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3236994219653179&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta9dc62Nx72z3oy8uM2UYXKHicL6ticjNybggIgvTb3iabSIDjPMXZPSIww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;519&quot;/&gt;&lt;figcaption&gt;=&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;解决方法&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要解决这个问题就得打破双亲委派原则&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以使用线程上下文类加载器（ContextClassLoader）加载&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Java 应用上下文加载器默认是使用AppClassLoader，想要在父类加载器使用到子类加载器加载的类可以使用 &lt;code&gt;Thread.currentThread().getContextClassLoader()&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如我们想要加载资源可以使用以下方式：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 使用线程上下文类加载器加载资源&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception&lt;/span&gt;{&lt;br/&gt;    String name = &lt;span&gt;&quot;java/sql/Array.class&quot;&lt;/span&gt;;&lt;br/&gt;    Enumeration&amp;lt;URL&amp;gt; urls = Thread.currentThread().getContextClassLoader().getResources(name);&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (urls.hasMoreElements()) {&lt;br/&gt;        URL url = urls.nextElement();&lt;br/&gt;        System.out.println(url.toString());&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3、Java SPI&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说完类加载机制，我们再回到 Java SPI 来，我们先通过例子熟悉下 SPI 的使用方式&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用过程图如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4898236092265943&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtapx7vzZUibz2tHg7eLibBMviamTWAwnCy63Qx33OQc8d6UhcshvxLcfv5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;737&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;更加通俗的理解，SPI 实际上就是一种&lt;code&gt;策略模式&lt;/code&gt;的实现，基于接口编程再配合上配置文件来读取。这也符合我们的编程方式：&lt;code&gt;可插拔&lt;/code&gt;~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用例子如下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;项目结构&lt;/strong&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8755458515283843&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta7gPeNLzIFzKJMMvI76BcFicWPCF6mRibg52eUYC5tOfErBhXhDIRD1Hw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;458&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;ICustomSvc&lt;/code&gt;：服务提供接口（也就是 SPI）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;CustomSvcOne/CustomSvcTwo&lt;/code&gt;：实现者（这里直接在一个项目中简单实现，也可以通过 jar 包导入的方式实现）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;cbuc.life.spi.service.ICustomSvc&lt;/code&gt;：配置文件&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;文件内容&lt;/strong&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9404934687953556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta8SZOSbrJwN2eTyccqS2aQ7KxxYKodELpqliaS0UY6LicU9LibReRf10Qg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1378&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后我们启动 &lt;code&gt;CustomTest&lt;/code&gt; 查看控制台结果&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2772727272727273&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta3ibuhZhHb3QqvRsr6Pkhw4MtVVCktExGtjlARpp3KSUpzezqH7yHHeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;220&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到是可以加载到我们的实现类的方法，而这也就意味着已经实现了SPI 的功能&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1）实现原理&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实我们上面使用SPI的时候可以看到一个关键的类那就是&lt;code&gt;ServiceLoader&lt;/code&gt; ，该类位于 &lt;code&gt;java.util&lt;/code&gt;包下，我们直接点进 &lt;code&gt;load()&lt;/code&gt; 方法查看如何调用&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;点进 &lt;code&gt;load()&lt;/code&gt; 方法我们首先看到以下代码&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.17732558139534885&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtaZUDnbalDicibJd4DuiaD6Ydh9QiaS4poG9G2aPuSrFyUliaP5ibPu2scwMEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该块代码只是简单的声明了使用线程上下文加载器，我们继续跟进 &lt;code&gt;ServiceLoader.load(service, cl)&lt;/code&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.22530864197530864&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtaSeIoDibuxYI14CboKxsc91EwV797iaCuicXibaticETkibWI7DqgMibCQUBSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;648&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该块代码也没啥内容，声明返回了 ServiceLoader 对象，这个对象有什么文章？我们可以查看这个类声明&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ServiceLoader&lt;/span&gt;&amp;lt;&lt;span&gt;S&lt;/span&gt;&amp;gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;Iterable&lt;/span&gt;&amp;lt;&lt;span&gt;S&lt;/span&gt;&amp;gt;&lt;/span&gt;{}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到这个对象实现了 &lt;code&gt;Iterable&lt;/code&gt; 接口，说明具有迭代的方法，可以猜测这样是为了取出我们定义 &lt;strong&gt;SPI&lt;/strong&gt; 的所有实现类。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该类的构造函数如下&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.20634920634920634&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta22riaT3RG2L71x0Bic5gXtuIEA3oUEsxVibTJcFXiaFqUPHsicntIJa3FzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;882&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;重点在于 &lt;code&gt;reload()&lt;/code&gt; 方法，我们继续跟进&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5073891625615764&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtaXEB5XW2usOR0ibk4YO9Y8S8C8pkh0GZ99pA5x3zp5pHrg9sDib0tl2VA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;812&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里将注释一起截取出来，我们可以看到这句话 &lt;code&gt;方法将惰性查找实例化&lt;/code&gt;，说明了上述说到实现 &lt;code&gt;Iterable&lt;/code&gt; 接口的用处，我们这里可以先点进 &lt;code&gt;iterator()&lt;/code&gt; 方法查看是如何实现的&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8558322411533421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta9uicx3VibUDpU4CV0icayYkKLiabL0jsGzrvoP0aIkXQmAg8ygwV8xqycA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到有个关键的缓存，该缓存存储 &lt;code&gt;provider&lt;/code&gt;,每次操作的时候都会去该缓存中查找，如果存在则返回，否则采用 &lt;code&gt;LazyIterator&lt;/code&gt; 进行查找，我们进行进入到&lt;code&gt;LazyIterator&lt;/code&gt;类中查看如何实现，由于该类代码过长，我们直接截取关键代码，有兴趣的同学可以自行查看完整代码：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6095764272559853&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWtabzFkRo0YF0BaJdnwZNhicgzRHoDLlOkSiaibCsVF3KotNiaPyKNEzIDjPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1086&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到该代码的实现顿时豁然开朗了，我们看到了熟悉的目录名 &lt;code&gt;META-INF/services/&lt;/code&gt;，该代码会去指定目录下获取文件资源，然后通过上传传入的线程上下文类加载器进行类加载，这样子我们的 SPI 实现类就可以供项目使用了~ 看完不得不感叹 &lt;strong&gt;妙啊&lt;/strong&gt;~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里为止，我们就已经拆解了 JAVA SPI 的使用以及实现原理，看完后是不是觉得该技巧也没有离我们很远~！&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4、小结&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 Java SPI 机制更好的实现了 &lt;code&gt;可插拔&lt;/code&gt; 的开发理念，使得第三方服务模块的装配与调用者的业务代码相分离，也就是 &lt;code&gt;解耦&lt;/code&gt; 的概念，我们应用程序可以根据实际业务需要进行动态插拔。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;二、扩展&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Spring SPI&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然 SPI 机制不仅仅在 JDK 中实现，我们日常开发用到的 Spring 以及 Dubbo 框架都有对应的 SPI 机制。在Spring Boot中好多配置和实现都有默认的实现，我们如果想要修改某些配置，我们只需要在配置文件中写上对应的配置，那么项目应用的便是我们定义的配置内容，而这种方式就是采用 SPI 实现的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Java SPI 与 Spring SPI 的区别&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;JDK 使用的加载工具类是 &lt;code&gt;ServiceLoader&lt;/code&gt;，而 Spring 使用的是 &lt;code&gt;SpringFactoriesLoader&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;JDK 目录命名方式是&lt;code&gt;META-INF/services/提供方接口全类名&lt;/code&gt;，而 Spring 使用的是 &lt;code&gt;META-INF/spring-factories&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用 Spring Boot 中我们会将想要注入 IOC 容器的类将全类限定名写到 &lt;code&gt;META-INF/spring.factories&lt;/code&gt;文件中，在 Spring Boot 程序启动的时候就会由 &lt;strong&gt;SpringFactoriesLoader&lt;/strong&gt; 进行加载，扫描每个 jar 包 class-path 目录下的 &lt;code&gt;META-INF/spring.factories&lt;/code&gt; 配置文件，然后解析 properties 文件，找到指定名称的配置后返回&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5215469613259669&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaUuMibQzNk4UHbSWDaH1fWta846haQxOZ8cXpiaxyzfibnxhh1JRRWBeZJssib3cicP7p7lDttIO17bQww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1810&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以说 SPI 在我们实际开发中随处可见，不止 Spring ，比如JDBC加载数据库驱动，SLF4J加载不同提供商的日志实现还有 Dubbo 使用SPI的方式实现框架的扩展等等&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不要空谈，不要贪懒，和小菜一起做个&lt;code&gt;吹着牛X做架构&lt;/code&gt;的程序猿吧~点个关注做个伴，让小菜不再孤单。咱们下文见！&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;今天的你多努力一点，明天的你就能少说一句求人的话！&lt;em&gt;我是小菜，一个和你一起变强的男人。&lt;/em&gt; &lt;code&gt;💋&lt;/code&gt;微信公众号已开启，&lt;strong&gt;菜农曰&lt;/strong&gt;，没关注的同学们记得关注哦！&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b791eb704ef8e2b535b146152690d9f6</guid>
<title>面试必备：MySQL 八股文系列</title>
<link>https://toutiao.io/k/7olzy1z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 三大范式&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第一范式：确保每列保持原子性，数据表中的所有字段值都是不可分解的原子值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第二范式：确保表中的每列都和主键相关。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第三范式：确保每列都和主键列直接相关而不是间接相关。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.1 反范式化&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们应从业务角度出发，设计出符合范式准则要求的表结构。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;反范式化指的是通过增加冗余或重复的数据来换时间增加效率,违反第二第三范式。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;反范式化可以减少关联查询时，join表的次数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在一些场景下，可以通过 JSON 数据类型进行反范式设计，提升存储效率。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. mysql的几种引擎，有什么区别&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;特性&lt;/th&gt;&lt;th&gt;InnoDB&lt;/th&gt;&lt;th&gt;MyISAM&lt;/th&gt;&lt;th&gt;MEMORY&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;事物安全&lt;/td&gt;&lt;td&gt;支持&lt;/td&gt;&lt;td&gt;不支持&lt;/td&gt;&lt;td&gt;不支持&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;对外建的支持&lt;/td&gt;&lt;td&gt;支持&lt;/td&gt;&lt;td&gt;不支持&lt;/td&gt;&lt;td&gt;不支持&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;存储限制&lt;/td&gt;&lt;td&gt;64TB&lt;/td&gt;&lt;td&gt;有&lt;/td&gt;&lt;td&gt;有&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;空间使用&lt;/td&gt;&lt;td&gt;高&lt;/td&gt;&lt;td&gt;低&lt;/td&gt;&lt;td&gt;低&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;内存使用&lt;/td&gt;&lt;td&gt;高&lt;/td&gt;&lt;td&gt;低&lt;/td&gt;&lt;td&gt;高&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;插入数据的速度&lt;/td&gt;&lt;td&gt;低&lt;/td&gt;&lt;td&gt;高&lt;/td&gt;&lt;td&gt;高&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1  InnoDB、MyISAM 对比&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;InnoDB支持事务，MyISAM不支持。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;InnoDB 支持外键，而 MyISAM 不支持。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键。MyISAM是非聚集索引，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;InnoDB 不保存表的具体行数。MyISAM 用一个变量保存了整个表的行数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Innodb 有 redolog 日志文件，MyISAM 没有。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Innodb：frm是表定义文件，ibd是数据文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Myisam：frm是表定义文件，myd是数据文件，myi是索引文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;InnoDB 支持表、行锁，而 MyISAM 支持表级锁。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;InnoDB 必须有唯一索引(主键),如果没有指定的话 InnoDB 会自己生成一个隐藏列 Row_id 来充当默认主键，MyISAM 可以没有。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3. 为什么要使用自增主键&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;１.普通索引的 B+ 树上存放的是主键索引的值，如果该值较大，会「导致普通索引的存储空间较大」&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;２.使用自增 id 做主键索引新插入数据只要放在该页的最尾端就可以，直接「按照顺序插入」，不用刻意维护&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3.页分裂容易维护，当插入数据的当前页快满时，会发生页分裂的现象，如果主键索引不为自增 id，那么数据就可能从页的中间插入，页的数据会频繁的变动，「导致页分裂维护成本较高」&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4. 什么是索引?&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;百度百科的解释：索引是对数据库表的一列或者多列的值进行排序一种结构，使用索引可以快速访问数据表中的特定信息。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;索引就一本书的目录，可以极大的提高我们在数据库的查询效率。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1 索引的优缺点？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;大大加快数据检索的速度。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;将随机I/O变成顺序I/O(因为B+树的叶子节点是连接在一起的)&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;加速表与表之间的连接&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;从空间角度考虑，建立索引需要占用物理空间&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;从时间角度 考虑，创建和维护索引都需要花费时间，例如对数据进行增删改的时候都需要维护索引。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.2 索引的数据结构？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;索引的数据结构主要有 B+ 树和哈希表，对应的索引分别为 B+ 树索引和哈希索引。InnoDB 默认的索引类型为 B+ 树索引。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.3 索引的类型有哪些?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MySQL 主要的索引类型主要有 FULLTEXT，HASH，BTREE，RTREE。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;FULLTEXT&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;FULLTEXT 即全文索引，MyISAM存储引擎和InnoDB存储引擎在MySQL5.6.4以上版本支持全文索引，一般用于查找文本中的关键字，多在CHAR，VARCHAR，TAXT 等数据类型上创建全文索引。全文索引主要是用来解决&lt;code&gt;WHERE name LIKE &quot;%wekenw%&quot;&lt;/code&gt;等针对文本的模糊查询效率低的问题。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;HASH&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;HASH 即哈希索引，哈希索引多用于等值查询，时间复杂夫为o(1)，效率非常高，但不支持排序、范围查询及模糊查询等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;BTREE&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;BTREE 即 B+ 树索引，INnoDB存储引擎默认的索引，支持排序、分组、范围查询、模糊查询等，并且性能稳定。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;RTREE&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;RTREE 即空间数据索引，多用于地理数据的存储，相比于其他索引，空间数据索引的优势在于范围查找。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.4 索引的种类有哪些？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;主键索引：数据列不允许重复，不能为NULL，一个表只能有一个主键索引&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;组合索引：由多个列值组成的索引。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;唯一索引：数据列不允许重复，可以为NULL，索引列的值必须唯一的，如果是组合索引，则列值的组合必须唯一。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;全文索引：对文本的内容进行搜索。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;普通索引：基本的索引类型，可以为NULL&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.5 什么是聚簇索引，什么是非聚簇索引？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;聚簇索引：将数据和索引放到一起存储，索引结构的叶子节点保留了数据行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;非聚簇索引：将数据进和索引分开存储，索引叶子节点存储的是指向数据行的地址。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.6 索引的设计原则？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;最适合创建索引的列是出现在 WHERE 或 ON 子句中的列，或连接子句中的列而不是出现在SELECT关键字后的列。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对于字符串进行索引，应该制定一个前缀长度，可以节省大量的索引空间。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引列的基数越大、索引列的区分度越高，索引的效果越好。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量使用短索引，因为较小的索引涉及到的磁盘I/O较少，并且索引高速缓存中的块可以容纳更多的键值，会使得查询速度更快。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量利用最左前缀。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不要过度索引，每个索引都需要额外的物理空间，维护也需要花费时间，所以索引不是越多越好。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.7 索引失效的场景有哪些?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;不要在索引上做任何操作（计算、函数、自动/手动类型转换），不然会导致索引失效而转向全表扫描。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不能继续使用索引中范围条件（bettween、&amp;lt;、&amp;gt;、in等）右边的列 。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引字段上使用（！= 或者 &amp;lt; &amp;gt;）判断时，会导致索引失效而转向全表扫描。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引字段上使用 is null / is not null 判断时，会导致索引失效而转向全表扫描。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引字段使用like以通配符开头（‘%字符串’）时，会导致索引失效而转向全表扫描，也是最左前缀原则。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引字段是字符串，但查询时不加单引号，会导致索引失效而转向全表扫描。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引字段使用 or 时，会导致索引失效而转向全表扫描。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.8 创建索引的语法：&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先创建一个表：&lt;code&gt;create table t1 (id int primary key,username varchar(20),password varchar(20));&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建单个索引的语法：&lt;code&gt;CREATE INDEX 索引名 on 表名（字段名）&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;索引名一般是：&lt;code&gt;表名_字段名&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;给id创建索引：&lt;code&gt;CREATE INDEX t1_id on t1(id);&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建联合索引的语法：&lt;code&gt;CREATE INDEX 索引名 on 表名（字段名1，字段名2）&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;给 username 和 password 创建联合索引：&lt;code&gt;CREATE index t1_username_password ON t1(username,password)&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中index还可以替换成 unique，primary key，分别代表唯一索引和主键索引&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;删除索引：&lt;code&gt;DROP INDEX t1_username_password ON t1&lt;/code&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.数据库的事务&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.1 什么是事务?其特性是什么?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事务是指是程序中一系列操作必须全部成功完成，有一个失败则全部失败&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;特性：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;1.「原子性（Atomicity）」：要么全部执行成功，要么全部不执行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2.「一致性（Consistency）」：事务前后数据的完整性必须保持一致。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3.「隔离性（Isolation）」：隔离性是当多个事务同事触发时，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4.「持久性（Durability）」：事务完成之后的改变是永久的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.2 事务的隔离级别?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;1.「读已提交」：即能够「读取到那些已经提交」的数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2.「读未提交」：即能够「读取到没有被提交」的数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3.「可重复读」：可重复读指的是在一个事务内，最开始读到的数据和事务结束前的「任意时刻读到的同一批数据都是一致的」。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4.「可串行化」：最高事务隔离级别，不管多少事务，都是「依次按序一个一个执行」。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.3 隔离性实现原理：&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;隔离性的实现原理比较特殊，是通过数据库锁的机制实现的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;隔离性分四个级别：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;读未提交：一个事务可以读到另外一个事务未提交的数据。脏读&lt;/p&gt;&lt;p&gt;实现：事务在读数据的时候并未对数据进行加锁。&lt;/p&gt;&lt;p&gt;事务在发生更新数据的瞬间，必须先对其加 行级共享锁，直到事务结束才释放。&lt;/p&gt;&lt;p&gt;举例：事务A读取某行记录时(没有加锁)，事务2也能对这行记录进行读取、更新。当事务B对该记录进行更新时，事务A读取该记录，能读到事务B对该记录的修改版本，即使该修改尚未被提交。&lt;/p&gt;&lt;p&gt;事务A更新某行记录时，事务B不能对这行记录做更新，直到事务A结束。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;读已提交：一个事务可以读到另外一个事务提交的数据。不可重复读&lt;/p&gt;&lt;p&gt;实现：事务对当前被读取的数据加 &lt;code&gt;行级共享锁&lt;/code&gt;（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；&lt;/p&gt;&lt;p&gt;事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 &lt;code&gt;行级排他锁&lt;/code&gt;，直到事务结束才释放。&lt;/p&gt;&lt;p&gt;原理：事务A读取某行记录时，事务B也能对这行记录进行读取、更新；当事务B对该记录进行更新时，事务A再次读取该记录，读到的只能是事务B对其更新前的版本，或者事务B提交后的版本。事务A更新某行记录时，事务B不能对这行记录做更新，直到事务1结束。&lt;/p&gt;&lt;p&gt;流程描述：事务A读操作会加上&lt;code&gt;共享锁&lt;/code&gt;，事务B写操作时会加上&lt;code&gt;排他锁&lt;/code&gt;，当事务B正在写操作时，事务A要读操作，发现有排他锁，事务A就会阻塞，等待排他锁释放(事务B写操作提交才会释放)，才能进行读操作。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;可重复读&lt;/p&gt;&lt;p&gt;实现：事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 &lt;code&gt;行级共享锁&lt;/code&gt;，直到事务结束才释放；&lt;/p&gt;&lt;p&gt;事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 &lt;code&gt;行级排他锁&lt;/code&gt;，直到事务结束才释放。&lt;/p&gt;&lt;p&gt;举例：事务A读取某行记录时，事务B也能对这行记录进行读取、更新；当事务B对该记录进行更新时，事务A再次读取该记录，读到的仍然是第一次读取的那个版本。事务A更新某行记录时，事务B不能对这行记录做更新，直到事务1结束。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;可串行化(Serializable) 写操作串联执行&lt;/p&gt;&lt;p&gt;实现：事务在读取数据时，必须先对其加 &lt;code&gt;表级共享锁&lt;/code&gt; ，直到事务结束才释放；&lt;/p&gt;&lt;p&gt;事务在更新数据时，必须先对其加 &lt;code&gt;表级排他锁&lt;/code&gt; ，直到事务结束才释放。&lt;/p&gt;&lt;p&gt;举例：事务A正在读取A表中的记录时，则事务B也能读取A表，但不能对A表做更新、新增、删除，直到事务A结束。事务A正在更新A表中的记录时，则事务B不能读取A表的任意记录，更不可能对A表做更新、新增、删除，直到事务A结束。&lt;/p&gt;&lt;p&gt;原理：在读操作时，加&lt;code&gt;表级共享锁&lt;/code&gt;，事务结束时释放；写操作时候，加&lt;code&gt;表级独占锁&lt;/code&gt;，事务结束时释放。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「MySQL的默认隔离级别是可重复读。」&lt;/strong&gt;数据库的隔离级别分别可以解决数据库的脏读、不可重复读、幻读等问题。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.29055007052186177&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QpKEUPD82yIdP1MOouczk6vPVbGJ2AaGd0j2vggdEqSrEhC8ibeKqUwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;709&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;1.「脏读」&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;脏读指的是「读到了其他事务未提交的数据」，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;2.「不可重复读」&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;对比可重复读，不可重复读指的是在同一事务内，「不同的时刻读到的同一批数据可能是不一样的」。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;3.「幻读」&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;幻读是针对数据插入（INSERT）操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现「好像刚刚的更改对于某些数据未起作用」，但其实是事务B刚插入进来的这就叫幻读。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.4 隔离级别是如何实现的？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事务的隔离机制主要是依靠锁机制和MVCC(多版本并发控制)实现的，提交读和可重复读可以通过MVCC实现，串行化可以通过锁机制实现。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6. 什么是MVCC，有什么作用?&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MVCC:多版本并发控制，主要用来提高数据库的并发性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MVCC的作用就是在不加锁的情况下，解决数据库读写冲突问题，并且解决脏读、幻读、不可重复读等问题，但是不能解决丢失修改问题。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7. 数据库的锁&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7.1 什么是数据库的锁？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当数据库有并发事务的时候，保证数据访问顺序的机制称为锁机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据库的锁与隔离级别的关系？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.33063209076175043&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QQ3lhwdc5lflGicf1wmTjTgPo8RpamjEB0KblNNcOOTYPqmiaQvhRJeIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;617&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7.2 数据库锁的类型有哪些？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2608695652173913&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QbMKm2cVDwf9YCXxn8Fg31K8UiaWicapflhJvtExyyC27Gwg4Vicee1qBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;598&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MyISAM 默认采用表级锁，InnoDB 默认采用行级锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从锁的类别上区别可以分为共享锁和排他锁&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;共享锁：共享锁又称读锁，简写为S锁，一个事务对一个数据对象加了S锁，可以对这个数据对象进行读取操作，但不能进行更新操作。并且在加锁期间其他事务只能对这个数据对象加S锁，不能加X锁。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;排他锁：排他锁又称为写锁，简写为X锁，一个事务对一个数据对象加了X锁，可以对这个对象进行读取和更新操作，加锁期间，其他事务不能对该数据对象进行加X锁或S锁。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7.3 什么是数据库的乐观锁和悲观锁，如何实现？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;乐观锁：系统假设数据的更新在大多数时候是不会产生冲突的，所以数据库只在更新操作提交的时候对数据检测冲突，如果存在冲突，则数据更新失败。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;乐观锁实现方式：一般通过版本号和CAS算法实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。通俗讲就是每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;悲观锁的实现方式：通过数据库的锁机制实现，对查询语句添加for updata。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7.4 什么是死锁？如何避免？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;死锁是指两个或者两个以上进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。在 MySQL 中，MyISAM 是一次获得所需的全部锁，要么全部满足，要么等待，所以不会出现死锁。在 InnoDB 存储引擎中，除了单个 SQL 组成的事务外，锁都是逐步获得的，所以存在死锁问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何避免MySQL发生死锁或锁冲突：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如果不同的程序并发存取多个表，尽量以相同的顺序访问表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在程序以批量方式处理数据的时候，如果已经对数据排序，尽量保证每个线程按照固定的顺序来处理记录。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在事务中，如果需要更新记录，应直接申请足够级别的排他锁，而不应该先申请共享锁，更新时在申请排他锁，因为在当前用户申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突或者死锁。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量使用较低的隔离级别。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量使用索引访问数据，使加锁更加准确，从而减少锁冲突的机会。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;合理选择事务的大小，小事务发生锁冲突的概率更低。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量用相等的条件访问数据，可以避免Next-Key锁对并发插入的影响。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不要申请超过实际需要的锁级别，查询时尽量不要显示加锁。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对于一些特定的事务，可以表锁来提高处理速度或减少死锁的概率。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;8. B 树和 B+ 树的区别？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;B 树中的内部节点和叶子节点均存放键和值，而 B+ 树的内部节点只有键没有值，叶子节点存放所有的键和值。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;B＋ 树的叶子节点是通过相连在一起的，方便顺序检索。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8493894165535957&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QZNeiavN72WDhQclGyZF5bvffrSyUdqwJY8Kx2CHBIMK6eDQ7126SV3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;737&quot;/&gt;&lt;/figure&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;9. 数据库为什么使用 B+ 树而不是 B 树？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;B 树适用于随机检索，而 B+ 树适用于随机检索和顺序检索。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;B+ 树的空间利用率更高，因为 B 树每个节点要存储键和值，而 B+ 树的内部节点只存储键，这样 B+ 树的一个节点就可以存储更多的索引，从而使树的高度变低，减少了 I/O 次数，使得数据检索速度更快。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;B+ 树的叶子节点都是连接在一起的，所以范围查找，顺序查找更加方便。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;B+ 树的性能更加稳定，因为在 B+ 树中，每次查询都是从根节点到叶子节点，而在 B 树中，要查询的值可能不在叶子节点，在内部节点就已经找到。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;9.1 什么情况适合使用 B 树呢？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为 B 树的内部节点也可以存储值，所以可以把一些频繁访问的值放在距离根节点比较近的地方，这样就可以提高查询效率。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;10. MySQL执行SQL语句的的流程？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7895522388059701&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8Q3GibBVsibmlaxeDD7RLBnCbDcB3E9nhicL8QN1qdyPcqG7aGrXLIAIdtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;670&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;1.通过连接器跟客户端「建立连接」。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2.通过查询「缓存查询」之前是否有查询过该 sql。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3.通过分析器「分析该 sql 的语义」是否正确，包括格式，表等等。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4.通过优化器「优化该语句」，比如选择索引，join 表的连接顺序。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;5.「验证权限」，验证是否有该表的查询权限。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;6.通过执行器调用存储引擎执行该 sql，然后返回「执行结果」。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;11. binlog、undolog、relaylog、redolog？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;binlog 是归档日志，属于 Server 层的日志，是一个二进制格式的文件，用于「记录用户对数据库更新的SQL语句信息」。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要作用：主从复制、数据恢复。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;undolog 是 InnoDB 存储引擎的日志，用于保证数据的原子性，「保存了事务发生之前的数据的一个版本，也就是说记录的是数据是修改之前的数据，可以用于回滚」，同时可以提供多版本并发控制下的读（MVCC）。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要作用：事务回滚、实现多版本控制(MVCC)。&lt;/p&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;relaylog 是中继日志，「在主从同步的时候使用到」，它是一个中介临时的日志文件，用于存储从master节点同步过来的binlog日志内容。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;redolog 是 「InnoDB 存储引擎所特有的一种日志」，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以做「数据恢复并且提供 crash-safe 能力」。当有增删改相关的操作时，会先记录到 Innodb 中，并修改缓存页中的数据，「等到 mysql 闲下来的时候才会真正的将 redolog 中的数据写入到磁盘当中」。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;12. 说说两阶段提交。&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;两阶段提交分为 prepare 和 commit 阶段：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;准备阶段：事物 SQL 先写入 redo log buffer，然后做一个事物准备标记，在将log buffer 中的数据刷新到 redo log。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;提交阶段：将事物产生的 binlog 写入文件，刷新磁盘。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;再在 redo log 中做一个事物提交的标记，并把 binlog 写成功的标记也一并写入 redo log 文件。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;场景分析两阶段提交如何保证数据库的一致性。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;准备阶段，redo log 刷新到磁盘了，但是 binlog 写磁盘前发生了 mysql实例 crash，这时会发生怎样的操作呢？&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;即使 redo log 写盘成功了，但由于 binlog 未写入成功，需要执行回滚操作来保证数据库的一致性。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;提交阶段，binlog 写盘成功了，这时 mysql 实例 crash了。这时 binlog 已经确保写成功了，我们在重启实例进行恢复的时候，只需要让 redo log 重做一次就可以了。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;13. 分库分表相关&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;13.1 分库分表方案:&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;13.2 常用的分库分表中间件：&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;13.3 分库分表可能遇到的问题&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;事务问题：需要用分布式事务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跨节点Join的问题：解决这一问题可以分两次查询实现。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据迁移，容量规划，扩容等问题。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跨分片的排序分页问题。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;13.4 数据库如何进行垂直拆分以及水平拆分的原理是什么？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;垂直拆分&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;专库专用
一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;拆分后业务清晰，拆分规则明确。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;系统之间整合或扩展容易。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据维护简单。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;部分业务表无法join，只能通过接口方式解决，提高了系统复杂度。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;事务处理复杂。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;水平拆分&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直拆分后遇到单机瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库中，而水平拆分是把同一个表拆到不同的数据库中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相对于垂直拆分，水平拆分不是将表的数据做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中，主要有分表，分库两种模式，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;不存在单库大数据，高并发的性能瓶颈。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对应用透明，应用端改造较少。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;按照合理拆分规则拆分，join操作基本避免跨库。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;提高了系统的稳定性跟负载能力。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;拆分规则难以抽象。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分片事务一致性难以解决。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据多次扩展难度跟维护量极大。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跨库join性能较差。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;14. Mysql 主从之间是怎么同步数据的?&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.master 主库将此次更新的事件类型「写入到主库的 binlog 文件」中。2.master 「创建 log dump 线程通知 slave」 需要更新数据。3.「slave」 向 master 节点发送请求，「将该 binlog 文件内容存到本地的 relaylog 中」。4.「slave 开启 sql 线程」读取 relaylog 中的内容，「将其中的内容在本地重新执行一遍」，完成主从数据同步。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5397727272727273&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QadO9tTomoZ60n1AdZGWsnN3mn799Ug29GIkDHnFEFicP7jLUBSkQPzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;704&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;14.1 同步策略&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.「全同步复制」：主库强制同步日志到从库，等全部从库执行完才返回客户端，性能差。2.「半同步复制」：主库收到至少一个从库确认就认为操作成功，从库写入日志成功返回ack确认。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;14.2 主从延迟要怎么解决?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;主从复制分了五个步骤进行：&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46189024390243905&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8Qibdp2bdDMQVqBxQJyd386zX0Avlia96C7JPIy1eDGy8k3AbIsAlW0gjQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;656&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;主库的更新事件(update、insert、delete)被写到binlog。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;从库发起连接，连接到主库。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;此时主库创建一个binlog dump thread，把binlog的内容发送到从库。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;主从同步延迟的原因:&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个服务器开放Ｎ个链接给客户端来连接的，这样有会有大并发的更新操作, 但是从服务器的里面读取binlog的线程仅有一个，当某个SQL在从服务器上执行的时间稍长 或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致， 也就是主从延迟。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;主从同步延迟的解决办法&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.MySQL 5.6 版本以后，提供了一种「并行复制」的方式，通过将 SQL 线程转换为多个 work 线程来进行重放。2.「提高机器配置」增加从服务器，目的分散读的压力，从而降低服务器负载。3.在业务初期就选择合适的分库、分表策略，「避免单表单库过大」带来额外的复制压力
4.「避免长事务」。5.「避免让数据库进行各种大量运算」。6.对于一些对延迟很敏感的业务「直接使用主库读」。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;15. 如何优化 SQL，说说你的 Sql 调优思路吧&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5491452991452992&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QNtVrLFrp0U2wtbSk0qn5hgXTx7dq7yfcpNRlnyuln0hqNky7JBLPKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;468&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;「表结构优化」&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;拆分字段&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;字段类型的选择&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;字段类型大小的限制&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;合理的增加冗余字段&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;新建字段一定要有默认值&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;「索引方面」&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;索引字段的选择&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;利用好mysql支持的索引下推，覆盖索引等功能&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;唯一索引和普通索引的选择&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;「查询语句方面」&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;避免索引失效&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;合理的书写where条件字段顺序&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;小表驱动大表&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可以使用force index()防止优化器选错索引&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;「分库分表」&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;16. 了解慢日志查询吗？统计过慢查询吗？对慢查询如何优化？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;慢查询一般用于记录执行时间超过某个临界值的SQL语句的日志。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相关参数：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;slow_query_log：是否开启慢日志查询，1表示开启，0表示关闭。slow_query_log_file：MySQL数据库慢查询日志存储路径。long_query_time：慢查询阈值，当SQL语句查询时间大于阈值，会被记录在日志上。log_queries_not_using_indexes：未使用索引的查询会被记录到慢查询日志中。log_output：日志存储方式。“FILE”表示将日志存入文件。“TABLE”表示将日志存入数据库。如何对慢查询进行优化？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分析语句的执行计划，查看SQL语句的索引是否命中
优化数据库的结构，将字段很多的表分解成多个表，或者考虑建立中间表。优化LIMIT分页。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;17. 字段为什么要设置成 not null?&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先说一点，NULL和空值是不一样的，空值是不占用空间的，而NULL是占用空间的，所以字段设为NOT NULL后仍然可以插入空值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;字段设置成not null主要有以下几点原因：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NULL值会影响一些函数的统计，如count，遇到NULL值，这条记录不会统计在内。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;B树不存储NULL，所以索引用不到NULL，会造成第一点中说的统计不到的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NOT IN子查询在有NULL值的情况下返回的结果都是空值。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;18. varchar和char的区别？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;varchar表示变长，char表示长度固定。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;存储容量不同，对于 char 来说，最多能存放的字符个数为255。对于 varchar，最多能存放的字符个数是 65532。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;存储速度不同，char 长度固定，存储速度会比 varchar 快一些，但在空间上会占用额外的空间，属于一种空间换时间的策略。而 varchar 空间利用率会高些，但存储速度慢，属于一种时间换空间的策略。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;18.1 为什么 VarChar 建议不要超过255?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;当定义varchar长度小于等于255时，长度标识位需要一个字节(utf-8编码)。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当大于255时，长度标识位需要两个字节，并且建立的索引也会失效。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;18.2 varchar(10)和int(10)代表什么含义?&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;varchar 的10代表了申请的空间长度，也是可以存储的数据的最大长度。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;int 的10只是代表了展示的长度，不足10位以0填充。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;int(1)和int(10)所能存储的数字大小以及占用的空间都是相同的，只是在展示时按照长度展示。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;19. drop、delete和truncate的区别？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;br/&gt;&lt;/th&gt;&lt;th&gt;drop&lt;/th&gt;&lt;th&gt;delete&lt;/th&gt;&lt;th&gt;truncate&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;速度&lt;/td&gt;&lt;td&gt;快&lt;/td&gt;&lt;td&gt;逐行删除，慢&lt;/td&gt;&lt;td&gt;较快&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;类型&lt;/td&gt;&lt;td&gt;DDL&lt;/td&gt;&lt;td&gt;DML&lt;/td&gt;&lt;td&gt;DDL&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;回滚&lt;/td&gt;&lt;td&gt;不可回滚&lt;/td&gt;&lt;td&gt;可回滚&lt;/td&gt;&lt;td&gt;不可回滚&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;删除内容&lt;/td&gt;&lt;td&gt;删除整个表，数据行、索引都会被删除&lt;/td&gt;&lt;td&gt;表结构还在，删除表的一部分或全部数据&lt;/td&gt;&lt;td&gt;表结构还在，删除表的全部数据&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结：删除整个表，使用drop，删除表的部分数据使用delete，保留表结构删除表的全部数据使用truncate。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;20 对慢查询如何优化？&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;慢查询一般用于记录执行时间超过某个临界值的SQL语句的日志。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;20.1 如何查找查询速度慢的原因？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;记录慢查询日志，分析查询日志，可以使用pt-query-digest工具进行分析。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相关参数：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;slow_query_log：是否开启慢日志查询，1表示开启，0表示关闭。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;slow_query_log_file：MySQL数据库慢查询日志存储路径。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;long_query_time：慢查询阈值，当SQL语句查询时间大于阈值，会被记录在日志上。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;log_queries_not_using_indexes：未使用索引的查询会被记录到慢查询日志中。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;log_output：日志存储方式。“FILE”表示将日志存入文件。“TABLE”表示将日志存入数据库。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;show profile&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;set&lt;/span&gt; profiling=&lt;span&gt;1&lt;/span&gt;; //开启，服务器上所有执行语句会记录执行时间，存到临时表中&lt;br/&gt;&lt;span&gt;show&lt;/span&gt; &lt;span&gt;profiles&lt;/span&gt;&lt;br/&gt;&lt;span&gt;show&lt;/span&gt; profile &lt;span&gt;for&lt;/span&gt; &lt;span&gt;query&lt;/span&gt; 临时表&lt;span&gt;ID&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;show status&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;show status 会返回一些计数器，show global status 会查看所有服务器级别的所有计数。有时根据这些计数，可以推测出哪些操作代价较高或者消耗时间多。&lt;/p&gt;&lt;ol start=&quot;4&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;show processlist&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;观察是否有大量线程处于不正常的状态或特征：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1889055472263868&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QOy3f917zFiclrgWLeCjfGeQeQ4eYySsyUaHO9y6asPkfsYtiaLP6yT4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;667&quot;/&gt;&lt;/figure&gt;&lt;ol start=&quot;5&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;使用 explain 分析语句&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分析慢语句是否命中索引：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2434402332361516&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wgqfEribn6dG42unCkRBUqDYeegFhS8QdHyPibnP9F3NEfEIOchvaSyvt1yCVwibibn0W9yQOBQtwEulAo60Jul2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;686&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;20.2 如何对慢查询进行优化？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;分析语句的执行计划，查看SQL语句的索引是否命中。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;优化数据库的结构，将字段很多的表分解成多个表，或者考虑建立中间表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;优化LIMIT分页。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c58308e804afa020412e270a1ac3ffbc</guid>
<title>好好的系统，为什么要分库分表？</title>
<link>https://toutiao.io/k/95gs1ek</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;a class=&quot;weapp_image_link js_weapp_entry&quot; data-miniprogram-appid=&quot;wxebadf544ddae62cb&quot; data-miniprogram-path=&quot;pages/survey/index?sid=11022804&amp;amp;hash=f3c0&quot; data-miniprogram-nickname=&quot;腾讯问卷&quot; data-miniprogram-type=&quot;image&quot; data-miniprogram-servicetype=&quot;&quot; href=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14166666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/dkwuWwLoRK8PXrZQwgoLmB10CNHZoLHNh9GOVdm5pE9gsB6TKqZ0icyXM4aVmscUybxBvvbAFViaiaQ5ViamuXs2wQ/640?wx_fmt=gif&quot; data-w=&quot;600&quot;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;什么是分库分表&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表是在海量数据下，由于单库、表数据量过大，导致数据库性能持续下降的问题，演变出的技术方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表是由&lt;code&gt;分库&lt;/code&gt;和&lt;code&gt;分表&lt;/code&gt;这两个独立概念组成的，只不过通常分库与分表的操作会同时进行，以至于我们习惯性的将它们合在一起叫做分库分表。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.41421143847487&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInaRibtuhkoWXCSibia28DS90txOibrv7C4TIdKYnppibSXHD2z4lZguZorjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1154&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过一定的规则，将原本数据量大的数据库拆分成多个单独的数据库，将原本数据量大的表拆分成若干个数据表，使得单一的库、表性能达到最优的效果（响应速度快），以此提升整体数据库性能。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;为什么分库分表&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;单机数据库的存储能力、连接数是有限的，它自身就很容易会成为系统的瓶颈。当单表数据量在百万以里时，我们还可以通过添加从库、优化索引提升性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦数据量朝着千万以上趋势增长，再怎么优化数据库，很多操作性能仍下降严重。为了减少数据库的负担，提升数据库响应速度，缩短查询时间，这时候就需要进行分库分表。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么需要分库？&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;容量&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们给数据库实例分配的磁盘容量是固定的，数据量持续的大幅增长，用不了多久单机的容量就会承载不了这么多数据，解决办法简单粗暴，加容量！&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;连接数&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;单机的容量可以随意扩展，但数据库的连接数却是有限的，在高并发场景下多个业务同时对一个数据库操作，很容易将连接数耗尽导致&lt;code&gt;too many connections&lt;/code&gt;报错，导致后续数据库无法正常访问。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以通过&lt;code&gt;max_connections&lt;/code&gt;查看MySQL最大连接数。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;show&lt;/span&gt; &lt;span&gt;variables&lt;/span&gt; &lt;span&gt;like&lt;/span&gt; &lt;span&gt;&#x27;%max_connections%&#x27;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.173015873015873&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInBUKBzcmPxvvjGbdGtueIYFoEqsN9nlauykBxqBa0gENlsZDaaiaeoOQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1260&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将原本单数据库按不同业务拆分成订单库、物流库、积分库等不仅可以有效分摊数据库读写压力，也提高了系统容错性。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么需要分表？&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;做过报表业务的同学应该都体验过，一条SQL执行时间超过几十秒的场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;导致数据库查询慢的原因有很多，SQL没命中索引、like扫全表、用了函数计算，这些都可以通过优化手段解决，可唯独数据量大是MySQL无法通过自身优化解决的。慢的根本原因是&lt;code&gt;InnoDB&lt;/code&gt;存储引擎，聚簇索引结构的 B+tree 层级变高，磁盘IO变多查询性能变慢，详细原理自行查找一下，这里不用过多篇幅说明。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阿里的开发手册中有条建议，单表行数超500万行或者单表容量超过2GB，就推荐分库分表，然而理想和实现总是有差距的，阿里这种体量的公司不差钱当然可以这么用，实际上很多公司单表数据几千万、亿级别仍然不选择分库分表。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.11318242343541944&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInkGJy6VW8WKq5qgKMlj35Gr8gImkTibcFpugZF6pR0QM1sHg6eMSvojQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1502&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;什么时候分库分表&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;技术群里经常会有小伙伴问，到底什么情况下会用分库分表呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表要解决的是&lt;code&gt;现存海量数据&lt;/code&gt;访问的性能瓶颈，对&lt;code&gt;持续激增&lt;/code&gt;的数据量所做出的架构预见性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;是否分库分表的关键指标是数据量&lt;/strong&gt;，我们以&lt;code&gt;fire100.top&lt;/code&gt;这个网站的资源表 &lt;code&gt;t_resource&lt;/code&gt;为例，系统在运行初始的时候，每天只有可怜的几十个资源上传，这时使用单库、单表的方式足以支持系统的存储，数据量小几乎没什么数据库性能瓶颈。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但某天开始一股神秘的流量进入，系统每日产生的资源数据量暴增至十万甚至上百万级别，这时资源表数据量到达千万级，查询响应变得缓慢，数据库的性能瓶颈逐渐显现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以MySQL数据库为例，单表的数据量在达到亿条级别，通过加索引、SQL调优等传统优化策略，性能提升依旧微乎其微时，就可以考虑做分库分表了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然MySQL存储海量数据时会出现性能瓶颈，那么我们是不是可以考虑用其他方案替代它？比如高性能的非关系型数据库&lt;code&gt;MongoDB&lt;/code&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以，但要看存储的数据类型！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在互联网上大部分公司的核心数据几乎是存储在关系型数据库（MySQL、Oracle等），因为它们有着&lt;code&gt;NoSQL&lt;/code&gt;如法比拟的稳定性和可靠性，产品成熟生态系统完善，还有核心的事务功能特性，也是其他存储工具不具备的，而评论、点赞这些非核心数据还是可以考虑用&lt;code&gt;MongoDB&lt;/code&gt;的。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;如何分库分表&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;分库分表的核心就是对数据的分片（&lt;code&gt;Sharding&lt;/code&gt;）并相对均匀的路由在不同的库、表中，以及分片后对数据的快速定位与检索结果的整合。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库与分表可以从：垂直（纵向）和 水平（横向）两种纬度进行拆分。下边我们以经典的订单业务举例，看看如何拆分。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInvcZoP6NdMzl9wr7icXnqYu0VOAD8XKvNJyic36OEC9DfsNgfJkLS5K3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1552&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;垂直拆分&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1、垂直分库&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分库一般来说按照业务和功能的维度进行拆分，将不同业务数据分别放到不同的数据库中，核心理念 &lt;code&gt;专库专用&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;按业务类型对数据分离，剥离为多个数据库，像订单、支付、会员、积分相关等表放在对应的订单库、支付库、会员库、积分库。不同业务禁止跨库直连，获取对方业务数据一律通过&lt;code&gt;API&lt;/code&gt;接口交互，这也是微服务拆分的一个重要依据。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.40665701881331406&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInG73MELGmbElnUcz4Xll9Z1vibGQC0V5ia0SznS4OINWf09L5DQpNRwkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1382&quot;/&gt;&lt;figcaption&gt;垂直分库&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分库很大程度上取决于业务的划分，但有时候业务间的划分并不是那么清晰，比如：电商中订单数据的拆分，其他很多业务都依赖于订单数据，有时候界线不是很好划分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分库把一个库的压力分摊到多个库，提升了一些数据库性能，但并没有解决由于单表数据量过大导致的性能问题，所以就需要配合后边的分表来解决。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2、垂直分表&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分表针对业务上字段比较多的大表进行的，一般是把业务宽表中比较独立的字段，或者不常用的字段拆分到单独的数据表中，是一种大表拆小表的模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：一张&lt;code&gt;t_order&lt;/code&gt;订单表上有几十个字段，其中订单金额相关字段计算频繁，为了不影响订单表&lt;code&gt;t_order&lt;/code&gt;的性能，就可以把订单金额相关字段拆出来单独维护一个&lt;code&gt;t_order_price_expansion&lt;/code&gt;扩展表，这样每张表只存储原表的一部分字段，通过订单号&lt;code&gt;order_no&lt;/code&gt;做关联，再将拆分出来的表路由到不同的库中。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5129449838187702&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInqPGcugSXaKAVAMJL3xIBJMCQIJj5DoIxoL1EK9ic5ZWXH5n9mzib0LGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1236&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据库它是以行为单位将数据加载到内存中，这样拆分以后核心表大多是访问频率较高的字段，而且字段长度也都较短，因而可以加载更多数据到内存中，减少磁盘IO，增加索引查询的命中率，进一步提升数据库性能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;水平拆分&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上边垂直分库、垂直分表后还是会存在单库、表数据量过大的问题，当我们的应用已经无法在细粒度的垂直切分时，依旧存在单库读写、存储性能瓶颈，这时就要配合水平分库、水平分表一起了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1、水平分库&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;水平分库是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，以此实现水平扩展，是一种常见的提升数据库性能的方式。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4723618090452261&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInTG3j8xBLV5zibIVkB0RhFT6XA6ib4yiasITIDDJ9I5ARYU04EQMqkVSNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1194&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：&lt;code&gt;db_orde_1&lt;/code&gt;、&lt;code&gt;db_order_2&lt;/code&gt;两个数据库内有完全相同的&lt;code&gt;t_order&lt;/code&gt;表，我们在访问某一笔订单时可以通过对订单的订单编号取模的方式 &lt;code&gt;订单编号 mod 2 （数据库实例数）&lt;/code&gt; ，指定该订单应该在哪个数据库中操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方案往往能解决单库存储量及性能瓶颈问题，但由于同一个表被分配在不同的数据库中，数据的访问需要额外的路由工作，因此系统的复杂度也被提升了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2、水平分表&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;水平分表是在&lt;strong&gt;同一个数据库内&lt;/strong&gt;，把一张大数据量的表按一定规则，切分成多个结构完全相同表，而每个表只存原表的一部分数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：一张&lt;code&gt;t_order&lt;/code&gt;订单表有900万数据，经过水平拆分出来三个表，&lt;code&gt;t_order_1&lt;/code&gt;、&lt;code&gt;t_order_2&lt;/code&gt;、&lt;code&gt;t_order_3&lt;/code&gt;，每张表存有数据300万，以此类推。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6375545851528385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInQKQHMMTrzaQJ9gtOBkXpzV0geic2PC2NDlibOo3ClAibUsQ0R8FEX6kjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1374&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;水平分表尽管拆分了表，但子表都还是在同一个数据库实例中，只是解决了单一表数据量过大的问题，并没有将拆分后的表分散到不同的机器上，还在竞争同一个物理机的CPU、内存、网络IO等。要想进一步提升性能，就需要将拆分后的表分散到不同的数据库中，达到分布式的效果。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5764705882352941&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInUm6sQ78O1p1K0wMDYnv8wLsOucdiaiaTicQic7HK9cp5ZF0ehUKXfYqibzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1530&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;数据存在哪个库的表&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表以后会出现一个问题，一张表会出现在多个数据库里，到底该往哪个库的哪个表里存呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上边我们多次提到过&lt;code&gt;一定规则&lt;/code&gt; ，其实这个规则它是一种路由算法，决定了一条数据具体应该存在哪个数据库的哪张表里。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的有 &lt;code&gt;取模算法&lt;/code&gt; 、&lt;code&gt;范围限定算法&lt;/code&gt;、&lt;code&gt;范围+取模算法&lt;/code&gt; 、&lt;code&gt;预定义算法&lt;/code&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1、取模算法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关键字段取模（对hash结果取余数 hash(XXX) mod N)，N为数据库实例数或子表数量）是最为常见的一种路由方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以&lt;code&gt;t_order&lt;/code&gt;订单表为例，先给数据库从 0 到 N-1进行编号，对 &lt;code&gt;t_order&lt;/code&gt;订单表中&lt;code&gt;order_no&lt;/code&gt;订单编号字段进行取模&lt;code&gt;hash(order_no) mod N&lt;/code&gt;，得到余数&lt;code&gt;i&lt;/code&gt;。&lt;code&gt;i=0&lt;/code&gt;存第一个库，&lt;code&gt;i=1&lt;/code&gt;存第二个库，&lt;code&gt;i=2&lt;/code&gt;存第三个库，以此类推。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5263157894736842&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInnapqp3zGVlFT0VNTiaJkZhxljnJlBJT5m5zRy4nLZ55pqUL42T7weQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1254&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同一笔订单数据会落在同一个库、表里，查询时用相同的规则，用&lt;code&gt;t_order&lt;/code&gt;订单编号作为查询条件，就能快速的定位到数据。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;优点&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实现简单，数据分布相对比较均匀，不易出现请求都打到一个库上的情况。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;缺点&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;取模算法对集群的伸缩支持不太友好，集群中有N个数据库实&lt;code&gt;·hash(user_id) mod N&lt;/code&gt;，当某一台机器宕机，本应该落在该数据库的请求就无法得到处理，这时宕掉的实例会被踢出集群。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时机器数减少算法发生变化&lt;code&gt;hash(user_id) mod N-1&lt;/code&gt;，同一用户数据落在了在不同数据库中，等这台机器恢复，用&lt;code&gt;user_id&lt;/code&gt;作为条件查询用户数据就会少一部分。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2、范围限定算法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;范围限定算法以某些范围字段，如&lt;code&gt;时间&lt;/code&gt;或&lt;code&gt;ID区&lt;/code&gt;拆分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用户表&lt;code&gt;t_user&lt;/code&gt;被拆分成&lt;code&gt;t_user_1&lt;/code&gt;、&lt;code&gt;t_user_2&lt;/code&gt;、&lt;code&gt;t_user_3&lt;/code&gt;三张表，后续将&lt;code&gt;user_id&lt;/code&gt;范围为1 ~ 1000w的用户数据放入&lt;code&gt;t_user_1&lt;/code&gt;，1000~ 2000w放入&lt;code&gt;t_user_2&lt;/code&gt;，2000~3000w放入&lt;code&gt;t_user_3&lt;/code&gt;，以此类推。按日期范围划分同理。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4913112164296998&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInfk4pwUYkzFEPcUEmap3ogOSIK6X5aPEZ0oYrPlStwMR5iaXqpOqWnGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1266&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;优点&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;单表数据量是可控的&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;水平扩展简单只需增加节点即可，无需对其他分片的数据进行迁移&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;缺点&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;由于连续分片可能存在&lt;code&gt;数据热点&lt;/code&gt;，比如按时间字段分片时，如果某一段时间（双11等大促）订单骤增，存11月数据的表可能会被频繁的读写，其他分片表存储的历史数据则很少被查询，导致数据倾斜，数据库压力分摊不均匀。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3、范围 + 取模算法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了避免热点数据的问题，我们可以对上范围算法优化一下&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这次我们先通过范围算法定义每个库的用户表&lt;code&gt;t_user&lt;/code&gt;只存1000w数据，第一个&lt;code&gt;db_order_1&lt;/code&gt;库存放&lt;code&gt;userId&lt;/code&gt;从1 ~ 1000w，第二个库1000~2000w，第三个库2000~3000w，以此类推。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6112565445026178&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseIn47gFXYHsvZd1ic5pspMuztPsMvr0dr22uV5cGD9Ap1ZWwNUTrTEq6cg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1528&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个库里再把用户表&lt;code&gt;t_user&lt;/code&gt;拆分成&lt;code&gt;t_user_1&lt;/code&gt;、&lt;code&gt;t_user_2&lt;/code&gt;、&lt;code&gt;t_user_3&lt;/code&gt;等，对&lt;code&gt;userd&lt;/code&gt;进行取模路由到对应的表中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有效的避免数据分布不均匀的问题，数据库水平扩展也简单，直接添加实例无需迁移历史数据。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4、地理位置分片&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;地理位置分片其实是一个更大的范围，按城市或者地域划分，比如华东、华北数据放在不同的分片库、表。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5、预定义算法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;预定义算法是事先已经明确知道分库和分表的数量，可以直接将某类数据路由到指定库或表中，查询的时候亦是如此。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;分库分表出来的问题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;了解了上边分库分表的拆分方式不难发现，相比于拆分前的单库单表，系统的数据存储架构演变到现在已经变得非常复杂。看几个具有代表性的问题，比如：&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;分页、排序、跨节点联合查询&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分页、排序、联合查询，这些看似普通，开发中使用频率较高的操作，在分库分表后却是让人非常头疼的问题。把分散在不同库中表的数据查询出来，再将所有结果进行汇总合并整理后提供给用户。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如：我们要查询11、12月的订单数据，如果两个月的数据是分散到了不同的数据库实例，则要查询两个数据库相关的数据，在对数据合并排序、分页，过程繁琐复杂。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5364238410596026&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInA5QAJeiaTCypxqTSqy2Iqsqib0GfBBDtafkyLaPLbhicWDVd34qJxDAicw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1510&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;事务一致性&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表后由于表分布在不同库中，不可避免会带来跨库事务问题。后续会分别以阿里的&lt;code&gt;Seata&lt;/code&gt;和MySQL的&lt;code&gt;XA&lt;/code&gt;协议实现分布式事务，用来比较各自的优势与不足。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;全局唯一的主键&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表后数据库表的主键ID业务意义就不大了，因为无法在标识唯一一条记录，例如：多张表&lt;code&gt;t_order_1&lt;/code&gt;、&lt;code&gt;t_order_2&lt;/code&gt;的主键ID全部从1开始会重复，此时我们需要主动为一条记录分配一个ID，这个全局唯一的ID就叫&lt;code&gt;分布式ID&lt;/code&gt;，发放这个ID的系统通常被叫发号器。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;多数据库高效治理&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对多个数据库以及库内大量分片表的高效治理，是非常有必要，因为像某宝这种大厂一次大促下来，订单表可能会被拆分成成千上万个&lt;code&gt;t_order_n&lt;/code&gt;表，如果没有高效的管理方案，手动建表、排查问题是一件很恐怖的事。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;历史数据迁移&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表架构落地以后，首要的问题就是如何平滑的迁移历史数据，增量数据和全量数据迁移，这又是一个比较麻烦的事情，后边详细讲。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;分库分表架构模式&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分库分表架构主要有两种模式：&lt;code&gt;client&lt;/code&gt;客户端模式和&lt;code&gt;proxy&lt;/code&gt;代理模式&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;客户模式&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;client&lt;/code&gt;模式指分库分表的逻辑都在你的系统应用内部进行控制，应用会将拆分后的SQL直连多个数据库进行操作，然后本地进行数据的合并汇总等操作。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48293515358361777&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseIn5NLhexuwavJEkxficshFgNu9LAmHXXyH6yql1rVqmlsFtQnibY8UHr8Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1172&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;代理模式&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;proxy&lt;/code&gt;代理模式将应用程序与MySQL数据库隔离，业务方的应用不在需要直连数据库，而是连接proxy代理服务，代理服务实现了MySQL的协议，对业务方来说代理服务就是数据库，它会将SQL分发到具体的数据库进行执行，并返回结果。该服务内有分库分表的配置，根据配置自动创建分片表。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5072697899838449&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0OzaL5uW2aMzBtytGgvE1derMNyqseInzAdRSXqQoYic9mqKibcGgoibrtsdVKAv0gj2nM1Q7PaGhVnoPOjRsTKSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1238&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;如何抉择&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何选择&lt;code&gt;client&lt;/code&gt;模式和&lt;code&gt;proxy&lt;/code&gt;模式，我们可以从以下几个方面来简单做下比较。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1、性能&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;性能方面&lt;code&gt;client&lt;/code&gt;模式表现的稍好一些，它是直接连接MySQL执行命令；&lt;code&gt;proxy&lt;/code&gt;代理服务则将整个执行链路延长了，应用-&amp;gt;代理服务-&amp;gt;MySQL，可能导致性能有一些损耗，但两者差距并不是非常大。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2、复杂度&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;client&lt;/code&gt;模式在开发使用通常引入一个jar可以；&lt;code&gt;proxy&lt;/code&gt;代理模式则需要搭建单独的服务，有一定的维护成本，既然是服务那么就要考虑高可用，毕竟应用的所有SQL都要通过它转发至MySQL。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3、升级&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;client&lt;/code&gt;模式分库分表一般是依赖基础架构团队的Jar包，一旦有版本升级或者Bug修改，所有应用到的项目都要跟着升级。小规模的团队服务少升级问题不大，如果是大公司服务规模大，且涉及到跨多部门，那么升级一次成本就比较高；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;proxy&lt;/code&gt;模式在升级方面优势很明显，发布新功能或者修复Bug，只要重新部署代理服务集群即可，业务方是无感知的，但要保证发布过程中服务的可用性。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4、治理、监控&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;client&lt;/code&gt;模式由于是内嵌在应用内，应用集群部署不太方便统一处理；&lt;code&gt;proxy&lt;/code&gt;模式在对SQL限流、读写权限控制、监控、告警等服务治理方面更优雅一些。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>71c61b8251f9d6f40f48a4b7b7c692bd</guid>
<title>美团一面：为什么线程崩溃崩溃不会导致 JVM 崩溃</title>
<link>https://toutiao.io/k/l9ztu3e</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.18273381294964028&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLU8h8QYrHeibbpq0MLf3Ov6l7q5icQVPvjL6uLVcoV6m6ODVT9BfSEfZ3gFDlTYMnPxmpGJibDfEvabw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;695&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;点击关注公众号，Java干货&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;及时送达&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;👇&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable js_wx_tap_highlight&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzU4MDUyMDQyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/knmrNHnmCLEX3M6DvCn5gKuBOaMMVu9lUJAvwH2k66nV9VgGG0cyczd1ryib06P1z5pF72Le3HUr5loicnQx36lg/0?wx_fmt=png&quot; data-nickname=&quot;小哈学Java&quot; data-alias=&quot;xiaoha_java&quot; data-signature=&quot;专注于Java领域干货分享，不限于BAT面试, 算法，数据库，Spring Boot, 微服务,高并发, JVM, Docker容器，ELK相关知识，期待与您一同进步。&quot; data-from=&quot;2&quot; data-is_biz_ban=&quot;0&quot; has-insert-preloading=&quot;1&quot; data-index=&quot;0&quot; data-origin_num=&quot;44&quot; data-isban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;网上看到一个很有意思的美团面试题：为什么线程崩溃崩溃不会导致 JVM 崩溃，这个问题我看了不少回答，但发现都没答到根上，所以决定答一答，相信大家看完肯定会有收获，本文分以下几节来探讨&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;线程崩溃，进程一定会崩溃吗&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;进程是如何崩溃的-信号机制简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么在 JVM 中线程崩溃不会导致 JVM 进程崩溃&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;openJDK 源码解析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;线程崩溃，进程一定会崩溃吗&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，&lt;strong&gt;各个线程的地址空间是共享的&lt;/strong&gt;，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9715370018975332&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLU8h8QYrHeibbpq0MLf3Ov6lribyJQz7knHBWnFceHjvlj6ZAiciadmsPY7IMjgkdxl8SxSR95wzusl8w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;527&quot; title=&quot;线程共享代码段，数据段，地址空间，文件&quot;/&gt;&lt;figcaption&gt;线程共享代码段，数据段，地址空间，文件&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;非法访问内存有以下几种情况，我们以 C 语言举例来看看&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;针对只读内存写入数据&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;   &lt;span&gt;char&lt;/span&gt; *s = &lt;span&gt;&quot;hello world&quot;&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// 向只读内存写入数据，崩溃&lt;/span&gt;&lt;br/&gt;   s[&lt;span&gt;1&lt;/span&gt;] = &lt;span&gt;&#x27;H&#x27;&lt;/span&gt;; &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;访问了进程没有权限访问的地址空间（比如内核空间）&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;   &lt;span&gt;int&lt;/span&gt; *p = (&lt;span&gt;int&lt;/span&gt; *)&lt;span&gt;0xC0000fff&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;   // 针对进程的内核空间写入数据，崩溃&lt;/span&gt;&lt;br/&gt;   *p = &lt;span&gt;10&lt;/span&gt;; &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在 32 位虚拟地址空间中，p 指向的是内核空间，显然不具有写入权限，所以上述赋值操作会导致崩溃&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;访问了不存在的内存，比如&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;   &lt;span&gt;int&lt;/span&gt; *a = &lt;span&gt;NULL&lt;/span&gt;;&lt;br/&gt;   *a = &lt;span&gt;1&lt;/span&gt;;     &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;以上错误都是访问内存时的错误，所以统一会报 Segment Fault 错误（即段错误），这些都会导致进程崩溃&lt;/p&gt;&lt;h3&gt;&lt;span&gt;进程是如何崩溃的-信号机制简介&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;那么线程崩溃后，进程是如何崩溃的呢，这背后的机制到底是怎样的，答案是&lt;strong&gt;信号&lt;/strong&gt;，大家想想要干掉一个正在运行的进程是不是经常用 kill -9 pid 这样的命令，这里的 kill 其实就是给指定 pid 发送终止信号的意思，其中的 9 就是信号，其实信号有很多类型的，在 Linux 中可以通过 &lt;code&gt;kill -l&lt;/code&gt;查看所有可用的信号&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.33094812164579607&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLU8h8QYrHeibbpq0MLf3Ov6lEsDjTB5TO65X36LkVIdHbwvaqjRUzR0LjqIRGAV7yYvfP03OjVWWFA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1118&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当然了发 kill 信号必须具有一定的权限，否则任意进程都可以通过发信号来终止其他进程，那显然是不合理的，实际上 kill 执行的是系统调用，将控制权转移给了内核（操作系统），由内核来给指定的进程发送信号&lt;/p&gt;&lt;p&gt;那么发个信号进程怎么就崩溃了呢，这背后的原理到底是怎样的？&lt;/p&gt;&lt;p&gt;其背后的机制如下&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CPU 执行正常的进程指令&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调用 kill 系统调用向进程发送信号&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;注意上面的第五步，如果进程没有注册自己的信号处理函数，那么操作系统会执行默认的信号处理程序（一般最后会让进程退出），但如果注册了，则会执行自己的信号处理函数，这样的话就给了进程一个垂死挣扎的机会，它收到 kill 信号后，可以调用 exit() 来退出，&lt;strong&gt;但也可以使用 sigsetjmp，siglongjmp 这两个函数来恢复进程的执行&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// 自定义信号处理函数示例&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;signal.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 自定义信号处理函数，处理自定义逻辑后再调用 exit 退出&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;sigHandler&lt;/span&gt;&lt;span&gt;(&lt;span&gt;int&lt;/span&gt; sig)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;printf&lt;/span&gt;(&lt;span&gt;&quot;Signal %d catched!\n&quot;&lt;/span&gt;, sig);&lt;br/&gt;  &lt;span&gt;exit&lt;/span&gt;(sig);&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(&lt;span&gt;void&lt;/span&gt;)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  signal(SIGSEGV, sigHandler);&lt;br/&gt;  &lt;span&gt;int&lt;/span&gt; *p = (&lt;span&gt;int&lt;/span&gt; *)&lt;span&gt;0xC0000fff&lt;/span&gt;;&lt;br/&gt;  *p = &lt;span&gt;10&lt;/span&gt;; &lt;span&gt;// 针对不属于进程的内核空间写入数据，崩溃&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 以上结果输出: Signal 11 catched!&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;如代码所示&lt;/strong&gt;：注册信号处理函数后，当收到 SIGSEGV 信号后，先执行相关的逻辑再退出&lt;/p&gt;&lt;p&gt;另外当进程接收信号之后也可以不定义自己的信号处理函数，而是选择忽略信号，如下&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;signal.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(&lt;span&gt;void&lt;/span&gt;)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// 忽略信号&lt;/span&gt;&lt;br/&gt;  signal(SIGSEGV, SIG_IGN);&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;// 产生一个 SIGSEGV 信号&lt;/span&gt;&lt;br/&gt;  raise(SIGSEGV);&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;printf&lt;/span&gt;(&lt;span&gt;&quot;正常结束&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也就是说虽然给进程发送了 kill 信号，但如果进程自己定义了信号处理函数或者无视信号就有机会逃出生天，当然了 kill -9 命令例外，不管进程是否定义了信号处理函数，都会马上被干掉&lt;/p&gt;&lt;p&gt;说到这大家是否想起了一道经典面试题：如何让正在运行的 Java 工程的优雅停机，通过上面的介绍大家不难发现，其实是 JVM 自己定义了信号处理函数，这样当发送 kill pid 命令（默认会传 15 也就是 SIGTERM）后，JVM 就可以在信号处理函数中执行一些资源清理之后再调用 exit 退出。这种场景显然不能用 kill -9，不然一下把进程干掉了资源就来不及清除了&lt;/p&gt;&lt;h3&gt;&lt;span&gt;为什么线程崩溃不会导致 JVM 进程崩溃&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;现在我们再来看看开头这个问题，相信你多少会心中有数，想想看在 Java 中有哪些是常见的由于非法访问内存而产生的 Exception 或 error 呢，常见的是大家熟悉的 StackoverflowError 或者 NPE（NullPointerException）,NPE 我们都了解，属于是访问了不存在的内存&lt;/p&gt;&lt;p&gt;但为什么栈溢出（Stackoverflow）也属于非法访问内存呢，这得简单聊一下进程的虚拟空间，也就是前面提到的共享地址空间&lt;/p&gt;&lt;p&gt;现代操作系统为了保护进程之间不受影响，所以使用了虚拟地址空间来隔离进程，进程的寻址都是针对虚拟地址，每个进程的虚拟空间都是一样的，而线程会共用进程的地址空间，以 32 位虚拟空间，进程的虚拟空间分布如下&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2405345211581291&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLU8h8QYrHeibbpq0MLf3Ov6lJbAtmPp0qZckAw8PAoALLG6j3LNYevSwHjrFUV6q0FrSVdDq4NVicQQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;449&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;那么 stackoverflow 是怎么发生的呢，进程每调用一个函数，都会分配一个栈桢，然后在栈桢里会分配函数里定义的各种局部变量，假设现在调用了一个无限递归的函数，那就会持续分配栈帧，但 stack 的大小是有限的（Linux 中默认为 8 M，可以通过 ulimit -a 查看），如果无限递归很快栈就会分配完了，此时再调用函数试图分配超出栈的大小内存，就会发生段错误，也就是 stackoverflowError&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.94140625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLU8h8QYrHeibbpq0MLf3Ov6lAZlrrAy3ahWYicGHfCkXwjwiaWicfQnfY3F7IP2bXmsRicKD9aupiafuBWQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;512&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;好了，现在我们知道了 StackoverflowError 怎么产生的，那问题来了，既然 StackoverflowError 或者 NPE 都属于非法访问内存， JVM 为什么不会崩溃呢，有了上一节的铺垫，相信你不难回答，其实就是因为 JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对这两者不让它们崩溃，怎么证明这个推测呢，我们来看下 JVM 的源码来一探究竟&lt;/p&gt;&lt;h3&gt;&lt;span&gt;openJDK 源码解析&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;HotSpot 虚拟机目前使用范围最广的 Java 虚拟机，据 R 大所述， Oracle JDK 与 OpenJDK 里的 JVM 都是 HotSpot VM，从源码层面说，两者基本上是同一个东西，OpenJDK 是开源的，所以我们主要研究下 Java 8 的 OpenJDK 即可，地址如下：&lt;span&gt;https://github.com/AdoptOpenJDK/openjdk-jdk8u&lt;/span&gt;，有兴趣的可以下载来看看&lt;/p&gt;&lt;p&gt;我们只要研究 Linux 下的 JVM，为了便于说明，也方便大家查阅，我把其中关于信号处理的关键流程整理了下（忽略其中的次要代码）&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5355691056910569&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLU8h8QYrHeibbpq0MLf3Ov6lKUkW94asyrUG3eovoKdtNChwS7WFZeicR5UErAokPK2Ibwhuz3cYsxQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;984&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;可以看到，在启动 JVM 的时候，也设置了信号处理函数，收到 SIGSEGV，SIGPIPE 等信号后最终会调用 JVM_handle_linux_signal 这个自定义信号处理函数，再来看下这个函数的主要逻辑&lt;/p&gt;&lt;pre&gt;&lt;code&gt;JVM_handle_linux_signal(&lt;span&gt;int&lt;/span&gt; sig,&lt;br/&gt;                        &lt;span&gt;siginfo_t&lt;/span&gt;* info,&lt;br/&gt;                        &lt;span&gt;void&lt;/span&gt;* ucVoid,&lt;br/&gt;                        &lt;span&gt;int&lt;/span&gt; abort_if_unrecognized) {&lt;br/&gt;&lt;br/&gt;   &lt;span&gt;// Must do this before SignalHandlerMark, if crash protection installed we will longjmp away&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;// 这段代码里会调用 siglongjmp，主要做线程恢复之用&lt;/span&gt;&lt;br/&gt;  os::ThreadCrashProtection::check_crash_protection(sig, t);&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (info != &lt;span&gt;NULL&lt;/span&gt; &amp;amp;&amp;amp; uc != &lt;span&gt;NULL&lt;/span&gt; &amp;amp;&amp;amp; thread != &lt;span&gt;NULL&lt;/span&gt;) {&lt;br/&gt;    pc = (address) os::Linux::ucontext_get_pc(uc);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// Handle ALL stack overflow variations here&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (sig == SIGSEGV) {&lt;br/&gt;      &lt;span&gt;// Si_addr may not be valid due to a bug in the linux-ppc64 kernel (see&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;// comment below). Use get_stack_bang_address instead of si_addr.&lt;/span&gt;&lt;br/&gt;      address addr = ((NativeInstruction*)pc)-&amp;gt;get_stack_bang_address(uc);&lt;br/&gt;&lt;br/&gt;      &lt;span&gt;// 判断是否栈溢出了&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (addr &amp;lt; thread-&amp;gt;stack_base() &amp;amp;&amp;amp;&lt;br/&gt;          addr &amp;gt;= thread-&amp;gt;stack_base() - thread-&amp;gt;stack_size()) {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (thread-&amp;gt;thread_state() == _thread_in_Java) {&lt;/code&gt;&lt;code&gt;            &lt;strong&gt;&lt;span&gt;// 针对栈溢出 JVM 的内部处理&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;            stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW);&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (sig == SIGSEGV &amp;amp;&amp;amp;&lt;br/&gt;               !MacroAssembler::needs_explicit_null_check((&lt;span&gt;intptr_t&lt;/span&gt;)info-&amp;gt;si_addr)) {&lt;br/&gt;         &lt;strong&gt;&lt;span&gt;// 此处会做空指针检查&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;      stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;// 如果是栈溢出或者空指针最终会返回 true，不会走最后的 report_and_die，所以 JVM 不会退出&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (stub != &lt;span&gt;NULL&lt;/span&gt;) {&lt;br/&gt;    &lt;span&gt;// save all thread context in case we need to restore it&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (thread != &lt;span&gt;NULL&lt;/span&gt;) thread-&amp;gt;set_saved_exception_pc(pc);&lt;br/&gt;&lt;br/&gt;    uc-&amp;gt;uc_mcontext.gregs[REG_PC] = (&lt;span&gt;greg_t&lt;/span&gt;)stub;&lt;br/&gt;    &lt;strong&gt;&lt;span&gt;// 返回 true 代表 JVM 进程不会退出&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;VMError &lt;span&gt;err&lt;/span&gt;&lt;span&gt;(t, sig, pc, info, ucVoid)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;  &lt;span&gt;// 生成 hs_err_pid_xxx.log 文件并退出&lt;/span&gt;&lt;br/&gt;  err.report_and_die();&lt;br/&gt;&lt;br/&gt;  ShouldNotReachHere();&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;; &lt;span&gt;// Mute compiler&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从以上代码（注意看加粗的红线字体部分）我们可以知道以下信息&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;发生 stackoverflow 还有空指针错误，确实都发送了 SIGSEGV，只是虚拟机不选择退出，而是自己内部作了额外的处理，其实是恢复了线程的执行，并抛出 StackoverflowError 和 NPE，这就是为什么 JVM 不会崩溃且我们能捕获这两个错误/异常的原因&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果针对 SIGSEGV 等信号，在以上的函数中 JVM 没有做额外的处理，那么最终会走到 report_and_die 这个方法，这个方法主要做的事情是生成 hs_err_pid_xxx.log crash 文件（记录了一些堆栈信息或错误），然后退出&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;至此我相信大家明白了为什么发生了 StackoverflowError 和 NPE 这两个非法访问内存的错误，JVM 却没有崩溃。原因其实就是虚拟机内部定义了信号处理函数，而在信号处理函数中对这两者做了额外的处理以让 JVM 不崩溃，另一方面也可以看出如果 JVM 不对信号做额外的处理，最后会自己退出并产生 crash 文件 hs_err_pid_xxx.log（可以通过 -XX:ErrorFile=/var/&lt;em&gt;log&lt;/em&gt;/hs_err.log 这样的方式指定），这个文件记录了虚拟机崩溃的重要原因，所以也可以说，虚拟机是否崩溃只要看它是否会产生此崩溃日志文件&lt;/p&gt;&lt;h3&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;正常情况下，操作系统为了保证系统安全，所以针对非法内存访问会发送一个 SIGSEGV 信号，而操作系统一般会调用默认的信号处理函数（一般会让相关的进程崩溃），但如果进程觉得&quot;罪不致死&quot;，那么它也可以选择自定义一个信号处理函数，这样的话它就可以做一些自定义的逻辑，比如记录 crash 信息等有意义的事，回过头来看为什么虚拟机会针对 StackoverflowError 和 NullPointerException 做额外处理让线程恢复呢，针对 stackoverflow 其实它采用了一种&lt;span&gt;栈回溯&lt;/span&gt;的方法保证线程可以一直执行下去，而捕获空指针错误主要是这个错误实在太普遍了，为了这一个很常见的错误而让 JVM 崩溃那线上的 JVM 要宕机多少次，所以出于工程健壮性的考虑，与其直接让 JVM 崩溃倒不如让线程起死回生，并且将这两个错误/异常抛给用户来处理&lt;/p&gt;&lt;pre&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100015743&quot; data-ratio=&quot;0.08658008658008658&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/TNUwKhV0JpTGQqtlGfEHkjibtshlaDwVKzjqq2pnpmYC14bKxDtSuhpWZWfVcicj5PFsoSMzuzicKIWZbsBpGXiaicg/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;462&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;pre&gt;&lt;pre&gt;&lt;pre data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(167, 167, 167)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(63, 63, 63)&quot; data-style=&quot;letter-spacing: 0.544px; font-size: 16px; color: rgb(63, 63, 63); word-spacing: 1px; line-height: inherit;&quot;&gt;&lt;section data-mpa-template-id=&quot;1250&quot; data-mpa-category=&quot;divider&quot; data-style=&quot;margin-right: 0.5em; margin-left: 0.5em; white-space: normal; font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; color: rgb(0, 0, 0); letter-spacing: 0px; word-spacing: 2px;&quot; data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(230, 230, 230)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(0, 0, 0)&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; data-style=&quot;margin: 10px 0em; color: rgb(89, 89, 89); letter-spacing: 0.544px;&quot; data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(138, 138, 138)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(89, 89, 89)&quot;&gt;&lt;section data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(138, 138, 138)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(89, 89, 89)&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(138, 138, 138)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(89, 89, 89)&quot;&gt;&lt;p data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(106, 104, 111)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(106, 104, 111)&quot;&gt;1. &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU4MDUyMDQyNQ==&amp;amp;mid=2247512193&amp;amp;idx=1&amp;amp;sn=4aa86b542ca93ea67c6e6715b85eefc0&amp;amp;chksm=fd576007ca20e9115b5d8bc68c33183c38fec130f6d7da4f241a905fa6ed3e76712862ba6606&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;我司用了 5 年的单点登录方案！从实现到部署实战详解，稳的一批!&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;我司用了 5 年的单点登录方案！从实现到部署实战详解，稳的一批!&lt;/a&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(138, 138, 138)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(89, 89, 89)&quot;&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(106, 104, 111)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(106, 104, 111)&quot;&gt;2. &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU4MDUyMDQyNQ==&amp;amp;mid=2247512168&amp;amp;idx=1&amp;amp;sn=fe1962a759c9697d6a916ac259d500c1&amp;amp;chksm=fd5760eeca20e9f8995e52629232d5b1b80e61b0925f6dde53f78863676b0ec7af719cd8a42a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;SpringBoot+ElasticSearch 实现模糊查询，批量CRUD，排序，分页，高亮&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;SpringBoot+ElasticSearch 实现模糊查询，批量CRUD，排序，分页，高亮&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(138, 138, 138)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(89, 89, 89)&quot;&gt;&lt;span&gt;3. &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU4MDUyMDQyNQ==&amp;amp;mid=2247512163&amp;amp;idx=1&amp;amp;sn=eea81c05aaab027f526ec0d4bf898f44&amp;amp;chksm=fd5760e5ca20e9f33140a6cc0bfef24d4f897b2d300903f4be94dd29be955b4afa1bd1023db5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;非常强，批处理框架 Spring Batch 就该这么用！（场景实战）&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;非常强，批处理框架 Spring Batch 就该这么用！（场景实战）&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(106, 104, 111)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(106, 104, 111)&quot;&gt;4. &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU4MDUyMDQyNQ==&amp;amp;mid=2247512131&amp;amp;idx=1&amp;amp;sn=246484f135ebd17fa941a620da69aea8&amp;amp;chksm=fd5760c5ca20e9d3141965e34e221fac733a30f825b1d4e4d0e323591e1c95b2a39dd4ade1ac&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;SpringBoot 还在用 if 校验参数？那你真的太low了，老司机都是这么玩的！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;SpringBoot 还在用 if 校验参数？那你真的太low了，老司机都是这么玩的！&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p data-style=&quot;margin-right: 0.5em; margin-left: 0.5em; white-space: normal; font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; letter-spacing: 0px; word-spacing: 2px; color: rgb(62, 62, 62); text-align: center;&quot; data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(168, 168, 168)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(62, 62, 62)&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100015744&quot; data-ratio=&quot;0.5552731893265566&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_gif/knmrNHnmCLEVGGmicJODkfibhcqyUwmTSC8CUvAMG78wPemfibvQ502uFs9jlziaLP50YcTs4rL9hQuzX32PAUOPHA/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;gif&quot; data-w=&quot;787&quot;/&gt;&lt;/p&gt;&lt;pre data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(138, 138, 138)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(89, 89, 89)&quot; data-style=&quot;letter-spacing: 0.544px; text-size-adjust: auto; word-spacing: 2px; color: rgb(89, 89, 89);&quot;&gt;&lt;p data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(168, 168, 168)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(62, 62, 62)&quot; data-style=&quot;margin-top: 5px; margin-bottom: 5px; white-space: normal; color: rgb(62, 62, 62); letter-spacing: 0.544px; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; font-size: 14px; line-height: normal;&quot;&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(120, 172, 254)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(120, 172, 254)&quot;&gt;最近面试BAT，整理一份面试资料&lt;/span&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(61, 167, 66)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(61, 167, 66)&quot;&gt;《&lt;strong data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(61, 167, 66)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(61, 167, 66)&quot;&gt;Java面试BATJ通关手册&lt;/strong&gt;》&lt;/span&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(120, 172, 254)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(120, 172, 254)&quot;&gt;，覆盖了Java核心技术、JVM、Java并发、SSM、微服务、数据库、数据结构等等。&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(156, 156, 156)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(74, 74, 74)&quot; data-style=&quot;margin-top: 15px; margin-bottom: 15px; letter-spacing: 0.544px; white-space: pre-line; line-height: 30px; color: rgb(74, 74, 74); font-family: Avenir, -apple-system-font, 微软雅黑, sans-serif;&quot;&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(120, 172, 254)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(120, 172, 254)&quot;&gt;获取方式：点“&lt;/span&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(61, 167, 66)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(61, 167, 66)&quot;&gt;在看&lt;/span&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(120, 172, 254)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(120, 172, 254)&quot;&gt;”，关注公众号并回复 &lt;/span&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(61, 167, 66)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(61, 167, 66)&quot;&gt;Java&lt;/span&gt;&lt;span data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(120, 172, 254)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(120, 172, 254)&quot;&gt; 领取，更多内容陆续奉上。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/pre&gt;&lt;pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;PS：因公众号平台更改了推送规则，如果不想错过内容，记得读完点一下&lt;/span&gt;&lt;strong&gt;“&lt;span&gt;在看&lt;/span&gt;”&lt;/strong&gt;&lt;span&gt;，加个&lt;/span&gt;&lt;strong&gt;“&lt;span&gt;星标&lt;/span&gt;”&lt;/strong&gt;&lt;span&gt;，这样每次新文章推送才会第一时间出现在你的订阅列表里。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;点&lt;strong&gt;“在看”&lt;/strong&gt;支持小哈呀，谢谢啦&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a1cf6a08c926b4050b972c562ced8fa5</guid>
<title>Taurus：面向机器学习的数据面架构</title>
<link>https://toutiao.io/k/9sdccca</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;em&gt;日益复杂的网络和多样化的工作负载要求网络内置更多的自动化决策能力，通过可编程网络设备在用户面支持机器学习工作负载就是一个可能的选项，本文提出了一种支持用户面推理的架构设计，相对控制面机器学习的性能有数量级的提升。原文: &lt;span&gt;Taurus: A Data Plane Architecture for Per-Packet ML&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;概要&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新兴应用(云计算、物联网、增强/虚拟现实)需要反应迅速、安全、可扩展的数据中心网络，当前这些网络实现了简单的、逐包计算的数据平面(如ECMP和sketches)，并在实现了数据驱动的性能、安全策略的慢速、毫秒级延迟控制平面的管理之下。然而，为了满足现代数据中心的应用服务水平目标(SLOs, service-level objectives)，网络必须弥合线速(line-rate)、逐包执行(per-packet execution)和复杂决策之间的差距。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此我们提出并设计和实现了&lt;em&gt;Taurus&lt;/em&gt;，这是一个用于线速推理的数据平面。Taurus将灵活的、抽象了并行模式(MapReduce)的定制化硬件添加到可编程网络设备(如交换机和网卡)中，这种新硬件基于流水线SIMD实现并行，完成逐包MapReduce操作(如推理)。我们对Taurus交换机ASIC的评估(基于几个真实世界的模型)表明，Taurus的运行速度比基于服务器的控制平面快几个数量级，同时面积增加了3.8%，线速机器学习模型的延迟增加了221ns。此外，Taurus FPGA原型实现了完整的模型精度，比最先进的控制平面异常检测系统的能力提升了两个数量级。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 简介&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为现代分布式工作负载(如云计算、物联网、增强/虚拟现实)保证严格的安全和服务水平目标(SLO)，需要根据整个数据中心网络的当前状态(如拓扑结构、队列大小以及链路和服务器负载)做出计算密集型管理和控制决策，并按线速应用在每个数据包上[170]。在当今双向Pb级带宽网络[60]中，即使是几微秒的延迟，也可能产生数以百万计的异常数据包[8][17][154]，从而使交换机队列饱和并导致拥堵[66][162][169]，或者由于丢包而导致过度重传[37]，以及造成流量和服务器负载不均衡[4][85]。然而，当前的实现面临两难，必须在每包线速执行或计算复杂性之间做出选择。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据面ASIC(如交换机和NIC)可以在纳秒级对网络条件做出反应，但其编程模型被限制为以线速度转发数据包(如流量表[15][63])，从而将网络操作限制在简单的启发式方法上[4][85][98]，或者需要在固定功能硬件中实现特定任务(如中间件[29][103]）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;控制面服务器可以做出复杂的、数据驱动的决策，但频率不高(通常在每条流的第一个数据包上)。即使有快速数据包IO[38][83][132]和专用硬件(如TPU[84]或GPU[119])，控制器和交换机之间的往返时延(10us或更多)也从根本上限制了控制面的反应速度。将计算转移到交换机CPU也没有帮助，因为缺乏全局网络知识，而且交换机ASIC和CPU之间的PCIe接口增加了大约900ns的往返延迟[117]，意味着在12.8Tb/s的网络上，ASIC在做出决定之前已经转发了大约12000个128字节的数据包(或22000个64字节数据包)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此提出如下问题:&quot;&lt;em&gt;如何能将控制面的复杂决策委托给数据面ASIC?&lt;/em&gt;&quot;控制面可以通过对全局网络状态进行采样来学习新的趋势(如攻击[106][153]、流量模式[162][169]和工作负载[169])，并可以训练机器学习(ML)模型来处理此类事件。然后，数据面可以使用封装了全网行为的模型，在不访问控制面的情况下做出转发决策。同时，控制面可以继续捕捉交换机的决策及其对指标的影响(如流量完成时间)，训练和优化模型以学习新的事件类型(或签名)以及提高决策质量，并以固定的时间间隔更新交换机模型。这种训练将发生在较粗的时间尺度上(几十毫秒)，但不在关键路径上。而且，使用最近训练的机器学习模型，数据面可以从流量的第一个数据包开始做决定，同时对已知(学习)类型的事件做出自主反应，控制面只需要对新(未见)事件类型进行干预&lt;sup&gt;[1]&lt;/sup&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[1] 另一方面，无论事件类型(或签名)如何[96]，流量规则需要控制面对每个事件进行干预。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么挑战就在于如何在数据面上运行机器学习模型。如果网络行为是稳定的，可以将模型输出映射为交换机的匹配动作表(MAT, match-action table)中的流量规则[15]。然而，现代数据中心网络是动态的，这将导致表项的频繁失效并需要频繁访问控制面，从而增加对网络事件做出反应的时间[170]。直接在现有交换机上实施模型，特别是深度神经网络(DNN, deep neural network)也是不可行的[144][168]。大多数机器学习算法是围绕线性代数建立的，使用了大量的重复性计算，在少量权重上进行定期通信[88][127][150]。匹配动作流水线的VLIW架构[15]缺乏必要的循环和乘法运算，以及不必要的灵活性(如全连通VLIW通信[178]、大型存储器和MAT中的三元CAM[15])，消耗了芯片面积，但对机器学习却没有好处[144]。简而言之，现有数据面缺乏执行现代机器学习算法(如DNN)所需的计算资源，而控制面服务器(和加速器)没有针对超过每秒几十比特的网络速度下的每包低延迟操作进行优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在本文中提出了Taurus，一个用于数据面逐包运算机器学习的特定领域架构。Taurus扩展了独立于协议的交换架构(PISA, ProtocolIndependent Switch Architecture)[15][63]，有一个基于并行模式抽象的新计算模块(即MapReduce)[88]，支持现代机器学习应用中常见的数据并行性[28]。MapReduce模块实现了空间SIMD架构，由内存单元(MU, memory unit)和计算单元(CU, compute
unit)组成，交错排列在一个网格中，并由一个静态互连(第4节)连接。每个CU有四个流水线计算阶段，每个计算阶段对16个独立的数据元素(通道)各进行一次8位定点操作。当评估一个16位输入感知器时，CU使用第一级来映射16个平行的乘法，然后使用第二级将乘法的值减少到一个单元。第二个CU应用激活函数(例如ReLU[112])。多个CU可以并行用于分层MapReduce计算(宽模型层)或串联用于流水线计算(多层)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MapReduce模块与解析器、MAT、调度器一起工作转发数据包，MAT将MapReduce与流水线连接起来，预处理MAT负责提取、格式化并记录数据包级、流级[154]、交叉流以及设备特征(基于带内网络遥测即INT[87])，MapReduce模块基于这些特征和机器学习模型生成数学结果，后处理MAT将输出转化为数据包转发决策。不需要机器学习决策的数据包可以绕过MapReduce模块，避免产生额外延迟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之，Taurus是一个集成系统，集合了网络和机器学习架构领域的想法(即用MapReduce模块扩展PISA流水线)，实现了&lt;em&gt;逐包机器学习(per-packet ML)&lt;/em&gt; 这种新的计算范式，以供行业和学界探索、创新&lt;sup&gt;[2]&lt;/sup&gt;。我们做出了如下贡献:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;用于MapReduce的带有可重配SIMD数据流引擎的Taurus交换机硬件设计(第3节)和实现(第4节)。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;基于15ns预测PDK[12]对ASIC&lt;sup&gt;[3]&lt;/sup&gt;(第5.1.1节)进行分析，并针对真实的机器学习网络应用(第5.1.2节)、微测试(第5.1.3节)和纯MAT实现(第5.1.4节)进行合成，以确定相对于市售交换机的速度和面积开销。Taurus的MapReduce模块为线速(1GPkt/s)机器学习模型平均增加了122ns延迟，而对于最大的模块配置来说，产生的面积和功耗开销分别增加了3.8%和2.8%。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;基于Taurus测试平台进行端到端系统评估，该测试平台基于连接到FPGA的可编程交换机，可对MapReduce模块进行模拟(第5.2.1节)。结果表明，Taurus完全实现了模型精度，并比控制面事件检测能力提升了两个数量级(第5.2.2节)。此外，数据面模型可以在几毫秒内学会处理来自控制器的新(异常)行为(第5.2.3节)。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[2] Taurus原型源代码可以在https://gitlab.com/dataplane-ai/taurus上公开获取。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[3] 设计评估基于最近的空间SIMD加速器Plasticine[127]，并将其修改为针对线速的纯推理应用。代价是需要降低精度，缩短流水线，并且不支持浮点运算，没有DRAM，以及更少的片上存储器。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. 逐包机器学习需求(THE NEED FOR PER-PACKET ML)&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了满足现代超大规模数据中心严格的SLO，网络界已经基于可编程数据平面(如Barefoot Tofino芯片[114][115])以包为单位运行服务(如负载均衡[4][85]、异常检测[95][102]和拥塞控制[162][169])。然而，数据平面的受限编程模型将服务限制在简单的启发式方法上，无法处理大规模数据中心网络的复杂交互[75]。另一方面，机器学习(ML)可以一定程度上处理这些复杂的交互[43][52]，而且，通过自动决策，机器学习算法可以利用大量网络数据，逐步学习适合特定数据中心的更明智的决策[6][17][42][101][110][123][152][153][172-174][99][131][169]。此外，最近关于拥塞控制[162][169]、数据包分类[99][126][131]和异常检测[106][153]的机器学习工作表明，这些算法比手动编写的启发式算法有更平滑、更准确的决策边界。例如，与现有机制(如PCC[37]和QUIC[91])相比，机器学习为拥塞控制提供了更好的针对吞吐量和延迟的平衡。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，机器学习通常用于闭环决策系统，因此其反应速度对数据中心的性能和安全性至关重要。例如，如表1所示，主动队列管理(例如RED[45][70]和DCTCP[5])必须针对每个数据包做出标记/删除的决定。入侵/故障检测和缓解方案(例如，针对重击[148]、微爆[139]、DoS[17][36]以及灰色故障[77][170])必须快速行动，因为即使几微秒的延迟也会造成PB级带宽网络中数百万的丢包，从而产生严重的影响。例如，在SYN-flood攻击中，每个丢包会在服务器上打开一个新的连接，造成CPU、内存资源以及网络带宽的不必要的消耗。另一方面，有效的资源分配(例如链接带宽)需要及时对网络流量进行分类[11]。在这些情况下，缓慢的机器学习决策会造成不同后果，但通常会导致次优的行为(例如无法达成安全和服务级别目标)，增加的延迟会导致延迟决策，并最终降低机器学习模型的准确性(第5节)。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7018030513176144&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmpGx2MQ7KSM6xLWn2YqfwHg7UjoicUtvhAGNryR2jK6loIMx9Z5VpqyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;721&quot;/&gt;&lt;figcaption&gt;表1. 网内应用需要的快速反应时间(基于包packet、微流flowlet、流flow或微秒级突发µburst)。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1. 数据面机器学习的限制(Limitations of Data-Plane ML)&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近有许多基于当前交换机抽象(例如MAT)[136][144][168]以及专门硬件[53]进行网络内机器学习的尝试，然而，这两种方法都有缺陷，因此无法提供线速的逐包机器学习。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1.1. 基于MAT的推理&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于VLIW架构的匹配动作(match-action)抽象，由于缺少指令(尤其是循环和乘法)以及低效的MAT流水线，在现代数据平面设备中不足以实现线速机器学习[15]。已经实现的二进制神经网络(基于几十个MAT)也不够精确[136][144]。同样，用于物联网分类的SVM[168]被证明在NetFPGA参考交换机(一个实验研究平台)上需要消耗额外8个表[104][113]。因此，相对于模型质量而言，其资源使用非常大(第5.1.4节)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;VLIW与SIMD并行模式的比较。&lt;/strong&gt;&lt;/em&gt; 单指令/多数据(SIMD)的每个指令成本比交换机的VLIW模型更便宜。目前在交换机MAT[15]中使用的VLIW模型，每级可以并行执行多个逻辑上独立的指令，可以在包头向量(PHV, packet-header vector)中读写任意位置。这种全对多(all-to-multiple)的输入通信和多对全(multiple-to-all)的输出通信需要大型交换结构，从而限制了每级指令数量。例如，一个16并发VLIW处理器的控制逻辑是同样强大的8个双并发处理器集群的20倍[178]。因此，Barefoot Tofino芯片每级只执行12个操作，8、16、32位操作各4个[65]。一个典型的DNN层可能需要72次乘法和144次加法[153]，即使乘法被添加到MAT中，也需要18个阶段(大部分情况下)。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1.2. 基于加速器的推理&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传统加速器(如TPU[84]、GPU[119]和FPGA[44])可以扩展数据平面，作为通过PCIe或以太网连接的直连推理引擎。在大多数加速器中，输入是批量的，以提高并行性，较大的批量可以通过更有效的矩阵乘法运算来提高吞吐量。然而，非批量(矩阵向量)处理对于确定性延迟是必要的，否则数据平面的数据包需要在等待批量填充时停滞。此外，增加物理上独立的加速器将消耗交换机端口(浪费收发器和带宽)或需要重复实现交换机功能(如数据包解析或者特征提取的匹配行动规则)。因此，独立的加速器会增加冗余面积，降低吞吐量，并增加更多能耗。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2. 控制面机器学习的限制(Limitations of Control-Plane ML)&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MAT[108]可以缓存在控制面上计算的推理结果，而不是按数据包执行深度模型。在缓存方案中，具有先前未见特征的数据包将被发送到控制面进行推理，而推理结果将作为流量规则存储在数据面中。然而，不同输入的深度模型(如数据包大小)，将被频繁触发昂贵的控制面操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于控制面的网络往返时间以及软件本身的开销，很难避免缓存失效的问题，即使有加速器，也会极大损害模型的准确性。表2在矢量CPU[1]、GPU[119]和TPU[84]上对一个用于异常检测的DNN模型[153]进行非批量推理的延迟进行了基准测试。延迟来自加速器的设置开销(例如Tensorflow[1])，CPU延迟最少，但仍需要0.67ms。最后，由于缓存随着流表的增加而增大[47][90]，规则配置时间(TCAM[25]为3ms)会限制缓存的大小。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3953488372093023&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmy8Xrl52wXLJUg6aNia8D1UwOYuxsxwYsYqWMRCQnoaccz8ysoBEBhmQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;387&quot;/&gt;&lt;figcaption&gt;表2. 控制面加速器推理时间。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3. Taurus架构&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Taurus是用于交换机(和网卡)的新型数据面架构，以线速基于每个数据包运行机器学习模型，并基于模型输出进行转发决策。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;系统概要设计。&lt;/strong&gt;&lt;/em&gt; 在支持Taurus的数据中心中，控制面收集网络全局视图，并训练机器学习模型以优化安全和交换机级指标。同时，数据面基于模型对每个数据包做出数据驱动决策。与传统基于SDN的数据中心不同，控制面在交换机中同时配置了权重和流量规则(图1)。权重比流量规则更节省空间，例如，匹配基准DNN(第5.1.2节)的动作可能需要12MB的流量规则(完整数据集)，但权重规则只占5.6KB，内存用量减少了2135倍。使用Deep Insight[78]等监控框架，控制面可以识别机器学习决策的影响并相应优化权重。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3755868544600939&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmfEXwjEcceiaK2Ih37SY0WAZSTxG9HvWO2Bc0ZiaPfkr62sIFVkJxYSDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;639&quot;/&gt;&lt;figcaption&gt;图1. 逐包机器学习: 训练和推理。主机随机标记数据包，追踪网络中的转发决策和QoS指标，以更新权重。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;异常检测案例研究。&lt;/strong&gt;&lt;/em&gt; 本节以基于机器学习的异常检测(使用4层DNN[153])作为实际运行的例子引入和介绍Taurus数据面流水线的各种逻辑组件(图2)。当数据包进入交换机时，首先被解析为包头矢量(PHV, 一种固定布局的结构化格式)[15]，以提取包头级别的特征(例如，连接时间、传输的字节数以及协议和服务类型)。接下来，交换机通过预处理MAT查找域级特征(例如，匹配IP地址与自治系统子网，以表明所有权或地理位置)，这些特征由控制面发现和配置，并使用VLIW动作对头域进行数据整合和增强(第3.1节)。然后，一旦MapReduce模块在提取的特征上执行完模型(第3.3节)，Taurus就通过后处理MAT将机器学习模型的输出转化为决策(第3.2节)。然后，这一决策被用来调度、转发或丢弃数据包。我们在基于PISA的交换机中共享MAT，以用于预处理和后处理。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2950138504155125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmH0e9XDfLDxGSYLuP7XPFpcb0eiasaoT4hOH8ofISWsVQBkzIO1ZTASg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;722&quot;/&gt;&lt;figcaption&gt;图2. Taurus异常检测应用逻辑步骤。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1. 解析和预处理(Parsing &amp;amp; Preprocessing)&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在推理之前，Taurus通过MAT将原始数据包头处理成规范的形式，根据需要添加或修复包级数据。通过交换机处理流水线的有状态元素(即寄存器)汇聚跨包和跨流特征。然后，MAT将汇聚信息添加到每个数据包元数据中，以增强基于每个数据包的预测。数据预处理也可以使用MAT将头域字段转换为机器学习模型的特征。例如，在异常检测例子中，MAT把特征格式化为定点数，MapReduce模块决定一个数据包是否正常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Taurus通过查找表将分类关系替换为更简单的数字关系。例如，表格将端口数字转换为线性似然值，这样更容易推理[31]。预处理也可以反转取样值所依据的概率分布。对指数分布的变量取对数会产生均匀分布，机器学习模型可以用更少的层来处理[138]。这样的特征工程将负载从机器学习模型转移到设计者身上，精炼特征可以用恒定大小来提高准确性[16][138]。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，带内网络遥测(INT, 将测量嵌入数据包)为交换机提供了全局网络状态视图[87]。因此，Taurus设备不限于利用交换机本地状态进行推理。相反，模型可以通过INT检查数据包的整个历史，并通过有状态寄存器检查流量的整个历史，以提升其预测能力(例如，计算整个流量的紧急标志或监测连接持续时间)。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2. 后处理和调度(Postprocessing &amp;amp; Scheduling)&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MAT也可以解释机器学习的决策。例如，如果异常检测模型输出0.9(表明可能的异常数据包)，MAT需要决定如何处理这个数据包，丢弃、标记还是隔离。在Taurus中，这些后处理MAT将推理与调度联系起来，使用像PIFO[147]这样的抽象来支持各种调度算法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;机器学习模型将提供概率保证，但我们可以用硬约束来约束其行为，以确保网络稳健运行。控制面将高层次的安全(没有不正确行为)和有效性(最终行为正确)属性编译成交换机的约束，作为后处理流程规则。通过约束机器学习模型的决策边界，数据面可以保证正确的网络行为，而无需复杂的模型验证。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3. 用于逐包机器学习推理的MapReduce(MapReduce for Per-Packet ML Inference)&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于每个数据包来说，通过推理结合清理过的特征和模型权重来做出决定。机器学习算法，例如支持向量机(SVM, support-vector machine)和神经网络，使用矩阵-向量线性代数运算和元素级非线性运算[59][72]。非线性运算让模型学习非线性语义，否则输出将是输入的线性组合。与头处理不同，机器学习运算是非常有规律的，使用许多乘加运算。在单个DNN神经元的计算量较大的线性部分中，输入特征分别与权重相乘，然后相加，产生标量值。概括来说，向量到向量(&lt;em&gt;map&lt;/em&gt;)和向量到标量(&lt;em&gt;reduce&lt;/em&gt;)运算足以满足神经元计算密集型的线性部分。这一点，加上目前交换机架构的局限性，促使我们需要新的数据面抽象，即&lt;em&gt;MapReduce&lt;/em&gt;，该抽象足够灵活，可以表达各种机器学习模型，但又足够定制化，从而允许有效的硬件实现。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3.1. MapReduce抽象&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们的设计利用MapReduce的SIMD并行性，以廉价的方式提供高计算量。&lt;em&gt;Map&lt;/em&gt;运算是对元素的向量运算，如加法、乘法或非线性运算。&lt;em&gt;Reduce&lt;/em&gt;运算是将元素的向量合并为标量，使用关联运算，如加法或乘法。图3显示了如何使用map和reduce来计算单个神经元(点积)，该神经元可以分层组合成大型神经网络。MapReduce是机器学习模型的一种流行形式，既可以在分布式系统中加速机器学习[22][54][55][57][133]，也可以在更精细的颗粒度上加速机器学习[20][21][28][150]。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6356073211314476&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmWfQYedRyyyzbuDGudgj5LZlOcH7cxLpq8FI9Hjumd8ymibn6DbgkwsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;601&quot;/&gt;&lt;figcaption&gt;图3. 感知机(perceptron)计算图，包括map、reduce和激活函数(外循环map)之间的细分，感知机是一个更大的DNN的基本构件。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;P4中的MapReduce控制块。&lt;/strong&gt;&lt;/em&gt; 为了给Taurus编程，我们在P4[13][122]中引入了新的专用控制块类型，称为&lt;code&gt;MapReduce&lt;/code&gt;，此外还有用于入口和出口匹配动作计算的控制块。在这个新的控制块中，MapReduce单元可以用&lt;code&gt;Map&lt;/code&gt;和&lt;code&gt;Reduce&lt;/code&gt;结构来调用。图4显示了我们提出的MapReduce语法(受到最近提出的Spatial语言[88]的启发)，实现了一个用于异常检测的例子。最外层的map对所有层的神经元进行迭代，而内部的MapReduce对每个神经元进行线性运算。最后一个map指令应用激活函数(即ReLU或sigmoids)。除了&lt;code&gt;Map&lt;/code&gt;和&lt;code&gt;Reduce&lt;/code&gt;之外，唯一需要的额外结构是数组和带外权重更新。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5822981366459627&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmOzhMfF6dGplBoNUphdfucUuXhYicPQ7llYgLRpSBw3xTRkxicW01398w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;644&quot;/&gt;&lt;figcaption&gt;图4. P4中基于Spatial[88]的MapReduce语法，用于异常检测示例的DNN层。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3.2. 更广泛的应用支持&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过提供通用原语，可以支持一系列比机器学习更广泛的应用(图5)，包括用于数据分析的流处理[18][89]，用于大规模分布式训练的梯度聚合[57][97][111][137]，以及交换机和NIC上的应用[125]。例如，Elastic RSS(eRSS)使用MapReduce进行一致性哈希调度数据包和处理器，map评估处理器的适用性，reduce选择最近的处理器[134]。MapReduce还可以支持sketching算法，包括用于流量大小估计的Count-Min-Sketches(CMS)[30]。此外，最近研究表明，布隆过滤器也可以从神经网络中受益，或者被神经网络取代[130]。实质上，Taurus提供了一个可编程的数据面抽象(MapReduce)，与现有的数据面抽象(即MAT)相比，可以更有效(在硬件资源使用和性能方面，第5节)的支持大量应用。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4817880794701987&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmMM51hemogBkpicEVqjzvkiazc473tfbIRuP8yNgxUhwMibDgg3OY1kgdw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;604&quot;/&gt;&lt;figcaption&gt;图5. 机器学习应用(上层)映射到模型和更简单的原语，然后编译到MapReduce。其他应用(右)直接映射到MapReduce。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4. Taurus实现&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图6显示了Taurus设备的完整物理数据面流水线，包括数据包解析控制块、MapReduce机器学习、基于MAT的数据包转发、调度以及非机器学习数据包的旁路。Taurus数据包解析器、预/后处理MAT和调度器基于现有硬件实现[15][56][147]。我们将Taurus的MapReduce模块建立在Plasticine[127]上，这是一个由计算和存储单元组成的粗粒度可重配阵列(CGRA, coarse-grained reconfigurable array)，可重新配置以匹配应用程序数据流图。然而，Plasticine最初是用于设计独立的加速器，而我们需要在网络中运行延迟优化的流媒体结构。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;MapReduce: 计算单元(Compute Unit, CU)。&lt;/strong&gt;&lt;/em&gt; 每个计算单元(CU，图8)由功能单元(FU,  functional unit)组成，按&lt;em&gt;通道(lane)&lt;/em&gt; 和&lt;em&gt;阶段(stage)&lt;/em&gt; 组织，分别或者同时执行map和reduce。在一个CU阶段内，所有通道执行相同的指令，并读取相同的相对位置。CU在各阶段之间有流水线寄存器，因此每个FU在每个周期都是活跃的，流水线也在CU之间的较高层次上发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于该结构需要作为全交换ASIC的一部分运行，因此资源效率是关键。我们使用定点低精度硬件来执行机器学习算法中线性代数所需的算术运算。与浮点运算相比，定点硬件速度更快，面积更小，而且功耗更低。此外，我们定制了CU中通道与阶段的比例，以适应应用空间的最低要求。对设计空间探索过程的完整解释见第5节。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;MapReduce: 内存单元(Memory Unit, MU)。&lt;/strong&gt;&lt;/em&gt; 接下来，我们重点关注内存访问速度。如果想对每个数据包做决策，就需要快速检索机器学习模型中的权重。基于SRAM操作可以在单周期内完成，所以我们只用片上存储器。由于DRAM访问需要100个周期，因此我们取消了DRAM控制器。虽然这限制了Taurus可以支持的模型大小，但可以在1GHz时钟下确保纳秒级延迟。我们使用堆叠的SRAM作为内存单元(MU)，像棋盘一样与CU穿插在一起，用于存储机器学习模型的权重(图7)。该设计也能支持粗粒度流水线，其中CU执行运算，MU充当流水线寄存器。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个CU内的多级流水线和互连流水线保证了1GHz的时钟频率，这是匹配高端交换机硬件线速的关键因素[15][147]&lt;sup&gt;[4]&lt;/sup&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[4] Taurus中的CU和MU架构目前支持密集机器学习模型，但也可以被扩展以支持稀疏线性代数[135]，这是我们未来的工作。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;预/后处理MAT。&lt;/strong&gt;&lt;/em&gt; 通过MAT(VLIW)进行数据清理，使用MapReduce(SIMD)进行推理，Taurus结合了不同的并行模式，建立了快速而灵活的数据面流水线。MAT通过相同的PHV接口与MapReduce模块相连，PHV接口用于连接流水线中其他阶段。只有包含特征的PHV的一部分进入MapReduce模块，而其他头域则直接进入后处理MAT，如图7所示。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4588859416445623&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmx1sichz9wTuiaG0SZcz3S5mzwboLtLMoz2iaZjhhvyXIOQCu0zmIJjPiaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;754&quot;/&gt;&lt;figcaption&gt;图6. Taurus修改后的数据面流水线，包括非机器学习数据包的旁路路径。预处理MAT根据PHV的元数据决定是否绕过机器学习，轮询(RR, round-robin)选择器仲裁哪条路径连接到后处理MAT。&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4880952380952381&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdm7ibrfcBsHVzcJ2NM4gnqDvHgC1WSfVbBpX3kk9YXLzSoNBkiclqyM6RA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;672&quot;/&gt;&lt;figcaption&gt;图7. Taurus MapReduce模块与流水线其余部分的接口。&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.37700145560407566&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdm4IGibqZqWjnmfTibGAnhk4B5AcXfI4JlAAURVcKLw2jv69CSmsGmpfgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;687&quot;/&gt;&lt;figcaption&gt;图8. 三级CU，由功能单元(FU, functional unit)和流水线寄存器(PR, pipeline register)组成。第三阶段支持map和稀疏reduce。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;非机器学习流量旁路。&lt;/strong&gt;&lt;/em&gt; 对于不需要机器学习推理的数据包，Taurus直接将其转发到后处理MAT，绕过了MapReduce(图6)。它将传统交换机的单一、大型包队列[15]分成三个子队列: 预处理MAT、MapReduce模块和后处理MAT。根据这些模块的流水线深度，按比例分配流量。预处理MAT将机器学习数据包转发到MapReduce模块(PHV在该模块中处理)，包体被排入相应队列，而非机器学习数据包则直接发送到后处理MAT，不会产生任何额外延迟。此外，数据包的非特征头也按照旁路路径进入后处理MAT，只有必要的特征头作为密集PHV才会进入MapReduce模块(以最小化稀疏数据的出现)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;目标无关的优化。&lt;/strong&gt;&lt;/em&gt; MapReduce的通用性足以支持与目标无关的优化，即考虑可用执行资源(并行化系数、带宽等)的优化，而不考虑特定硬件的设计细节[128][176]。并行化MapReduce程序在空间上展开循环，如果有足够的硬件资源，一个模型可以在每个周期执行一次迭代。由于循环的展开是在编译时进行的，Taurus可以保证确定性的吞吐量: 要么是线速性能，要么遵循已知系数。在交换机中由于回流[15]，或者在数据中心网络中由于链路超额订阅[62][118]，原有线速都会以某个静态系数下降。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了面积之外，由于交换机必须在数百纳秒内转发数据包，因此延迟也限制了交换机级的机器学习。延迟随着深度的增加而增加，所以数据中心SLO有效限制了模型的层数。通过用MAT预处理特征，可以用更少的层数和更少的延迟提供足够的准确性: 模型只需要学习特征间的关系，而不用考虑包头与特征的映射。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;依赖目标的编译。&lt;/strong&gt;&lt;/em&gt; 各种编程语言都支持MapReduce[71][109][121][155]。为了支持基于SIMD的结构，我们使用Spatial[88]的修改版对Taurus的MapReduce模块进行编程，Spatial是一种基于并行模式的特定领域语言(DSL)，将MapReduce程序表示为一连串嵌套循环，支持与目标相关的优化，也支持与目标无关的Taurus优化。程序被编译成流式数据流图，在这一层次结构中，最内部的循环是一个CU内的SIMD操作，外部循环被映射到多个CU。然后，过大的模式(那些需要太多计算阶段、输入或内存的模式)被分割成适合CU和MU的较小模式，这对于映射具有长基本块(即没有分支的长代码序列)的非线性函数很有必要。最后，得到的图通过MapReduce模块的互连结构进行路由。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5. 演进&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1. Taurus ASIC分析&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们首先通过分析其功率和面积来检查MapReduce模块(第5.1.1节)，然后通过编译几个最近提出的网络机器学习应用来评估其性能(第5.1.2节)。接下来，使用常见的机器学习组件来证明其灵活性，这些组件可以被组成表达各种算法(第5.1.3节)。最后，我们将其与现有的纯MAT的机器学习实现进行比较(第5.1.4节)。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.1. 设计空间探索(Design Space Exploration)&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Taurus的MapReduce模块是参数化的，包括精度、通道数和阶段数。我们通过ASIC合成和FreePDK15(一个预测性的15ns标准单元库[12])来估算Taurus的面积和功率，还使用CACTI 7.0[9]来估算存储器面积。为了指导评估，我们最大限度的减少面积、功率和延迟，同时以全模型精度(即无量化损失)和每包吞吐量为目标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;*&lt;strong&gt;定点精度。&lt;/strong&gt; 对于机器学习推理来说，在同等精度下，定点运算比浮点运算要快[67][84]。Taurus使用8位精度，其已经被证明足以用于推理(压缩模型使用的位数更少)[34][100][160]。表3中我们可以看到，对于各种DNN来说，量化误差(使用TensorFlow Lite [61][81])可以忽略不计。最小精度损失和4倍的资源节约(表4)证明我们降低精度的架构是有用的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4155844155844156&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmyLqXM8YcdKIic4crJTdn6oHCicCb6AwtR6WhqoOBPWs2FjDZY2lzCMHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;462&quot;/&gt;&lt;figcaption&gt;表3. 用于TMC物联网流量分类器的DNN的准确性[145]，表明8位量化损失最小。&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.35469107551487417&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmGuOn2kXHDWrD0Sc49Kgib4YdicUerjKzWX4vVffvElueib8cG7963vHxw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;437&quot;/&gt;&lt;figcaption&gt;表4. 不同精度的目标设计(16通道，4阶段)的面积和功率比例(每FU)。(横条代表每个条目相对该列中最大条目的大小)。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;通道数。&lt;/strong&gt;&lt;/em&gt; 理想情况下，一个CU中的通道数与可用的向量(SIMD)并行量相匹配。如果提供的通道太少，一个向量操作将不得不在多个CU之间进行映射，增加所需的控制逻辑，降低了效率。同样，提供超过向量并行量的通道会导致一些通道被闲置，因为CU只能在一个向量上执行操作。图9显示，原始面积效率(每FU的面积)随着通道数量的增加而增加。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5065885797950219&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmqHU9Lx0MNlmqd1mDl8ibY0ZuWEuxw9sfPUxj4cziaskwQ5kebCe5icyaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot;/&gt;&lt;figcaption&gt;图9. 各种CU配置(通道和阶段)的每个FU的面积和功耗。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;异常检测DNN[153]是需要线速运算的最大模型，所以我们用它来设定理想的通道数。DNN的最大层有12个隐藏单元，因此最大的点积计算涉及12个元素，16通道配置在一个CU内完全展开点积，同时最大限度减少利用率的不足。目前，16通道的配置平衡了面积开销、功率和map效率，但随着数据面机器学习模型的发展，最佳通道数可能会发生变化。由于MapReduce程序与硬件无关，编译器将根据需要处理展开系数的差异(即CU内与跨CU的并行性)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;阶段数。&lt;/strong&gt;&lt;/em&gt; 我们进行了类似研究来量化CU的阶段数对准确性的影响。内积(大多数模型背后的线性运算)使用两个阶段: 一个map(乘法)和一个reduce(加法)，而非线性运算使用一连串的map。因此，我们研究阶段数对非线性运算的影响。图10显示了使用不同深度的CU实现各种激活函数所需的总面积(CU数与面积的乘积)。此外，对于浅层激活函数（如ReLU)，后面的阶段没有被映射，导致面积随着阶段的增加而增加。理论上，更多的阶段更有效率(图9)，并且通过上下文合并可以让编译器映射更复杂的激活函数[177]。然而，内积和ReLU微基准(它们构成了许多普通网络的核心)只受益于两个阶段。因此，我们在最终的ASIC设计中选择了四个计算阶段来支持这两者。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5625965996908809&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmfz64pIcIkzceP3CB6PicoxzjotQnxic7ibibQgicn4mEpGgcQfzxZMv71kw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;647&quot;/&gt;&lt;figcaption&gt;图10. 随着阶段数的变化，激活函数所需的面积，所有运算都在线速(1GPkt/s)下进行。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;最终ASIC配置。&lt;/strong&gt;&lt;/em&gt; 最终的CU有16个通道、4阶段以及一个8位定点数据路径。包括路由资源[176]在内，需要0.044 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;(平均每个FU 680 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;µm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 1838.8 1033.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mo&quot;&gt;&lt;text data-variant=&quot;normal&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot; font-size=&quot;966.9px&quot; font-family=&quot;serif&quot;&gt;µ&lt;/text&gt;&lt;/g&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(557.2, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;)。每个MU有16组，每组1024个条目，包括路由资源在内消耗0.029 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;。总的来说，我们提供12×10的网格，CU和MU的比例为3:1，占用4.8 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;。考虑有4个可重配流水线的交换机，每个流水线有32个MAT，50%的芯片面积被MAT占用[86]。而且，每条流水线增加一个MapReduce模块会使总芯片面积增加3.8%，一个相同面积的设计会使每条流水线减少3个MAT。与我们可以支持的程序类型相比，这是一个可以忽略不计的开销(第5.1.2节)。Taurus的ASIC参数基于目前使用的应用和功能，对于新的模型来说，新的参数可能提供更大的效率。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.2. 应用基准测试(Application Benchmarks)&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们用4个机器学习模型[106][153][168][169]评估Taurus。第一个是物联网流量分类，基于11个特征和5个类别实现了KMeans聚类。第二个是基于SVM[106]的异常检测算法，有8个从KDD数据集[2][36]中选出的输入特征和一个径向基函数来模拟非线性关系。第三个是基于DNN的异常检测算法，需要6个输入特征(也是KDD子集)，有12、6和3个隐藏单元的层[153]。最后是基于LSTM的在线拥堵控制算法(Indigo [169])，使用32个LSTM单元和一个softmax层，被设计为在终端主机网卡上运行。虽然Indigo不是按包计算，但其更新间隔明显低于Taurus，从而能够实现更准确的控制决策和更快的反应时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;面积与功率。&lt;/strong&gt;&lt;/em&gt; 表5显示了相对于现有带有PISA流水线[15]的可编程交换ASIC&lt;sup&gt;[5]&lt;/sup&gt;的面积和功率，只考虑执行有用工作的CU和MU的数量。因此，这些基准测试所用原型的实际面积是最大基准面积，禁用了较小基准的未使用CU。如基于SVM的异常检测这样的简单模型，只有0.2%的面积开销和0.3%的功率开销。因此，我们设定Taurus的MapReduce模块面积为4.8 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;，与最近提出的交换结构增加的面积相似(例如，CONGA[4]和Banzai[146]分别消耗2%和12%的额外面积)。如果只支持较小的模型，KMeans、SVM和DNN将只增加约0.8%的面积和0.9%的功率。对于16位和32位的数据路径，面积和功率都将分别增加约2倍和4倍。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[5] 由于台积电的光罩限制为858 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;[142]，64×100 Gb/s交换芯片的尺寸为500-600 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4065155807365439&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmCfRrGVC7CH5RFsFicqFXkXPxcJicMx4NE6ympXJ0wbNQGMAaJWK2g8Yw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;706&quot;/&gt;&lt;figcaption&gt;表5. 几种应用模型的性能和资源开销。开销是相对于具有4个可重配流水线的500 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;mm^2&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -833.9 2159.6 844.9&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;msup&quot; transform=&quot;translate(878, 0)&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(878, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt; 芯片计算的[65]，该系统在以1 GPkt/s线速运行时预计功耗为270W[3][19][114]。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;延迟和吞吐量。&lt;/strong&gt;&lt;/em&gt; KMeans、SVM和DNN每周期(线速)处理一个数据包头，其延迟保持在纳秒范围内(表5)。假设数据中心交换延迟为1 μs[35]，KMeans、SVM和DNN分别增加了6.1%、8.3%和22.1%的延迟。在软件实现中，Indigo LSTM每10毫秒运行一次(可能是受LSTM的计算要求限制)，大大改善了应用层的吞吐量和延迟[169]。在Taurus中，Indigo可以每805 ns产生一个决策，从而使得LSTM网络可以对负载的变化做出更快速的反应，并更好的控制尾部延迟，数据旁路也能够避免增加非机器学习数据包的延迟。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.3. 微基准(Microbenchmarks)&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;较小的数据流应用可以组成一个大应用，例如，图11显示了由几个(线性)感知器层与非线性激活函数融合而成的DNN。这些微观基准是一般的构建模块，旨在展示可编程的、基于MapReduce的结构的多功能性。线性函数包含reduce网络，能够限制免通信并行的程度。相反，非线性函数由于相邻的数据元素之间没有互动，可以完美实现SIMD并行化。例如，如果16个不同的感知器的输出被输入到ReLU，我们只需将ReLU映射到16个输出上，然后就可以并行计算。表6显示了每个微基准在以线速运行时所需的面积和延迟。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3829787234042553&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmlvoRGl9t1xnWib5P5trhU9SpYjUWkmZnZxGvGuspEL9zxQALfZ4aRNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;658&quot;/&gt;&lt;figcaption&gt;图11. 被分解成独立微基准的小型DNN。&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6027874564459931&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmE4hLo5kplo9QcbSpYYJqM3UwvKEClNBWACA1EJjVZVrnZcjicH0Cdbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;574&quot;/&gt;&lt;figcaption&gt;表6. 在16通道/4级CU中以线速运行的每个微基准的面积和延迟。(延迟是感知器和ReLU执行时间之和）。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;线性运算。&lt;/strong&gt;&lt;/em&gt; 线性微基准是由一个具有8个输出和2个内核维度的一维卷积(经常用于寻找空间或时间上的相关性[94])和一个16元素的内积组成的，构成了感知器神经网络、LSTM和SVM的核心。由于卷积不能很好的映射到向量MapReduce中(有多个小的内积)，需要8倍的展开和大量芯片面积。然而，内积只在一个CU中以线速运行，可以被有效组成高性能深度神经网络。一个16通道的CU执行一个MapReduce的最小延迟是5个周期: 1个周期用于map，4个周期用于reduce，每个reduce周期处理不同片段(图8)。其余延迟来自于数据从输入到CU再到输出的移动，Taurus每次移动数据大约需要5个周期，这是空间分布式数据流的结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;展开(Unrolling)。&lt;/strong&gt;&lt;/em&gt; 基于MapReduce与目标无关的优化，大型机器学习模型可以在多个周期内运行，并相应的降低线速(表7)。展开内循环和外循环将实现更高的吞吐量和更低的延迟，同时消耗更多的面积。然而，并不是所有基准都可以展开其外循环的，例如，内积就没有外循环。迭代(即基于循环的)卷积以1/8的线速运行，展开它以满足线速会导致面积增加8倍。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3961267605633803&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdm3vnsdLfPUT6vcaLdVVMwW2TD6jSh2dZfiadfmokPDrmWxQ0gAxibhO1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;568&quot;/&gt;&lt;figcaption&gt;表7. 展开因子为1到8的微基准的吞吐量和面积比例。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;非线性运算。&lt;/strong&gt;&lt;/em&gt; 激活函数对于学习非线性行为是必要的，否则整个神经网络会崩溃成单一线性函数。每个激活函数都有不同的用途: LSTM使用tanh进行门控[73]，而DNN使用更简单的ReLU和Leaky ReLU[112]。最有效的函数(ReLU和Leaky ReLU)不需要查找表(LUT, lookup table)，只需要CU。更复杂的函数，包括sigmoid和tanh，有几个版本: 泰勒级数(Taylor series)、分片逼近(piecewise approximations)和LUT[67][161]，泰勒级数和分片逼近需要2-5倍的面积。基于LUT的函数需要更多内存，每个表通过将预先计算的输出值存储为1024个8位条目来近似模拟激活函数[67][161]，即使在复制时，也需要消耗交换内存的一小部分。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.4. 与只有MAT的机器学习设计的比较&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正如第5.1.1节所述，最终Taurus ASIC有4条流水线，每条流水线有一个MapReduce模块，消耗了3.8%的额外芯片面积(或者说相当于每个MapReduce模块等价于3个MAT的面积)。相比之下，只有MAT的神经网络(NN)实现[144][168]需要消耗10个MAT。例如，N2Net(一个二进制神经网络实现)，每层至少需要12个MAT[144]，总共需要48个MAT来支持异常检测DNN[153]，而Taurus只需要3个。同样，如果用IIsy框架[168]在MAT上实现非神经网络算法，SVM和KMeans分别消耗8和2个MAT，而相应的Taurus ASIC只需要0.5%的芯片面积(或1个MAT)。N2Net和IIsy都提供了将机器学习算法映射到MAT的独特方法，然而为了使数据面机器学习无处不在，我们需要为网络提供更有效的机器学习硬件。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2. 端到端性能&lt;span/&gt;&lt;/h4&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.1. Taurus测试环境&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了评估Taurus的端到端性能，我们使用工业标准的SDN工具、Tofino交换机以及实现了MapReduce模块的FPGA建立了一个测试平台，如图12所示。基于该测试平台，可以看到Taurus以每包为基础进行决策，比传统控制面机器学习解决方案更快，并且具有更大的准确性(第5.2.2节)。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6473988439306358&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmNriaVg4BtrsZJolf6jHfFDfpAuHZpdItmYhW6rmtpibt9xiaWLbib6AE2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;692&quot;/&gt;&lt;figcaption&gt;图12. 用于推理的Taurus测试平台。服务器运行领先的开源软件，即ONOS[46]、XDP[129]、InfluxDB[33]，以及使用TensorFlow[1]的控制面推理。Tofino交换机和FPGA分别实现了Taurus的MAT流水线和MapReduce模块。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;控制面机器学习: 基线(baseline)。&lt;/strong&gt;&lt;/em&gt; 为了确定比较基线&lt;sup&gt;[6]&lt;/sup&gt;，控制面服务器通过10Gbps链接，利用支持XDP的英特尔X710网卡[79] (运行一个84行的自定义XDP/eBPF程序)对遥测数据包进行采样，并将其存储在InfluxDB流数据库中[33]。向量机器学习模型(Keras[64]编写，272行)分批对数据包进行推理，开放网络操作系统(ONOS)[46]将模型结果作为流规则配置在交换机上。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[6] XDP 2.6.32 | Tensorflow/Keras 2.4.0 | InfluxDB 1.7.4 | ONOS 2.2.2 | Stratum/Barefoot SDE 9.2.0 | Xilinx Vivado 2020.2 | Spatial 40d182 | MoonGen 525d991&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;用户面机器学习: Taurus。&lt;/strong&gt;&lt;/em&gt; 在Taurus中&lt;sup&gt;[6]&lt;/sup&gt;，Stratum OS[48]运行在可编程Barefoot Wedge 100BF-32X[116]交换机上，实现Taurus的PISA组件。Tofino交换机的匹配动作流水线实现了Taurus的解析和预处理MAT(172行)。100Gbps以太网链接将交换机连接到Xilinx Alveo U250 FPGA[164]，模拟MapReduce硬件。Spatial[88] (105行)和Xilinx OpenNIC Shell[166]将机器学习模型编译到FPGA。为了传输数据包，我们将Xilinx 100G CMAC[167]与AXI流接口[165] (298行)集成到FPGA的MapReduce模块。一旦被FPGA处理，数据包在被转发到网络之前要经过交换机的后处理MAT。最后，用另外两个运行MoonGen[39]的80核英特尔至强服务器来产生和接收流量。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.2. 异常检测案例研究&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在控制面和数据面实现了机器学习异常检测模型(第3节)。我们从NSL-KDD[36]数据集生成标记的数据包级trace(labeled packet-level trace)，方法是将连接级记录扩展为分档的数据包trace(即每个trace元素代表一组数据包)，并对其状态进行标记(异常或正常)。从原始trace中取样获取流量大小的分布、混合和数据包头域的变化率，以创造现实的工作负载。我们用这些数据来训练DNN，离线F1得分(典型机器学习指标[157])为71.1。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了测试数据面机器学习，我们将所有流量发送到交换机和FPGA。交换机使用MAT对特征进行预处理。首先用数据包五元组来索引一组有状态寄存器，这些寄存器积累了整个数据包的特征(例如紧急标志的数量)，然后将这些特征格式化为定点数，并将数据包转发到FPGA，由机器学习模型将其标记为异常或正常。然后，数据包返回交换机，后处理MAT基于机器学习决策对包进行处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在基线系统中，交换机积累特征并将其作为遥测数据包发送到控制面进行推理。如果该模型确定某个数据包不正常，就会提取相应的IP，并配置一个交换机规则，将其数据包标记为异常。任何在规则安装前通过的数据包都会被(错误的)原样转发。流量以固定的5Gbps发送，而控制面采样从100 kbps (&lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;10^{-5}&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -864 1953.7 886&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot;/&gt;&lt;path data-c=&quot;30&quot; d=&quot;M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z&quot; transform=&quot;translate(500, 0)&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; transform=&quot;translate(1000, 393.1) scale(0.707)&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mo&quot;&gt;&lt;path data-c=&quot;2212&quot; d=&quot;M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(778, 0)&quot;&gt;&lt;path data-c=&quot;35&quot; d=&quot;M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;)到100 Mbps (&lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;10^{-2}&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -864 1953.7 886&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot;/&gt;&lt;path data-c=&quot;30&quot; d=&quot;M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z&quot; transform=&quot;translate(500, 0)&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; transform=&quot;translate(1000, 393.1) scale(0.707)&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mo&quot;&gt;&lt;path data-c=&quot;2212&quot; d=&quot;M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(778, 0)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;)不等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;Taurus对每个包作出响应。&lt;/strong&gt;&lt;/em&gt; 表8显示控制面的毫秒级延迟。即使在低采样率下，基线也有32毫秒的延迟。随着负载增长，批处理的规模也在增长，因为批处理的第一个元素必须等待整个批处理的完成，这又进一步增加了延迟。此外，当实现逐包处理的系统时，机器学习不是瓶颈。相反，表8显示，规则配置和数据包收集使系统不堪重负&lt;sup&gt;[7]&lt;/sup&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.1632068718682892&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdm3aX46lcCfvhGLREOgzocMFYXveqpcLjMtJf5LfsjZxcpnODByD4mkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1397&quot;/&gt;&lt;figcaption&gt;表8. 基线机器学习系统的批大小、延迟和准确性。Taurus发现重要事件的能力相对基线系统提升了两个数量级。&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[7] 我们还探索了在交换机CPU而不是在服务器上配置规则，以消除控制器和交换机操作系统之间的RTT。然而，由于交换机CPU性能较差(8个1.6GHz CPU，而服务器有80个2.5GHz CPU），减少的RTT时间被额外的流量规则计算时间所抵消，平均延迟高出112%。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;Taurus维持了全部模型的准确性。&lt;/strong&gt;&lt;/em&gt; 大多数异常数据包都没有被基线系统检测到，而Taurus捕获了一半以上(表8)。考虑到被识别的异常情况、遗漏的异常情况和被错误标记为异常的正常数据包的数量[8][153]，我们使用F1分数来评估准确性。Taurus实现了与孤立模型相同的F1得分。然而，由于规则配置和其他处理延迟，基线系统错过了很多数据包，因此有效F1得分较低。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.3. 在线训练&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Taurus的机器学习模型也可以被更新以优化全局指标，这对于单个交换机无法观察到的行为(如下游拥堵)很有帮助。我们将遥测数据包送入控制面的训练应用程序，并使用流量规则配置时间作为估计，评估更新数据面模型权重所需的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图13显示，更高的采样率(对应更多的批处理数据)收敛速度更快(几十到几百毫秒)，表明在线训练是可能的，并切控制面采样数据频率越高越好。此外，图14显示，具有最小批量(64)和最多周期(10)的配置会获得最高的F1分数，并且增加的训练时间被更快的收敛所抵消。因此，较小批量和较大周期会产生较少的但更有意义的更新，从而避免频繁但没有意义的更新。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4717948717948718&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmGlbM7VOnQTYKicBp24p9T5D29K7hxI2EJAALRljtYOJfaT1DVBTXj4g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;585&quot;/&gt;&lt;figcaption&gt;图13. Taurus的准确性随着时间的推移而提高。用更高的采样率进行训练，收敛得更快。&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4500818330605565&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0Wfnn5FS676p3CxceC73icdmWvlhRI7WxZ8F86tibthBEYwFKRuwMhDFLKFNSQETJzJlcnJ0sw23S9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;611&quot;/&gt;&lt;figcaption&gt;图14. 较小批量和较多周期进行训练，收敛速度更快(采样率为 &lt;span&gt;&lt;span role=&quot;presentation&quot; data-formula=&quot;10^{-2}&quot; data-formula-type=&quot;inline-equation&quot;&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -864 1953.7 886&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot;/&gt;&lt;path data-c=&quot;30&quot; d=&quot;M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z&quot; transform=&quot;translate(500, 0)&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; transform=&quot;translate(1000, 393.1) scale(0.707)&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mo&quot;&gt;&lt;path data-c=&quot;2212&quot; d=&quot;M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(778, 0)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;)。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6. 当前的限制以及未来的工作&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然Taurus可以比现有平台更有效的支持逐包ML算法，但模型大小仍然受到可用硬件资源的限制。为了适应更大的模型，必须研究模型压缩技术。此外，需要更多研究来提供正确性可证明的模型验证和更快的训练时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;模型压缩。&lt;/strong&gt;&lt;/em&gt; Taurus的主要应用是网络控制和协调。神经网络可以解决各种控制问题[10][149][156]，而且越来越小。例如，用于非线性控制的结构化控制网[149]的性能几乎与512个神经元的DNN一样好，每层只需要4个神经元。有了这样的小网络，Taurus可以同时运行多个模型(例如，一个模型用于入侵检测，另一个用于流量优化)。此外，像量化(quantization)、修剪(pruning)和蒸馏(distillation)等技术可以进一步减少模型大小[7][69][81][158]。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;正确性。&lt;/strong&gt;&lt;/em&gt; 某些应用(如路由)有明确的正确和错误答案，如果没有安全措施，将会很难保证。相反，机器学习最适合于本质上是启发式的应用，如拥塞控制[162][169]、负载均衡[4][85]和异常检测[106][153]，其决定只影响网络性能和安全性，而不是其核心的包转发行为。当机器学习决策可能影响网络正确性时，后处理规则可以确保最终决策是有边界的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;训练速度。&lt;/strong&gt;&lt;/em&gt; 最后，对于较大的数据中心网络，训练反应时间可能会更高。这意味着瞬时网络问题(如特定链路上的负载)不能通过训练来处理，因为在训练完成之前，事件可能就已经结束了。相反，训练会逐渐学习是什么导致这些问题以及如何避免这些问题。为了检测和应对具体事件，较低延迟的技术，如INT，反而可以将网络状态作为特征提供给模型。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;7. 相关工作&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;面向机器学习的架构。&lt;/strong&gt;&lt;/em&gt; 现场可编程门阵列(FPGA, Field programmable gate array)是最为广泛使用的可重配架构，既可用作定制加速器[140]，也可用作原型(例如NetFPGA[104][113])。然而，FPGA的片上网络消耗了高达70%的芯片总功率[23]，而且其可变、缓慢的时钟频率使网络和交换速度(每秒Tb级)操作变得复杂。CGRA为机器学习运算进行了优化，通常有快速、固定的时钟频率，可以和Taurus中的MapReduce模块和MAT进行无缝集成[32][50][58][105][107][143]。其他架构，如Eyeriss[26]、Brainwave[49]和EIE[68]，专注于特定算法实现，从而提高效率。这些实现都可用于交换机内机器学习，但过于死板，如果基于特定加速器实现标准化，就有可能由于缺乏灵活的抽象(如MapReduce)，使得网络无法从未来的机器学习研究中获益。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;面向机器学习的数据面。&lt;/strong&gt;&lt;/em&gt; 在现代数据中心内部，基于MAT的可编程数据面交换机(如Barefoot Tofino[114][115])，允许网络轻松支持、执行不同任务(如重击者检测[148]、负载均衡[85]、安全[93, 175]、快速重路由[74]和调度[147])，而这些任务之前需要通过终端主机服务器、中间件或固定功能交换机实现。最近业界正在努力(N2Net[144]和IIsy[168])研究在交换机上运行更复杂的机器学习算法。然而，仅靠MAT是不适合支持机器学习算法的，为了让数据面机器学习变得无处不在，需要更有效的硬件来减少不必要的资源使用(即面积和功率)。我们相信Taurus是朝着这个方向迈出的第一步。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据中心终端主机上，现代智能网卡(和网络加速器)为服务器提供了更高的计算能力，不仅可以卸载数据包处理逻辑，还可以处理特定应用逻辑，以实现更低的延迟和更高的吞吐量。像英特尔的基础设施单元(IPU, Infrastructure Unit)[80]、英伟达的数据处理单元(DPU, Data Processing Unit)[120]和基于FPGA的智能网卡[44, 164]等产品都旨在加速各种终端主机工作负载(例如，管理程序、虚拟交换、基于批处理的机器学习训练和推理、存储)。然而，这些智能网卡并不适合需要在数据中心全网范围内进行的逐包操作。数据包仍然需要从交换机访问服务器(和网卡)，从而导致从收到数据包到交换机上的应用做出相应决策之间有一个RTT的延迟。中间件在其固定功能硬件实现上也有类似的问题，从而限制了灵活性并促使其频繁升级[141]。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;面向网络的机器学习。&lt;/strong&gt;&lt;/em&gt; 许多网络应用可以从机器学习中受益。例如，拥塞控制学习算法[162][169]已被证明优于人类设计的同类算法[37][66][171]。此外，Boutaba等人[17]确定了网络任务的机器学习用例，如流量分类[40][41]、流量预测[24][27]、主动队列管理[151][179]和安全[124]。所有这些应用都可以立即基于Taurus进行部署。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;面向机器学习的网络。&lt;/strong&gt;&lt;/em&gt; 特定的网络也可以加速机器学习算法本身。通过对现代数据面硬件的细微改进，交换机可以在网络中聚合梯度，将训练速度提高300%[51][92][137]。Gaia(一个用于分布式机器学习的系统[76])也考虑了广域网络带宽并在训练过程中调节梯度的移动。虽然Taurus没有明确为分布式训练加速而设计，但MapReduce可以比MAT更有效的聚合包含在数据包中的数字化权重。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;8. 结论&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前，数据中心网络被划分为线速网络、逐包数据面和较慢的控制面，其中控制面运行复杂的、数据驱动的管理策略来配置数据面。这种方法太慢了，控制面的传输增加了不可避免的延迟，因此控制面无法对网络事件做出足够快的反应。Taurus把复杂决策放到数据面，降低反应时间，并提高了管理和控制策略的特殊性。我们证明，Taurus可以线速运行，并在可编程交换机流水线(RMT)上增加了很小的开销(3.8%的面积和122 ns的平均延迟)，同时可以加速最近提出的几个机器学习网络基准测试。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;展望未来，为了实现自动驾驶网络(self-driving network, 又称自智网络)，必须在大规模训练开始之前部署硬件。我们相信，Taurus为网内机器学习提供了一个立足点，其硬件可以安装在下一代数据平面上，以提高性能和安全性。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;A. 附录&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;A.1. 概要&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该工件包含文中提出的Taurus的MapReduce模块(第3.3节)和端到端性能评估中使用的异常检测(AD)应用程序(第5.2节)的源代码。MapReduce模块与Xilinx OpenNIC Shell[166]集成，并通过称为Spatial[88]的高级DSL进行编程。AD应用程序在端到端测试平台上运行，由各种组件组成: P4程序、Python脚本、ONOS应用和Spatial代码(第5.2.2节)。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;A.2. 范围&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该工件包含两个新组件: MapReduce模块和异常检测代码，目标是提供实现完整测试平台(第5.2节)所需的两个缺失组件，以运行端到端性能评估。其余组件是现有的专用硬件(Barefoot Tofino Switch [114], Xilinx Alveo Board [164])和软件代码库(P4 [14], ONOS [46], Spatial [88], 等等)的集合，可以随时购买和下载(请见下文的依赖关系)&lt;sup&gt;[8]&lt;/sup&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[8] 我们希望用户购买所需硬件，并获得必要的工具和许可证的个人访问权，因此在工件中不包含这些组件的设置。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;A.3. 内容&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;em&gt;FPGA中的MapReduce模块。&lt;/em&gt; 该资源库包含了构建基于FPGA的MapReduce模块实现的源代码和说明。在FPGA上运行MapReduce模块的详细文档在这里提供: https://gitlab.com/dataplane-ai/taurus/mapreduce。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;em&gt;异常检测应用。&lt;/em&gt; 该资源库含有异常检测应用(AD)的源代码(P4、Python、ONOS、Spatial)。此外还提供了复制用于评估AD应用的端到端测试平台所需的细节。对AD应用的介绍在这里: https://gitlab.com/dataplane-ai/taurus/applications/anomalydetection-asplos22。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;A.4. 托管&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;源代码托管在GitLab&lt;sup&gt;[9]&lt;/sup&gt;和figshare&lt;sup&gt;[10]&lt;/sup&gt;上。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;[9] https://gitlab.com/dataplane-ai/taurus&lt;br/&gt;[10] https://doi.org/10.6084/m9.figshare.17097524&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;A.5. 依赖&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该工件依赖于以下第三方硬件和软件工具:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;EdgeCore Wedge 100BF-32X Switch&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Xilinx Alveo U250 FPGA board&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Intel P4 Studio&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Xilinx Vivado Design Tool&lt;/span&gt;&lt;sup&gt;[5]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Xilinx OpenNIC Shell&lt;/span&gt;&lt;sup&gt;[6]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Spatial DSL&lt;/span&gt;&lt;sup&gt;[7]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;ONF Stratum OS&lt;/span&gt;&lt;sup&gt;[8]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;[ONF Open Network Operating System (ONOS)](https://opennetworking.org/onos/ &quot;ONF Open Network Operating System (ONOS &quot;ONF Open Network Operating System (ONOS)&quot;)&quot;)&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;MoonGen Traffic Generator&lt;/span&gt;&lt;sup&gt;[9]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;参考文献&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. 2016. Tensorflow: A System For Large-Scale Machine Learning. In USENIX OSDI ’16.&lt;br/&gt;[2] Preeti Aggarwal and Sudhir Kumar Sharma. 2015. Analysis of KDD Dataset Attributes-Class Wise For Intrusion Detection. Computer Science 57 (2015), 842–851. https://doi.org/10.1016/j.procs.2015.07.490&lt;br/&gt;[3] Anurag Agrawal and Changhoon Kim. 2020. Intel Tofino2 – A 12.9Tbps P4-Programmable Ethernet Switch. In Hot Chips ’20.&lt;br/&gt;[4] Mohammad Alizadeh, Tom Edsall, Sarang Dharmapurikar, Ramanan Vaidyanathan, Kevin Chu, Andy Fingerhut, Vinh The Lam, Francis Matus, Rong Pan, Navindra Yadav, and George Varghese. 2014. CONGA: Distributed Congestion-aware Load Balancing for Datacenters. In ACM SIGCOMM ’14. https://doi.org/10.1145/2619239.2626316&lt;br/&gt;[5] Mohammad Alizadeh, Albert Greenberg, David A Maltz, Jitendra Padhye, Parveen Patel, Balaji Prabhakar, Sudipta Sengupta, and Murari Sridharan. 2010. Data Center TCP (DCTCP). In ACM SIGCOMM ’10. https://doi.org/10.1145/1851182.1851192&lt;br/&gt;[6] Tom Auld, Andrew W Moore, and Stephen F Gull. 2007. Bayesian Neural Networks For Internet Traffic Classification. IEEE Transactions on Neural Networks ’07 18, 1 (2007), 223–239. https://doi.org/10.1109/TNN.2006.883010&lt;br/&gt;[7] Jimmy Ba and Rich Caruana. 2014. Do Deep Nets Really Need to be Deep?. In NeurIPS ’14.&lt;br/&gt;[8] Jarrod Bakker, Bryan Ng, Winston KG Seah, and Adrian Pekar. 2019. Traffic Classification with Machine Learning in a Live Network. In 2019 IFIP/IEEE Symposium on Integrated Network and Service Management (IM) ’19.&lt;br/&gt;[9] Rajeev Balasubramonian, Andrew B Kahng, Naveen Muralimanohar, Ali Shafiee, and Vaishnav Srinivas. 2017. CACTI 7: New tools for interconnect exploration in innovative off-chip memories. ACM Transactions on Architecture and Code Optimization (TACO ’17) 14, 2 (2017), 1–25. https://doi.org/10.1145/3085572&lt;br/&gt;[10] Marc G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling. 2013. The Arcade Learning Environment: An Evaluation Platform for General Agents. Journal of Artificial Intelligence Research (JAIR) 47 (2013), 253–279.&lt;br/&gt;[11] Laurent Bernaille, Renata Teixeira, Ismael Akodkenou, Augustin Soule, and Kave Salamatian. 2006. Traffic Classification on the Fly. ACM SIGCOMM Computer Communication Review (CCR) 36, 2 (2006), 23–26. https://doi.org/10.1145/1129582.1129589&lt;br/&gt;[12] Kirti Bhanushali and W Rhett Davis. 2015. FreePDK15: An open-source predictive process design kit for 15nm FinFET technology. In Proceedings of the 2015 Symposium on International Symposium on Physical Design. 165–170. https://doi.org/10.1145/2717764.2717782&lt;br/&gt;[13] Pat Bosshart, Dan Daly, Glen Gibb, Martin Izzard, Nick McKeown, Jennifer Rexford, Cole Schlesinger, Dan Talayco, Amin Vahdat, George Varghese, et al. 2014. P4: Programming protocol-independent packet processors. ACM SIGCOMM Computer Communication Review 44, 3 (2014), 87–95. https://doi.org/10.1145/2656877.2656890&lt;br/&gt;[14] Pat Bosshart, Dan Daly, Glen Gibb, Martin Izzard, Nick McKeown, Jennifer Rexford, Cole Schlesinger, Dan Talayco, Amin Vahdat, George Varghese, et al. 2014. P4: Programming Protocol-Independent Packet Processors. ACM SIGCOMM Computer Communication Review (CCR) 44, 3 (2014), 87–95. https://doi.org/10.1145/2656877.2656890&lt;br/&gt;[15] Pat Bosshart, Glen Gibb, Hun-Seok Kim, George Varghese, Nick McKeown, Martin Izzard, Fernando Mujica, and Mark Horowitz. 2013. Forwarding Metamorphosis: Fast Programmable Match-Action Processing in Hardware for SDN. In ACM SIGCOMM ’13. https://doi.org/10.1145/2534169.2486011&lt;br/&gt;[16] Leon Bottou. 2010. Feature Engineering. https://www.cs.princeton.edu/ courses/archive/spring10/cos424/slides/18-feat.pdf. Accessed on 08/12/2021.&lt;br/&gt;[17] Raouf Boutaba, Mohammad A Salahuddin, Noura Limam, Sara Ayoubi, Nashid Shahriar, Felipe Estrada-Solano, and Oscar M Caicedo. 2018. A Comprehensive Survey on Machine Learning for Networking: Evolution, Applications and Research Opportunities. Journal of Internet Services and Applications (JISA) 9, 1
(2018), 16. https://doi.org/10.1186/s13174-018-0087-2&lt;br/&gt;[18] Andrey Brito, Andre Martin, Thomas Knauth, Stephan Creutz, Diogo Becker, Stefan Weigert, and Christof Fetzer. 2011. Scalable and Low-Latency Data Processing with Stream MapReduce. In IEEE CLOUDCOM ’11. https://doi.org/10.1109/CloudCom.2011.17&lt;br/&gt;[19] Broadcom. [n.d.]. Tomahawk/BCM56960 Series. https://www.broadcom.com/products/ethernet-connectivity/switching/strataxgs/bcm56960-series. Accessed on 08/12/2021.&lt;br/&gt;[20] Kevin J Brown, HyoukJoong Lee, Tiark Romp, Arvind K Sujeeth, Christopher De Sa, Christopher Aberger, and Kunle Olukotun. 2016. Have Abstraction and Eat Performance, too: Optimized Heterogeneous Computing with Parallel Patterns. In IEEE/ACM CGO ’16. https://doi.org/10.1145/2854038.2854042&lt;br/&gt;[21] Kevin J Brown, Arvind K Sujeeth, Hyouk Joong Lee, Tiark Rompf, Hassan Chafi, Martin Odersky, and Kunle Olukotun. 2011. A Heterogeneous Parallel Framework for Domain-Specific Languages. In IEEE PACT ’11. https://doi.org/10.1109/PACT.2011.15&lt;br/&gt;[22] Douglas Ronald Burdick, Amol Ghoting, Rajasekar Krishnamurthy, Edwin Peter Dawson Pednault, Berthold Reinwald, Vikas Sindhwani, Shirish Tatikonda, Yuanyuan Tian, and Shivakumar Vaithyanathan. 2013. Systems and methods for processing machine learning algorithms in a MapReduce environment. US Patent 8,612,368.&lt;br/&gt;[23] Benton Highsmith Calhoun, Joseph F Ryan, Sudhanshu Khanna, Mateja Putic, and John Lach. 2010. Flexible Circuits and Architectures for Ultralow Power. Proc. IEEE 98, 2 (2010), 267–282.&lt;br/&gt;[24] Samira Chabaa, Abdelouhab Zeroual, and Jilali Antari. 2010. Identification and Prediction of Internet Traffic Using Artificial Neural Networks. Journal of Intelligent Learning Systems and Applications (JILSA) 2, 03 (2010), 147. https://doi.org/10.4236/jilsa.2010.23018&lt;br/&gt;[25] Huan Chen and Theophilus Benson. 2017. The Case for Making Tight Control Plane Latency Guarantees in SDN Switches. In ACM SOSR ’17. https://doi.org/10.1145/3050220.3050237&lt;br/&gt;[26] Yu-Hsin Chen, Tushar Krishna, Joel S Emer, and Vivienne Sze. 2016. Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks. IEEE Journal of Solid-State Circuits 52, 1 (2016), 127–138. https://doi.org/10.1109/JSSC.2016.2616357&lt;br/&gt;[27] Zhitang Chen, Jiayao Wen, and Yanhui Geng. 2016. Predicting Future Traffic Using Hidden Markov Models. In IEEE ICNP ’16.&lt;br/&gt;[28] Cheng-Tao Chu, Sang K Kim, Yi-An Lin, YuanYuan Yu, Gary Bradski, Kunle Olukotun, and Andrew Y Ng. 2007. Map-Reduce for Machine Learning on Multicore. In NeurIPS ’07. 281–288.&lt;br/&gt;[29] Cisco Systems, Inc. [n.d.]. Cisco Meraki (MX450): Powerful Security and SD-WAN for the Branch &amp;amp; Campus. https://meraki.cisco.com/products/appliances/mx450. Accessed on 08/12/2021.&lt;br/&gt;[30] Graham Cormode and Shan Muthukrishnan. 2005. An Improved Data Stream Summary: The Count-Min Sketch and its Applications. Journal of Algorithms 55, 1 (2005), 58–75. https://doi.org/10.1016/j.jalgor.2003.12.001&lt;br/&gt;[31] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for Youtube Recommendations. In ACM RecSys ’16. https://doi.org/10.1145/2959100.2959190&lt;br/&gt;[32] Darren C Cronquist, Chris Fisher, Miguel Figueroa, Paul Franklin, and Carl Ebeling. 1999. Architecture Design of Reconfigurable Pipelined Datapaths. In IEEE ARVLSI ’99.&lt;br/&gt;[33] Influx Data. [n.d.]. InfluxDB. https://www.influxdata.com/products/influxdboverview/. Accessed on 08/12/2021.&lt;br/&gt;[34] Christopher De Sa, Megan Leszczynski, Jian Zhang, Alana Marzoev, Christopher R Aberger, Kunle Olukotun, and Christopher Ré. 2018. High-Accuracy Low-Precision Training. arXiv preprint arXiv:1803.03383 (2018).&lt;br/&gt;[35] Dell EMC. [n.d.]. Data Center Switching Quick Reference
Guide. https://i.dell.com/sites/doccontent/shared-content/datasheets/en/Documents/Dell-Networking-Data-Center-Quick-ReferenceGuide.pdf. Accessed on 08/12/2021.&lt;br/&gt;[36] L Dhanabal and SP Shantharajah. 2015. A Study on NSL-KDD Dataset for Intrusion Detection System Based on Classification Algorithms. International Journal of Advanced Research in Computer and Communication Engineering (IJARCCE) 4, 6 (2015), 446–452. https://doi.org/10.17148/IJARCCE.2015.4696&lt;br/&gt;[37] Mo Dong, Qingxi Li, Doron Zarchy, P Brighten Godfrey, and Michael Schapira. 2015. PCC: Re-architecting Congestion Control for Consistent High Performance. In USENIX NSDI ’15.&lt;br/&gt;[38] DPDK. [n.d.]. DPDK. https://www.dpdk.org/. Accessed on 08/12/2021.&lt;br/&gt;[39] Paul Emmerich, Sebastian Gallenmüller, Daniel Raumer, Florian Wohlfart, and Georg Carle. 2015. Moongen: A Scriptable High-Speed Packet Generator. In ACM IMC ’15.&lt;br/&gt;[40] Jeffrey Erman, Martin Arlitt, and Anirban Mahanti. 2006. Traffic Classification Using Clustering Algorithms. In ACM MineNet ’06. https://doi.org/10.1145/1162678.1162679&lt;br/&gt;[41] Jeffrey Erman, Anirban Mahanti, Martin Arlitt, and Carey Williamson. 2007. Identifying and Discriminating Between Web and Peer-to-Peer Traffic in the Network Core. In WWW ’07. https://doi.org/10.1145/1242572.1242692&lt;br/&gt;[42] Alice Este, Francesco Gringoli, and Luca Salgarelli. 2009. Support Vector Machines For TCP Traffic Classification. Computer Networks 53, 14 (2009), 2476–2490. https://doi.org/10.1016/j.comnet.2009.05.003&lt;br/&gt;[43] Nick Feamster and Jennifer Rexford. 2018. Why (and How) Networks Should Run Themselves. In ACM ANRW ’18.&lt;br/&gt;[44] Daniel Firestone, Andrew Putnam, Sambhrama Mundkur, Derek Chiou, Alireza Dabagh, Mike Andrewartha, Hari Angepat, Vivek Bhanu, Adrian Caulfield, Eric Chung, et al. 2018. Azure Accelerated Networking: SmartNICs in the Public Cloud. In USENIX NSDI ’18.&lt;br/&gt;[45] Sally Floyd and Van Jacobson. 1993. Random early detection gateways for congestion avoidance. IEEE/ACM Transactions on networking 1, 4 (1993), 397–413.&lt;br/&gt;[46] Open Networking Foundation. [n.d.]. ONOS: Open Network Operating System. https://www.opennetworking.org/onos/. Accessed on 08/12/2021.&lt;br/&gt;[47] Open Networking Foundation. [n.d.]. ONOS: Single Bench Flow Latency Test. https://wiki.onosproject.org/display/ONOS/2.2%3A+Experiment+I+-+Single+Bench+Flow+Latency+Test. Accessed on 08/12/2021.&lt;br/&gt;[48] Open Networking Foundation. [n.d.]. Stratum OS. https://www.opennetworking.org/stratum/. Accessed on 08/12/2021.&lt;br/&gt;[49] Jeremy Fowers, Kalin Ovtcharov, Michael Papamichael, Todd Massengill, Ming Liu, Daniel Lo, Shlomi Alkalay, Michael Haselman, Logan Adams, Mahdi Ghandi, et al. 2018. A Configurable Cloud-Scale DNN Processor for Real-Time AI. In IEEE ISCA ’18. https://doi.org/10.1109/ISCA.2018.00012&lt;br/&gt;[50] Mingyu Gao and Christos Kozyrakis. 2016. HRL: Efficient and Flexible Reconfigurable Logic for Near-Data Processing. In IEEE HPCA ’16.&lt;br/&gt;[51] Nadeen Gebara, Manya Ghobadi, and Paolo Costa. 2021. In-network Aggregation for Shared Machine Learning Clusters. In MLSys ’21.&lt;br/&gt;[52] Yilong Geng, Shiyu Liu, Feiran Wang, Zi Yin, Balaji Prabhakar, and Mendel Rosenblum. 2017. Self-Programming Networks: Architecture and Algorithms. In IEEE Allerton ’17.&lt;br/&gt;[53] Yilong Geng, Shiyu Liu, Zi Yin, Ashish Naik, Balaji Prabhakar, Mendel Rosenblum, and Amin Vahdat. 2019. SIMON: A Simple and Scalable Method for Sensing, Inference and Measurement in Data Center Networks. In USENIX NSDI ’19.&lt;br/&gt;[54] Amol Ghoting, Prabhanjan Kambadur, Edwin Pednault, and Ramakrishnan Kannan. 2011. NIMBLE: A Toolkit for the Implementation of Parallel Data Mining and Machine Learning Algorithms on MapReduce. In ACM SIGKDD KDD ’11. https://doi.org/10.1145/2020408.2020464&lt;br/&gt;[55] Amol Ghoting, Rajasekar Krishnamurthy, Edwin Pednault, Berthold Reinwald, Vikas Sindhwani, Shirish Tatikonda, Yuanyuan Tian, and Shivakumar Vaithyanathan. 2011. SystemML: Declarative Machine Learning on MapReduce. In IEEE ICDE ’11.&lt;br/&gt;[56] Glen Gibb, George Varghese, Mark Horowitz, and Nick McKeown. 2013. Design principles for packet parsers. In ACM/IEE ANCS ’13. https://doi.org/10.1109/ANCS.2013.6665172&lt;br/&gt;[57] Dan Gillick, Arlo Faria, and John DeNero. 2006. MapReduce: Distributed Computing for Machine Learning. Berkley, Dec 18 (2006).&lt;br/&gt;[58] Seth Copen Goldstein, Herman Schmit, Mihai Budiu, Srihari Cadambi, Matthew Moe, and R Reed Taylor. 2000. PipeRench: A Reconfigurable Architecture and Compiler. Computer 33, 4 (2000), 70–77.&lt;br/&gt;[59] Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. 2016. Deep Learning. Vol. 1. MIT Press, Cambridge.&lt;br/&gt;[60] Google. [n.d.]. A look inside Google’s Data Center Networks. https://-cloudplatform.googleblog.com/2015/06/A-Look-Inside-Googles-Data-CenterNetworks.html. Accessed on 08/12/2021.&lt;br/&gt;[61] Google. 2021. Tensorflow Lite. https://www.tensorflow.org/tflite.&lt;br/&gt;[62] Albert Greenberg, James R. Hamilton, Navendu Jain, Srikanth Kandula, Changhoon Kim, Parantap Lahiri, David A. Maltz, Parveen Patel, and Sudipta Sengupta. 2009. VL2: A Scalable and Flexible Data Center Network. In ACM SIGCOMM ’09. https://doi.org/10.1145/1592568.1592576&lt;br/&gt;[63] P4.org Archictecture Working Group. 2018. P4-16 Portable Switch Architecture. https://p4.org/p4-spec/docs/PSA-v1.1.0.pdf.&lt;br/&gt;[64] Antonio Gulli and Sujit Pal. 2017. Deep learning with Keras. Packt Publishing Ltd.&lt;br/&gt;[65] Vladimir Gurevich. 2018. Programmable Data Plane at Terabit Speeds. https://p4.org/assets/p4_d2_2017_programmable_data_plane_at_terabit_-speeds.pdf. Accessed on 08/12/2021.&lt;br/&gt;[66] Sangtae Ha, Injong Rhee, and Lisong Xu. 2008. CUBIC: A New TCP-Friendly High-Speed TCP Variant. ACM SIGOPS Operating Systems Review 42, 5 (2008), 64–74. https://doi.org/10.1145/1400097.1400105&lt;br/&gt;[67] Song Han, Junlong Kang, Huizi Mao, Yiming Hu, Xin Li, Yubin Li, Dongliang Xie, Hong Luo, Song Yao, Yu Wang, et al. 2017. ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA. In ACM/SIGDA FPGA ’17. https://doi.org/10.1145/3020078.3021745&lt;br/&gt;[68] Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A Horowitz, and William J Dally. 2016. EIE: Efficient Inference Engine on Compressed Deep Neural Network. In ACM/IEEE ISCA ’16. https://doi.org/10.1145/3007787.3001163&lt;br/&gt;[69] Song Han, Jeff Pool, John Tran, and William Dally. 2015. Learning Both Weights and Connections for Efficient Neural Network. In NeurIPS ’15.&lt;br/&gt;[70] B Hariri and N Sadati. 2007. NN-RED: an AQM mechanism based on neural networks. Electronics Letters 43, 19 (2007), 1053–1055. https://doi.org/10.1049/el:20071791&lt;br/&gt;[71] Robert Harper, David MacQueen, and Robin Milner. 1986. Standard ML. Department of Computer Science, University of Edinburgh.&lt;br/&gt;[72] Marti A. Hearst, Susan T Dumais, Edgar Osuna, John Platt, and Bernhard Scholkopf. 1998. Support Vector Machines (SVMs). IEEE Intelligent Systems and their Applications 13, 4 (1998), 18–28.&lt;br/&gt;[73] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory (LSTM). Neural Computation 9, 8 (1997), 1735–1780.&lt;br/&gt;[74] Thomas Holterbach, Edgar Costa Molero, Maria Apostolaki, Alberto Dainotti, Stefano Vissicchio, and Laurent Vanbever. 2019. Blink: Fast Connectivity Recovery Entirely in the Data Plane. In USENIX NSDI ’19.&lt;br/&gt;[75] Kurt Hornik. 1991. Approximation capabilities of multilayer feedforward networks. Neural networks 4, 2 (1991), 251–257. https://doi.org/10.1016/0893-6080(91)90009-T&lt;br/&gt;[76] Kevin Hsieh, Aaron Harlap, Nandita Vijaykumar, Dimitris Konomis, Gregory R Ganger, Phillip B Gibbons, and Onur Mutlu. 2017. Gaia: Geo-Distributed Machine Learning Approaching LAN Speeds. In USENIX NSDI ’17.&lt;br/&gt;[77] Peng Huang, Chuanxiong Guo, Lidong Zhou, Jacob R Lorch, Yingnong Dang, Murali Chintalapati, and Randolph Yao. 2017. Gray Failure: The Achilles’ Heel of Cloud-Scale Systems. In ACM HotOS ’17. https://doi.org/10.1145/3102980.3103005&lt;br/&gt;[78] Intel. [n.d.]. Intel Deep Insight Network Analytics Software. https://www.intel.com/content/www/us/en/products/network-io/programmable-ethernetswitch/network-analytics/deep-insight.html. Accessed on 08/12/2021.&lt;br/&gt;[79] Intel. [n.d.]. Intel® Ethernet Network Adapter X710-DA2 for OCP 3.0. https://ark.intel.com/content/www/us/en/ark/products/184822/intelethernet-network-adapter-x710-da4-for-ocp-3-0.html. Accessed on 08/12/2021.&lt;br/&gt;[80] Intel. 2021. Intel Infrastructure Processing Unit (Intel IPU) and SmartNICs. https://www.intel.com/content/www/us/en/products/network-io/smartnic.html.&lt;br/&gt;[81] Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko. 2018. Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference. In IEEE CVPR ’18.&lt;br/&gt;[82] Nathan Jay, Noga Rotman, Brighten Godfrey, Michael Schapira, and Aviv Tamar. 2019. A deep reinforcement learning perspective on internet congestion control. In ICML ’19.&lt;br/&gt;[83] Eun Young Jeong, Shinae Woo, Muhammad Jamshed, Haewon Jeong, Sunghwan Ihm, Dongsu Han, and KyoungSoo Park. 2014. MTCP: A Highly Scalable UserLevel TCP Stack for Multicore Systems. In USENIX NSDI ’14.&lt;br/&gt;[84] Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. 2017. In-Datacenter Performance Analysis of a Tensor Processing Unit. In IEEE ISCA ’17. https://doi.org/10.1145/3079856.3080246&lt;br/&gt;[85] Naga Katta, Mukesh Hira, Changhoon Kim, Anirudh Sivaraman, and Jennifer Rexford. 2016. HULA: Scalable Load Balancing Using Programmable Data Planes. In ACM SOSR ’16. https://doi.org/10.1145/2890955.2890968&lt;br/&gt;[86] Changhoon Kim. [n.d.]. Programming The Network Data Plane: What, How, and Why? https://conferences.sigcomm.org/ events/apnet2017/slides/chang.pdf. Accessed on 08/12/2021.&lt;br/&gt;[87] Changhoon Kim, Anirudh Sivaraman, Naga Katta, Antonin Bas, Advait Dixit, and Lawrence J Wobker. 2015. In-Band Network Telemetry via Programmable Dataplanes. In ACM SIGCOMM ’15 (Demo).&lt;br/&gt;[88] David Koeplinger, Matthew Feldman, Raghu Prabhakar, Yaqi Zhang, Stefan Hadjis, Ruben Fiszel, Tian Zhao, Luigi Nardi, Ardavan Pedram, Christos Kozyrakis, and Kunle Olukotun. 2018. Spatial: A Language and Compiler for Application Accelerators. In ACM/SIGPLAN PLDI ’18. https://doi.org/10.1145/3192366.3192379&lt;br/&gt;[89] Vibhore Kumar, Henrique Andrade, Buğra Gedik, and Kun-Lung Wu. 2010. DEDUCE: At the Intersection of MapReduce and Stream Processing. In ACM EDBT ’10. https://doi.org/10.1145/1739041.1739120&lt;br/&gt;[90] Maciej Kuźniar, Peter Perešíni, and Dejan Kostić. 2015. What You Need to Know About SDN Flow Tables. In PAM ’15. Springer.&lt;br/&gt;[91] Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles Krasic, Dan Zhang, Fan Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar, et al. 2017.&lt;br/&gt;The QUIC Transport Protocol: Design and Internet-Scale Deployment. In ACM SIGCOMM ’17. https://doi.org/10.1145/3098822.3098842&lt;br/&gt;[92] ChonLam Lao, Yanfang Le, Kshiteej Mahajan, Yixi Chen, Wenfei Wu, Aditya Akella, and Michael M Swift. 2021. ATP: In-network Aggregation for Multitenant Learning. In NSDI ’21.&lt;br/&gt;[93] Ângelo Cardoso Lapolli, Jonatas Adilson Marques, and Luciano Paschoal Gaspary. 2019. Offloading real-time ddos attack detection to programmable data planes. In 2019 IFIP/IEEE Symposium on Integrated Network and Service Management (IM) ’19. IEEE, 19–27.&lt;br/&gt;[94] Yann LeCun, LD Jackel, Leon Bottou, A Brunot, Corinna Cortes, JS Denker, Harris Drucker, I Guyon, UA Muller, Eduard Sackinger, P Simard, and V Vapnik. 1995. Comparison of Learning Algorithms for Handwritten Digit Recognition. In ICANN ’95.&lt;br/&gt;[95] Guanyu Li, Menghao Zhang, Shicheng Wang, Chang Liu, Mingwei Xu, Ang Chen, Hongxin Hu, Guofei Gu, Qi Li, and Jianping Wu. 2021. Enabling Performant, Flexible and Cost-Efficient DDoS Defense With Programmable Switches. IEEE/ACM Transactions on Networking ’21 (2021). https://doi.org/10.1109/TNET.2021.3062621&lt;br/&gt;[96] Ruey-Hsia Li and Geneva G. Belford. 2002. Instability of Decision Tree Classification Algorithms. In ACM SIGKDD ’02. https://doi.org/10.1145/775047.775131&lt;br/&gt;[97] Youjie Li, Iou-Jen Liu, Yifan Yuan, Deming Chen, Alexander Schwing, and Jian Huang. 2019. Accelerating Distributed Reinforcement Learning with In-Switch Computing. In ACM/IEEE ISCA ’19. https://doi.org/10.1145/3307650.3322259&lt;br/&gt;[98] Yuliang Li, Rui Miao, Hongqiang Harry Liu, Yan Zhuang, Fei Feng, Lingbo Tang, Zheng Cao, Ming Zhang, Frank Kelly, Mohammad Alizadeh, and Minlan Yu. 2019. HPCC: High Precision Congestion Control. In ACM SIGCOMM ’19. https://doi.org/10.1145/3341302.3342085&lt;br/&gt;[99] Eric Liang, Hang Zhu, Xin Jin, and Ion Stoica. 2019. Neural Packet Classification. In ACM SIGCOMM ’19. https://doi.org/10.1145/3341302.3342221&lt;br/&gt;[100] Darryl Lin, Sachin Talathi, and Sreekanth Annapureddy. 2016. Fixed Point Quantization of Deep Convolutional Networks. In ICML ’16.&lt;br/&gt;[101] Yingqiu Liu, Wei Li, and Yun-Chun Li. 2007. Network Traffic Classification Using K-Means Clustering. In IEEE IMSCCS ’07. https://doi.org/10.1109/IMSCCS.2007.52&lt;br/&gt;[102] Zaoxing Liu, Hun Namkung, Georgios Nikolaidis, Jeongkeun Lee, Changhoon Kim, Xin Jin, Vladimir Braverman, Minlan Yu, and Vyas Sekar. 2021. Jaqen: A High-Performance Switch-Native Approach for Detecting and Mitigating Volumetric DDoS Attacks with Programmable Switches. In USENIX Security ’21.&lt;br/&gt;[103] Loadbalancer.org. [n.d.]. Hardware ADC. https://www.loadbalancer.org/products/hardware/. Accessed on 08/12/2021.&lt;br/&gt;[104] John W Lockwood, Nick McKeown, Greg Watson, Glen Gibb, Paul Hartke, Jad Naous, Ramanan Raghuraman, and Jianying Luo. 2007. NetFPGA: An Open Platform for Gigabit-Rate Network Switching and Routing. In IEEE MSE ’07.&lt;br/&gt;[105] Alan Marshall, Tony Stansfield, Igor Kostarnov, Jean Vuillemin, and Brad Hutchings. 1999. A Reconfigurable Arithmetic Array for Multimedia Applications. In IEEE FPGA ’99. https://doi.org/10.1145/296399.296444&lt;br/&gt;[106] Tahir Mehmood and Helmi B Md Rais. 2015. SVM for Network Anomaly Detection using ACO Feature Subset. In IEEE iSMSC ’15.&lt;br/&gt;[107] Bingfeng Mei, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. 2002. DRESC: A Retargetable Compiler for Coarse-Grained Reconfigurable Architectures. In IEEE FPT ’02.&lt;br/&gt;[108] Albert Mestres, Alberto Rodriguez-Natal, Josep Carner, Pere Barlet-Ros, Eduard Alarcón, Marc Solé, Victor Muntés-Mulero, David Meyer, Sharon Barkai, Mike J Hibbett, et al. 2017. Knowledge-Defined Networking. ACM SIGCOMM Computer Communication Review (CCR) 47, 3 (2017), 2–10. https://doi.org/10.1145/3138808.3138810&lt;br/&gt;[109] Yaron Minsky, Anil Madhavapeddy, and Jason Hickey. 2013. Real World OCaml: Functional Programming for the Masses. O’Reilly Media, Inc.&lt;br/&gt;[110] Andrew W Moore and Denis Zuev. 2005. Internet Traffic Classification using Bayesian Analysis Techniques. In ACM SIGMETRICS ’05. https://doi.org/10.1145/1064212.1064220&lt;br/&gt;[111] Manya Ghobadi Nadeen Gebara, Paolo Costa. 2021. In-Network Aggregation for Shared Machine Learning Clusters. In MlSys.&lt;br/&gt;[112] Vinod Nair and Geoffrey E Hinton. 2010. Rectified Linear Units Improve Restricted Boltzmann Machines. In ICML ’10.&lt;br/&gt;[113] NetFPGA. [n.d.]. NetFPGA: A Line-rate, Flexible, and Open Platform for Research and Classroom Experimentation. https://netfpga.org/. Accessed on 08/12/2021.&lt;br/&gt;[114] Barefoot Networks. [n.d.]. Barefoot Tofino. https://www.intel.com/content/www/us/en/products/network-io/programmable-ethernet-switch/tofinoseries.html. Accessed on 08/12/2021.&lt;br/&gt;[115] Barefoot Networks. [n.d.]. Barefoot Tofino 2. https://www.intel.com/content/www/us/en/products/network-io/programmable-ethernet-switch/tofino2-series.html. Accessed on 08/12/2021.&lt;br/&gt;[116] Edgecore Networks. [n.d.]. WEDGE 100BF-32X: 100GBE Data Center Switch. https://www.edge-core.com/productsInfo.php?cls=1&amp;amp;cls2=5&amp;amp; cls3=181&amp;amp;id=335. Accessed on 08/12/2021.&lt;br/&gt;[117] Rolf Neugebauer, Gianni Antichi, José Fernando Zazo, Yury Audzevich, Sergio López-Buedo, and Andrew W. Moore. 2018. Understanding PCIe Performance for End Host Networking. In ACM SIGCOMM ’18. https://doi.org/10.1145/3230543.3230560&lt;br/&gt;[118] Radhika Niranjan Mysore, Andreas Pamboris, Nathan Farrington, Nelson Huang, Pardis Miri, Sivasankar Radhakrishnan, Vikram Subramanya, and Amin Vahdat. 2009. PortLand: A Scalable Fault-tolerant Layer 2 Data Center Network Fabric. In ACM SIGCOMM ’09. https://doi.org/10.1145/1592568.1592575&lt;br/&gt;[119] NVIDIA. [n.d.]. Tesla T4. https://www.nvidia.com/en-us/data-center/tesla-t4/. Accessed on 08/12/2021.&lt;br/&gt;[120] NVidia. 2021. NVIDIA BLUEFIELD DATA PROCESSING UNITS. https://www.nvidia.com/en-us/networking/products/data-processing-unit/.&lt;br/&gt;[121] Martin Odersky, Lex Spoon, and Bill Venners. 2008. Programming in Scala. Artima Inc.&lt;br/&gt;[122] P4.org. 2020. P4-16 Language Specification. https://p4.org/p4-spec/docs/P4-16-v1.2.1.pdf. &lt;br/&gt;[123] Junghun Park, Hsiao-Rong Tyan, and C-C Jay Kuo. 2006. Internet Traffic Classification for Scalable QoS Provision. In IEEE ICME ’06.&lt;br/&gt;[124] Roberto Perdisci, Davide Ariu, Prahlad Fogla, Giorgio Giacinto, and Wenke Lee. 2009. McPAD: A Multiple Classifier System for Accurate Payload-Based Anomaly Detection. Computer Networks 53, 6 (2009), 864–881. https://doi.org/10.1016/j.comnet.2008.11.011&lt;br/&gt;[125] Dan RK Ports and Jacob Nelson. 2019. When Should The Network Be The Computer?. In ACM HotOS ’19. https://doi.org/10.1145/3317550.3321439&lt;br/&gt;[126] Pascal Poupart, Zhitang Chen, Priyank Jaini, Fred Fung, Hengky Susanto, Yanhui Geng, Li Chen, Kai Chen, and Hao Jin. 2016. Online Flow Size Prediction for Improved Network Routing. In IEEE ICNP ’16.&lt;br/&gt;[127] Raghu Prabhakar, Yaqi Zhang, David Koeplinger, Matt Feldman, Tian Zhao, Stefan Hadjis, Ardavan Pedram, Christos Kozyrakis, and Kunle Olukotun. 2017. Plasticine: A Reconfigurable Architecture for Parallel Patterns. In ACM/IEEE ISCA ’17. https://doi.org/10.1145/3079856.3080256&lt;br/&gt;[128] Raghu Prabhakar, Yaqi Zhang, and Kunle Olukotun. 2020. Coarse-Grained Reconfigurable Architectures. In NANO-CHIPS 2030. Springer, 227–246. https://doi.org/10.1007/978-3-030-18338-7_14&lt;br/&gt;[129] IO Visor Project. [n.d.]. XDP: eXpress Data Path. https://www.iovisor.org/technology/xdp. Accessed on 08/12/2021.&lt;br/&gt;[130] Jack W Rae, Sergey Bartunov, and Timothy P Lillicrap. 2019. Meta-Learning Neural Bloom Filters. arXiv:1906.04304 (2019).&lt;br/&gt;[131] Alon Rashelbach, Ori Rottenstreich, and Mark Silberstein. 2020. A Computational Approach to Packet Classification. In ACM SIGCOMM ’20. https://doi.org/10.1145/3387514.3405886&lt;br/&gt;[132] Luigi Rizzo. 2012. Netmap: A Novel Framework for Fast Packet I/O. In USENIX ATC ’12.&lt;br/&gt;[133] Joshua Rosen, Neoklis Polyzotis, Vinayak Borkar, Yingyi Bu, Michael J Carey, Markus Weimer, Tyson Condie, and Raghu Ramakrishnan. 2013. Iterative mapreduce for large scale machine learning. arXiv preprint arXiv:1303.3517 (2013).&lt;br/&gt;[134] Alexander Rucker, Tushar Swamy, Muhammad Shahbaz, and Kunle Olukotun. 2019. Elastic RSS: Co-Scheduling Packets and Cores Using Programmable NICs. In ACM APNet ’19. https://doi.org/10.1145/3343180.3343184&lt;br/&gt;[135] Alexander Rucker, Matthew Vilim, Tian Zhao, Yaqi Zhang, Raghu Prabhakar, and Kunle Olukotun. 2021. Capstan: A Vector RDA for Sparsity. Association for Computing Machinery, New York, NY, USA, 1022–1035.&lt;br/&gt;[136] Davide Sanvito, Giuseppe Siracusano, and Roberto Bifulco. 2018. Can the Network Be the AI Accelerator?. In NetCompute ’18. https://doi.org/10.1145/3229591.3229594&lt;br/&gt;[137] Amedeo Sapio, Marco Canini, Chen-Yu Ho, Jacob Nelson, Panos Kalnis, Changhoon Kim, Arvind Krishnamurthy, Masoud Moshref, Dan RK Ports, and Peter Richtárik. 2019. Scaling Distributed Machine Learning with In-Network Aggregation. arXiv:1903.06701 (2019).&lt;br/&gt;[138] Dipanjan Sarkar. 2018. Continuous Numeric Data – Strategies for Working with Continuous, Numerical Data. https://towardsdatascience.com/understandingfeature-engineering-part-1-continuous-numeric-data-da4e47099a7b. Accessed on 08/12/2021.&lt;br/&gt;[139] Danfeng Shan, Fengyuan Ren, Peng Cheng, Ran Shu, and Chuanxiong Guo. 2018. Micro-burst in Data Centers: Observations, Analysis, and Mitigations. In IEEE ICNP ’18. https://doi.org/10.1109/ICNP.2018.00019&lt;br/&gt;[140] Ahmad Shawahna, Sadiq M Sait, and Aiman El-Maleh. 2018. Fpga-Based Accelerators of Deep Learning Networks for Learning and Classification: A Review. IEEE Access 7 (2018), 7823–7859.&lt;br/&gt;[141] Justine Sherry, Sylvia Ratnasamy, and Justine Sherry At. 2012. A survey of enterprise middlebox deployments. (2012).&lt;br/&gt;[142] Anton Shilov. [n.d.]. TSMC &amp;amp; Broadcom Develop 1700-mm2 CoWoS Interposer: 2x Larger Than Reticles. https://www.anandtech.com/show/15582/tsmcbroadcom-develop-1700-mm2-cowos-interposer-2x-larger-than-reticles. Accessed on 08/12/2021.
[143] Hartej Singh, Ming-Hau Lee, Guangming Lu, Fadi J Kurdahi, Nader Bagherzadeh, and Eliseu M Chaves Filho. 2000. MorphoSys: An Integrated Reconfigurable System for Data-Parallel and Computation-Intensive Applications. IEEE Transactions on Computers ’00 49, 5 (2000), 465–481.&lt;br/&gt;[144] Giuseppe Siracusano and Roberto Bifulco. 2018. In-Network Neural Networks. arXiv:1801.05731 (2018).&lt;br/&gt;[145] Arunan Sivanathan, Hassan Habibi Gharakheili, Franco Loi, Adam Radford, Chamith Wijenayake, Arun Vishwanath, and Vijay Sivaraman. 2018. Classifying IoT devices in Smart Environments Using Network Traffic characteristics. IEEE Transactions on Mobile Computing ’18 18, 8 (2018), 1745–1759. https://doi.org/10.1109/TMC.2018.2866249&lt;br/&gt;[146] Anirudh Sivaraman, Alvin Cheung, Mihai Budiu, Changhoon Kim, Mohammad Alizadeh, Hari Balakrishnan, George Varghese, Nick McKeown, and Steve Licking. 2016. Packet Transactions: High-Level Programming for Line-Rate Switches. In ACM SIGCOMM ’16. https://doi.org/10.1145/2934872.2934900&lt;br/&gt;[147] Anirudh Sivaraman, Suvinay Subramanian, Mohammad Alizadeh, Sharad Chole, Shang-Tse Chuang, Anurag Agrawal, Hari Balakrishnan, Tom Edsall, Sachin Katti, and Nick McKeown. 2016. Programmable Packet Scheduling at Line Rate. In ACM SIGCOMM ’16. https://doi.org/10.1145/2934872.2934899&lt;br/&gt;[148] Vibhaalakshmi Sivaraman, Srinivas Narayana, Ori Rottenstreich, Shan Muthukrishnan, and Jennifer Rexford. 2017. Heavy-Hitter Detection Entirely in the Data Plane. In ACM SOSR ’17. https://doi.org/10.1145/3050220.3063772&lt;br/&gt;[149] Mario Srouji, Jian Zhang, and Ruslan Salakhutdinov. 2018. Structured control nets for deep reinforcement learning. In ICML ’18. PMLR, 4742–4751.&lt;br/&gt;[150] Arvind K Sujeeth, HyoukJoong Lee, Kevin J Brown, Tiark Rompf, Hassan Chafi, Michael Wu, Anand R Atreya, Martin Odersky, and Kunle Olukotun. 2011. OptiML: an implicitly parallel domain-specific language for machine learning. In ICML ’11.&lt;br/&gt;[151] Jinsheng Sun and Moshe Zukerman. 2007. An Adaptive Neuron AQM for a Stable Internet. In International Conference on Research in Networking ’07. Springer.&lt;br/&gt;[152] Runyuan Sun, Bo Yang, Lizhi Peng, Zhenxiang Chen, Lei Zhang, and Shan Jing. 2010. Traffic Classification Using Probabilistic Neural Networks. In IEEE ICNC ’10.&lt;br/&gt;[153] Tuan A Tang, Lotfi Mhamdi, Des McLernon, Syed Ali Raza Zaidi, and Mounir Ghogho. 2016. Deep Learning Approach for Network Intrusion Detection in Software Defined Networking. In IEEE WINCOM ’16.&lt;br/&gt;[154] Mahbod Tavallaee, Ebrahim Bagheri, Wei Lu, and Ali A Ghorbani. 2009. A Detailed Analysis of the KDD CUP 99 Data Set. In IEEE CISDA ’09.&lt;br/&gt;[155] Simon Thompson. 2011. Haskell: The Craft of Functional Programming. Vol. 2. Addison-Wesley.&lt;br/&gt;[156] Emanuel Todorov, Tom Erez, and Yuval Tassa. 2012. Mujoco: A Physics Engine for Model-Based Control. In IEEE IROS ’12.&lt;br/&gt;[157] C Van Rijsbergen. 1979. Information Retrieval: Theory and Practice. In Proceedings of the Joint IBM/University of Newcastle upon Tyne Seminar on Data Base Systems ’79.&lt;br/&gt;[158] Erwei Wang, James J Davis, Ruizhe Zhao, Ho-Cheung Ng, Xinyu Niu, Wayne Luk, Peter YK Cheung, and George A Constantinides. 2019. Deep Neural Network Approximation for Custom Hardware: Where We’ve Been, Where We’re Going. ACM Computing Surveys (CSUR) ’19 52, 2 (2019), 1–39. https://doi.org/10.1145/3309551&lt;br/&gt;[159] Haining Wang, Danlu Zhang, and Kang G Shin. 2002. Detecting SYN Flooding Attacks. In Twenty-First Annual Joint Conference of the IEEE Computer and Communications Societies ’02, Vol. 3. 1530–1539.&lt;br/&gt;[160] Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, and Kailash Gopalakrishnan. 2018. Training Deep Neural Networks with 8-bit Floating Point Numbers. In NeurIPS ’18.&lt;br/&gt;[161] Shuo Wang, Zhe Li, Caiwen Ding, Bo Yuan, Qinru Qiu, Yanzhi Wang, and Yun Liang. 2018. C-LSTM: Enabling Efficient LSTM using Structured Compression Techniques on FPGAs. In ACM/SIGDA FPGA ’18. https://doi.org/10.1145/3174243.3174253&lt;br/&gt;[162] Keith Winstein and Hari Balakrishnan. 2013. TCP Ex Machina: ComputerGenerated Congestion Control. In ACM SIGCOMM ’13. https://doi.org/10.1145/2534169.2486020&lt;br/&gt;[163] Shihan Xiao, Haiyan Mao, Bo Wu, Wenjie Liu, and Fenglin Li. 2020. Neural Packet Routing. In ACM NetAI ’20. https://doi.org/10.1145/3405671.3405813&lt;br/&gt;[164] Xilinx. [n.d.]. Alveo U250 Data Center Accelerator Card. https://www.xilinx.com/products/boards-and-kits/alveo/u250.html. Accessed on 08/12/2021.&lt;br/&gt;[165] Xilinx. [n.d.]. Xilinx: AXI Reference Guide. https://www.xilinx.com/support/-documentation/ip_documentation/ug761_axi_reference_guide.pdf. Accessed on 08/12/2021.&lt;br/&gt;[166] Xilinx. [n.d.]. Xilinx OpenNIC Shell. https://github.com/Xilinx/open-nic-shell. Accessed on 09/30/2021.&lt;br/&gt;[167] Xilinx. [n.d.]. Xilinx: UltraScale+ Integrated 100G Ethernet Subsystem. https://www.xilinx.com/products/intellectual-property/cmac_usplus.html. Accessed on 08/12/2021.&lt;br/&gt;[168] Zhaoqi Xiong and Noa Zilberman. 2019. Do Switches Dream of Machine Learning? Toward In-Network Classification. In ACM HotNets ’19. https://doi.org/10.1145/3365609.3365864&lt;br/&gt;[169] Francis Y Yan, Jestin Ma, Greg D Hill, Deepti Raghavan, Riad S Wahby, Philip Levis, and Keith Winstein. 2018. Pantheon: The Training Ground for Internet Congestion-Control Research. In USENIX ATC ’18.&lt;br/&gt;[170] Liangcheng Yu, John Sonchack, and Vincent Liu. 2020. Mantis: Reactive Programmable Switches. In ACM SIGCOMM ’20. https://doi.org/10.1145/3387514.3405870&lt;br/&gt;[171] Yasir Zaki, Thomas Pötsch, Jay Chen, Lakshminarayanan Subramanian, and Carmelita Görg. 2015. Adaptive Congestion Control for Unpredictable Cellular Networks. In ACM SIGCOMM ’15. https://doi.org/10.1145/2785956.2787498&lt;br/&gt;[172] Sebastian Zander, Thuy Nguyen, and Grenville Armitage. 2005. Automated Traffic Classification and Application Identification Using Machine Learning. In IEEE LCN ’05.&lt;br/&gt;[173] Jun Zhang, Chao Chen, Yang Xiang, Wanlei Zhou, and Yong Xiang. 2012. Internet Traffic Classification by Aggregating Correlated Naïve Bayes Predictions. IEEE Transactions on Information Forensics and Security ’12 8, 1 (2012), 5–15. https://doi.org/10.1109/TIFS.2012.2223675&lt;br/&gt;[174] Jun Zhang, Xiao Chen, Yang Xiang, Wanlei Zhou, and Jie Wu. 2014. Robust Network Traffic Classification. IEEE/ACM Transactions on Networking ’14 23, 4 (2014), 1257–1270. https://doi.org/10.1109/TNET.2014.2320577&lt;br/&gt;[175] Menghao Zhang, Guanyu Li, Shicheng Wang, Chang Liu, Ang Chen, Hongxin Hu, Guofei Gu, Qianqian Li, Mingwei Xu, and Jianping Wu. 2020. Poseidon: Mitigating Volumetric DDoS Attacks with Programmable Switches. In NDSS ’20. https://doi.org/10.14722/ndss.2020.24007&lt;br/&gt;[176] Yaqi Zhang, Alexander Rucker, Matthew Vilim, Raghu Prabhakar, William Hwang, and Kunle Olukotun. 2019. Scalable Interconnects for Reconfigurable Spatial Architectures. In ACM/IEEE ISCA ’19. https://doi.org/10.1145/3307650.3322249&lt;br/&gt;[177] Yaqi Zhang, Nathan Zhang, Tian Zhao, Matt Vilim, Muhammad Shahbaz, and Kunle Olukotun. 2021. SARA: Scaling a Reconfigurable Dataflow Accelerator. In ACM/IEEE ISCA ’21. https://doi.org/10.1109/ISCA52012.2021.00085&lt;br/&gt;[178] Hongtao Zhong, Kevin Fan, Scott Mahlke, and Michael Schlansker. 2005. A Distributed Control Path Architecture for VLIW Processors. In IEEE PACT ’05.&lt;br/&gt;[179] Chuan Zhou, Dongjie Di, Qingwei Chen, and Jian Guo. 2009. An Adaptive AQM Algorithm Based on Neuron Reinforcement Learning. In IEEE ICCA ’09.\&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。&lt;br/&gt;微信公众号：DeepNoMind&lt;/em&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;Taurus: A Data Plane Architecture for Per-Packet ML: &lt;em&gt;https://arxiv.org/ftp/arxiv/papers/2002/2002.08987.pdf&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;EdgeCore Wedge 100BF-32X Switch: &lt;em&gt;https://www.edge-core.com/productsInfo.php?cls=1&amp;amp;cls2=5&amp;amp;cls3=181&amp;amp;id=335&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;Xilinx Alveo U250 FPGA board: &lt;em&gt;https://www.xilinx.com/products/boards-and-kits/alveo.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;Intel P4 Studio: &lt;em&gt;https://www.intel.com/content/www/us/en/products/network-io/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[5]&lt;/span&gt;&lt;p&gt;Xilinx Vivado Design Tool: &lt;em&gt;https://www.xilinx.com/support/university/vivado.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[6]&lt;/span&gt;&lt;p&gt;Xilinx OpenNIC Shell: &lt;em&gt;https://github.com/Xilinx/open-nic-shell&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[7]&lt;/span&gt;&lt;p&gt;Spatial DSL: &lt;em&gt;https://github.com/stanford-ppl/spatial&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[8]&lt;/span&gt;&lt;p&gt;ONF Stratum OS: &lt;em&gt;https://opennetworking.org/stratum/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[9]&lt;/span&gt;&lt;p&gt;MoonGen Traffic Generator: &lt;em&gt;https://github.com/emmericp/MoonGen&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;- END -&lt;/span&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>