<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>907a3f66a3c20f8785905e5fb6cb7555</guid>
<title>听说&quot;羊了个羊”很火，带大家写个代码快速加入羊群~</title>
<link>https://toutiao.io/k/udifd0q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;因为公众号的交流群里其实已经有人给了答案，只需要请求加入羊群的接口就行了，所以这里我偷个懒，直接抄答案了：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;php&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;response = requests.get(f&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;https://cat-match.easygame2021.com/sheep/v1/game/game_over?rank_score=1&amp;amp;rank_state=1&amp;amp;rank_time={random.randint(1, 3600)}&amp;amp;rank_role=1&amp;amp;skin=1&#x27;&lt;/span&gt;, headers=&lt;span class=&quot;code-snippet__keyword&quot;&gt;self&lt;/span&gt;.headers, timeout=&lt;span class=&quot;code-snippet__number&quot;&gt;10&lt;/span&gt;, verify=&lt;span class=&quot;code-snippet__keyword&quot;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; response.json()[&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;err_code&#x27;&lt;/span&gt;] == &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;self&lt;/span&gt;.logging(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;闯关羊群成功&#x27;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;self&lt;/span&gt;.logging(f&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;闯关羊群失败, 返回内容为:\n{response.json()}&#x27;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;然后请求的headers里需要加入每个用户特有的t值：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;headers = {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;Host&#x27;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;cat-match.easygame2021.com&#x27;&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;User-Agent&#x27;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;Mozilla/5.0 (iPhone; CPU iPhone OS 15_6_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 MicroMessenger/8.0.28(0x18001c27) NetType/WIFI Language/zh_CN&#x27;&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;t&#x27;&lt;/span&gt;: user_t,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;Referer&#x27;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;https://servicewechat.com/wx141bfb9b73c970a9/17/page-frame.html&#x27;&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;Accept-Encoding&#x27;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;gzip,compress,br,deflate&#x27;&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;Connection&#x27;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;close&#x27;&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;随便找个抓包工具抓包就行了，比如我水果机上的抓包结果如下(同时打开小程序和抓包工具，随便玩下就能抓到，域名是cat-match.easygame2021.com)：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2524590163934426&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zZTbkic2pYRo3qa21JrUYC1NSGcefA38MJrFeQ9vibII0l83WicQuLnhVAwJXHfDWAGSBxqVxbP3TibLahkd0CZpFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;305&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把t值copy下来放到请求头对应的位置就行了，完整代码已经整合在pytools里了，你只需要pip安装一下：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attribute&quot;&gt;pip&lt;/span&gt; install pikachupytools&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;然后写个简单的调用代码就ok啦，例如：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; pytools &lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; pytools&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;tool_client = pytools.pytools()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;tool_client.execute(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;sheepsheep&#x27;&lt;/span&gt;, {&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;user_t&#x27;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;xxx&#x27;&lt;/span&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;效果如下：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.16445623342175067&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zZTbkic2pYRo3qa21JrUYC1NSGcefA38MI9KqkHRbAkFibM1fPmAHWfyOTSnjluF7OTYvm4TsdfoAZujic8DB7EvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;754&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.8592233009708738&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zZTbkic2pYRo3qa21JrUYC1NSGcefA38MeFQEa1WGZicz6xgicwlaWmth3D5oFy87boPsmzgibXRiadGD7UibHwHqDWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;206&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ok，大功告成啦，完整源代码详见相关文件~&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>72857236e45129e064cc39abe1ed6210</guid>
<title>PostgreSQL 越来越流行</title>
<link>https://toutiao.io/k/ojs1csb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有 15 年以上经验的 PostgreSQL 用户中，有 44% 至少为 PostgreSQL 做出过一次贡献。“事实上，无论他们的经验如何，所有用户都为 PostgreSQL 社区做出了贡献。”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;55% 的受访者表示如今 PostgreSQL 的使用量比一年前更多。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;超过 3/4 的受访者表示将 PostgreSQL 用于个人项目，95% 的受访者在工作中使用 PostgreSQL ，74% 的受访者将 PostgreSQL 用于个人和专业项目。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大多数受访者 (76.2%) 表示技术文档是他们学习 PostgreSQL 的首选方式，其次是长篇博文 (51.5%) 和短篇博文 (43.3%)。拥有少于 5 年 PostgreSQL 经验的受访者更喜欢视频而不是博客文章。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在社区互动上，虽然有一些受访者提到使用 PostgreSQL 邮件列表作为与核心团队和整个项目交互的主要方式存在困难，但超过 20% 的受访者表示邮件列表是他们与社区保持联系的方式之一。其他的一些参与渠道包括 Slack (10%)、Stack Overflow (8%)、博客 (8%)、Twitter (6%) 和 Reddit (6%)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;受访者还分享了他们最喜欢的一些 PostgreSQL 扩展。排名靠前的依次有：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PostGIS&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TimescaleDB&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;pg_stat_statements&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;pgcrypto&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;pg_trgm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Citus&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;uuid-ossp&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SQL、Python、Java、shell 脚本和 JavaScript / TypeScript 被列为访问 PostgreSQL 最常用的语言。相较 Java，具有 0-5 年经验的 PostgreSQL 用户更有可能使用 JavaScript 或 TypeScript；拥有 6 年以上经验的用户更有可能使用 shell 脚本来访问数据库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在使用工具连接 PostgreSQL 进行查询和管理任务的受访者中，psql (69.4%)、pgAdmin (35.3%) 和 DBeaver (26.2%) 是前三位的选择。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Grafana、pgAdmin 和 DBeaver 是最可能使用的可视化工具。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与 2019 年和 2021 年相比，表示会自行管理 PostgreSQL 数据库的受访者越来越少。似乎 PostgreSQL 用户开始越来越多地使用 DBaaS 供应商来部署 PostgreSQL。在将 PostgreSQL 部署为 Kubernetes 容器的人中，44% 使用 Helm，16% 使用 Crunchy Operator，7% 使用 Zalando Operator。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e111c9450707e5abce2e5b6116cb5345</guid>
<title>优雅的使用 Dockerfile 定制镜像，1.5W 字长文，值得收藏！</title>
<link>https://toutiao.io/k/ccgjv8r</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;您好，我是路人，更多优质文章见个人博客：http://itsoku.com&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，本文是对 Docker 自定义镜像的详细讲解，讲解了如何进行构建自己的 Docker 镜像以及 Dockerfile 的操作指令。希望对大家有所帮助~&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、使用 Dockerfile 定制镜像&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.1、Dockerfile 定制镜像&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 &lt;code&gt;Dockerfile&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Dockerfile&lt;/code&gt; 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以 &lt;code&gt;nginx&lt;/code&gt; 镜像为例，这次我们使用 &lt;code&gt;Dockerfile&lt;/code&gt; 来定制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在一个空白目录中，建立一个文本文件，并命名为 &lt;code&gt;Dockerfile&lt;/code&gt;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; mkdir mynginx&lt;/span&gt;&lt;br/&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; &lt;span&gt;cd&lt;/span&gt; mynginx&lt;/span&gt;&lt;br/&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; touch Dockerfile&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其内容为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; nginx&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; &lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&#x27;&amp;lt;h1&amp;gt;Hello, Docker!&amp;lt;/h1&amp;gt;&#x27;&lt;/span&gt; &amp;gt; /usr/share/nginx/html/index.html&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个 &lt;code&gt;Dockerfile&lt;/code&gt; 很简单，一共就两行。涉及到了两条指令，&lt;code&gt;FROM&lt;/code&gt; 和 &lt;code&gt;RUN&lt;/code&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2、FROM 指定基础镜像&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 &lt;code&gt;nginx&lt;/code&gt; 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 &lt;code&gt;FROM&lt;/code&gt; 就是指定&lt;strong&gt;基础镜像&lt;/strong&gt;，因此一个 &lt;code&gt;Dockerfile&lt;/code&gt; 中 &lt;code&gt;FROM&lt;/code&gt;是必备的指令，并且必须是第一条指令。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 &lt;code&gt;Docker Store&lt;/code&gt; 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 &lt;code&gt;nginx&lt;/code&gt;、&lt;code&gt;redis&lt;/code&gt;、&lt;code&gt;mongo&lt;/code&gt;、&lt;code&gt;mysql&lt;/code&gt;、&lt;code&gt;httpd&lt;/code&gt;、&lt;code&gt;php&lt;/code&gt;、&lt;code&gt;tomcat&lt;/code&gt; 等；也有一些方便开发、构建、运行各种语言应用的镜像，如&lt;code&gt;node&lt;/code&gt;、&lt;code&gt;openjdk&lt;/code&gt;、&lt;code&gt;python&lt;/code&gt;、&lt;code&gt;ruby&lt;/code&gt;、&lt;code&gt;golang&lt;/code&gt;等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如&lt;code&gt;ubuntu&lt;/code&gt;、&lt;code&gt;debian&lt;/code&gt;、&lt;code&gt;centos&lt;/code&gt;、&lt;code&gt;fedora&lt;/code&gt;、&lt;code&gt;alpine&lt;/code&gt; 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了选择现有镜像为基础镜像外，&lt;code&gt;Docker&lt;/code&gt; 还存在一个特殊的镜像，名为 &lt;code&gt;scratch&lt;/code&gt;。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; scratch&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果你以 &lt;code&gt;scratch&lt;/code&gt; 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如&lt;code&gt;swarm&lt;/code&gt;、&lt;code&gt;coreos/etcd&lt;/code&gt;。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 &lt;code&gt;FROM scratch&lt;/code&gt; 会让镜像体积更加小巧。使用 Go 语言开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 &lt;code&gt;Go&lt;/code&gt; 是特别适合容器微服务架构的语言的原因之一。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.3、RUN 执行命令&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;RUN&lt;/code&gt; 指令是用来执行命令行命令的。由于命令行的强大能力，&lt;code&gt;RUN&lt;/code&gt; 指令在定制镜像时是最常用的指令之一。其格式有两种：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;em&gt;shell&lt;/em&gt; 格式：&lt;code&gt;RUN &amp;lt;命令&amp;gt;&lt;/code&gt;，就像直接在命令行中输入的命令一样。刚才写的 &lt;code&gt;Dockerfile&lt;/code&gt; 中的 &lt;code&gt;RUN&lt;/code&gt; 指令就是这种格式。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; &lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&#x27;&amp;lt;h1&amp;gt;Hello, Docker!&amp;lt;/h1&amp;gt;&#x27;&lt;/span&gt; &amp;gt; /usr/share/nginx/html/index.html&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;em&gt;exec&lt;/em&gt; 格式：&lt;code&gt;RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]&lt;/code&gt;，这更像是函数调用中的格式。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然 &lt;code&gt;RUN&lt;/code&gt; 就像 &lt;code&gt;Shell&lt;/code&gt; 脚本一样可以执行命令，那么我们是否就可以像 &lt;code&gt;Shell&lt;/code&gt; 脚本一样把每个命令对应一个 &lt;code&gt;RUN&lt;/code&gt; 呢？比如这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; debian:jessie&lt;br/&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; apt-get update&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; apt-get install -y gcc libc6-dev make&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; wget -O redis.tar.gz &lt;span&gt;&quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; mkdir -p /usr/src/redis&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; make -C /usr/src/redis&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; make -C /usr/src/redis install&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前说过，&lt;code&gt;Dockerfile&lt;/code&gt; 中每一个指令都会建立一层，&lt;code&gt;RUN&lt;/code&gt; 也不例外。每一个 &lt;code&gt;RUN&lt;/code&gt; 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，&lt;code&gt;commit&lt;/code&gt; 这一层的修改，构成新的镜像。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。这是很多初学 &lt;code&gt;Docker&lt;/code&gt; 的人常犯的一个错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;code&gt;Union FS&lt;/code&gt; 是有最大层数限制的，比如 &lt;code&gt;AUFS&lt;/code&gt;，曾经是最大不能超过 42 层，现在是不能超过 127 层。&lt;/em&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的 &lt;code&gt;Dockerfile&lt;/code&gt; 正确的写法应该是这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; debian:jessie&lt;br/&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; buildDeps=&lt;span&gt;&#x27;gcc libc6-dev make&#x27;&lt;/span&gt; \&lt;br/&gt;    &amp;amp;&amp;amp; apt-get update \&lt;br/&gt;    &amp;amp;&amp;amp; apt-get install -y &lt;span&gt;$buildDeps&lt;/span&gt; \&lt;br/&gt;    &amp;amp;&amp;amp; wget -O redis.tar.gz &lt;span&gt;&quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;&lt;/span&gt; \&lt;br/&gt;    &amp;amp;&amp;amp; mkdir -p /usr/src/redis \&lt;br/&gt;    &amp;amp;&amp;amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \&lt;br/&gt;    &amp;amp;&amp;amp; make -C /usr/src/redis \&lt;br/&gt;    &amp;amp;&amp;amp; make -C /usr/src/redis install \&lt;br/&gt;    &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* \&lt;br/&gt;    &amp;amp;&amp;amp; rm redis.tar.gz \&lt;br/&gt;    &amp;amp;&amp;amp; rm -r /usr/src/redis \&lt;br/&gt;    &amp;amp;&amp;amp; apt-get purge -y --auto-remove &lt;span&gt;$buildDeps&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，之前所有的命令只有一个目的，就是编译、安装 &lt;code&gt;Redis&lt;/code&gt; 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 &lt;code&gt;RUN&lt;/code&gt; 对一一对应不同的命令，而是仅仅使用一个 &lt;code&gt;RUN&lt;/code&gt; 指令，并使用 &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 &lt;code&gt;Dockerfile&lt;/code&gt; 的时候，要经常提醒自己，这并不是在写 &lt;code&gt;Shell&lt;/code&gt; 脚本，而是在定义每一层该如何构建。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并且，这里为了格式化还进行了换行。&lt;code&gt;Dockerfile&lt;/code&gt; 支持 Shell 类的行尾添加 &lt;code&gt;\&lt;/code&gt; 的命令换行方式，以及行首 &lt;code&gt;#&lt;/code&gt; 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 &lt;code&gt;apt&lt;/code&gt; 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多人初学 &lt;code&gt;Docker&lt;/code&gt; 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.4、构建镜像&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再回到之前定制的 &lt;code&gt;Nginx&lt;/code&gt; 镜像的 &lt;code&gt;Dockerfile&lt;/code&gt; 来。现在我们明白了这个 &lt;code&gt;Dockerfile&lt;/code&gt; 的内容，那么让我们来构建这个镜像吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 &lt;code&gt;Dockerfile&lt;/code&gt; 文件所在目录执行：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker build -t nginx:v3 .&lt;/span&gt;&lt;br/&gt;Sending build context to Docker daemon 2.048 kB&lt;br/&gt;Step 1 : FROM nginx&lt;br/&gt;&lt;span&gt; ---&amp;gt;&lt;/span&gt;&lt;span&gt; e43d811ce2f4&lt;/span&gt;&lt;br/&gt;Step 2 : RUN echo &#x27;&amp;lt;h1&amp;gt;Hello, Docker!&amp;lt;/h1&amp;gt;&#x27; &amp;gt; /usr/share/nginx/html/index.html&lt;br/&gt;&lt;span&gt; ---&amp;gt;&lt;/span&gt;&lt;span&gt; Running &lt;span&gt;in&lt;/span&gt; 9cdc27646c7b&lt;/span&gt;&lt;br/&gt;&lt;span&gt; ---&amp;gt;&lt;/span&gt;&lt;span&gt; 44aa4490ce2c&lt;/span&gt;&lt;br/&gt;Removing intermediate container 9cdc27646c7b&lt;br/&gt;Successfully built 44aa4490ce2c&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 &lt;code&gt;Step 2&lt;/code&gt;中，如同我们之前所说的那样，&lt;code&gt;RUN&lt;/code&gt; 指令启动了一个容器 &lt;code&gt;9cdc27646c7b&lt;/code&gt;，执行了所要求的命令，并最后提交了这一层 &lt;code&gt;44aa4490ce2c&lt;/code&gt;，随后删除了所用到的这个容器 &lt;code&gt;9cdc27646c7b&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们使用了 &lt;code&gt;docker build&lt;/code&gt; 命令进行镜像构建。其格式为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;docker build [选项] &amp;lt;上下文路径/URL/-&amp;gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这里我们指定了最终镜像的名称 &lt;code&gt;-t nginx:v3&lt;/code&gt;，构建成功后，我们可以像之前运行 &lt;code&gt;nginx:v2&lt;/code&gt; 那样来运行这个镜像，其结果会和 &lt;code&gt;nginx:v2&lt;/code&gt;一样。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.5、镜像构建上下文（Context）&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果注意，会看到 &lt;code&gt;docker build&lt;/code&gt; 命令最后有一个 &lt;code&gt;.&lt;/code&gt;，&lt;code&gt;.&lt;/code&gt; 表示当前目录，而 &lt;code&gt;Dockerfile&lt;/code&gt; 就在当前目录，因此不少初学者以为这个路径是在指定 &lt;code&gt;Dockerfile&lt;/code&gt; 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定&lt;strong&gt;上下文路径&lt;/strong&gt;。那么什么是上下文呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们要理解 &lt;code&gt;docker build&lt;/code&gt; 的工作原理。&lt;code&gt;Docker&lt;/code&gt; 在运行时分为 &lt;code&gt;Docker&lt;/code&gt; 引擎（也就是服务端守护进程）和客户端工具。&lt;code&gt;Docker&lt;/code&gt; 的引擎提供了一组 REST API，被称为 &lt;code&gt;Docker Remote API&lt;/code&gt;，而如 &lt;code&gt;docker&lt;/code&gt; 命令这样的客户端工具，则是通过这组 &lt;code&gt;API&lt;/code&gt; 与 &lt;code&gt;Docker&lt;/code&gt; 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 &lt;code&gt;docker&lt;/code&gt; 功能，但实际上，一切都是使用的远程调用形式在服务端（&lt;code&gt;Docker&lt;/code&gt; 引擎）完成。也因为这种 &lt;code&gt;C/S&lt;/code&gt; 设计，让我们操作远程服务器的 &lt;code&gt;Docker&lt;/code&gt; 引擎变得轻而易举。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当我们进行镜像构建的时候，并非所有定制都会通过 &lt;code&gt;RUN&lt;/code&gt; 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 &lt;code&gt;COPY&lt;/code&gt; 指令、&lt;code&gt;ADD&lt;/code&gt; 指令等。而 &lt;code&gt;docker build&lt;/code&gt; 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 &lt;code&gt;Docker&lt;/code&gt; 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，&lt;code&gt;docker build&lt;/code&gt; 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 &lt;code&gt;Docker&lt;/code&gt; 引擎。这样 &lt;code&gt;Docker&lt;/code&gt; 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果在 &lt;code&gt;Dockerfile&lt;/code&gt; 中这么写：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; ./package.json /app/&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这并不是要复制执行 &lt;code&gt;docker build&lt;/code&gt; 命令所在的目录下的 &lt;code&gt;package.json&lt;/code&gt;，也不是复制 &lt;code&gt;Dockerfile&lt;/code&gt; 所在目录下的 &lt;code&gt;package.json&lt;/code&gt;，而是复制 &lt;strong&gt;上下文（context）&lt;/strong&gt; 目录下的 &lt;code&gt;package.json&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，&lt;code&gt;COPY&lt;/code&gt; 这类指令中的源文件的路径都是&lt;em&gt;相对路径&lt;/em&gt;。这也是初学者经常会问的为什么 &lt;code&gt;COPY ../package.json /app&lt;/code&gt; 或者 &lt;code&gt;COPY /opt/xxxx /app&lt;/code&gt; 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在就可以理解刚才的命令 &lt;code&gt;docker build -t nginx:v3 .&lt;/code&gt; 中的这个 &lt;code&gt;.&lt;/code&gt;，实际上是在指定上下文的目录，&lt;code&gt;docker build&lt;/code&gt; 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果观察 &lt;code&gt;docker build&lt;/code&gt; 输出，我们其实已经看到了这个发送上下文的过程：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker build -t nginx:v3 .&lt;/span&gt;&lt;br/&gt;Sending build context to Docker daemon 2.048 kB&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 &lt;code&gt;COPY /opt/xxxx /app&lt;/code&gt; 不工作后，于是干脆将 &lt;code&gt;Dockerfile&lt;/code&gt; 放到了硬盘根目录去构建，结果发现 &lt;code&gt;docker build&lt;/code&gt; 执行后，在发送一个几十 &lt;code&gt;GB&lt;/code&gt; 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 &lt;code&gt;docker build&lt;/code&gt; 打包整个硬盘，这显然是使用错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说，应该会将 &lt;code&gt;Dockerfile&lt;/code&gt; 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 &lt;code&gt;.gitignore&lt;/code&gt; 一样的语法写一个 &lt;code&gt;.dockerignore&lt;/code&gt;，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么为什么会有人误以为 &lt;code&gt;.&lt;/code&gt; 是指定 &lt;code&gt;Dockerfile&lt;/code&gt; 所在目录呢？这是因为在默认情况下，如果不额外指定 &lt;code&gt;Dockerfile&lt;/code&gt; 的话，会将上下文目录下的名为 &lt;code&gt;Dockerfile&lt;/code&gt; 的文件作为 Dockerfile。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这只是默认行为，实际上 &lt;code&gt;Dockerfile&lt;/code&gt; 的文件名并不要求必须为 &lt;code&gt;Dockerfile&lt;/code&gt;，而且并不要求必须位于上下文目录中，比如可以用 &lt;code&gt;-f ../Dockerfile.php&lt;/code&gt; 参数指定某个文件作为 &lt;code&gt;Dockerfile&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，一般大家习惯性的会使用默认的文件名 &lt;code&gt;Dockerfile&lt;/code&gt;，以及会将其置于镜像构建上下文目录中。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.6、其他 docker build 的用法&lt;/span&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1.6.1、直接用 Git repo 进行构建&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;docker build&lt;/code&gt; 还支持从 &lt;code&gt;URL&lt;/code&gt; 构建，比如可以直接从 &lt;code&gt;Git repo&lt;/code&gt; 中构建：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker build https://github.com/twang2218/gitlab-ce-zh.git&lt;span&gt;#:8.14&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;docker build https://github.com/twang2218/gitlab-ce-zh.git\#:8.14&lt;br/&gt;Sending build context to Docker daemon 2.048 kB&lt;br/&gt;Step 1 : FROM gitlab/gitlab-ce:8.14.0-ce.0&lt;br/&gt;8.14.0-ce.0: Pulling from gitlab/gitlab-ce&lt;br/&gt;aed15891ba52: Already exists&lt;br/&gt;773ae8583d14: Already exists&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这行命令指定了构建所需的 &lt;code&gt;Git repo&lt;/code&gt;，并且指定默认的 &lt;code&gt;master&lt;/code&gt; 分支，构建目录为 &lt;code&gt;/8.14/&lt;/code&gt;，然后 Docker 就会自己去 &lt;code&gt;git clone&lt;/code&gt; 这个项目、切换到指定分支、并进入到指定目录后开始构建。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1.6.2、用给定的 tar 压缩包构建&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker build http://server/context.tar.gz&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果所给出的 URL 不是个 &lt;code&gt;Git repo&lt;/code&gt;，而是个 &lt;code&gt;tar&lt;/code&gt; 压缩包，那么 &lt;code&gt;Docker&lt;/code&gt; 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1.6.3、从标准输入中读取 Dockerfile 进行构建&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;docker build - &amp;lt; Dockerfile&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cat Dockerfile | docker build -&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果标准输入传入的是文本文件，则将其视为 &lt;code&gt;Dockerfile&lt;/code&gt;，并开始构建。这种形式由于直接从标准输入中读取 &lt;code&gt;Dockerfile&lt;/code&gt; 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件 &lt;code&gt;COPY&lt;/code&gt; 进镜像之类的事情。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1.6.4、从标准输入中读取上下文压缩包进行构建&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker build - &amp;lt; context.tar.gz&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果发现标准输入的文件格式是 &lt;code&gt;gzip&lt;/code&gt;、&lt;code&gt;bzip2&lt;/code&gt; 以及 &lt;code&gt;xz&lt;/code&gt; 的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、Dockerfile 指令&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们已经介绍了 &lt;code&gt;FROM&lt;/code&gt;，&lt;code&gt;RUN&lt;/code&gt;，还提及了 &lt;code&gt;COPY&lt;/code&gt;, &lt;code&gt;ADD&lt;/code&gt;，其实 &lt;code&gt;Dockerfile&lt;/code&gt; 功能很强大，它提供了十多个指令。下面我们继续讲解其他的指令。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1、COPY&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;格式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;COPY &amp;lt;源路径&amp;gt;... &amp;lt;目标路径&amp;gt;&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;COPY [&quot;&amp;lt;源路径1&amp;gt;&quot;,... &quot;&amp;lt;目标路径&amp;gt;&quot;]&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和 &lt;code&gt;RUN&lt;/code&gt; 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;COPY&lt;/code&gt; 指令将从构建上下文目录中 &lt;code&gt;&amp;lt;源路径&amp;gt;&lt;/code&gt; 的文件/目录复制到新的一层的镜像内的 &lt;code&gt;&amp;lt;目标路径&amp;gt;&lt;/code&gt; 位置。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; package.json /usr/src/app/&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&amp;lt;源路径&amp;gt;&lt;/code&gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 &lt;code&gt;Go&lt;/code&gt; 的 &lt;code&gt;filepath.Match&lt;/code&gt; 规则，如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; hom* /mydir/&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; hom?.txt /mydir/&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&amp;lt;目标路径&amp;gt;&lt;/code&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 &lt;code&gt;WORKDIR&lt;/code&gt; 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，还需要注意一点，使用 &lt;code&gt;COPY&lt;/code&gt; 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 &lt;code&gt;Git&lt;/code&gt; 进行管理的时候。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2、ADD&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ADD&lt;/code&gt; 指令和 &lt;code&gt;COPY&lt;/code&gt; 的格式和性质基本一致。但是在 &lt;code&gt;COPY&lt;/code&gt; 基础上增加了一些功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 &lt;code&gt;&amp;lt;源路径&amp;gt;&lt;/code&gt; 可以是一个 &lt;code&gt;URL&lt;/code&gt;，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;code&gt;&amp;lt;目标路径&amp;gt;&lt;/code&gt; 去。下载后的文件权限自动设置为 &lt;code&gt;600&lt;/code&gt;，如果这并不是想要的权限，那么还需要增加额外的一层 &lt;code&gt;RUN&lt;/code&gt; 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 &lt;code&gt;RUN&lt;/code&gt; 指令进行解压缩。所以不如直接使用 &lt;code&gt;RUN&lt;/code&gt; 指令，然后使用 &lt;code&gt;wget&lt;/code&gt; 或者 &lt;code&gt;curl&lt;/code&gt; 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 &lt;code&gt;&amp;lt;源路径&amp;gt;&lt;/code&gt; 为一个 &lt;code&gt;tar&lt;/code&gt; 压缩文件的话，压缩格式为 &lt;code&gt;gzip&lt;/code&gt;, &lt;code&gt;bzip2&lt;/code&gt;以及 &lt;code&gt;xz&lt;/code&gt; 的情况下，&lt;code&gt;ADD&lt;/code&gt; 指令将会自动解压缩这个压缩文件到 &lt;code&gt;&amp;lt;目标路径&amp;gt;&lt;/code&gt; 去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 &lt;code&gt;ubuntu&lt;/code&gt;中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;FROM scratch&lt;br/&gt;ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 &lt;code&gt;ADD&lt;/code&gt; 命令了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 &lt;code&gt;Docker&lt;/code&gt; 官方的 &lt;code&gt;Dockerfile 最佳实践文档&lt;/code&gt; 中要求，尽可能的使用 &lt;code&gt;COPY&lt;/code&gt;，因为 &lt;code&gt;COPY&lt;/code&gt; 的语义很明确，就是复制文件而已，而 &lt;code&gt;ADD&lt;/code&gt; 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 &lt;code&gt;ADD&lt;/code&gt; 的场合，就是所提及的需要自动解压缩的场合。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外需要注意的是，&lt;code&gt;ADD&lt;/code&gt; 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此在 &lt;code&gt;COPY&lt;/code&gt; 和 &lt;code&gt;ADD&lt;/code&gt; 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 &lt;code&gt;COPY&lt;/code&gt; 指令，仅在需要自动解压缩的场合使用 &lt;code&gt;ADD&lt;/code&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.3、CMD&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;CMD&lt;/code&gt; 指令的格式和 &lt;code&gt;RUN&lt;/code&gt; 相似，也是两种格式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;shell&lt;/code&gt; 格式：&lt;code&gt;CMD &amp;lt;命令&amp;gt;&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;exec&lt;/code&gt; 格式：&lt;code&gt;CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...]&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参数列表格式：&lt;code&gt;CMD [&quot;参数1&quot;, &quot;参数2&quot;...]&lt;/code&gt;。在指定了 &lt;code&gt;ENTRYPOINT&lt;/code&gt;指令后，用 &lt;code&gt;CMD&lt;/code&gt; 指定具体的参数。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。&lt;code&gt;CMD&lt;/code&gt; 指令就是用于指定默认的容器主进程的启动命令的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，&lt;code&gt;ubuntu&lt;/code&gt; 镜像默认的 &lt;code&gt;CMD&lt;/code&gt; 是 &lt;code&gt;/bin/bash&lt;/code&gt;，如果我们直接 &lt;code&gt;docker run -it ubuntu&lt;/code&gt; 的话，会直接进入 &lt;code&gt;bash&lt;/code&gt;。我们也可以在运行时指定运行别的命令，如 &lt;code&gt;docker run -it ubuntu cat /etc/os-release&lt;/code&gt;。这就是用 &lt;code&gt;cat /etc/os-release&lt;/code&gt; 命令替换了默认的 &lt;code&gt;/bin/bash&lt;/code&gt; 命令了，输出了系统版本信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在指令格式上，一般推荐使用 &lt;code&gt;exec&lt;/code&gt; 格式，这类格式在解析时会被解析为 &lt;code&gt;JSON&lt;/code&gt; 数组，因此一定要使用双引号 &lt;code&gt;&quot;&lt;/code&gt;，而不要使用单引号。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果使用 &lt;code&gt;shell&lt;/code&gt; 格式的话，实际的命令会被包装为 &lt;code&gt;sh -c&lt;/code&gt; 的参数的形式进行执行。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;CMD&lt;/span&gt;&lt;span&gt; &lt;span&gt;echo&lt;/span&gt; &lt;span&gt;$HOME&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在实际执行中，会将其变更为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;CMD&lt;/span&gt;&lt;span&gt; [ &lt;span&gt;&quot;sh&quot;&lt;/span&gt;, &lt;span&gt;&quot;-c&quot;&lt;/span&gt;, &lt;span&gt;&quot;echo &lt;span&gt;$HOME&lt;/span&gt;&quot;&lt;/span&gt; ]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提到 &lt;code&gt;CMD&lt;/code&gt; 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 &lt;code&gt;upstart/systemd&lt;/code&gt; 去启动后台服务，容器内没有后台服务的概念。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一些初学者将 &lt;code&gt;CMD&lt;/code&gt; 写为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;CMD&lt;/span&gt;&lt;span&gt; service nginx start&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后发现容器执行后就立即退出了。甚至在容器内去使用 &lt;code&gt;systemctl&lt;/code&gt; 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而使用 &lt;code&gt;service nginx start&lt;/code&gt; 命令，则是希望 upstart 来以后台守护进程形式启动 &lt;code&gt;nginx&lt;/code&gt; 服务。而刚才说了 &lt;code&gt;CMD service nginx start&lt;/code&gt; 会被理解为 &lt;code&gt;CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]&lt;/code&gt;，因此主进程实际上是 &lt;code&gt;sh&lt;/code&gt;。那么当 &lt;code&gt;service nginx start&lt;/code&gt; 命令结束后，&lt;code&gt;sh&lt;/code&gt; 也就结束了，&lt;code&gt;sh&lt;/code&gt; 作为主进程退出了，自然就会令容器退出。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正确的做法是直接执行 &lt;code&gt;nginx&lt;/code&gt; 可执行文件，并且要求以前台形式运行。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.4、ENTRYPOINT&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ENTRYPOINT&lt;/code&gt; 的格式和 &lt;code&gt;RUN&lt;/code&gt; 指令格式一样，分为 &lt;code&gt;exec&lt;/code&gt; 格式和 &lt;code&gt;shell&lt;/code&gt;格式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ENTRYPOINT&lt;/code&gt; 的目的和 &lt;code&gt;CMD&lt;/code&gt; 一样，都是在指定容器启动程序及参数。&lt;code&gt;ENTRYPOINT&lt;/code&gt; 在运行时也可以替代，不过比 &lt;code&gt;CMD&lt;/code&gt; 要略显繁琐，需要通过 &lt;code&gt;docker run&lt;/code&gt; 的参数 &lt;code&gt;--entrypoint&lt;/code&gt; 来指定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当指定了 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 后，&lt;code&gt;CMD&lt;/code&gt; 的含义就发生了改变，不再是直接的运行其命令，而是将 &lt;code&gt;CMD&lt;/code&gt; 的内容作为参数传给 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 指令，换句话说实际执行时，将变为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&amp;lt;ENTRYPOINT&amp;gt; &quot;&amp;lt;CMD&amp;gt;&quot;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么有了 &lt;code&gt;CMD&lt;/code&gt; 后，为什么还要有 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 呢？这种 &lt;code&gt;&amp;lt;ENTRYPOINT&amp;gt; &quot;&amp;lt;CMD&amp;gt;&quot;&lt;/code&gt; 有什么好处么？让我们来看几个场景。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2.4.1、场景一：让镜像变成像命令一样使用&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设我们需要一个得知自己当前公网 &lt;code&gt;IP&lt;/code&gt; 的镜像，那么可以先用 &lt;code&gt;CMD&lt;/code&gt; 来实现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; ubuntu:&lt;span&gt;16.04&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; apt-get update \&lt;br/&gt;    &amp;amp;&amp;amp; apt-get install -y curl \&lt;br/&gt;    &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*&lt;/span&gt;&lt;br/&gt;&lt;span&gt;CMD&lt;/span&gt;&lt;span&gt; [ &lt;span&gt;&quot;curl&quot;&lt;/span&gt;, &lt;span&gt;&quot;-s&quot;&lt;/span&gt;, &lt;span&gt;&quot;http://ip.cn&quot;&lt;/span&gt; ]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假如我们使用 &lt;code&gt;docker build -t myip .&lt;/code&gt; 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker run myip&lt;/span&gt;&lt;br/&gt;当前 IP：160.155.224.xx 来自：XX市 联通&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 &lt;code&gt;CMD&lt;/code&gt; 中可以看到实质的命令是 &lt;code&gt;curl&lt;/code&gt;，那么如果我们希望显示 HTTP 头信息，就需要加上 &lt;code&gt;-i&lt;/code&gt; 参数。那么我们可以直接加 &lt;code&gt;-i&lt;/code&gt; 参数给 &lt;code&gt;docker run myip&lt;/code&gt; 么？&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker run myip -i&lt;/span&gt;&lt;br/&gt;docker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \&quot;exec: \\\&quot;-i\\\&quot;: executable file not found in $PATH\&quot;\n&quot;.&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看到可执行文件找不到的报错，&lt;code&gt;executable file not found&lt;/code&gt;。之前我们说过，跟在镜像名后面的是 &lt;code&gt;command&lt;/code&gt;，运行时会替换 &lt;code&gt;CMD&lt;/code&gt; 的默认值。因此这里的 &lt;code&gt;-i&lt;/code&gt; 替换了原来的 &lt;code&gt;CMD&lt;/code&gt;，而不是添加在原来的 &lt;code&gt;curl -s http://ip.cn&lt;/code&gt; 后面。而 &lt;code&gt;-i&lt;/code&gt; 根本不是命令，所以自然找不到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么如果我们希望加入 &lt;code&gt;-i&lt;/code&gt; 这参数，我们就必须重新完整的输入这个命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker run myip curl -s http://ip.cn -i&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这显然不是很好的解决方案，而使用 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 就可以解决这个问题。现在我们重新用 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 来实现这个镜像：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; ubuntu:&lt;span&gt;16.04&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; apt-get update \&lt;br/&gt;    &amp;amp;&amp;amp; apt-get install -y curl \&lt;br/&gt;    &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ENTRYPOINT&lt;/span&gt;&lt;span&gt; [ &lt;span&gt;&quot;curl&quot;&lt;/span&gt;, &lt;span&gt;&quot;-s&quot;&lt;/span&gt;, &lt;span&gt;&quot;http://ip.cn&quot;&lt;/span&gt; ]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这次我们再来尝试直接使用 &lt;code&gt;docker run myip -i&lt;/code&gt;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker run myip&lt;/span&gt;&lt;br/&gt;当前 IP：160.155.224.xx 来自：XX市 联通&lt;br/&gt;&lt;span&gt;&lt;br/&gt;$&lt;/span&gt;&lt;span&gt; docker run myip -i&lt;/span&gt;&lt;br/&gt;HTTP/1.1 200 OK&lt;br/&gt;Server: nginx/1.8.0&lt;br/&gt;Date: Tue, 22 Nov 2016 05:12:40 GMT&lt;br/&gt;Content-Type: text/html; charset=UTF-8&lt;br/&gt;Vary: Accept-Encoding&lt;br/&gt;X-Powered-By: PHP/5.6.24-1~dotdeb+7.1&lt;br/&gt;X-Cache: MISS from cache-2&lt;br/&gt;X-Cache-Lookup: MISS from cache-2:80&lt;br/&gt;X-Cache: MISS from proxy-2_6&lt;br/&gt;Transfer-Encoding: chunked&lt;br/&gt;Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006&lt;br/&gt;Connection: keep-alive&lt;br/&gt;&lt;br/&gt;当前 IP：160.155.224.xx 来自：XX市 联通&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，这次成功了。这是因为当存在 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 后，&lt;code&gt;CMD&lt;/code&gt; 的内容将会作为参数传给 &lt;code&gt;ENTRYPOINT&lt;/code&gt;，而这里 &lt;code&gt;-i&lt;/code&gt; 就是新的 &lt;code&gt;CMD&lt;/code&gt;，因此会作为参数传给 &lt;code&gt;curl&lt;/code&gt;，从而达到了我们预期的效果。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2.4.2、场景二：应用运行前的准备工作&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 &lt;code&gt;mysql&lt;/code&gt; 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，可能希望避免使用 &lt;code&gt;root&lt;/code&gt; 用户去启动服务，从而提高安全性，而在启动服务前还需要以 &lt;code&gt;root&lt;/code&gt; 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 &lt;code&gt;root&lt;/code&gt; 身份执行，方便调试等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些准备工作是和容器 &lt;code&gt;CMD&lt;/code&gt; 无关的，无论 &lt;code&gt;CMD&lt;/code&gt; 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 中去执行，而这个脚本会将接到的参数（也就是 &lt;code&gt;&amp;lt;CMD&amp;gt;&lt;/code&gt;）作为命令，在脚本最后执行。比如官方镜像 &lt;code&gt;redis&lt;/code&gt; 中就是这么做的：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; alpine:&lt;span&gt;3.4&lt;/span&gt;&lt;br/&gt;...&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; addgroup -S redis &amp;amp;&amp;amp; adduser -S -G redis redis&lt;/span&gt;&lt;br/&gt;...&lt;br/&gt;&lt;span&gt;ENTRYPOINT&lt;/span&gt;&lt;span&gt; [&lt;span&gt;&quot;docker-entrypoint.sh&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;EXPOSE&lt;/span&gt; &lt;span&gt;6379&lt;/span&gt;&lt;br/&gt;&lt;span&gt;CMD&lt;/span&gt;&lt;span&gt; [ &lt;span&gt;&quot;redis-server&quot;&lt;/span&gt; ]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到其中为了 &lt;code&gt;Redis&lt;/code&gt; 服务创建了 &lt;code&gt;Redis&lt;/code&gt; 用户，并在最后指定了 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 为 &lt;code&gt;docker-entrypoint.sh&lt;/code&gt; 脚本。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;!/bin/sh&lt;/span&gt;&lt;br/&gt;...&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; allow the container to be started with `--user`&lt;/span&gt;&lt;br/&gt;if [ &quot;$1&quot; = &#x27;redis-server&#x27; -a &quot;$(id -u)&quot; = &#x27;0&#x27; ]; then&lt;br/&gt; chown -R redis .&lt;br/&gt; exec su-exec redis &quot;$0&quot; &quot;$@&quot;&lt;br/&gt;fi&lt;br/&gt;&lt;br/&gt;exec &quot;$@&quot;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该脚本的内容就是根据 &lt;code&gt;CMD&lt;/code&gt; 的内容来判断，如果是 &lt;code&gt;redis-server&lt;/code&gt; 的话，则切换到 &lt;code&gt;redis&lt;/code&gt; 用户身份启动服务器，否则依旧使用 &lt;code&gt;root&lt;/code&gt; 身份执行。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; docker run -it redis id&lt;/span&gt;&lt;br/&gt;uid=0(root) gid=0(root) groups=0(root)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.5、ENV&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;格式有两种：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;ENV &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;ENV &amp;lt;key1&amp;gt;=&amp;lt;value1&amp;gt; &amp;lt;key2&amp;gt;=&amp;lt;value2&amp;gt;...&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 &lt;code&gt;RUN&lt;/code&gt;，还是运行时的应用，都可以直接使用这里定义的环境变量。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;ENV VERSION=1.0 DEBUG=on \&lt;br/&gt;    NAME=&quot;Happy Feet&quot;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 &lt;code&gt;Shell&lt;/code&gt; 下的行为是一致的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 &lt;code&gt;node&lt;/code&gt; 镜像 &lt;code&gt;Dockerfile&lt;/code&gt; 中，就有类似这样的代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;ENV NODE_VERSION 7.2.0&lt;br/&gt;&lt;br/&gt;RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \&lt;br/&gt;  &amp;amp;&amp;amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \&lt;br/&gt;  &amp;amp;&amp;amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \&lt;br/&gt;  &amp;amp;&amp;amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\$&quot; SHASUMS256.txt | sha256sum -c - \&lt;br/&gt;  &amp;amp;&amp;amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components=1 \&lt;br/&gt;  &amp;amp;&amp;amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \&lt;br/&gt;  &amp;amp;&amp;amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这里先定义了环境变量 &lt;code&gt;NODE_VERSION&lt;/code&gt;，其后的 &lt;code&gt;RUN&lt;/code&gt; 这层里，多次使用 &lt;code&gt;$NODE_VERSION&lt;/code&gt; 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 &lt;code&gt;7.2.0&lt;/code&gt; 即可，&lt;code&gt;Dockerfile&lt;/code&gt; 构建维护变得更轻松了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下列指令可以支持环境变量展开：&lt;code&gt;ADD&lt;/code&gt;、&lt;code&gt;COPY&lt;/code&gt;、&lt;code&gt;ENV&lt;/code&gt;、&lt;code&gt;EXPOSE&lt;/code&gt;、&lt;code&gt;LABEL&lt;/code&gt;、&lt;code&gt;USER&lt;/code&gt;、&lt;code&gt;WORKDIR&lt;/code&gt;、&lt;code&gt;VOLUME&lt;/code&gt;、&lt;code&gt;STOPSIGNAL&lt;/code&gt;、&lt;code&gt;ONBUILD&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 &lt;code&gt;Dockerfile&lt;/code&gt; 制作更多的镜像，只需使用不同的环境变量即可。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.6、VOLUME&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;格式为：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;VOLUME [&quot;&amp;lt;路径1&amp;gt;&quot;, &quot;&amp;lt;路径2&amp;gt;&quot;...]&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;VOLUME &amp;lt;路径&amp;gt;&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 &lt;code&gt;Dockerfile&lt;/code&gt; 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;VOLUME /data&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的 &lt;code&gt;/data&lt;/code&gt; 目录就会在运行时自动挂载为匿名卷，任何向 &lt;code&gt;/data&lt;/code&gt; 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;docker run -d -v mydata:/data xxxx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这行命令中，就使用了 &lt;code&gt;mydata&lt;/code&gt; 这个命名卷挂载到了 &lt;code&gt;/data&lt;/code&gt; 这个位置，替代了 &lt;code&gt;Dockerfile&lt;/code&gt; 中定义的匿名卷的挂载配置。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.7、EXPOSE&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;格式为 &lt;code&gt;EXPOSE &amp;lt;端口1&amp;gt; [&amp;lt;端口2&amp;gt;...]&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;EXPOSE&lt;/code&gt; 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 &lt;code&gt;Dockerfile&lt;/code&gt; 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 &lt;code&gt;docker run -P&lt;/code&gt; 时，会自动随机映射 &lt;code&gt;EXPOSE&lt;/code&gt; 的端口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，在早期 &lt;code&gt;Docker&lt;/code&gt; 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 &lt;code&gt;Docker&lt;/code&gt; 引擎参数 &lt;code&gt;--icc=false&lt;/code&gt;，当指定该参数后，容器间将默认无法互访，除非互相间使用了 &lt;code&gt;--links&lt;/code&gt; 参数的容器才可以互通，并且只有镜像中 &lt;code&gt;EXPOSE&lt;/code&gt; 所声明的端口才可以被访问。这个 &lt;code&gt;--icc=false&lt;/code&gt; 的用法，在引入了 &lt;code&gt;docker network&lt;/code&gt; 后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要将 &lt;code&gt;EXPOSE&lt;/code&gt; 和在运行时使用 &lt;code&gt;-p &amp;lt;宿主端口&amp;gt;:&amp;lt;容器端口&amp;gt;&lt;/code&gt; 区分开来。&lt;code&gt;-p&lt;/code&gt;，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 &lt;code&gt;EXPOSE&lt;/code&gt; 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.8、WORKDIR&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;格式为 &lt;code&gt;WORKDIR &amp;lt;工作目录路径&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 &lt;code&gt;WORKDIR&lt;/code&gt; 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，&lt;code&gt;WORKDIR&lt;/code&gt; 会帮你建立目录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前提到一些初学者常犯的错误是把 &lt;code&gt;Dockerfile&lt;/code&gt; 等同于 &lt;code&gt;Shell&lt;/code&gt; 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;UN cd /app&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; &lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&quot;hello&quot;&lt;/span&gt; &amp;gt; world.txt&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果将这个 &lt;code&gt;Dockerfile&lt;/code&gt; 进行构建镜像运行后，会发现找不到 &lt;code&gt;/app/world.txt&lt;/code&gt; 文件，或者其内容不是 &lt;code&gt;hello&lt;/code&gt;。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 &lt;code&gt;Dockerfile&lt;/code&gt; 中，这两行 &lt;code&gt;RUN&lt;/code&gt; 命令的执行环境根本不同，是两个完全不同的容器。这就是对 &lt;code&gt;Dockerfile&lt;/code&gt; 构建分层存储的概念不了解所导致的错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前说过每一个 &lt;code&gt;RUN&lt;/code&gt; 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 &lt;code&gt;RUN cd /app&lt;/code&gt; 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此如果需要改变以后各层的工作目录的位置，那么应该使用 &lt;code&gt;WORKDIR&lt;/code&gt;指令。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原文：https://micromaple.blog.csdn.net/article/details/125804242&lt;br/&gt;作者：微枫 Micromaple&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cf56735e7daff22befebd7bde1f33f94</guid>
<title>字节跳动数据湖在实时数仓中的实践</title>
<link>https://toutiao.io/k/pvgyw02</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080E4BM5ibwjP1hqI0xUVA5I6XOiccVd1uib4icU5cicewwaTe7ichXVv4ZoI4Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了数据湖更好的落地，我们在落地之前与业务做了一些深入的沟通，并根据不同业务的特点主要分为了三个场景：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①场景一典型的业务主要是短视频和直播&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，它的数据量级一般都比较大，例如大流量的日志数据，其计算周期一般是自然的天、小时或者分钟级别的，实时性的要求一般是五分钟内，主要诉求是批流的复用，可以容忍少量数据的不一致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②场景二一般是直播或者电商的部分场景&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，数据量一般是中等体量，为长周期计算，对于实时性的要求一般是一分钟以内，主要诉求是低成本的数据回溯以及冷启动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;③场景三主要是电商和教育的一些场景&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，一般都是小规模的业务数据，会对数据做全量计算，其实时性要求是秒级的，主要诉求是强一致性以及高QPS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们结合这些特点基于数据湖做了一些成套的解决方案，接下来我们会基于实际的一些场景和案例一一去了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;实时数仓场景初探&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节我们讨论的是&lt;strong&gt;字节实时数仓场景的初探以及遇到的问题和解决方案&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;坦白地讲，在最初落地时大家对数据湖能支持线上生产的态度都是存疑的，我们开始的方案也就比较保守。我们首先挑选一些对比现有解决方案，数据湖具有凸显的优势的场景，针对其中的一些痛点问题尝试小规模的落地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080TAiaPvib3jIylCTR47Pyc4MrDk1ZGrKLYMd8yZ6ElDdicDWtSfFh86TzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;离线数仓有两个比较大的问题，一个是时效性问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，现状一般是天或小时级；&lt;/span&gt;&lt;strong&gt;&lt;span&gt;第二个比较大的问题是更新问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，例如需要更新某个小时内的部分数据，现状需要将分区内数据全部重刷，这样的更新效率是很低的。对于这样的场景，数据湖兼具时效性和高效更新能力。同时相对于实时数仓来说，数据湖可以一份存储，批流两用，从而直接进行高效的数据分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上对业务的分析，我们会按照以下步骤来做一线的落地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080Rp1r5AQzOOV57Hy7QDxtGS5z7qxsco1SaQpuyzm3tI0DsE7Xs0kicdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 基于视频元数据的落地方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看上图我们原有的方案有三个Hive表，Hive Table 1，2，3。对于整个链路来说我们会把左边MySQL数据源的数据导到Table 1中，右边Redis的数据导到Table 2中，然后将两个表做Join。这里存在两个比较大的问题，一个是高峰期的资源占用率较高，因为天级 Dump 数据量较大，且都集中在凌晨；二是就绪时间比较长，因为存在去重逻辑，会将 T-1 天分区的数据和当天分区的数据合并去重计算后落到当天（T天）的分区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080RfmLdSvdA3icMgdBJj3soUib8fDcialSlZSxxgBictdobtzwBAnTuphfAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过引入Hudi把天级的Dump分摊到每个小时进行Upsert。由于Hudi自身可以支持去重的逻辑，我们可以将Table 1看成一个实时的全量数据，当小时级别（例如23点）的数据一旦Upsert完成之后，我们就可以直接进行下游的Join逻辑，这样的话我们可以将数据的就绪时间提前3.5个小时左右，高峰期的资源消耗可以减少40%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080XAu6d2Tc7sPh4BK4r39katVV7qXdIZeia8L3bDJicvEGKvPN1X3zlZ7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 近实时数据校验方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于实时场景来说，当实时任务进行一个比较频繁的变更，比如优化或者新增指标的改动，一般需要校验实时任务的产出是否符合预期。我们当前的方案是会跑一个小时级别的Job，将一个小时的数据从Kafka Dump到Hive之后再校验全量数据是否符合预期。在一些比较紧急的场景下，我们只能抽查部分数据，这时候就对时效性的要求就比较高。在使用基于的Hudi 方案后，我们可以通过Flink将数据直接Upsert到Hudi表中，之后直接通过Presto查询数据从而做到全量数据近实时的可见可测。从线上效果来看可以极大提高实时任务的开发效率，同时保证数据质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080ztEresWp79bLHRlu7ML6f2MkdLF6joibsv7Wf1qW8KS7noRzKznrUiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以上探索过程中遇到了比较多的问题，第一个问题就是易用性比较差，运维成本和解释成本比较高。对于易用性这一部分，我们起初是通过脚本来提交SQL，可以看到SQL中的参数是比较多的，并且包含DDL的Schema，这在当列数比较多的情况下是比较麻烦的，会导致易用性较差，并且对业务侧来说也是不可接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080dPSv22FPn1hX4OZPaaelWSic9qqtCCSw3giagbWzGebuTFkiagxPv7SSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于以上问题我们做了一个针对性的解决方案，首先我们对之前的任务提交方式替换为了纯SQL化提交，并且通过接入统一的Catalog自动化读取 Schema和必要参数，入湖的SQL就可以简化为如图的形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;典型场景实践&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080zsEFT2C5cAOibCj9M31afsJAQnFh9CSTVFARcALk57PqIgSbe5YPcuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来让我们看&lt;strong&gt;字节目前基于Hudi的实时数仓整体链路&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，我们支持数据的实时入湖，例如MySQL，Kafka通过Flink可以直接落到Hudi；也支持进行一定的湖内计算，比如图中左下将MySQL数据通过Flink导入Hudi进一步通过Flink做一些计算后再落到Hudi。在数据分析方面，我们可以使用Spark和Presto连接看板BI进行一些交互式查询。当我们需要接到其他在线系统，尤其是QPS较高的场景，我们会先接入到KV存储，再接入业务系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们来看具体场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf0804jdsH2GzL2ojDxlsdedT4SwMxsb2CJxaEMOvnmPYS7xekwXc3P25Lw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 实时多维汇总&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于一个实时多维汇总的场景，我们可以把Kafka 数据增量写入到 Hudi 的轻度汇总层中。对于分析场景，可以基于 Presto 按需进行多维度的重度汇总计算，并可以直接构建对应的可视化看板。这个场景对QPS和延迟要求都不是很高，所以可以直接构建，但是对于高 QPS 和低延迟诉求的数据产品场景，目前的一个解决方案是通过 Presto 进行多维度预计算，然后导入到 KV 系统，进一步对接数据产品。从中长期来看我们会采取基于物化视图的方式，这样就可以进一步去简化业务侧的一些操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080YdoRByRc9CoCHktNIkFGcsDhfmvD4RGdV77jKW0UYFCeIgHQR4BGhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以上链路中，我们也遇到了比较多的&lt;strong&gt;问题&lt;/strong&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①写入稳定性差&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。第一点就是Flink在入湖的过程中任务占用资源比较大，第二点是任务频繁重启很容易导致失败，第三点是Compaction没有办法及时执行从而影响到查询。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②更新性能差&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。会导致任务的反压比较严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;③并发度难提升&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。会对Hudi Metastore Service（目前字节内部自主研发的Hudi元数据服务，兼容Hive接口，准备贡献到社区）稳定性产生比较大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;④查询性能比较差&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。有十分钟的延迟甚至经常查询失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对这些问题，我接下来简单介绍一下针对性的一些解决方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080lyjibXxMkqLjLZRp0abbBJge8EuMNs2gaibUctGTIsUFGIMicpoZWia18Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①写入稳定性治理&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一块我们通过异步的Compaction + Compaction Service的方案去解决这个问题。我们之前Flink入湖默认是在Flink内部去做Compaction，发现这一步是暴露以上一系列问题的关键。经过优化，Flink入湖任务只负责增量数据的写入，以及 Schedule Compaction逻辑，而Compaction执行则由Compaction Service负责。具体而言，Compaction Service 会从Hudi Metastore异步拉取Pending Compaction Plan，并提交Spark批任务完成实际的Compact。Compaction执行任务与Flink写入任务完全异步隔离，从而对稳定性有较大提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080OSNg5RmxAoDeq4vic5HdicLVHoSr2YcfA8vumsoLnr1n0bXLanjbCvEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②高效更新索引&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;支持数据量级的大幅提升。简单来说，我们可以基于哈希计算快速定位目标文件，提升写入性能；同时可以进行哈希过滤，从而也可以进行查询分析侧的优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080Dy9OFYTo9grHexmfhdfwq4RKh7j3bib2Un7X94rc9V76IpNZcJjZGibA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;③请求模型的优化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前的Hudi社区版的WriteTask 会轮询Timeline，导致持续访问Hudi Metastore，从而造成拓展能力受限的问题。我们将WriteTask的轮询请求从Hudi Metastore转移到了对JobManager缓存的拉取，这样就能大幅降低对Hudi Metastore的影响。经过这个优化可以让我们从几十万量级的RPS(Request Per Sec)提升到近千万的量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来我们来讲一下查询相关的优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080I9C4ibIa0bNQA8ZfXzJY8C8vZomBCRJ0icCJ9ib3TkWEOtsQUt8FsicG5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;④MergeOnRead列裁剪&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于原生的MergeOnRead来说，我们会在全量读取LogFile和BaseFile之后做合并，这在只查询部分列的时候会造成性能损耗，尤其是列比较多的情况。我们所做的优化是把列的读取下推到Scan层，同时在进行log文件合并时，会使用map结构存储K，V（K是主键，V是行记录），之后对行记录做列裁剪，最后再进行Log Merge的操作。这样会对序列化和反序列化开销以及内存使用率都有极大降低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080liaEWDLFB6FeH9yic25FHXeFx9XuJg2ibmRNrkVQLy7Kv4Nwq07vXwf4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⑤并行读优化&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一般引擎层在读Hudi时，一个Filegroup只对应一个Task，这样当单个 FileGroup 数据量较大时就极易造成性能瓶颈。我们对此的优化方案是对BaseFile进行切分，每个切分的文件对应一个Task从而提高读并行度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080Aia4NdR0Lc2NibtcicWQw46jNxm5PEYibmMDXVXWQ5jH6MTYMflIFrwm4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⑥Combine Engine&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hudi社区版目前在内存中对数据的合并和传输的实现完全是基于Avro格式，这会造成与具体引擎对接时有大量的序列化与反序列化计算，从而导致比较大的性能问题。对于这个问题我们与社区合作做了Combine Engine的优化，具体做法就是将接口深入到了引擎层的数据结构。例如在读取FileGroup时我们直接读取的就是Spark的InternalRow或是Flink的RowData，从而尽量减少对Avro格式的依赖。这样的优化可以极大地提高MergeOnRead和Compaction的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来两个优化由于时间原因就不做详细介绍了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080PNdqRzvYU0kfpwNJucM1EW6oCtPqlRvHLEId7IrqnU9g80hksqFmOQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⑦实时数据分析&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个场景我们可以把明细数据直接通过Flink导入到Hudi中，还会根据DIM表做一个宽表的处理从而落到Hudi表。这个场景的诉求主要有两点，一个是日志型数据的高效入湖，另一个是实时数据的关联。对于这两个场景的诉求，我们针对性的进行了一些优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080PzNFzrjWRUIkKNtAnvelzj93BmBqwuzYIDdo5m16x4o4unYNKOgnYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⑧日志型数据高效入湖&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于日志型数据，我们支持了NonIndex的索引。Hudi社区版主要支持是基于有主键的索引，比如Bloom Filter或者是我们给社区提供的Bucket Index。生成基于主键的索引方式主要会有两个步骤，第一个步骤是数据在写进来的时候会先对数据做定位，查询是否有历史数据存在，如果有的话就Update，没有的话就Insert，之后会定位到对应的文件把数据Append到Log中。然后在Merge或者在Compaction的过程中要在内存中做合并与去重处理，这两个操作也是比较耗时的。对于NonIndex来说，是不存在主键的概念的，所以支持的也是没有主键的日志型数据入湖。这样对于日志型数据在写入时可以直接Append到Log File中，在合并的过程中，我们可以不做去重处理，直接将增量数据数据Append到Base File中。这样就对入湖的效率有了很大的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080HgdmCYNVyS3QpmvLSsOzOWOlARg6sznbp2bwmlCaFvHRMP4X0ARz9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;⑨实时数据关联&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对目前实时Join出现的一系列问题，我们基于Hudi支持了存储层的关联。对Hudi来说不同的流可以完成其所对应列的写入，并在Merge的时候做拼接，这样对于外界查询来说就是一个完整的宽表。具体来说，在实时数据写入的过程中有一个比较大的问题是怎么处理多个流的写入冲突问题。我们主要是基于Hudi Metastore来做冲突检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf0803sj2xrhByvF7YAddjQ3NZfbohFm8HA8gOcnOUzgxMT6mI8cESic23oA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于读的流程，我们会先将多个LogFile读入内存进行Merge，然后再与BaseFile进行最终Merge，最后输出查询结果，Merge和Compaction都会使用到这个优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;04&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;未来规划&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080OTq8cGLiaLIBrxIlbRwRAdfIgGtIPocP7smtZnEEgVlLFXpq8o4ZSHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 弹性可扩展的索引系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们刚刚介绍了Bucket Index支持大数据量场景下的更新，Bucket Index也可以对数据进行分桶存储，但是对于桶数的计算是需要根据当前数据量的大小进行评估的，如果后续需要re-hash的话成本也会比较高。在这里我们预计通过建立Extensible Hash Index来提高哈希索引的可扩展能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080icub6cialOhno0IV7pib9ib4lOqSUwYg9yolibHVgHOB2uAP02PTRCqCzpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 自适应的表优化服务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了降低用户的理解和使用成本，我们会与社区深度合作推出Table Management Service来托管Compaction，Clean，Clustering以及Index Building的作业。这样对用户来说相关的优化都是透明的，从而降低用户的使用成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080wFWms6t7kbU3BB7yduKjv6ZlkxRoGwAtZqantT3iaNE0Axr1f5AGT1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 元数据服务增强&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前我们内部已经使用Hudi Metastore稳定支持了一些线上业务，但是也有更多需求随之而来，预计增强的元数据服务如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①Schema Evolution&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：支持业务对Hudi Schema变更的诉求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②Concurrency Control&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在Hudi Metastore中支持批流并发写入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5626666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080ibj5ekbun07ia1EKBEQxJ6svfGibXSYOydPLJ9FaPmtypSdqKCDts3huA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. 批流一体&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于流批一体处理，我们的规划如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①Unified SQL&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：做到批流统一的SQL层，Runtime由Flink/Spark/Presto多引擎协同计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②Unified Storage&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：基于Hudi的实时数据湖存储，由Hudi来做统一的存储。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;③Unified Catalog&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：统一元数据的构建以及接入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;05&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问答环节&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q1：MergeOnRead 列裁剪的文件格式是列式的还是行式的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A1：在没有优化前是基于Avro的行式存储我们目前已经支持了Parquet Log的列存格式，能够带来存储以及查询性能上的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q2：Async Compaction的调度是在Flink内部访问的Hudi Metastore吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A2：Flink之前默认是做了三件事，第一件事是Hudi增量写，第二件事是在几次增量写之后会Schedule一个Compaction计划，第三件事是执行Compaction Plan。我们目前所做的事情是只把Compaction Plan执行的这一步拆分了出来使用Compaction Service拉取Hudi Metastore元数据来执行Compaction。（图见写入稳定性治理）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q3：Hudi 表是如何管理的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A3：通过Hudi Metastore。目前我们使用的Hudi Metastore主要是部署在MySQL上面，支持文件与库表元数据的管理，Snapshot 服务，Hudi自有的Timeline 服务以及一些并发控制的处理。上层接口我们完全兼容Hive Metastore的接口标准，然后基于Hudi特性，我们拓展了Hudi特有的例如Timeline 相关的接口。同时我们支持流批应用统一接入到Hudi Metastore去做数据处理。（图见元数据服务增强）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q4：可以深入介绍一下多流写Hudi的流程以及冲突解决吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A4：多流Hudi增量写入，不同的流可以写到不同的Log文件中去，这一点是不冲突的，会产生冲突的点是二阶段的提交冲突，如果涉及到写的是同一个列的话是会产生列冲突的，这时我们会在Hudi Metastore中进行列级别的冲突检测，如果有冲突的话会直接拒绝提交，没有的话我们会认为是写两个流，就可以正常并发写入。（图见实时数据关联 — 写流程）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q5：实时数仓里的Kafka流表和Hudi流表是什么关系，以后是否会用Hudi表来代替Kafka的流表？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A5：我们今天介绍主要是Hudi支持的一些近实时（分钟级别）场景的落地和尝试，在某些场景我们需要秒级的响应，这样就需要我们做一些流批一体的规划和尝试。长期来看我们会使用Hudi 流式能力来替换Kafka的流式能力。（图见未来规划 – 流批一体）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q6：实时数仓是否每一层都用Hudi？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A6：湖内计算还在小范围的推广阶段，某些场景我们正在做POC，个别场景也在准备上线的过程中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q7：为何会使用Bucket Index？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A7：在使用Bucket Index前我们使用的是Bloom Filter Index，布隆过滤器在小数据量场景使用是没有问题的，但在百TB级别的数据下会有突出的假阳性的问题，当数据不存在的时候会扫描很多非必须的文件造成资源浪费。通过Bucket Index 我们可以直接通过hash值的计算能更加快速的定位数据所在的文件。&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp wxw_wechannel_card_not_horizontal&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe videosnap_video_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAvAszj9BnkwAAAAstQy6ubaLX4KHWvLEZgBPE_KF0NxRjcMyCzNPgMItsejQeO6Y1cF-bGOOUIgVo&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzW7l3gQJrlN9UOvicGicAlF452K7BzON0a34Jgias73OLSicw5ttc1Q9ibN7pp9gcCGib7j4sibeI5XlJFmsOYlRBKsrdw&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=AxricY7RBHdV4DcNhR0KCKQKmZ4MypNzNy1u4vpjzlt0nCvnhgia0zR0ibiabPthQibk7NBoHqALIb4A&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/Q3auHgzwzM65dPMvw5LV1YKkNSOYWPNEiax9tdVpZs627Us6C2b4W9A/0&quot; data-username=&quot;v2_060000231003b20faec8c7e18a1ec3ddcb0ceb33b07771cd1cb5408d3b3fdc0ac1072c28df1a@finder&quot; data-nickname=&quot;DataFunTalk&quot; data-desc=&quot;点击链接下载【多维分析PPT】Hudi表的管理是怎么做的？#数据湖 #实时数仓 #多维分析&quot; data-nonceid=&quot;2267253158257630400&quot; data-type=&quot;video&quot; data-width=&quot;1080&quot; data-height=&quot;1440&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;今天的分享就到这里，谢谢大家。&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;在文末分享、点赞、在看，给个3连击呗~&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;分享嘉宾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section data-id=&quot;40633&quot; data-tools=&quot;小蚂蚁编辑器&quot; powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;22b98&quot;&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;22b98&quot;&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47148148148148145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPjzodGzicCkJoF62BXoHf080Ay2gej53PJdrbvh2aymcp5nJXADpZtVzBBnde9BCOGRu3otKibWarjg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-id=&quot;46143&quot; data-type=&quot;lspecial02&quot; data-tools=&quot;小蚂蚁编辑器&quot; powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;section data-bastyle=&quot;display:inline-block;vertical-align:middle;width:5px;height:26px;background-color:rgb(168, 166, 209);margin-right:10px;transform:rotate(8deg);-webkit-transform:rotate(8deg);-moz-transform:rotate(8deg);-o-transform:rotate(8deg);&quot; data-md5=&quot;44f44&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-bastyle=&quot;background-color: rgba(168, 166, 209, 0.2);padding:0px 2px;box-sizing:border-box;&quot; data-md5=&quot;44f44&quot;&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;p data-md5=&quot;44f44&quot;&gt;&lt;span&gt;&lt;strong data-md5=&quot;44f44&quot;&gt;张友军&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;section powered-by=&quot;xmyeditor.com&quot; data-md5=&quot;44f44&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong data-md5=&quot;44f44&quot;&gt;字节跳动 &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;大数据引擎研发工程师&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;就职于字节跳动数据引擎部门数据湖团队，任数据湖高级工程师。先后从事 Spark 引擎研发，智能数仓研发，现负责基于 HUDI 的实时数据湖内核研发及在字节跳动的场景落地。&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;&lt;span&gt;02&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;免费下载资料&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;704&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.47148148148148145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjzodGzicCkJoF62BXoHf080Mdq6edhicw5r4QE3wC4xIK8Lovy1uUkWp5oZeabqbD3icCrryVBAPm4g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; title=&quot;大数据专题书.png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;报名看直播 免费领PPT&lt;/span&gt;&lt;/strong&gt;
    &lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;1301&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;1408&quot; data-ratio=&quot;2.25&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgGRsbGKA2L4Yne25p6WNYz0GeWqdoTia10C745vtBorfAQNE1QrGYUKSMJXbknF8kAKicYnYIzCqgw/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; title=&quot;公众号尾banner.jpg&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;04&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;/&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;关于我们&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;DataFun：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;专注于大数据、人工智能技术应用的分享与交流。发起于2017年，在北京、上海、深圳、杭州等城市举办超过100+线下和100+线上沙龙、论坛及峰会，已邀请超过2000位专家和学者参与分享。其公众号 DataFunTalk 累计生产原创文章700+，百万+阅读，14万+精准粉丝&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU1NTMyOTI4Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPh87SyjsEtoRFs9iaLyPXYh9ls0BcsiaPDnFkg72xgLsvku13ZRYibyq93DgRoCaTaTkbJj7Hia4dvI1w/0?wx_fmt=png&quot; data-nickname=&quot;DataFunTalk&quot; data-alias=&quot;datafuntalk&quot; data-signature=&quot;专注于大数据、人工智能技术应用的分享与交流。致力于成就百万数据科学家。定期组织技术分享直播，并整理大数据、推荐/搜索算法、广告算法、NLP 自然语言处理算法、智能风控、自动驾驶、机器学习/深度学习等技术应用文章。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;🧐 &lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;分享、点赞、在看&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，给个&lt;/span&gt;&lt;span&gt;&lt;strong&gt;3连击&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;呗&lt;/span&gt;&lt;/span&gt;&lt;span&gt;！&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;👇&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>378d81523592ca4d2d7fb4fd9cf9be0d</guid>
<title>C++类设计和实现的十大最佳实践</title>
<link>https://toutiao.io/k/mbd7pmc</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;em&gt;C++代码提供了足够的灵活性，因此对于大部分工程师来说都很难把握。本文介绍了写好C++代码需要遵循的10个最佳实践，并在最后提供了一个工具可以帮助我们分析C++代码的健壮度。原文：10 Best practices to design and implement a C++ class&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 尽可能尝试使用新的C++标准&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到2022年，C++已经走过了40多个年头。新的C++标准实际上简化了许多令人沮丧的细节，提供了新的现代方法来改进C++代码，但让开发人员认识到这一点并不容易。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以内存管理为例，这可能是C++中受到最多批评的机制。多年来，对象分配都是由new关键字完成的，开发人员一定得记住在代码的某个地方调用delete。“现代C++”解决了这个问题，并促进了共享指针的使用。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. 使用命名空间模块化代码&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现代C++库广泛使用命名空间来模块化代码库，它们利用“Namespace-by-feature”方法，按功能划分命名空间来反映功能集，将单个特性(且仅与该特性)相关的所有内容放到单个命名空间中。从而使得命名空间具有高内聚性和高模块化，并且耦合最小，紧耦合的项目被放在了一起。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Boost是按特性分组的最佳示例，其包含数千个命名空间，每个命名空间用于对特定的特性进行分组。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3. 抽象&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据抽象是C++中面向对象编程最基本和最重要的特性之一。抽象意味着只显示基本信息而隐藏细节，数据抽象指的是仅向外部世界提供关于数据的基本信息，隐藏背景细节或实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尽管许多书籍、网络资源、会议演讲者和专家都推荐这种最佳实践，但在很多项目中，这条规则仍然被忽略了，许多类的细节并没有被隐藏。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4. 类越小越好&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具有多行代码的类型应该被划分为一组较小的类型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要很大的耐心重构一个大的类，甚至可能需要从头重新创建所有东西。以下是一些重构建议:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;BigClass中的逻辑必须被分成更小的类。这些较小的类最终可能成为嵌套在原始God Class中的私有类，God Class的实例对象由较小嵌套类的实例组成。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;较小的类划分应该由God Class负责的多个职责驱动。要确定这些职责，通常需要查找与字段的子集强耦合的方法的子集。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果BigClass包含的逻辑比状态多，一个好的选择是定义一个或几个不包含静态字段而只包含纯静态方法的静态类。纯静态方法是一种只根据输入参数计算结果的函数，它不读取或分配任何静态或实例字段。纯静态方法的主要优点是易于测试。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;首先尝试维护BigClass的接口，并委托调用新提取的类。最后，BigClass应该是一个没有自己逻辑的纯接口，可以为了方便将其保留，也可以将其扔掉，并开始只使用新类。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;单元测试可以提供帮助: 在提取方法之前为每个方法编写测试，以确保不会破坏功能。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5. 每个类尽量提供最少的方法&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;包含20个以上方法的类可能很难理解和维护。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个类有许多方法可能是实现了太多责任的症状。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也许所面对的类控制了系统中太多的其他类，并且已经超出了应有的逻辑，成为了一个无所不能的类。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6. 加强低耦合&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;低耦合是理想状态，可以在应用中进行较少的更改实现程序的某个变更。从长远来看，可以减少修改、添加新特性的大量时间、精力和成本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;低耦合可以通过使用抽象类或泛型类和方法来实现。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;7. 加强高内聚&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;单一责任原则规定一个类不应该有多于一个更改的理由，这样的类被称为内聚类。较高的LCOM值通常可以意味着类的内聚性较差。有几个LCOM指标，取值范围为[0-1]。LCOM HS (HS代表Henderson-Sellers)取值范围为[0-2]。LCOM HS值大于1时需要产生警惕。下面是计算LCOM指标:&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;LCOM = 1 — (sum(MF)/M*F) &lt;br/&gt;LCOM HS = (M — sum(MF)/F)(M-1)&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中……&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;M是类中方法的数量(包括静态方法和实例方法，它还包括构造函数、属性getter/setter、事件添加/删除方法)。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;F是类中实例字段的数量。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MF是类访问特定实例字段的方法数量。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Sum(MF)是该类所有实例字段的MF之和。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些公式背后的基本思想可以表述如下: 如果一个类的所有方法都使用它的所有实例字段，那么这个类就是完全内聚的，这意味着sum(MF)=M*F，然后LCOM = 0和LCOMHS = 0。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;LCOMHS值大于1就需要警惕了。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;8. 只注释代码不能表达的内容&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;鹦鹉学舌的代码注释没有为读者提供任何额外的东西。代码库中充斥着嘈杂的注释和不正确的注释，促使程序员忽略所有的注释，或者采取积极的措施隐藏它们。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;9. 尽量不要用重复的代码&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;众所周知，重复代码的存在对软件开发和维护有负面影响。实际上，一个主要缺点是，当为了修复bug或添加新特性而更改重复代码的实例时，所有对应的代码必须同时更改。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;产生重复代码最常见的原因是复制/粘贴操作，这种情况下，相似的源代码出现在两个或多个地方。许多文章、书籍和网站都警告不要采用这种做法，但有时实践这些建议并不容易，开发人员还是会选择简单的解决方案: 复制/粘贴大法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用适当的工具可以容易的从复制/粘贴操作中检测到重复代码，但是，在某些情况下，克隆代码很难被检测到。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;10. 不变性有助于多线程编程&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基本上，如果对象在创建之后状态不变，那么这个对象就是不可变(immutable)的。如果一个类的实例是不可变的，那么该类就是不可变的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不可变对象极大简化了并发编程，这是支持使用它的重要理由。想想看，为什么编写适当的多线程程序是一项艰巨的任务？因为同步线程访问资源(对象或其他操作系统资源)是很困难的。为什么同步这些访问很困难？因为很难保证多个线程对多个对象进行的多次写访问和读访问之间不会出现竞争条件。如果不再有写访问会怎么样？换句话说，如果被线程访问的对象的状态没有改变会怎么样？就不再需要同步了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于不可变类的另一个好处是它们永远不会违反里氏替换原则(LSP, Liskov Subtitution Principle)，以下是维基百科对LSP的定义:&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Liskov的行为子类型的概念定义了可变对象可替换性的概念，也就是说，如果S是T的子类型，那么程序中T类型的对象可以被替换为S类型的对象，而不改变该程序的任何期望属性(例如，正确性)。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果没有公共字段，没有可以更改其内部数据的方法，并且派生类方法无法更改其内部数据，那么引用对象类就是不可变的。因为值不可变，所以在所有情况下都可以引用相同的对象，不需要复制构造函数或赋值操作符。出于这个原因，建议将复制构造函数和赋值操作符设为私有，或者从boost::noncopyable继承，或者使用新的C++ 11特性“显式默认和删除特殊成员函数”&lt;sup&gt;[2]&lt;/sup&gt;。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;如何加强对这些最佳实践进行检查?&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CppDepend&lt;sup&gt;[3]&lt;/sup&gt;提供了名为CQLinq&lt;sup&gt;[4]&lt;/sup&gt;的代码查询语言，可以像数据库一样查询代码库。开发人员、设计人员和架构师可以自定义查询，以便轻松找到容易出现bug的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过CQLinq，可以结合来自代码度量、依赖关系、API使用和其他模型的数据来定义非常高级的查询，以匹配容易出现bug的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，分析clang源代码后，可以检测到大类:&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.4740406320541761&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0UFXSjnVlKF6ABmuESoc18o0NFpBgsAY2mCNibPSO9WWNjZWo7bb6ibvGXltoKr2zTiaQ3BSkS4MdUJw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;886&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;检测到有大量方法的类:&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.345679012345679&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0UFXSjnVlKF6ABmuESoc18ofVOsaWEEvnhZkaaLAcKAgaJlROwJczClFUczsKZ8E3S6V8IfNEqpDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;891&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或者检测到内聚性较差的类:&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9738134206219312&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0UFXSjnVlKF6ABmuESoc18oCMP3OWVL86aG2pqoIIHFn5EAdlQNCNsLdkjibVPYv1iare5uDCW1SPyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1222&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt; &lt;br/&gt;[1] 10 Best practices to design and implement a C++ class: https://issamvb.medium.com/10-best-practices-to-design-and-implement-a-c-class-4326611827e1#:~:text=10%20Best%20practices%20to%20design%20and%20implement%20a,class%20as%20you%20can.%20...%20More%20items...%20 &lt;br/&gt;[2] Explicitly defaulted and deleted special member functions: http://en.wikipedia.org/wiki/C%2B%2B11#Explicitly_defaulted_and_deleted_special_member_functions &lt;br/&gt;[3] CppDepend: http://www.cppdepend.com/ &lt;br/&gt;[4] CQLinq: https://www.cppdepend.com/cqlinq&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。&lt;br/&gt;微信公众号：DeepNoMind&lt;/p&gt;&lt;/blockquote&gt;&lt;span&gt;- END -&lt;/span&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>