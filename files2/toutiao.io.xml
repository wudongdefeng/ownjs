<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>b92b914eb9627e712ba8345afd3e066a</guid>
<title>优质网站同好者周刊（第 111 期） | 倾城博客</title>
<link>https://toutiao.io/k/g1765df</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/?utm_source=weekly&quot;&gt;倾城之链&lt;/a&gt;作为一个开放平台，旨在云集全球&lt;strong&gt;优秀网站&lt;/strong&gt;，探索互联网中更广阔的世界。此周刊，将汇聚过去一周&lt;a href=&quot;https://nicelinks.site/?utm_source=weekly&quot;&gt;倾城&lt;/a&gt;所收录的内容，以飨同好；欢迎推荐或自荐（仅限有独立域名的网站，可以是二级域名）。您如果要了解收录要求，请参见&lt;a href=&quot;https://nicelinks.site/about?utm_source=weekly&quot;&gt;关于倾城&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;备注&lt;/strong&gt;：本周刊&lt;strong&gt;每周五&lt;/strong&gt;生成，首发于个人微信公众号&lt;a href=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI5MDIwMzM2Mg==&amp;amp;action=getalbum&amp;amp;album_id=1530765143352082433&amp;amp;scene=173&amp;amp;from_msgid=2650641087&amp;amp;from_itemidx=1&amp;amp;count=3#wechat_redirect&quot;&gt;晚晴幽草轩&lt;/a&gt;、博客&lt;a href=&quot;https://www.jeffjade.com&quot;&gt;晚晴幽草轩&lt;/a&gt;，以及&lt;a href=&quot;https://forum.lovejade.cn/&quot;&gt;悠然宜想亭&lt;/a&gt;社区；此一键生成脚本基于 &lt;a href=&quot;https://nicelinks.site/post/602d30aad099ff5688618591&quot;&gt;Deno&lt;/a&gt; 编写，并在 Github 开源：&lt;a href=&quot;https://github.com/nicejade/nicelinks-weekly&quot;&gt;nicejade/nicelinks-weekly&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E7%BB%84%E4%BB%B6&quot;&gt;&lt;code&gt;组件&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/Svelte&quot;&gt;&lt;code&gt;Svelte&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/Markdown&quot;&gt;&lt;code&gt;Markdown&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Combine svelte and markdown in the same file. Live your dreams!&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/mdsvex.com.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - mdsvex - markdown in svelte!&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://mdsvex.com/&quot;&gt;MDSvex&lt;/a&gt; 是一个基于 &lt;a href=&quot;https://nicelinks.site/tags/Markdown&quot;&gt;Markdown&lt;/a&gt; 和 &lt;a href=&quot;https://nicelinks.site/tags/Svelte&quot;&gt;Svelte&lt;/a&gt; 技术栈的工具，可以将 Markdown 文档转换为可交互的组件化 UI。该工具允许开发者以类似于编写 React 组件的方式编写 Markdown 文件，并支持在 Markdown 中嵌入 Svelte 组件。MDSvex 的主要特点如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;基于 Markdown&lt;/strong&gt;：MDSvex 使用 Markdown 作为文档格式，并支持 GitHub Flavored Markdown 标准。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;支持 Svelte 组件&lt;/strong&gt;：开发者可以在 Markdown 中嵌入 Svelte 组件，并通过 props 实现组件之间的数据传递和状态管理。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可交互性&lt;/strong&gt;：由于 MDSvex 可以将 Markdown 转换为组件化 UI，因此可以实现更加丰富和动态的用户交互体验。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：MDSvex 支持自定义配置和插件，可以根据项目需求进行灵活扩展和定制化。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/redirect?url=https://mdsvex.com/&quot;&gt;MDSvex&lt;/a&gt; 基本上是 Svelte 的 &lt;a href=&quot;https://nicelinks.site/post/63e4e3eee63ccd089dee6686&quot;&gt;MDX&lt;/a&gt; ，允许您在 markdown 中使用 Svelte 组件，或在 Svelte 组件中使用 markdown。mdsvex 支持所有 Svelte 语法和_几乎_所有 markdown 语法。有关详细信息，请参阅 &lt;a href=&quot;https://mdsvex.com/docs/#limitations&quot;&gt;限制&lt;/a&gt; ，下面是使用示例：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot;&gt;&amp;lt;script&amp;gt;
    import { Chart } from &quot;../components/Chart.svelte&quot;;
&amp;lt;/script&amp;gt;

# Here’s a chart
The chart is rendered inside our MDsveX document.

&amp;lt;Chart /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;近期有基于 &lt;a href=&quot;https://nicelinks.site/post/62a9c2ad90509e23cea772c0&quot;&gt;Svelte&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/post/5fd20cb4c06d6302c1907ec7&quot;&gt;TailwindCSS&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/post/6010e1b10c71de1fb957b64e&quot;&gt;Vite&lt;/a&gt; 开发一款 &lt;a href=&quot;https://nicelinks.site/tags/ChatGPT&quot;&gt;ChatGPT&lt;/a&gt; 相关的 Web 应用： &lt;a href=&quot;https://chatgpt.nicelinks.site/&quot;&gt;素问智聊斋&lt;/a&gt; ；其中 &lt;a href=&quot;https://chatgpt.nicelinks.site/#/about&quot;&gt;关于&lt;/a&gt; 、 &lt;a href=&quot;https://chatgpt.nicelinks.site/#/sponsor&quot;&gt;赞助&lt;/a&gt; 等页面，基于 Markdown、 &lt;a href=&quot;https://nicelinks.site/post/5fd20cb4c06d6302c1907ec7&quot;&gt;TailwindCSS&lt;/a&gt; 、和 &lt;a href=&quot;https://nicelinks.site/redirect?url=https://mdsvex.com/&quot;&gt;MDSvex&lt;/a&gt; 来开发，配置简单，效率贼高，效果很棒，体验极好；颇为赞叹。下面是 Sponsor（赞助）页面的代码：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot;&gt;&amp;lt;script&amp;gt;
import Sponsor from &#x27;./../markdown/Sponsor.md&#x27;
&amp;lt;/script&amp;gt;

&amp;lt;div class=&quot;flex-col justify-between mx-auto my-4 prose page-warpper lg:prose-xl md:prose-sm&quot;&amp;gt;
  &amp;lt;Sponsor /&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用 MDSvex 可以帮助开发者快速构建可交互的文档和演示页面，同时&lt;strong&gt;提高开发效率&lt;/strong&gt;和&lt;strong&gt;代码复用性&lt;/strong&gt;，强烈推荐；该项目在 &lt;a href=&quot;https://github.com/pngwn/mdsvex&quot;&gt;Github 开源&lt;/a&gt; ，感兴趣的朋友可移步以了解更多。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/642598ca2d6c9c63445c8862&quot;&gt;倾城之链 - mdsvex - markdown in svelte!&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E7%BC%96%E8%BE%91%E5%99%A8&quot;&gt;&lt;code&gt;编辑器&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/AI&quot;&gt;&lt;code&gt;AI&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/ChatGPT&quot;&gt;&lt;code&gt;ChatGPT&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Refactor, understand, and write code effortlessly with Cursor.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/www.cursor.so.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - Cursor | Build Fast&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://www.cursor.so/&quot;&gt;Cursor&lt;/a&gt; 是一款专为 &lt;a href=&quot;https://nicelinks.site/tags/AI&quot;&gt;AI&lt;/a&gt; 编程而生的编辑器，配置非常简单，因为内置了 &lt;a href=&quot;https://nicelinks.site/tags/ChatGPT&quot;&gt;ChatGPT&lt;/a&gt; 的能力，所以下载即用，通过 &lt;code&gt;Ctrl+k&lt;/code&gt; 调出对话框进行会话，输入 prompts 即可得到结果。现在 cursor 还处于早期阶段，但现在它可以帮助您做一些事情，诸如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;编写&lt;/strong&gt;：使用比 Copilot 更智能的 AI 生成 10-100 行代码；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Diff&lt;/strong&gt;：要求 AI 编辑一段代码，只查看建议的更改；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;聊天&lt;/strong&gt;：了解您当前文件的 ChatGPT 风格界面；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;还有更多&lt;/strong&gt;：要求修复 lint 错误，在悬停时生成测试/评论等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实际体验，当输入 prompts 进行会话时，它要求登录从而使用 AI 功能，理由是避免滥用它们后台；当然，Cursor 有其 AI 提供了另一种方式，即需要用户输入自己的 Open API key。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/post/5af55777979f626ea3d37917&quot;&gt;VSCode&lt;/a&gt; 有提供名为 CodeGPT 的扩展，也是需要用户输入 &lt;code&gt;OpenAI API&lt;/code&gt; 密钥，才能使用；有感兴趣的网友，对两者进行了测试，认为 Cursor 的体验要略胜一筹。毫不疑问，如今的 AI 已强大非常，可以帮各种用户做更多工作；推荐有条件的朋友，可以用起来，以提升效率、节省时间、启发灵感。如果您对 Cursor 感兴趣，可移步至 &lt;a href=&quot;https://github.com/getcursor/cursor&quot;&gt;Github 开源仓库&lt;/a&gt;从而了解更多。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/642573d62d6c9c63445c835c&quot;&gt;倾城之链 - Cursor | Build Fast&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93&quot;&gt;&lt;code&gt;数据库&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E6%90%9C%E7%B4%A2&quot;&gt;&lt;code&gt;搜索&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/AI&quot;&gt;&lt;code&gt;AI&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/weaviate.io.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - Welcome | Weaviate - vector database&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 是一个基于向量搜索 (vector search) 和自然语言处理 (NLP) 技术的开源向量数据库。它不仅可以存储、管理和查询向量，还可以自动学习向量之间的关系和上下文，从而支持更智能的搜索和推荐。Weaviate 具有如下功能特征：&lt;/p&gt;&lt;h3 id=&quot;矢量搜索&quot;&gt;&lt;a href=&quot;#%E7%9F%A2%E9%87%8F%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;矢量搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;矢量搜索&lt;/h3&gt;&lt;p&gt;无论您是自带向量还是使用其中一个向量化模块，您都可以为数十亿个数据对象建立索引以进行搜索。&lt;/p&gt;&lt;h3 id=&quot;混合搜索&quot;&gt;&lt;a href=&quot;#%E6%B7%B7%E5%90%88%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;混合搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;混合搜索&lt;/h3&gt;&lt;p&gt;结合多种搜索技术，例如基于关键字的搜索和矢量搜索，以提供最先进的搜索体验。&lt;/p&gt;&lt;h3 id=&quot;生成搜索&quot;&gt;&lt;a href=&quot;#%E7%94%9F%E6%88%90%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;生成搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;生成搜索&lt;/h3&gt;&lt;p&gt;通过 GPT-3 等 LLM 模型输送搜索结果来改进您的搜索结果，以创建下一代搜索体验。&lt;/p&gt;&lt;h3 id=&quot;超越搜索&quot;&gt;&lt;a href=&quot;#%E8%B6%85%E8%B6%8A%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;超越搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;超越搜索&lt;/h3&gt;&lt;p&gt;Weaviate 支持闪电般快速的矢量搜索，但它的功能远不止于此。它的其他一些超能力包括推荐、总结以及与神经搜索框架的集成。&lt;/p&gt;&lt;p&gt;官方网站 &lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 提供了丰富的文档资料、教程和示例代码，可以帮助开发者更好地理解和使用 Weaviate。同时，官网还提供了 Weaviate Playground 工具，可以在线试用和体验 Weaviate 的功能和接口。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 的应用场景非常广泛，可以用于各种不同的领域，如企业搜索、医疗健康、金融服务、新闻媒体等。它可以帮助企业和机构快速地找到所需的信息和数据，提高工作效率和准确率。同样地，在医疗和健康领域，它可以帮助医生和研究人员快速地查找和分析相关文献和数据，支持疾病预防和诊断。&lt;/p&gt;&lt;p&gt;总之， &lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 提供了丰富的文档和的资源，帮助用户更好地理解 Weaviate 数据库的功能和优势，从而支持开发者快速构建智能应用，提高数据查询和处理的准确率。同时，由于 Weaviate 是开源项目，用户可以在 &lt;a href=&quot;https://github.com/weaviate/weaviate&quot;&gt;GitHub 上获取其源代码&lt;/a&gt; ，并对其进行自定义和扩展。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/6422e0762d6c9c63445c73ed&quot;&gt;倾城之链 - Welcome | Weaviate - vector database&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/JavaScript&quot;&gt;&lt;code&gt;JavaScript&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%B7%A5%E5%85%B7&quot;&gt;&lt;code&gt;工具&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91&quot;&gt;&lt;code&gt;前端开发&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;JavaScript Obfuscator is a free online tool that obfuscates your source code, preventing it from being stolen and used without permission.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/obfuscator.io.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - JavaScript Obfuscator Tool&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://obfuscator.io/&quot;&gt;JavaScript Obfuscator Tool&lt;/a&gt; ，是一个在线代码混淆工具，免费且高效；它可以将 &lt;a href=&quot;https://nicelinks.site/tags/JavaScript&quot;&gt;JavaScript&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/tags/CSS&quot;&gt;CSS&lt;/a&gt; 和 &lt;a href=&quot;https://nicelinks.site/tags/HTML&quot;&gt;HTML&lt;/a&gt; 代码进行混淆，从而防止源代码被恶意利用或破解。它提供了多种混淆选项，如随机变量名、删除空格、注释等等，以此增加被攻击者解密的难度，提高代码的安全性。同时，该工具还支持在线预览和多款编码风格的选择，可以方便地查看和选择混淆后的代码风格，以及调整混淆程度。&lt;/p&gt;&lt;p&gt;值得一提的是，该网站的服务是基于&lt;strong&gt;加密算法&lt;/strong&gt;实现的，因此不需要上传代码即可进行混淆，确保了用户的代码的隐私和安全（这也是跟类似产品如 UglifyJS、Closure Compiler 不同的地方）。另外，该网站还提供了 Chrome 插件，可以在开发过程中直接使用，非常方便。&lt;/p&gt;&lt;p&gt;需要注意的是，代码混淆只能增加被攻击者破解的难度，但并不能完全保证代码不被破解。高度复杂的代码混淆对代码的可读性和可维护性也会带来影响。因此，在实际开发中，需要根据实际情况选择适当的混淆方式。同时，还需要采取其他安全措施，如加密和防火墙等，以提高代码的安全性。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/6422da402d6c9c63445c7319&quot;&gt;倾城之链 - JavaScript Obfuscator Tool&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E5%B7%A5%E5%85%B7&quot;&gt;&lt;code&gt;工具&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%B9%B3%E5%8F%B0&quot;&gt;&lt;code&gt;平台&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%B7%A5%E5%85%B7%E7%AE%B1&quot;&gt;&lt;code&gt;工具箱&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：工具平台，帮小忙&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;帮小忙，腾讯 QQ 浏览器工具箱平台。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/tool.browser.qq.com.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 -  帮小忙，腾讯QQ浏览器在线工具箱平台 &quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://tool.browser.qq.com/&quot;&gt;帮小忙&lt;/a&gt; ，友腾讯 QQ 浏览器团队推出的在线工具箱平台，功能较为齐全，有图片加水印、数据换算、生活娱乐、教育、文本工具、证件生成、、文字提取、今天吃什么、亲戚关系计算、字帖生成、文档转换、开发工具、视频和 PDF 转换工具等等，分免费的和限时免费。类似工具聚合平台较多，诸如 &lt;a href=&quot;https://nicelinks.site/post/5a5cc0b60aee782ded3e7b6b&quot;&gt;在线工具 - 程序员的工具箱&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/post/62727acd7d02b74eba0f09d9&quot;&gt;即时工具-致力打造即用即走型在线工具箱&lt;/a&gt; 等等，您可按需选择典藏、使用。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/641e8f67abfccb2329b4e383&quot;&gt;倾城之链 - 帮小忙，腾讯QQ浏览器在线工具箱平台&lt;/a&gt;&lt;/p&gt;&lt;p&gt;对倾城之链感兴趣的朋友，可通过 Web，小程序，快应用等渠道进行访问(后续将支持更多，如 VsCode 插件，Chrome 扩展等)。您有任何问题，欢迎随时向我们反馈（您可以通过官网反馈渠道，或添加如下客服微信），🤲 。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://image.nicelinks.site/%E5%80%BE%E5%9F%8E%E4%B9%8B%E9%93%BE-%E5%BE%AE%E4%BF%A1-mini.jpeg&quot; alt=&quot;倾城之链 - 客服微信&quot;/&gt;&lt;/p&gt;&lt;h2 id=&quot;本期文末寄语&quot;&gt;&lt;a href=&quot;#%E6%9C%AC%E6%9C%9F%E6%96%87%E6%9C%AB%E5%AF%84%E8%AF%AD&quot; aria-label=&quot;本期文末寄语 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;本期文末寄语&lt;/h2&gt;&lt;p&gt;风急天高猿啸哀，渚清沙白鸟飞回。&lt;br/&gt;无边落木萧萧下，不尽长江滚滚来。&lt;br/&gt;万里悲秋常作客，百年多病独登台。&lt;br/&gt;艰难苦恨繁霜鬓，潦倒新停浊酒杯。&lt;br/&gt;── 唐朝 · 杜甫 《登高》&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/?utm_source=weekly&quot;&gt;倾城之链&lt;/a&gt;作为一个开放平台，旨在云集全球&lt;strong&gt;优秀网站&lt;/strong&gt;，探索互联网中更广阔的世界；在这里，你可以轻松发现、学习、分享更多有用或有趣的事物。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://image.nicelinks.site/nicelinks-miniprogram-code.jpeg?imageView2/1/w/250/h/250/interlace/1/ignore-error/1&quot; alt=&quot;小程序码 - 倾城之链&quot;/&gt;&lt;/p&gt;&lt;h2 id=&quot;您可能感兴趣的文章&quot;&gt;&lt;a href=&quot;#%E6%82%A8%E5%8F%AF%E8%83%BD%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E6%96%87%E7%AB%A0&quot; aria-label=&quot;您可能感兴趣的文章 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;您可能感兴趣的文章&lt;/h2&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f9b1596bd0e7a0a3bf6140b1804c1674</guid>
<title>连接 AI，NebulaGraph Python ORM 项目 Carina 简化 Web 开发</title>
<link>https://toutiao.io/k/ol4fi9h</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post&quot; itemprop=&quot;articleBody&quot;&gt;
          &lt;p&gt;&lt;img src=&quot;https://nebula-website-cn.oss-cn-hangzhou.aliyuncs.com/nebula-blog/nebula-python-orm.jpg&quot; alt=&quot;&quot; role=&quot;presentation&quot;/&gt;&lt;/p&gt;
&lt;p&gt;作者：Steam &amp;amp; Hao&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文整理自社区第 7 期会议中 13‘21″ 到 44’11″ 的 Python ORM 的分享，视频见 &lt;a href=&quot;https://www.bilibili.com/video/BV1s8411N7Cw&quot;&gt;https://www.bilibili.com/video/BV1s8411N7Cw&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在做业务开发时，NebulaGraph Python ORM 项目作者：Sword Elucidator（下文简称：Hao）发现图数据库在某些场景下有比较不错的应用实践，而 NebulaGraph 是他觉得不错、较为先进的一款图数据库产品。在 Hao 的开发过程中，他发现：虽然&lt;a href=&quot;https://discuss.nebula-graph.com.cn/c/blog/47-category/47&quot;&gt;图数据库被应用在多个业务场景&lt;/a&gt;中，但对于像是 App 开发之类的 ISO/OSI 高层实践的话，nebula-python 之类的客户端就略显笨重。&lt;/p&gt;
&lt;p&gt;而 ORM 作为一个能简化 CURD 操作、免去繁琐的查询语句编写的存在，是被广大的 Web 开发者所熟知。但是，目前 NebulaGraph 社区有 Golang 版本的 ORM &lt;a href=&quot;https://github.com/zhihu/norm&quot;&gt;norm&lt;/a&gt;、Java ORM &lt;a href=&quot;https://github.com/nebula-contrib/ngbatis&quot;&gt;NGBatis&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/nebula-contrib/graph-ocean&quot;&gt;graph-ocean&lt;/a&gt; 唯独没有 Hao 所熟悉的 Python 语言的 ORM。&lt;/p&gt;
&lt;p&gt;于是，做一个 NebulaGraph Python ORM 的想法便诞生了。&lt;/p&gt;
&lt;h2&gt;
&lt;a name=&quot;nebulagraph-python-orm-1&quot; class=&quot;anchor&quot; href=&quot;#nebulagraph-python-orm-1&quot;/&gt;NebulaGraph Python ORM&lt;/h2&gt;
&lt;h3&gt;
&lt;a name=&quot;nebula-carina-2&quot; class=&quot;anchor&quot; href=&quot;#nebula-carina-2&quot;/&gt;Nebula Carina 名字的由来&lt;/h3&gt;
&lt;p&gt;NebulaGraph Python ORM，又名 &lt;a href=&quot;https://github.com/nebula-contrib/nebula-carina&quot;&gt;nebula-carina&lt;/a&gt;，虽然目前只是一个雏形，但是已经基本上具备了一个 ORM 的基础功能。在命名 Python ORM 项目之时，Hao 先想到了 nebula-model，见名便知这是一个 ORM，搞了一些封装。但它不够优雅（&lt;s&gt;cool&lt;/s&gt;），所以 nebula-carina 便诞生了。&lt;/p&gt;
&lt;p&gt;Carina 船底座，/kəˈriːnə/，意为龙骨，是南半球可见最大的星云。而一个组件能成为一个 Nebula（星云）还挺酷的。&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;python-orm-3&quot; class=&quot;anchor&quot; href=&quot;#python-orm-3&quot;/&gt;Python ORM 功能设计&lt;/h3&gt;
&lt;p&gt;Nebula Carina 是用 Python 开发的针对 NebulaGraph + Python 的 ORM 框架。在设计上没有局限于 Web 框架，因此可以被应用在 Django、FastAPI 和 Flask 等主流框架上。&lt;/p&gt;
&lt;p&gt;目前，Nebula Carina 包含了常规的 schema 定义、对象管理器 object manager（雏形）、Model Builder（雏形），以及常见的图语言、MATCH 语句封装。雏形的意思是，这些功能具备了，但是暂时只有一、两个方法在里面，欢迎阅读本文的你一起来完善。除了基础功能之外，Nebula Carina 还支持了简单的 migration 功能，能够自动计算 schema model 结构与 DB schema 的差异，并同步 schema 到当前 space。但相较于其他成熟的 ORM 项目，例如：Django ORM，Nebula Carina 缺少可回溯性及树状结构来支持 migration 包含依赖、merge 数据。所以，Nebula Carina 未来考虑设计和支持包含依赖关系的 migration 系统。如果你对此有兴趣的话，欢迎来项目：&lt;a href=&quot;https://github.com/nebula-contrib/nebula-carina&quot;&gt;https://github.com/nebula-contrib/nebula-carina&lt;/a&gt; issue 区交流下。&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;python-orm-4&quot; class=&quot;anchor&quot; href=&quot;#python-orm-4&quot;/&gt;Python ORM 的神奇之处&lt;/h3&gt;
&lt;p&gt;上面简单说了下 Nebula Carina 是什么，有什么功能。在这里，我们来解决下“为什么要用 Nebula Carina”的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nebula Carina 首要应对的问题是快速解决轻量级 App 开发的常规需求&lt;/strong&gt;，虽然 NebulaGraph 具有极好的性能，诸如美团、快手等大企业都在使用。但大企业和小公司不同，大企业用图数据库会用非常重，像美团就直接开发了个图平台对接集团上百的业务线。而小公司的轻量级应用来说，它需要一个快速地生成简洁 schema。小公司的 Web 开发人员能非常容易地定义常用的、供于业务逻辑使用的 schema，再一键快速将 schema 同步到 space，而不需要去写些 SQL（这里指的是查询语句）来处理这些事项。此外，应对小公司的轻量级 App 开发需求，还需要支持 JSON 序列化和逆序列化来简化接口，不需要在接口处封装各类东西。最后，也是最重要的，为什么不用 Golang 之类的语言 ORM。Nebula Carina 采用了易于使用的 Python Data Model。Python 使用人员可以方便地用 Python 来调用、控制程序，像是打印，或者是在 Python Model 里面将 Dictionary 展开时拥有的 fields 都可以符合标准 Python 规范进行使用。&lt;/p&gt;
&lt;p&gt;此外，除了适用于任何的 Python Web Framework，Nebula Carina 也适用于裸 Python 开发，可与 AI 行业快速集成。毕竟像是 Machine Learning 之类的，十有八九是 Python 语言搞的，Nebula Carina 就可以轻松应用在 GNN、NLP 这些用图数据比较多的技术领域。&lt;/p&gt;
&lt;p&gt;总之，Nebula Carina 让 Python 开发者使用 NebulaGraph 时能把更多精力运用在业务/模型上，而非繁琐的数据库操作。&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;python-orm-5&quot; class=&quot;anchor&quot; href=&quot;#python-orm-5&quot;/&gt;Python ORM 设计实现&lt;/h3&gt;
&lt;p&gt;目前，Carina 的实现比较简单粗暴，由 4 个部分组成：&lt;strong&gt;settings&lt;/strong&gt;、&lt;strong&gt;nGQL 层&lt;/strong&gt;、&lt;strong&gt;model 层&lt;/strong&gt;和&lt;strong&gt;其他&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://nebula-website-cn.oss-cn-hangzhou.aliyuncs.com/nebula-blog/nebula-carina-feature.png&quot; alt=&quot;&quot; role=&quot;presentation&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;settings&lt;/strong&gt;，搞环境变量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nGQL 层&lt;/strong&gt;，有 connection、query、record、schema 和 statement：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;query，主要是 condition / match / … 语句封装&lt;/li&gt;
&lt;li&gt;record，主要是 vertex / edge 语句封装&lt;/li&gt;
&lt;li&gt;schema，封装了 Data Types、schema 语句、space 语句封装&lt;/li&gt;
&lt;li&gt;statements，主要是 Order By、Limit、Edge 定义、Edge Value、TTL、Alter 等 statements 的语句封装，statement 的意思是 state 某类行为；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;model 层&lt;/strong&gt;，主要是调用 nGQL 层的封装的 class 和当中的方法，来解决一些具体上层的问题。它包括 nebula-python 的 vertex / edge 转成 Carina 的 vertex model / edge model 的 &lt;strong&gt;protocol&lt;/strong&gt;，以及 field 和 model（schema model &amp;amp; data model）的封装，同绝大数编程语言的 ORM 类似，定义成某类语言常见的 class 进行封装，参见下方 Figure 类的示例说明；&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-python&quot;&gt;class Figure(models.TagModel):
    name: str = _(data_types.FixedString(30), ..., )
    age: int = _(data_types.Int16, ..., )
    valid_until: int = _(data_types.Int64, None, )
    hp: int = _(data_types.Int16, 100, )
    style: str = _(data_types.FixedString(10), &#x27;rap&#x27;, )
    is_virtual: bool = _(data_types.Bool, True)
    created_on: datetime = _(data_types.Datetime, data_types.Datetime.auto)
    some_dt: datetime = _(data_types.Datetime, datetime(2022, 1, 1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述示例代码，用 Figure class 继承 TagModel，在当中定义 tag 所需的这些 field，比如：name、age…Carina 就是采用这种方式来处理 NebulaGraph 中 Schema 结构；&lt;/p&gt;
&lt;p&gt;model 层中的 model builder 则是位于 nGQL 和纯 model 层之间的桥梁。它可以用来描述高层和低层之间的某种行为，比如说，下面的代码就定义了一个全局 MATCH 语句，而所有的 MATCH 语句都会走这样一个函数同 nGQL 层交互：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-python&quot;&gt;def match(
    pattern: str, to_model_dict: dict[str, Type[NebulaConvertableProtocol]],
    *, distinct_field: str = None,
    condition: Condition = None, order_by: OrderBy = None, limit: Limit = None
) -&amp;gt; Iterable[SingleMatchResult]:  # should be model
    output = &#x27;, &#x27;.join(
    (&quot;DISTINCT &quot; if key == distinct_field else &quot;&quot;) + key
    for key in to_model_dict.keys()
)
results = match(pattern, output, condition, order_by, limit)
return (
    SingleMatchResult({
        key: to_model_dict[key].from_nebula_db_cls(value.value)
        for key, value in zip(results.keys(), row.values) if key in to_model_dict
    }) for row in results.rows()
) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而 model 层的 object manager 会根据应用场景，基于 schema 为出发点，对 model builder 具体 match 语句进行操作，对这些操作行为搞了个高级封装；migrations 则负责封装 schema model 的变更并同步给数据库；&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;其他模块&lt;/strong&gt;，则是 Django 适配的 apps 和 setting。因为要支持 Django，它的思路同 FastAPI 不同，所以需要做适配来让 Carina 无缝衔接 Django；&lt;/p&gt;
&lt;h2&gt;
&lt;a name=&quot;nebula-carina-6&quot; class=&quot;anchor&quot; href=&quot;#nebula-carina-6&quot;/&gt;Nebula Carina 使用&lt;/h2&gt;
&lt;p&gt;下面举些例子来让大家了解下 Carina 的使用，主要还是摘录自 Carina 的 README：&lt;a href=&quot;https://github.com/nebula-contrib/nebula-carina&quot;&gt;https://github.com/nebula-contrib/nebula-carina&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;nebula-carina-7&quot; class=&quot;anchor&quot; href=&quot;#nebula-carina-7&quot;/&gt;安装 Nebula Carina&lt;/h3&gt;
&lt;p&gt;一句命令搞定&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell&quot;&gt;pip install nebula-carina
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果你用的是 Django，那么需要将 nebula_carina 添加到 INSTALLED_APPS，像是这样：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell&quot;&gt;INSTALLED_APPS = [
    ...
    &#x27;nebula_carina&#x27;,
    ...
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再在 &lt;code&gt;settings.py&lt;/code&gt; 文件中设置 CARINA_SETTINGS，主要配置一些同 NebulaGraph 有关的信息。像是这样：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell&quot;&gt;CARINA_SETTINGS = {
    &quot;auto_create_default_space_with_vid_desc&quot;: &quot;FIXED_STRING(20)&quot;, #创建默认图空间
    &quot;default_space&quot;: &quot;main&quot;, #图空间名
    &quot;max_connection_pool_size&quot;: 10, #连接数大小
    &quot;model_paths&quot;: [&quot;nebula.carina&quot;], #model 路径
    &quot;user_name&quot;: &quot;root&quot;, #登陆 NebulaGraph 的用户名
    &quot;password&quot;: &quot;1234&quot;, #登陆 NebulaGraph 的密码
    &quot;servers&quot;: [&quot;192.168.31.248:9669&quot;], # NebulaGraph graphd 服务所在服务器信息，可配置多个
    &quot;timezone_name&quot;: &quot;UTC&quot;, #服务器所用时区
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;目前 Carina 只有支持上述信息，后续会再增加其他字段。&lt;/p&gt;
&lt;p&gt;如果你用的是 FastAPI 之类的，用环境变量即可，具体的话可以参考项目文档：&lt;a href=&quot;https://github.com/nebula-contrib/nebula-carina#by-environment-variables&quot;&gt;https://github.com/nebula-contrib/nebula-carina#by-environment-variables&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;h-8&quot; class=&quot;anchor&quot; href=&quot;#h-8&quot;/&gt;图空间创建&lt;/h3&gt;
&lt;p&gt;你可以通过下面 Python 语句来创建 Space，当然你也可以像上面 CARINA_SETTINGS 一样，用 &lt;code&gt;&quot;auto_create_default_space_with_vid_desc&quot;: &quot;FIXED_STRING(20)&quot;&lt;/code&gt; 自动创建一个默认图空间。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-python&quot;&gt;from nebula_carina.ngql.schema.space import create_space, show_spaces, VidTypeEnum

main_space_name = &quot;main&quot;

if main_space_name not in show_spaces():
    create_space(main_space_name, (VidTypeEnum.FIXED_STRING, 20))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;
&lt;a name=&quot;schema-9&quot; class=&quot;anchor&quot; href=&quot;#schema-9&quot;/&gt;点边 schema 定义&lt;/h3&gt;
&lt;p&gt;同点 vertex 不同，一条边只有一个 edgetype，而一个点可以拥有多个 tag。所以在 Carina 中，Model 层的封装，&lt;code&gt;models.py&lt;/code&gt; 文件里引入了 &lt;code&gt;VirtualCharacter&lt;/code&gt; 的概念，在 &lt;code&gt;VirtualCharacter&lt;/code&gt; 类里，定义这个点拥有那些 tag。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-python&quot;&gt;class VirtualCharacter(models.VertexModel):
    figure: Figure
    source: Source
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个 &lt;code&gt;figure&lt;/code&gt; 就是一个 tag，&lt;code&gt;source&lt;/code&gt; 是另外一个 tag 的名字。这里 Figure 和 Source 都是具体的某个 tag 在 Carina 中的映射类名，在示例中，它就叫 Figure、Source。&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;h-10&quot; class=&quot;anchor&quot; href=&quot;#h-10&quot;/&gt;点边数据操作&lt;/h3&gt;
&lt;p&gt;上文提过 &lt;code&gt;VirtualCharacter&lt;/code&gt; 的概念，在 Data Model Mathod 里，像下面这种代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;VirtualCharacter(
    vid=&#x27;char_test1&#x27;, figure=Figure(
        name=&#x27;test1&#x27;, age=100, is_virtual=False, some_dt=datetime(2021, 3, 3, 0, 0, 0, 12)
    ), source=Source(name=&#x27;movie1&#x27;)
).save()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;是定义了一个 VID（唯一标识）为 char_test1 的点，它拥有个名为 Figure 的 tag，这个 tag 中有 name、age、is_virtual 之类的属性。此外，它还有一个 tag Source，Source tag 的属性 name 是 movie1。而 .save() 则是保存这段代码。&lt;/p&gt;
&lt;p&gt;同点类似，边的定义是这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-python&quot;&gt;EdgeModel(src_vid=&#x27;char_test1&#x27;, dst_vid=&#x27;char_test2&#x27;, ranking=0, edge_type=Love(way=&#x27;gun&#x27;, times=40)).save()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个语句主要表达了一条边的起点是 char_test1，终点是 char_test2，边的 rank 是 0，类型是 Love。而 Love 边类型有 2 个属性 way 和 times，&lt;img src=&quot;https://discuss-cdn.nebula-graph.com.cn/images/emoji/apple/joy.png?v=12&quot; title=&quot;:joy:&quot; class=&quot;emoji&quot; alt=&quot;:joy:&quot; loading=&quot;lazy&quot;/&gt; 也许这是一对相杀相爱的恋人，滚了 40 次。&lt;/p&gt;
&lt;h2&gt;
&lt;a name=&quot;nebula-carina-11&quot; class=&quot;anchor&quot; href=&quot;#nebula-carina-11&quot;/&gt;Nebula Carina 再升级&lt;/h2&gt;
&lt;p&gt;因为个人能力有限，在这里希望借助大家的力量。对 Nebula Carina 的未来规划，主要集中在这些方面&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;connection pool (v3.3.0)&lt;/li&gt;
&lt;li&gt;Indexes&lt;/li&gt;
&lt;li&gt;Go / Fetch /  Lookup statements封装&lt;/li&gt;
&lt;li&gt;Bulk操作封装&lt;/li&gt;
&lt;li&gt;Generic Vertex Model&lt;/li&gt;
&lt;li&gt;advanced migrations&lt;br/&gt;
…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;nebula-python 在 v3.3.0 中对 connection pool 做了原生支持，希望在未来 Carina 能结合这块内容更加完善。&lt;/p&gt;
&lt;p&gt;再者就是索引，上面其实提到过，Carina 目前就封装了 MATCH 语句，后续将会对 LOOKUP、GO、FETCH 之类的 statement 字句进行封装。&lt;/p&gt;
&lt;p&gt;然后是 Bulk 操作的封装，可以处理一次性创建大量数据。&lt;/p&gt;
&lt;p&gt;Generic Vertex Model 则是再抽象 vertex，用户不需要告诉程序它想得到什么样的 vertex，它的结构是如何的。直接通过虚拟结构进行定义，像是上面提到的 Figuer 和 Source，现在我不定义了，Generic Vertex Model 可以把这块抽象好，自己就搞定了。&lt;/p&gt;
&lt;p&gt;最后，之前也提到过的 advanced migrations，树状的 migration 可以搞定依赖关系。&lt;/p&gt;
&lt;p&gt;以上，便是 Hao 贡献的 NebulaGraph Python ORM 的简单介绍。如果你有改进、优化它的 idea，欢迎来 Carina issue 和 pr 区交流哟 &lt;a href=&quot;https://github.com/nebula-contrib/nebula-carina/issues/new&quot;&gt;https://github.com/nebula-contrib/nebula-carina/issues/new&lt;/a&gt;~&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;strong&gt;谢谢你读完本文&lt;/strong&gt; (///▽///)&lt;/p&gt;
&lt;p&gt;NebulaGraph Desktop，Windows 和 macOS 用户安装图数据库的绿色通道，10s 拉起搞定海量数据的图服务。通道传送门：&lt;a href=&quot;http://c.nxw.so/c0svX&quot; class=&quot;inline-onebox&quot;&gt;入门概览 - NebulaGraph Database 手册&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;想看源码的小伙伴可以前往 GitHub 阅读、使用、(^з^)-☆ star 它 → &lt;a href=&quot;http://c.nxw.so/8yTlk&quot;&gt;GitHub&lt;/a&gt;；和其他的 NebulaGraph 用户一起交流图数据库技术和应用技能，留下&lt;a href=&quot;http://c.nxw.so/9jvQN&quot;&gt;「你的名片」&lt;/a&gt;一起玩耍呢~&lt;/p&gt;
        &lt;/div&gt;

        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9be4accd37ece7c20b90aa7e0c0aae2d</guid>
<title>开箱即用，完整版 ChatGPT 克隆方案，开源了！</title>
<link>https://toutiao.io/k/mwebpmj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content              autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;公众号关注 “GitHubDaily”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设为 “&lt;/span&gt;&lt;span&gt;星标&lt;/span&gt;&lt;span&gt;”，每天带你逛 GitHub！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;316&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6453703703703704&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JKunUvtPFbY2bXnhpPc4yfhh6sOkjybYuVMv38g7QemW9wriaaGMZicqg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n2&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在过去的短短几个月，以 ChatGPT、GPT4 为代表的 AI 应用和大模型火爆全球，被视为开启了新的科技工业革命和 AGI （通用人工智能）的新起点。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n2&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;不仅科技巨头间你追我赶，争相推出新品，许多学术界、工业界的 AI 大佬也纷纷投入投身相关创业浪潮。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n94&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;生成式 AI 正以“天”为单位，快速迭代，持续狂飙！&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n3&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;然而，OpenAI 并未将其开源，它们背后的技术细节有哪些？如何快速跟进、追赶并参与到此轮技术浪潮中？如何降低 AI 大模型构建和应用的高昂成本？如何保护核心数据与知识产权不会因使用第三方大模型 API 外泄？&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n4&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;作为当下最受欢迎的开源 AI 大模型解决方案，GitHub 知名开源项目 Colossal-AI 率先建立了包含&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;监督数据集收集-&amp;gt;监督微调-&amp;gt;奖励模型训练-&amp;gt;强化学习微调的完整 RLHF 流程。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n4&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;以 LLaMA 为基础预训练模型，推出 ColossalChat，&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;是目前最接近 ChatGPT 原始技术方案的实用开源项目&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;!&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n5&quot; mdtype=&quot;paragraph&quot;&gt;开源地址：&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n6&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;包含以下内容&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n207&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n211&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Demo：可直接在线体验模型效果，无需注册或 waitinglist；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n213&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;训练代码：开源完整 RLHF 训练代码，已开源至含 7B 和 13B 两种模型；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n215&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;数据集：开源 104K 中、英双语数据集；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n217&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;推理部署：4bit 量化推理 70 亿参数模型仅需 4GB 显存；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n219&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;模型权重：仅需单台服务器少量算力即可快速复现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n221&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;更大规模模型、数据集、其他优化等将保持高速迭代添加。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 cid=&quot;n13&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;平价模型，强大能力&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n14&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 仅需不到百亿参数，在大语言模型的基础上进行 RLHF 微调，即可掌握中、英双语能力，达到与 ChatGPT 和 GPT-3.5 类似的效果。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;例如常识问答：&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;    &lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;542&quot; data-ratio=&quot;0.9805555555555555&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JIIHAD9oNWohZD73S3BenqFrb4R6UUibbuqY3f2ZbkEANeThFDiatPvnQ/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;中文应答：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n18&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J18szqASMnhIJakseaZYeypW3PMZZEfGrvWZF2jqbycn55oEgOqvsJw/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;225&quot; data-ratio=&quot;0.4064814814814815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8Jwibe6vMQ5JNw7RBicMdVs1x8UuHicGh349cYzP9TukVX3vyS8sPkP4sicA/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n19&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;写一封邮件：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n20&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JHThDAiaLS95O5WTyBDnnQFe826icGaKbeIFzpvgseaCI4tyctQJvQ0og/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;535&quot; data-ratio=&quot;0.9703703703703703&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JIqjXK2FylA8htLYEiak9OobJ6d2n5NVR17VPF4UIiasKgKhxaKuvVcyQ/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n21&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;写个算法：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n22&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J5hkib1561dwD0ia2x9iaje7OJmL6ldVbewLibJW7JFIia76ziaNPbo1Rb94A/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;345&quot; data-ratio=&quot;0.625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JSBc5CESMJrSscN34XQicia7XZ9B3tv49ELGdxbXT4gwNQPaDI1QmlnfA/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n23&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;完整 ChatGPT 克隆方案&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n24&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;尽管 ChatGPT 和 GPT-4 等 GPT 系列模型非常强大，但是它们不太可能被完全开源。幸运的是，开源社区一直在不断努力。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n25&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;例如 Meta 开源了 LLaMA 模型，该模型的参数量从 70 亿到 650 亿不等，130 亿参数即可胜过 1750 亿的 GPT-3 模型在大多数基准测试的表现。但是由于没有被指令微调（instruct tuning），因此实际生成效果不够理想。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n26&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;斯坦福的 Alpaca 通过调用OpenAI API，以 self-instruct 方式生成训练数据，使得仅有 70 亿参数的轻量级模型以极低成本微调后，即可获得媲美 GPT-3.5 这样千亿参数的超大规模语言模型的对话效果。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n27&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;但是&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;现有开源方案都可以被视为只得到了人类反馈强化学习（RLHF）中第一步的监督微调模型&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;，没有进行后续的对齐和微调工作。同时 Alpaca 的训练数据集过小，语料只有英文，也在一定程度上限制了模型的性能。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n28&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;而 &lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;ChatGPT 和 GPT-4 的惊艳效果，还在于将 RLHF 引入训练过程，使得生成内容更加符合人类价值观。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n29&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JnrZwqfDteVWoLqKzxniaYqqGnichIM47K5YgMNlOZLDAEXhmUeAPqZTQ/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;318&quot; data-ratio=&quot;0.5768518518518518&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J9Rk4EsLIRXBoJQNaSwnn2L9YO6Xod1T2AiaNVXlicLO25NBm6dw5Kicqg/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;span&gt;RLHF的三个阶段&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n31&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;基于 LLaMA 模型，Colossal-AI 首个开源包含完整 RLHF 流程的类Chat模型复现方案 ColossalChat，是目前&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;最接近 ChatGPT 原始技术路线&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;的实用开源项目!&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n32&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;训练数据集开源&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n33&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 开源了包含约 10 万条问答的中、英双语数据集。该数据集收集并清洗了社交平台上人们的真实提问场景作为种子数据集，利用 self-instruct 技术扩充数据，花费约 900 美元进行标注。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n33&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;对比其他 self-instruct 方法生成的数据集，该数据集的种子数据更加真实、丰富，生成的数据集涵盖的话题更多。该数据可以同时用于微调和 RLHF 训练。通过高质量的数据，ColossalChat 能进行更好地对话交互，同时支持中文。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n34&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JvvL8tOd8Zadr1FqAWBBicsNbKD3pnxHu4rCVGIhKr44LOm8vF11icO5g/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;245&quot; data-ratio=&quot;0.4425925925925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J82iamibvHrr6zQvqxlJ0sgib75DhdRQBhhPZYlnDSAoHibgb0Ojc3gsxMQ/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;span&gt;ColossalChat 数据集收集流程&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n36&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF算法复现&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n37&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF-Stage1 是 supervised-fintuning，即使用上文提到的数据集进行模型微调。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n38&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF-Stage2 训练了奖励模型，它通过对于同一个 prompt 的不同输出进行人工排序，得到对应分数，监督训练奖励模型。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n39&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF-Stage3 使用了强化学习算法，是训练流程中最复杂的一部分：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n40&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JbT9jGymUXtzGzcjYmpic6OJ7Ww3Iwz8Get0DGE8hiccMLiafPcxdiayOvg/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;240&quot; data-ratio=&quot;0.4361111111111111&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JQ6McNTvfpICsNFHcSbASII4ibAlEicrUtB2IsOwhEjBWGCHuZjXTpOJA/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;span&gt;RLHF-Stage3算法流程图&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n42&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 PPO 部分，ColossalChat 分为两个阶段进行：首先是 Make Experience 部分，利用 SFT 、Actor、RM、Critic 模型计算生成 Experience 存入 buffer 中；之后是参数更新部分，利用 Experience 计算策略损失和价值损失。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n43&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 PTX 部分，ColossalChat 计算 Actor 输出 response 和输入语料的回答部分的交叉熵损失函数，用来在 PPO 梯度中加入预训练梯度，以保持语言模型原有性能防止遗忘。最后将策略损失、价值损失和 PTX 损失加和进行反向传播和参数更新。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n44&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;快速上手&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n45&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 开源了基于 LLaMA 模型，复现训练 ChatGPT 三个阶段的完整代码。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n46&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;第一阶段，训练 SFT 模型：&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n47&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;# Training with a 4-GPU servers&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;colossalai run &lt;span&gt;--nproc_per_node&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; train_sft.py \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain&lt;/span&gt; &lt;span&gt;&quot;/path/to/LLaMa-7B/&quot;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--model&lt;/span&gt; &lt;span&gt;&#x27;llama&#x27;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--strategy&lt;/span&gt; colossalai_zero2 \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--log_interval&lt;/span&gt; &lt;span&gt;10&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--save_path&lt;/span&gt;  /path/to/Coati-7B \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--dataset&lt;/span&gt; /path/to/data.json \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--batch_size&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--accimulation_steps&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--lr&lt;/span&gt; 2e-5&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n50&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;第二阶段，训练奖励模型：&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n51&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;# Training with a 4-GPU servers&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;colossalai run &lt;span&gt;--nproc_per_node&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; train_reward_model.py \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain&lt;/span&gt; &lt;span&gt;&quot;/path/to/LLaMa-7B/&quot;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--model&lt;/span&gt; &lt;span&gt;&#x27;llama&#x27;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--strategy&lt;/span&gt; colossalai_zero2 \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--dataset&lt;/span&gt; /path/to/datasets&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n54&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;第三阶段，使用 RL 训练：&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n58&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;# Training with a 8-GPU servers&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;colossalai run &lt;span&gt;--nproc_per_node&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; train_prompts.py prompts.csv \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--strategy&lt;/span&gt; colossalai_zero2 \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain&lt;/span&gt; &lt;span&gt;&quot;/path/to/Coati-7B&quot;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--model&lt;/span&gt; &lt;span&gt;&#x27;llama&#x27;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain_dataset&lt;/span&gt; /path/to/dataset&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n102&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在获得最终模型权重后，还可通过量化降低推理硬件成本，并启动在线推理服务，仅需单张约 4GB 显存的 GPU 即可完成 70 亿参数模型推理服务部署。&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n59&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;python server.py /path/to/pretrained &lt;span&gt;--quant&lt;/span&gt; 4bit &lt;span&gt;--gptq_checkpoint&lt;/span&gt; /path/to/coati-7b-4bit-128g.pt &lt;span&gt;--gptq_group_size&lt;/span&gt; &lt;span&gt;128&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;h3 cid=&quot;n62&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;系统性能优化与开发加速&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n63&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 能够快速跟进 ChatGPT 完整 RLHF 流程复现，离不开 AI 大模型基础设施 Colossal-AI 及相关优化技术的底座支持，相同条件下&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;训练速度&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;相比 Alpaca 采用的 FSDP(Fully Sharded Data Parallel) &lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;可提升两倍以上&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n64&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;系统基础设施 Colossal-AI&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;AI 大模型开发系统 Colossal-AI 为该方案提供了基础支持，它可基于 PyTorch 高效快速部署 AI 大模型训练和推理，从而降低 AI 大模型应用的成本。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 由加州伯克利大学杰出教授 James Demmel 和新加坡国立大学校长青年教授尤洋领导开发。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;自开源以来，Colossal-AI 已经多次在 GitHub 热榜位列世界第一，获得 GitHub Star 约两万颗，并成功入选 SC、AAAI、PPoPP、CVPR、ISC 等国际 AI 与 HPC 顶级会议的官方教程。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n66&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;减少内存冗余的 ZeRO + Gemini&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n67&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 支持使用无冗余优化器 (ZeRO) 提高内存使用效率，低成本容纳更大模型，同时不影响计算粒度和通信效率。自动 Chunk 机制可以进一步提升 ZeRO 的性能，提高内存使用效率，减少通信次数并避免内存碎片。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n67&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;异构内存空间管理器 Gemini 支持将优化器状态从 GPU 显存卸载到 CPU 内存或硬盘空间，以突破 GPU 显存容量限制，扩展可训练模型的规模，降低 AI 大模型应用成本。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;使用 LoRA 低成本微调&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n69&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 支持使用低秩矩阵微调（LoRA）方法，对 AI 大模型进行低成本微调。LoRA 方法认为大语言模型是过参数化的，而在微调时，参数改变量是一个低秩矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n69&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;因此，可以将这个矩阵分解为两个更小的矩阵的乘积。在微调过程中，大模型的参数被固定，只有低秩矩阵参数被调整，从而显著减小了训练所需的参数量，并降低成本。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n70&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;低成本量化推理&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n71&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8Jib1fgkNuXmAqZGQhJPQKYEcibiaFMML9Rs1Q4a2P7Qdu4nstKjrQyiabyg/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;222&quot; data-ratio=&quot;0.4027777777777778&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J6wGqxOj6zvsT55ibn0OrlLtyuL5YU22op80TB9l2uQqqy1y6FxXiaF3Q/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;span&gt;GPTQ量化&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n73&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;为降低推理部署成本，Colossal-AI 使用 GPTQ 4bit 量化推理。在 GPT/OPT/BLOOM 类模型上，它比传统的RTN(rount-to-nearest) 量化技术能够获得更好的 Perplexity 效果。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n73&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;相比常见的 FP16 推理，它可将显存消耗降低75%，只损失极少量的吞吐速度与 Perplexity 性能。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n74&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;以 ColossalChat-7B 为例，在使用 4bit 量化推理时，70 亿参数模型仅需大约 4GB 显存即可完成短序列（生成长度为 128 ）推理，在普通消费级显卡上即可完成（例如 RTX 3060 Laptop），仅需一行代码即可使用。&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n75&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;args&lt;/span&gt;.&lt;span&gt;quant&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;&#x27;4bit&#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;model&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;load_quant&lt;/span&gt;(&lt;span&gt;args&lt;/span&gt;.&lt;span&gt;pretrained&lt;/span&gt;, &lt;span&gt;args&lt;/span&gt;.&lt;span&gt;gptq_checkpoint&lt;/span&gt;, &lt;span&gt;4&lt;/span&gt;, &lt;span&gt;args&lt;/span&gt;.&lt;span&gt;gptq_group_size&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n78&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;如果采用高效的异步卸载技术(offload)，还可以进一步降低显存要求，使用更低成本的硬件推理更大的模型。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n79&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;开放协作&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n80&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;尽管已经进一步引入RLHF，但由于算力和数据集有限，在部分场景下的实际性能仍有提升空间。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n81&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J9ib6IvdsLulXfz6W3EZ4Iic3E0icuFHM8NVgw0GsxTG7ajtldPIJjbgqQ/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;159&quot; data-ratio=&quot;0.287962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JxgkCCU0DicxUVLy2znwLibvX4FSOGYibyMGDkVjhv6jQjPEov2EiacwqWw/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n82&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;幸运的是，不同以往 AI 大模型与前沿技术仅由少数科技巨头垄断，PyTorch、Hugging Face 和 OpenAI 等开源社区与初创企业在本轮浪潮中也起到了关键作用。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n82&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;借鉴开源社区的成功经验，Colossal-AI 欢迎各方参与共建，拥抱大模型时代！&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n83&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;可通过以下方式联系或参与：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; cid=&quot;n84&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n191&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 GitHub 发布 issue 或提交 pull request (PR)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;2&quot; cid=&quot;n85&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n193&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;加入 Colossal-AI 用户微信或 Slack 群交流&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n195&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;发送正式合作提案到邮箱 &lt;/span&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;youy@comp.nus.edu.sg&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;3&quot; cid=&quot;n86&quot; mdtype=&quot;list&quot;/&gt;&lt;p cid=&quot;n87&quot; mdtype=&quot;paragraph&quot;&gt;开源地址：&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzAxOTcxNTIwNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28ia8xsyOClt8NDDCTAZNaDsEic4EEpUG1FPduFr5TUMK1GbDiaFX0qNCJiaS2XPfHzWlFicK95v1a9ic7Vg/0?wx_fmt=png&quot; data-nickname=&quot;GitHubDaily&quot; data-alias=&quot;GitHubDaily&quot; data-signature=&quot;专注于分享 GitHub 上知名的 Python、Java、Web、AI、数据分析等多个领域的优质学习资源、开源项目及开发者工具，为 GitHub 开发者提供优质编程资讯。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1cd9f2f8f5fd05c09688de685fb2cca8</guid>
<title>各大互联网公司喜欢用的“智能推荐”，具体有什么区别？</title>
<link>https://toutiao.io/k/91g2fmw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;container app-preview post-body&quot;&gt;
  &lt;div class=&quot;preview&quot;&gt;&lt;p&gt;智能推荐是一种根据用户行为、兴趣爱好等信息，为用户推荐相关内容或产品服务的人工智能技术。现已广泛应用于电商、社交媒体、品牌零售等行业。当前市面上智能推荐相关产品有很多，大致可分为以下几种类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.基于内容的推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于用户历史行为和偏好，系统可以推荐与用户之前喜欢的内容相似的新内容。它通常基于文本、图像、音频和视频等内容元素的相似度计算。例如，淘宝根据用户浏览和购买记录、搜索关键词以及商品属性等信息，向用户推荐具有相似属性或者风格的商品。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.协同过滤推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;协同过滤推荐是根据用户之间的行为相似性来推荐产品。如果两个用户在过去喜欢了相似的产品，那么当其中一个用户喜欢新产品时，系统可以将该新产品推荐给另一个用户。例如，豆瓣根据用户对电影的评分，向用户推荐喜欢同样类型电影的其他用户也喜欢的电影。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.混合推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;混合推荐结合了不同类型的推荐算法来推荐产品，以获得更好的推荐效果。例如，可以将基于内容的推荐与协同过滤推荐结合起来，以利用它们各自的优点来提高内容推荐的准确性和多样性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.实时推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实时推荐是指根据当前上下文和用户行为实时推荐产品。例如，如果用户在搜索某个特定主题时，系统可以根据用户的搜索行为和搜索历史，推荐与该主题相关的最新内容。例如，知乎根据用户发布的问题、回答以及浏览历史等信息，综合运用基于内容推荐和基于协同过滤推荐，在推荐相似问题的同时，也会推荐用户可能感兴趣的话题和用户。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.基于知识的推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于知识的推荐是一种利用领域知识来推荐产品的方法。例如，如果用户在搜索特定主题时，系统可以基于该主题的领域知识推荐相关的书籍、论文和其他学术资源。&lt;/p&gt;

&lt;p&gt;上述推荐算法各自具有不同的特点和应用场景。通常需要根据企业经营具体情况选择适当的智能推荐算法，以满足用户的需求和提高推荐的准确性和效果。&lt;/p&gt;

&lt;p&gt;神策智能推荐系统是一款基于用户行为分析的全流程智能推荐产品。它基于神策分析强大的数据采集能力，从用户行为数据的采集、数据建模、数据挖掘到效果分析，完成从“数据采集+推荐引擎+效果反馈”的推荐全流程。&lt;/p&gt;

&lt;p&gt;对比其他智能推荐系统，神策智能推荐系统拥有以下4大特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;完整性：实现采集、推荐、反馈的完整推荐闭环&lt;/li&gt;
&lt;li&gt;开放性：推荐算法的白盒，开放全平台的算法逻辑&lt;/li&gt;
&lt;li&gt;指标灵活性：可自定义多指标、漏斗转化评价能力&lt;/li&gt;
&lt;li&gt;算法迭代能力强：数据反馈与问题定位，实现算法精准迭代&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;神策智能推荐系统能够帮助企业实现对用户“千人千面”的个性化内容推荐，改善用户体验，持续提升核心业务指标。&lt;/p&gt;

&lt;p&gt;欢迎前往神策数据官网免费体验！&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a9b719e3334c467a6c80b971698593ad</guid>
<title>图解 Git 工作原理</title>
<link>https://toutiao.io/k/nvavx18</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文图解Git中的最常用命令。如果你稍微理解Git的工作原理，这篇文章能够让你理解的更透彻。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基本用法&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3626373626373626&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdVldJGOGXuibWZGhib6OyVXMic1ZznAwYtO2eFpicV29aUVpNpwCMDia6B4w/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;728&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的四条命令在工作目录、暂存目录（也叫做索引）和仓库之间复制文件。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;git add files把当前文件放入暂存区域。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git commit给暂存区域生成快照并提交。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git reset – files用来撤销最后一次git add files，你也可以用git reset撤销所有暂存区域文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git checkout – files把文件从暂存区域复制到工作目录，用来丢弃本地修改。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可以用git reset -p，git checkout -p，or git add -p进入交互模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也可以跳过暂存区域直接从仓库取出文件或者直接提交代码。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.30484988452655887&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdYReXDk7rS1rOicCQ7WtiagoMiaicu2xX2XmnNtiaiariayeskukH5fu1J3UibQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;866&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;git commit -a相当于运行git add把所有当前目录下的文件加入暂存区域再运行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git commit files进行一次包含最后一次提交加上工作目录中文件快照的提交。并且文件被添加到暂存区域。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git checkout HEAD – files回滚到复制最后一次提交。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;约定&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后文中以下面的形式使用图片。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43441636582430804&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdbdwYDx6TQR4KD6FWsr2B8UI1QBYzIlp7LGzmSLG1DU0Z1gUESMqGDg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;绿色的5位字符表示提交的ID，分别指向父节点。分支用橘色显示，分别指向特定的提交。当前分支由附在其上的HEAD标识。这张图片里显示最后5次提交，ed489是最新提交。master分支指向此次提交，另一个maint分支指向祖父提交节点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;命令详解&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Diff&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有许多种方法查看两次提交之间的变动，下面是一些示例。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42839951865222625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdDpAGboibbjp15iaKlk0LyveH5aibicWiaibs0icmJgohye76ojHT8gBOVQA3w/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Commit&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提交时，Git用暂存区域的文件创建一个新的提交，并把此时的节点设为父节点。然后把当前分支指向新的提交节点。下图中，当前分支是master。在运行命令之前，master指向ed489，提交后，master指向新的节点f0cec并以ed489作为父节点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdVZvuXkGQXTnibv4hkRL3ALkCXGibtgPicPgmTjllf8dRg7sJ9PNozzOaQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即便当前分支是某次提交的祖父节点，Git会同样操作。下图中，在master分支的祖父节点maint分支进行一次提交，生成了1800b。这样，maint分支就不再是master分支的祖父节点。此时，合并[1]（或者衍合[2]）是必须的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacduYic50KBcqN9pwAdTEJDI63zxQTx8aapgIkopvqXCDwK1UpQUf9icypg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果想更改一次提交，使用git commit –amend。Git会使用与当前提交相同的父节点进行一次新提交，旧的提交会被取消。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdrSBGHl2PZIfsTticrNYGQDgQqLC1Zn7rJVicpIJaJXDkiaVjrAnbfh0Bw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一个例子是分离HEAD提交[3]，后文讲。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Checkout&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Checkout命令用于从历史提交（或者暂存区域）中拷贝文件到工作目录，也可用于切换分支。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当给定某个文件名（或者打开-p选项，或者文件名和-p选项同时打开）时，Git会从指定的提交中拷贝文件到暂存区域和工作目录。比如，git checkout HEAD~ foo.c会将提交节点HEAD~（即当前提交节点的父节点）中的foo.c复制到工作目录并且加到暂存区域中。（如果命令中没有指定提交节点，则会从暂存区域中拷贝内容。）注意当前分支不会发生变化。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4368231046931408&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacd3nvKaac5eIaNEa0ibH7D3HGJRNHA57Vc8icte35clLq7sbOCo41Q9uKA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当不指定文件名，而是给出一个（本地）分支时，那么HEAD标识会移动到那个分支（也就是说，我们“切换”到那个分支了），然后暂存区域和工作目录中的内容会和HEAD对应的提交节点一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新提交节点（下图中的a47c3）中的所有文件都会被复制（到暂存区域和工作目录中）；只存在于老的提交节点（ed489）中的文件会被删除；不属于上述两者的文件会被忽略，不受影响。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacd4njffFGDBaiaiawib1jv6eS5umZXNwl0jdVibDlCdZrSN0aT6JGYgu2bYQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果既没有指定文件名，也没有指定分支名，而是一个标签、远程分支、SHA-1值或者是像master~3类似的东西，就得到一个匿名分支，称作detached HEAD（被分离的HEAD标识）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样可以很方便地在历史版本之间互相切换。比如说你想要编译1.6.6.1版本的Git，你可以运行git checkout v1.6.6.1（这是一个标签，而非分支名），编译，安装，然后切换回另一个分支，比如说git checkout master。然而，当提交操作涉及到“分离的HEAD”时，其行为会略有不同，详情见在下面。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdVxGHWej6PnlIiaoREvuQrnIicXPaltU9SAJ72TbePvOtA0icELZOlYcdg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;HEAD标识处于分离状态时的提交操作&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当HEAD处于分离状态（不依附于任一分支）时，提交操作可以正常进行，但是不会更新任何已命名的分支。（你可以认为这是在更新一个匿名分支。）&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdIknsiaJ60s2S1aYoPyn4qjkn9YepPUcpXosgNicGSKo2lEV7MmYL3bwQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦此后你切换到别的分支，比如说master，那么这个提交节点（可能）再也不会被引用到，然后就会被丢弃掉了。注意这个命令之后就不会有东西引用2eecb。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdtUMpFj1s3iaVAHc8OdO1nQNpE1OFqibZca2gGhDib6GOgAvC1HUdJeUFg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，如果你想保存这个状态，可以用命令git checkout -b name来创建一个新的分支。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdQ9sMJahbLwjLRUCcWBX9IX4TAPZDg4zYmCHmtKwdD1JO0K8IQ1678A/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Reset&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Reset命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不给选项，那么当前分支指向到那个提交。如果用–hard选项，那么工作目录也更新，如果用–soft选项，那么都不变。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4368231046931408&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdg7cp5MbL5g78655RSGxzh9xLFapI79n5WGbicWSMSwA3zickCZlnslicw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果没有给出提交点的版本号，那么默认用HEAD。这样，分支指向不变，但是索引会回滚到最后一次提交，如果用–hard选项，工作目录也同样。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdlpE3ic4w3pOznB3LDhric6FYMjPLiam2d9eytrmcKJ32f1wrYw41Q6YHw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果给了文件名（或者-p选项），那么工作效果和带文件名的checkout差不多，除了索引被更新。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdIkvt4DjfTJp02cNdxicsCPWLAxEVwWyicG0Vh0PG94prKJJMEjORdzZg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Merge&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Merge命令把不同分支合并起来。合并前，索引必须和当前提交相同。如果另一个分支是当前提交的祖父节点，那么合并命令将什么也不做。另一种情况是如果当前提交是另一个分支的祖父节点，就导致fast-forward合并。指向只是简单的移动，并生成一个新的提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdxsnHyTf9U6NVM6iasdyop8ZFMDtINC7qYhzfpp84ECg8ArLPiauXX2iag/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;否则就是一次真正的合并。默认把当前提交（ed489 如下所示）和另一个提交（33104）以及他们的共同祖父节点（b325c）进行一次三方合并[4]。结果是先保存当前目录和索引，然后和父节点33104一起做一次新提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46690734055354993&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdDFSlUbw008ODVcP0qlj9FF1kpMV1ZsQSzX5BspvfkiajVaE2q428oibQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Cherry Pick&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;cherry-pick命令“复制”一个提交节点并在当前分支做一次完全一样的新提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdlGk2GCEeqNdG4opRvmPcxglggpuYSJ2OibqKtrk6k3CHeia1Uc9ewOVw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Rebase&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;衍合是合并命令的另一种选择。合并把两个父分支合并进行一次提交，提交历史不是线性的。衍合在当前分支上重演另一个分支的历史，提交历史是线性的。本质上，这是线性化的自动的 cherry-pick。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdNpPX70icDA8vR1DKM7B0HATDmibTGZoLVvtKzH6RVwabwddKRfa3wefQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的命令都在topic分支中进行，而不是master分支，在master分支上重演，并且把分支指向新的节点。注意旧提交没有被引用，将被回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要限制回滚范围，使用–onto选项。下面的命令在master分支上重演当前分支从169a6以来的最近几个提交，即2c33a。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdEy3uLQL1VCFeOsGeC1uaVM6UPwiafbiaycrzpnWBujErcic7sH1SIYmcQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样有git rebase –interactive让你更方便的完成一些复杂操作，比如丢弃、重排、修改、合并提交。没有图片体现这些，细节看这里：git-rebase(1)[5]。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;技术说明&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;文件内容并没有真正存储在索引（.git/index）或者提交对象中，而是以blob的形式分别存储在数据库中（.git/objects），并用SHA-1值来校验。索引文件用识别码列出相关的blob文件以及别的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于提交来说，以树（tree）的形式存储，同样用对于的哈希值识别。树对应着工作目录中的文件夹，树中包含的 树或者blob对象对应着相应的子目录和文件。每次提交都存储下它的上一级树的识别码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果用detached HEAD提交，那么最后一次提交会被the reflog for HEAD引用。但是过一段时间就失效，最终被回收，与git commit –amend或者git rebase很像。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相关链接：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;http://marklodato.github.io/visual-git-guide/index-zh-cn.html#merge&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://marklodato.github.io/visual-git-guide/index-zh-cn.html#detached&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://en.wikipedia.org/wiki/Three-way_merge&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://www.kernel.org/pub/software/scm/git/docs/git-rebase.html#_interactive_mode&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>