<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f81fa78f47a5b5cbbc2d830743e8356d</guid>
<title>团队一盘散沙，怎么破？</title>
<link>https://toutiao.io/k/kdzpdh5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原创不易，求分享、求一键三连&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近有个粉丝问了一道&lt;strong&gt;大题&lt;/strong&gt;：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;blockquote&gt;&lt;p&gt;小钗，我最近空降到一个小公司做技术负责人，感觉团队士气很低，同学们要么有力无处使，要么常规摸鱼，这种一盘散沙的团队该如何带呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;这道题我还真会！&lt;/strong&gt;只不过这是一道大题，没那么简单，需要大家耐着性子读完，这里先给出解题思路：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;直面问题，分析成因；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;目标确定，合理分解；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;梯队确定，奖善罚恶；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;资源确定，粮草先行；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;机制流程，抹平障碍；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来我们现身说法，依次分解。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;直面问题，分析成因&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;顶层梳理&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队为什么会一团散沙，首先要有自己的基本判断，比如我们团队的问题是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;去年有一次比较大的团队合并，单就技术团队算是150+120的合并规模，正常情况，这种合并效果都不会太好，加上互联网寒冬，所以导致了第二个问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后疫情时代，降本增效成了很多公司的主题，与多数公司一样，我们进行了大规模的人员优化，半年优化量多达70%！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;人员优化倒是完成了，而服务规模却未减少。单后端来说，当前103个服务无人维护；少数核心同学维护服务又超过70个，风险很大，却又无可奈何。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;几轮人员优化下来，剩下的同学不免人心惶惶，而这个时期负责人也难以打包票&lt;strong&gt;不会再发生&lt;/strong&gt;，而且正常情况这时候应该有一波团队激励，但这次情况特殊，整个公司都锁死了，于是粮草也不足...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;人的问题盘点完，还要盘点事的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队合并导致的最大问题是两套技术体系，特别是后端完全是两个技术栈：Golang、Java，在后端整体人数受限的情况下，很难重用，直接导致战斗力减半！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此常见的业务历史债就不多赘述了，每个团队都有，就看严重程度了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，双技术栈加上几波裁员情况下，30%团队要维护原来100%的业务，还没加薪，这个团队士气不低就奇怪了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自己有了初步判断后，还得收集一线同学的想法。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基层视角&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;收集一线信息的方法比较简单，发一个调查问卷，再找几个关键人聊天即可：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;你觉得当前团队最大的问题是什么；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你觉得产生这些问题的原因是什么；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你觉得该如何处理；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由此可以形成一个脑图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.636726546906188&quot; data-type=&quot;png&quot; data-w=&quot;501&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTAhJicnwkIFHbXOTYtyvH1rf80d8KfMCCibXl1OaIdASvfOyOJb5drHB2dFWicJ0jFweQgIaWMqWFibVA/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，一线同学看到的点跟我们的认知还是统一的：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;历史债重；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;激励不足；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;氛围不好；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;业务拉胯；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;目标不清晰；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;...&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;貌似这个比我们两年前遇到的问题更糟糕了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;3.198148148148148&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTAhJicnwkIFHbXOTYtyvH1rf729yroAPpV0sv2uIQhjrr0CQlP3faH6ic6aAfj142GURFnbq4cQictSg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比较有意思的是，其中一些问题之前已经解决，但是过一段时间后又回来了，所以这个过程总是循环往复啊，那么如何解决呢？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;目标是什么：选题&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的选题，就是把自己的疑惑，将业务中碰到的问题，整理成一些课题，将这些课题指派给团队的“专家组”进行研讨，找到答案形成方案，选题的重点有二：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;找准问题；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;问题切割；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;工作中问题很多，不能眉毛胡子一把抓，要发现主要矛盾是什么，要有优先级，所以一定要找准要解决的问题，集中资源解决；找准问题后要做问题切割，问题大了资源不足做不了，问题小了没有效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;思考选题时要卷入足够的资源、足够的意见，但不要被轻易带偏，要有自己的坚持，自己的主见，选题能力就是战略能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，现在有那么多问题，我们要先解决什么，后解决什么，光说不练假把式，一起来实操下吧！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;俗话说得好，兵草未动，粮草先行，如果人心不稳，就算有明确的目标也没人想做，所以第一步是稳住人，众所周知，稳住人最好的办法是&lt;strong&gt;给他钱&lt;/strong&gt;或者&lt;strong&gt;帮他成长&lt;/strong&gt;能赚更多钱。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面说了，今年情况特殊，想要加钱是比较难的，但比较难并非不能实现，只不过这种时候要站在公司角度思考问题：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;我为什么要给你钱；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我应该给谁钱；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;怎么证明这笔钱花得值；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;公司事实上也不是一毛不拔的，毕竟还要维持运营，但公司需要识别谁是团队可用之才，并且需要证据链，这种时候由于屁股问题，不能听负责人的一面之词了，所以我们需要准备证据链，做两个事：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;识别团队人才；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;证明人才的ROI；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何做呢，有一个简单的解法是，证明人才同等时间做的事情更多更好就行了，而高级程序员的效率相较初级程序员确实会高不少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们这里第一个要实现的目标是：&lt;strong&gt;找出团队不可或缺的20%，并证明他们优秀，想办法说服公司给予激励&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个目标是帮他成长，那么对应的&lt;strong&gt;梯队建设&lt;/strong&gt;，上升通道以及人才运营机制需要重新设计并维护起来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;粮草只能暂时解决人才焦虑问题，远大的目标才能让所有人走得更远，关于目标问题有几个点要注意：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;技术团队难以影响业务团队目标，所以不要妄图&lt;strong&gt;技术驱动业务&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;现阶段技术基建资源会很有限，所以不可能有太多资源&lt;strong&gt;投入技术基建&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;新的目标要可达成、有成就感、并且技术说了可以算；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总而言之，要让技术有尊严，最好能解决&lt;strong&gt;安全感&lt;/strong&gt;问题，那么这只有一条路可以走：&lt;strong&gt;创造营收，甚至自己养活一部分自己！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何做呢，这里有个&lt;strong&gt;“比较摆烂”&lt;/strong&gt;的策略：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;开展外包业务；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;开展技术培训业务；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也不要看到&lt;strong&gt;外包&lt;/strong&gt;就难受，如果跟业务方撕逼的时候真的将自己当外包团队，很多问题可以迎刃而解：&lt;strong&gt;别跟我扯犊子，什么排期我都行，只不过得加钱！&lt;/strong&gt;并且，外公司都是这么给钱的！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有几个点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;搞定老板，让他同意；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;真要外包，最多解决团队10%的人力成本就行，有个证明就行，不用占比太多；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;搞培训的话，优先抓大学生，有好的苗子可以留下培养；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上把自己当外包团队是个很妙的想法，团队内部的关注点都会逐渐转移至：&lt;strong&gt;如何养活自己&lt;/strong&gt;；团队外部对于一些不认可的业务方，便可以堂而皇之的降低其需求优先级了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体效果，等我试过后跟大家聊，这里有个一定要注意的点：&lt;strong&gt;不要把主业务搞崩了&lt;/strong&gt;，注意尺度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，这里可以给团队设定第三个目标：&lt;strong&gt;技术团队承担人力成本的10%！&lt;/strong&gt;，具体赚的钱可以跟公司分账，具体怎么分要聊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是为了保证生存，依旧要有保证核心业务的目标，不然就真做成外包团队了...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面提了一下成长问题，但公司级的上升通道建设，职级体系还是得有，如果公司这块不成熟，需要推动建设。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么职级体系很重要呢，因为升职一般伴随着加薪，所有人都看着的呢，需要规定&lt;strong&gt;做了什么工作可以获得什么成就。&lt;/strong&gt;其实只要职级体系做得好，可以解决很大的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队需要做的是将培训和分享做起来，特别是针对Leader层的干训班，具体怎么做后面有介绍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，第四、五个目标是将团队的&lt;strong&gt;职级体系搭起来&lt;/strong&gt;，其次要把&lt;strong&gt;内部培训分享搞起来&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解决了主观能动性和目标问题，接下来就要解决环境问题，要去实地考察当前环境中什么流程是多余的，什么是割裂的，多的流程要去掉，没有的流程要补，所以第六个目标是：&lt;strong&gt;核心机制流程补足&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后总结一下，为了解决我们的问题，我们提出了以下目标：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;找出团队不可或缺的20%，并证明他们优秀，想办法说服公司给予激励；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;梯队建设（职级体系+分享培训体系）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;技术团队承担人力成本的10%；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;核心机制流程补足；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来依次说说每个目标的实现思路。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;人才识别&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一步依旧是要想办法要钱，这里第一个问题就是如何证明我优秀，这里的实操思路是：&lt;strong&gt;统计每个人每周/月完成了多少任务&lt;/strong&gt;，步骤是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;周会、项目日会等会上提出待完成的任务；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;将任务分给不同的人；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;任务完成后，进行简单任务定级，存档；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;任务一般是一周以内的工作，任务过大应该被设置为OKR，然后在OKR的基础下再分解任务，所以一个周期结束，可以看到所有人完成的任务以及完成了什么样的任务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理想的情况下还可以对任务定价，那么一个人一个月赚了多少钱可以计算出来，最后任务赚来的钱/员工工资，ROI就出来了...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你拿到所有人的所有任务，并可以细化到每个人的ROI去找老板聊天的时候，相信我，他首先会给你钱，其次会让你把这套工具复用到整个公司。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;衍生一下，如果以任务为单位的形式运行的好的话，是可以算出业务方的需求价值的，如果业务方的需求没有外包的需求价值高，还可以反向PUA。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;萦绕很久的效能度量问题，结果被市场经济运作下的外包模式解决了，我真的是醉了！&lt;/strong&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;梯队建设&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的梯队建设核心围绕着上升通道（职级体系）与分享培训体系展开。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上升通道首先必须拉着HR玩，让他定义清楚当前部门的职级，并且每年什么时候达成什么条件可以升级，升级后的匹配奖励是是什么，没有这个东西，大家都只能抓瞎！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于团队成长还是首推三件事：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;CaseStudy；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;干训班培训；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;技术分享；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中技术分享不多说，说下CS与干训班：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对平时工作中爆发的工程或组织问题，需要责任人写CS（CaseStudy）文档，每周二下午，相关人一起做复盘的机制，旨在杜绝类似问题产生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于如何做CaseStudy的文章，之前复盘时候介绍了，这里不展开。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一路打怪（做项目、OKR）升级，如果”运气好“成为小leader，那么就进入了干训班辐射范围，干训班事实上更多是面向经理的”福利“，帮助经理建立管理认知的培训实践课程，比如就会涉及以下信息：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;向上管理怎么做，如何拿到资源；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跨部门沟通的诀窍，我为什么要配合你；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;从理论到实战的差距是什么；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如何用数据说话；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;系统性解决问题，竖井效应与内卷；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;...&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些培训一般由几种元素构成（不是每个案例都会完整覆盖）：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;事件案例 -&amp;gt; 案例分析 -&amp;gt; 观点阐述 -&amp;gt; 理论、机制形成 -&amp;gt; 讨论（辩论）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果案例本身比较经典，再进一步会考虑：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要不要纳入团队机制 -&amp;gt; HowTo -&amp;gt; OKR -&amp;gt; 执行人 -&amp;gt; 形成团队案例 -&amp;gt; ......&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个公司案例不尽相同，大家不可完全套用。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;营收思路&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;技术话语权弱，也是一个长时间萦绕心间的问题，其实想要话语权只需要做两件事：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;带来营收；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;证明自己跟营收有绝对联系；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前我的想法是自己跨出圈子去做业务方，这样就能带来营收了，但是转念一想，这个其实只能证明我能带来营收，并不能证明技术团队能带来营收；而强行跟业务方拉关系，分他们的营收蛋糕，无异于低人一等，都不是好的解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，如果将自己作为&lt;strong&gt;外包团队&lt;/strong&gt;，在市场经济下，似乎情况又有所变化，我们只需要说服老板：&lt;strong&gt;我们可以自己养活自己&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来的操作就是，所有的业务方跟技术团队提需求，我们先说好一个需求多少钱，你如果不满意可以真的去找外包，这么一来的话，技术团队其实是处于公司的外包团队，我们可以选择不接有些需求：&lt;strong&gt;对不起，你那个需求太烂了，钱也少，我们不做，你去找外包吧&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们是用自身的技术能力赚取服务费用，我们&lt;strong&gt;自己养活了自己&lt;/strong&gt;，当然，不可避免可能会谈崩几次，导致赚钱的费用不足以覆盖所有技术的人力成本，这个时候就只有两个方案：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;裁员；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;接外包；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;站起来肯定要付出一些代价，但越做越小肯定不是我们的初衷，所以真实的方案只有接外包一途，这里要注意：&lt;strong&gt;接外包不可太过&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;外包带来的营收不要超过团队的10%，或者能够保证不裁员就好，不要接太多，因为多少还是有点&lt;strong&gt;不务正业的&lt;/strong&gt;，尝到甜头乐此不疲可能真的演变成外包团队，那不会是团队想要的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于如何接到外包，这个是个商务问题，大家自己去思考吧。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;流程机制&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大目标定了，如何让目标执行的更顺畅，这就需要流程机制的匹配了，比如：业务团队如何采买服务能力，如何定价，财务如何结算等等都需要有一套完整的流程，并且需要&lt;strong&gt;系统化！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是我们需要一套内部管理工具来匹配这些目标，我这里的思路是：实现了一套以任务为核心的OKR系统，具体系统如何，使用过后再拿出来分享吧。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后回到问题本身，如果当前团队一团散沙，首先要思考钱的问题，没钱的激励人们很难有启动的动力；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队初步启动后要思考目标的问题，找准当前问题的核心，和当前环境最适合解决什么；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目标落定后要解决环境问题，匹配对应的流程机制，让目标更容易发生，具体到目标实现的时候，一定要注意目标切割，先打造小案例，实现小目标，激励大家的信心，一步一步，后续就会顺畅很多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，今天的分享就到这。如果本文对你有帮助的话，欢迎&lt;strong&gt;点赞&amp;amp;评论&amp;amp;在看&amp;amp;分享&lt;/strong&gt;，这对我非常重要，感谢🙏🏻。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要更多交流可以加我微信：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5549076773566569&quot; data-type=&quot;png&quot; data-w=&quot;2058&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTAhJicnwkIFHbXOTYtyvH1rfP2N5l9gf7IviaxXFYHQ4KTAKBPjwHurzRTeIWRz55USveXYiaPNXaWMA/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9cfac4b2751da44d99562ee6d23143bf</guid>
<title>社区点赞业务缓存设计优化探索</title>
<link>https://toutiao.io/k/rplztap</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;h1&gt;&lt;strong&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内容点赞业务在得物社区中是一个非常高频的业务场景，功能本身复杂度不高，但是业务场景多、QPS高、而且由于社区的用户体量，整体点赞的数据量非常大。其中最核心、对响应性能要求最高的主要是“用户是否点赞内容”和“内容点赞数”场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在得物社区中凡是有内容消费的场景，都会有上面两个点赞场景的处理，所以整体点赞业务的&lt;span&gt;QPS&lt;/span&gt;在社区都是非常高的。当我们在刷各种Feed流时，每一次下滑，都需要对数十篇内容进行登录用户是否点赞状态的判断。作为基础业务，内容点赞业务的高性能响应，对上游内容场景的消费体验有极大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文对得物社区的点赞业务如何做到高性能响应以及历史上在缓存使用上关于高性能、稳定性、低成本上的优化探索过程进行讲述，希望能给读者带来一些收获。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;演进探索&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;v1.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社区各种Feed流及内容详情页“登录用户是否已点赞内容” “内容被赞总数” “内容最新点赞用户列表”几个场景消费展示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点赞业务整体的高性能是基于Redis+MySQL架构。&lt;span&gt;M&lt;/span&gt;&lt;span&gt;y&lt;/span&gt;&lt;span&gt;SQL&lt;/span&gt;做数据存储和查询支持，Redis撑起业务的高性能响应。在1.0版本中，服务架构还是单体PHP服务，技术方案上将动态下所有的点赞用户查询出来放到PHP数组里，然后序列化为Json字符串以Key/Value的方式存储到Redis中，当用户浏览内容时，取出缓存数据，反序列化Json为PHP数组，然后通过in_array和count方法判断是否已点赞及内容点赞数。在缓存的维护上，则是每一次有新用户点赞或取消赞则直接清除Redis。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构图下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ini&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cId =&amp;gt; &#x27;[uid1,uid2,uid3...]&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;786&quot; data-backw=&quot;578&quot; data-ratio=&quot;1.3598553345388789&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLjVTPsuVkaBsIeRZTsHhGAY8ggzlZOCtJStdKJYpXibsic3GdbRTVropw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1106&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;主要问题&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个版本的方案存在比较多待优化点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一、缓存构造时要查询动态下所有点赞用户数据，数据量大，容易产生慢SQL，对DB和带宽都可能有比较大的压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二、缓存存储数据结构上为Key/Value结构，每次使用时需先从Redis查询，再反序列化成PHP数组，in_array()和count()方法都有比较大的开销，尤其是查询热门动态时，对服务器的CPU和MEM资源都有一定浪费，对Redis也产生了比较大的网络带宽开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三、缓存维护上，每次新增点赞都直接清除缓存，热门动态大量点赞操作下会出现缓存击穿，会造成大量DB回查操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;v2.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家都知道一些热点事件很容易在社区中发酵，得物社区自然也存在这种情况。在某一场热点事件中，得物社区瞬间出现多篇热点内容，大量用户进入得物社区浏览相关动态并点赞，从v1.0版本的点赞维护流程上可以看出执行缺陷，即每次有新点赞都会清除缓存！当有大量用户浏览热点动态，同时又有大量用户在点赞而导致缓存清除的场景下，缓存被击穿的风险非常高，这样会导致大量查询请求打到DB层，研发侧在评估风险之后，连夜进行了缓存改造。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、解决热点内容缓存击穿的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、优化代码层面对缓存数据序列化和反序列化导致的服务器资源消耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次改造，除了优化解决缓存击穿的风险外，也针对之前缓存本身的一些不足之处，思考了一些更高效的实现。在缓存数据结构上摒弃了之前的Key/Value结构，采用了集合结构。集合的特性保证集合中的用户ID不会出现重复，可以准确维护了动态下的点赞总数，通过查看用户是否在集合中，可以高效判断用户是否点赞内容。这样解决每次查询时需要从Redis中获取全部数据和每次需要代码解析Json的过程，Redis集合支持直接通过&lt;strong&gt;SISMEMBER&lt;/strong&gt;和&lt;strong&gt;SCARD&lt;/strong&gt;接口判断是否赞和计算点赞数，从而提升了整个模块的响应速度和服务负载。在缓存维护上，每次有新增点赞时，主动向集合中添加用户ID，并更新缓存过期时间。每次查询时，也同样会查询缓存的剩余过期时间，如果低于三分之一，就会重新更新过期时间，这样避免了热门动态有大量新增点赞动作时，出现缓存击穿的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ini&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid =&amp;gt; [uid1,uid2,uid3...]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.191806331471136&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLDicyrXfQaoxKX0pl0RxZib22Cb6ITapfXbxszeTZiau4noCLntDOZWvgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1074&quot;/&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;主要问题&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在技术方案中，会将动态下全部的点赞记录全部查出，放入一个集合中，当动态是一个热门动态时，点赞用户量会非常大，此时集合变成了一个大Key，而大Key的清理对Redis的稳定性有比较大的影响，随时可能会因为缓存过期，而引起Redis的抖动，进而引起服务的抖动。并且每次查询出全部的点赞用户，容易产生慢SQL，对网络带宽也比较有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;v3.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、解决V2.0版本中缓存大Key风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、优化缓存重建时查询内容全部点赞用户产生的慢SQL场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在3.0版本中，对大Key进行了打散处理，对同一个动态下的点赞用户，进行打散分片再维护到缓存，每次操作缓存时先根据用户ID计算分片值，这样每个分片都具有更小的体积和更快的维护和响应速度。而点赞总数的获取，此时社区服务已经迁移到Go服务架构，我们也搭建了单独的计数服务，单独维护内容的被赞总数，节省了scard接口的消耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;makefile&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid_slice1 =&amp;gt; [uid1,uid11,uid111...] &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid_slice2 =&amp;gt; [uid2,uid22,uid222...] &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid_slice3 =&amp;gt; [uid3,uid33,uid333...] &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.85546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLAdA9TF7thuH4gyqE2hWj1As2BM7I7iahRJwNjMbM0ibFuBIJwndCZkkg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;主要问题&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果仅仅从技术实现上看v3.0版本，似乎已经暂时达到了一个水平，在一定时间内也能正常支撑社区点赞业务的高性能响应。但是如果从业务角度和全局观念上去考虑，这个设计方案仍旧存在比较多的优化点。例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存分片中仍旧维护了被浏览动态下全部的点赞用户数据，消耗了非常大的Redis资源，也增加了缓存维护难度。缓存数据的有效使用率很低，推荐流场景下，用户浏览过的动态，几乎不会再次浏览到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前技术方案针对单篇内容进行设计，在各种Feed流场景中，查询任务在点赞服务里其实放大了十数倍。这种放大对服务器、Redis以及DB，都产生一定的资源消耗浪费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些点赞量特别多的历史动态，有人访问时均会重建缓存，重建成本高，但使用率不高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存集合分片的设计维护了较多无用数数据，也产生了大量的Key，Key在Redis中同样是占用内存空间的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;... ...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下，较高的服务器负载、Redis请求量、DB请求量。非常大的Redis资源使用(几十GB)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们需要一个更优的方案，解决优化以下现象：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Feed流场景下批量查询内容任务放大导致的服务器负载，Redis请求，DB请求放大现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、缓存更高效的存储和使用，降低缓存整体的使用量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、缓存更高的命中率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、区分冷热数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h5&gt;&lt;strong&gt;&lt;span&gt;实际Feed场景下的实现逻辑：&lt;/span&gt;&lt;/strong&gt;&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;批量查询动态点赞数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLB38awZK3hiaIGUJNVN9Nqm7bzmV4DUZCfPR7JX5uqomicapgby9RXtqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;V4.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合实际业务场景，大部分场景上游服务都是批量判断是否点赞，社区的动态本身也存在一定的新鲜度(冷热)。对新缓存的要求是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、能解决Feed流场景下批量查询流量放大现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、缓存数据区分冷热，减少无效存储（能在内容和点赞用户角度都区分冷热数据）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、缓存结构要简单易维护，使业务实现要清晰明了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、批量查询任务之所以放大是因为之前的缓存是以内容为维度进行设计，新方案要以用户为维度进行设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、旧方案中访问内容点赞数据会重建缓存，有些老旧内容重建缓存性价比低，而且内容下的点赞用户并不是一直活跃和会重新访问内容，新方案要等区分冷热数据，冷数据直接访问DB，不再进行缓存的重建/更新维护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、旧方案在维护缓存过期时间和延长过期时间的设计中，每次操作缓存都会进行ttl接口操作，QPS直接x2。新方案要避免ttl操作，但同时又可以维护缓存过期时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、缓存操作和维护要简单，期望一个Redis接口操作能达到目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以新方案Redis数据结构的选择中，能判断是否点赞、是否是冷热数据、是否需要延长过期时间，之前的集合是不能满足了，我们选择&lt;strong&gt;H&lt;/strong&gt;&lt;strong&gt;ash表结构。&lt;/strong&gt;用户ID做Key，contentId做field，考虑到社区内容ID是趋势递增的，一定程度上coententID能代表数据的冷热，在缓存中只维护&lt;strong&gt;一定时间和一定数量&lt;/strong&gt;的contentID，并且增加minCotentnID用于区分冷热数据，为了减少ttl接口的调用，还增加ttl字段用户判断缓存有效期和延长缓存过期时间。一举三得！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &quot;userId&quot;:{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;ttl&quot;:1653532653,    //缓存新建或更新时时间戳&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;cid1&quot;:1,            //用户近一段时间点赞过的动态id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;cid2&quot;:1,            //用户近一段时间点赞过的动态id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;cidn&quot;:1,            //用户近一段时间点赞过的动态id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;minCid&quot;:3540575,    //缓存中最小的动态id，用以区分冷热，&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLCnodPSI7jVfJ81oJeHBtNPLbE34s9V08HEAxXKPO3w9oYsdTRtdR2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过流程图，我们可以清晰看到， 上游Feed流，一次批量查询请求，没有了循环逻辑，最优情况下，只有一次Redis操作，业务实现也非常简单明了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后Redis查询量QPS日常峰值下降了20倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLE9DsIfsRGOCAkUYiaTibpIGbHQibIVxw11Hx7HWx9AmlZamQhku4P0jng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后接口平均RT下降了10倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2671875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLkic6aXGFTSEoZgiazeul8HfDsoeEAJaMr2oxQhPNhvYicnrGlfTdW2kcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后DB查询量QPS日常峰值下降了6倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.41605839416058393&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLmQmCMr22roW8oacLxWlGTTLQIVh3BYHb4p5Fwkbk2j6N5T4cm5XiaMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1096&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.400355871886121&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoL12TMMGz2BiaE09ic0yucknpQWcdQXUQGVOkQG6zMmLQ9xegG3mqXwXEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1124&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后缓存节省了16G左右存储空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.26171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLyhWgnibqzt9XJgQFcQKUFeMIE0uTM3XWQc91c9WLeMR6892QlY0Iyew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;后续&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化不会结束，技术不会停止，技术方案会随着业务的演进而演进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本篇文章中对得物社区点赞业务缓存优化的探索演进做了相关历史背景和技术方案的解析，当前其中还有更多的细节。而这么多次版本的优化，都是根据实际的业务场景中出现的风险点以及需求不断摸索出来的，每个版本的方案也都不是完美方案，v4.0也不是最终方案，还需要开发人员也需要进一步思索，探索更优的技术方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且随着业务的不断发展迭代，会涌现出更多的场景和困难，我们一直在优化探索的路上。&lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;strong mp-original-font-size=&quot;11&quot; mp-original-line-height=&quot;17.600000381469727&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;*文&lt;/span&gt;&lt;/strong&gt;&lt;strong mp-original-font-size=&quot;11&quot; mp-original-line-height=&quot;17.600000381469727&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;/慎之&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;br mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;/&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;svg viewbox=&quot;0 0 1 1&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;svg viewbox=&quot;0 0 1 1&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt; 关注得物技术，每周一三五晚18:30更新技术干货&lt;br mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;/&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkxNTE3ODU0NA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74DWvZPADM5XknnTibzgrxuvzvLtcjycF3pIbYqpsXSWwxz9QLfqbWCufybUH4agABGQlhkqfdI0pNw/0?wx_fmt=png&quot; data-nickname=&quot;得物技术&quot; data-alias=&quot;&quot; data-signature=&quot;技术知识分享交流平台，与你一同走向技术的云端。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;活动推荐&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题：得物技术沙龙-算法专场&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间：7月30日 13:50-18:00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;报名方式：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_live_iframe&quot; data-pluginname=&quot;videosnap&quot; data-headimgurl=&quot;https://wx.qlogo.cn/finderhead/Q3auHgzwzM6A15Sbkl3fcb3MH3giciciaiaypmMpAKzLbz2rnKDXs4ia2bg/0&quot; data-username=&quot;v2_060000231003b20faec8cae28b1dc7d5cf02ea3db07785f6268ca44f543d593c9d5004c1e666@finder&quot; data-nickname=&quot;得物Tech&quot; data-desc=&quot;将在07月30日 13:50 直播&quot; data-intro=&quot;得物技术沙龙算法专场，已邀请得物电商搜索算法负责人&amp;amp;推荐算法负责人、阿里机器学习平台高级专家、阿里智能引擎技术专家分享&quot; data-noticeid=&quot;finderlivenotice-v2_060000231003b20faec8cae28b1dc7d5cf02ea3db07785f6268ca44f543d593c9d5004c1e666@finder-1658132882814577-1566451037&quot; data-type=&quot;live&quot;/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>39e45cda073ce3e977fd5c2ed9d032de</guid>
<title>Go 垃圾回收器指南</title>
<link>https://toutiao.io/k/kce21o1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;简介&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本指南旨在帮助高级Go语言用户更好地了解Go语言垃圾回收器的使用成本。它还提供了Go用户如何利用这些知识来提高应用程序的资源利用率的指导。它并不假设你了解垃圾回收，但假设你熟悉Go语言。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言负责安排Go语言值的存储。在大多数情况下，Go语言开发人员根本不需要关心这些值存储在哪里，或者为什么要存储。然而，在实践中，这些值通常需要存储在计算机&lt;strong&gt;物理内存&lt;/strong&gt;中，而物理内存是有限的资源。因为内存是有限的，所以必须小心地管理和回收内存，以避免在执行Go语言程序时耗尽内存。Go语言的工作就是根据需要分配和回收内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自动回收内存的另一个说法是&lt;strong&gt;垃圾回收&lt;/strong&gt;。从较高的层次上讲，垃圾回收器（或简称为GC）是一个系统，这个系统通过标识内存的哪些部分不再需要来代表应用程序回收内存。Go语言的标准工具链提供了一个运行时库，它随每个应用程序一起提供，并且这个运行时库包含了一个垃圾回收器。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，Go语言规范并不能保证本指南所描述的垃圾回收器的存在，只不过Go语言本身负责管理Go语言值的底层存储。这一省略是有意的，并允许使用完全不同的内存管理技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，本指南是关于Go语言的一个具体实现的指导，可能不适用于其他实现。具体来说，本指南适用于标准工具链（gc Go compiler和工具）。Gccgo和Gollvm都使用非常相似的GC实现，因此许多相同的概念都适用，但细节可能会有所不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，这是一个一直在修正的文档，随着时间的推移而变化，以最好地反映Go语言的最新版本。本文档目前描述的是Go语言1.19中的垃圾回收器。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;价值所在&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在深入研究GC之前，让我们首先讨论一下不需要由GC管理的内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，存储在局部变量中的非指针Go语言的值可能根本不会被Go语言的GC管理，Go语言会安排内存的分配，并将其绑定到创建它的&lt;span&gt;词法作用域&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;中。一般来说，这比依赖GC更有效率，因为Go语言编译器能够预先确定何时释放内存，并发出清理内存的机器指令。通常，我们把这种为Go语言的值分配内存的方式称为“&lt;strong&gt;栈分配&lt;/strong&gt;”，因为空间存储在goroutine栈中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果Go语言的值不能以这种方式分配内存，则Go语言编译器无法确定它的生存期，那么这些值就被称为“&lt;strong&gt;逃逸到堆&lt;/strong&gt;”。“堆”可以被认为是内存分配的一个大杂烩，Go语言的值需要被放置在堆的某个地方。在堆上分配内存的操作通常称为“动态内存分配”，因为编译器和运行库都很少会对如何使用内存以及何时可以清理内存做出假设。这就是GC的用武之地：它是一个专门标识和清理动态内存分配的系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言的值需要逃逸到堆中的原因有很多。一个原因可能是其大小是动态确定的。例如，考虑一个切片的支持数组，它的初始大小由一个变量而不是一个常量确定。请注意，逃逸到堆也必须是可传递的：如果一个Go值的引用被写入到另一个已经被确定为逃逸的Go值中，那么这个值也必须逃逸。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言的值是否逃逸取决于使用它的上下文和Go语言编译器的逃逸分析算法。当价值观逃逸时，试图准确地列举它将是脆弱和困难的：算法本身相当复杂，并且在不同的Go语言版本中会有所变化。有关如何识别哪些值逃逸而哪些值不逃逸的详细信息，请参阅&lt;span&gt;消除堆分配&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;一节。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;跟踪垃圾回收&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垃圾回收可能指自动回收内存的众多实现方法，例如引用计数。在本文档的上下文中，垃圾回收指的是跟踪垃圾回收，其通过循着指针来标识正在使用的、所谓的活动对象。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;让我们更严格地定义这些术语:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;对象&lt;/strong&gt; - 对象是一个动态分配的内存块，包含一个或多个Go值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;指针&lt;/strong&gt; - 指向对象内任何值的内存地址。这自然包括 &lt;code&gt;*T&lt;/code&gt; 形式的Go语言值，但也包括部分内置Go语言值。字符串、切片、通道、map和接口值都包含GC必须跟踪的内存地址。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对象和指向其他对象的指针一起形成&lt;strong&gt;对象图&lt;/strong&gt;。为了识别活动内存，GC从程序的&lt;strong&gt;根&lt;/strong&gt;开始遍历对象图，程序明确使用的对象的指针。根的两个例子是局部变量和全局变量。遍历对象图的过程被称为&lt;strong&gt;扫描&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此基本算法对所有跟踪GC通用。跟踪GC的不同之处在于，一旦它们发现内存是活的，它们会做什么。Go语言的GC使用了&lt;strong&gt;标记(mark)&lt;strong&gt;—&lt;/strong&gt;清除(sweep)&lt;strong&gt;技术，这意味着为了跟踪它的过程，GC也会将它遇到的值&lt;/strong&gt;标记&lt;/strong&gt;为活动的。跟踪完成后，GC将遍历堆中的所有内存，并使所有未标记的对象的内存设置为可用于分配的内存。此过程称为**扫描(scanning)**。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;您可能熟悉的另一种技术是将对象实际移动到内存的新部分，并留下一个转发指针，以后将使用该指针更新应用程序的所有指针。我们称以这种方式移动对象的GC为&lt;strong&gt;移动GC&lt;/strong&gt;; Go的GC不是这样子的，它是&lt;strong&gt;非移动GC&lt;/strong&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;GC循环&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于Go GC是一个标记—清除GC，因此它大致分为两个阶段：&lt;strong&gt;标记阶段&lt;/strong&gt;和&lt;strong&gt;清扫阶段&lt;/strong&gt;。虽然这句话似乎是重复的，但它包含了一个重要的见解：在跟踪完所有内存之前，不可能释放内存以供分配，因为可能仍有未扫描的指针使对象保持活动状态。因此，清扫动作必须与标记动作完全分开。此外，当没有与GC相关的工作要做时，GC也可能根本不活动。GC在离开(off)、标记和扫描这三种状态之间不断循环，这就是所谓的GC循环。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来的几个章节我们将集中讨论如何直观地了解GC的成本，以帮助用户调整GC参数，从而为自己谋福利。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;了解成本&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GC本质上是一个构建在更复杂系统上的复杂软件。当试图理解GC并调整其行为时，很容易陷入细节的泥潭。本节旨在提供一个框架，用于说明Go GC的开销和调优参数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开始讨论前，先了解基于四个简单公理的GC成本模型。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在GC执行时，应用程序会暂停。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;GC只涉及两种资源：CPU时间和物理内存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;GC的内存开销包括活动堆内存、标记阶段之前分配的新堆内存，以及元数据空间（即使与前两个的开销成比例，但相比之下元数据空间开销也很小）。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：活动堆内存是由上一个GC周期确定为活动的内存，而新堆内存是在当前周期中分配的任何内存，在结束时可能是活动的，也可能不是活动的。&lt;/p&gt;&lt;/blockquote&gt;&lt;ol start=&quot;4&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;GC的CPU成本被建模为每个周期的固定成本，以及与活动堆的大小成比例的边际成本(marginal cost)。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：从渐进的角度来说，清扫的伸缩性比标记和扫描要差，因为它必须执行与整个堆的大小成比例的工作，包括被确定为非活动（即“死”）的内存。然而，在当前的实现中，清扫操作比标记和扫描快得多，因此在本讨论中可以忽略其相关成本。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种模型简单而有效：它准确地对GC的主要成本进行了分类。然而，这个模型没有说明这些成本的规模，也没有说明它们是如何相互作用的。为了对此建模，考虑以下情况，我们称这种场景为&lt;strong&gt;稳态&lt;/strong&gt;(steady-stat)。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;应用程序分配新内存的速率（以字节/秒为单位）是恒定的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：重要的是要理解这个分配率与这个新内存是否是活动的完全无关。没有一个是活的，所有的都是活的，或者一部分是活的都有可能。(除此之外，一些旧的堆内存也可能死亡，因此，如果该内存是活动的，活动堆大小不一定会增长。）
更具体地说，假设有一个web服务为它处理的每个请求分配2 MiB的总堆内存。在请求过程中，2 MiB中最多有512 KiB在请求进行期间保持活动状态，当服务完成对请求的处理时，所有这些内存都会死亡。稳定的请求流（比如每秒100个请求）会产生200 MiB/s的分配率和50 MiB的峰值活动堆。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;应用程序的对象图每次看起来都大致相同（对象的大小相似，指针的数量大致恒定，图的最大深度大致恒定）。另一种思考方式是GC的边际成本是恒定的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：稳态可能看起来是人为的，但它的确代表了应用程序在某个恒定工作负载下的行为。当然，在应用程序执行时，工作负载也可能发生变化，但通常应用程序行为看起来总体上像是一串稳定状态，中间穿插着一些瞬态行为。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：稳定状态对活动堆没有任何假设。它可能会随着每个后续GC周期而增长，可能会缩小，也可能会保持不变。然而，试图在下面的解释中包含所有这些情况很无聊乏味，而且不是很有说明性，所以本指南将重点放在活动堆保持不变的示例上。GOGC一节会更详细地探讨了非常量活动堆的场景。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在活动堆大小不变的稳定状态下，只要GC在经过相同的时间后执行，每个GC周期在成本模型中看起来都是相同的。这是因为在固定的时间内，如果应用程序的分配速率是固定的，则将分配固定数量的新堆内存。因此，在活动堆大小不变的情况下，新的堆大小&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在活动堆大小不变的稳定状态下，只要GC在经过相同的时间后执行，每个GC周期在成本模型中看起来都是相同的。这是因为在固定的时间内，如果应用程序的分配速率是固定的，则将分配固定数量的新堆内存。因此，在活动堆大小和新堆内存保持不变的情况下，内存使用量将始终保持不变。而且因为活动堆的大小相同，所以边际GC CPU成本也相同，并且固定成本将以某个固定间隔发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在考虑GC如果延迟，发生在稍后时间应该运行的点之后， 因此将分配更多的内存，但每个GC周期仍将导致相同的CPU开销。但是，在其他固定的时间窗口中，完成的GC周期会更少，从而降低了总体CPU成本。如果GC决定提前启动，则情况正好相反：将分配较少的内存并且将更频繁地引起CPU成本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况代表了GC可以在CPU时间和内存之间进行的基本权衡，由GC实际执行的频率来控制。换句话说，折衷完全由GC的频率定义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一个细节需要定义，那就是GC应该决定何时开始。注意，这直接设置了任何特定稳态下的GC频率，从而定义了折衷。在Go语言中，决定GC何时启动是用户可以控制的主要参数。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;GOGC&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GOGC是Go GC的一个调优参数，它通过控制GC频率直接反映了CPU时间和内存之间的平衡。更具体地说，GOGC设置GC的目标堆大小，或者在标记阶段完成之前应该分配的新内存量。GOGC被定义为GC需要完成的工作量的百分比开销。这项工作目前被定义为活动堆的大小加上GC根的大小（以字节为单位）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个例子，假设一个Go语言程序，它有8 MiB的堆，1 MiB的goroutine栈，1 MiB的全局变量指针。如果GOGC值为100，则在下一次GC运行之前将分配的新内存量将为10 MiB，或10 MiB工作量的100%，总堆占用量为18 MiB。如果GOGC值为50，则它将为50%，即分配的新内存量为5 MiB。如果GOGC值为200，则为200%，即分配的新内存量20 MiB。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：GOGC可以更精确地描述为定义在下一个扫描阶段开始之前可以分配的新内存量。从技术上讲，这个记时对于本指南目前使用的GC模型来说是正确的，但是它也适用于Go语言使用的真实GC实现，在延迟一节中会有更详细的讨论。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以这种方式定义权衡(trade-off)的好处是，无论GC必须完成的工作量如何（也就是说，无论活动堆和根集的大小如何），GC的成本在稳态下都保持不变，因为频率总是与必须完成的工作量成比例。换句话说，它代表了CPU成本和内存使用之间权衡的一个固定点。(需要注意的是，如果稳定状态也发生变化，则此固定点也可能发生偏移，但关键是它不依赖于活动堆的大小。）&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：GOGC 自Go 1.18开始包含根集， 以前它只对活动堆进行计数。通常，goroutine堆栈中的内存量非常小，并且活动堆的大小支配着GC的所有其他工作来源, (所以先前的计算大概也没问题,) 但是当程序有几十万个goroutine时，GC会做出错误的判断。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GOGC可以通过GOGC环境变量（所有Go语言程序都能识别）或者&lt;code&gt;runtime/debug&lt;/code&gt;包中的&lt;code&gt;SetGCPercent&lt;/code&gt; API来配置。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;请注意，GOGC也可用于通过设置&lt;code&gt;GOGC=off&lt;/code&gt;或调用&lt;code&gt;SetGCPercent(-1)&lt;/code&gt;来完全关闭GC（前提是memory limit没有使用）。从概念上讲，此设置等效于将GOGC设置为无穷大值，因为在触发GC之前新内存的数量是无限的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了更好地理解我们到目前为止讨论的所有内容，请尝试下面的交互式可视化，它是基于前面讨论的GC成本模型构建的。该可视化描述了某个程序的执行，该程序的非GC工作需要10秒的CPU时间才能完成。在进入稳定状态之前的第一秒，它执行一些初始化步骤（增长其活动堆）。应用程序总共分配200 MiB，其中20 MiB一次处于活动状态。它假设要完成的唯一相关GC工作来自活动堆，并且（不现实地）应用程序不使用额外的内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用滑块调整GOGC的值，以查看应用程序在总持续时间和GC开销方面的响应情况。每次GC循环都会在新堆降为零时发生。X轴移动以始终显示程序的完整CPU持续时间。请注意，GC使用的额外CPU时间会增加总持续时间。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/figure&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.26171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvtoF5TwxAA6PLTA6yFzgu1KGadaab09l269c1I8tVq4JDq2r6YUPzrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，GC总是会导致一些CPU和峰值内存开销。随着GOGC的增加，这些CPU开销降低，但峰值内存与活动堆大小成比例增加。随着GOGC的减小，峰值内存需求也会减少，但会增加额外的CPU开销。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：图形显示的是CPU时间，而不是完成程序所需的挂钟时间(wall-clock time)。如果程序在1个CPU上运行并充分利用其资源，则它们是等效的。真实的的程序可能运行在多核系统上，并且不会始终100%地利用CPU。在这些情况下，GC的挂钟时间影响会比较低。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：Go GC的最小总堆大小为4 MiB，因此如果GOGC设置的目标值低于该值，则会取整。这个图形展示反映此细节。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有一个动态的和更有真实感的例子。同样，在没有GC的情况下，应用程序需要10个CPU秒才能完成，但在中途，稳态分配率急剧增加，并且活动堆大小在第一阶段发生了一些变化。这个示例演示了当活动堆大小实际上发生变化时，稳定状态可能是什么样子的，以及更高的分配率如何导致更频繁的GC周期。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvBSPKjA2kjicsCcIia0OL7ib6gmwiaYfqLIHw8GKTI0c1LmAsZTG7MJIoLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;内存限制 （memory limit）&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在Go 1.19之前，GOGC是唯一一个可以用来修改GC行为的参数。虽然它作为一种设置权衡(trade-off)的方式非常有效，但它没有考虑到可用内存是有限的。考虑当活动堆大小出现短暂峰值时会发生什么情况：因为GC将选择与活动堆大小成比例的总堆大小，所以GOGC必须被配置为峰值活动堆大小相匹配的值，即使在通常情况下，较高的GOGC值会提供了更好的权衡效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面的可视化演示了这种瞬态堆峰值情况。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.28203125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvomNjpheNo6vdiagYXPJSTL35zxvmuJL59ZLsuibAy8fic3OtLMJIicy3VQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果示例工作负载在可用内存略高于60 MiB的容器中运行，则GOGC不能增加到100以上，即使其余GC周期有可用内存来使用该额外内存。此外，在一些应用中，这些瞬时峰值可能是罕见的并且难以预测，从而导致偶然的、不可避免的并且可能代价高昂的内存不足情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是为什么在1.19版本中，Go语言增加了对设置运行时内存限制的支持。内存限制可以通过所有Go语言程序都能识别的&lt;strong&gt;GOMEMLIMIT&lt;/strong&gt;环境变量来配置，也可以通过&lt;code&gt;runtime/debug&lt;/code&gt;包中的&lt;code&gt;SetMemoryLimit&lt;/code&gt;函数来配置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个内存限制设置了Go语言运行时可以使用的最大内存总量。包含的特定内存集是&lt;code&gt;runtime.MemStats&lt;/code&gt;的&lt;code&gt;Sys - HeapReleased&lt;/code&gt;的值，或者等价于&lt;code&gt;runtime/metrics&lt;/code&gt;的公式&lt;code&gt;/memory/classes/total:bytes - /memory/classes/heap/released:bytes&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为Go GC可以显式控制它使用多少堆内存，所以它会根据这个内存限制和Go运行时使用的其他内存来设置总的堆大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面的可视化描述了来自GOGC部分的相同的单阶段稳态工作负载，但这次Go运行时额外增加了10 MiB的开销，并且内存限制可调。尝试在GOGC和内存限制之间移动，看看会发生什么。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvfIBw2MJVATFp8E2WxW8JNDTPG31PvI0y1wawlI2nAtSQGu1K5ic4pBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，当内存限制降低到GOGC确定的峰值内存（GOGC为100时为42 MiB）以下时，GC会更频繁地运行，以将峰值内存保持在限制的内存之下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回到我们前面的瞬态堆峰值的例子，通过设置内存限制并打开GOGC，我们可以获得两个世界的最佳结果：不违反内存限制，且更好地节约资源。请尝试以下交互式可视化。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.25625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvfXkURiaQu1cQ2tgvMHMA5Welhle78YLYFI3JTuqBQShj9Iqj21v3O8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，对于GOGC的某些值和内存限制，峰值内存使用在内存限制为多少时停止，但程序执行的其余部分仍然遵守GOGC设置的总堆大小规则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一观察引出了另一个有趣的细节：即使GOGC设置为关闭，内存限制仍然有效! 实际上，这种特定的配置代表了资源经济的最大化，因为它设置了维持某个内存限制所需的最小GC频率。在这种情况下，所有程序的执行都会使堆大小增加以满足内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在，虽然内存限制显然是一个强大的工具，&lt;strong&gt;但使用内存限制并不是没有代价的&lt;/strong&gt;，当然也不会使GOGC的实用性失效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请考虑当活动堆增长到足以使总内存使用量接近内存限制时会发生什么。在上面的稳定状态可视化中，尝试关闭GOGC，然后慢慢地进一步降低内存限制，看看会发生什么。请注意，应用程序花费的总时间将开始以无限制的方式增长，因为GC不断地执行以维持不可能的内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况，即程序由于不断的GC循环而无法取得合理的进展，称为系统颠簸(thrashing)。这是特别危险的，因为它严重地拖延了程序。更糟糕的是，它可能会发生在我们试图避免使用GOGC的情况下：一个足够大临时堆尖峰会导致程序无限期地停止! 尝试在瞬态堆峰值可视化中降低内存限制（大约30 MiB或更低），并注意最坏的行为是如何从堆峰值开始的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在许多情况下，无限期暂停比内存不足情况更糟，因为后者往往会导致更快的失败以便我们发现和处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，内存限制被定义为软限制。Go语言运行时并不保证在任何情况下都能保持这个内存限制;它只承诺了一些合理的努力。内存限制的放宽对于避免系统颠簸行为至关重要，因为它为GC提供了一条出路：让内存使用超过限制以避免在GC中花费太多时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这在内部是如何工作的？GC mitigates 设置了一个在某个时间窗口内可以使用的CPU时间量的上限（对于CPU使用中非常短的瞬时峰值，有一些滞后）。此限制当前设置为大约50%，具有&lt;code&gt;2 * GOMAXPROCS CPU-second&lt;/code&gt;窗口。限制GC CPU时间的结果是GC的工作被延迟，同时Go程序可能会继续分配新的堆内存，甚至超过内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;50% GC CPU限制背后的直觉是基于对具有充足可用内存的程序的最坏情况影响。在内存限制配置错误的情况下，它被错误地设置得太低，程序最多会慢2倍，因为GC占用的CPU时间不能超过50%。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：此页上的可视化不会模拟GC CPU限制。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;建议用法&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然内存限制是一个强大的工具，Go语言运行时也会采取措施来减少误用造成的最坏行为，但谨慎使用它仍然很重要。下面是一些关于内存限制在哪些地方最有用，以及在哪些地方可能弊大于利的建议。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当Go语言程序的执行环境完全在你的控制之下，并且Go语言程序是唯一可以访问某些资源的程序时（也就是说，某种内存预留，就像容器内存限制一样），一定要利用内存限制。一个很好的示例是将web服务部署到具有固定可用内存量的容器中。&lt;strong&gt;在这种情况下，一个很好的经验法则是，留出额外的5-10%的空间来处理Go语言运行时不知道的内存资源。&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;请随时调整内存限制，以适应不断变化的条件。一个很好的例子是cgo程序，其中C库暂时需要使用更多的内存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如果Go语言程序可能会与其他程序共享有限的内存，那么不要将GOGC设置为off，因为这些程序通常与Go语言程序是解耦的。相反，保留内存限制，因为它可能有助于抑制不需要的瞬态行为，但将GOGC设置为某个较小的、对于一般情况而言合理的值。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然尝试为共享程序“保留”内存是很诱人的，但除非程序完全同步（例如，Go程序在被调用程序执行时调用某些子进程和阻塞），否则结果将不太可靠，因为两个程序都不可避免地需要更多内存。让Go程序在不需要内存的时候使用更少的内存，总体上会产生更可靠的结果。此建议也适用于过量使用的情况，在这种情况下，在一台计算机上运行的容器的内存限制之和可能会超过该计算机可用的实际物理内存。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当部署到您无法控制的执行环境时，不要使用内存限制，特别是当程序的内存使用与其输入成比例时。CLI工具或桌面应用程序就是一个很好的例子。在不清楚可能输入什么类型的输入，或者系统上可能有多少可用内存时，将内存限制写入程序可能会导致混乱的崩溃和性能下降。此外，高级最终用户可以根据需要设置内存限制。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当程序已经接近其环境的内存限制时，不要设置内存限制以避免内存不足的情况。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这有效地将内存不足的风险替换为严重的应用程序速度减慢的风险，这通常不是一个有利的交易，即使Go语言努力减轻系统颠簸。在这种情况下，提高环境的内存限制（然后可能设置内存限制）或降低GOGC（这提供了比系统颠簸缓解更干净的权衡）将更加有效。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;延迟时间&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到目前为止，本文将应用程序建模在在GC执行时会暂停这一公理上。确实存在这样的GC实现，它们被称为&lt;strong&gt;stop-the-world&lt;/strong&gt; GC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，Go GC并不是完全停止工作，实际上它的大部分工作都是与应用程序同时进行的。这样做的主要原因是它减少了应用程序延迟。具体来说，延迟是指单个计算单元（例如，web请求）的端到端持续时间。到目前为止，本文主要考虑应用程序吞吐量，或这些操作的聚合（例如，每秒处理的web请求）。请注意，GC周期部分中的每个示例都侧重于执行程序的总CPU持续时间。然而，这样的持续时间对于例如web服务来说意义要小得多，web服务的持续时间主要捕获可靠性（即uptime）而不是成本。虽然吞吐量（即每秒的查询数）对于web服务仍然很重要，但通常每个单独请求的延迟甚至更重要，因为它与其他重要指标相关。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就延迟而言，stop-the-world GC可能需要相当长的时间来执行其标记和扫描阶段，在此期间，应用程序以及在web服务的上下文中的任何正在进行的请求都无法取得进一步的进展。相反，Go GC确保了任何全局应用程序暂停的长度都不会以任何形式与堆的大小成比例，并且在应用程序主动执行的同时执行核心跟踪算法。这种选择并非没有成本，因为在实践中，它往往会导致吞吐量较低的设计，但需要注意的是，低延迟并不必然意味着低吞吐量，即使在许多情况下，这两者并不一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，Go GC的并发特性可能看起来与前面介绍的成本模型有很大的不同。幸运的是，模型背后的直觉仍然适用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然第一条公理不再成立，但它开始并不是那么重要;其余的成本仍然如模型所描述的那样，并且使用相同的稳态概念。因此，GC频率仍然是GC在CPU时间和内存吞吐量之间进行权衡的主要方式，它还承担了延迟的角色。关于吞吐量，只要假设并发GC所产生的所有小开销都发生在GC周期的末尾，就很容易回到模型的范围内。关于延迟，GC增加的延迟中的大部分特别来自标记阶段处于活动状态的时间段。因此，GC处于标记阶段的频率越高，这些成本就越频繁地发生，因此等待时间也跟随GC频率。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;更具体地，调整GC参数以降低GC频率也可以导致延迟改善。这意味着需要增加GOGC和/或内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，理解延迟通常比理解吞吐量更复杂，因为它是程序即时执行的产物，而不仅仅是成本的聚合之物。因此，延迟和GC频率之间的联系更加脆弱，可能不那么直接。下面是一个可能导致延迟的来源列表，供那些倾向于深入研究的人使用。这些延迟源在执行跟踪中是可见的。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;当GC在标记和清除阶段之间转换时，&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;调度延迟是因为GC在标记阶段占用了25%的CPU资源，&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;用户goroutine贡献出来以便辅助GC处理高内存分配率&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当GC处于标记阶段时，指针写入需要额外的处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;运行中的goroutine必须被暂停，以便扫描它们的根。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;其他资源&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然上面提供的信息是准确的，但它缺乏充分理解Go GC设计中的成本和权衡的细节。有关详细信息，请参阅以下其他资源。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;The GC Handbook&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt; — 一个垃圾收集器设计的优秀通用资源和参考资料。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;TCMalloc&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt; — C/C++内存分配器TCMalloc的设计文档，Go内存分配器就是基于此。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Go 1.5 GC announcement&lt;/span&gt;&lt;sup&gt;[5]&lt;/sup&gt; — 官方介绍Go 1.5并发GC的博客文章，其中更详细地描述了算法。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Getting to Go&lt;/span&gt;&lt;sup&gt;[6]&lt;/sup&gt; — 深入介绍Go GC设计到2018年的演变&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Go 1.5 concurrent GC pacing&lt;/span&gt;&lt;sup&gt;[7]&lt;/sup&gt; — 确定何时开始并发标记阶段的设计文档&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Smarter scavenging&lt;/span&gt;&lt;sup&gt;[8]&lt;/sup&gt; — 订正Go运行时向操作系统返回内存的方式的设计文档&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Scalable page allocator&lt;/span&gt;&lt;sup&gt;[9]&lt;/sup&gt; — 订正Go运行时管理其从操作系统获得的内存的方式的设计文档&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;GC pacer redesign (Go 1.18)&lt;/span&gt;&lt;sup&gt;[10]&lt;/sup&gt; — 用于修改算法以确定何时开始并发标记阶段的设计文件&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Soft memory limit (Go 1.19)&lt;/span&gt;&lt;sup&gt;[11]&lt;/sup&gt; — 软内存限制的设计文件&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;关于虚拟内存注意事项&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本指南主要关注GC的物理内存使用，但经常出现的一个问题是你到底想说个啥，以及它与虚拟内存的比较（通常在像top这样的程序中表示为“VSS”）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;物理内存是大多数计算机中实际物理RAM芯片中的内存。虚拟内存是由操作系统提供的物理内存上的抽象，用于将程序彼此隔离。程序保留完全不映射到任何物理地址的虚拟地址空间通常也是可以接受的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;由于虚拟内存只是操作系统维护的映射，因此保留不映射到物理内存的大型虚拟内存通常非常便宜。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言运行时通常在以下几个方面依赖于这种虚拟内存开销视图：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Go语言运行时不会删除它所映射的虚拟内存。相反，它使用大多数操作系统提供的特殊操作来显式释放与某个虚拟内存范围相关联的任何物理内存资源。该技术被显式地用于管理内存限制，并将Go语言运行时不再需要的内存返回给操作系统。Go运行时也会在后台连续释放不再需要的内存。有关详细信息，请参阅其他资源。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;在32位平台上，Go运行时会为堆预留128 MiB到512 MiB的地址空间，以限制碎片问题。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Go语言运行时在实现几个内部数据结构时使用了大量的虚拟内存地址空间预留。在64位平台上，它们通常具有大约700 MiB的最小虚拟内存占用量。在32位平台上，它们的占用空间可以忽略不计。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，虚拟内存指标，比如top中的“VSS”，在理解Go语言程序的内存占用方面通常不是很有用。相反，应该关注“RSS”和类似的度量，它们更直接地反映了物理内存的使用情况。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;优化指南&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;确定成本&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在尝试优化Go语言应用程序与GC的交互方式之前，首先确定GC是一个主要的开销，这一点很重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go生态系统提供了大量的工具来识别成本和优化Go应用程序。有关这些工具的简要概述，请参阅&lt;span&gt;诊断指南&lt;/span&gt;&lt;sup&gt;[12]&lt;/sup&gt;。在这里，我们将重点讨论这些工具的一个子集，以及应用它们的合理顺序，以便理解GC的影响和行为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;** 1、CPU profile**&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优化程序的一个很好的起点是&lt;span&gt;CPU profiling&lt;/span&gt;&lt;sup&gt;[13]&lt;/sup&gt;。CPU profiling提供了CPU时间花费在何处的概述，尽管对于未经训练的眼睛来说，可能很难确定GC在特定应用程序中所起作用的大小。幸运的是，理解profile的GC主要归结为了解&lt;code&gt;runtime&lt;/code&gt;包中不同函数的含义即可。以下是这些函数中用于解释CPU profile文件的有用子集。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：下面列出的函数不是叶函数，因此它们可能不会显示在pprof工具为top命令提供的默认值中。相反，使用&lt;code&gt;top cum&lt;/code&gt;命令或直接对这些函数使用&lt;code&gt;list&lt;/code&gt;命令，并将注意力集中在累计百分比列上。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;runtime.gcBgMarkWorker&lt;/strong&gt;: 专用标记工作goroutine的入口点。这里花费的时间与GC频率以及对象图的复杂性和大小成比例。它表示应用程序标记和扫描所用时间的基准。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：在一个大部分时间都处于空闲状态的Go应用程序中，Go GC会消耗额外的（空闲的）CPU资源来更快地完成任务。结果，该符号可以表示它认为是免费采样部分。一个常见的原因是，一个应用程序完全在一个goroutine中运行，但是GOMAXPROCS &amp;gt; 1。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;runtime.mallocgc&lt;/strong&gt;:堆内存的内存分配器的入口点。此处花费的大量累积时间（&amp;gt; 15%）通常表示分配了大量内存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;runtime.gcAssistAlloc&lt;/strong&gt;: goroutine进入这个函数是为了腾出一些时间来帮助GC进行扫描和标记。这里花费的大量累积时间（&amp;gt; 5%）表明应用程序在分配速度方面可能超过了GC。它表示GC的影响程度特别高，并且还表示应用程序在标记和扫描上花费的时间。请注意，它包含在&lt;code&gt;runtime.mallocgc&lt;/code&gt;调用树中，因此它也会使该调用树累计时间增加。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2、执行跟踪&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然CPU profile文件非常适合用于确定时间在聚合中的花费点，但对于指示更细微、更罕见或与延迟具体相关的性能成本，它们的用处不大。另一方面，执行跟踪提供了Go语言程序执行的一个短窗口的丰富而深入的视图。它们包含了与Go GC相关的各种事件，可以直接观察到具体的执行路径，沿着应用程序与Go GC的交互方式。所有被跟踪的GC事件都在跟踪查看器中被方便地标记为GC事件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有关如何开始使用执行跟踪的信息，请参阅 &lt;span&gt;runtime/trace&lt;/span&gt;&lt;sup&gt;[14]&lt;/sup&gt; 的文档。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;** 3、GC跟踪**&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当所有其他方法都失败时，Go GC还提供了一些不同的特定跟踪，这些跟踪提供了对GC行为的更深入的了解。这些踪迹总是被直接打印到 STDERR 中，每个GC循环一行，并且通过所有Go语言程序都能识别的 GODEBUG 环境变量来配置。它们主要用于调试Go GC本身，因为它们需要对GC实现的细节有一定的了解，但是偶尔也可以用于更好地理解GC的行为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过设置&lt;code&gt;GODEBUG=gctrace=1&lt;/code&gt;，可以启用核心GC跟踪。此跟踪生成的输出记录在&lt;span&gt;runtime&lt;/span&gt;&lt;sup&gt;[15]&lt;/sup&gt;包文档的环境变量部分中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个称为&lt;code&gt;pacer trace&lt;/code&gt;的技术用来补充GC跟踪，提供了更深入的见解，它通过设置&lt;code&gt;GODEBUG=gcpacertrace=1&lt;/code&gt;来启用。解释这个输出需要理解GC的&lt;code&gt;pacer&lt;/code&gt;（参见&lt;span&gt;其他参考资料&lt;/span&gt;&lt;sup&gt;[16]&lt;/sup&gt;），这超出了本指南的范围。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;消除堆分配&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;降低GC成本的一种方法是让GC开始管理较少的值。下面描述的技术可以带来一些最大的性能改进，因为正如GOGC部分所展示的，Go语言程序的分配率是GC频率的一个主要因素，GC频率是本指南使用的关键成本度量。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;堆分析&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在确定GC是一个巨大开销的来源之后，消除堆分配的下一步是找出它们中的大多数来自哪里。为此，内存 profile 文件（实际上是堆内存 profile 文件）非常有用。请查看&lt;span&gt;文档&lt;/span&gt;&lt;sup&gt;[17]&lt;/sup&gt;以了解如何开始使用它们。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存 profile 文件描述了程序堆中分配的来源，并通过分配时的堆栈跟踪来标识它们。每个内存 profile 文件可以按四种方式分析：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;inuse_objects - 活动对象的数量&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;inuse_space - 按活动对象使用的内存量（以字节为单位&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;alloc_objects - 自Go程序开始执行以来已经分配的对象数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;alloc_space - 自Go程序开始执行以来所分配的内存总量&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这些不同的堆内存视图之间切换可以通过pprof工具的 &lt;code&gt;-sample_index&lt;/code&gt;标志来完成，或者在交互式使用该工具时通过&lt;code&gt;sample_index&lt;/code&gt;选项来完成。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：默认情况下，内存 profile 文件只对堆对象的子集进行采样，因此它们不会包含有关每个堆分配的信息。但是，这足以找到热点。若要更改采样率，请参见&lt;span&gt;runtime.MemProfileRate&lt;/span&gt;&lt;sup&gt;[18]&lt;/sup&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了降低GC成本，alloc_space通常是最有用的视图，因为它直接对应于分配率。此视图将指示可提供最大益处的分配热点。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;逃逸分析&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦在&lt;span&gt;堆 profile 文件&lt;/span&gt;&lt;sup&gt;[19]&lt;/sup&gt;的帮助下确定了候选堆分配点，如何消除它们？关键是要利用Go语言编译器的逃逸分析，让Go语言编译器为这个内存找到替代的、更有效的存储空间，比如在goroutine栈中。幸运的是，Go语言编译器能够描述为什么要将Go语言的值逃逸到堆中。有了这些知识，就变成了重新组织源代码以改变分析结果的问题（这通常是最困难的部分，但超出了本指南的范围）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于如何从Go语言编译器的逃逸分析中获取信息，最简单的方法是通过Go语言编译器支持的调试标志，该标志以文本格式描述了对某个包应用或未应用的所有优化。这包括值是否逃逸。尝试下面的命令，其中&lt;code&gt;package&lt;/code&gt;是Go语言包的路径:&lt;code&gt;$go build-gcflags=-m=3 软件包&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此信息也可以在VS代码中可视化为覆盖图。此覆盖在VS Code Go插件设置中配置和启用:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;设置&lt;span&gt;ui.codelenses设置以包括gc_details&lt;/span&gt;&lt;sup&gt;[20]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过&lt;span&gt;将ui.diagnostic.annotations设置为包括逃逸，启用逃逸分析的覆盖&lt;/span&gt;&lt;sup&gt;[21]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，Go编译器以机器可读（JSON）格式提供了这些信息，可以用来构建其他定制工具。有关这方面的更多信息，请参见&lt;span&gt;Go语言源代码中的文档&lt;/span&gt;&lt;sup&gt;[22]&lt;/sup&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;基于特定实现的优化&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go GC对活动内存的人口统计很敏感，因为对象和指针的复杂图既限制了并行性，又为GC生成了更多的工作。因此，GC包含了一些针对特定公共结构的优化。下面列出了对性能优化最直接有用的方法。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：应用下面的优化可能会因为混淆意图而降低代码的可读性，并且可能无法在Go语言的各个版本中保持。希望只在最重要的地方应用这些优化。可以使用确定成本一节中列出的工具来确定这些地点。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，从并不严格需要指针的数据结构中消除指针可能是有利的，因为这减少了GC施加在程序上的缓存压力。因此，依赖于指针值上的索引的数据结构虽然类型化较差，但可能执行得更好。只有当对象图很复杂并且GC花费大量时间进行标记和扫描时，才值得这样做。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，将结构类型值中的指针字段分组在值的开头可能是有利的。只有当应用程序花费大量时间进行标记和扫描时，才值得这样做。(理论上，编译器可以自动执行此操作，但尚未实现，并且结构字段的排列方式与源代码中所写的相同。）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，GC必须与它所看到的几乎每个指针交互，因此，例如，使用切片中的索引而不是指针，可以帮助降低GC成本。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;译者著， 这篇文章， 和Russ Cox的那三遍关于Go内存的模型一样， 里面有众多的未解释的名词，不是那么容易进行翻译，而Go语言规范和Go内存相对就容易理解和翻译了。我之所以尝试翻译，最重要的原因想深入学习本文介绍的相关知识，疏漏之处，欢迎斧正。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go官方原文: &lt;span&gt;A Guide to the Go Garbage Collector&lt;/span&gt;&lt;sup&gt;[23]&lt;/sup&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;词法作用域: &lt;em&gt;https://go.dev/ref/spec#Declarations_and_scope&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;消除堆分配: &lt;em&gt;https://tip.golang.org/doc/gc-guide#Eliminating_heap_allocations&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;The GC Handbook: &lt;em&gt;https://tip.golang.org/doc/gc-guide#:~:text=following%20additional%20resources.-,The%20GC%20Handbook,-%E2%80%94An%20excellent%20general&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;TCMalloc: &lt;em&gt;https://google.github.io/tcmalloc/design.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[5]&lt;/span&gt;&lt;p&gt;Go 1.5 GC announcement: &lt;em&gt;https://go.dev/blog/go15gc&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[6]&lt;/span&gt;&lt;p&gt;Getting to Go: &lt;em&gt;https://go.dev/blog/ismmkeynote&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[7]&lt;/span&gt;&lt;p&gt;Go 1.5 concurrent GC pacing: &lt;em&gt;https://docs.google.com/document/d/1wmjrocXIWTr1JxU-3EQBI6BK6KgtiFArkG47XK73xIQ/edit&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[8]&lt;/span&gt;&lt;p&gt;Smarter scavenging: &lt;em&gt;https://github.com/golang/go/issues/30333&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[9]&lt;/span&gt;&lt;p&gt;Scalable page allocator: &lt;em&gt;https://github.com/golang/go/issues/35112&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[10]&lt;/span&gt;&lt;p&gt;GC pacer redesign (Go 1.18): &lt;em&gt;https://github.com/golang/go/issues/44167&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[11]&lt;/span&gt;&lt;p&gt;Soft memory limit (Go 1.19): &lt;em&gt;https://github.com/golang/go/issues/48409&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[12]&lt;/span&gt;&lt;p&gt;诊断指南: &lt;em&gt;https://tip.golang.org/doc/diagnostics&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[13]&lt;/span&gt;&lt;p&gt;CPU profiling: &lt;em&gt;https://pkg.go.dev/runtime/pprof#hdr-Profiling_a_Go_program&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[14]&lt;/span&gt;&lt;p&gt;runtime/trace: &lt;em&gt;https://pkg.go.dev/runtime/trace&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[15]&lt;/span&gt;&lt;p&gt;runtime: &lt;em&gt;https://pkg.go.dev/runtime#hdr-Environment_Variables&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[16]&lt;/span&gt;&lt;p&gt;其他参考资料: &lt;em&gt;https://tip.golang.org/doc/gc-guide#Additional_resources&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[17]&lt;/span&gt;&lt;p&gt;文档: &lt;em&gt;https://pkg.go.dev/runtime/pprof#hdr-Profiling_a_Go_program&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[18]&lt;/span&gt;&lt;p&gt;runtime.MemProfileRate: &lt;em&gt;https://pkg.go.dev/runtime#pkg-variables&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[19]&lt;/span&gt;&lt;p&gt;堆 profile 文件: &lt;em&gt;https://tip.golang.org/doc/Heap_profiling&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[20]&lt;/span&gt;&lt;p&gt;ui.codelenses设置以包括gc_details: &lt;em&gt;https://github.com/golang/vscode-go/wiki/settings#uicodelenses&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[21]&lt;/span&gt;&lt;p&gt;将ui.diagnostic.annotations设置为包括逃逸，启用逃逸分析的覆盖: &lt;em&gt;https://github.com/golang/vscode-go/wiki/settings#uidiagnosticannotations&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[22]&lt;/span&gt;&lt;p&gt;Go语言源代码中的文档: &lt;em&gt;https://cs.opensource.google/go/go/+/master:src/cmd/compile/internal/logopt/log_opts.go;l=25;drc=351e0f4083779d8ac91c05afebded42a302a6893&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[23]&lt;/span&gt;&lt;p&gt;A Guide to the Go Garbage Collector: &lt;em&gt;https://tip.golang.org/doc/gc-guide?continueFlag=bf311ba190bf0d160b5d3461e092f0f4&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6149ee69b5bd4bad8b893a2422c1c1a6</guid>
<title>IntelliJ IDEA 2022.2发布首个Beta版本</title>
<link>https://toutiao.io/k/jfldi2r</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;ImportNew&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;importnew&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;ImportNew 专注Java 技术分享，包括Java基础技术、进阶技能、架构设计和Java技术领域动态等&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ae581631cbcc9fe7ee3a1d8821731411</guid>
<title>网易游戏 Flink SQL 平台化实践</title>
<link>https://toutiao.io/k/h0wwrv1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;h2&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Apache Flink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Apache Flink&quot; data-alias=&quot;apacheflinkcc&quot; data-signature=&quot;Flink 中文社区官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;摘&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;要&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;本文整理自网易游戏资深开发工程师林小铂在 Flink Forward Asia 2021 平台建设专场的演讲。主要内容包括：&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;网易游戏 Flink SQL 发展历程&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于模板 jar 的 StreamflySQL v1&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 SQL Gateway 的 StreamflySQL v2&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;未来工作&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Tips：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;点击&lt;/span&gt;&lt;strong&gt;&lt;span&gt;「阅读原文」&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;查看原文视频&amp;amp;PPT～&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n14&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;网易游戏 Flink SQL 发展历程&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavyvnk5pFiciawP9A1D9ttTaeeqAg5YcD39WsCoT7kHxjiaFQnPQUEENAEA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网易游戏实时计算平台叫做 Streamfly，这个名字取名自电影《驯龙高手》中的 Stormfly。由于我们已经在从 Storm 迁移到 Flink，所以将 Stormfly 中的 Storm 替换成了更为通用的 Stream。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Streamfly 前身是离线作业平台 Omega 下的名为 Lambda 的子系统，它负责了所有实时作业的调度，最开始开始支持 Storm 和 Spark Streaming，后来改为只支持 Flink。在 2019 年的时候我们将 Lambda 独立出来以此为基础建立了 Streamfly 计算平台。随后，我们在 2019 年底开发并上线了第一个版本 Flink SQL 平台 StreamflySQL。这个版本基于模板 jar 提供了基本 Flink SQL 的功能，但是用户体验还有待提升，因此我们在 2021 年年初从零开始重新建设了第二个版本的 StreamflySQL，而第二个版本是基于 SQL Gateway。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要了解这两个版本的不同，我们需要先回顾下 Flink SQL 的基本工作流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p cid=&quot;n19&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiav2qUtkIRBuKY8RCVn2xLYf5he3R6ibIzyVRE4BatXhovEaz45h5tDlSw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户提交的 SQL 首先会被 Parser 解析为逻辑执行计划；逻辑执行计划经过 Planner Optimizer 优化，会生成物理执行计划；物理执行计划再通过 Planner CodeGen 代码生成，翻译为 DataStream API 常见的 Transformation；最后 StreamGraphGenerator 会将这些 Transformation 转换为 Flink 作业的最终表示 JobGraph 提交到 Flink 集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述一系列过程都发生在 TableEnvironment 里面。取决于部署模式的不同，TableEnvironment 可能运行在 Flink Client 或者 JobManager 里。Flink 现在支持 3 种集群部署模式，包括 Application、 Per-Job 和 Session 模式。在 Application 模式下，TableEnvironment 会在 JobManager 端运行，而在其余两种模式下，TableEnvironment 都运行在 Client 端。不过这三种模式都有一个共同的特点，TableEnvironment 都是一次性的，会在提交 JobGraph 之后自动退出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p cid=&quot;n22&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavYlWcW7xLfZeVKCZJCI5ocoiboCUjESwtGZV56ibWicH7qkv2ytqu3fwgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好地复用 TableEnvironment 提高效率和提供有状态的操作，有的项目会将 TableEnvironment 放到一个新的独立 Server 端进程里面去运行，由此产生了一种新的架构，我们称之为 Server 端 SQL 编译。相对地，还有 Client 端 SQL 编译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有同学可能会问，为什么没有 JobManager 端 SQL 编译，这是因为 JobManager 是相对封闭的组件，不适合拓展，而且即使做了达到的效果跟 Client 端编译效果基本一样。所以总体来看，一般就有 Client 和 Server 两种常见的 Flink SQL 平台架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Client 端 SQL 编译，顾名思义就是 SQL 的解析翻译优化都在 Client 端里进行（这里的 Client 是广义的 Client，并不一定是 Flink Client）。典型的案例就是通用模板 jar 和 Flink 的 SQL Client。这种架构的优点是开箱即用，开发成本低，而且使用的是 Flink public 的 API，版本升级比较容易；缺点是难以支持高级的功能，而且每次都要先启动一个比较重的 TableEnvironment 所以性能比较差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后是 Server 端 SQL 编辑。这种架构将 SQL 解析翻译优化逻辑放到一个独立的 Server 进程去进行，让 Client 变得非常轻，比较接近于传统数据库的架构。典型的案例是 Ververica 的 SQL Gateway。这种架构的优点是可拓展性好，可以支持很多定制化功能，而且性能好；缺点则是现在开源界没有成熟的解决方案，像上面提到 SQL Gateway 只是一个比较初期的原型系统，缺乏很多企业级特性，如果用到生产环境需要经过一定的改造，而且这些改造涉及比较多 Flink 内部 API，需要比较多 Flink 的背景知识，总体来说开发成本比较高，而且后续版本升级工作量也比较大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;编者按：Ap&lt;/span&gt;&lt;span&gt;ache Flink 社区目前正在开发 SQL Gateway 组件，将原生提供 Flink SQL 服务化的能力，并兼容 HiveServer2 协议，计划于 1.16 版本中发布，敬请期待。感兴趣的同学可以关注 FLIP-91&lt;span&gt;&lt;sup&gt;&lt;span&gt;[1] &lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;和 FLIP-223&lt;span&gt;&lt;sup&gt;&lt;span&gt;[2] &lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;了解更多，也非常欢迎大家参与贡献。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] https://cwiki.apache.org/confluence/display/FLINK/FLIP-91%3A+Support+SQL+Gateway &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2] https://cwiki.apache.org/confluence/display/FLINK/FLIP-223%3A+Support+HiveServer2+Endpoint &lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到我们 Flink SQL 平台，我们 StreamflySQL v1 是基于 Client 端 SQL 编译，而 v2 是基于 Server 端的 SQL 编译。下面就让我逐个介绍一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n37&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;基于模板 jar 的 StreamflySQL v1&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;StreamflySQL v1 选择 Client 端 SQL 编译的主要原因有三个:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p cid=&quot;n39&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavUeTQm5xhj5EtcjHxZqc9ibPwUIiaOYVXkAAic4HvJRGIMJgicgonqbASvw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n43&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiav96gVWvGVq23fqnTRO6P8icB3m9dzAEQedVjxlZlxOhFxTAWZMpw2DFQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是 v1 版本的整体架构图。我们在主要在 Lambda 作业平台的基础上新增了 StreamflySQL 后端作为配置中心，负责根据用户提交的 SQL 和作业运行配置加上通用的模板 jar 来生成一个 Lambda 作业。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;总体的作业提交流程如下:&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;用户在前端的 SQL 编辑器提交 SQL 和运行配置。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;StreamflySQL 后端收到请求后生成一个 Lambda 作业并传递配置 ID。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;然后 Lambda 启动作业，背后是执行 Flink CLI run 命令来提交作业。、&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink CLI run 命令会启动 Flink Client 来加载并执行模版 jar 的 main 函数，这时会读取 SQL 和配置，并初始化 TableEnvironment。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;TableEnvironment 会从 Catalog 读取必要的 Database/Table 等元信息。这里顺带一提是，在网易游戏我们没有使用统一的 Catalog 来维护不同组件的元信息，而是不同组件有自己的元数据中心，对应不同的 Catalog。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;最后 TableEnvironment 编译好 JobGraph，以 Per-Job Cluster 的方式部署作业。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;StreamflySQL v1 实现了 Flink SQL 平台从零到一的建设，满足了部分业务需求，但仍有不少痛点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第一个痛点是响应慢。&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n55&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiava81kMZqLfkC8AWNemrOS6wE0f4ibauW8ZEBnG9jhjbdVPbtDEus4RBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以一个比较典型的 SQL 来说，以模板 jar 的方式启动作业需要准备 TableEnviroment，这可能会花费 5 秒钟，然后执行 SQL 的编译优化包括与 Catalog 交互去获取元数据，也可能会花费 5 秒钟；编译得到jobgraph之后还需要准备 per-job cluster，一般来说也会花费 20 秒以上；最后还需要等待 Flink job的调度，也就是作业从 scheduled 变成 running 的状态，这个可能也需要 10 秒钟。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;总体来说，v1 版本启动一个 Flink SQL 作业至少需要 40 秒的时间，这样的耗时相对来说是比较长的。但是仔细分析这些步骤，只有 SQL的编译优化和 job 调度是不可避免的，其他的比如 TableEnvironment 和 Flink cluster 其实都可以提前准备，这里的慢就慢在资源是懒初始化的，而且几乎没有复用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第二个痛点是调试难。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n58&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavPbvwkkCE5uhujfUKIVZ2bSM67WBNz06bxJz4bmyaMkcWa6peWkrAkw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们对 SQL 调试的需求有以下几点：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一点是调试的 SQL 与线上的 SQL 要基本一致。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二点是调试 SQL 不能对线上的数据产生影响，它可以去读线上的数据，但不能去写。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三点，因为调试的 SQL 通常只需要抽取少量的数据样本就可以验证 SQL 的正确性，所以我们希望限制调试 SQL 的资源，一方面是出于成本的考虑，另外一方面也是为了防止调试的 SQL 与线上作业产生资源竞争。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第四点，因为调试 SQL 处理的数据量比较少，我们希望以更快更便捷的方式获取到结果。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 v1 版本中，我们对上述需求设计了如下解决方案：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;首先对于调试的 SQL，系统会在 SQL 翻译的时候将原来的一个 Sink 替换为专用的 PrintSink，这解决了需求中的前两点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;然后对 PrintSink 进行限流，通过 Flink 的反压机制达到总体的限流，并且会限制作业的最长执行时间，超时之后系统会自动把作业结束掉，这解决了需求中的资源限制这点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;最后为了更快地响应，调试的作业并不会提交到 YARN 集群上去运行，而是会在 Lamdba 服务器本地开启开启一个 MiniCluster 去执行，同时也方便我们从标准输出去提取 PrintSink 的结果，这点解决了需求中的最后一点。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavILJGlNfqJ3xg4Gml2cTnWCGrQnF131XAjRdHib6gBf8eYKdsCSB5kog/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;调试模式的架构如上图所示，比起一般的 SQL 提交流程，主要区别在于作业不会提交到 YARN 上，而是在 Lambda 服务器的本地执行，从而节省了准备 Flink 集群的开销，并且更容易管控资源和获取结果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上述调试解决方案基本可用，但是实际使用过程中依然存在不少问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一，如果用户提交的 SQL 比较复杂，那么 SQL 的编译优化可能会耗费比较久的时间，这会导致作业很容易超时，在有结果输出之前可能就被系统结束掉，同时这样的 SQL 也会给服务器造成比较大的压力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二，该架构没法去调试时间窗口比较长的作业或者需要 Bootstrap State 的作业。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三，因为执行结果是在作业结束之后才批量返回的，不是在作业执行过程中就流式返回，因此用户需要等到作业结束——通常是 10 分钟以上才可以看到结果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第四，在 SQL 的翻译阶段把调试 SQL 的 Sink 替换掉，这个功能是通过改造 Flink 的 Planner 来实现的，相当于业务逻辑入侵到了 Planner 里面，这样并不优雅。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第三个痛点是 v1 版本只允许单条 DML。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n75&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiaviauibCpeecXJIfjen4TyeqblicqVP7OP2hyqpF3Brjr3L5UpExA7Oibemg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;相比传统的数据库，我们支持的 SQL 语句是很有限的，比如，MySQL 的 SQL 可以分成 DML、DQL、DDL 和 DCL。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;DML 用于操控数据，常见的语句有 INSERT / UPDATE / DELETE。StreamflySQL v1 只支持了 INSERT，这和 Flink SQL 是保持一致的。Flink SQL 用 Retract 模式 — 也就是类似 Changelog 的方式 — 来表示 UPDATE/DELETE，所以只支持 INSERT，这点其实没有问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;DQL 用于查询数据，常见语句是 SELECT。这在 Flink SQL 是支持的，但因为缺乏 Sink 不能生成一个有意义的 Flink 作业，所以 StreamflySQL v1 不支持 DQL。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;DDL 用于定义元数据，常见语句是 CREATE / ALTER /DROP 等。这在 StreamflySQL v1 版本是不支持的，因为模板 jar 调用 SQL 的入口是 sqlUpdate，不支持纯元数据的操作，而且为纯元数据的操作单独启动一个 TableEnvironment 来执行也是完全不划算。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;最后是 DCL，用于管理数据权限，比如 GRANT 跟 REVOKE 语句。这个 Flink SQL 是不支持的，原因是 Flink 目前只是数据的用户而不是管理者，DCL 并没有意义。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;综合来看，v1 版本只支持了单条 DML，这让我们很漂亮的 SQL 编辑器变得空有其表。基于以上这些痛点，我们在今年调研并开发了 StreamflySQL v2。v2 采用的是 Server 端 SQL 编译的架构。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n84&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;基于 SQL Gateway 的 StreamflySQL v2&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n85&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavWr5S0pEdVOJGrn07SLDLKDibncibtJCeib9BNvS8D7KCwbDiciaojwBNvNw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们的核心需求是解决 v1 版本的几个痛点，包括改善用户体验和提供更完整的 SQL 支持。总体的思路是采用 Server 端的 SQL 编译的架构，提高可拓展性和性能。此外，我们的集群部署模式也改成 Session Cluster，预先准备好集群资源，省去启动 YARN application 的时间。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里会有两个关键问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;首先是我们要完全自研还是基于开源项目？在调研期间我们发现 Ververica 的 SQL Gateway 项目很符合我们需求，容易拓展而且是 Flink 社区 FLIP-91 SQL Gateway 的一个基础实现，后续也容易与社区的发展方向融合。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二个问题是，SQL Gateway 本身有提交作业的能力，这点跟我们已有的 Lambda 平台是重合的，会造成重复建设和难以统一管理的问题，比如认证授权、资源管理、监控告警等都会有两个入口。那么两者应当如何进行分工？我们最终的解决方案是，利用 Session Cluster 的两阶段调度，即资源初始化和作业执行是分离的，所以我们可以让 Lambda 负责 Session Cluster 的管理，而 StreamflySQL 负责 SQL 作业的管理，这样能复用 Lambda 大部分的基础能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n92&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavaG9H9WQm5JiaUOhvHVeANsiaHxQmB8m8eqL8hWzc233ZGCkPgibh0oicoA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这是 StreamflySQL v2 的架构图。我们将 SQL Gateway 内嵌到 SpringBoot 应用中，开发了新的后端。总体看起来比 v1 版本要复杂，原因是原本的一级调度变成了会话和作业的两级调度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先用户需要创建一个 SQL 会话，StreamflySQL 后端会生成一个会话作业。在 Lambda 看来会话作业是一种特殊作业，启动时会使用 yarn-session 的脚本来启动一个 Flink Session Cluster。在 Session Cluster 初始化之后，用户就可以在会话内去提交 SQL。StreamflySQL 后端会给每个会话开启一个 TableEnvironment，负责执行 SQL 语句。如果是只涉及元数据的 SQL，会直接调用 Catalog 接口完成，如果是作业类型的 SQL，会编译成 JobGraph 提交到 Session Cluster 去执行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n97&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavyERvjqrRm4IzNlsRewaSHMy5CleicbxzBXIbR8JSr8J0OIfCeyr62Lw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;v2 版本很大程度上解决了 v1 版本的几个痛点:&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在响应时间方面，v1 常常会需要 1 分钟左右，而 v2 版本通常在 10 秒内完成。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在调试预览方面，v2 不需要等作业结束，而是在作业运行时，将结果通过 socket 流式地返回。这点是依赖了 SQL gateway 比较巧妙的设计。对于 select 语句，SQL Gateway 会自动注册一个基于 socket 的临时表，并将 select 结果写入到这个表。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在 SQL 支持方面，v1 只支持 DML，而 v2 借助于 SQL Gateway 可以支持 DML/DQL/DDL。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;不过 SQL Gateway 虽然有不错的核心功能，但我们使用起来并不是一帆风顺，也遇到一些挑战。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;首先最为重要的是元数据的持久化。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n106&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavU44DdXqOWZ5P7nfO3qmncvSgficKmS9aC0vABUKC3ibZGSMKWAGSOraw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SQL Gateway 本身的元数据只保存在内存中，如果进程重启或是遇到异常崩溃，就会导致元数据丢失，这在企业的生产环境里面是不可接受的。因此我们将 SQL Gateway 集成到 SpringBoot 程序之后，很自然地就将元数据保存到了数据库。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;元数据主要是会话元数据，包括会话的 Catalog、Function、Table 和作业等等。这些元数据按照作用范围可以分为 4 层。底下的两层是全局的配置，以配置文件的形式存在；上面两层是运行时动态生成的元数据，存在数据库中。上层的配置项优先级更高，可以用于覆盖下层的配置。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们从下往上看这些元数据：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;最底层是全局的默认 Flink Configuration，也就是我们在 Flink Home 下的 flink-conf yaml 配置。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;再上面一层是 Gateway 自身的配置，比如部署模式（比如是 YARN 还是 K8S），比如默认要出册的 Catalog 和 Function 等等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三层是 Session 会话级别的 Session Configuraion，比如会话对应的 Session Cluster 的集群 ID 或者 TaskManager 的资源配置等等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;最上面一层是 Job 级别的配置，包括作业动态生成的元数据，比如作业 ID、用户设置 checkpoint 周期等等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这样比较灵活的设计除了解决了元数据持久化的问题，也为我们的多租户特性奠定了基础。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第二个挑战是多租户。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n118&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavKcSsiaZ4HrUrUuGicibvT1dV2AFu8RkdxOhrxZ74w6qwzL1Y0h4k8Qe1g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;多租户分为资源和认证两个方面：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在资源方面，StreamflySQL 利用 Lambda 作业平台可以在不同的队列启动 Session Cluster，它们的 Master 节点和资源很自然就是隔离的，所以没有像 Spark Thrift Server 那样不同用户共用一个 Master 节点和混用资源的问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在认证方面，因为 Session Cluster 属于不同用户，所以 StreamflySQL 后端需要实现多租户的伪装。在网易游戏，组件一般会使用 Kerberos 认证。我们采用多租户实现的方式是使用 Hadoop 的 Proxy User，先登录为超级用户，然后伪装成项目用户来向不同组件获取 delegation token，这里的组件主要是 Hive MetaStore 跟 HDFS，最后把这些 token 存到 UGI 里面并用 doAS 的方式来提交作业。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第三个挑战是水平拓展。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n124&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavB9gutsws9TL51NZCBN0EIyaGHrX2f5SUpa4KAeENBuwS0l7OX33IJw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了高可用和拓展服务能力，StreamflySQL 很自然需要以多实例的架构部署。因为我们已经将主要的状态元数据存到数据库，我们可以随时从数据库构建出一个新的 TableEnvironment，所以 StreamflySQL 实例类似普通 Web 服务一样非常轻，可以很容易地扩容缩容。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;但是并不是所有状态都可以持久化的，另外有些状态我们故意会不持久化。比如用户使用 SET 命令来改变 TableEnvironment 的属性，比如开启 Table Hints，这些属于临时属性，会在重建 TableEnvironment 后被重置。这是符合预期的。再比如用户提交 select 查询做调试预览时，TaskManager 会与 StreamflySQL 后端建立 socket 链接，而 socket 链接显然也是不可持久化的。因此我们在 StreamflySQL 的多实例前加了亲和性的负载均衡，按照 Session ID 来调度流量，让在正常情况下同一个用户的请求都落到同一个实例上，确保用户使用体验的连续性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第四个挑战是作业状态管理。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n129&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavyfPwI0yppGc038CTl6V8PAmKuHA5jopUR70z4DD1CzNNnMicWcWSLGQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其实这里的状态一词是双关，有两个含义：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一个含义是作业的运行状态。SQL gateway 目前只是提交 SQL 并不监控后续的运行状态。因此，StreamflySQL 设置了监控线程池来定时轮询并更新作业状态。因为 StreamflySQL 是多实例的，它们的监控线程同时操作同一个作业的话，可能会有更新丢失的问题，所以我们这里使用了 CAS 乐观锁来保证过时的更新不会生效。然后我们会在作业异常退出或者无法获取状态时进行告警，比如 JobManager 进行 failover 的情况下，我们无法得知 Flink 作业的状态，这时系统就会发出 disconnected 的异常状态告警。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二个含义是 Flink 的持久化状态，即 Flink State。原生的 SQL gateway 并没有管理 Flink 的 Savepoint 和 Checkpoint，因此我们加上了 stop 和 stop-with-savepoint 的功能，并强制开启 retained checkpoint。这使得在作业遇到异常终止或者简单 stop 之后，再次重启时系统可以自动查找到最新的 checkpoint。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里我可以分享下我们的算法。其实自动查找最新 checkpoint 的功能 Lambda 也有提供，但是 Lambda 假设作业都是 Per-Job Cluster，因此只要查找集群 checkpoint 目录里最新的一个 checkpoint 就可以了。但这样的算法对 StreamflySQL 却不适用，因为 Session Cluster 有多个作业，最新的 checkpoint 并不一定是我们目标作业的。因此，我们改为了使用类似 JobManager HA 的查找方式，先读取作业归档目录元数据，从里面提取最新的一个 checkpoint。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;04&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n138&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;未来工作&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n139&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ypbldJibtZvYABKDnUytiavxDH8mK4odhtQwjgiajtnfwz2RW5OBIGnW39bkGCCTwoc6nr2fjG1wicA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;未来我们首先要解决的一个问题是 State 迁移的问题，即用户对 SQL 进行变更后，如何从原先的 Savepoint 进行恢复。目前只能通过变更类型来告知用户风险，比如通常而言加减字段不会造成 Savepoint 的不兼容，但如果新增一个 join 表，造成的影响就很难说了。因此后续我们计划通过分析 SQL 变更前后的执行计划，来预先告知用户变更前后的状态兼容性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二个问题是细粒度的资源管理。目前我们并不能在作业编译时去指定 SQL 的资源，比如 TaskManager 的 CPU 和内存在 Session Cluster 启动之后就确定了，是会话级别的。目前调整资源只能通过作业并行度调整，很不灵活并且容易造成浪费。现在 Flink 1.14 已经支持了 DataStream API 的细粒度资源管理，可以在算子级别设置资源，但 SQL API 现在还没有计划，后续我们可能参与进去推动相关议案的进展。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;最后是社区贡献。我们对 SQL Gateway 有一定使用经验，而且也对其进行了不少的改进，后续希望这些改进能回馈给 Flink 社区，推动 FLIP-91 SQL Gateway 的进展。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;往期精选&lt;/p&gt;&lt;/section&gt;&lt;img data-ratio=&quot;2&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4xD6UfczsbsschXJDhYWrmCoyoiaA0ObsZibBfAEjX32ibgufrRibwUD41Rb5faeM7rn5WsJJKP5TFAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;50&quot;/&gt; &lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247498810&amp;amp;idx=1&amp;amp;sn=4b09d77923c700e9d0fa11d5f278746e&amp;amp;chksm=fd387278ca4ffb6e0e3f589b90b648135575c617453826e3cf9a9ffb11e582b2e4f203f12351&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4259259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu4xD6UfczsbsschXJDhYWrmqibOMpS3x54OgtlicvATfpPqFtgMX8FvpYOOmQQLibMKhKbCrdF4BPFIA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247498786&amp;amp;idx=1&amp;amp;sn=6b3664ff103410c2f0828967980105fa&amp;amp;chksm=fd387260ca4ffb7698b4943ad9d6616166b6e3c9c2d75d268626b9ce746f056f2c1bda5b9f9a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4259259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu4xD6UfczsbsschXJDhYWrmfXkqic3PyibTZnaV8QFyicVzcbGLnDmiaGAGoBYb2ls6wykOQUUNFnocGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247498721&amp;amp;idx=1&amp;amp;sn=bc4ddafcf374d651b7de8c6d044ed302&amp;amp;chksm=fd3875a3ca4ffcb5d5d38a835f1849d7f33e609447511132289420174f723185056627f1ad28&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4xD6UfczsbsschXJDhYWrmx7JAMXTxmJkzYnHnwicp2WTP9ZxN9DBmf1KRSzbkGrQtjt2Kz2AyH5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247498575&amp;amp;idx=1&amp;amp;sn=5a4dbb383c259523eb830529aa8ba34a&amp;amp;chksm=fd38750dca4ffc1b04915e4875af96b0689d7c39a7ed0855b9ffae068403e5cdbf591c978ddc&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4xD6UfczsbsschXJDhYWrmEhYypkZDLmuq9QqoPzSzTXtTG9Buiaib14OqRPuJEthfZTa6ptqGeTDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Apache Flink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Apache Flink&quot; data-alias=&quot;apacheflinkcc&quot; data-signature=&quot;Flink 中文社区官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;4&quot; data-cropselx2=&quot;204&quot; data-cropsely1=&quot;1&quot; data-cropsely2=&quot;243&quot; data-fileid=&quot;100010716&quot; data-ratio=&quot;1.162531017369727&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu573SfR5B9zrZybQe6w2yUInzu48HG5BMCDdHgE77LRzrnlGSl2kzKKfp9ypsduOukxibm1W99g26w/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;806&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100010714&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot;/&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;点击「阅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;读原文&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，查看原文视频 &amp;amp; PPT&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>