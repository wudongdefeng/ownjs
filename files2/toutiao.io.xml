<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>50af2cca8b140c815139b8d2b8bfb94e</guid>
<title>如何用 Vue + 免费的 WebDB 实现一个世界杯足球竞猜系统</title>
<link>https://toutiao.io/k/uvrxuq9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;最近世界杯在如火如荼的进行。我们都知道，中国也派出了我们的一支强大的队伍：中国建筑队，全程参与了世界杯的所有比赛。&lt;/p&gt;

&lt;p&gt;哈哈开个玩笑，不过说到世界杯，还真有不少朋友，不仅仅是看球，还切身参与了。比如足彩，世界杯竞猜等等活动。&lt;/p&gt;

&lt;p&gt;那么今天我们就通过kintone来自己实现一个世界杯竞猜系统吧！&lt;/p&gt;

&lt;h1&gt;视频学习&lt;/h1&gt;

&lt;p&gt;开始学习前，可以先来看看本文的视频“如何用vue+免费的web db，来实现一个世界杯足球竞猜系统”，可以帮助你更好的理解本文的思路，更能提高学习的效率。配合着视频我们快来学习吧！&lt;/p&gt;

&lt;h1&gt;功能梳理&lt;/h1&gt;

&lt;h2&gt;想要实现的功能如下：&lt;/h2&gt;

&lt;p&gt;用户竞猜前台：
1 每个人拥有自己独立的积分&lt;/p&gt;

&lt;p&gt;2 有比赛列表，赔付率信息。能实现各自投票。&lt;/p&gt;

&lt;p&gt;3 有个人信息界面，列出我的积分，往期竞猜信息及结果。&lt;/p&gt;

&lt;p&gt;竞猜系统后台：
1 可以录入比赛信息，赔付率信息。可以到期进行开奖。&lt;/p&gt;

&lt;p&gt;2 可以查询用户的竞猜信息。&lt;/p&gt;

&lt;p&gt;3 用户的积分变化有迹可查。&lt;/p&gt;

&lt;h1&gt;如何实现？&lt;/h1&gt;

&lt;p&gt;效果看完了，那这个世界杯竞猜系统是如何通过kintone实现的呢？&lt;/p&gt;

&lt;h2&gt;应用准备&lt;/h2&gt;

&lt;p&gt;这个世界杯竞猜系统可以简单通过以下应用进行搭建 &lt;/p&gt;

&lt;p&gt;1 球队信息应用：&lt;/p&gt;

&lt;p&gt;记录球队名，球队国旗等。&lt;/p&gt;

&lt;p&gt;2 比赛信息应用：&lt;/p&gt;

&lt;p&gt;记录比赛的两支球队，场次，该场比分，赔付率等。&lt;/p&gt;

&lt;p&gt;3 用户竞猜信息应用：&lt;/p&gt;

&lt;p&gt;记录用户id，他的竞猜的比赛场次，胜负，竞猜使用的积分等。&lt;/p&gt;

&lt;p&gt;4 积分变更履历应用：&lt;/p&gt;

&lt;p&gt;记录用户积分变化的履历，每个场次押注所获得或者付出的积分。&lt;/p&gt;

&lt;p&gt;5 轮播图应用&lt;/p&gt;

&lt;p&gt;记录一些比赛精彩图片，美化页面。&lt;/p&gt;

&lt;h2&gt;系统开发&lt;/h2&gt;

&lt;p&gt;接下来分享下这个系统是如何开发的。&lt;/p&gt;

&lt;p&gt;整个投注系统使用Vue3框架来实现。&lt;/p&gt;

&lt;p&gt;引入根节点
首先通过kintone的 JS API来获取门户上方的空白部分的元素 kintone.portal.getContentSpaceElement()，将其作为根节点。这样就能把Vue产生的页面挂载到这个根结点上。同时可以引入Pinia作为集中式状态管理，Element UI 作为我们的UI框架。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { createApp } from &quot;vue&quot;;
import App from &quot;./App.vue&quot;;
import installElementPlus from &quot;@/libs/element&quot;;
import { createPinia } from &quot;pinia&quot;;
/* eslint-disable */
kintone.events.on(&quot;portal.show&quot;, (event) =&amp;gt; {
    const myContainer = kintone.portal.getContentSpaceElement();
    const app = createApp(App);
    installElementPlus(app);
    app.use(createPinia());
    app.mount(myContainer);
    return event;
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;准备数据源，获取数据
然后通过kintone的REST API就能将kintone各个应用中的数据取出来，并在页面上进行展示。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import { KintoneRestAPIClient } from &quot;@kintone/rest-api-client&quot;;
const client = new KintoneRestAPIClient();

//获取比赛列表
export const GetMatchList = async () =&amp;gt; {
    const app = appList.matchInfo;
    import {appList,matchInfoField,usersField,userChipInField,picField} from &quot;@/config&quot;;
    try {
        const params = {
            app,
        };
        const resp = await client.record.getRecords(params);
        if (resp.records.length &amp;gt; 0) {
        return resp.records.map((record) =&amp;gt; {
            return dataConvert(record);
        });
        } else {
            return null;
        }
    } catch (err) {
        console.log(err);
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多语言开发
同时通过kintone.getLoginUser()我们可以获取到当前登陆用户的信息。其中包含了他的语言信息。根据语言信息，我们可以配置I18N做多语言的开发。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const { language } = kintone.getLoginUser();
//   &#x27;language&#x27;: &#x27;zh&#x27;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;集中式状态管理
可以将用户的剩余积分，比赛下注信息等写入集中式状态管理，因为他可能会在多页面进行响应式变化。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import {
  GetLeftScore,
  GetChipInList,
  GetMatchList,
} from &quot;@/services/kintoneApi&quot;;
import { defineStore } from &quot;pinia&quot;;

export const useStore = defineStore(&quot;store&quot;, {
  state: () =&amp;gt; {
    return {
      myScore: 0,
      chipInList: [],
    };
  },

  getters: {
    chipListShow(state) {
      return state.chipInList.map((record) =&amp;gt; {
        if (record.Score_result == 0) {
          record.scoreWin = &quot;--&quot;;
          record.teamInfo.Score = &quot;--&quot;;
          record.type = &quot;chip in&quot;;
        } else if (record.Score_result &amp;lt; 0) {
          record.scoreWin = `--`;
          record.type = &quot;loss&quot;;
        } else {
          record.scoreWin = `+ ${record.Score_result}`;
          record.type = &quot;win&quot;;
        }
        return record;
      });
    },
  },

  actions: {
    async init() {
      const initLeftScorePromise = this.getLeftScore();
      const initChipInListPromise = this.getChipInList();
      return Promise.all([initLeftScorePromise, initChipInListPromise]);
    },

    async getLeftScore() {
      this.myScore = await GetLeftScore();
    },

    async getChipInList() {
      const chipInList = await GetChipInList();
      const matches = await GetMatchList();
      const matchMapping = {};
      for (const item of matches) {
        matchMapping[item.Match_id] = {
          FlagA: item.FlagA,
          FlagB: item.FlagB,
          TeamA_name: item.TeamA_name,
          TeamB_name: item.TeamB_name,
          Score: `${item.ScoreA}:${item.ScoreB}`,
        };
      }
      chipInList.map((chip) =&amp;gt; {
        chip.teamInfo = matchMapping[chip.Match_id];
        return chip;
      });
      this.chipInList = chipInList;
    },
  },
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;竞猜系统整体说明&lt;/h1&gt;

&lt;p&gt;首先是可以通过管理员给每个用户录入一些初始积分，用户有了积分可以进行比赛的胜负平的竞猜。比赛场次，胜负平赔付率可以通过取出后台数据后进行展示。&lt;/p&gt;

&lt;p&gt;当用户进行竞猜后，会将记录写入用户竞猜信息应用。同时还可以计算出用户的剩余积分，用户的竞猜列表等。&lt;/p&gt;

&lt;h1&gt;开奖系统整体说明&lt;/h1&gt;

&lt;p&gt;开奖系统可以直接对比赛信息应用进行自定义开发。&lt;/p&gt;

&lt;p&gt;当比赛结束出来结果后，管理员可以录入比分，自动计算出比赛结果。然后可以一键开奖，系统自动计算出哪些用户猜对了比赛，并且通过赔付率计算出他所获得的积分。并且写入到用户的积分履历中去。&lt;/p&gt;

&lt;h1&gt;开发上的注意点&lt;/h1&gt;

&lt;p&gt;因为这里没有后端系统，所以可能存在用户自行通过伪造请求等方式生成投票数据。这样就有可能出现：&lt;/p&gt;

&lt;p&gt;1 帮别人投票，让别人无分可投&lt;/p&gt;

&lt;p&gt;2 让自己的投票超出自己的积分&lt;/p&gt;

&lt;p&gt;3 比赛结束后进行投票&lt;/p&gt;

&lt;p&gt;等等一系列的问题。那这边如何一一化解呢？&lt;/p&gt;

&lt;p&gt;1 伪造别人投票：可以通过应用的创建者字段来实现。因为这个字段是系统后端自动生成，所以不再有这个困扰。&lt;/p&gt;

&lt;p&gt;2 让自己的投票超出自己的积分：为防止这种篡改积分的情况，这里将用户的竞猜列表和积分列表分开。竞猜列表用户有读写权限，但是积分列表用户只有读取权限。&lt;/p&gt;

&lt;p&gt;通过kintone的权限设置，普通登录用户都是只读权限，没有修改权限。然后通过管理员用户的开奖系统对用户的竞猜进行审核。过滤后，由管理员进行修改（当然这些都是代码自动实现的。）&lt;/p&gt;

&lt;p&gt;比如判断用户的投票时，会先计算出他当前没有开奖的投票总数是否大于他剩余的积分。这样就能防止他是否会进行伪造投票。&lt;/p&gt;

&lt;p&gt;3 超过时间的投票：通过kintone自带的更新时间字段（这是用户无法自行修改的特点），判断用户该条投票记录的更新时间是否超过该场比赛的投票截止时间，就能过滤掉用户的超时伪造投票。&lt;/p&gt;

&lt;p&gt;经过以上种种的判断，就能很好的避免了用户伪造的数据，让这次投票无需服务器，也能变得安全可靠了。&lt;/p&gt;

&lt;h1&gt;代码分享&lt;/h1&gt;

&lt;p&gt;参考：&lt;a href=&quot;https://cybozudev.kf5.com/hc/kb/article/1588162/&quot;&gt;https://cybozudev.kf5.com/hc/kb/article/1588162/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;视频参考：&lt;a href=&quot;https://www.bilibili.com/video/BV1Q841157A3/&quot;&gt;https://www.bilibili.com/video/BV1Q841157A3/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8e854183c2a04f5488d3ade3030be829</guid>
<title>硬核干货！一文掌握 binlog 、redo log、undo log</title>
<link>https://toutiao.io/k/74mfq4h</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzA3MDg5MDkzOA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgQmUQ0Aca9qSYNFn0tQEXQc5EibBkqQLYtibYBj1hXuagwXkNc3kVwplHxIl7KQfBIiagysgn9GDUUibw/0?wx_fmt=png&quot; data-nickname=&quot;架构精进之路&quot; data-alias=&quot;jiagou_jingjin&quot; data-signature=&quot;十年研发风雨路，大厂架构师，CSDN博客专家，InfoQ写作社区签约作者。专注软件架构研究，技术学习与职业成长，坚持分享接地气儿的架构技术干货文章！&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;hello，大家好，我是张张，「架构精进之路」公号作者。&lt;/span&gt;&lt;/p&gt;&lt;p data-pm-slice=&quot;1 1 []&quot;&gt;&lt;span&gt;在MySQL 中我们经常会接触到三个核心日志，它们分别是：binlog 、redo log、undo log。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好多同学对于它们可能并不陌生，但是具体区分起来各自的功能用途以及实现原理，那可能认知就会比较模糊了，今天就跟大家一起，来清晰明了的介绍一下这些日志的核心思想和功能原理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mpcps class=&quot;js_editor_new_cps&quot; data-templateid=&quot;list&quot; data-traceid=&quot;e8581707-ffb7-45f6-a5b8-9d4f2d6d0181&quot; data-goodssouce=&quot;1&quot; data-pid=&quot;101_12574719&quot; data-appuin=&quot;3070890938&quot; data-buffer=&quot;{&amp;quot;category_id&amp;quot;:10,&amp;quot;pid&amp;quot;:&amp;quot;101_12574719&amp;quot;,&amp;quot;biz_uin&amp;quot;:&amp;quot;3070890938&amp;quot;,&amp;quot;trace_id&amp;quot;:&amp;quot;e8581707-ffb7-45f6-a5b8-9d4f2d6d0181&amp;quot;,&amp;quot;sku_id&amp;quot;:&amp;quot;101_12574719&amp;quot;,&amp;quot;source_id&amp;quot;:2,&amp;quot;source_name&amp;quot;:&amp;quot;京东&amp;quot;,&amp;quot;audit_state&amp;quot;:1,&amp;quot;main_img&amp;quot;:&amp;quot;https://pcm-img.zhls.qq.com/productcenter-76bb2afd--1018824-6340041869161675403/98952071429072022/55fe5917a5d54c102dba032ba09741ae.jpg&amp;quot;,&amp;quot;product_name&amp;quot;:&amp;quot;深入浅出MySQL 数据库开发 优化与管理维护 第3版(异步图书出品)&amp;quot;,&amp;quot;current_price&amp;quot;:12010,&amp;quot;first_category_id&amp;quot;:&amp;quot;10&amp;quot;,&amp;quot;product_label_name_list&amp;quot;:[&amp;quot;京东配送&amp;quot;],&amp;quot;select_tag_name_list&amp;quot;:[],&amp;quot;appuin&amp;quot;:&amp;quot;3070890938&amp;quot;,&amp;quot;isNewCpsKOL&amp;quot;:1,&amp;quot;templateId&amp;quot;:&amp;quot;list&amp;quot;}&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;1 binlog&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;1.1 binlog 设计目标&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;binlog 记录了对MySQL数据库执行更改的所有的写操作，包括所有对数据库的数据、表结构、索引等等变更的操作。&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;注意：这其中不包含SELECT、SHOW等，因为对数据没有修改&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;只要是对数据库有变更的操作都会记录到binlog里面来，我们可以把数据库的数据看做银行账户里的余额，而binlog就相当于我们银行卡的流水记录。账户余额只是一个结果，至于这个结果怎么来的，那就必须得看流水了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实际应用中， binlog 的主要应用场景分别是 &lt;strong&gt;主从复制&lt;/strong&gt; 和 &lt;strong&gt;数据恢复&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p data-number=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;主从复制&lt;/strong&gt; ：在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 来达到主从数据一致。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-number=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt;数据恢复&lt;/strong&gt; ：通过使用 mysqlbinlog 工具来恢复数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-number=&quot;2&quot;&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.2 binlog 数据格式&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;binlog 日志有三种格式，分别为 STATMENT 、 ROW 和 MIXED。&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;在 MySQL 5.7.7 之前，默认的格式是 STATEMENT ， MySQL 5.7.7 之后，默认值是 ROW。日志格式通过 binlog-format 指定。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;ROW&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：基于行的复制（row-based replication, RBR），不记录每条SQL语句的上下文信息，仅需记录哪条数据被修改了。如果一个update语句修改一百行数据，那么这种模式下就会记录100行对应的记录日志。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;STATMENT&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：基于SQL语句的复制( statement-based replication, SBR )，每一条会修改数据的SQL语句会记录到 binlog 中 。相对于ROW模式，STATEMENT模式下只会记录这个 update 的语句，所以此模式下会非常节省日志空间，也避免着大量的IO操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MIXED&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：基于 STATMENT 和 ROW 两种模式的混合复制（mixed-based replication, MBR），一般的复制使用 STATEMENT 模式保存 binlog ，对于一些函数，STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于这三种模式需要注意的是：&lt;/span&gt;&lt;/p&gt;&lt;p data-indent-1=&quot;&quot;&gt;&lt;span&gt;1）使用 row 格式的 binlog 时，在进行数据同步或恢复的时候不一致的问题更容易被发现，因为它是基于数据行记录的。&lt;/span&gt;&lt;/p&gt;&lt;p data-indent-1=&quot;&quot;&gt;&lt;span&gt;2）使用 mixed 或者 statement 格式的 binlog 时，很多事务操作都是基于SQL逻辑记录，我们都知道一个SQL在不同的时间点执行它们产生的数据变化和影响是不一样的，所以这种情况下，数据同步或恢复的时候就容易出现不一致的情况。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;1.3 binlog 写入策略&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;对于 InnoDB 存储引擎而言，在进行事务的过程中，首先会把binlog 写入到binlog cache中（因为写入到cache中会比较快，一个事务通常会有多个操作，避免每个操作都直接写磁盘导致性能降低），只有在事务提交时才会记录 biglog ，此时记录还在内存中，那么 biglog 是什么时候刷到磁盘中的呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MySQL 其实是通过 sync_binlog 参数控制 biglog 的刷盘时机，取值范围是 0-N：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;0&lt;/strong&gt;：每次提交事务binlog不会马上写入到磁盘，而是先写到page cache。不去强制要求，由系统自行判断何时写入磁盘，在Mysql 崩溃的时候会有丢失日志的风险；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1&lt;/strong&gt;：每次提交事务都会执行 fsync 将 binlog 写入到磁盘；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;N&lt;/strong&gt;：每次提交事务都先写到page cach，只有等到积累了N个事务之后才 fsync 将 binlog 写入到磁盘，在 MySQL 崩溃的时候会有丢失N个事务日志的风险。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;很显然三种模式下，sync_binlog=1 是强一致的选择，选择0或者N的情况下在极端情况下就会有丢失日志的风险，具体选择什么模式还是得看系统对于一致性的要求。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;2、redo log&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.1 redo log 设计目标&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;redo log 是属于引擎层(innodb)的日志，称为&lt;strong&gt;重做日志&lt;/strong&gt; ，当MySQL服务器意外崩溃或者宕机后，&lt;strong&gt;保证已经提交的事务&lt;/strong&gt;持久化到磁盘中（&lt;strong&gt;持久性&lt;/strong&gt;）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它能保证对于已经COMMIT的事务产生的数据变更，即使是系统宕机崩溃也可以通过它来进行数据重做，达到数据的持久性，一旦事务成功提交后，不会因为异常、宕机而造成数据错误或丢失。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.2 redo log 数据格式&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;redo log 包括两部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MySQL 每执行一条 DML 语句，先将记录写入 redo log buffer，后续某个时间点再一次性将多个操作记录写到 redo log file。&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;通常所说的&lt;strong&gt;Write-Ahead Log&lt;/strong&gt;(预先日志持久化)指的是&lt;strong&gt;在持久化一个数据页之前，先将内存中相应的日志页持久化。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;在计算机操作系统中，用户空间( user space )下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( kernel space )缓冲区( OS Buffer )。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此， redo log buffer 写入 redo logfile 实际上是先写入 OS Buffer ，然后再通过系统调用 fsync() 将其刷到 redo log file中，过程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8257918552036199&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HI0lX5uiaaaOnGCDD9ZOtN66t6BUqdDTl1YQ6s4SDlSdSASg2U7XJ24A/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;442&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;修改数据的操作流程：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.569078947368421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HtYj1ItVKd2pdolDibrlhwDQWsQHx9DFLPiacz3WmARFtdLrDumIzgo9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;912&quot;/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p data-number=&quot;1&quot;&gt;&lt;span&gt;先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝，产生脏数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-number=&quot;2&quot;&gt;&lt;span&gt;生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-number=&quot;3&quot;&gt;&lt;span&gt;默认在事务提交后将redo log buffer中的内容刷新到redo log file，对redo log file采用追加写的方式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-number=&quot;4&quot;&gt;&lt;span&gt;定期将内存中修改的数据刷新到磁盘中（这里说的是那些还没及时被后台线程刷盘的脏数据）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-number=&quot;4&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;2.3 关于 redo log 的几点疑惑&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;读到这里，相必有同学会有如下疑问：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q1：为什么不直接修改磁盘中的数据？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为直接修改磁盘数据的话，它是随机IO，修改的数据分布在磁盘中不同的位置，需要来回的查找，所以命中率低，消耗大，而且一个小小的修改就不得不将整个页刷新到磁盘，利用率低；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与之相对的是顺序IO，磁盘的数据分布在磁盘的一块，所以省去了查找的过程，节省寻道时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用后台线程以一定的频率去刷新磁盘可以降低随机IO的频率，增加吞吐量，这是使用buffer pool的根本原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q2：同为操作数据变更的日志，有了binlog为什么还要redo log？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为最核心的一点就是&lt;strong&gt;两者记录的数据变更粒度是不一样&lt;/strong&gt;的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以修改数据为例，binlog 是以表为记录主体，在ROW模式下，binlog保存的表的每行变更记录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MySQL 是以页为单位进行刷盘的，每一页的数据单位为16K，所以在刷盘的过程中需要把数据刷新到磁盘的多个扇区中去。而把16K数据刷到磁盘的每个扇区里这个过程是无法保证原子性的，如果数据库宕机，那么就可能会造成一部分数据成功，而一部分数据失败的情况。而通过 binlog 这种级别的日志是无法恢复的，因为一个update可能更改了多个磁盘区域的数据，所以这个时候得需要通过redo log这种记录到磁盘数据级别的日志进行数据恢复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5046296296296297&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HCpcJJaE2vH1mN34Fk7oBoVH5gMJZqq6iaDmYtLOFgVg8HJIrGnW05pQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由以上两者的对比可知：binlog 日志只用于归档，只依靠 binlog 是没有 crash-safe 能力的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样只有 redo log 也不行，因为 redo log 是 InnoDB特有的，且日志上的记录落盘后会被覆盖掉。因此需要 binlog和 redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Q3：redo log一定能保证事务的持久性吗？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不一定，这要根据redo log的刷盘策略决定，因为redo log buffer同样是在内存中，如果提交事务之后，redo log buffer还没来得及将数据刷新到redo log file进行持久化，此时发生宕机照样会丢失数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那该如何解决呢？刷盘写入策略。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;2.4 redo log 写入策略&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;当redo log空间满了之后又会从头开始以循环的方式进行覆盖式的写入。MySQL 支持三种将 redo log buffer 写入 redo log file 的时机，可以通过 innodb_flush_log_at_trx_commit 参数配置，各参数含义如下：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;0（延迟写）&lt;/strong&gt;：表示每次事务提交时都只是把 redo log 留在 redo log buffer 中，开启一个后台线程，每&lt;strong&gt;1s&lt;/strong&gt;刷新一次到磁盘中 ;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1（实时写，实时刷）&lt;/strong&gt;：表示每次事务提交时都将 redo log 直接持久化到磁盘，真正保证数据的持久性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2（实时写，延迟刷）&lt;/strong&gt;：表示每次事务提交时都只是把 redo log 写到 page cache，具体的刷盘时机不确定。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了上面几种机制外，还有其它两种情况会把redo log buffer中的日志刷到磁盘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;3、undo log&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;3.1 undo log设计目标&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;redo log 是也属于引擎层(innodb)的日志，从上面的redo log介绍中我们就已经知道了，redo log 和undo log的核心是为了保证innodb事务机制中的持久性和原子性，事务提交成功由redo log保证数据持久性，而事务可以进行回滚从而保证事务操作原子性则是通过undo log 来保证的。&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;原子性 是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;undo log 的主要应用场景分别：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p data-number=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;事务回滚&lt;/strong&gt; ：前面提到过，后台线程会不定时的去刷新buffer pool中的数据到磁盘，但是如果该事务执行期间出现各种错误(宕机)或者执行rollback语句，那么前面刷进去的操作都是需要回滚的，保证原子性，undo log就是提供事务回滚的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-number=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt;MVCC&lt;/strong&gt;：当读取的某一行被其他事务锁定时，可以从undo log中分析出该行记录以前的数据版本是怎样的，从而让用户能够读取到当前事务操作之前的数据——快照读。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-number=&quot;2&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;3.2 undo log 数据格式&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;undo log 数据主要分两类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;insert 操作的记录，只对事务本身可见，对其他事务不可见(这是事务隔离性的要求)，故该undo log可以在事务提交后直接删除，不需要进行purge操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;update undo log记录的是对delete和update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能在事务提交时就进行删除。提交时放入undo log链表，等待purge线程进行最后的删除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在InnoDB存储引擎中，undo log使用rollback segment回滚段进行存储，每隔回滚段包含了1024个undo log segment。MySQL5.5之后，一共有128个回滚段。即总共可以记录128 * 1024个undo操作。&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;每个事务只会使用一个回滚段，一个回滚段在同一时刻可能会服务于多个事务。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;3.3 undo log 操作实例&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1、首先准备一张原始原始数据表（user_info）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于InnoDB引擎来说，每个行记录除了记录本身的数据之外，还有几个隐藏的列:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.22832369942196531&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HvuqfKzEVxpMxrpmppVIrApeiaPepO6JgRILbZWce1fHvckZmjhkytcA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;692&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2、开启一个事务A&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对 user_info 表执行如下SQL：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;update user_info set name =“李四”where id=1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;将会进行如下流程操作：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、首先获得一个事务编号 104&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、把user_info表修改前的数据拷贝到undo log&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、修改user_info表 id=1的数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、把修改后的数据事务版本号改成 当前事务版本号，并把DB_ROLL_PTR 地址指向undo log数据地址。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3、最后执行结束&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3901734104046243&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HTBjRFFBz4AshZCkT0V1OXzyP9sNxXiaxqdsDgIdwKW1FibtAVnXbcmTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;692&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以发现每次对数据的变更都会产生一个undo log，当一条记录被变更多次时，那么就会产生多条undo log，undo log记录的是变更前的日志，并且每个undo log的序号是递增的，那么当要回滚的时候，按照序号依次向前推，就可以找到我们的原始数据了。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;binlog 是MySQL server层的日志，而redo log 和undo log都是引擎层（InnoDB）的日志，要换其他数据引擎那么就未必有redo log和undo log了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它的设计目标是支持innodb的“事务”的特性，事务ACID特性分别是原子性、一致性、隔离性、持久性， 一致性是事务的最终追求的目标，隔离性、原子性、持久性是达成一致性目标的手段，根据的之前的介绍我们已经知道隔离性是通过锁机制来实现的，而事务的原子性和持久性则是通过redo log 和undo log来保障的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;写入策略&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事务执行过程中，先把日志写到bin log cache ，事务提交的时候，再把binlog cache写到binlog文件中。因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7110187110187111&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HB4ZGiaCicraicm2I9l6w28O0r6OxdZUiafDJB1vgJib4Jv67CichCiaGWY6jA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;962&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;binlog vs redo log&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个侧重点也不同， redo log让InnoDB有了崩溃恢复的能力，binlog保证了MySQL集群架构的数据一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1673881673881674&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgTyibwb7YuHIYj3u7lloNE1HPxVFf09DyiaicV0R06jWHbOjP6USjlWGfhgyftCtaDibHo1nP4v7hCkxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;693&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样。&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;&lt;span&gt;往期热文推荐：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable js_wx_tap_highlight&quot; data-id=&quot;MzA3MDg5MDkzOA==&quot; data-pluginname=&quot;mpprofile&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/Z2bVaFK6CgQmUQ0Aca9qSYNFn0tQEXQc5EibBkqQLYtibYBj1hXuagwXkNc3kVwplHxIl7KQfBIiagysgn9GDUUibw/0?wx_fmt=png&quot; data-nickname=&quot;架构精进之路&quot; data-alias=&quot;jiagou_jingjin&quot; data-signature=&quot;十年研发风雨路，大厂架构师，CSDN博客专家，InfoQ写作社区签约作者。专注软件架构研究，技术学习与职业成长，坚持分享接地气儿的架构技术干货文章！&quot; data-from=&quot;2&quot; data-is_biz_ban=&quot;0&quot; has-insert-preloading=&quot;1&quot; data-index=&quot;1&quot; data-origin_num=&quot;106&quot; data-isban=&quot;0&quot; data-weui-theme=&quot;light&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;关注公众号，免费领学习资料&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;87502&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;28&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;28&quot;&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;如果您觉得还不错，欢迎关注和转发~     &lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5163398692810458&quot; data-type=&quot;png&quot; data-w=&quot;306&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9TPn66HT930CzevNBb2yMhKjOn9yuJqsCPbyzicCBx6Zm9sNJCWibo6VzGRYbxrSfjJaaGibSRuyZFQmr3KcX07sw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4639e0248759f366153fd0014c6fc620</guid>
<title>Redis 队列实现 Java 版秒杀系统（无脚本、可用于生产）</title>
<link>https://toutiao.io/k/nffd0ib</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;写在前面&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需求是做一个秒杀系统，比如大家来抢100台手机，先到先得。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;查阅了网上很多用redis实现秒杀的demo（java语言），竟然没一个能用的！！！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有些是php的，没闲心研究了，现在说说为什么不能用：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;绝大多数的DEMO都是基于redis的watch特性的事务实现①，&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;个别是基于redis分布式锁实现②。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当然还有些用了脚本的，我也没仔细看是lua还是调用redis指令，哪有那个闲心去研究哇。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;照顾一下小白，分析一下为什么这几种实现不行&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.基于watch特性的 不靠谱 实现&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实这两种实现方式，完全可以理解为乐观锁(watch)和悲观锁(加分布式锁)&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;watch事务，相当于是乐观锁，这种方法在并发情况下极为不靠谱，假设有100个人同时尝试秒杀，那么极端情况下，有99个人都会失败，只有一个能修改成功。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而demo里甚至没写如果修改失败了就重试这个功能，那显然这失败的99个人，已经提示失败了，过一会回来，发现还剩了90多。那我是怎么失败的？我替他们问问了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并且使用这种方式实现呢，在并发量较大的时候，过多的重试线程应该会严重影响服务器性能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.基于用redis做个分布式锁的 不靠谱 实现&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种实现方式相当于一个悲观锁，每次执行减减操作之前，在redis中存入一个k,v键值对，使用特定的名称，并且使用setNX特性，确保抢锁没有安全问题，并在使用完成后释放锁。那么问题是，在100个人秒杀时，只有一个人抢到锁，剩下99个人怎么办?&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;demo里同样没写个重试，抢不到锁就失败，醉了，不过就算写重新抢锁的机制，那么几十个上百个线程不断抢锁，想想是个挺恐怖的事，更别提高并发了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基于脚本的实现 不靠谱 实现&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为一个C系语言开发，我看不太懂，看不懂就是不靠谱，出了问题都不知道改哪里，你说靠不靠谱&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;正题：使用spring操作redis的list队列实现&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我用的是springboot的StringRedisTemplate，至于如何整合jedis到spring等等，去查阅其他文章吧，我就不重复写了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;贴工具类：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; org.springframework.beans.factory.annotation.Autowired;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.springframework.data.redis.core.StringRedisTemplate;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.springframework.stereotype.Service;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; java.time.Duration;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; java.util.Collection;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;RedisServiceImpl&lt;/span&gt;&amp;lt;&lt;span&gt;T&lt;/span&gt;&amp;gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;RedisService&lt;/span&gt;&amp;lt;&lt;span&gt;T&lt;/span&gt;&amp;gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; StringRedisTemplate stringRedisTemplate;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;//添加字符串并设置过期时间&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;addString&lt;/span&gt;&lt;span&gt;(String key, String value, Duration duration)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        stringRedisTemplate.opsForValue().set(key, value, duration);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;//查找字符串&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; String &lt;span&gt;findString&lt;/span&gt;&lt;span&gt;(String key)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; stringRedisTemplate.opsForValue().get(key);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;//根据Key删除&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Boolean &lt;span&gt;deleteByKey&lt;/span&gt;&lt;span&gt;(String key)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; stringRedisTemplate.delete(key);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//在队列尾部减少一个对象&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; String &lt;span&gt;removeOneEntryOnListRight&lt;/span&gt;&lt;span&gt;(String listName)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; stringRedisTemplate.opsForList().rightPop(listName);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//在队列头部新增对象&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Long &lt;span&gt;addEntriesOnListLeft&lt;/span&gt;&lt;span&gt;(String listName, Collection&amp;lt;String&amp;gt; args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; stringRedisTemplate.opsForList().leftPushAll(listName, args);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解释一下哈 这个类的父类是我自己写的service层，不是提供好的&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要使用的是最后两个方法，最后一个方法，在队列头部新增对象，如果没有这个队列，他会创建出来这个队列，然后将一个集合统统塞到这个redis队列中。倒数第二个方法每调用一次，会删除队列中最后一个元素，然后返回这个元素的值，如果队列中已经没有元素了(队列已经没了)那么他会返回null，他们都是原子操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如此，每个请求都无需经过加锁操作，直接利用redis的单线程特性，即可实现高并发下的秒杀：请求到达redis，redis会逐个执行，每一次执行要么返回一个值，要么返回null。很显然，返回值的就是抢到了，返回null的就是没抢到。而且可以灵活的为这个队列新加入一些元素(老板发话再加100台)或者直接把这个队列删了(老板说不行，不卖了)都不会对代码产生任何影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中对应的redis操作指令分别是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在队列左侧新增：lpush&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在队列右侧消费：rpop&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;老板不卖了：del （笑）&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;接下来贴出十分简单的使用方法&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先贴在任务开始时向redis中插入一个大队列&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;List&amp;lt;String&amp;gt; entriesList = &lt;span&gt;new&lt;/span&gt; LinkedList&amp;lt;&amp;gt;();&lt;br/&gt;   &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;100&lt;/span&gt;; i++){&lt;br/&gt;       entriesList.add(&lt;span&gt;&quot;某个商品&quot;&lt;/span&gt;);&lt;br/&gt;   }&lt;br/&gt;   redisService.addEntriesOnListLeft(&lt;span&gt;&quot;队列名&quot;&lt;/span&gt;,entriesList);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;突然想到这个实现即使秒杀100台不同型号的手机（并且在秒到时就通知用户秒到的是啥），也不用改代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每次秒杀执行：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;String redisResult = redisService.removeOneEntryOnListRight(&lt;span&gt;&quot;队列名&quot;&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;null&lt;/span&gt; == redisResult) {&lt;br/&gt;        &lt;span&gt;//说明没抢到&lt;/span&gt;&lt;br/&gt;    }&lt;span&gt;else&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;//说明抢到了 执行抢到逻辑&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;突然发现这个实现看起来甚至比那些所谓的秒杀demo还简单&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但他既没有并发问题，也没有为了解决并发问题而衍生的性能问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然没经过测试，不过我认为就算秒杀10万台，放到redis队列里，应该也占用不了多少内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;赶工分布式秒杀，没想到如此基本的内容，竟没找到一个靠谱的实现，从上午写到现在(周末晚8点)一顿饭没吃，被网上过于demo的资源逼的，忍饿怒出此文。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5a1887ab8ce13d3dc55a89fdc3d7193f</guid>
<title>得物云原生全链路追踪Trace2.0-采集篇</title>
<link>https://toutiao.io/k/42uyrlw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;0&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;0xcc 开篇&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;2020 年 3月，得物技术团队在三个月的时间内完成了整个交易体系的重构，交付了五彩石项目，业务系统也进入了微服务时代。系统服务拆分之后，虽然每个服务都会有不同的团队各司其职，但服务之间的依赖也变得复杂，对服务治理等相关的基础建设要求也更高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对服务进行监控是服务治理、稳定性建设中的一个重要的环节，它能帮助提早发现问题，预估系统水位，以及对故障进行分析等等。从 2019 年末到现在，得物的应用服务监控系统经历了三大演进阶段，如今，整个得物的应用微服务监控体系已经全面融入云原生可观测性技术 OpenTelemetry。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;416&quot; data-ratio=&quot;0.2803234501347709&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaibhleuxpZmic1ibwge8eaAreBRMxd5EotHmPZVftrqROrqlz843Wm0NJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1484&quot; data-width=&quot;1484&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾过去十年间，应用服务监控行业的竞争也很激烈，相关产品如雨后春笋般涌现，如推特在 2012 年开源的 Zipkin，韩国最大的搜索引擎和门户网站 Naver 开源的 Pinpoint，近几年 Uber 公司开源的 Jaeger，以及我们国内吴晟开源的 SkyWalking。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人说，这些其实都归功于 Google 在 2010 年基于其内部大规模分布式链路追踪系统 Dapper 实践而发表的论文，它的设计理念是一切分布式调用链追踪系统的始祖，但其实早在二十年前（2002年），当年世界上最大的电商平台 eBay 就已拥有了调用链追踪系统 CAL(Centralized Application Logging)。2011 年，原eBay的中国研发中心的资深架构师吴其敏跳槽至大众点评，并且深入吸收消化了 CAL 的设计思想，主导研发并开源了CAT(Centralized Application Tracking）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;462&quot; data-ratio=&quot;0.2876712328767123&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVawbOjOicfqpxomSzQA9BHSBj7D0jDLtic4HgYBoj5Fiboic6ticGJoaRgReQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1606&quot; data-width=&quot;1606&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;CAT 作为国人主导的开源系统，其本地化工作也是做得非常到位，而凭借着架构简单，开箱即用的特点，CAT 也是我们得物使用的第一个应用监控系统。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt; 0x01 第一阶段&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;从0～1基于CAT的实时应用监控&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在得物五彩石项目交付之前，系统仅有基础设施层面的监控，CAT 的引入，很好地弥补了应用监控盲区。它支持提供各个维度的性能监控报表，健康状况检测，异常统计，对故障问题排查起到了积极推动的作用，同时也提供简单的实时告警的能力。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1712&quot; data-ratio=&quot;0.5336658354114713&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVa1mhCBQ1OHhvFqteBpfoUPgA6QsCZRVAkbia2NHaLkMnGnicg8abtWxibA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3208&quot; data-width=&quot;3208&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CAT 拥有指标分钟级别的聚合统计的能力，从 UI 上不难看出，它拥有丰富的报表统计能力和问题排障能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1228&quot; data-ratio=&quot;0.35594202898550725&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaInibO2qx9WXficIcTWoRhicQnXUMOCCSW37VuV2kSVfIpt4tp3I669qow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3450&quot; data-width=&quot;3450&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但随着公司业务规模逐步扩大，微服务粒度也不可避免地变小，我们发现，CAT 已经逐步无法满足我们的使用场景了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题排障与日常性能分析的场景也越来越复杂，对于一个核心场景，其内部的调用链路通常复杂多变，站在流量角度上看，需要完整地知道它的来源，上下游链路，异步调用等等，这对于 CAT 来说可能略显超纲。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;CAT 虽供多维度报表分析，但定制化能力非常有限，在当时，业内的图表组件定制化解决方案逐步向 Grafana + Prometheus 靠拢，但若使用 CAT，则无法享受强大的图表绘制能力。与此同时，随着云原生社区可观测性项目 OpenTracing 的崛起，大约不到半年时间我们逐步下线了 CAT，向 OpenTracing 生态演进。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt; 0x02 第二阶段&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt; 持续创造 基于OpenTracing全链路采样监控&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenTracing 为全链路追踪 Trace 定制了完整的一套协议标准，本身并不提供实现细节。在 OpenTracing 协议中，Trace 被认为是 Span 的有向无环图（DAG）。官方也例举了以下 8 个 Span 的因果关系和他们组成的单 Trace示例图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;602&quot; data-ratio=&quot;0.5574074074074075&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgValNQfgVvq8LFHo6KLzBztK4eyraOl6iauJCeNRPQRIOTDS3EWUCcCPkQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; data-width=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在当时， OpenTracing 相关的开源社区也是异常活跃，它使用 Jaeger 来解决数据的收集，调用链则使用了甘特图展示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1340&quot; data-ratio=&quot;0.38683602771362585&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaP5MBianGoYqFnL50rlqIibDh5GYOBlJ11fr8icvxXac8zNaMZ5c48aKbQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3464&quot; data-width=&quot;3464&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 OpenTracing 生态中，我们对链路的采样使用头部采样策略， 对于指标 Metrics，OpenTracing 并没有制定它的规范，但在 Google SRE Book 里，关于 Monitoring Distributed System 章节中提到了四类黄金指标：&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-type=&quot;quote_container&quot;&gt;&lt;ol start=&quot;1&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;吞吐量：如每秒请求数，通常的实现方式是，设定一个计数器，每完成一次请求将自增。通过计算时间窗口内的变化率来计算出每秒的吞吐量。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;2&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;延迟：处理请求的耗时。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;错误率/错误数：如 HTTP 500 错误。当然，有些即便是 HTTP 200 状态也需要根据特定业务逻辑来区分当前请求是否属于“错误”请求。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;4&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;饱和度：类似服务器硬件资源如CPU,内存,网络的使用率等等。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;所以，我们决定使用 Micrometer 库来对各个组件进行吞吐量，延迟和错误率的埋点，从而对 DB 类，RPC类的组件做性能监控。因此也可以说，我们&lt;strong&gt;第二阶段的监控是以&lt;/strong&gt;&lt;strong&gt;指标&lt;/strong&gt;&lt;strong&gt;监控为主，调用链监控为辅的应用性能监控&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.1 使用 Endpoint 贯穿指标埋点帮助性能分析&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在指标埋点过程中，我们在所有的指标中引入了“流量入口（Endpoint）”标签。这个标签的引入，实现了根据不同流量入口来区分关联 DB，缓存，消息队列，远程调用类的行为。通过流量入口，贯穿了一个实例的所有组件指标，基本满足了以下场景的监控：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1320&quot; data-ratio=&quot;0.38372093023255816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVagmicXiaqhfavRVScicHd9hkD1hfpweGhdibBxNOrHJxO6MrDN9oV5nn8yQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3440&quot; data-width=&quot;3440&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;628&quot; data-ratio=&quot;0.18309037900874636&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaq3viaX2H2EnTS49aq76C5RajUVZQCyRpmmtWssasMm6UDYicHzojTjEw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3430&quot; data-width=&quot;3430&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.2 关于选型的疑问&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会问，链路监控领域在业内有现成的 APM 产品，比如 Zipkin, Pinpoint, SkyWalking 等，为什么当时会选择 OpenTracing + Prometheus 自行埋点？主要有两大因素：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第一&lt;/strong&gt;，在当时，CAT 无法满足全链路监控和一些定制化的报表分析，而得物交易链路五彩石项目交付也趋于尾声，贸然去集成外部一款庞大的 APM 产品在没有充分的验证下，会给服务带来稳定性风险，在极其有限的时间周期内不是个理智的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第二&lt;/strong&gt;，监控组件是随着统一的基础框架来发布，同时，由另一团队牵头开发的全链路影子库路由组件借助了 OpenTracing 随行数据透传机制，且与监控组件是强耦合关系，而基础框架将统筹监控，压测和其他模块，借助Spring Boot Starter 机制，一定程度上做到了功能的开箱即用，无缝集成。而使用字节码增强方式的 Pinpoint, SkyWalking，无法很好地做到与基础框架集成，若并行开发，也会多出基础框架与 Java Agent 两边的管理和维护成本，减缓迭代速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;854&quot; data-ratio=&quot;0.977116704805492&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaQRdzIQMu6Ihp1ckDQpIkfEjCUr1zzG4WcUey4gYaalWqic1MYNGy0nQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;874&quot; data-width=&quot;874&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之后将近两年的时间里，应用服务监控覆盖了得物技术部使用的将近 70% 的组件，为得物App在 2021 年实现全年 99.97% 的 SLA 提供了强有力的支持。现在看来，基于 OpenTracing + Prometheus 生态，很好地解决了分布式系统的调用链监控，借助 Grafana 图表工具，做到了灵活的指标监控，融合基础框架，让业务方开箱即用…然而，我们说第二阶段是基于 OpenTracing 全链路采样监控，随着业务的高速发展，这套架构的不足点也逐渐显露出来。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;2.3 架构特点&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;链路&lt;/strong&gt;：1%的采样率使得业务服务基本不会因调用链发送量大而导致性能问题，但同时也往往无法从错误，高耗时的场景中找到正好采样的链路。期间，我们曾经考虑将头部采样策略改为尾部采样，但面临着非常高昂的 SDK 改造成本和复杂调用情况下（如异步）采样策略的回溯，且无法保证发生每个高耗时，错误操作时能还原整个完整的调用链路。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;集成方式&lt;/strong&gt;：业务和基础框架均采用 Maven 来构建项目，使用 Spring Boot Starter &quot;all in one&quot;开箱即用方式集成，极大降低了集成成本的同时，也给依赖冲突问题埋下了隐患。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;迭代周期分化矛盾，与基础框架的集成是当时快速推广落地全链路监控的不二选择，通过这种方式，Java 服务的接入率曾一度接近100%，但在业务高速发展的背景下，基础框架的迭代速度已经远远跟不上业务迭代速度了，这也间接制约了整个监控系统的迭代。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;数据治理成本逐步偏高，由于基础框架和业务系统的迭代节奏天然的不一致，且每个业务系统也有自身的迭代节奏，放眼全网后端服务上看，基础框架版本参差不齐。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1178&quot; data-ratio=&quot;1.6925287356321839&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaGtydK6mSC8H375ZtDTy4bRGbeZ2UqicjeDRvo5WpsaTZGs8Y60HvsibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;696&quot; data-width=&quot;696&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管监控系统在每一次迭代时都会尽可能保证最大的向后兼容，但将近两年的迭代周期里，不同版本造成的数据差异也极大制约了监控门户系统天眼的迭代，开发人员长时间奔波于数据上的妥协，在很多功能的实现上曲线救国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关预案依托于 Spring 框架 Bean 的自动装配逻辑，业务方理解成本低，便于变更，但缺少细粒度的预案，比如运行时期间特定逻辑降级等等。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;412&quot; data-ratio=&quot;0.1813380281690141&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaFqoia8XlSIOL1xdch8qjaDMGIXW1HQnSRlzhhIdWoWnZntiaU3J7CN1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2272&quot; data-width=&quot;2272&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt; 0x03 第三阶段&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;向前一步 基于OpenTelemetry全链路应用性能监控&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenTelemetry 的定位在于可观测性领域中对遥测数据采集和语义规范的统一，有 CNCF (云原生计算基金会)的加持，近两年里随着越来越多的人关注和参与，整个体系也越发成熟稳定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实，我们在2020年底就已开始关注 OpenTelemetry 项目，只不过当时该项目仍处于萌芽阶段， Trace, Metrics API 还在 Alpha 阶段，有很多不稳定因素，考虑到需尽快投入生产使用，笔者曾在 2021 年中到年末期间也或多或少参与了 OpenTelemetry 社区相关 issue 的讨论，遥测模块的开发，底层数据协议的一致和一些 BUG 的修复。在这半年期间，相关 API 和 SDK 随着越来越多的人参与也逐步趋于稳定。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;OpenTelemetry&lt;/strong&gt;&lt;/em&gt;&lt;em&gt;&lt;strong&gt;架构（图源自 opentelemetry.io）&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1267&quot; data-ratio=&quot;1.58375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaLXib1tQib4CMKvgGR1yc0znR5PAY6fv3gLNJXpIn1XofeK9ePJ6fvXkA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; data-width=&quot;800&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.1 迈入 Trace2.0 时代&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenTelemetry 的定位致力于将可观测性三大要素 Metrics,Trace,Log 进行统一，在遥测 API 制定上，提供了统一的上下文以便 SDK 实现层去关联。如 Metrics 与 Trace 的关联，笔者认为体现在 OpenTelemetry 在 Metrics 的实现上包含了对 OpenMetrics 标准协议的支持，其中 Exemplar 格式的数据打通了 Trace 与 Metrics 的桥梁：&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-type=&quot;quote_container&quot;/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在这之前，Metrics 指标类型的数据无法精确关联到具体某个或某些 Trace 链路，只能根据时间戳粗略关联特定范围内的链路。这个方案的缺陷源自指标采集器 vmagent 每隔 10s~30s 的 Pull 模式中，指标的时间戳取决于采集时刻，与 Trace 调用时间并不匹配。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;590&quot; data-ratio=&quot;0.6614349775784754&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaWziclSfqic5fIj8k9ibbbyCNZgcm16LXAI2X8d68sts63Nfovz7ran0vw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot; data-width=&quot;892&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Exemplar 数据在直方图度量格式末尾会追加当前上下文中的 Trace ID,Span ID 信息，如下：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;objectivec&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;shadower_virtual_field_map_operation_seconds_bucket{holder=&quot;Filter:Factory&quot;,key=&quot;WebMvcMetricsFilter&quot;,operation=&quot;get&quot;,tcl=&quot;AppClassLoader&quot;,value=&quot;Servlet3FilterMappingResolverFactory&quot;,le=&quot;0.2&quot;} 3949.0 1654575981.216 # {span_id=&quot;48f29964fceff582&quot;,trace_id=&quot;c0a80355629ed36bcd8fb1c6c89dedfe&quot;} 1.0 1654575979.751&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了采集 Exemplar 格式指标，同时又需防止分桶标签“le”产生的高基数问题，我们二次开发了指标采集 vmagent，额外过滤携带 Exemplar 数据的指标，并将这类数据异步批量发送到了 Kafka，经过 Flink 消费后落入 Clickhouse 后，由天眼监控门户系统提供查询接口和UI。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;464&quot; data-ratio=&quot;0.24091381100726894&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVa6yL0YlPuSWHyJNP0mdtzUIK46L5G4Qr0x9L6E6KPM1kShibSFMJ0sRQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1926&quot; data-width=&quot;1926&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;分位线统计与Exemplar 数据关联UI示意图&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;401&quot; data-ratio=&quot;0.31328125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaKzbOKUTxZKicB2IicOybgKYZgUa3OIbQ3xKGjaJXCJnnwAvLs9rVHibdA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-width=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据上报层，OpenTelemetry Java SDK 使用了比 JDK 原生的阻塞队列性能更好的 Mpsc (多生产单消费）队列，它使用大量的 long 类型字段来做内存区域填充，用空间换时间解决了伪共享问题，减少了并发情况下的写竞争来提高性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在流量高峰时期，链路数据的发送队列这一块的性能从火焰图上看 CPU 占比平均小于2%，日常服务CPU整体水位与0采样相比几乎没有明显差距，因此我们经过多方面压测对比后，决定在生产环境客户端侧开放链路数据的全量上报，实现了在得物技术史上的全链路 100% 采样，终结了一直以来因为低采样率导致问题排查困难的问题，至此，&lt;strong&gt;在第三阶段，得物的全链路追踪技术正式迈入 &lt;/strong&gt;&lt;strong&gt;Trace2.0&lt;/strong&gt;&lt;strong&gt; 时代。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;得益于 OpenTelemetry 整体的可插拔式 API 设计，我们二次开发了 OpenTelemetry Java Instrumentation 项目 Shadower Java，扩展了诸多功能特性：&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.2 引入控制平面管理客户端采集行&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1198&quot; data-ratio=&quot;0.5475319926873857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaPhNdQtozboXd6QNXraEYnE87a0GekXkMeBV1MKsrF1aZ343W2Xhrbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2188&quot; data-width=&quot;2188&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用控制平面，通过客户端监听机制来确保配置项的下发动作，包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1090&quot; data-ratio=&quot;0.44745484400656815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVadQxaplvgZ3DnwFhqibkwK1emeMiahQbiceQQf8JboQxNQ1ulYuAjgdoaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2436&quot; data-width=&quot;2436&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;控制平面的引入，弥补了无降级预案的空白，也提供了更加灵活的配置，支持了不同流量场景下快速变更数据采集方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;438&quot; data-ratio=&quot;0.611731843575419&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaHbaCT6WgjEzhGKicR40G4icPlDLeqJEvEl60rJv0b1dVDnevSVI9YUGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;716&quot; data-width=&quot;716&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1502&quot; data-ratio=&quot;2.495016611295681&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaUIiahv1nYpMfBAZxprmAJKMos7AgBLmZ4uspbkZqBwZF1PegCT662rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; data-width=&quot;602&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.3 独立的启动模块&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;为了解决业务方因集成基础框架而长期面临的依赖冲突问题，以及多版本共存引起的数据格式分散与兼容问题，我们自研了无极探针工具箱 Promise, 它是个通用的 javaagent launcher, 结合远端存储，支持可配置化任意 javaagent 的下载，更新，安装和启动：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ini&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[plugins]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;enables = shadower,arthas,pyroscope,chaos-agent&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[shadower]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;artifact_key = /javaagent/shadower-%s-final.jar&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;boot_class = com.shizhuang.apm.javaagent.bootstrap.AgentBootStrap&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;classloader = system&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;default_version = 115.16&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[arthas]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;artifact_key = /tools/arthas-bin.zip&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;;boot_class = com.taobao.arthas.agent334.AgentBootstrap&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;boot_artifact = arthas-agent.jar&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;premain_args = .attachments/arthas/arthas-core.jar;;ip=127.0.0.1&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[pyroscope]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;artifact_key = /tools/pyroscope.jar&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[chaos-agent]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;artifact_key = /javaagent/chaos-agent.jar&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;boot_class = com.chaos.platform.agent.DewuChaosAgentBootstrap&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;classloader = system&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;apply_envs = dev,test,local,pre,xdw&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;324&quot; data-ratio=&quot;0.18969555035128804&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaR6bUcwPrSCzWs0oSL1jyk4kicasxBM0lwfGia8qLS8sbJ9rmq5ekxqMA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1708&quot; data-width=&quot;1708&quot;/&gt;&lt;/section&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.4 基于 Otel API 的扩展&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;3.4.1 丰富的组件度量&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;在第二阶段 OpenTracing 时期，我们使用 Endpoint 贯穿了多个组件的指标埋点，这个优秀的特性也延续至第三阶段，我们基于底层 Prometheus SDK 设计了一套完善的指标埋点 SDK，并且借助字节码插桩的便捷，优化并丰富了更多了组件库。&lt;span&gt;（在此阶段，OpenTelemetry SDK 主版本是 1.3.x ，相关 Metrics SDK 还处于Alpha 阶段）&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;Otel 的 Java Instrumnetation 主要使用 WeakCo&lt;span&gt;ncurrentMap 来做异步链路上下文数据传递和同线程上下文关联的容器，由于 Otel 对许多流行组件库做了增强，因此 WeakConcurrentMap 的使用频率也是非常高的，针对这个对象的 size 做监控，有助于排查因探针导致的内存泄露问题，且它的增长率一旦达到我们设定的阈值便会告警，提早进行人工干预，执行相关预案，防止线上故障发生。&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;em&gt;&lt;strong&gt;部分自&lt;/strong&gt;&lt;strong&gt;监控&lt;/strong&gt;&lt;strong&gt;面板&lt;/strong&gt;&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1710&quot; data-ratio=&quot;0.534375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaZGPeOqNf56k0grguI92diafvibkNW1qr6vLbYbL4kQuIYCXVkat2Sw4g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3200&quot; data-width=&quot;3200&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.4.2扩展链路透传协&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;1) 引入RPC ID&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;为了更好地关联上下游应用，让每个流量都有“身份”，我们扩展了 &lt;strong&gt;TextMapPropagator &lt;/strong&gt;&lt;span&gt;接口，让每个流量在链路上都知道请求的来源，这对跨区域，环境调用排障场景起到关键性作用。&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1136&quot; data-ratio=&quot;1.7694704049844237&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVahHkYSJBWicrUjhufMze1b0ZLl51eAdJ0cicup1EqREkN8HgIkNTnYibkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;642&quot; data-width=&quot;642&quot;/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;此外，对于跨端场景，我们参考了阿里鹰眼调用链RPCID模型，增加了RpcID字段，这个字段在每次发生跨端调用时末尾数值会自增，而对于下游应用，字段本身的层级自增：&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1160&quot; data-ratio=&quot;1.277533039647577&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVade5ibnFw98RqfzJM0PwmS5aibHlzt41f7CE6W4ZUcl671lXvuzsosFtA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;908&quot; data-width=&quot;908&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;该字段拥有以下作用：&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;支&lt;span&gt;持提供精简化的调用链路视图，查询臃肿链路（如那些涉及缓存，DB调用大于 2000 Span的链路）时只提供 RPC 调用节点和调用层次关系。&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;链路保真，客户端链路数据上报队列并不是个无界限队列，当客户端自身调用频繁时，若上报队列堆积达到阈值即会丢弃，这会造成整个链路的不完整，当然这是预期内的现象，但若没有RpcID字段，链路视图将无法关联丢失的节点，从而导致整个链路层级混乱失真。&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1408&quot; data-ratio=&quot;0.5491419656786272&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaaL4ZoRu0VmyI7HupfU8awWVzhricDfmglJDsMKbDGVmtT1VUibuBATibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2564&quot; data-width=&quot;2564&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2) 自定义 Trace ID&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;为了实现链路详情页高效的检索效率，我们扩展 TraceID 生成逻辑，ID的前8位使用实例IP，中8位使用当前时间戳，后16位采用随机数生成。&lt;/span&gt;&lt;/h2&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;32位自定义traceId：c0a8006b62583a724327993efd1865d8&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;c0a8006b  62583a72   4327993efd1865d8&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   |         |             |&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;高8位(IP) 中8位(Timestmap) 低16位(Random)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;h2&gt;&lt;span&gt;这样的好处有两点：&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;通过 TraceID 反向解析时间戳，锁定时间范围，有助于提高存储库 Clickhouse 的检索效率，此外也能帮助决定当前的 Trace 应该查询热库还是冷库。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;458&quot; data-ratio=&quot;0.44901960784313727&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaGOuibuet98xvByTzmpINHv6ywMWg9uicg3uzLIflGAP4okAwZzU3dueQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1020&quot; data-width=&quot;1020&quot;/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;绑定实例 IP，有助于关联当前 Trace 流量入口所属的实例，在某些极端场景，当链路上的节点检索不到时，也能通过实例和时间两个要素来做溯源。&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3) 异步调用识别&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;业务系统为了提高服务吞吐量，充分运用硬件资源，异步调用场景可谓无处不在。&lt;span&gt;我们基于Otel实现的异步链路上下文传递的基础上，额外扩充了&quot;async_flag&quot;字段来标识当前节点相对于父节点的调用关系，从而在展示层上能迅速找出发生异步调用的场景&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;224&quot; data-ratio=&quot;0.36363636363636365&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVan4068Czs589fpXf1c9ReIu1XSqxktzCJq3GtDve5l8bR1sNX4KCdtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;616&quot; data-width=&quot;616&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.4.3  更清晰的调用链结构&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;在 Otel 支持的部分组件中，有些操作不涉及到网络调用，或者具有非常频繁的操作，如 MVC 过程，数据库连接获取等，通常来说这类节点在链路详情主视图中的意义不大，因此我们对这类节点的产生逻辑进行了优化调整，使得整个链路主体结构聚焦于“跨端”，同时，对部分核心组件关键内部方法细节做了增强，以“事件”的形式挂载于它们的父节点上，便于更细粒度的排查：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;h2&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;RPC&lt;/strong&gt;&lt;strong&gt; 调用关键内部事件&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/h2&gt;&lt;h2&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;487&quot; data-ratio=&quot;1.058695652173913&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVap23IJV82yIjAmGbcd4aMew4ul8pg6onHslTfaKIP07nEkW1H8qM1YQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;460&quot; data-width=&quot;460&quot;/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;DB 调用连接获取事件&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/h2&gt;&lt;h2&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1102&quot; data-ratio=&quot;1.6158357771260996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaI07W1dSL0JtVtfLS9NDtuYFcq2y507NvA2vDhN8ehFHFuJOL9ziaic2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;682&quot; data-width=&quot;682&quot;/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.4.4 profiling 的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;1）线程栈分析的集成。&lt;span&gt;通过集成 Arthas 这类工具，可以很方便地查看某个实例线程的实时堆栈信息，同时对采样间隔做控制，避免频繁抓取影响业务自身性能。&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1400&quot; data-ratio=&quot;0.48703703703703705&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaImyiceEoyvDn9MJJF1G6W2xGaQpNBbEVhlEWIcfeATBiaEw0ZicUCjEIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; data-width=&quot;2876&quot;/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;2）通过集成 pyroscope，打通高延迟性能排查最后一公里。&lt;span&gt;Pyroscope 对 async profiler 做了二次开发，同时也支持 Otel 去集成，但截至目前，官方并没有实现完整的 Profiling 行为的生命周期，而 Profiling 行为一定程度上会影响性能，于是我们对官方 Pyroscope 的生命周期做了扩展，实现“停止”行为的同时，采用时间轮算法来检测特定操作的耗时，当达到期望的阈值将触发开启 profiling, 待操作结束或超过最大阈值则停止。&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;218&quot; data-ratio=&quot;0.06315179606025492&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVavbDoib4TwCKzWSLkhaYxHs1kancnGOySdKNhlDZzxe0zazbVEJu7OHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3452&quot; data-width=&quot;3452&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;1708&quot; data-ratio=&quot;0.5659377070907886&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74C7cwr1iam7XNocN4qr3TgVaicDm2bnMZnrfv2wdz17gcVLvETuxru9dEQmhUCZyPviaAJ9rUsYZCfQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3018&quot; data-width=&quot;3018&quot;/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;关于性能诊断相关的运用，请期待后续诊断专题。&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt; 0xff 结语&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;纵观得物在应用监控采集领域的三大里程碑迭代，第一阶段的 CAT 则是 0~1 的过程，它提供了应用服务对自身观测的途径，让业务方第一次真实地了解了服务运行状况，而第二阶段开始，随着业务发展的飞速提升，业务方对监控系统的要求就不仅只是从无到有了，而是要精细，准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，快速迭代的背景下，功能与架构演进层面的矛盾，加上外部云原生大背景下可观测领域的发展因素，促使我们进行了基于 OpenTelemetry 体系的第三阶段的演进。功能，产品层面均取得了优异的结果。如今，我们即将进行下一阶段的演进，深度结合调用链与相关诊断工具，以第三阶段为基础，让得物全链路追踪技术正式迈入性能分析诊断时代。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;关于我们&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;得物监控团队提供一站式的可观测性平台，负责链路追踪、时序数据库、日志系统，包括自定义大盘、应用大盘、业务监控、智能告警、AIOPS等排障分析。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dapper, a Large-Scale Distributed Systems Tracing Infrastructure&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大众点评开源分布式监控平台 CAT 深度剖析-阿里云开发者社区&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://developer.aliyun.com/article/269295&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;h1 data-v-052ff562=&quot;&quot; data-v-b110a92e=&quot;&quot;&gt;&lt;span&gt;趣谈“分布式链路追踪“组件发展史&lt;/span&gt;&lt;/h1&gt;&lt;h1 data-v-052ff562=&quot;&quot; data-v-b110a92e=&quot;&quot;&gt;&lt;span&gt;https://xie.infoq.cn/article/8e06e8d9e43d1768e021225cb&lt;/span&gt;&lt;/h1&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Jaeger Sampling&lt;/span&gt;&lt;br/&gt;&lt;span&gt;https://www.jaegertracing.io/docs/1.39/sampling/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A brief history of OpenTelemetry (So Far) | Cloud Native Computing Foundation&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.cncf.io/blog/2019/05/21/a-brief-history-of-opentelemetry-so-far/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The OpenMetrics project — Creating a standard for exposing metrics data&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://openmetrics.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Merging OpenTracing and OpenCensus: A Roadmap to Convergence&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Monitoring Distributed Systems&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;strong mp-original-font-size=&quot;11&quot; mp-original-line-height=&quot;17.600000381469727&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;*文&lt;/span&gt;&lt;/strong&gt;&lt;strong mp-original-font-size=&quot;11&quot; mp-original-line-height=&quot;17.600000381469727&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;/栉枫忻垣&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;关注得物技术，每周一三五晚18:30更新技术干货&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzkxNTE3ODU0NA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74AlsHDtoVyU8hqzNTGS26fV9PmHAcZ8uib1GWNJibIuBiavPdAXw9IOzjlEAYRJUNjOEme5geMNPoZ1Q/0?wx_fmt=png&quot; data-nickname=&quot;得物技术&quot; data-alias=&quot;&quot; data-signature=&quot;技术知识分享交流平台，与你一同走向技术的云端。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>191439000e7cbe4fe472ff6b3309ea68</guid>
<title>玩转 Go 链路追踪</title>
<link>https://toutiao.io/k/jdq1xz6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;链路追踪是每个微服务架构下必备的利器，go-zero 当然早已经为我们考虑好了，只需要在配置中添加配置即可使用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于 go-zero 如何追踪的原理追溯，之前已经有同学分享，这里我就不再多说，如果有想了解的同学去 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2ODU1MTI0OA==&amp;amp;mid=2247483946&amp;amp;idx=1&amp;amp;sn=ca51f2917c28b0c1f5454f49867d38fc&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;https://mp.weixin.qq.com/s/hJEWcWc3PnGfWfbPCHfM9g&lt;/a&gt; 这个链接看就好了。默认会在 api 的中间件与 rpc 的 interceptor 添加追踪，如果有不了解 go-zero 默认如何使用默认的链路追踪的，请移步我的开源项目 go-zero-looklook 文档 https://github.com/Mikaelemmmm/go-zero-looklook/blob/main/doc/chinese/12-%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA.md。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天我想讲的是，除了 go-zero 默认在 api 的 middleware 与 rpc 的 interceptor 中帮我们集成好的链路追踪，我们想自己在某些本地方法添加链路追踪代码或者我们想在 api 发送一个消息给 mq 服务时候想把整个链路包含 mq 的 producer、consumer 穿起来，在 go-zero 中该如何做。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;场景&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先简单讲一下我们的小 demo 的场景，一个请求进来调用 api 的 &lt;code&gt;Login&lt;/code&gt; 方法，在 Login 方法中先调用 rpc 的 &lt;code&gt;GetUserByMobile&lt;/code&gt; 方法，之后在调用 api 本地的 &lt;code&gt;local&lt;/code&gt; 方法，紧接着调用 &lt;code&gt;rabbitmq&lt;/code&gt; 传递消息到 mq 服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;go-zero 默认集成了 jaeger、zinpink，这里我们就以 jaeger 为例&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们希望看到的链路是&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4945717732207479&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UyIojWicPOg3I9ajxZkfty80df7saufvGWvicXyiazH3awibnOpT2vOuLQ27UBVs25VebZDhK7A8pvc8qIuxBMsgDw/640?wx_fmt=png&quot;/&gt;&lt;figcaption&gt;api.Login -&amp;gt; rpc.GetUserByMobile&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是 api 衍生出来三条子链路，&lt;code&gt;api.producerMq&lt;/code&gt; 有一条调用 &lt;code&gt;mq.Consumer&lt;/code&gt; 的子链路。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们想要将一个方法添加到链路中需要两个因素，一个 traceId，一个span，当我们在同一个 traceId 下开启 span 把相关的 span 都串联起来，如果想形成父子关系，就要把 span 之间相互串联起来，因为「&lt;strong&gt;微服务实践&lt;/strong&gt;」公众号中讲解原理太多，我这里就简单提一下不涉及过多，如果不是特别熟悉原理可以看文章开头推荐的文章，这里我们只需要知道 &lt;code&gt;traceId&lt;/code&gt; 与 &lt;code&gt;spanId&lt;/code&gt; 关系就好。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;核心业务代码&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、首先 API 中 &lt;code&gt;LoginLogic&lt;/code&gt; 代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; LoginLogic &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;  logx.Logger&lt;br/&gt;  ctx    context.Context&lt;br/&gt;  svcCtx *svc.ServiceContext&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewLoginLogic&lt;/span&gt;&lt;span&gt;(ctx context.Context, svcCtx *svc.ServiceContext)&lt;/span&gt; *&lt;span&gt;LoginLogic&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &amp;amp;LoginLogic{&lt;br/&gt;    Logger: logx.WithContext(ctx),&lt;br/&gt;    ctx:    ctx,&lt;br/&gt;    svcCtx: svcCtx,&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; MsgBody &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;  Carrier *propagation.HeaderCarrier&lt;br/&gt;  Msg     &lt;span&gt;string&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(l *LoginLogic)&lt;/span&gt; &lt;span&gt;Login&lt;/span&gt;&lt;span&gt;(req *types.RegisterReq)&lt;/span&gt; &lt;span&gt;(*types.AccessTokenResp, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  resp, err := l.svcCtx.UserRpc.GetUserByMobile(l.ctx, &amp;amp;usercenter.GetUserByMobileReq{&lt;br/&gt;    Mobile: req.Mobile,&lt;br/&gt;  })&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &amp;amp;types.AccessTokenResp{}, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  l.local()&lt;br/&gt;&lt;br/&gt;  tracer := otel.GetTracerProvider().Tracer(trace.TraceName)&lt;br/&gt;  spanCtx, span := tracer.Start(l.ctx, &lt;span&gt;&quot;send_msg_mq&quot;&lt;/span&gt;,  oteltrace.WithSpanKind(oteltrace.SpanKindProducer))&lt;br/&gt;  carrier := &amp;amp;propagation.HeaderCarrier{}&lt;br/&gt;  otel.GetTextMapPropagator().Inject(spanCtx, carrier)&lt;br/&gt;&lt;br/&gt;  producer := rabbit.NewRabbitmqPublisher(RabbitmqDNS)&lt;br/&gt;  msg :=  &amp;amp;MsgBody{&lt;br/&gt;    Carrier: carrier,&lt;br/&gt;    Msg:     req.Mobile,&lt;br/&gt;  }&lt;br/&gt;  b, err := json.Marshal(msg)&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;panic&lt;/span&gt;(err)&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err := producer.Publish(spanCtx, ExchangeName, RoutineKeys, b); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    logx.Errorf(&lt;span&gt;&quot;Publish Fail , msg :%s , err:%v&quot;&lt;/span&gt;, msg, err)&lt;br/&gt;  }&lt;br/&gt;  span.End()&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &amp;amp;types.AccessTokenResp{&lt;br/&gt;    AccessExpire: resp.User.Id,&lt;br/&gt;  }, err&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(l *LoginLogic)&lt;/span&gt; &lt;span&gt;local&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  tracer := otel.GetTracerProvider().Tracer(trace.TraceName)&lt;br/&gt;  _ , span := tracer.Start(l.ctx, &lt;span&gt;&quot;local&quot;&lt;/span&gt;, oteltrace.WithSpanKind(oteltrace.SpanKindInternal))&lt;br/&gt;  &lt;span&gt;defer&lt;/span&gt; span.End()&lt;br/&gt;  &lt;br/&gt;  &lt;span&gt;// 执行你的代码 .....&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、rpc 中 &lt;code&gt;GetUserByMobile&lt;/code&gt; 的代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(s *Logic)&lt;/span&gt; &lt;span&gt;GetUserByMobile&lt;/span&gt;&lt;span&gt;(context.Context, *usercenterPb.GetUserByMobileReq)&lt;/span&gt; &lt;span&gt;(*usercenterPb.GetUserByMobileResp, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  vo := &amp;amp;usercenterPb.UserVo{&lt;br/&gt;    Id: &lt;span&gt;1&lt;/span&gt;,&lt;br/&gt;  }&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &amp;amp;usercenterPb.GetUserByMobileResp{&lt;br/&gt;    User: vo,&lt;br/&gt;  }, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、mq 中 &lt;code&gt;Consumer&lt;/code&gt; 的代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; MsgBody &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;  Carrier *propagation.HeaderCarrier&lt;br/&gt;  Msg     &lt;span&gt;string&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(c *consumer)&lt;/span&gt; &lt;span&gt;Consumer&lt;/span&gt;&lt;span&gt;(ctx context.Context, data []&lt;span&gt;byte&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;var&lt;/span&gt; msg MsgBody&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err := json.Unmarshal(data, &amp;amp;msg); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    logx.Errorf(&lt;span&gt;&quot; consumer err : %v&quot;&lt;/span&gt;, err)&lt;br/&gt;  } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;    logx.Infof(&lt;span&gt;&quot;consumerOne Consumer  , msg:%+v&quot;&lt;/span&gt;, msg)&lt;br/&gt;&lt;br/&gt;    wireContext := otel.GetTextMapPropagator().Extract(ctx, msg.Carrier)&lt;br/&gt;    tracer := otel.GetTracerProvider().Tracer(trace.TraceName)&lt;br/&gt;    _, span := tracer.Start(wireContext, &lt;span&gt;&quot;mq_consumer_msg&quot;&lt;/span&gt;, oteltrace.WithSpanKind(oteltrace.SpanKindConsumer))&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; span.End()&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;代码详解&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1、go-zero 默认集成&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当一个请求进入 api 后，我们可以在 go-zero 源码中查看到 https://github.com/zeromicro/go-zero/blob/master/rest/engine.go#L92。go-zero 已经在 api 的 middleware 中帮我们添加了第一层 trace，当进入 Login 方法内，我们调用了 rpc 的 &lt;code&gt;GetUserByMobile&lt;/code&gt; 方法，通过 go-zero 的源码 https://github.com/zeromicro/go-zero/blob/master/zrpc/internal/rpcserver.go#L55 可以看到在 rpc 的 interceptor 也默认帮我们添加好了，这两层都是 go-zero 默认帮我们做好的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2、本地方法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当调用完 rpc 的 &lt;code&gt;GetUserByMobile&lt;/code&gt; 之后，api 调用了本地的 &lt;code&gt;local&lt;/code&gt;，如果我们想在整个链路上体现出来调用了本地 &lt;code&gt;local&lt;/code&gt; 方法，那默认的 go-zero 是没有帮我们做的，需要我们手动来添加。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;  tracer := otel.GetTracerProvider().Tracer(trace.TraceName)&lt;br/&gt;  _ , span := tracer.Start(l.ctx, &lt;span&gt;&quot;local&quot;&lt;/span&gt;,  oteltrace.WithSpanKind(oteltrace.SpanKindInternal))&lt;br/&gt;  &lt;span&gt;defer&lt;/span&gt; span.End()&lt;br/&gt; &lt;br/&gt;&lt;span&gt;// 执行你的代码 .....&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们通过上面代码拿到 tracer，ctx 之后开启一个 local 的 span，因为 start 时候会从 ctx 获取父 span 所以会将 local 方法与 Login 串联起父子调用关系，这样就将本次操作加入了这个链路&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3、mq 的 producer 到 mq 的 consumer&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在mq传递中如何串联起来这个链路呢？也就是形成 &lt;code&gt;api.Login-&amp;gt;api.producer-&amp;gt;mq.Consumer&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想一下原理，虽然跨越了网络，api 可以通过 &lt;code&gt;header&lt;/code&gt; 传递，rpc 可以通过 &lt;code&gt;metadata&lt;/code&gt; 传递，那么 mq 是不是也可以通过 &lt;code&gt;header&lt;/code&gt;、&lt;code&gt;body&lt;/code&gt; 传递就可以了，按照这个想法来看下我门的代码。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;  tracer := otel.GetTracerProvider().Tracer(trace.TraceName)&lt;br/&gt;  spanCtx , span := tracer.Start(l.ctx, &lt;span&gt;&quot;send_msg_mq&quot;&lt;/span&gt;, oteltrace.WithSpanKind(oteltrace.SpanKindProducer))&lt;br/&gt;  carrier := &amp;amp;propagation.HeaderCarrier{}&lt;br/&gt;  otel.GetTextMapPropagator().Inject(spanCtx,carrier)&lt;br/&gt;&lt;br/&gt;  producer := rabbit.NewRabbitmqPublisher(RabbitmqDNS)&lt;br/&gt;  msg := &amp;amp;MsgBody{&lt;br/&gt;    Carrier: carrier,&lt;br/&gt;    Msg:     req.Mobile,&lt;br/&gt;  }&lt;br/&gt;  b , err := json.Marshal(msg)&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;panic&lt;/span&gt;(err)&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err := producer.Publish(spanCtx, ExchangeName, RoutineKeys, b); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    logx.Errorf(&lt;span&gt;&quot;Publish Fail, msg :%s, err:%v&quot;&lt;/span&gt;, msg, err)&lt;br/&gt;  }&lt;br/&gt;  span.End()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先获取到了这个全局的 &lt;code&gt;tracer&lt;/code&gt;，然后开启一个 &lt;code&gt;producer&lt;/code&gt; 的 &lt;code&gt;span&lt;/code&gt;，跟 &lt;code&gt;local&lt;/code&gt; 方法一样，我们开启 &lt;code&gt;producer&lt;/code&gt; 的 &lt;code&gt;span&lt;/code&gt; 时候也是通过 &lt;code&gt;ctx&lt;/code&gt; 获取到上一级父级 &lt;code&gt;span&lt;/code&gt;，这样就可以将 &lt;code&gt;producer&lt;/code&gt; 的 &lt;code&gt;span&lt;/code&gt; 与 &lt;code&gt;Login&lt;/code&gt; 形成父子 &lt;code&gt;span&lt;/code&gt; 调用关系，那我们想将 &lt;code&gt;producer&lt;/code&gt; 的 &lt;code&gt;span&lt;/code&gt; 与 mq 的 &lt;code&gt;consumer&lt;/code&gt; 中的 &lt;code&gt;span&lt;/code&gt; 形成调用父子关系怎么做？我们将 &lt;code&gt;api.producer&lt;/code&gt; 的 &lt;code&gt;spanCtx&lt;/code&gt; 注入到 &lt;code&gt;carrier&lt;/code&gt; 中，这里我们通过 mq 的 &lt;code&gt;body&lt;/code&gt; 将 &lt;code&gt;carrier&lt;/code&gt; 发送给 &lt;code&gt;consumer&lt;/code&gt;，发送完成我们 &lt;code&gt;stop&lt;/code&gt; 我们的 &lt;code&gt;producer&lt;/code&gt;，那么 &lt;code&gt;producer&lt;/code&gt; 的这层链路完成了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随后我们来看 &lt;code&gt;mq-consumer&lt;/code&gt; 在接收到 &lt;code&gt;body&lt;/code&gt; 消息之后怎么做的。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; MsgBody &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;  Carrier *propagation.HeaderCarrier&lt;br/&gt;  Msg     &lt;span&gt;string&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(c *consumer)&lt;/span&gt; &lt;span&gt;Consumer&lt;/span&gt;&lt;span&gt;(ctx context.Context, data []&lt;span&gt;byte&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;var&lt;/span&gt; msg MsgBody&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err := json.Unmarshal(data, &amp;amp;msg); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    logx.Errorf(&lt;span&gt;&quot; consumer err : %v&quot;&lt;/span&gt;, err)&lt;br/&gt;  } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;    logx.Infof(&lt;span&gt;&quot;consumerOne Consumer  , msg:%+v&quot;&lt;/span&gt;, msg)&lt;br/&gt;&lt;br/&gt;    wireContext := otel.GetTextMapPropagator().Extract(ctx, msg.Carrier)&lt;br/&gt;    tracer := otel.GetTracerProvider().Tracer(trace.TraceName)&lt;br/&gt;    _, span := tracer.Start(wireContext, &lt;span&gt;&quot;mq_consumer_msg&quot;&lt;/span&gt;, oteltrace.WithSpanKind(oteltrace.SpanKindConsumer))&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; span.End()&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;consumer&lt;/code&gt; 接收到消息后反序列化出来 &lt;code&gt;Carrier *propagation.HeaderCarrier&lt;/code&gt;，然后通过 &lt;code&gt;otel.GetTextMapPropagator().Extract&lt;/code&gt; 取出来 &lt;code&gt;api.producer&lt;/code&gt; 注入的 &lt;code&gt;wireContext&lt;/code&gt;，在通过 &lt;code&gt;tracer.Start&lt;/code&gt;、&lt;code&gt;wireContext&lt;/code&gt; 创建 &lt;code&gt;consumer&lt;/code&gt; 的 &lt;code&gt;span&lt;/code&gt;，这样 &lt;code&gt;consumer&lt;/code&gt; 就是 &lt;code&gt;api.producer&lt;/code&gt; 的子 &lt;code&gt;span&lt;/code&gt;，就形成了调用链路关系，最终我们得到的关系就是&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4945717732207479&quot; data-type=&quot;png&quot; data-w=&quot;829&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UyIojWicPOg3I9ajxZkfty80df7saufvGWvicXyiazH3awibnOpT2vOuLQ27UBVs25VebZDhK7A8pvc8qIuxBMsgDw/640?wx_fmt=png&quot;/&gt;&lt;figcaption&gt;api.Login -&amp;gt; rpc.GetUserByMobile&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;让我们来调用一下 &lt;code&gt;Logic&lt;/code&gt; 方法，看下 jaeger 中的链路如果与我们预想的链路一致，so happy～&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.37383966244725736&quot; data-type=&quot;jpeg&quot; data-w=&quot;1185&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UyIojWicPOg3I9ajxZkfty80df7saufvGicaNxwCvUythsS0gicjkUBHeWiaeCPHfI8QO4Sm6JzYuXVTMXdiciciaGQdA/640?wx_fmt=jpeg&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;项目地址&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;go-zero 微服务框架：https://github.com/zeromicro/go-zero&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;go-zero 微服务最佳实践项目：https://github.com/Mikaelemmmm/go-zero-looklook&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;欢迎使用 &lt;code&gt;go-zero&lt;/code&gt; 并 &lt;strong&gt;star&lt;/strong&gt; 支持我们！&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;微信交流群&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关注『&lt;strong&gt;微服务实践&lt;/strong&gt;』公众号并点击 &lt;strong&gt;交流群&lt;/strong&gt; 获取社区群二维码。&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weuitheme=&quot;light&quot; data-id=&quot;Mzg2ODU1MTI0OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/UyIojWicPOg0AVP4WUKYKGFYXampCduKtGgGQgTibaEGvORjtq7icd3EOiaSMb6LeZY2k77dJFOibf914CUs3JTwMLA/0?wx_fmt=png&quot; data-nickname=&quot;微服务实践&quot; data-alias=&quot;zeromicro&quot; data-signature=&quot;分享微服务的原理和最佳实践，讲透服务治理的底层原理，带你细读 go-zero 源码。go-zero 是一个集成了各种工程实践的 web 和 rpc 框架，旨在缩短从需求到上线的距离。公众号文章勘误在知乎号：万俊峰Kevin&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>