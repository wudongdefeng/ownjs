<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ce975edcc73243a6e697003d3283d3b1</guid>
<title>强化学习调参技巧（二）：DDPG、TD3、SAC 算法为例</title>
<link>https://toutiao.io/k/43k6p3s</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h1&gt;1.训练环境如何正确编写&lt;/h1&gt;

&lt;p&gt;强化学习里的 env.reset() env.step() 就是训练环境。其编写流程如下：&lt;/p&gt;

&lt;h2&gt;1.1 初始阶段：&lt;/h2&gt;

&lt;p&gt;先写一个简化版的训练环境。把任务难度降到最低，确保一定能正常训练。记录正常训练的智能体的分数，与随机动作、传统算法得到的分数做比较。
DRL算法的分数应该明显高于随机动作（随机执行动作）。DRL算法不应该低于传统算法的分数。如果没有传统算法，那么也需要自己写一个局部最优的算法&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;评估策略的性能:&lt;/strong&gt; 大部分情况下，可以直接是对Reward Function 给出的reward 进行求和得到的每轮收益episode return作为策略评分。有时候可以需要直接拿策略的实际分数作为评分
&lt;strong&gt;需要保证这个简化版的代码：高效、简洁、可拓展&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;1.2 改进阶段：&lt;/h2&gt;

&lt;p&gt;让任务难度逐步提高，对训练环境env 进行缓慢的修改，时刻保存旧版本的代码同步微调 Reward Function，可以直接代入自己的人类视角，为某些行为添加正负奖励。注意奖励的平衡（有正有负）。注意不要为Reward Function 添加太多额外规则，时常回过头取消一些规则，避免过度矫正。
 同步微调 DRL算法，只建议微调超参数，但不建议对算法核心进行修改。因为任务变困难了，所以需要调整超参数让训练变快。同时摸清楚在这个训练环境下，算法对&lt;strong&gt;哪几个超参数是敏感的&lt;/strong&gt;。有时候为了节省时间，甚至可以为 off-policy 算法保存一些典型的 trajectory（不建议在最终验证阶段使用）。
每一次修改，都需要跑一下记录不同方法的分数，确保：随机动作 &amp;lt; 传统方法 &amp;lt; DRL算法。这样才能及时发现代码逻辑上的错误。要极力避免代码中出现复数个的错误，因为极难排查。&lt;/p&gt;

&lt;h2&gt;1.3 收尾阶段：&lt;/h2&gt;

&lt;p&gt;尝试慢慢删掉Reward Function 中一些比较复杂的东西，删不掉就算了。
选择&lt;font&gt;&lt;strong&gt;高低两组超参数&lt;/strong&gt;&lt;/font&gt;再跑一次，确认没有优化空间。&lt;/p&gt;

&lt;h1&gt;2. 超参数解释分析&lt;/h1&gt;

&lt;h2&gt;2.1 off-policy算法中常见的超参数&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网络宽度：&lt;/strong&gt; network dimension number。DRL 全连接层的宽度（特征数量）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络层数：&lt;/strong&gt; network layer number。一个输入张量到输出需要乘上w的次数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;随机失活：&lt;/strong&gt; dropout&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批归一化&lt;/strong&gt;： batch normalization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;记忆容量：&lt;/strong&gt; 经验回放缓存 experimence replay buffer 的最大容量 max capacity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批次大小：&lt;/strong&gt; batch size。使用优化器更新时，每次更新使用的数据数量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新次数&lt;/strong&gt;：update times。使用梯度下降更新网络的次数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;折扣因子：&lt;/strong&gt; discount factor、gamma&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;【网络宽度、网络层数】&lt;/strong&gt; 越复杂的函数就需要越大容量的神经网络去拟合。在需要训练1e6步的任务中，我一般选择 宽度&lt;strong&gt;128、256&lt;/strong&gt;，层数小于8的网络（请注意，乘以一个w算一层，一层LSTM等于2层）。使用ResNet等结构会有很小的提升。一般选择一个略微冗余的网络容量即可，把调整超参数的精力用在这上面不划算，我建议这些超参数都粗略地选择2的N次方，&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;因为：防止过度调参，超参数选择x+1 与 x-1并没有什么区别，但是 x与2x一定会有显著区别
2的N次方大小的数据，刚好能完整地放进CPU或GPU的硬件中进行计算，如Tensor Core
过大、过深的神经网络不适合DRL，
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;因为：深度学习可以在整个训练结束后再使用训练好的模型。
而强化学习需要在几秒钟的训练后马上使用刚训好的模型。
这导致DRL只能用比较浅的网络来保证快速拟合（10层以下）
并且强化学习的训练数据不如有监督学习那么稳定，无法划分出训练集测试集去避免过拟合，
因此DRL也不能用太宽的网络（超过1024），避免参数过度冗余导致过拟合
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;【dropout、批归一化】&lt;/strong&gt; 她们在DL中得到广泛地使用，可惜不适合DRL。如果非要用，那么也要选择非常小的 &lt;strong&gt;dropout rate（0~0.2）&lt;/strong&gt;，而且要注意在使用的时候关掉dropout。我不用dropout。&lt;/p&gt;

&lt;p&gt;好处：在数据不足的情况下缓解过拟合；像Noisy DQN那样去促进策略网络探索
坏处：影响DRL快速拟合的能力；略微增加训练时间&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【批归一化】&lt;/strong&gt; 经过大量实验，DRL绝对不能直接使用批归一化，如果非要用，那么就要修改Batch Normalization的动量项超参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【记忆容量】&lt;/strong&gt; 经验回放缓存 experimence replay buffer 的最大容量 max capacity，如果超过容量限制，它就会删掉最早的记忆。在简单的任务中（训练步数小于1e6），对于探索能力强的DRL算法，通常在缓存被放满前就训练到收敛了，不需要删除任何记忆。然而，过大的记忆也会拖慢训练速度，我一般会先从默认值 2 ** 17 ~ 2 ** 20 开始尝试，如果环境的随机因素大，我会同步增加记忆容量 与 batch size、网络更新次数，直到逼近服务器的内存、显存上限（放在显存训练更快）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【批次大小、更新次数】&lt;/strong&gt; 一般我会选择与网络宽度相同、或略大的批次大小batch size。我一般从&lt;strong&gt;128、256&lt;/strong&gt; 开始尝试这些2的N次方。在off-policy中，每往Replay 更新几个数据，就对应地更新几次网络，这样做简单，但效果一般。（深度学习里）更优秀的更新方法是：根据Replay中数据数量，成比例地修改更新次数。Don&#x27;t Decay the Learning Rate, Increase the Batch Size. ICLR. 2018 。，经过验证，DRL也适用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【折扣因子】&lt;/strong&gt; discount factor、discount-rate parameter 或者叫 gamma 。0.99&lt;/p&gt;

&lt;h2&gt;2.2 on-policy算法中常见的超参数&lt;/h2&gt;

&lt;p&gt;同策略（A3C、PPO、PPO+GAE）与异策略（DQN、DDPG、TD3、SAC）的主要差异是：&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;【记忆容量】&lt;/strong&gt; on-policy 算法每轮更新后都需要删除“用过的数据”，所以on-policy的记忆容量应该大于等于【单轮更新的采样步数】，随机因素更多的任务需要更大的单层采样步数才能获得更多的 轨迹 trajectory，才能有足够的数据去表达环境与策略的互动关系。详见下面PPO算法的【单轮更新的采样步数】&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【批次大小】&lt;/strong&gt; on-policy 算法比off-policy更像深度学习，它可以采用稍大一点的学习率（2e-4）。因为【单轮更新的采样步数】更大，所以它也需要搭配更大的batch size（2&lt;strong&gt;9 ~ 2&lt;/strong&gt;12）。如果内存显存足够，我建议使用更大的batch size，我发现一些很难调的任务，在很大的batch size（2 ** 14） 面前更容易获得单调上升的学习曲线（训练慢但是及其稳定，多GPU分布式）。请自行取舍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【更新次数】&lt;/strong&gt; 一般我们不直接设置更新次数，而是通过【单轮更新的采样步数】、【批次大小】和【数据重用次数】一同算出【更新次数】，详见下面PPO算法的【数据重用次数】&lt;/p&gt;

&lt;h1&gt;3. TD3特有的超参数&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;探索噪声方差 exploration noise std&lt;/li&gt;
&lt;li&gt;策略噪声方差 policy noise std&lt;/li&gt;
&lt;li&gt;延迟更新频率 delay update frequency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果你擅长调参，那么可以可以考虑TD3算法。如果你的算法的&lt;strong&gt;最优策略通常是边界值&lt;/strong&gt;，那么你首选的算法就是TD3----&lt;font&gt;&lt;strong&gt;最佳策略总在动作边界&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【TD3的探索方式】&lt;/strong&gt; 让其很容易在探索「边界动作」：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;策略网络输出张量，经过激活函数 tanh 调整到 (-1, +1)&lt;/li&gt;
&lt;li&gt;为动作添加一个clip过的高斯噪声，噪声大小由人类指定&lt;/li&gt;
&lt;li&gt;对动作再进行一次clip操作，调整到 (-1， +1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;好处：&lt;/strong&gt; 一些任务的最优策略本就存在存在大量边界动作，TD3可以很快学得很快。
&lt;strong&gt;坏处：&lt;/strong&gt; 边界动作都是 -1或 +1，这会降低策略的多样性，网络需要在多样性好数据上训练才不容易过拟合。对于clip 到正负1之间的action，过大的噪声方差会产生大量边界动作 。
&lt;img src=&quot;https://s2.51cto.com/images/blog/202212/15135614_639ab6fea6da517014.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【探索噪声方差 exploration noise std】&lt;/strong&gt;  就是上图中的s。需要先尝试小的噪声方差（如0.05），然后逐渐加大。大的噪声方差刻意多探索边界值，特定任务下能让探索更快。&lt;strong&gt;且高噪声下训练出来的智能体更robust（稳健、耐操）&lt;/strong&gt;。
请注意：过大的噪声方差（大于上图蓝线的0.5）并不会让探索动作接近随机动作，而是让探索动作更接近单一的边界动作。此外，过大的噪声会影响智能体性能，导致她不容易探索到某些state。&lt;/p&gt;

&lt;p&gt;因此，合适的探索噪声方差只能慢慢试出来，TD3适合愿意调参的人使用。在做出错误动作后容易挽回的环境，可以直接尝试较大的噪声。
我们也可以模仿 epslion-Greedy，设置一个使用随机动作的概率，或者每间隔几步探索就不添加噪声，甚至也在TD3中使用探索衰减。这些操作都会增加超参数的数量，慎用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【策略噪声方差 policy noise std】&lt;/strong&gt; 确定了探索噪声后，策略噪声只需要比探索噪声稍大&lt;strong&gt;（1~2倍）&lt;/strong&gt;。TD3对策略噪声的解释是“计算Q值时，因为相似的动作的Q值也是相似的，所以TD3也为动作加一个噪声，这能使Q值函数更加光滑，提高训练稳定性 我们还能多使用几个添加噪声的动作，甚至使用加权重要性采样去算出更稳定的Q值期望。在确定策略梯度算法里的这种“在计算Q值时，为动作加noise的操作”，让TD3变得有点像随机策略梯度。无论是否有clip，策略噪声方差最大也不该超过0.5。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【延迟更新频率 delay update frequency】&lt;/strong&gt; TD3认为：引入目标网络进行 soft update 就是为了提高训练稳定性，那么既然 network 不够稳定，那么我们应该延迟更新目标网络 target network，即多更新几次 network，然后再更新一次target network。从这个想法再拓展出去，我们甚至可以模仿TTUR的思想做得更细致一点，针对双层优化问题我们能做：&lt;/p&gt;

&lt;p&gt;环境随机因素多，则需要尝试更大的延迟更新频率，可尝试的值有 1~8，默认值为2
提供策略梯度的critic可以多更新几次，再更新一次actor，可尝试的值有 1~4&amp;lt;&lt;/p&gt;

&lt;p&gt;提供策略梯度的critic可以设计更大的学习率，例如让critic的学习率是actor 的1~10倍&lt;/p&gt;

&lt;p&gt;由于critic 需要处理比 actor 更多的数据，因此建议让critic网络的宽度略大于actor&lt;/p&gt;

&lt;h1&gt;4. SAC特有的超参数&lt;/h1&gt;

&lt;p&gt;尽管下面列举了4个超参数，但是后三个超参数可以直接使用默认值（默认值只会有限地影响训练速度），第一个超参数甚至可以直接通过计算选择出来，不需要调整。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;reward scale 按比例调整奖励&lt;/li&gt;
&lt;li&gt;alpha 温度系数 或 target entropy 目标 策略熵&lt;/li&gt;
&lt;li&gt;learning rate of alpha 温度系数 alpha 的学习率&lt;/li&gt;
&lt;li&gt;initialization of alpha 温度系数 alpha 的初始值
SAC有极少的超参数，甚至这些超参数可以在训练开始前就凭经验确定。
&lt;img src=&quot;https://s2.51cto.com/images/blog/202212/15135614_639ab6fea92375198.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=&quot; alt=&quot;在这里插入图片描述&quot;/&gt;任何存在多个loss相加的目标函数，一定需要调整系数 lambda，例如SAC算法、共享了actor critic 网络的A3C或PPO，使用了辅助任务的PPG。我们需要确定好各个 lambda 的比例。SAC的第二篇论文加入了自动调整 温度系数 alpha 的机制，处于lambda2位置的温度alpha 已经用于自动调整策略熵了，所以我们只能修改lambda1。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;reward scaling 是指直接让reward 乘以一个常数k (reward scale)，在不破坏reward function 的前提下调整reward值，从而间接调整Q值到合适的大小。 修改reward scale，相当于修改lambda1，从而让可以让 reward项 和 entropy项 它们传递的梯度大小接近。与其他超参数不同，只要我们知晓训练环境的累计收益范围，我们就能在训练前，直接随意地选定一个reward scaling的值，让累计收益的范围落在 -1000~1000以内即可，不需要精细调整：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【温度系数、目标策略熵】&lt;/strong&gt;  Temperature parameters (alpha)、target &#x27;policy entropy&#x27;。SAC的第二篇论文加入了自动调整 温度系数 alpha 的机制：通过自动调整温度系数，做到让策略的熵维持在目标熵的附近（不让alpha过大而影响优化，也不让alpha过小而影响探索）&lt;/p&gt;

&lt;p&gt;策略熵的默认值是 动作的个数 的负log，详见SAC的第二篇论文 section 5 Automating Entropy Adjustment for Maximum Entropy 。SAC对这个超参数不敏感，一般不需要修改。有时候策略的熵太大将导致智能体无法探索到某些有优势的state，此时需要将目标熵调小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【温度系数 alpha 的学习率】&lt;/strong&gt; learning rate of alpha 温度系数alpha 最好使用 log 形式进行优化，因为alpha是表示倍数的正数。一般地，温度系数的学习率和网络参数的学习率保持一致（一般都是1e-4）。当环境随机因素过大，导致每个batch 算出来的策略熵 log_prob 不够稳定时，我们需要调小温度系数的学习率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【温度系数 alpha 的初始值】&lt;/strong&gt; initialization of alpha 温度系数的初始值可以随便设置，只要初始值不过于离奇，它都可以被自动调整为合适的值。一般偷懒地将初始值设置为 log(0) 其实过大了，这会延长SAC的预热时间，我一般设置成更小的数值，详见 The alpha loss calculating of SAC is different from other repo · Issue #10 · Yonv1943/ElegantRL 。&lt;/p&gt;

&lt;h1&gt;5. 自己模型训练调参记录（TD3）&lt;/h1&gt;

&lt;h2&gt;5.1 模型环境参数&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;常规参数：&lt;/strong&gt;
| 无人机初始位置|用户初始位置  | 无人机覆盖半径(米)|最大关联数 |UAV飞行距离 |
|--|--|--|--|--|
| 【20，180】 |【20，180】  | 【75，100】|【20，30】 |【0，30】 |
&lt;strong&gt;时延记录:&lt;/strong&gt;
|前景（MB） | 0.125 |0.5 |1|1.25  |1.5 |
|--|--|--|--|--|--|
| 背景(MB) |0.5 | 2|4 | 5| 6|
| local(ms) |13 | 52|105| ---|150|
| UAV(ms) |47 | 29.4|39.7 | ---| 50.6|
| coop(ms) |44 | 29.6|38.2| ----| 47|
&lt;strong&gt;超参数：&lt;/strong&gt;
| ACTOR_LR |CRITIC_LR | BATCH_SIZE|GAMMA  |TAU  |
|--|--|--|--|--|
| 【1e-4 ，1e-5】 |【1e-3 ，1e-4】  | 【256，512】|0.99】 |0.005 |
| EXPL_NOISE|policy_noise | noise_clip| policy_freq |hid_size |
|0.1、0.05|0.2、0.1|0.5|【1，8】默认：2|【128，512】|&lt;/p&gt;

&lt;p&gt;目前采用组合有如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ACTOR_LR = 1e-4  # Actor网络的 learning rate 学习率  1e-3&lt;/li&gt;
&lt;li&gt;CRITIC_LR = 1e-3  # Critic网络的 learning rate   1e-3&lt;/li&gt;
&lt;li&gt;EXPL_NOISE = 0.05   # 动作噪声方差&lt;/li&gt;
&lt;li&gt;self.hid_size=256&lt;/li&gt;
&lt;li&gt;self.hid1_size=128

&lt;/li&gt;
&lt;li&gt;noise_clip=0.5,&lt;/li&gt;
&lt;li&gt; policy_freq=2&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;5.2 &lt;strong&gt;调参效果：&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;可以看到模型训练的稳定性和收敛效果越来越好，调多了你也就知道哪些超参数影响的大了&lt;/p&gt;

&lt;h2&gt;5.3 &lt;strong&gt;造成波动的原因，然后采用对应的解决方案：&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;如果在策略网络没有更新的情况下，Agent在环境中得到的分数差异过大。那么这是环境发生改变造成的：
-1. 每一轮训练都需要 env.reset()，然而，有时候重置环境会改变难度，这种情况下造成的波动无法消除。
-2. 有时候是因为DRL算法的泛化性不够好。此时我们需要调大相关参数增加探索，以训练出泛化性更好的策略。&lt;/li&gt;
&lt;li&gt;如果在策略网络没有更新的情况下，Agent在环境中得到的分数差异较小。等到更新后，相邻两次的分数差异很大。那么这是环境发生改变造成的： 1. 把 learning rate 调小一点。2. 有时候是因为算法过度鼓励探索而导致的，调小相关参数即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>658b81adcf4679229d35c2c404ef3735</guid>
<title>计算存储分离在京东云消息中间件 JCQ 上的应用</title>
<link>https://toutiao.io/k/vg47ljm</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;&lt;strong&gt;作者：田寄远&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;JCQ 全名 JD Cloud Message Queue，是京东云自研、具有 CloudNative 特性的分布式消息中间件。 JCQ 设计初衷即为适应云特性的消息中间件；具有高可用、数据可靠性、副本物理隔离、服务自治、健康状态汇报、少运维或无运维、容器部署、弹性伸缩、租户隔离、按量付费、云账户体系、授权等特性。&lt;/p&gt;

&lt;h1&gt;演进过程&lt;/h1&gt;

&lt;p&gt;2017 年中开始开发 JCQ 1.0 版本，2018 年 11 月正式 GA 上线对外售卖，1.0 版本中 Topic 受限于单台服务器限制，满足不了用户超大规格 topic 的需求。&lt;/p&gt;

&lt;p&gt;2019 年 4 月 JCQ 2.0 正式上线，主要新增特性是 topic 扩缩容能力、热点 Topic 在 Broker 间的负载均衡、热点 Broker 的流量转移。&lt;/p&gt;

&lt;p&gt;2019 年 7 月 JCQ 做了一次大的架构演进 —— 计算存储分离，大版本号为 JCQ 3.0, 于 2019 年底上线。计算存储分离对架构带来了比较明显的好处，解决了日常遇到许多的痛点问题。下文详细介绍此次演进带来的好处及解决的痛点问题。&lt;/p&gt;

&lt;h1&gt;升级影响范围尽可能小&lt;/h1&gt;

&lt;p&gt;在 JCQ2.0 中计算模块与存储模块处于同一个进程，升级计算模块势必将存储模块一起升级。而存储模块重启是比较重的动作，需要做的工作有：加载大量数据、进行消息数据与消息索引数据比对、脏数据截断等操作。往往修复计算模块一个小的 Bug，就需要做上述非常重的存储模块重启。而在现实工作中，大部分升级工作都是由于计算模块功能更新或 Bugfix 引起的。&lt;/p&gt;

&lt;p&gt;为了解决这个问题， JCQ3.0 将计算模块、存储模块独立部署，之间通过 RPC 调用。各自升级互不影响。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a562b9cadd1840bfbdfdb50b7611a471%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;计算节点 Broker 只负责生产消息、推送消息、鉴权、认证、限流、拥塞控制、客户端负载均衡等业务逻辑，属于无状态服务。比较轻量，升级速度快。&lt;/p&gt;

&lt;p&gt;存储节点 Store 只负责数据写入、副本同步、数据读取。因为业务逻辑简单，功能稳定后，除优化外基本无需改动，也就无需升级。&lt;/p&gt;

&lt;h1&gt;成本降低&lt;/h1&gt;

&lt;p&gt;JCQ 是共享消息中间件，用户申请的是不同规格 TPS 的 Topic，并不感知 cpu、memory、disk 等硬件指标。 所以，JCQ 服务方需要考虑如何合理的使用这些硬件指标。&lt;/p&gt;

&lt;p&gt;JCQ 是容器部署，有多种类型的组件，这些组件对硬件的需求也是多样化的，其中对资源消耗最多的是计算模块和存储模块。在 JCQ2.0 版本计算模块和存储模块部署在一起，选择机型时要兼顾 cpu、memory、disk 等指标，机型要求单一，很难与其他产品线混合部署。即使是同一资源池，也存在因为调度顺序，造成调度失败的情况。如一台机器剩余资源恰好能调度一个需要大规格磁盘的 A 容器，但是因为 B 容器先被调度到这台机器上，剩余资源就不够创建一个 A 容器，那这台机器上的磁盘就浪费了。&lt;/p&gt;

&lt;p&gt;JCQ3.0 后，计算节点 Broker，与存储节点 Store 独立部署。这两个组件可以各自选择适合自己业务的机型，部署在相应资源池中；最终，可以做到与其他产品混合部署，共用资源池水位，而不用独自承担资源水位线。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2178ae2323e14114bd7f7976e53b6846%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h1&gt;架构改进带来的成本降低&lt;/h1&gt;

&lt;p&gt;JCQ3.0 中计算节点 Broker 是无状态服务，主从切换比较轻量，能在秒级完成故障转移；且部署时考虑了物理设备反亲和，如跨 Rack、跨 AZ 部署。所以，可以在可用性、资源成本之间做一定的权衡；如可以使用 M:1 方式做高可用冷备，而不必 1：1 的比例高可用冷备，进而达到节省硬件资源的目的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f186617cbc544829bd797eef28b206d0%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h1&gt;解决 Raft 性能问题&lt;/h1&gt;

&lt;p&gt;JCQ 1.0 设计之初就采用 Raft 算法，来解决服务高可用、数据一致性的问题。Message Log 与 Raft Log 有很多共同的特性，如顺序写、随机读、末端热数据。所以，直接用 Raft Log 当成 Message Log 是非常合适的。&lt;/p&gt;

&lt;p&gt;在 JCQ 演进中我们也发现了 Raft 本身的一些性能问题，如顺序复制、顺序 commit、有的流程只能用单线程处理等限制。针对这些问题，最直接有效的办法就是扩展 Raft 的数目、扩展单线程流程数目，在一定数量级内，并发能力随着 Raft Group 数目的增长，呈线性增长关系，称之 MultiRaft，如下图所示。&lt;/p&gt;

&lt;p&gt;****&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/98c079025a1e42e787957216492cdb2c%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;上图中，每个 StoreNode 节点是一个独立进程，内部有四组逻辑 RaftGroup（橙色的节点为 RaftGroup 的 Leader），各组 RaftGroup 之间是并行关系，可以做到 Group 间并行复制、并行 commit。&lt;/p&gt;

&lt;p&gt;由于大量使用了 NIO，这些 RaftGroup 之间可以共享通信线程池，扩充 RaftGroup 数目并不会带来线程资源线性增长的问题。&lt;/p&gt;

&lt;h1&gt;快速故障恢复、轻量的负载均衡&lt;/h1&gt;

&lt;p&gt;在 JCQ3.0 中，Broker 为轻量的无状态服务，在主从切换、故障恢复方面相对 2.0 更为轻量，本身能更快的恢复对外服务能力。&lt;/p&gt;

&lt;p&gt;同时，Broker 将 Producer、Consumer 的连接请求，抽象为 PubTask 和 SubTask，后文统称为 Task。Task 的概念非常轻量，仅描述 Client 与 Broker 的对应关系，由元数据管理器 Manager 统一调度、管理。转移 Task 只需要修改 Task 的内容，客户端重新连接新 Broker 即可。&lt;/p&gt;

&lt;p&gt;一般来说，Broker 的主要瓶颈在于网络带宽。Broker 定期统计网络入口流量与出口流量，并上报给管理节点 Manager。Manager 根据入口流量、出口流量与带宽阈值进行裁决，发现超过阈值后，通过一定策略将相应的 Task 转移到较小负载的 Broker 上，并通知相应的 Producer 与 Consumer；Producer 与 Consumer 收到通知后，重新获取 Task 的路由信息，自动重连到新的 Broker 继续进行生产、消费。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a25855ca88404ee994b9c97269414954%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h1&gt;高扇出需求&lt;/h1&gt;

&lt;p&gt;设想一个场景，有一个大规格的 topic，创建了 n 个消费组。消费总 TPS 是生产总 TPS 的 n 倍。增加消费组，会导致消费总 TPS 线性增长。到达一定消费组规模后，单 Broker 由于网卡带宽的原因，无法满足这种高扇出的场景。单服务器是无法解决这个问题。&lt;/p&gt;

&lt;p&gt;在 JCQ 3.0 可以将这些不同的消费组对应的 SubTask 分散到若干个 Broker 上，每个 Broker 负责一部分 SubTask，单 Broker 从 Store 预读消息，将数据推送给 Consumer。这样多个 Broker 共同完成所有消费组的消息流量，协作一起提供高扇出的能力。&lt;/p&gt;

&lt;h1&gt;支持多种存储引擎&lt;/h1&gt;

&lt;p&gt;消息中间件很大的特点是：大部分场景下，热数据都在末端，而回溯几天之前的消息这个功能是不常用的。所以，就有冷热数据之分。&lt;/p&gt;

&lt;p&gt;JCQ 计算节点设计了一层存储抽象层 Store Bridge 可以接入不同的存储引擎，可以接入 Remote Raft Cluster，或者分布式文件系统 WOS、或者 S3。甚者可以将冷数据定期从昂贵的本地盘卸载到廉价的存储引擎上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cd929e01f6b447d49801036b9a274853%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;副作用&lt;/h1&gt;

&lt;p&gt;相对于 JCQ2.0，计算节点与存储节点之间的通信方式，由接口调用变为 RPC 调用，在延迟方面会有一定损失。经过测试，绝大部分延迟都在 1ms 左右，在大多数场景下 牺牲 1ms 左右的延迟并不会给业务带来太大的影响。&lt;/p&gt;

&lt;h1&gt;后续发展规划&lt;/h1&gt;

&lt;p&gt;JCQ 后续会主要在多协议兼容，按需自动扩缩容、云原生等方面演进。&lt;/p&gt;

&lt;h1&gt;多协议兼容&lt;/h1&gt;

&lt;p&gt;JCQ 协议为私有协议，在引导用户迁移方面有比较大的障碍。后续会抽离 JCQ Kernel，外部提供不同的协议接入层。方便用户从其他 MQ 接入 JCQ。目前已兼容 RocketMQ 协议，SQS 协议&lt;/p&gt;

&lt;h1&gt;自动扩缩容&lt;/h1&gt;

&lt;p&gt;JCQ 是共享消息中间件，但缺少 Serverless 自动扩缩容的特性。每逢大促，如 618，双 11，服贸会等重要活动。业务方很难预估自己的业务量峰值，或者估计不足，会造成 topic 限流等问题。如在保证 JCQ 服务本身能力情况下，能做到 topic 灵活的自动扩缩容，将对用户有极大的帮助，起到真正的削峰填谷作用。&lt;/p&gt;

&lt;h1&gt;云原生&lt;/h1&gt;

&lt;p&gt;支持在 kubernetes 环境部署与交付，提供原生的 Operator，能够快速的部署在 k8s 环境中，更好的交付私有云、混合云项目。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cebbddf68496432499aa07df9f7016ec</guid>
<title>最强开源 OLAP 数据库，你应该选择的 10 个理由</title>
<link>https://toutiao.io/k/h1z5lkl</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;col-md-10 col-sm-12&quot;&gt;
            &lt;h1&gt; 最强开源 OLAP 数据库，你应该选择的 10 个理由&lt;/h1&gt;
            &lt;hr/&gt;
            &lt;p&gt;作者: 康凯森&lt;/p&gt;
            &lt;p&gt;日期: 2022-12-13&lt;/p&gt;
            &lt;p&gt;分类: &lt;a href=&quot;../tag/OLAP.html&quot; target=&quot;_blank&quot;&gt;OLAP&lt;/a&gt;&lt;/p&gt;
            &lt;hr/&gt;
            


&lt;p&gt;2022 年即将结束，疫情持续了 3 年，StarRocks 也创立了快 3 年，今天就总结下 StarRocks 用户侧可以感知的十大 Fature 和 优化，也希望大家对 StarRocks 有一个更全面的认知。&lt;/p&gt;
&lt;h2 id=&quot;一-极速-olap&quot;&gt;一 极速 OLAP&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16688670975989.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图中是我们官网展示的 SSB 单表的查询性能对比，可以看到，相比业界其他优秀的 OLAP 数据库，我们 StarRcoks 在性能上有着明显的优势，不止是 SSB 单表查询，SSB 多表，TPC-H 查询，TPC-DS 等复杂的多表查询，我们同样拥有极致的性能。TPC-DS 查询在 100G 和 1T 规模下，StarRcoks 相比 Snowflake 有2到3倍的性能优势。&lt;/p&gt;
&lt;p&gt;极致的性能不仅可以带来更好的用户体验，让之前难以实现的需求可以实现，更重要的是，可以节省大量的机器，为企业降本增效。&lt;/p&gt;
&lt;p&gt;我们 StarRcoks 能拥有极致的 OLAP 分析性能，是因为2年多来，我们在以下几个方面做了大量持续深入的优化：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;MPP 分布式执行&lt;/strong&gt;：StarRocks 拥有 MPP 的分布式执行框架，保证了 StarRocks 可以充分发挥多机 scale out 的能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline 并行执行框架&lt;/strong&gt;：我们从零打造了 pipeline 并行框架，可以让  StarRocks 充分发挥多核 scale up 的能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;向量化执行&lt;/strong&gt;：我们从零打造了 StarRocks 的向量化执行引擎，让 StarRocks 单核可以拥有极致的执行性能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CBO 优化器&lt;/strong&gt;：通过 MPP 分布式执行， Pipeline 并行执行 和 向量化执行，我们拥有了世界领先的查询执行器，但是对于复杂的SQL，优化器产生的 Plan 好坏对查询性能影响更大，所以我们又从零打造了 CBO 优化器，让 StarRocks 对于复杂查询可以产生足够好的 Plan，进而对于复杂查询，StarRocks 也可以拥有极佳的查询性能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Global Runtime Filter&lt;/strong&gt; : Runtime Filter 对复杂的join 查询影响极大，开关 Runtime filter，可以有几十倍的查询，我们在 Global 和 Local Runtime Filter 上都做了挺多深度优化和创新&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全局低基数字典优化&lt;/strong&gt;：目前主要是可以优化包含低基数字符串的各类查询，整体会有2到3倍的性能提升，面向的场景主要是业务的维表中有大量的低基数字符串列。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对上面技术原理感兴趣的可以参考我们 StarRocks 官方微信公众号和 B 站的相关技术分享。&lt;/p&gt;
&lt;h2 id=&quot;二-极速数据湖分析&quot;&gt;二 极速数据湖分析&lt;/h2&gt;
&lt;p&gt;当我们拥有了一个极速的查询引擎，可以实现极速 Olap 分析后，一个自然而然的想法就是，我们是不是也可以直接查询 Apache Hive、Apache Iceberg 和 Apache Hudi 等开源数据湖或数据仓库的数据上呢？ 答案是 Yes ! 这样的一个巨大好处是用户省去了数据导入或者同步这个工作，对用户的易用性大大增强。&lt;/p&gt;
&lt;p&gt;所以从21年开始，我们就成立了专门的数据湖分析团队，致力于提供开箱即用的极速数据湖分析体验。一年多来，用户侧可以感知的优化和功能如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1 各种外部数据源接入更加简单&lt;/strong&gt;：开发了全新的 Connector 框架和 Catalog 机制，访问外部数据源变得很容易，只需要配置下 Catalog，就可以查询到对应 DB 下的所有表数据，而不是最初一张表一张表配置，极大提升了用户的易用性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16688650649458.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2 更加极致的性能&lt;/strong&gt;：除了查询引擎本身的持续性能提升，数据湖分析额外在 Scan 算子和外表元数据访问上做了大量优化，在有 Local Cache的情况下，外表查询性能可以媲美本地的 OLAP 表。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16679830144946.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;3 更加弹性&lt;/strong&gt;： 当 BE 不负责数据存储时，就变成了一个无状态的计算节点，弹性伸缩就变得十分自然和容易，而且数据湖分析大多属于 Adhoc 查询，查询范式不固定，相比与传统的 Olap 查询，更需要弹性伸缩的能力。所以我们就新增了一种新的节点：Compute Node —— 是将 BE 的存储功能移除，只保留计算模块。 并和 K8S 结合，做到了弹性伸缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16709203320364.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;4 更加安全&lt;/strong&gt;： 我们更好地支持了 Kerberos 认证，接入了云厂商托管的 IAM 服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;三-主键更新&quot;&gt;三 主键更新&lt;/h2&gt;
&lt;p&gt;过去两年来，我们从零实现了全新的 基于列存的 Delete-and-Insert 模式的主键更新模型，可以同时支持实时更新和极致的查询性能，在大规模实时数据写入的同时，查询性能可以做到其他行业领先 OLAP 数据库的 3-5 倍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16709237307812.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;两年来，我们的主键模型做了如下优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主键索引持久化：减少了主键索引的内存使用量，可以支持更大数据量的单表&lt;/li&gt;
&lt;li&gt;部分列更新：以现有的 Delete + Insert 模式为基础，通过读取老版本数据，来填充缺失列&lt;/li&gt;
&lt;li&gt;条件更新：当满足某个固定条件时才更新对应行，否则就不更新&lt;/li&gt;
&lt;li&gt;高频导入优化：对 Publish version 过程，compaction 过程，合并事务数等优化&lt;/li&gt;
&lt;li&gt;Update 和 Delete 语句支持复杂表达式和子查询&lt;/li&gt;
&lt;li&gt;主键和排序键分离&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实时化是整个数据分析的大趋势，而更新的需求也越来越多，有了 StarRocks 优秀的主键模型，你可以更好的支持下面的业务场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CDC 实时同步 TP 数据到 StarRocks 中，这也是使用最广泛的场景&lt;/li&gt;
&lt;li&gt;数据处理范式从 ETL 变成 ELT，也需要强大的更新能力&lt;/li&gt;
&lt;li&gt;实时流中通过多表 Join 更新数据的场景，有了 Partial-Update，就可以代替部分多表 Join 的需求&lt;/li&gt;
&lt;li&gt;根据某个时间戳进行条件更新&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;四-资源隔离&quot;&gt;四 资源隔离&lt;/h2&gt;
&lt;p&gt;在生产环境中，大家一般都会遇到大查询的问题： 几个大查询吃满了整个集群的资源，影响了正常的小查询，大查询很难及时熔断和定位。 针对大查询的问题，我们从 2.3 版本开始，基于 Pipeline 执行引擎，实现了资源隔离。 目前 StarRocks 支持了内存资源的硬隔离，CPU 和 IO 资源的软隔离。&lt;/p&gt;
&lt;p&gt;我们引入了 Work Group 的概念，每个 Work Group 可以配置使用的 CPU 和 IO 比例，我们通过两级队列调度和类型 Linux CFS 调度的算法基本保证了每个 Work Group在查询运行时，使用的资源可以符合配置的比例。&lt;/p&gt;
&lt;p&gt;同时为了提高资源的利用率，在集群资源空闲时，每个 work group 可以使用到更多资源，对集群资源的利用率和隔离性进行了兼顾。&lt;/p&gt;
&lt;p&gt;对一些高优业务，用户可能期望隔离性更高，我们也支持了短查询 Work Group 的 CPU 硬隔离，任何情况下，其对应的 CPU 资源都不会被占用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16709327441519.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;五-物化视图&quot;&gt;五 物化视图&lt;/h2&gt;
&lt;p&gt;StarRocks 第一版的物化视图是从 Rollup 转换而来，只能用来透明加速查询，不能显示直接查询某个物化视图，也就是说物化视图只有物化的语义，没有视图的语义。&lt;/p&gt;
&lt;p&gt;我们物化视图 2.0 版本进行了5方面的加强：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;让物化视图可以直接被查询&lt;/strong&gt;：将物化视图也视为一张表，这样在复杂的 ELT 或者 ELT 的数据处理过程中，就可以使用物化视图来简化 SQL&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在数据建模场景下，支持任意复杂的SQL&lt;/strong&gt;：也就是说，物化视图里面可以定义任意复杂的SQL，但是不保证每个物化视图都支持透明的查询改写加速&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在透明加速场景下，支持更复杂的SQL:&lt;/strong&gt; 目前 StarRocks 已经可以支持 Aggregate, Join, Filter, Union 等复杂查询的物化视图透明改写&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持对数据湖上的数据建立物化视图&lt;/strong&gt;：对数据湖上的近期热点数据利用物化视图进行强有力的透明加速&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;物化视图支持异步刷新和自动刷新&lt;/strong&gt;：让物化视图的创建过程和刷新过程更加简单&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 StarRocks 3.0 中，物化视图将会有一个质变，成为 StarRocks 的 Killer Feature，大家敬请期待。&lt;/p&gt;
&lt;h2 id=&quot;六-tablet-level-query-cache&quot;&gt;六 Tablet Level Query Cache&lt;/h2&gt;
&lt;p&gt;在实时报表分析和时序查询中，大家经常会遇到分析最近某几天的数据，或者分析今天从零点一直到现在的数据这种场景，在这类查询中，最近某几天的分区 或者 最近某几个小时的数据可能被高频查询到，这种场景很适合 Query Cache 发挥作用，StarRocks 是基于 Tablet 粒度实现的 Query Cache，具有以下亮点：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/44ebdb2c-950e-400f-8b68-aca5e7c8aa76.png&quot; alt=&quot;44ebdb2c-950e-400f-8b68-aca5e7c8aa76&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cache 命中率高&lt;/strong&gt; ：因为 Cache 粒度是 Tablet 粒度，比较细，不是整个查询结果集，或者某个分区的查询结果集，Cache 命中率理论上会更高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;支持多版本&lt;/strong&gt;：支持多版本有多个好处，首先是可以支持高频实时导入，因为 tablet 旧版本的对应的 Cache 内容可以复用，只需要旧版本的 Cache 结果和新版本的增量结果合并即可&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;支持 Join 等多表复杂查询的结果集Cache&lt;/strong&gt;：不像大多数系统只能支持单表查询的 Query Cache.&lt;/p&gt;
&lt;p&gt;StarRocks 的 Query Cache 已经在 2.5 版本发布，欢迎大家使用。&lt;/p&gt;
&lt;h2 id=&quot;七-半结构化数据分析&quot;&gt;七 半结构化数据分析&lt;/h2&gt;
&lt;p&gt;过去两年来，StarRocks 在持续完善半结构化数据分析能力：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持了 Array, Map, Struct, Json 数据类型&lt;/li&gt;
&lt;li&gt;支持了大量 Array, Map, Struct, Json 相关函数&lt;/li&gt;
&lt;li&gt;支持了 Lateral Join 和 Unnest Table Function，详情可以参考 &lt;a href=&quot;https://docs.starrocks.io/zh-cn/latest/using_starrocks/Lateral_join&quot;&gt;https://docs.starrocks.io/zh-cn/latest/using_starrocks/Lateral_join&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;支持了 Lambda 函数，  详情可以参考 StarRocks Lambda 函数用户文档&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有了这些基础能力，你可以用 StarRocks 做一些更强大的事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;StarRocks 可以更好地支持用户行为分析（留存及漏斗分析，路径分析等）&lt;/li&gt;
&lt;li&gt;StarRocks 可以更好地支持 Parquet, ORC 等文件导入和分析&lt;/li&gt;
&lt;li&gt;支持 Map 和 Json 类型可以让 StarRocks 更容易进行 Schema 变更&lt;/li&gt;
&lt;li&gt;支持 Json 类型让 StarRocks 对日志分析，事件分析等场景支持更加友好&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;StarRocks 明年也会持续在半结构化数据分析上发力。&lt;/p&gt;
&lt;h2 id=&quot;八-查询并行度自适应&quot;&gt;八 查询并行度自适应&lt;/h2&gt;
&lt;p&gt;StarRocks 的查询一开始是 Fragment 并行机制，将每个查询的并行度设置交给了用户，但是这个具体的并行度值用户很难设置，简单查询串行执行时并行度高点性能会好，但是高并发时，并行度高性能反而会更差，因为旧版的执行框架，是每个 fragment 一个执行线程，fragment 数越多，执行线程会更多，线程切换和竞争的开销会更大。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，StarRocks 一年多来分三步走解决了这个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;实现 Pipeline 并行引擎&lt;/strong&gt;：将执行线程数固定成 CPU 核数，查询默认的并行度改成核数的一半，用户不需要再关心并行度的设置，但是还存在一些优化空间&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;单 Tablet 内部并行&lt;/strong&gt;：支持单个 Tablet 可以并行查询，将查询的并行度和 Tablet 数解耦，解决了 Tablet 数较少时无法设置更高并行度的问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;查询并行度自适应（下个版本支持）&lt;/strong&gt;: 根据不同的集群复杂和查询类型，自动设置最合理的并行度。默认并行度设置成为核数，当数据量比较少时 或者 集群负载比较高时，自动减少并行度；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过这三步，当你在 StarRocks 时就再也不用自己操心查询并发度的设置了，无论是 Benchmark 场景，还是高并发场景，无论是复杂的大查询，还是简单的小查询，StarRocks 都会自动为你提供&lt;strong&gt;开箱即用的极致性能体验&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;九-云原生存储分离&quot;&gt;九 云原生存储分离&lt;/h2&gt;
&lt;p&gt;大家都知道，Cloud Native 是大势所趋，而要支持 Cloud Native，StarRocks 就必须从之前的 Shared-Nothing 架构转向存算分离架构。从 21 年初，StarRocks 就组建了专门的 Cloud 团队全力打造全新的存算分离架构，历经我们 Cloud 团队长达两年的设计和研发，存算分离的 StarRocks 第一版已经开发测试完成，目前已经交付部分用户进行试用测试，有想提前尝鲜的用户也欢迎联系我们。&lt;/p&gt;
&lt;p&gt;如上图所示（由于官方还未公开过图，我就不放了，大家可以根据 《Data-Parallel Actors：千行代码构建高性能 OLAP 数据库》一文中的描述脑补下），是我们 StarRocks 新一代的全新架构，我们新一代存算分离架构的核心是 StarOS, StarOS 一个极具野心的项目，简单来说，StarOS 会对分布式相关逻辑进行抽象和统一，对云上存储进行抽象和统一，让我们未来打造一个存算分离服务变得十分简单。 具体的技术内幕大家可以期待我们 Cloud 团队同学之后的深度分享。&lt;/p&gt;
&lt;p&gt;那么从用户视角来看，我们全新的存算分离架构会提供什么独特的优势呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在可以弹性伸缩的同时，可以提供媲美 Shared-Nothing 架构的性能&lt;/li&gt;
&lt;li&gt;依靠 StarOS, 同时支持云上部署和本地部署&lt;/li&gt;
&lt;li&gt;实时更新能力&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然，普遍存储架构的优点我们已经或即将具备：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;极致弹性&lt;/li&gt;
&lt;li&gt;更低成本&lt;/li&gt;
&lt;li&gt;多租户&lt;/li&gt;
&lt;li&gt;读写分离&lt;/li&gt;
&lt;li&gt;Serverless&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;十-saas-byoc&quot;&gt;十 SAAS BYOC&lt;/h2&gt;
&lt;p&gt;所谓云原生的存算分离，我们除了存储分离的内核，还需要在云上将数据库服务化，所以在一边打造存算分离内核的同时，我们也成立了一个专门的团队在打造 SAAS 服务，我们目前已经推出了 BYOC 的 SASS 模式。 BYOC 是 bring-your-own-cloud 的缩写，也就是&lt;strong&gt;使用用户自己的云，这样会有更好的数据隐私，更好的安全性&lt;/strong&gt;。如图所示（由于官方还未公开过图，我就不放了），整个架构分为控制面板和数据面板，控制面板在 StarRocks 的 VPC， 数据面板在用户的 VPC，目前已经有多个用户在正式使用。&lt;/p&gt;
&lt;p&gt;我们即将迎来2023年，在新的一年里， StarRocks 会带来更多的 Killer Feature，也会大力提升稳定性和易用性，努力让 StarRocks 成为最受欢迎的 OLAP 数据库。&lt;/p&gt;

            &lt;hr/&gt;
            &lt;h3&gt;欢迎来知识星球和我交流&lt;/h3&gt;
            
        &lt;/div&gt;
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9f79bc780e22524d5af8f1b0ae03c23c</guid>
<title>如何用 Java 实现一致性 hash 算法 (consistent hashing)（上）</title>
<link>https://toutiao.io/k/zcezqpo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;article_content&quot; class=&quot;article_content clearfix&quot;&gt;
        
        
                &lt;div id=&quot;content_views&quot; class=&quot;markdown_views prism-tomorrow-night&quot;&gt;
                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
                        &lt;path stroke-linecap=&quot;round&quot; d=&quot;M5,0 0,2.5 5,5z&quot; id=&quot;raphael-marker-block&quot;/&gt;
                    &lt;/svg&gt;
                    &lt;h3&gt;&lt;a id=&quot;hash_0&quot;/&gt;一致性hash的历史&lt;/h3&gt; 
&lt;p&gt;【Consistent Hashing算法】早在 1997 年就在论文 Consistent hashing and random trees 中被提出，目前在 cache 系统中应用越来越广泛；&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;hash_4&quot;/&gt;一致性hash的目的&lt;/h3&gt; 
&lt;p&gt;一致性哈希算法是分布式系统中常用的算法，一致性哈希算法解决了普通余数Hash算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_8&quot;/&gt;问题背景&lt;/h3&gt; 
&lt;p&gt;业务开发中，我们常把数据持久化到数据库中，如果需要读取这些数据，除了直接从数据库中读取外，为了减轻数据库的访问压力以及提高访问速度，更多地引入缓存来对数据进行存取。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_12&quot;/&gt;分布式缓存&lt;/h3&gt; 
&lt;p&gt;分布式缓存，不同机器上存储不同对象的数据。为了实现这些缓存机器的负载均衡，一般就会存在两种Hash算法进行均匀分配数据节点存储：普通Hash算法&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;Hash_16&quot;/&gt;普通的Hash算法的&lt;/h3&gt; 
&lt;h4&gt;&lt;a id=&quot;Hash_18&quot;/&gt;Hash取模做法的缺陷&lt;/h4&gt; 
&lt;p&gt;一个Redis集群中，如果我们把一条数据经过Hash，然后再根据集群节点数取模得出应该放在哪个节点，这种做法的缺陷在于：扩容(增加一个节点)之后，有大量缓存失效。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;Hash_22&quot;/&gt;普通Hash的案例分析&lt;/h4&gt; 
&lt;p&gt;比如你有 N 个 cache 服务器（后面简称 cache ），那么如何将一个对象 object 映射到 N 个 cache 上呢，你很可能会采用类似下面的通用方法计算 object 的 hash 值，然后均匀的映射到到 N 个 cache ；&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;hash(object)%N 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;一切都运行正常，再考虑如下的两种情况；&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;一个 cache 服务器 m down 掉了（在实际应用中必须要考虑这种情况），这样所有映射到 cache m 的对象都会失效，怎么办，需要把 cache m 从 cache 中移除，这时候 cache 是 N-1 台，映射公式变成了 hash(object)%(N-1) ；&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;由于访问加重，需要添加 cache ，这时候 cache 是 N+1 台，映射公式变成了 hash(object)%(N+1) ；&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;这意味着突然之间几乎所有的 cache 都失效了。对于服务器而言，这是一场灾难，洪水般的访问都会直接冲向后台服务器；（造成缓存雪崩机制）&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/630daeb47f55c834998ff223edd3b962.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;Hash_40&quot;/&gt;一致性Hash算法&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;一致性hash算法正是为了解决此类问题的方法，它可以保证当机器增加或者减少时，对缓存访问命中的概率影响减至很小。下面我们来详细说一下一致性hash算法的具体过程。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;一致性hash算法通过一个叫作一致性hash环的数据结构实现。这个环的起点是0，终点是2^32 - 1，并且起点与终点连接，环的中间的整数按逆时针分布，故这个环的整数分布范围是[0, 2^32-1]&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;整个哈希值空间组织成一个虚拟的圆环，将节点的IP地址或主机名作为关键字进行哈希计算，得出的结果作为节点在环上的位置。数据经过hash后按顺时针方向找到最近一个节点存放，如图data的hash位置，应该存放在node2。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/5c52e347ec775107e3ff9a8a3f4b05c3.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
 
&lt;h3&gt;&lt;a id=&quot;Hash_54&quot;/&gt;改良版一致性Hash算法&lt;/h3&gt; 
&lt;h4&gt;&lt;a id=&quot;Hash___56&quot;/&gt;一致性Hash算法 + 虚拟节点&lt;/h4&gt; 
&lt;p&gt;为了解决数据分布不均的问题，我们引入虚拟节点的概念。我们对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。定位到虚拟节点的数据就存到该虚拟节点对应的真实节点上，这样数据分布就相对均匀了，虚拟节点数越多，分布越均匀。&lt;/p&gt; 
&lt;p&gt;引入“虚拟节点”后，映射关系就从 { 对象 -&amp;gt; 节点 } 转换到了 { 对象 -&amp;gt; 虚拟节点 } 。查询物体所在 cache 时的映射关系&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/e8220e34bd5e99215199ec5828271951.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;一般虚拟节点数32个以上，dubbo是160个。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/7dec7ba4b09e633d77c6684220b032e4.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_68&quot;/&gt;处理机器增减的情况&lt;/h4&gt; 
&lt;p&gt;对于线上的业务，增加或者减少一台机器的部署是常有的事情。&lt;/p&gt; 
&lt;p&gt;例如，增加机器c4的部署并将机器c4加入到hash环的机器c3与c2之间。这时，只有机器c3与c4之间的对象需要重新分配新的机器。对于我们的例子，只有对象o4被重新分配到了c4，其他对象仍在原有机器上。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;Hash_75&quot;/&gt;一致性Hash算法的实现原理&lt;/h3&gt; 
&lt;p&gt;在业务开发中，我们常把数据持久化到数据库中。如果需要读取这些数据，除了直接从数据库中读取外，为了减轻数据库的访问压力以及提高访问速度，我们更多地引入缓存来对数据进行存取。读取数据的过程一般为：&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;JavaHash_79&quot;/&gt;Java代码实现Hash算法的实现&lt;/h3&gt; 
&lt;p&gt;用一个TreeMap来作为环，key为虚拟节点下标，value为真实节点的hash。个人感觉可以加一个Map&amp;lt;T, Set&amp;gt;来维护真实节点-虚拟节点的关系。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;prism language-java&quot;&gt;
&lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ConsistentHash&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Serializable&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;long&lt;/span&gt; serialVersionUID &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1L&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    
    &lt;span class=&quot;token class-name&quot;&gt;Hash32&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;SortedMap&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; circle &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;TreeMap&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ConsistentHash&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;numberOfReplicas &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;hashFunc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; key &lt;span class=&quot;token operator&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            
            &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;HashUtil&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;fnvHash&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;key&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node &lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ConsistentHash&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Hash32&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;numberOfReplicas &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;hashFunc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node &lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hashFunc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;hash32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hashFunc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;hash32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Object&lt;/span&gt; key&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; hash &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;hash32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;key&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;containsKey&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hash&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token class-name&quot;&gt;SortedMap&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; tailMap &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;tailMap&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hash&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;   
            hash &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; tailMap&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;?&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;firstKey&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; tailMap&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;firstKey&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        
        &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hash&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
                &lt;/div&gt;
                
                
        &lt;/div&gt;
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fa78302f321d2e8611a0ab96f708d0af</guid>
<title>软件架构的 23 个基本原则</title>
<link>https://toutiao.io/k/9c0uz2q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;软件体系架构基于一组适用于各种软件系统的基本原则，有经验的架构师知道这些原则，并且能够在软件产品的正确位置实现特定的原则。下面我们快速浏览一下架构师日常遵循的基本原则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. 依赖倒置（Dependency Inversion）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一原则表明依赖的方向应该是抽象的，而不是具体实现。如果编译时依赖在运行时执行的方向上流动，就形成了直接依赖。通过依赖倒置，可以反转依赖控制的方向。下面的文章更深入的讨论了这一原则：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://medium.com/p/de6abf20e423&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. 关注点分离（Separation of Concerns）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一原则指出，软件系统应该按照所做的工作类型来划分。比方说可以按照业务逻辑、基础设施或用户界面划分为不同的部分。通过将系统划分为基于不同活动区域的不同部分，使得开发/测试/部署更加容易。SoC是软件架构模式（如领域驱动设计、六边形架构、整洁架构）背后的驱动力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3. 控制反转（Inversion of Control）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该原则类似于依赖倒置原则，但适用于更广泛的背景。IoC反转了由不同的第三方框架（如Spring Framework）管理的控制流。与传统Java EE程序（由开发工程师按程序初始化Beans）不同，Spring控制Bean的配置，这意味着控制倒置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;4. 依赖注入（Dependency Injection）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该原则意味着依赖应该在运行时通过构造函数注入。在下面的例子中，Action Interface通过HumanAction Implementation注入到Human类中，从而决定在运行时实现哪个特定的动作。这种技术提供了控制依赖的灵活性：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; az.alizeynalli.di;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;interface&lt;/span&gt; &lt;span&gt;Action&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;do&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;HumanAction&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;Action&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt; &lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;do&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.print(&lt;span&gt;&quot;run&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;Human&lt;/span&gt;  &lt;/span&gt;{&lt;br/&gt;     &lt;br/&gt;    Action action;&lt;br/&gt;     &lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;Human&lt;/span&gt;&lt;span&gt;(Action action)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;this&lt;/span&gt;.action = action;&lt;br/&gt;    }&lt;br/&gt; &lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;do&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{        &lt;br/&gt;        actoin.&lt;span&gt;do&lt;/span&gt;();        &lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        Human human = &lt;span&gt;new&lt;/span&gt; Human(&lt;span&gt;new&lt;/span&gt; HumanAction);&lt;br/&gt;        human.&lt;span&gt;do&lt;/span&gt;();&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;5. 单一职责（Single Responsibility）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该原则的主要思想是限定软件系统的每个构建块只承担唯一的责任。无论构建块的作用域是什么，是插件、包、类、函数，甚至是变量，应该只有一个职责。这篇文章更深入的讨论了这一原则：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://medium.com/p/6b886f6d943e&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;6. DRY（Don’t Repeat Yourself）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该原则旨在通过避免重复代码来消除冗余。如果存在针对某些行为的现有功能，则应该重复使用，而不是在多个实例中拷贝相同的代码片段。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个知识片段在系统中都必须有单一、明确、权威的表示。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;7. 开闭原则（Open-Closed）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;软件构件应该对扩展开放，对修改关闭。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一原理的简单描述首先是由Bertrand Meyer提出的。每次都需要修改的软件系统只会变得一团糟，并且这种混乱的程序很容易在每次修改时出现错误。每个新功能都应该最大限度的增加新代码，最小限度减少旧代码的更改，理想情况下对旧代码的更改为零。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;8. 持久化透明（Persistence Ignorance）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;持久化透明的理念是，代码应该不受任何数据库或持久性技术的影响。业务逻辑应该与任何技术无关。如果明天，有更好、更有效、更便宜的持久化技术，应该能够以不影响上层抽象的方式改变系统的这一部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;9. YAGNI&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;You ain’t gonna need it. 这一原则试图避免软件系统的过早优化。开发人员通常会在系统中过度设计一些东西，以期在将来的某个时候会有帮助，但这一时刻往往不会到来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;10. 童子军规则（Boy Scout Rule）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在离开的时候要让露营地比来的时候更干净。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的主要思想是，当开发时遇到反模式，要坚持重构代码。随着时间的推移，这会提高代码质量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;11. 里氏替换原则（Liskov-Subsititution）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果对于每个类型为S的对象o1，都有一个类型为T的对象o2，这样对于用T定义的所有程序P，当o1取代o2时，P的行为不变，那么S就是T的子类型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Barbara Liskov的这个定义可能听起来很混乱，但本质上这个原则简单易懂。如果重述上面的定义，该原则的意思是: 在使用继承时，继承的层次结构应该在功能和业务逻辑方面保持一致。子类应该是可以相互替换的，并且不能改变父类的行为。作为一个简单的例子，可以用“臭名昭著的正方形/矩形”问题。其中正方形不应该是矩形的子类型，因为这两个几何形状的高度和长度的定义是不同的（正方形的高度和长度是相等的，而矩形的高度和长度是不同的）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;12. 封装（Encapsulation）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;软件系统的不同构建块应该通过封装来限制外界对其组件的访问，可以通过在类范围内设置组件为私有或在插件范围内设置访问限制来实现（就Java而言），从而隐藏信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;13. 松耦合（Loose Coupling）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;软件架构中最重要的原则之一是松耦合，这一原则表明软件系统的依赖关系应该松散，系统的一部分发生变化，对其他部分的影响应该最小。松耦合可以通过依赖倒置、异步消息中间件、事件源等实现。下面的文章深入探讨了软件工程中不同形式的耦合：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://medium.com/p/4d5cf2b3e99e&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;14. 内聚（Cohesion）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内聚是指模块内的元素依赖的程度。某种意义上说，是对类的方法和数据以及该类所服务的某种统一目的或概念之间关系强度的度量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;构建高内聚的类是一种最佳实践，有利于实现单一责任原则、松耦合等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;15. 接口隔离（Interface Segregation）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接口隔离原则指出，不应强迫客户端依赖不使用的方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;应该明确的是，这个原则主要适用于静态类型的编程语言，如Java、C等。在像Python或Ruby这样的动态类型语言中，这个原则没有太大意义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以想象这样一种情况，我们的Income和Expense用例都依赖于支持这两种用例的业务逻辑功能。因此Income用例的很多依赖都和Expense用例相关，而Expense用例的依赖情况也有相同的问题。基于以上讨论，ISP违规情况如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; az.alizeynalli.cashflow.core.service;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;interface&lt;/span&gt; &lt;span&gt;ConverterService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;Income &lt;span&gt;convertIncome&lt;/span&gt;&lt;span&gt;(Income income)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;Expense &lt;span&gt;convertExpense&lt;/span&gt;&lt;span&gt;(Expense expense)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;@Component&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ExpenseConverterServiceImpl&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;ConverterService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Income &lt;span&gt;convertIncome&lt;/span&gt;&lt;span&gt;(Income income)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; UnsupportedOperationException();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Expense &lt;span&gt;convertExpense&lt;/span&gt;&lt;span&gt;(Expense expense)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// convert expense here&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; expense;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;@Component&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;IncomeConverterServiceImpl&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;ConverterService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Income &lt;span&gt;convertIncome&lt;/span&gt;&lt;span&gt;(Income income)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// convert income here&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; income;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Expense &lt;span&gt;convertExpense&lt;/span&gt;&lt;span&gt;(Expense expense)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;br/&gt;        &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; UnsupportedOperationException();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;16. 限界上下文（Bounded Context）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;限界上下文是领域驱动设计的中心模式。通过将大型应用程序或组织分解为单独的概念模块，提供了一种处理复杂性的方法。每个概念模块代表一个上下文，该上下文与其他上下文分离（因此是有边界的），并且可以独立发展。理想情况下，每个限界上下文应该可以自由的为其中的概念选择自己的名称，并且应该独占的访问自己的持久化存储。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;17. 依赖稳定原则（Stable Dependencies）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一原则指出，软件系统的不同构建块应该只依赖于可靠、稳定的工件。这个原则在Docker镜像术语中更有意义，当我们从docker hub导入不同的依赖时，甚至不知道它们是否可靠/稳定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;18. 多态（Polymorphism）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这实际上属于面向对象编程的4大支柱，鼓励使用可以以多种形式提供的接口，多态性意味着具有多种形式的实体。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;19. 模块化（Modularization）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;模块化是将软件系统划分为多个独立模块的过程，每个模块独立工作。这一原则是应用于软件系统静态架构的单一职责分离原则的另一种形式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;20. 抽象（Abstraction）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这也属于面向对象编程的四大支柱:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在研究物体或系统时去除物理的、空间的或时间的细节或属性以集中注意力于更重要的部分，本质上与泛化过程相似。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;21. KISS（Keep It Simple, Stupid）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;按照字面意思理解，这一原则激励工程师保持代码简单和愚蠢（容易理解），避免他人误解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;22. 增量/迭代方法（Incremental/Iterative Approach）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一原则是敏捷软件开发宣言的基础，基于软件系统应该以增量和迭代的方式开发的思想，每一次迭代都会增加系统功能并保证其运行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;23. 最少知识原则（Least Knowledge）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或者叫信息嫉妒（information envying），是封装或信息隐藏原则的另一个术语，规定软件系统的不同部分应该只拥有需要的知识。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>