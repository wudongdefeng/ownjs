<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ce975edcc73243a6e697003d3283d3b1</guid>
<title>强化学习调参技巧（二）：DDPG、TD3、SAC 算法为例</title>
<link>https://toutiao.io/k/43k6p3s</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h1&gt;1.训练环境如何正确编写&lt;/h1&gt;

&lt;p&gt;强化学习里的 env.reset() env.step() 就是训练环境。其编写流程如下：&lt;/p&gt;

&lt;h2&gt;1.1 初始阶段：&lt;/h2&gt;

&lt;p&gt;先写一个简化版的训练环境。把任务难度降到最低，确保一定能正常训练。记录正常训练的智能体的分数，与随机动作、传统算法得到的分数做比较。
DRL算法的分数应该明显高于随机动作（随机执行动作）。DRL算法不应该低于传统算法的分数。如果没有传统算法，那么也需要自己写一个局部最优的算法&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;评估策略的性能:&lt;/strong&gt; 大部分情况下，可以直接是对Reward Function 给出的reward 进行求和得到的每轮收益episode return作为策略评分。有时候可以需要直接拿策略的实际分数作为评分
&lt;strong&gt;需要保证这个简化版的代码：高效、简洁、可拓展&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;1.2 改进阶段：&lt;/h2&gt;

&lt;p&gt;让任务难度逐步提高，对训练环境env 进行缓慢的修改，时刻保存旧版本的代码同步微调 Reward Function，可以直接代入自己的人类视角，为某些行为添加正负奖励。注意奖励的平衡（有正有负）。注意不要为Reward Function 添加太多额外规则，时常回过头取消一些规则，避免过度矫正。
 同步微调 DRL算法，只建议微调超参数，但不建议对算法核心进行修改。因为任务变困难了，所以需要调整超参数让训练变快。同时摸清楚在这个训练环境下，算法对&lt;strong&gt;哪几个超参数是敏感的&lt;/strong&gt;。有时候为了节省时间，甚至可以为 off-policy 算法保存一些典型的 trajectory（不建议在最终验证阶段使用）。
每一次修改，都需要跑一下记录不同方法的分数，确保：随机动作 &amp;lt; 传统方法 &amp;lt; DRL算法。这样才能及时发现代码逻辑上的错误。要极力避免代码中出现复数个的错误，因为极难排查。&lt;/p&gt;

&lt;h2&gt;1.3 收尾阶段：&lt;/h2&gt;

&lt;p&gt;尝试慢慢删掉Reward Function 中一些比较复杂的东西，删不掉就算了。
选择&lt;font&gt;&lt;strong&gt;高低两组超参数&lt;/strong&gt;&lt;/font&gt;再跑一次，确认没有优化空间。&lt;/p&gt;

&lt;h1&gt;2. 超参数解释分析&lt;/h1&gt;

&lt;h2&gt;2.1 off-policy算法中常见的超参数&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网络宽度：&lt;/strong&gt; network dimension number。DRL 全连接层的宽度（特征数量）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络层数：&lt;/strong&gt; network layer number。一个输入张量到输出需要乘上w的次数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;随机失活：&lt;/strong&gt; dropout&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批归一化&lt;/strong&gt;： batch normalization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;记忆容量：&lt;/strong&gt; 经验回放缓存 experimence replay buffer 的最大容量 max capacity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批次大小：&lt;/strong&gt; batch size。使用优化器更新时，每次更新使用的数据数量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更新次数&lt;/strong&gt;：update times。使用梯度下降更新网络的次数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;折扣因子：&lt;/strong&gt; discount factor、gamma&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;【网络宽度、网络层数】&lt;/strong&gt; 越复杂的函数就需要越大容量的神经网络去拟合。在需要训练1e6步的任务中，我一般选择 宽度&lt;strong&gt;128、256&lt;/strong&gt;，层数小于8的网络（请注意，乘以一个w算一层，一层LSTM等于2层）。使用ResNet等结构会有很小的提升。一般选择一个略微冗余的网络容量即可，把调整超参数的精力用在这上面不划算，我建议这些超参数都粗略地选择2的N次方，&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;因为：防止过度调参，超参数选择x+1 与 x-1并没有什么区别，但是 x与2x一定会有显著区别
2的N次方大小的数据，刚好能完整地放进CPU或GPU的硬件中进行计算，如Tensor Core
过大、过深的神经网络不适合DRL，
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;因为：深度学习可以在整个训练结束后再使用训练好的模型。
而强化学习需要在几秒钟的训练后马上使用刚训好的模型。
这导致DRL只能用比较浅的网络来保证快速拟合（10层以下）
并且强化学习的训练数据不如有监督学习那么稳定，无法划分出训练集测试集去避免过拟合，
因此DRL也不能用太宽的网络（超过1024），避免参数过度冗余导致过拟合
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;【dropout、批归一化】&lt;/strong&gt; 她们在DL中得到广泛地使用，可惜不适合DRL。如果非要用，那么也要选择非常小的 &lt;strong&gt;dropout rate（0~0.2）&lt;/strong&gt;，而且要注意在使用的时候关掉dropout。我不用dropout。&lt;/p&gt;

&lt;p&gt;好处：在数据不足的情况下缓解过拟合；像Noisy DQN那样去促进策略网络探索
坏处：影响DRL快速拟合的能力；略微增加训练时间&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【批归一化】&lt;/strong&gt; 经过大量实验，DRL绝对不能直接使用批归一化，如果非要用，那么就要修改Batch Normalization的动量项超参数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【记忆容量】&lt;/strong&gt; 经验回放缓存 experimence replay buffer 的最大容量 max capacity，如果超过容量限制，它就会删掉最早的记忆。在简单的任务中（训练步数小于1e6），对于探索能力强的DRL算法，通常在缓存被放满前就训练到收敛了，不需要删除任何记忆。然而，过大的记忆也会拖慢训练速度，我一般会先从默认值 2 ** 17 ~ 2 ** 20 开始尝试，如果环境的随机因素大，我会同步增加记忆容量 与 batch size、网络更新次数，直到逼近服务器的内存、显存上限（放在显存训练更快）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【批次大小、更新次数】&lt;/strong&gt; 一般我会选择与网络宽度相同、或略大的批次大小batch size。我一般从&lt;strong&gt;128、256&lt;/strong&gt; 开始尝试这些2的N次方。在off-policy中，每往Replay 更新几个数据，就对应地更新几次网络，这样做简单，但效果一般。（深度学习里）更优秀的更新方法是：根据Replay中数据数量，成比例地修改更新次数。Don&#x27;t Decay the Learning Rate, Increase the Batch Size. ICLR. 2018 。，经过验证，DRL也适用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【折扣因子】&lt;/strong&gt; discount factor、discount-rate parameter 或者叫 gamma 。0.99&lt;/p&gt;

&lt;h2&gt;2.2 on-policy算法中常见的超参数&lt;/h2&gt;

&lt;p&gt;同策略（A3C、PPO、PPO+GAE）与异策略（DQN、DDPG、TD3、SAC）的主要差异是：&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;【记忆容量】&lt;/strong&gt; on-policy 算法每轮更新后都需要删除“用过的数据”，所以on-policy的记忆容量应该大于等于【单轮更新的采样步数】，随机因素更多的任务需要更大的单层采样步数才能获得更多的 轨迹 trajectory，才能有足够的数据去表达环境与策略的互动关系。详见下面PPO算法的【单轮更新的采样步数】&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【批次大小】&lt;/strong&gt; on-policy 算法比off-policy更像深度学习，它可以采用稍大一点的学习率（2e-4）。因为【单轮更新的采样步数】更大，所以它也需要搭配更大的batch size（2&lt;strong&gt;9 ~ 2&lt;/strong&gt;12）。如果内存显存足够，我建议使用更大的batch size，我发现一些很难调的任务，在很大的batch size（2 ** 14） 面前更容易获得单调上升的学习曲线（训练慢但是及其稳定，多GPU分布式）。请自行取舍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【更新次数】&lt;/strong&gt; 一般我们不直接设置更新次数，而是通过【单轮更新的采样步数】、【批次大小】和【数据重用次数】一同算出【更新次数】，详见下面PPO算法的【数据重用次数】&lt;/p&gt;

&lt;h1&gt;3. TD3特有的超参数&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;探索噪声方差 exploration noise std&lt;/li&gt;
&lt;li&gt;策略噪声方差 policy noise std&lt;/li&gt;
&lt;li&gt;延迟更新频率 delay update frequency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果你擅长调参，那么可以可以考虑TD3算法。如果你的算法的&lt;strong&gt;最优策略通常是边界值&lt;/strong&gt;，那么你首选的算法就是TD3----&lt;font&gt;&lt;strong&gt;最佳策略总在动作边界&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【TD3的探索方式】&lt;/strong&gt; 让其很容易在探索「边界动作」：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;策略网络输出张量，经过激活函数 tanh 调整到 (-1, +1)&lt;/li&gt;
&lt;li&gt;为动作添加一个clip过的高斯噪声，噪声大小由人类指定&lt;/li&gt;
&lt;li&gt;对动作再进行一次clip操作，调整到 (-1， +1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;好处：&lt;/strong&gt; 一些任务的最优策略本就存在存在大量边界动作，TD3可以很快学得很快。
&lt;strong&gt;坏处：&lt;/strong&gt; 边界动作都是 -1或 +1，这会降低策略的多样性，网络需要在多样性好数据上训练才不容易过拟合。对于clip 到正负1之间的action，过大的噪声方差会产生大量边界动作 。
&lt;img src=&quot;https://s2.51cto.com/images/blog/202212/15135614_639ab6fea6da517014.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【探索噪声方差 exploration noise std】&lt;/strong&gt;  就是上图中的s。需要先尝试小的噪声方差（如0.05），然后逐渐加大。大的噪声方差刻意多探索边界值，特定任务下能让探索更快。&lt;strong&gt;且高噪声下训练出来的智能体更robust（稳健、耐操）&lt;/strong&gt;。
请注意：过大的噪声方差（大于上图蓝线的0.5）并不会让探索动作接近随机动作，而是让探索动作更接近单一的边界动作。此外，过大的噪声会影响智能体性能，导致她不容易探索到某些state。&lt;/p&gt;

&lt;p&gt;因此，合适的探索噪声方差只能慢慢试出来，TD3适合愿意调参的人使用。在做出错误动作后容易挽回的环境，可以直接尝试较大的噪声。
我们也可以模仿 epslion-Greedy，设置一个使用随机动作的概率，或者每间隔几步探索就不添加噪声，甚至也在TD3中使用探索衰减。这些操作都会增加超参数的数量，慎用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【策略噪声方差 policy noise std】&lt;/strong&gt; 确定了探索噪声后，策略噪声只需要比探索噪声稍大&lt;strong&gt;（1~2倍）&lt;/strong&gt;。TD3对策略噪声的解释是“计算Q值时，因为相似的动作的Q值也是相似的，所以TD3也为动作加一个噪声，这能使Q值函数更加光滑，提高训练稳定性 我们还能多使用几个添加噪声的动作，甚至使用加权重要性采样去算出更稳定的Q值期望。在确定策略梯度算法里的这种“在计算Q值时，为动作加noise的操作”，让TD3变得有点像随机策略梯度。无论是否有clip，策略噪声方差最大也不该超过0.5。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【延迟更新频率 delay update frequency】&lt;/strong&gt; TD3认为：引入目标网络进行 soft update 就是为了提高训练稳定性，那么既然 network 不够稳定，那么我们应该延迟更新目标网络 target network，即多更新几次 network，然后再更新一次target network。从这个想法再拓展出去，我们甚至可以模仿TTUR的思想做得更细致一点，针对双层优化问题我们能做：&lt;/p&gt;

&lt;p&gt;环境随机因素多，则需要尝试更大的延迟更新频率，可尝试的值有 1~8，默认值为2
提供策略梯度的critic可以多更新几次，再更新一次actor，可尝试的值有 1~4&amp;lt;&lt;/p&gt;

&lt;p&gt;提供策略梯度的critic可以设计更大的学习率，例如让critic的学习率是actor 的1~10倍&lt;/p&gt;

&lt;p&gt;由于critic 需要处理比 actor 更多的数据，因此建议让critic网络的宽度略大于actor&lt;/p&gt;

&lt;h1&gt;4. SAC特有的超参数&lt;/h1&gt;

&lt;p&gt;尽管下面列举了4个超参数，但是后三个超参数可以直接使用默认值（默认值只会有限地影响训练速度），第一个超参数甚至可以直接通过计算选择出来，不需要调整。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;reward scale 按比例调整奖励&lt;/li&gt;
&lt;li&gt;alpha 温度系数 或 target entropy 目标 策略熵&lt;/li&gt;
&lt;li&gt;learning rate of alpha 温度系数 alpha 的学习率&lt;/li&gt;
&lt;li&gt;initialization of alpha 温度系数 alpha 的初始值
SAC有极少的超参数，甚至这些超参数可以在训练开始前就凭经验确定。
&lt;img src=&quot;https://s2.51cto.com/images/blog/202212/15135614_639ab6fea92375198.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=&quot; alt=&quot;在这里插入图片描述&quot;/&gt;任何存在多个loss相加的目标函数，一定需要调整系数 lambda，例如SAC算法、共享了actor critic 网络的A3C或PPO，使用了辅助任务的PPG。我们需要确定好各个 lambda 的比例。SAC的第二篇论文加入了自动调整 温度系数 alpha 的机制，处于lambda2位置的温度alpha 已经用于自动调整策略熵了，所以我们只能修改lambda1。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;reward scaling 是指直接让reward 乘以一个常数k (reward scale)，在不破坏reward function 的前提下调整reward值，从而间接调整Q值到合适的大小。 修改reward scale，相当于修改lambda1，从而让可以让 reward项 和 entropy项 它们传递的梯度大小接近。与其他超参数不同，只要我们知晓训练环境的累计收益范围，我们就能在训练前，直接随意地选定一个reward scaling的值，让累计收益的范围落在 -1000~1000以内即可，不需要精细调整：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【温度系数、目标策略熵】&lt;/strong&gt;  Temperature parameters (alpha)、target &#x27;policy entropy&#x27;。SAC的第二篇论文加入了自动调整 温度系数 alpha 的机制：通过自动调整温度系数，做到让策略的熵维持在目标熵的附近（不让alpha过大而影响优化，也不让alpha过小而影响探索）&lt;/p&gt;

&lt;p&gt;策略熵的默认值是 动作的个数 的负log，详见SAC的第二篇论文 section 5 Automating Entropy Adjustment for Maximum Entropy 。SAC对这个超参数不敏感，一般不需要修改。有时候策略的熵太大将导致智能体无法探索到某些有优势的state，此时需要将目标熵调小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【温度系数 alpha 的学习率】&lt;/strong&gt; learning rate of alpha 温度系数alpha 最好使用 log 形式进行优化，因为alpha是表示倍数的正数。一般地，温度系数的学习率和网络参数的学习率保持一致（一般都是1e-4）。当环境随机因素过大，导致每个batch 算出来的策略熵 log_prob 不够稳定时，我们需要调小温度系数的学习率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;【温度系数 alpha 的初始值】&lt;/strong&gt; initialization of alpha 温度系数的初始值可以随便设置，只要初始值不过于离奇，它都可以被自动调整为合适的值。一般偷懒地将初始值设置为 log(0) 其实过大了，这会延长SAC的预热时间，我一般设置成更小的数值，详见 The alpha loss calculating of SAC is different from other repo · Issue #10 · Yonv1943/ElegantRL 。&lt;/p&gt;

&lt;h1&gt;5. 自己模型训练调参记录（TD3）&lt;/h1&gt;

&lt;h2&gt;5.1 模型环境参数&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;常规参数：&lt;/strong&gt;
| 无人机初始位置|用户初始位置  | 无人机覆盖半径(米)|最大关联数 |UAV飞行距离 |
|--|--|--|--|--|
| 【20，180】 |【20，180】  | 【75，100】|【20，30】 |【0，30】 |
&lt;strong&gt;时延记录:&lt;/strong&gt;
|前景（MB） | 0.125 |0.5 |1|1.25  |1.5 |
|--|--|--|--|--|--|
| 背景(MB) |0.5 | 2|4 | 5| 6|
| local(ms) |13 | 52|105| ---|150|
| UAV(ms) |47 | 29.4|39.7 | ---| 50.6|
| coop(ms) |44 | 29.6|38.2| ----| 47|
&lt;strong&gt;超参数：&lt;/strong&gt;
| ACTOR_LR |CRITIC_LR | BATCH_SIZE|GAMMA  |TAU  |
|--|--|--|--|--|
| 【1e-4 ，1e-5】 |【1e-3 ，1e-4】  | 【256，512】|0.99】 |0.005 |
| EXPL_NOISE|policy_noise | noise_clip| policy_freq |hid_size |
|0.1、0.05|0.2、0.1|0.5|【1，8】默认：2|【128，512】|&lt;/p&gt;

&lt;p&gt;目前采用组合有如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ACTOR_LR = 1e-4  # Actor网络的 learning rate 学习率  1e-3&lt;/li&gt;
&lt;li&gt;CRITIC_LR = 1e-3  # Critic网络的 learning rate   1e-3&lt;/li&gt;
&lt;li&gt;EXPL_NOISE = 0.05   # 动作噪声方差&lt;/li&gt;
&lt;li&gt;self.hid_size=256&lt;/li&gt;
&lt;li&gt;self.hid1_size=128

&lt;/li&gt;
&lt;li&gt;noise_clip=0.5,&lt;/li&gt;
&lt;li&gt; policy_freq=2&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;5.2 &lt;strong&gt;调参效果：&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;可以看到模型训练的稳定性和收敛效果越来越好，调多了你也就知道哪些超参数影响的大了&lt;/p&gt;

&lt;h2&gt;5.3 &lt;strong&gt;造成波动的原因，然后采用对应的解决方案：&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;如果在策略网络没有更新的情况下，Agent在环境中得到的分数差异过大。那么这是环境发生改变造成的：
-1. 每一轮训练都需要 env.reset()，然而，有时候重置环境会改变难度，这种情况下造成的波动无法消除。
-2. 有时候是因为DRL算法的泛化性不够好。此时我们需要调大相关参数增加探索，以训练出泛化性更好的策略。&lt;/li&gt;
&lt;li&gt;如果在策略网络没有更新的情况下，Agent在环境中得到的分数差异较小。等到更新后，相邻两次的分数差异很大。那么这是环境发生改变造成的： 1. 把 learning rate 调小一点。2. 有时候是因为算法过度鼓励探索而导致的，调小相关参数即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cebbddf68496432499aa07df9f7016ec</guid>
<title>最强开源 OLAP 数据库，你应该选择的 10 个理由</title>
<link>https://toutiao.io/k/h1z5lkl</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;col-md-10 col-sm-12&quot;&gt;
            &lt;h1&gt; 最强开源 OLAP 数据库，你应该选择的 10 个理由&lt;/h1&gt;
            &lt;hr/&gt;
            &lt;p&gt;作者: 康凯森&lt;/p&gt;
            &lt;p&gt;日期: 2022-12-13&lt;/p&gt;
            &lt;p&gt;分类: &lt;a href=&quot;../tag/OLAP.html&quot; target=&quot;_blank&quot;&gt;OLAP&lt;/a&gt;&lt;/p&gt;
            &lt;hr/&gt;
            


&lt;p&gt;2022 年即将结束，疫情持续了 3 年，StarRocks 也创立了快 3 年，今天就总结下 StarRocks 用户侧可以感知的十大 Fature 和 优化，也希望大家对 StarRocks 有一个更全面的认知。&lt;/p&gt;
&lt;h2 id=&quot;一-极速-olap&quot;&gt;一 极速 OLAP&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16688670975989.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图中是我们官网展示的 SSB 单表的查询性能对比，可以看到，相比业界其他优秀的 OLAP 数据库，我们 StarRcoks 在性能上有着明显的优势，不止是 SSB 单表查询，SSB 多表，TPC-H 查询，TPC-DS 等复杂的多表查询，我们同样拥有极致的性能。TPC-DS 查询在 100G 和 1T 规模下，StarRcoks 相比 Snowflake 有2到3倍的性能优势。&lt;/p&gt;
&lt;p&gt;极致的性能不仅可以带来更好的用户体验，让之前难以实现的需求可以实现，更重要的是，可以节省大量的机器，为企业降本增效。&lt;/p&gt;
&lt;p&gt;我们 StarRcoks 能拥有极致的 OLAP 分析性能，是因为2年多来，我们在以下几个方面做了大量持续深入的优化：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;MPP 分布式执行&lt;/strong&gt;：StarRocks 拥有 MPP 的分布式执行框架，保证了 StarRocks 可以充分发挥多机 scale out 的能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline 并行执行框架&lt;/strong&gt;：我们从零打造了 pipeline 并行框架，可以让  StarRocks 充分发挥多核 scale up 的能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;向量化执行&lt;/strong&gt;：我们从零打造了 StarRocks 的向量化执行引擎，让 StarRocks 单核可以拥有极致的执行性能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CBO 优化器&lt;/strong&gt;：通过 MPP 分布式执行， Pipeline 并行执行 和 向量化执行，我们拥有了世界领先的查询执行器，但是对于复杂的SQL，优化器产生的 Plan 好坏对查询性能影响更大，所以我们又从零打造了 CBO 优化器，让 StarRocks 对于复杂查询可以产生足够好的 Plan，进而对于复杂查询，StarRocks 也可以拥有极佳的查询性能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Global Runtime Filter&lt;/strong&gt; : Runtime Filter 对复杂的join 查询影响极大，开关 Runtime filter，可以有几十倍的查询，我们在 Global 和 Local Runtime Filter 上都做了挺多深度优化和创新&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全局低基数字典优化&lt;/strong&gt;：目前主要是可以优化包含低基数字符串的各类查询，整体会有2到3倍的性能提升，面向的场景主要是业务的维表中有大量的低基数字符串列。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对上面技术原理感兴趣的可以参考我们 StarRocks 官方微信公众号和 B 站的相关技术分享。&lt;/p&gt;
&lt;h2 id=&quot;二-极速数据湖分析&quot;&gt;二 极速数据湖分析&lt;/h2&gt;
&lt;p&gt;当我们拥有了一个极速的查询引擎，可以实现极速 Olap 分析后，一个自然而然的想法就是，我们是不是也可以直接查询 Apache Hive、Apache Iceberg 和 Apache Hudi 等开源数据湖或数据仓库的数据上呢？ 答案是 Yes ! 这样的一个巨大好处是用户省去了数据导入或者同步这个工作，对用户的易用性大大增强。&lt;/p&gt;
&lt;p&gt;所以从21年开始，我们就成立了专门的数据湖分析团队，致力于提供开箱即用的极速数据湖分析体验。一年多来，用户侧可以感知的优化和功能如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1 各种外部数据源接入更加简单&lt;/strong&gt;：开发了全新的 Connector 框架和 Catalog 机制，访问外部数据源变得很容易，只需要配置下 Catalog，就可以查询到对应 DB 下的所有表数据，而不是最初一张表一张表配置，极大提升了用户的易用性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16688650649458.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2 更加极致的性能&lt;/strong&gt;：除了查询引擎本身的持续性能提升，数据湖分析额外在 Scan 算子和外表元数据访问上做了大量优化，在有 Local Cache的情况下，外表查询性能可以媲美本地的 OLAP 表。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16679830144946.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;3 更加弹性&lt;/strong&gt;： 当 BE 不负责数据存储时，就变成了一个无状态的计算节点，弹性伸缩就变得十分自然和容易，而且数据湖分析大多属于 Adhoc 查询，查询范式不固定，相比与传统的 Olap 查询，更需要弹性伸缩的能力。所以我们就新增了一种新的节点：Compute Node —— 是将 BE 的存储功能移除，只保留计算模块。 并和 K8S 结合，做到了弹性伸缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16709203320364.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;4 更加安全&lt;/strong&gt;： 我们更好地支持了 Kerberos 认证，接入了云厂商托管的 IAM 服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;三-主键更新&quot;&gt;三 主键更新&lt;/h2&gt;
&lt;p&gt;过去两年来，我们从零实现了全新的 基于列存的 Delete-and-Insert 模式的主键更新模型，可以同时支持实时更新和极致的查询性能，在大规模实时数据写入的同时，查询性能可以做到其他行业领先 OLAP 数据库的 3-5 倍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16709237307812.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;两年来，我们的主键模型做了如下优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主键索引持久化：减少了主键索引的内存使用量，可以支持更大数据量的单表&lt;/li&gt;
&lt;li&gt;部分列更新：以现有的 Delete + Insert 模式为基础，通过读取老版本数据，来填充缺失列&lt;/li&gt;
&lt;li&gt;条件更新：当满足某个固定条件时才更新对应行，否则就不更新&lt;/li&gt;
&lt;li&gt;高频导入优化：对 Publish version 过程，compaction 过程，合并事务数等优化&lt;/li&gt;
&lt;li&gt;Update 和 Delete 语句支持复杂表达式和子查询&lt;/li&gt;
&lt;li&gt;主键和排序键分离&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实时化是整个数据分析的大趋势，而更新的需求也越来越多，有了 StarRocks 优秀的主键模型，你可以更好的支持下面的业务场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CDC 实时同步 TP 数据到 StarRocks 中，这也是使用最广泛的场景&lt;/li&gt;
&lt;li&gt;数据处理范式从 ETL 变成 ELT，也需要强大的更新能力&lt;/li&gt;
&lt;li&gt;实时流中通过多表 Join 更新数据的场景，有了 Partial-Update，就可以代替部分多表 Join 的需求&lt;/li&gt;
&lt;li&gt;根据某个时间戳进行条件更新&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;四-资源隔离&quot;&gt;四 资源隔离&lt;/h2&gt;
&lt;p&gt;在生产环境中，大家一般都会遇到大查询的问题： 几个大查询吃满了整个集群的资源，影响了正常的小查询，大查询很难及时熔断和定位。 针对大查询的问题，我们从 2.3 版本开始，基于 Pipeline 执行引擎，实现了资源隔离。 目前 StarRocks 支持了内存资源的硬隔离，CPU 和 IO 资源的软隔离。&lt;/p&gt;
&lt;p&gt;我们引入了 Work Group 的概念，每个 Work Group 可以配置使用的 CPU 和 IO 比例，我们通过两级队列调度和类型 Linux CFS 调度的算法基本保证了每个 Work Group在查询运行时，使用的资源可以符合配置的比例。&lt;/p&gt;
&lt;p&gt;同时为了提高资源的利用率，在集群资源空闲时，每个 work group 可以使用到更多资源，对集群资源的利用率和隔离性进行了兼顾。&lt;/p&gt;
&lt;p&gt;对一些高优业务，用户可能期望隔离性更高，我们也支持了短查询 Work Group 的 CPU 硬隔离，任何情况下，其对应的 CPU 资源都不会被占用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/16709327441519.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;五-物化视图&quot;&gt;五 物化视图&lt;/h2&gt;
&lt;p&gt;StarRocks 第一版的物化视图是从 Rollup 转换而来，只能用来透明加速查询，不能显示直接查询某个物化视图，也就是说物化视图只有物化的语义，没有视图的语义。&lt;/p&gt;
&lt;p&gt;我们物化视图 2.0 版本进行了5方面的加强：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;让物化视图可以直接被查询&lt;/strong&gt;：将物化视图也视为一张表，这样在复杂的 ELT 或者 ELT 的数据处理过程中，就可以使用物化视图来简化 SQL&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在数据建模场景下，支持任意复杂的SQL&lt;/strong&gt;：也就是说，物化视图里面可以定义任意复杂的SQL，但是不保证每个物化视图都支持透明的查询改写加速&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在透明加速场景下，支持更复杂的SQL:&lt;/strong&gt; 目前 StarRocks 已经可以支持 Aggregate, Join, Filter, Union 等复杂查询的物化视图透明改写&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持对数据湖上的数据建立物化视图&lt;/strong&gt;：对数据湖上的近期热点数据利用物化视图进行强有力的透明加速&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;物化视图支持异步刷新和自动刷新&lt;/strong&gt;：让物化视图的创建过程和刷新过程更加简单&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 StarRocks 3.0 中，物化视图将会有一个质变，成为 StarRocks 的 Killer Feature，大家敬请期待。&lt;/p&gt;
&lt;h2 id=&quot;六-tablet-level-query-cache&quot;&gt;六 Tablet Level Query Cache&lt;/h2&gt;
&lt;p&gt;在实时报表分析和时序查询中，大家经常会遇到分析最近某几天的数据，或者分析今天从零点一直到现在的数据这种场景，在这类查询中，最近某几天的分区 或者 最近某几个小时的数据可能被高频查询到，这种场景很适合 Query Cache 发挥作用，StarRocks 是基于 Tablet 粒度实现的 Query Cache，具有以下亮点：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16679811340710/44ebdb2c-950e-400f-8b68-aca5e7c8aa76.png&quot; alt=&quot;44ebdb2c-950e-400f-8b68-aca5e7c8aa76&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cache 命中率高&lt;/strong&gt; ：因为 Cache 粒度是 Tablet 粒度，比较细，不是整个查询结果集，或者某个分区的查询结果集，Cache 命中率理论上会更高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;支持多版本&lt;/strong&gt;：支持多版本有多个好处，首先是可以支持高频实时导入，因为 tablet 旧版本的对应的 Cache 内容可以复用，只需要旧版本的 Cache 结果和新版本的增量结果合并即可&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;支持 Join 等多表复杂查询的结果集Cache&lt;/strong&gt;：不像大多数系统只能支持单表查询的 Query Cache.&lt;/p&gt;
&lt;p&gt;StarRocks 的 Query Cache 已经在 2.5 版本发布，欢迎大家使用。&lt;/p&gt;
&lt;h2 id=&quot;七-半结构化数据分析&quot;&gt;七 半结构化数据分析&lt;/h2&gt;
&lt;p&gt;过去两年来，StarRocks 在持续完善半结构化数据分析能力：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持了 Array, Map, Struct, Json 数据类型&lt;/li&gt;
&lt;li&gt;支持了大量 Array, Map, Struct, Json 相关函数&lt;/li&gt;
&lt;li&gt;支持了 Lateral Join 和 Unnest Table Function，详情可以参考 &lt;a href=&quot;https://docs.starrocks.io/zh-cn/latest/using_starrocks/Lateral_join&quot;&gt;https://docs.starrocks.io/zh-cn/latest/using_starrocks/Lateral_join&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;支持了 Lambda 函数，  详情可以参考 StarRocks Lambda 函数用户文档&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有了这些基础能力，你可以用 StarRocks 做一些更强大的事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;StarRocks 可以更好地支持用户行为分析（留存及漏斗分析，路径分析等）&lt;/li&gt;
&lt;li&gt;StarRocks 可以更好地支持 Parquet, ORC 等文件导入和分析&lt;/li&gt;
&lt;li&gt;支持 Map 和 Json 类型可以让 StarRocks 更容易进行 Schema 变更&lt;/li&gt;
&lt;li&gt;支持 Json 类型让 StarRocks 对日志分析，事件分析等场景支持更加友好&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;StarRocks 明年也会持续在半结构化数据分析上发力。&lt;/p&gt;
&lt;h2 id=&quot;八-查询并行度自适应&quot;&gt;八 查询并行度自适应&lt;/h2&gt;
&lt;p&gt;StarRocks 的查询一开始是 Fragment 并行机制，将每个查询的并行度设置交给了用户，但是这个具体的并行度值用户很难设置，简单查询串行执行时并行度高点性能会好，但是高并发时，并行度高性能反而会更差，因为旧版的执行框架，是每个 fragment 一个执行线程，fragment 数越多，执行线程会更多，线程切换和竞争的开销会更大。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，StarRocks 一年多来分三步走解决了这个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;实现 Pipeline 并行引擎&lt;/strong&gt;：将执行线程数固定成 CPU 核数，查询默认的并行度改成核数的一半，用户不需要再关心并行度的设置，但是还存在一些优化空间&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;单 Tablet 内部并行&lt;/strong&gt;：支持单个 Tablet 可以并行查询，将查询的并行度和 Tablet 数解耦，解决了 Tablet 数较少时无法设置更高并行度的问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;查询并行度自适应（下个版本支持）&lt;/strong&gt;: 根据不同的集群复杂和查询类型，自动设置最合理的并行度。默认并行度设置成为核数，当数据量比较少时 或者 集群负载比较高时，自动减少并行度；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过这三步，当你在 StarRocks 时就再也不用自己操心查询并发度的设置了，无论是 Benchmark 场景，还是高并发场景，无论是复杂的大查询，还是简单的小查询，StarRocks 都会自动为你提供&lt;strong&gt;开箱即用的极致性能体验&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;九-云原生存储分离&quot;&gt;九 云原生存储分离&lt;/h2&gt;
&lt;p&gt;大家都知道，Cloud Native 是大势所趋，而要支持 Cloud Native，StarRocks 就必须从之前的 Shared-Nothing 架构转向存算分离架构。从 21 年初，StarRocks 就组建了专门的 Cloud 团队全力打造全新的存算分离架构，历经我们 Cloud 团队长达两年的设计和研发，存算分离的 StarRocks 第一版已经开发测试完成，目前已经交付部分用户进行试用测试，有想提前尝鲜的用户也欢迎联系我们。&lt;/p&gt;
&lt;p&gt;如上图所示（由于官方还未公开过图，我就不放了，大家可以根据 《Data-Parallel Actors：千行代码构建高性能 OLAP 数据库》一文中的描述脑补下），是我们 StarRocks 新一代的全新架构，我们新一代存算分离架构的核心是 StarOS, StarOS 一个极具野心的项目，简单来说，StarOS 会对分布式相关逻辑进行抽象和统一，对云上存储进行抽象和统一，让我们未来打造一个存算分离服务变得十分简单。 具体的技术内幕大家可以期待我们 Cloud 团队同学之后的深度分享。&lt;/p&gt;
&lt;p&gt;那么从用户视角来看，我们全新的存算分离架构会提供什么独特的优势呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在可以弹性伸缩的同时，可以提供媲美 Shared-Nothing 架构的性能&lt;/li&gt;
&lt;li&gt;依靠 StarOS, 同时支持云上部署和本地部署&lt;/li&gt;
&lt;li&gt;实时更新能力&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然，普遍存储架构的优点我们已经或即将具备：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;极致弹性&lt;/li&gt;
&lt;li&gt;更低成本&lt;/li&gt;
&lt;li&gt;多租户&lt;/li&gt;
&lt;li&gt;读写分离&lt;/li&gt;
&lt;li&gt;Serverless&lt;/li&gt;
&lt;li&gt;。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;十-saas-byoc&quot;&gt;十 SAAS BYOC&lt;/h2&gt;
&lt;p&gt;所谓云原生的存算分离，我们除了存储分离的内核，还需要在云上将数据库服务化，所以在一边打造存算分离内核的同时，我们也成立了一个专门的团队在打造 SAAS 服务，我们目前已经推出了 BYOC 的 SASS 模式。 BYOC 是 bring-your-own-cloud 的缩写，也就是&lt;strong&gt;使用用户自己的云，这样会有更好的数据隐私，更好的安全性&lt;/strong&gt;。如图所示（由于官方还未公开过图，我就不放了），整个架构分为控制面板和数据面板，控制面板在 StarRocks 的 VPC， 数据面板在用户的 VPC，目前已经有多个用户在正式使用。&lt;/p&gt;
&lt;p&gt;我们即将迎来2023年，在新的一年里， StarRocks 会带来更多的 Killer Feature，也会大力提升稳定性和易用性，努力让 StarRocks 成为最受欢迎的 OLAP 数据库。&lt;/p&gt;

            &lt;hr/&gt;
            &lt;h3&gt;欢迎来知识星球和我交流&lt;/h3&gt;
            
        &lt;/div&gt;
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9f79bc780e22524d5af8f1b0ae03c23c</guid>
<title>如何用 Java 实现一致性 hash 算法 (consistent hashing)（上）</title>
<link>https://toutiao.io/k/zcezqpo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;article_content&quot; class=&quot;article_content clearfix&quot;&gt;
        
        
                &lt;div id=&quot;content_views&quot; class=&quot;markdown_views prism-tomorrow-night&quot;&gt;
                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
                        &lt;path stroke-linecap=&quot;round&quot; d=&quot;M5,0 0,2.5 5,5z&quot; id=&quot;raphael-marker-block&quot;/&gt;
                    &lt;/svg&gt;
                    &lt;h3&gt;&lt;a id=&quot;hash_0&quot;/&gt;一致性hash的历史&lt;/h3&gt; 
&lt;p&gt;【Consistent Hashing算法】早在 1997 年就在论文 Consistent hashing and random trees 中被提出，目前在 cache 系统中应用越来越广泛；&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;hash_4&quot;/&gt;一致性hash的目的&lt;/h3&gt; 
&lt;p&gt;一致性哈希算法是分布式系统中常用的算法，一致性哈希算法解决了普通余数Hash算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_8&quot;/&gt;问题背景&lt;/h3&gt; 
&lt;p&gt;业务开发中，我们常把数据持久化到数据库中，如果需要读取这些数据，除了直接从数据库中读取外，为了减轻数据库的访问压力以及提高访问速度，更多地引入缓存来对数据进行存取。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_12&quot;/&gt;分布式缓存&lt;/h3&gt; 
&lt;p&gt;分布式缓存，不同机器上存储不同对象的数据。为了实现这些缓存机器的负载均衡，一般就会存在两种Hash算法进行均匀分配数据节点存储：普通Hash算法&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;Hash_16&quot;/&gt;普通的Hash算法的&lt;/h3&gt; 
&lt;h4&gt;&lt;a id=&quot;Hash_18&quot;/&gt;Hash取模做法的缺陷&lt;/h4&gt; 
&lt;p&gt;一个Redis集群中，如果我们把一条数据经过Hash，然后再根据集群节点数取模得出应该放在哪个节点，这种做法的缺陷在于：扩容(增加一个节点)之后，有大量缓存失效。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;Hash_22&quot;/&gt;普通Hash的案例分析&lt;/h4&gt; 
&lt;p&gt;比如你有 N 个 cache 服务器（后面简称 cache ），那么如何将一个对象 object 映射到 N 个 cache 上呢，你很可能会采用类似下面的通用方法计算 object 的 hash 值，然后均匀的映射到到 N 个 cache ；&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;hash(object)%N 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;一切都运行正常，再考虑如下的两种情况；&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;一个 cache 服务器 m down 掉了（在实际应用中必须要考虑这种情况），这样所有映射到 cache m 的对象都会失效，怎么办，需要把 cache m 从 cache 中移除，这时候 cache 是 N-1 台，映射公式变成了 hash(object)%(N-1) ；&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;由于访问加重，需要添加 cache ，这时候 cache 是 N+1 台，映射公式变成了 hash(object)%(N+1) ；&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;这意味着突然之间几乎所有的 cache 都失效了。对于服务器而言，这是一场灾难，洪水般的访问都会直接冲向后台服务器；（造成缓存雪崩机制）&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/630daeb47f55c834998ff223edd3b962.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;Hash_40&quot;/&gt;一致性Hash算法&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;一致性hash算法正是为了解决此类问题的方法，它可以保证当机器增加或者减少时，对缓存访问命中的概率影响减至很小。下面我们来详细说一下一致性hash算法的具体过程。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;一致性hash算法通过一个叫作一致性hash环的数据结构实现。这个环的起点是0，终点是2^32 - 1，并且起点与终点连接，环的中间的整数按逆时针分布，故这个环的整数分布范围是[0, 2^32-1]&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;整个哈希值空间组织成一个虚拟的圆环，将节点的IP地址或主机名作为关键字进行哈希计算，得出的结果作为节点在环上的位置。数据经过hash后按顺时针方向找到最近一个节点存放，如图data的hash位置，应该存放在node2。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/5c52e347ec775107e3ff9a8a3f4b05c3.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
 
&lt;h3&gt;&lt;a id=&quot;Hash_54&quot;/&gt;改良版一致性Hash算法&lt;/h3&gt; 
&lt;h4&gt;&lt;a id=&quot;Hash___56&quot;/&gt;一致性Hash算法 + 虚拟节点&lt;/h4&gt; 
&lt;p&gt;为了解决数据分布不均的问题，我们引入虚拟节点的概念。我们对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。定位到虚拟节点的数据就存到该虚拟节点对应的真实节点上，这样数据分布就相对均匀了，虚拟节点数越多，分布越均匀。&lt;/p&gt; 
&lt;p&gt;引入“虚拟节点”后，映射关系就从 { 对象 -&amp;gt; 节点 } 转换到了 { 对象 -&amp;gt; 虚拟节点 } 。查询物体所在 cache 时的映射关系&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/e8220e34bd5e99215199ec5828271951.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;一般虚拟节点数32个以上，dubbo是160个。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/7dec7ba4b09e633d77c6684220b032e4.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_68&quot;/&gt;处理机器增减的情况&lt;/h4&gt; 
&lt;p&gt;对于线上的业务，增加或者减少一台机器的部署是常有的事情。&lt;/p&gt; 
&lt;p&gt;例如，增加机器c4的部署并将机器c4加入到hash环的机器c3与c2之间。这时，只有机器c3与c4之间的对象需要重新分配新的机器。对于我们的例子，只有对象o4被重新分配到了c4，其他对象仍在原有机器上。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;Hash_75&quot;/&gt;一致性Hash算法的实现原理&lt;/h3&gt; 
&lt;p&gt;在业务开发中，我们常把数据持久化到数据库中。如果需要读取这些数据，除了直接从数据库中读取外，为了减轻数据库的访问压力以及提高访问速度，我们更多地引入缓存来对数据进行存取。读取数据的过程一般为：&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;JavaHash_79&quot;/&gt;Java代码实现Hash算法的实现&lt;/h3&gt; 
&lt;p&gt;用一个TreeMap来作为环，key为虚拟节点下标，value为真实节点的hash。个人感觉可以加一个Map&amp;lt;T, Set&amp;gt;来维护真实节点-虚拟节点的关系。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;prism language-java&quot;&gt;
&lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ConsistentHash&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Serializable&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;long&lt;/span&gt; serialVersionUID &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1L&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    
    &lt;span class=&quot;token class-name&quot;&gt;Hash32&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    &lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;SortedMap&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; circle &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;TreeMap&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    
    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ConsistentHash&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;numberOfReplicas &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;hashFunc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; key &lt;span class=&quot;token operator&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            
            &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;HashUtil&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;fnvHash&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;key&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node &lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ConsistentHash&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Hash32&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;numberOfReplicas &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;hashFunc &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node &lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; nodes&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hashFunc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;hash32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; node&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numberOfReplicas&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hashFunc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;hash32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;node&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    
    &lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Object&lt;/span&gt; key&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; hash &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; hashFunc&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;hash32&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;key&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;containsKey&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hash&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;token class-name&quot;&gt;SortedMap&lt;/span&gt;&lt;span class=&quot;token generics&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token class-name&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt; tailMap &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;tailMap&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hash&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;   
            hash &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; tailMap&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;?&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;firstKey&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt; tailMap&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;firstKey&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        
        &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; circle&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;hash&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
                &lt;/div&gt;
                
                
        &lt;/div&gt;
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ceab79e45e658c44af1afa7f7c7b7063</guid>
<title>Go 编程语言与环境：万字长文复盘导致 Go 语言成功的那些设计决策（译）</title>
<link>https://toutiao.io/k/ffc9tj1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post-content&quot;&gt;&amp;#13;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-1.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://tonybai.com/2022/05/04/the-paper-of-go-programming-language-and-environment&quot;&gt;本文永久链接&lt;/a&gt; – https://tonybai.com/2022/05/04/the-paper-of-go-programming-language-and-environment&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cacm.acm.org/&quot;&gt;美国计算机学会通讯(Communications of the ACM)&lt;/a&gt;期刊2022年5月第65卷第5期将发表一篇有关Go语言的综述类Paper：&lt;a href=&quot;https://cacm.acm.org//magazines/2022/5/260357-the-go-programming-language-and-environment/fulltext&quot;&gt;《Go编程语言与环境》&lt;/a&gt;，这类综述类文章只有资深的Go核心团队的人才“有资格”写，该文的作者列表印证了这一点，他们是Russ Cox，Robert Griesemer，Rob Pike，Ian Lance Taylor和Ken Thompson，都是Go语言核心团队耳闻能详的人物。&lt;/p&gt;
&lt;p&gt;这篇文章是&lt;strong&gt;Go核心团队对10多年来Go演化发展的复盘&lt;/strong&gt;，深入分析了那些对Go的成功最具决定性的设计哲学与决策，个人觉得这是Go诞生十多年来最重要的一篇文章。所以我建议Gopher们都能认真读一遍或几遍这篇文章。这里将其翻译为中文，方便大家enjoy it。&lt;/p&gt;
&lt;p&gt;原文pdf版在&lt;a href=&quot;https://cacm.acm.org/magazines/2022/5/260357-the-go-programming-language-and-environment/pdf&quot;&gt;这里&lt;/a&gt;可以下载。&lt;/p&gt;
&lt;hr/&gt;
&lt;blockquote&gt;
&lt;p&gt;Go是一种编程语言，于2007年底在Google(谷歌)创建，并在2009年11月作为以开放源代码形式发布。从那时起，它就一直被作为一个公共项目运作，有成千上万的个人和几十家公司为Go项目做出过贡献。Go已经成为构建云计算基础设施的一种流行语言。&lt;a href=&quot;https://tonybai.com/tag/docker&quot;&gt;Docker（一种Linux容器管理器）&lt;/a&gt;和&lt;a href=&quot;https://tonybai.com/tag/kubernetes&quot;&gt;Kubernetes（一种容器部署系统）&lt;/a&gt;都是用Go编写的核心云技术。今天，Go是每个主要的云供应商的关键基础设施的基础，&lt;a href=&quot;https://www.cncf.io&quot;&gt;云原生计算基金会(CNCF)&lt;/a&gt;托管孵化的大多数项目都是Go语言实现的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-3.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;主要见解(key insights)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Go语言尽管没有什么技术上的突出进步，但却有着广泛的应用。并且，Go的成功在于专注于工程软件项目的整体环境。&lt;/li&gt;
&lt;li&gt;Go的做法是不会将语言特性视为比环境特性更重要，例如：谨慎处理依赖关系(译注：尤指最小版本选择MVS)、可规模化(scale)的开发和生产、默认安全的程序、工具辅助的测试和开发、对自动化修改的适应性以及&lt;a href=&quot;https://go.dev/doc/go1compat&quot;&gt;长期保证的兼容性&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tonybai.com/2022/04/20/some-changes-in-go-1-18&quot;&gt;Go 1.18于2022年3月发布&lt;/a&gt;，增加了十年来第一个重要的新语言特性：参数化多态性，经裁剪后可以很好地适应Go语言的其他部分(译注：仍然可以保持向后兼容，满足Go1兼容性承诺)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-2.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;引子&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;早期用户被Go所吸引的原因有很多&lt;/strong&gt;。首先，一种支持&lt;a href=&quot;https://tonybai.com/2020/03/10/visualizing-memory-management-in-golang/&quot;&gt;垃圾回收&lt;/a&gt;、静态编译的系统级编程语言，其本身就是不寻常的。其次，Go对&lt;a href=&quot;https://tonybai.com/2015/06/23/concurrency-and-parallelism/&quot;&gt;并发(concurrency)和并行(parallelism)&lt;/a&gt;的原生支持有助于利用当时正在成为主流的多核机器的优势。再次，自包含的二进制文件(译注：无需依赖目标主机上的C运行库和其他系统库)和简单的&lt;a href=&quot;https://tonybai.com/2014/10/20/cross-compilation-with-golang/&quot;&gt;交叉编译&lt;/a&gt;简化了部署。最后，&lt;a href=&quot;https://tonybai.com/2012/10/08/the-new-age-of-programming-language/&quot;&gt;谷歌的名字无疑也是一个亮点&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;但为什么用户会留存下来呢？为什么Go可以越来越流行、越来越受欢迎而同期的其他语言项目却没有呢？我们相信，语言本身只是答案的一小部分。&lt;strong&gt;完整的故事(答案)必须涉及整个Go环境：库、工具、惯例和针对软件工程的整体做法&lt;/strong&gt;，它们都对使用Go语言编程提供了支持。我们在语言设计中做出的最重要的决定，就是使Go更适合大规模软件工程，并帮助我们吸引志同道合的开发者。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我们研究了我们认为对Go的成功最具决定性的那些设计决策，探讨了它们不仅适用于语言，而且适用于更广泛的环境的原因。然而，要分离并量化出某个具体设计决策的贡献度是很困难的，所以这篇文章不应该被理解为科学分析，而应该被理解为&lt;strong&gt;基于Go过去十年的经验和用户反馈的最佳理解的呈现&lt;/strong&gt;。&lt;/p&gt;
&lt;h3&gt;起源(Origins)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Go是在Google建立大规模分布式系统的经验中产生的&lt;/strong&gt;，在一个由成千上万的软件工程师共享的大型代码库中工作。我们希望为这种环境设计的语言和工具能够解决公司和整个行业所面临的挑战。由于开发工作和正在部署的生产系统的规模都很大，挑战因此出现了!&lt;/p&gt;
&lt;h4&gt;开发规模(Development scale)&lt;/h4&gt;
&lt;p&gt;在开发方面，谷歌在2007年有大约4000名活跃的用户在一个单一的、共享的、多语言（C++、Java、Python）的代码库中工作。单一的代码库使问题很容易修复，例如，使主网络服务器变慢的内存分配器中的问题。但是在开发一个库的时候，由于很难找到一个包的所有依赖关系，所以很容易在不知不觉中破坏了这个库的一个以前未知的用户。&lt;/p&gt;
&lt;p&gt;另外，在我们使用的现有语言中，导入一个库可能导致编译器递归加载所有导入的库。在2007年的一次C++编译中，我们观察到编译器（在#include预处理后）在编译一组总共4.2MB的文件时，居然读取了超过8GB的数据，在一个已经很大的程序上，扩展系数几乎达到2000。如果为编译一个给定的源文件而读取的头文件的数量随着源代码树线性增长，那么整个源树的编译成本就会呈现指数级增长。&lt;/p&gt;
&lt;p&gt;为了弥补速度的减慢，我们开始研究一个新的、大规模并行和可缓存的编译系统，它最终成为开源的Bazel编译系统。但是并行性和缓存对于修复低效的系统只能起到这么大的作用了，我们相信语言本身可以做更多的事情来为编译大型程序提供帮助。&lt;/p&gt;
&lt;h4&gt;生产规模(Production scale)&lt;/h4&gt;
&lt;p&gt;在生产方面，谷歌正在运行非常大的系统。例如，2005年3月，一个1500颗CPU的Sawzall日志分析系统集群处理了2.8PB的数据。2006年8月，谷歌的388个大表服务集群由24500个独立的tablet服务器组成，其中一组8069个服务器每秒处理了120万个请求。&lt;/p&gt;
&lt;p&gt;然而，谷歌和业界其他公司一样，都在努力编写高效的程序，以充分利用多核系统的优势。我们的许多系统不得不在一台机器上运行同一个二进制文件的多个副本，因为现有的多线程支持既笨重又低性能。庞大的、固定大小的线程栈，重量级的栈开关，以及用于创建新线程和管理它们之间交互的笨拙语法，都使得使用多核系统变得更加困难。但很明显，服务器中的cpu核数量只会越来越多。&lt;/p&gt;
&lt;p&gt;在这里，我们也相信语言本身可以通过提供轻量级的、易于使用的并发性原语来提供帮助。我们还在这些额外的cpu核中看到了一个机会：垃圾收集器可以在一个专用的核上与主程序并行运行，减少其延迟成本。&lt;/p&gt;
&lt;p&gt;为应对这些挑战而设计的编程语言可能是什么样子的呢？Go就是我们针对这一问题的回答。Go之所以受欢迎，部分原因无疑是整个科技行业现在每天都面临这些挑战。云计算供应商使最小的公司也有可能进行非常大的生产部署。虽然大多数公司没有成千上万的员工在写代码，但现在几乎所有的公司都依赖于由成千上万的程序员贡献的大量开源基础设施。&lt;/p&gt;
&lt;p&gt;本文的后续部分将研究具体的设计决策是如何解决这些开发和生产的规模化问题的。我们从语言核心本身开始，向外扩展到周围的环境。&lt;strong&gt;我们并不试图对该语言进行完整的介绍&lt;/strong&gt;。要想全面详细了解Go语言，请参见&lt;a href=&quot;https://go.dev/ref/spec&quot;&gt;Go语言规范&lt;/a&gt;或&lt;a href=&quot;http://www.gopl.io&quot;&gt;《Go程序设计语言》&lt;/a&gt;等书籍。&lt;/p&gt;
&lt;h3&gt;包(Packages)&lt;/h3&gt;
&lt;p&gt;一个Go程序是由一个或多个可导入的包组成的，每个包包含一个或多个文件。图1中的网络服务器说明了关于Go的包系统设计的许多重要细节。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-4.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;&lt;center&gt;图1：Go Web服务器&lt;/center&gt;
&lt;p&gt;该程序启动了一个本地网络服务器（第9行），它通过调用hello函数来处理每个请求，hello函数用消息”hello, world”（第14行）作为响应。&lt;/p&gt;
&lt;p&gt;一个包使用显式的import语句导入另一个包（第3-6行），这与许多语言一样，但与C++的#include机制相反。不过，与大多数语言不同的是，Go安排每个导入语句只读取一个文件(译注：仅会读取依赖包对应的.a文件，以fmt为例，读取的是fmt.a)。例如，fmt包的公共API引用了io包的类型：fmt.Fprintf的第一个参数是io.Writer类型的接口值。在大多数语言中，编译器处理fmt包的导入时，也都会加载所有io的符号来满足fmt包的需要，这可能又需要加载额外的包来满足所有io包中符号的需要。依此类推，一条导入语句可能最终要加载并处理几十个甚至几百个包。&lt;/p&gt;
&lt;p&gt;Go通过采用与Modula-2语言类似的做法，即：使编译后的fmt包的元数据包含了了解其自身依赖关系所需的一切，例如io.Writer的定义，从而避免了上述这种问题。因此，编译import “fmt”语句时只需读取一个完全描述fmt及其依赖关系的文件(译注：这个文件指fmt.a)。 此外，这种“扁平化”处理是在编译fmt包时一次完成的，避免了每次导入时的多次加载。这种方法使编译器的工作更少，构建速度更快，有助于大规模开发。同时，包的导入循环是不允许的：&lt;strong&gt;即如果fmt包导入了io包，那么io包就不能导入fmt包，也不能导入任何其他导入fmt的包，即使是间接的导入&lt;/strong&gt;。这也使得编译器工作进一步减少，保证了一个特定的构建可以被分割为多个单独的包的编译。这也使得增量程序分析成为可能，我们甚至可以在运行测试之前就运行这种分析来捕捉错误。&lt;/p&gt;
&lt;p&gt;一个包导入fmt包并不能使io.Writer这个名字对当前这个包可用。如果main包想使用io.Writer这个类型，它必须自己使用import “io”语句导入io包。因此，一旦所有使用fmt限定名称的引用被从源文件中删除– 例如，如果上面例子中fmt.Fprintf的调用被删除，import “fmt”语句就可以安全地从源文件中删除，而无需做进一步分析。这个属性使得自动管理源代码中的导入语句成为可能。事实上，Go不允许未使用的导入，以避免将未使用的代码链接到程序中而产生的可执行文件膨胀。&lt;/p&gt;
&lt;p&gt;导入路径是带引号的字符串字面值，这使其解释具有灵活性。一个斜线分隔的路径在import语句中标识了导入的包，但随后源代码使用包声明语句中声明的短标识符来引用包。例如，import “net/http”提供了包的路径，但我们却使用其顶层名称http对其内容进行访问。在标准库之外，包由以域名开头的类似URL的路径来识别，如import “github.com/google/uuid”。我们将在后面对这类包进行更多的介绍。&lt;/p&gt;
&lt;p&gt;关于包的最后一个细节，请大家注意fmt.Fprintf和io.Writer这两个名字中的大写字母。Go使用一种&lt;strong&gt;命名惯例&lt;/strong&gt;来对C++和Java的public、private和protected概念和关键字进行模拟。首字母为大写字母的名字，如Printf和Writer，是”导出的”（公共的），其他的则不是。基于首字母大小写的、编译器强制执行的导出规则适用于常量、函数和类型等包级标识符；以及方法名和结构字字段名。我们采用这一规则是为了避免在公共API中涉及的每一个标识符旁边都写上一个像export这样的关键字的语法负担。 随着时间的推移，我们已经开始看重这种可以查看标识符是否在包之外可用或仅在内部使用的能力。&lt;/p&gt;
&lt;h3&gt;类型(Types)&lt;/h3&gt;
&lt;p&gt;Go提供了一套常见的基本类型：布尔(bool)，定长整型，如uint8和int32，非定长整型int和uint（32或64位，取决于机器大小），以及定长浮点类型(float32和float64)和复数类型(complex64和complex128)。Go还类似C语言那样提供了指针、固定大小的数组和结构体类型。Go还提供了一个内置的字符串类型(string)，一个被称为map类型的哈希表，以及称为slice类型的动态大小的数组。大多数Go程序都依赖于这些类型，Go没有其他特殊的容器类型了。&lt;/p&gt;
&lt;p&gt;Go没有提供类(class)，但允许将方法(method)绑定到任何类型上，包括结构体、数组、切片、map，甚至是基本类型，如整型。它没有类型层次体系；我们认为继承性往往会使程序在演化过程中更难适应。相反，&lt;strong&gt;Go鼓励类型的组合&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-5.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Go通过其接口类型提供面向对象的多态性。就像Java接口或C++的抽象虚拟类一样，Go的接口包含一个方法名称和签名的列表。例如，前面提到的io.Writer接口在io包中的定义如图2所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-6.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;&lt;center&gt;图2：io包中的Writer接口定义&lt;/center&gt;
&lt;p&gt;Write方法接受一个字节切片，并返回一个整数和可能的错误。与Java和C++不同的是，任何Go类型如果拥有与某个接口相同名称和签名的方法集合，就被认为是实现了该接口，而无需额外的显式声明。例如，os.File类型有一个签名相同的Write方法，因此它实现了io.Writer，而没有使用像Java的”implements”进行显式指示。&lt;/p&gt;
&lt;p&gt;避免接口和实现之间的显式关联，允许Go程序员定义小型、灵活以及临时性的接口，而不是将它们作为复杂类型层次结构的基础构件。&lt;strong&gt;它鼓励捕捉开发过程中出现的关系和操作，而不是需要提前计划和定义它们&lt;/strong&gt;。这对大型程序尤其有帮助，因为在刚开始开发时，最终的结构是很难看清楚的。去除声明实现的簿记，鼓励使用精确的、只有一种或两种方法的接口，如Writer、Reader、Stringer（类似于Java的toString方法）等，这些接口在标准库中被广泛应用。&lt;/p&gt;
&lt;p&gt;初次学习Go的开发者常常担心一个类型会意外地实现一个接口。虽然很容易建立起这样的假设，但在实践中，不太可能为两个不兼容的操作选择相同的名称和签名，而且我们从未在实际的Go程序中看到这种情况发生。&lt;/p&gt;
&lt;h3&gt;并发(Concurrency)&lt;/h3&gt;
&lt;p&gt;当我们开始设计Go语言的时候，多核计算机已经开始广泛使用，但线程在所有流行的语言和操作系统中仍然是一个重量级的概念。创建、使用和管理线程的难度使其不受欢迎，这限制了对多核CPU能力的充分利用。&lt;strong&gt;解决这一矛盾是创建Go的主要动机之一&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Go语言中原生包含了多个并发控制线程的概念，称为&lt;strong&gt;goroutines&lt;/strong&gt;。goroutines在一个共享地址空间中运行，并能被有效地通过多路复用机制调度到操作系统线程上。对阻塞操作的调用，如从文件或网络中读取数据，只阻塞进行该操作的goroutine；该线程上的其他goroutine可能被移到另一个线程中，这样它们就可以在调用者被阻塞时继续执行。goroutine开始时只有几千字节的堆栈(译注：在Linux x86-64上默认是2KB)，它可以根据需要自动调整大小，而无需程序员参与。开发人员在设计程序结构时将Goroutines视作一种丰富的、廉价的原语。对于一个服务器程序来说，拥有数千甚至数百万个goroutines是很平常的，因为它们的使用成本比线程低得多。&lt;/p&gt;
&lt;p&gt;例如，net.Listener是一个带有Accept方法的接口，可以监听并返回客户端新发起的网络连接。图3显示了一个接受连接的函数listen，并为每个连接启动一个新的goroutine来运行服务函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-7.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;&lt;center&gt;图3：一个Go网络服务器&lt;/center&gt;
&lt;p&gt;listen函数主体中的无限for循环（第22-28行）中调用了listener.Accept方法，它返回两个值：连接和一个可能的错误。假设没有错误发生，go语句（第27行）在一个新的goroutine中启动其参数：一个函数调用serve(conn)，这类似于Unix shell命令的后缀&amp;amp;，但在同一个操作系统进程中。要调用的函数及其参数在原goroutine中被求值；这些值被复制以创建新goroutine的初始栈帧。因此，程序为每个新发起的网络连接运行一个独立的serve函数实例。每个serve的调用处理一个给定连接上的所有请求（第37行对handle(req)的调用没有以go为前缀）；每次serve调用都可以阻塞而不影响对其他网络连接的处理。&lt;/p&gt;
&lt;p&gt;在Go的内部，Go的实现使用了有效的多路复用操作，比如Linux的epoll，来处理并发的I/O操作，但用户看不到。Go的运行时库&lt;strong&gt;对用户呈现的是阻塞式I/O的抽象&lt;/strong&gt;，其中每个goroutine都是顺序执行的，不需要回调，这很容易理解。&lt;/p&gt;
&lt;p&gt;在创建了多个goroutine之后，一个程序必须经常在它们之间进行协调。Go提供了&lt;strong&gt;channel原语&lt;/strong&gt;，允许goroutine之间进行通信和同步：channel是一个单向的、大小有限的管道，在goroutine之间传输类型化的信息。Go还提供了一个多路选择原语&lt;strong&gt;select&lt;/strong&gt;，可以根据某channel上的通信是否可进行来控制执行。这些想法来自Hoare的”通信顺序过程(Communicating Sequential Processes)”和早期的语言实验，特别是Newsqueak、Alef和Limbo。&lt;/p&gt;
&lt;p&gt;图4显示了另一个版本的listen，它是为了限制任何时候可处理的连接数量而写的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-8.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;&lt;center&gt;图4：一个Go网络服务器，将并发处理的能力限制在10个连接&lt;/center&gt;
&lt;p&gt;这个版本的listen首先创建了一个名为ch的channel（第42行），然后启动了一个由10个服务端goroutines组成的池（第44-46行），它们接收来自这个单一channel的连接。当新的连接被接受时，listen使用发送语句ch &amp;lt;- conn（第53行）在ch上发送每个连接。一个server执行接收表达式&amp;lt;- ch（第59行）完成了此次channel通信。这里创建的是无缓冲channel(Go默认如此)，ch没有空间来缓冲正在发送的值，所以在10个server忙完前10个连接后，第11个ch &amp;lt;-conn将被阻塞，直到一个server完成对serve函数的调用并执行新的接收。被阻塞的通信操作对Listener产生了隐性的压力，这回阻止Listener接受新的连接，直到前一个连接被处理完。&lt;/p&gt;
&lt;p&gt;请注意，这些程序中没有互斥或其他传统的同步机制。在channel上进行的数据值通信可以作为同步的一部分；按照惯例，在channel上发送数据会将所有权从发送方传给接收方。Go有提供互斥、条件变量、信号量和原子操作的库，供低级别互斥或同步使用，但channel往往是更好的选择。根据我们的经验，人们对消息传递–利用通信在goroutine之间转移所有权–的理解比对互斥和条件变量的理解更容易、更正确。早期流行的一句Go箴言是：”&lt;strong&gt;不要通过共享内存来通信，而是通过通信来共享内存&lt;/strong&gt;“。&lt;/p&gt;
&lt;p&gt;Go的垃圾收集器大大简化了并发API的设计，消除了关于哪个goroutine负责释放共享数据的问题。与大多数语言一样（但与Rust不同），可变数据的所有权不由类型系统静态跟踪。相反，Go集成了TSAN(ThreadSanitizer)，为测试和受限的生产使用提供了一个动态竞态检测器。&lt;/p&gt;
&lt;h3&gt;安全性(Security和Safety)&lt;/h3&gt;
&lt;p&gt;任何新语言诞生的部分原因都是为了解决以前语言的缺陷，对Go来说，这还包括影响网络软件安全的安全问题。Go删除了在C和C++程序中造成许多安全问题的未定义行为。整数类型不会自动相互强制转型。空指针解引用、越界的数组和切片索引会导致运行时异常。不存在进入栈帧的空悬指针。任何可能超出其栈帧范围的变量，例如在闭包中捕获的变量，将被移到堆中。在堆中也没有空悬的指针；使用垃圾收集器而不是手动内存管理可以消除使用后的错误。当然，Go并没有解决所有问题，有些东西被遗漏了，也许应该被解决。例如，整数溢出本可以被定义为运行时错误，而不是定义为绕过不处理。&lt;/p&gt;
&lt;p&gt;由于Go是一种系统级编程的语言(译注：Go最初被设计者们定位为一种系统级编程语言)，它可能需要破坏类型安全的机器级操作，因此它能够将指针从一种类型强制转换为另一种类型，并进行地址运算，但只能通过使用unsafe包及其受限制的特殊类型unsafe.Pointer。必须注意这种对类型系统的违反要与垃圾收集器保持兼容–例如，垃圾收集器必须始终能够识别一个特定的字(word)是一个整数还是一个指针。在实践中，unsafe包很少出现：安全Go是相当有效的。因此，看到import “unsafe”是一个信号，让我们更仔细地检查源文件是否存在安全问题。&lt;/p&gt;
&lt;p&gt;Go的安全属性(safety properties)使它比C或C++等语言更适合于编写加密和其他安全关键的代码。一个微不足道的错误，例如一个越界的数组索引，在C和C++中可能会导致敏感数据的泄露或远程执行，但在Go中会引起运行时异常，从而停止程序，大大限制了潜在的影响。Go中有一整套密码学库，包括对SSL/TLS的支持；Go标准库包括一个可用于生产的HTTPS客户端和服务器。事实上，Go的安全性、性能和高质量库的结合使其成为现代安全工作的热门试验场。例如，免费提供的证书授权机构Let’s Encrypt依靠Go来提供生产服务，并在最近跨越了一个里程碑，签发了10亿份证书。&lt;/p&gt;
&lt;h3&gt;完整性(Completeness)&lt;/h3&gt;
&lt;p&gt;Go在语言、库和工具层面上提供了现代开发所需的核心部分。这就需要小心翼翼地平衡，既要增加足够多的”开箱即用”的功能，又不能增加太多，以至于我们自己的开发过程因为要支持太多的功能而陷入困境。&lt;/p&gt;
&lt;p&gt;Go语言提供了内置的字符串、hash map和动态大小的数组等易于使用的数据类型。如前面所述，这些对于大多数Go程序来说已经足够了。其结果是Go程序之间有了更大的互操作性–例如，没有产生竞争性的字符串或hash map的实现来分裂包的生态系统。Go包含的goroutines和channel是另一种形式的完整性。这些功能提供了现代网络程序中所需要的核心并发功能。Go直接在语言中提供这些功能，而不是在库中提供，这样可以更容易地调整语法、语义和实现，使其尽可能地轻量和易于使用，同时为所有用户提供统一的方法。&lt;/p&gt;
&lt;p&gt;Go标准库包括一个生产就绪的HTTPS客户端和服务器。对于在互联网上与其他机器互动的程序来说，这一点至关重要。直接满足这一需求可以避免额外的碎片化。我们已经看到了io.Writer接口；任何输出数据流都按惯例实现了这个接口，并与所有其他I/O适配器进行互操作。图1中的ListenAndServe调用可作为另一个例子，它期望有一个http.Handler类型作为第二个参数，其定义如下图5所示。参数http.HandlerFunc(hello)通过调用hello实现了Handler的ServeHTTP方法。该库创建了一个新的goroutine来处理每个连接，就像本文”并发”部分中的Listener例子一样，所以handler可以用简单的阻塞风格来编写，服务器可以自动扩展以同时处理许多连接。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-9.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;&lt;center&gt;图5：net/http包的Handler接口&lt;/center&gt;
&lt;p&gt;http包还提供了一个基本的分派器(dispatcher)，它本身就是Handler的另一个实现，它允许为不同的URL路径注册不同的handler。将Handler类型确立为约定俗成的接口，使得许多不同类型的HTTP服务器中间件(middleware)能够被创建并相互操作。我们不需要将所有这些实现添加到标准库中，但我们确实需要建立一个允许它们一起工作的接口。&lt;/p&gt;
&lt;p&gt;标准Go发行版还提供了对交叉编译、测试、性能剖析(profiling)、代码覆盖率、&lt;a href=&quot;https://tonybai.com/2021/12/01/first-class-fuzzing-in-go-1-18&quot;&gt;模糊测试&lt;/a&gt;等的集成支持。测试是另一个领域，在这个领域中，建立关于核心概念的协议–例如什么是测试用例以及如何运行–使得创建的自定义测试库和测试执行环境都能很好地互操作。&lt;/p&gt;
&lt;h3&gt;一致性(Consistency)&lt;/h3&gt;
&lt;p&gt;我们对Go的一个目标是&lt;strong&gt;让它在不同的实现、执行环境中，甚至在不同的时间内表现出相同的行为&lt;/strong&gt;。这种”无聊”的一致性行为使开发人员能够专注于他们的日常工作，并使Go隐退到后台。&lt;/p&gt;
&lt;p&gt;首先，Go语言尽可能地规定了一致的结果，即使是错误的行为，如本文的”安全性”部分所讨论的空指针解引用和数组索引越界。这种一致性行为的一个例外是对map的迭代。我们发现，程序员经常不经意地写下依赖于哈希函数的代码，导致在不同的架构或Go实现上出现不同的结果。&lt;/p&gt;
&lt;p&gt;为了使程序在任何地方都有相同的表现，一种选择是强制规定一个特定的哈希函数。相反，Go定义了map迭代是非确定的。该实现为每个map使用不同的随机种子，并从哈希表中的一个随机偏移量开始对地图进行每次迭代。其结果是，map在不同的实现中都是不可预知的。代码不能再意外地依赖于实现细节。与此类似，竞态检测器为调度决策增加了额外的随机性，创造了更多的机会来观察竞态行为。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tonybai.com/wp-content/uploads/the-go-programming-language-and-environment-10.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;一致性的另一个方面是在程序的生命周期内的性能。使用传统的编译器而不是Java和Node.js等语言使用的JIT来实现Go的决策，可以在启动时和短生命周期的程序中提供了一致的性能。没有”慢启动”来惩罚每个进程生命周期的前几秒。这种快速启动使Go成为命令行工具（如上一节所述）以及谷歌应用引擎(Google App Engine)等规模化网络服务器的目标。&lt;/p&gt;
&lt;p&gt;稳定的性能包括垃圾收集的开销。最初的Go原型使用了一个基本的、停止世界(STW)的垃圾收集器，当然，它在网络服务器中引入了明显的尾部延时。今天，Go使用了一个完全并发的垃圾收集器，暂停时间不到一毫秒，通常只有几微秒，与堆的大小无关。最主要的延迟是操作系统向必须中断的线程传递信号所需的时间。&lt;/p&gt;
&lt;p&gt;最后一种一致性是语言和库随着时间的推移而产生的一致性。在Go诞生的前几年，我们在每周的发布中都会对它进行修补和调整。用户在更新到新的Go版本时，常常不得不改变他们的程序。我们提供自动工具以减少开发人员的负担，但手动调整依然是必要的。从2012年发布的Go 1.0开始，我们&lt;strong&gt;公开承诺只对语言和标准库进行向后兼容的修改&lt;/strong&gt;，这样程序在编译到较新的Go版本时可以继续运行而不发生变化。这一承诺对业界产生了吸引力，它不仅鼓励了那些长声明周期的工程项目，也鼓励了其他努力，如书籍、培训课程和第三方软件包的繁荣生态系统。&lt;/p&gt;
&lt;h3&gt;工具辅助开发(Tool-Aided Development)&lt;/h3&gt;
&lt;p&gt;大规模的软件开发需要大量的自动化和辅助工具。从一开始，Go的设计就是为了鼓励这种工具化，并使其易于创建。&lt;/p&gt;
&lt;p&gt;开发者对Go的日常体验是通过go命令进行的。与只编译或运行代码的语言命令不同，go命令为开发周期的所有关键部分提供了子命令：go build和go install构建和安装可执行文件，go test运行测试用例，go get添加新的依赖。go命令还提供了对构建细节的编程访问接口，例如软件包图，从而使得新工具的创建更加容易。&lt;/p&gt;
&lt;p&gt;其中一个工具是go vet，它可以执行增量的、每次打包的程序分析，可以像缓存编译的对象文件那样缓存，实现增量构建。go vet工具的目的是高精度地识别常见的正确性问题，这样开发人员就有条件地听从它的报告。简单的例子包括在调用fmt.Printf和相关函数时检查格式字符串和参数是否匹配，或者诊断对变量或结构体字段的未用的写入。这些不是编译器错误，因为我们不希望仅仅因为发现了一个新的可能的错误就停止编译旧代码。它们也不是编译器警告；用户要学会忽略这些。将这些检查放在一个单独的工具中，可以让它们在开发者方便的时候运行，而不干扰普通的构建过程。这也使得所有的开发者都可以使用同样的检查，即使是在使用Go编译器的另一种实现，如Gccgo或Gollvm。这种增量方法使这些静态检查足够高效，我们在go test期间自动运行它们，然后再运行测试本身。无论如何，测试是用户在寻找错误，测试报告往往有助于解释实际的测试失败。这个增量框架也可以被其他工具重复使用。&lt;/p&gt;
&lt;p&gt;分析程序的工具是很有帮助的，但是编辑程序的工具就更好了，特别是对于程序的维护，很多工具都是乏味的、可自动化运作的。&lt;/p&gt;
&lt;p&gt;Go程序源码的标准样式是通过算法定义的。一个名为gofmt的工具将源文件解析为抽象的语法树，然后使用一致的布局规则将其格式化为源代码。&lt;strong&gt;在Go中，在将代码存储到源码控制系统中之前将其格式化被认为是一种最佳做法&lt;/strong&gt;。这种方法使数以千计的开发人员能够在一个共享的代码库中工作，而不需要为大括号样式和其他细节进行争论，这些争论常伴随着这种大型项目。更重要的是，工具可以通过对抽象语法形式的操作来修改Go程序，然后用gofmt的printer输出结果。只有实际改变的部分才会被触及，产生的”差异”与人的手写结果是一致的。人和程序可以在同一个代码库中无缝协作。&lt;/p&gt;
&lt;p&gt;为了实现这种方法，Go的语法被设计为能够在没有类型信息或任何其他外部输入的情况下解析源文件，而且没有预处理器或其他宏系统。Go标准库提供了一些包，允许工具重新创建gofmt的输入和输出端，同时还有一个完整的类型检查器。&lt;/p&gt;
&lt;p&gt;在发布Go 1.0 –第一个稳定的Go版本之前，我们写了一个叫做gofix的重构工具，它就使用这些包来解析源代码、重写抽象语法树，并写出格式良好的代码。例如，当从map中删除一个条目的语法被改变时，我们就使用了gofix。每次用户更新到一个新版本时，他们可以在他们的源文件上运行gofix，自动应用更新到新版本所需的大部分变化。&lt;/p&gt;
&lt;p&gt;这些技术也适用于IDE插件和其他支持Go程序员的工具–profiler、调试器、分析器、构建自动程序、测试框架等等的构建。Go的常规语法、既定的算法代码布局惯例以及基于标准库的直接支持，使得这些工具的构建比其他方式要容易得多。因此，Go世界拥有一个丰富的、不断扩展的、可互操作的工具包。&lt;/p&gt;
&lt;h3&gt;库(Libraries)&lt;/h3&gt;
&lt;p&gt;在语言和工具之后，下一个用户关键体验是可用的Go库。作为一种分布式计算的语言，Go没有提供用于发布Go软件包的中央服务器。相反，每个以域名开始的导入路径都被解释为一个URL（有一个隐含的前导https://），提供远程源代码的位置。例如，导入 “github.com/google/uuid”可以获取托管在相应的GitHub仓库的代码。&lt;/p&gt;
&lt;p&gt;托管源代码最常见的方式是指向公共的Git或Mercurial服务器，但私人服务器也同样得到了很好的支持，作者可以选择发布一个静态的文件包，而不是开放对源码控制系统的访问。这种灵活的设计和发布库的便利性创造了一个繁荣的可导入Go包的社区。依靠域名，避免了在扁平的包名空间中急于索取有价值的条目(译注：应该是避免了导入路径冲突的问题)。&lt;/p&gt;
&lt;p&gt;仅仅下载软件包是不够的，我们还必须知道要使用哪些版本。Go将包分组为称为&lt;strong&gt;module&lt;/strong&gt;的版本单位。一个module可以为它的一个依赖关系指定一个最低要求的版本，但没有其他限制。当构建一个特定的程序时，Go通过选择最大版本来解决竞争的依赖module的所需版本：如果程序的一部分需要某个依赖module的1.2.0版本，而另一部分需要1.3.0版本，Go会选择1.3.0版本–也就是说，Go要求使用语义版本划分，其中1.3.0版本必须是1.2.0的直接替换(译注：1.3.0保持与1.2.0的兼容性)。另一方面，在这种情况下，即使1.4.0版本可用，Go也不会选择它，因为程序中没有任何部分明确要求使用该较新的版本。这个规则保持了构建的可重复性，并最大限度地减少了因意外破坏新版本所引入的变化而造成的潜在风险。&lt;/p&gt;
&lt;p&gt;在语义版本管理中，一个module只能在一个新的主要版本中引入有意的破坏性变化，比如2.0.0。在Go中，从2.0.0开始的每个主要版本在其导入路径中都有一个主要版本后缀，比如/v2。不同的主版本和其他不同名字的module一样被分开。这种方法不允许出现钻石依赖性问题，而且在实践中，它可以适应不兼容的情况，也可以适应具有更精细约束的系统。&lt;/p&gt;
&lt;p&gt;为了提高从互联网上下载软件包的构建的可靠性和可重现性，我们在Go工具链中运行了两个默认使用的服务：一个是可用的Go软件包的公共镜像，一个是其预期内容的加密签名的透明日志。即便如此，广泛使用从互联网上下载的软件包仍然存在安全和其他风险。我们正在努力使Go工具链能够主动识别并向用户报告有漏洞的软件包。&lt;/p&gt;
&lt;h3&gt;结论(Conclusion)&lt;/h3&gt;
&lt;p&gt;虽然大多数语言的设计都集中在语法、语义或类型的创新上，但&lt;strong&gt;Go的重点是软件开发过程本身&lt;/strong&gt;。Go语言高效、易学、免费，但&lt;strong&gt;我们认为它的成功之处在于它所采取的编写程序的方法，特别是多个程序员在一个共享代码库上工作时&lt;/strong&gt;。该语言本身的主要不寻常属性–并发性–解决了2010年代随着多核CPU的广泛应用而出现的问题。但更重要的是，早期的工作为打包、依赖关系、构建、测试、部署和软件开发领域的其他工作任务奠定了基础，这些方面在传统的语言设计中并没有受到应有的重视。&lt;/p&gt;
&lt;p&gt;这些想法吸引了志同道合的开发者，他们重视与努力的结果是：容易并发、明确的依赖关系、可扩展的开发和生产、安全的程序、简单的部署、自动代码格式化、工具辅助开发等等。这些早期的开发者帮助普及了Go，并播种了最初的Go包生态系统。他们还推动了该语言的早期发展，例如，将编译器和库移植到Windows和其他操作系统上（最初的版本只支持Linux和MacOS X）。&lt;/p&gt;
&lt;p&gt;不是每个人都喜欢–例如，有些人反对该语言省略了继承和泛型等常见功能。但是Go的以开发为中心的理念足够吸引人，也足够有效，以至于社区在保持最初推动Go存在的核心原则的同时，也得到了蓬勃发展。在很大程度上，由于该社区和它所建立的技术，Go现在是现代云计算环境的一个重要组成部分。&lt;/p&gt;
&lt;p&gt;自Go第一版发布以来，该语言几乎被冻结。然而，工具已经大大扩展，有了更好的编译器，更强大的构建和测试工具，以及改进的依赖性管理，更不用说支持Go的大量开源工具了。然而，变化正在到来。&lt;a href=&quot;https://tonybai.com/2022/04/20/some-changes-in-go-1-18&quot;&gt;2022年3月发布的Go 1.18&lt;/a&gt;包含了对语言的真正改变的第一个版本，一个被广泛要求的改变–参数化多态性的第一版实现。我们曾将任何形式的泛型排除在原始语言之外，因为我们敏锐地意识到，它很难设计好，而且在其他语言中，往往是复杂性而非生产力的来源。在Go的第一个十年中，我们考虑了很多设计，但直到最近才找到一个我们认为很适合Go的设计。在坚持一致性、完整性和社区原则的前提下进行如此大的语言变革，将是对该方法的严峻考验。&lt;/p&gt;
&lt;h3&gt;致谢(Acknowledgments)&lt;/h3&gt;
&lt;p&gt;Go最早的工作从Google的许多同事的建议和帮助中受益匪浅。自公开发布以来，由于Google的Go团队不断扩大，加上大量的开源贡献者，Go不断成长和改进。Go现在是由成千上万的人共同完成的，这里无法一一列举。我们感谢每一个帮助Go发展到今天的人。&lt;/p&gt;
&lt;h3&gt;参考资料(References)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Aas, J. and Gran, S. Let’s Encrypt has issued a billion certificates. Let’s Encrypt (2020), https://letsencrypt.org/2020/02/27/one-billion-certs.html.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aas, J., et al. Let’s Encrypt: An automated certificate authority to encrypt the entire web. In Proceedings of the 2019 ACM SIGSAC Conf. on Computer and Communications Security, 2473–2487.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bloch, D. Life on the edge: Monitoring and running a very large Perforce installation. Presented at 2007 Perforce User Conf., https://go.dev/s/bloch2007.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Chang, F., et al. Bigtable: A distributed storage system for structured data. In 7th USENIX Symposium on Operating Systems Design and Implementation (2006), 205–218.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cox, R. Introducing Gofix. The Go Blog (2011), https://go.dev/blog/introducing-gofix.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cox, R. The principles of versioning in Go. (2019), https://research.swtch.com/vgo-principles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cox, R. Surviving software dependencies. Communications of the ACM 62, 9 (Aug. 2019), 36–43.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cox, R. Transparent logs for skeptical clients (2019), https://research.swtch.com/tlog.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cox, R. and Pike, R. Go programming. Presented at Google I/O (2010), https://www.youtube.com/watch?v=jgVhBThJdXc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Crosby, S.A. and Wallach, D.S. Efficient data structures for tamper-evident logging. In Proceedings of the 18th USENIX Security Symp. (2009), 317–334.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Donovan, A.A.A. and Kernighan, B.W. The Go Programming Language. Addison-Wesley, USA (2015).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dorward, S., Pike, R., and Winterbottom, P. Programming in Limbo. In IEEE COMPCON 97 Proceedings (1997), 245–250.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Geissmann, L.B. Separate compilation in Modula-2 and the structure of the Modula-2 compiler on the personal computer Lilith. Ph.D. dissertation. Swiss Federal Institute of Technology (1983), https://www.cfbsoftware.com/modula2/ETH7286.pdf.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gerrand, A. Go fmt your code. The Go Blog (2013), https://go.dev/blog/gofmt.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go Project. Setting up and using gccgo. (2009), https://go.dev/doc/install/gccgo.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go Project. Go 1 and the future of Go programs. (2012), https://go.dev/doc/go1compat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go Project. Gollvm, an LLVM-based Go compiler. (2017), https://go.googlesource.com/gollvm/.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Go Project. The Go programming language specification. (2021), https://go.dev/ref/spec.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hoare, C.A.R. Communicating Sequential Processes. Prentice-Hall, Inc., USA (1985).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hockman, K. Go Module Proxy: Life of a query. Presented at GopherCon 2019, https://www.youtube.com/watch?v=KqTySYYhPUE&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hudson, R.L. Getting to Go: The journey of Go’s garbage collector. The Go Blog (2018), https://go.dev/blog/ismmkeynote.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Klabnik, S. and Nichols, C. The Rust Programming Language. No Starch Press, USA (2018).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lam, A. Using remote cache service for Bazel. Communications of the ACM 62, 1 (Dec. 2018), 38–42.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ousterhout, J. Why threads are a bad idea (for most purposes). (1995), https://web.stanford.edu/~ouster/cgi-bin/papers/threads.pdf&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pike, R. The implementation of Newsqueak. Software: Practice and Experience 20, 7 (1990), 649–659.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pike, R., Dorward, S., Griesemer, R., and Quinlan, S. Interpreting the data: Parallel analysis with Sawzall. Scientific Programming Journal 13 (2005), 277–298.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Preston-Werner, T. Semantic versioning 2.0.0. (2013), https://semver.org/&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Serebryany, K., Potapenko, A., Iskhodzhanov, T., and Vyukov, D. Dynamic race detection with LLVM compiler: Compile-time instrumentation for ThreadSanitizer. In Runtime Verification, S. Khurshid, and K. Sen (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg (2012), 110–114.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stambler, R. Go, pls stop breaking my editor. Presented at GopherCon 2019, https://www.youtube.com/watch?v=EFJfdWzBHwE.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Symonds, D., Tao, N., and Gerrand, A. Go and Google App Engine. The Go Blog (2011), https://go.dev/blog/appengine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Winterbottom, P. Alef language reference manual. In Plan 9: Programmer’s Manual Volume 2. Harcourt Brace and Co., New York (1996).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;作者(Authors)&lt;/h3&gt;
&lt;p&gt;Russ Cox (rsc@go.dev), Robert Griesemer, Rob Pike, Ian Lance Taylor, and Ken Thompson作为美国加州山景城的谷歌公司的软件工程师创造了Go编程语言和环境。Cox、Griesemer和Taylor继续在Google领导Go项目，而Pike和Thompson已经退休了。&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;a href=&quot;https://wx.zsxq.com/dweb2/index/group/51284458844544&quot;&gt;“Gopher部落”知识星球&lt;/a&gt;旨在打造一个精品Go学习和进阶社群！高品质首发Go技术文章，“三天”首发阅读权，每年两期Go语言发展现状分析，每天提前1小时阅读到新鲜的Gopher日报，网课、技术专栏、图书内容前瞻，六小时内必答保证等满足你关于Go语言生态的所有需求！2022年，Gopher部落全面改版，将持续分享Go语言与Go应用领域的知识、技巧与实践，并增加诸多互动形式。欢迎大家加入！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image.tonybai.com/img/tonybai/gopher-tribe-zsxq-small-card.png&quot; alt=&quot;img{512x368}&quot;/&gt;&lt;br/&gt;
&lt;img src=&quot;http://image.tonybai.com/img/tonybai/go-programming-from-beginner-to-master-qr.png&quot; alt=&quot;img{512x368}&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://image.tonybai.com/img/tonybai/go-first-course-banner.png&quot; alt=&quot;img{512x368}&quot;/&gt;&lt;br/&gt;
&lt;img src=&quot;http://image.tonybai.com/img/tonybai/imooc-go-column-pgo-with-qr.jpg&quot; alt=&quot;img{512x368}&quot;/&gt;&lt;br/&gt;
&lt;img src=&quot;http://image.tonybai.com/img/tonybai/imooc-k8s-practice-with-qr.jpg&quot; alt=&quot;img{512x368}&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://51smspush.com/&quot;&gt;我爱发短信&lt;/a&gt;：企业级短信平台定制开发专家 https://51smspush.com/。smspush : 可部署在企业内部的定制化短信平台，三网覆盖，不惧大并发接入，可定制扩展； 短信内容你来定，不再受约束, 接口丰富，支持长短信，签名可选。2020年4月8日，中国三大电信运营商联合发布《5G消息白皮书》，51短信平台也会全新升级到“51商用消息平台”，全面支持5G RCS消息。&lt;/p&gt;
&lt;p&gt;著名云主机服务厂商DigitalOcean发布最新的主机计划，入门级Droplet配置升级为：1 core CPU、1G内存、25G高速SSD，价格5$/月。有使用DigitalOcean需求的朋友，可以打开这个&lt;a href=&quot;https://m.do.co/c/bff6eed92687&quot;&gt;链接地址&lt;/a&gt;：https://m.do.co/c/bff6eed92687 开启你的DO主机之路。&lt;/p&gt;
&lt;p&gt;Gopher Daily(Gopher每日新闻)归档仓库 – https://github.com/bigwhite/gopherdaily&lt;/p&gt;
&lt;p&gt;我的联系方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微博：https://weibo.com/bigwhite20xx&lt;/li&gt;
&lt;li&gt;微信公众号：iamtonybai&lt;/li&gt;
&lt;li&gt;博客：tonybai.com&lt;/li&gt;
&lt;li&gt;github: https://github.com/bigwhite&lt;/li&gt;
&lt;li&gt;“Gopher部落”知识星球：https://public.zsxq.com/groups/51284458844544&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://image.tonybai.com/img/tonybai/iamtonybai-wechat-qr.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;商务合作方式：撰稿、出书、培训、在线课程、合伙创业、咨询、广告合作。&lt;/p&gt;
&lt;p&gt;© 2022, &lt;a href=&quot;https://tonybai.com&quot;&gt;bigwhite&lt;/a&gt;. 版权所有. &lt;/p&gt;
&lt;p&gt;Related posts:&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://tonybai.com/2021/10/06/the-go-programming-language-and-environment/&quot; rel=&quot;bookmark&quot; title=&quot;Go语言之父谈Go编程语言与环境&quot;&gt;Go语言之父谈Go编程语言与环境&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tonybai.com/2020/11/04/the-recommend-books-list-for-learning-go/&quot; rel=&quot;bookmark&quot; title=&quot;系统学习Go语言，有这几本书就够了！&quot;&gt;系统学习Go语言，有这几本书就够了！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tonybai.com/2019/05/03/go-is-on-a-trajectory-to-become-the-next-enterprise-programming-language/&quot; rel=&quot;bookmark&quot; title=&quot;Go正走在成为下一个企业级编程语言的轨道上&quot;&gt;Go正走在成为下一个企业级编程语言的轨道上&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tonybai.com/2017/10/24/go-evolution-for-ten-years-an-interview-by-osc/&quot; rel=&quot;bookmark&quot; title=&quot;源创会开源访谈：十年成长，Go语言的演化之路&quot;&gt;源创会开源访谈：十年成长，Go语言的演化之路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tonybai.com/2017/09/24/go-ten-years-and-climbing/&quot; rel=&quot;bookmark&quot; title=&quot;Go语言：成长的十年&quot;&gt;Go语言：成长的十年&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;&amp;#13;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>658b81adcf4679229d35c2c404ef3735</guid>
<title>计算存储分离在京东云消息中间件 JCQ 上的应用</title>
<link>https://toutiao.io/k/vg47ljm</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;&lt;strong&gt;作者：田寄远&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;JCQ 全名 JD Cloud Message Queue，是京东云自研、具有 CloudNative 特性的分布式消息中间件。 JCQ 设计初衷即为适应云特性的消息中间件；具有高可用、数据可靠性、副本物理隔离、服务自治、健康状态汇报、少运维或无运维、容器部署、弹性伸缩、租户隔离、按量付费、云账户体系、授权等特性。&lt;/p&gt;

&lt;h1&gt;演进过程&lt;/h1&gt;

&lt;p&gt;2017 年中开始开发 JCQ 1.0 版本，2018 年 11 月正式 GA 上线对外售卖，1.0 版本中 Topic 受限于单台服务器限制，满足不了用户超大规格 topic 的需求。&lt;/p&gt;

&lt;p&gt;2019 年 4 月 JCQ 2.0 正式上线，主要新增特性是 topic 扩缩容能力、热点 Topic 在 Broker 间的负载均衡、热点 Broker 的流量转移。&lt;/p&gt;

&lt;p&gt;2019 年 7 月 JCQ 做了一次大的架构演进 —— 计算存储分离，大版本号为 JCQ 3.0, 于 2019 年底上线。计算存储分离对架构带来了比较明显的好处，解决了日常遇到许多的痛点问题。下文详细介绍此次演进带来的好处及解决的痛点问题。&lt;/p&gt;

&lt;h1&gt;升级影响范围尽可能小&lt;/h1&gt;

&lt;p&gt;在 JCQ2.0 中计算模块与存储模块处于同一个进程，升级计算模块势必将存储模块一起升级。而存储模块重启是比较重的动作，需要做的工作有：加载大量数据、进行消息数据与消息索引数据比对、脏数据截断等操作。往往修复计算模块一个小的 Bug，就需要做上述非常重的存储模块重启。而在现实工作中，大部分升级工作都是由于计算模块功能更新或 Bugfix 引起的。&lt;/p&gt;

&lt;p&gt;为了解决这个问题， JCQ3.0 将计算模块、存储模块独立部署，之间通过 RPC 调用。各自升级互不影响。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a562b9cadd1840bfbdfdb50b7611a471%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;计算节点 Broker 只负责生产消息、推送消息、鉴权、认证、限流、拥塞控制、客户端负载均衡等业务逻辑，属于无状态服务。比较轻量，升级速度快。&lt;/p&gt;

&lt;p&gt;存储节点 Store 只负责数据写入、副本同步、数据读取。因为业务逻辑简单，功能稳定后，除优化外基本无需改动，也就无需升级。&lt;/p&gt;

&lt;h1&gt;成本降低&lt;/h1&gt;

&lt;p&gt;JCQ 是共享消息中间件，用户申请的是不同规格 TPS 的 Topic，并不感知 cpu、memory、disk 等硬件指标。 所以，JCQ 服务方需要考虑如何合理的使用这些硬件指标。&lt;/p&gt;

&lt;p&gt;JCQ 是容器部署，有多种类型的组件，这些组件对硬件的需求也是多样化的，其中对资源消耗最多的是计算模块和存储模块。在 JCQ2.0 版本计算模块和存储模块部署在一起，选择机型时要兼顾 cpu、memory、disk 等指标，机型要求单一，很难与其他产品线混合部署。即使是同一资源池，也存在因为调度顺序，造成调度失败的情况。如一台机器剩余资源恰好能调度一个需要大规格磁盘的 A 容器，但是因为 B 容器先被调度到这台机器上，剩余资源就不够创建一个 A 容器，那这台机器上的磁盘就浪费了。&lt;/p&gt;

&lt;p&gt;JCQ3.0 后，计算节点 Broker，与存储节点 Store 独立部署。这两个组件可以各自选择适合自己业务的机型，部署在相应资源池中；最终，可以做到与其他产品混合部署，共用资源池水位，而不用独自承担资源水位线。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2178ae2323e14114bd7f7976e53b6846%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h1&gt;架构改进带来的成本降低&lt;/h1&gt;

&lt;p&gt;JCQ3.0 中计算节点 Broker 是无状态服务，主从切换比较轻量，能在秒级完成故障转移；且部署时考虑了物理设备反亲和，如跨 Rack、跨 AZ 部署。所以，可以在可用性、资源成本之间做一定的权衡；如可以使用 M:1 方式做高可用冷备，而不必 1：1 的比例高可用冷备，进而达到节省硬件资源的目的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f186617cbc544829bd797eef28b206d0%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h1&gt;解决 Raft 性能问题&lt;/h1&gt;

&lt;p&gt;JCQ 1.0 设计之初就采用 Raft 算法，来解决服务高可用、数据一致性的问题。Message Log 与 Raft Log 有很多共同的特性，如顺序写、随机读、末端热数据。所以，直接用 Raft Log 当成 Message Log 是非常合适的。&lt;/p&gt;

&lt;p&gt;在 JCQ 演进中我们也发现了 Raft 本身的一些性能问题，如顺序复制、顺序 commit、有的流程只能用单线程处理等限制。针对这些问题，最直接有效的办法就是扩展 Raft 的数目、扩展单线程流程数目，在一定数量级内，并发能力随着 Raft Group 数目的增长，呈线性增长关系，称之 MultiRaft，如下图所示。&lt;/p&gt;

&lt;p&gt;****&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/98c079025a1e42e787957216492cdb2c%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;上图中，每个 StoreNode 节点是一个独立进程，内部有四组逻辑 RaftGroup（橙色的节点为 RaftGroup 的 Leader），各组 RaftGroup 之间是并行关系，可以做到 Group 间并行复制、并行 commit。&lt;/p&gt;

&lt;p&gt;由于大量使用了 NIO，这些 RaftGroup 之间可以共享通信线程池，扩充 RaftGroup 数目并不会带来线程资源线性增长的问题。&lt;/p&gt;

&lt;h1&gt;快速故障恢复、轻量的负载均衡&lt;/h1&gt;

&lt;p&gt;在 JCQ3.0 中，Broker 为轻量的无状态服务，在主从切换、故障恢复方面相对 2.0 更为轻量，本身能更快的恢复对外服务能力。&lt;/p&gt;

&lt;p&gt;同时，Broker 将 Producer、Consumer 的连接请求，抽象为 PubTask 和 SubTask，后文统称为 Task。Task 的概念非常轻量，仅描述 Client 与 Broker 的对应关系，由元数据管理器 Manager 统一调度、管理。转移 Task 只需要修改 Task 的内容，客户端重新连接新 Broker 即可。&lt;/p&gt;

&lt;p&gt;一般来说，Broker 的主要瓶颈在于网络带宽。Broker 定期统计网络入口流量与出口流量，并上报给管理节点 Manager。Manager 根据入口流量、出口流量与带宽阈值进行裁决，发现超过阈值后，通过一定策略将相应的 Task 转移到较小负载的 Broker 上，并通知相应的 Producer 与 Consumer；Producer 与 Consumer 收到通知后，重新获取 Task 的路由信息，自动重连到新的 Broker 继续进行生产、消费。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a25855ca88404ee994b9c97269414954%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h1&gt;高扇出需求&lt;/h1&gt;

&lt;p&gt;设想一个场景，有一个大规格的 topic，创建了 n 个消费组。消费总 TPS 是生产总 TPS 的 n 倍。增加消费组，会导致消费总 TPS 线性增长。到达一定消费组规模后，单 Broker 由于网卡带宽的原因，无法满足这种高扇出的场景。单服务器是无法解决这个问题。&lt;/p&gt;

&lt;p&gt;在 JCQ 3.0 可以将这些不同的消费组对应的 SubTask 分散到若干个 Broker 上，每个 Broker 负责一部分 SubTask，单 Broker 从 Store 预读消息，将数据推送给 Consumer。这样多个 Broker 共同完成所有消费组的消息流量，协作一起提供高扇出的能力。&lt;/p&gt;

&lt;h1&gt;支持多种存储引擎&lt;/h1&gt;

&lt;p&gt;消息中间件很大的特点是：大部分场景下，热数据都在末端，而回溯几天之前的消息这个功能是不常用的。所以，就有冷热数据之分。&lt;/p&gt;

&lt;p&gt;JCQ 计算节点设计了一层存储抽象层 Store Bridge 可以接入不同的存储引擎，可以接入 Remote Raft Cluster，或者分布式文件系统 WOS、或者 S3。甚者可以将冷数据定期从昂贵的本地盘卸载到廉价的存储引擎上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cd929e01f6b447d49801036b9a274853%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;副作用&lt;/h1&gt;

&lt;p&gt;相对于 JCQ2.0，计算节点与存储节点之间的通信方式，由接口调用变为 RPC 调用，在延迟方面会有一定损失。经过测试，绝大部分延迟都在 1ms 左右，在大多数场景下 牺牲 1ms 左右的延迟并不会给业务带来太大的影响。&lt;/p&gt;

&lt;h1&gt;后续发展规划&lt;/h1&gt;

&lt;p&gt;JCQ 后续会主要在多协议兼容，按需自动扩缩容、云原生等方面演进。&lt;/p&gt;

&lt;h1&gt;多协议兼容&lt;/h1&gt;

&lt;p&gt;JCQ 协议为私有协议，在引导用户迁移方面有比较大的障碍。后续会抽离 JCQ Kernel，外部提供不同的协议接入层。方便用户从其他 MQ 接入 JCQ。目前已兼容 RocketMQ 协议，SQS 协议&lt;/p&gt;

&lt;h1&gt;自动扩缩容&lt;/h1&gt;

&lt;p&gt;JCQ 是共享消息中间件，但缺少 Serverless 自动扩缩容的特性。每逢大促，如 618，双 11，服贸会等重要活动。业务方很难预估自己的业务量峰值，或者估计不足，会造成 topic 限流等问题。如在保证 JCQ 服务本身能力情况下，能做到 topic 灵活的自动扩缩容，将对用户有极大的帮助，起到真正的削峰填谷作用。&lt;/p&gt;

&lt;h1&gt;云原生&lt;/h1&gt;

&lt;p&gt;支持在 kubernetes 环境部署与交付，提供原生的 Operator，能够快速的部署在 k8s 环境中，更好的交付私有云、混合云项目。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>