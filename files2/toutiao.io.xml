<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>383cdeea43582b8d91960907d44a6233</guid>
<title>Kafka在美团数据平台的实践</title>
<link>https://toutiao.io/k/92uh7d6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;58&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBVHPgeBXgTUj0ib1Kwfosl82xO1Aw7x6gccLuuYs1dbxI7REI7OcjbGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总第526&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2022年 第043篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img border=&quot;0&quot; class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;103&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;103&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBic5ADGrKxgSd0tibyMiasOHXjb46qFBw7PTfuWAxXzWq32lDkL05icwkMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; data-width=&quot;100%&quot; opacity=&quot;&quot; title=&quot;undefined&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; data-style=&quot;text-align: left; font-size: 14px; color: inherit;&quot;&gt;&lt;section&gt;&lt;span&gt;Kafka在美团数据平台承担着统一的数据缓存和分发的角色，随着数据量的增长，集群规模的扩大，Kafka面临的挑战也愈发严峻。本文分享了美团Kafka面临的实际挑战，以及美团针对性的一些优化工作，希望能给从事相关开发工作的同学带来帮助或启发。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1. 现状和挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2. 读写延迟优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2.1 概览&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2.2 应用层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2.3 系统层&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2.4 混合层-SSD新缓存架构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3. 大规模集群管理优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.1 隔离策略&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.2 全链路监控&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.3 服务生命周期管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.4 TOR容灾&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4 未来展望&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 现状和挑战&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.1 现状&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;Kafka是一个开源的流处理平台，我们首先了解一下Kafka在美团数据平台的现状。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;473&quot; data-ratio=&quot;0.84765625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2Ep8NK5lDVqekicpD25HBsqeDqh3hOUJicB6fzIRibdk7L2LNeeia8v2h4Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图1-1 Kafka在美团数据平台的现状&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图1-1所示，蓝色部分描述了Kafka在数据平台定位为流存储层。主要的职责是做数据的缓存和分发，它会将收集到的日志分发到不同的数据系统里，这些日志来源于系统日志、客户端日志以及业务数据库。下游的数据消费系统包括通过ODS入仓提供离线计算使用、直接供实时计算使用、通过DataLink同步到日志中心，以及做OLAP分析使用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kafka在美团的集群规模总体机器数已经超过了15000+台，单集群的最大机器数也已经到了2000+台。在数据规模上，天级消息量已经超过了30+P，天级消息量峰值也达到了4+亿/秒。不过随着集群规模的增大，数据量的增长，Kafka面临的挑战也愈发严峻，下面讲一下具体的挑战都有哪些。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.2 挑战&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;213&quot; data-ratio=&quot;0.3814814814814815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2kjgz9Iktia4WEAlbpBO7ZZ5RkLWb7VJg8NHFiagQd0V5R8Co9yh0bWCQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图1-2 Kafka在美团数据平台面临的挑战&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图1-2所示，具体的挑战可以概括为两部分：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;第一部分是慢节点影响读写&lt;/strong&gt;，这里慢节点参考了HDFS的一个概念，具体定义指的是读写延迟TP99大于300ms的Broker。造成慢节点的原因有三个：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集群负载不均衡会导致局部热点，就是整个集群的磁盘空间很充裕或者ioutil很低，但部分磁盘即将写满或者ioutil打满。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PageCache容量，比如说，80GB的PageCache在170MB/s的写入量下仅能缓存8分钟的数据量。那么如果消费的数据是8分钟前的数据，就有可能触发慢速的磁盘访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Consumer客户端的线程模型缺陷会导致端到端延时指标失真。例如当Consumer消费的多个分区处于同一Broker时，TP90可能小于100ms，但是当多个分区处于不同Broker时，TP90可能会大于1000ms。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;第二部分是大规模集群管理的复杂性&lt;/strong&gt;，具体表现有4类问题：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不同Topic之间会相互影响，个别Topic的流量突增，或者个别消费者的回溯读会影响整体集群的稳定性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Kafka原生的Broker粒度指标不够健全，导致问题定位和根因分析困难。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;故障感知不及时，处理成本较高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Rack级别的故障会造成部分分区不可用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 读写延迟优化&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;接下来我们先介绍一下针对读写延迟问题，美团数据平台做了哪些优化。首先从宏观层面，我们将受影响因素分为应用层和系统层，然后详细介绍应用层和系统层存在的问题，并给出对应的解决方案，包括流水线加速、Fetcher隔离、迁移取消和Cgroup资源隔离等，下面具体介绍各种优化方案的实现。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.1 概览&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;286&quot; data-ratio=&quot;0.51171875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2U4VwXgjpKhlv14KQobga8wS5SspwC4akxDiczg3Oo1sR4gMaIiaveKpw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-1 Kafka读写延迟优化概览&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图2-1是针对读写延迟碰到的问题以及对应优化方案的概览图。我们把受影响的因素分为应用层和系统层。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;应用层&lt;/strong&gt;主要包括3类问题：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1）Broker端负载不均衡，例如磁盘使用率不均衡、ioutil不均衡等问题。个别磁盘负载升高影响整个Broker的请求受到影响。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2）Broker的数据迁移存在效率问题和资源竞争问题。具体来讲，包括以下3个层面：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3）Consumer端单线程模型存在缺陷导致运维指标失真，并且单Consumer消费的分区数不受限制，消费能力不足就无法跟上实时最新的数据，当消费的分区数增多时可能会引起回溯读。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;系统层&lt;/strong&gt;也主要包括3类问题：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1）PageCache污染。Kafka利用内核层提供的ZeroCopy技术提升性能，但是内核层无法区分实时读写请求和回溯读请求，导致磁盘读可能污染PageCache，影响实时读写。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2）HDD在随机读写负载下性能差。HDD对于顺序读写友好，但是面对混合负载场景下的随机读写，性能显著下降。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3）CPU和内存等系统资源在混部场景下的资源竞争问题。在美团大数据平台，为了提高资源的利用率，IO密集型的服务（&lt;/span&gt;&lt;span&gt;比如Kafka&lt;/span&gt;&lt;span&gt;）会和CPU密集型的服务（&lt;/span&gt;&lt;span&gt;比如实时计算作业&lt;/span&gt;&lt;span&gt;）混布，混布存在资源竞争，影响读写延迟。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以上提到的问题，我们采取了针对性的策略。比如应用层的磁盘均衡、迁移流水线加速、支持迁移取消和Consumer异步化等。系统层的Raid卡加速、Cgroup隔离优化等。此外，针对HDD随机读写性能不足的问题，我们还设计并实现了基于SSD的缓存架构。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.2 应用层&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;① 磁盘均衡&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;488&quot; data-ratio=&quot;0.84296875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj205CQrOf1PVflyCApAxibK4s38sq1MbR9LGLLrAAz3iab67Gj8IiaicD32A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-2 Kafka应用层磁盘均衡&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;磁盘热点导致两个问题：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这两个问题，我们采用了基于空闲磁盘优先的分区迁移计划，整个计划分为3步，由组件Rebalancer统筹管理：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;生成迁移计划。Rebalancer通过目标磁盘使用率和当前磁盘使用率（&lt;/span&gt;&lt;span&gt;通过Kafka Monitor上报&lt;/span&gt;&lt;span&gt;）持续生成具体的分区迁移计划。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提交迁移计划。Rebalancer向Zookeeper的Reassign节点提交刚才生成的迁移计划，Kafka的Controller收到这个Reassign事件之后会向整个Kafka Broker集群提交Reassign事件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;检查迁移计划。Kafka Broker负责具体执行数据迁移任务，Rebalancer负责检查任务进展。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;如图2-2所示，每块Disk持有3个分区是一个相对均衡的状态，如果部分Disk持有4个分区，比如Broker1-Disk1和Broker4-Disk4；部分Disk持有2个分区，比如Broker2-Disk2，Broker3-Disk3，Reblanacer就会将Broker1-Disk1和Broker4-Disk4上多余的分区分别迁移到Broker2-Disk2和Broker3-Disk3，最终尽可能地保证整体磁盘利用率均衡。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;② 迁移优化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;虽然基于空闲磁盘优先的分区迁移实现了磁盘均衡，但是迁移本身仍然存在效率问题和资源竞争问题。接下来，我们会详细描述我们采取的针对性策略。&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;采取流水线加速策略优化迁移缓慢引起的迁移效率问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持迁移取消解决长尾分区迁移缓慢引起的读写请求受影响问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;采取Fetcher隔离缓解数据迁移请求和实时读写请求共用Fetcher线程的问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;优化一，流水线加速&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;525&quot; data-ratio=&quot;0.90859375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2N0uJeeWaBvcdRujyNrDw2TArwCUwEsR5hGpJt5aWeGDuubFnU7icXkQ/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-3 流水线加速&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图2-3所示，箭头以上原生Kafka版本只支持按批提交，比如说一批提交了四个分区，当TP4这个分区一直卡着无法完成的时候，后续所有分区都无法继续进行。采用流水线加速之后，即使TP4这个分区还没有完成，可以继续提交新的分区。在相同的时间内，原有的方案受阻于TP4没有完成，后续所有分区都没办法完成，在新的方案中，TP4分区已经迁移到TP11分区了。图中虚线代表了一个无序的时间窗口，主要用于控制并发，目的是为了和原有的按组提交的个数保持一致，避免过多的迁移影响读写请求服务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;优化二，迁移取消&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;373&quot; data-ratio=&quot;0.6453125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2kTHuKIghUiakWJWZjzX8JfibMrj54j805zy6dUMyLb4Y1OGGbD3Z50ow/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-4-1 迁移问题&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图2-4-1所示，箭头左侧描述了因为迁移影响的三种线上类型。第一种是因为迁移会触发最旧读，同步大量的数据，在这个过程中会首先将数据回刷到PageCache上引起PageCache污染，导致某个实时读的分区发生Cache Miss，触发磁盘度进而影响读写请求；第二种是当存在某些异常节点导致迁移Hang住时，部分运维操作无法执行，比如流量上涨触发的Topic自动扩分区。因为在Kafka迁移过程中这类运维操作被禁止执行。第三种和第二种类似，它的主要问题是当目标节点Crash，Topic扩分区也无法完成，用户可能一直忍受读写请求受影响。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;481&quot; data-ratio=&quot;0.83203125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2vUgult7YLNYibLgZS1weeF9IGTKwOKDGFB5OyyhZa6GYOLiaYYVqibAQw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-4-2 迁移取消&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对上面提到的3种问题，我们支持了迁移取消功能。管理员可以调用迁移取消命令，中断正在迁移的分区，针对第一种场景，PageCache就不会被污染，实时读得以保证；在第二、三种场景中，因为迁移取消，扩分区得以完成。迁移取消会删除未完成迁移的分区，删除可能会导致磁盘IO出现瓶颈影响读写，因此我们通过支持平滑删除避免大量删除引起的性能问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;优化三，Fetcher隔离&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;719&quot; data-ratio=&quot;1.24375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2Ma5q6bUXngHJGd4d92pr3NUL8VVUpEYxWSdCibKtibNGbQQNG5IIVWKw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-5 Fetcher隔离&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图2-5，绿色代表实时读，红色代表延时读。当某一个Follower的实时读和延时读共享同一个Fetcher时，延时读会影响实时读。因为每一次延时读的数据量是显著大于实时读的，而且延时读容易触发磁盘读，可能数据已经不在PageCache中了，显著地拖慢了Fetcher的拉取效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这种问题，我们实施的策略叫Fetcher隔离。也就是说所有ISR的Follower共享Fetcher，所有非ISR的Follower共享Fetcher，这样就能保证所有ISR中的实时读不会被非ISR的回溯读所影响。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;③ Consumer异步化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;457&quot; data-ratio=&quot;0.81328125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2ZU9JDCpdyvNghySib2YpzQTgBF7drSibSeZkSALPCkYIYauIibCY8eyicg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-6 Kafka-Broker分阶段延时统计模型&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在讲述Consumer异步化前，需要解释下图2-6展示的Kafka-Broker分阶段延时统计模型。Kafka-Broker端是一个典型的事件驱动架构，各组件通过队列通信。请求在不同组件流转时，会依次记录时间戳，最终就可以统计出请求在不同阶段的执行耗时。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;具体来说，当一个Kafka的Producer或Consumer请求进入到Kafka-Broker时，Processor组件将请求写入RequestQueue，RequestHandler从RequestQueue拉取请求进行处理，在RequestQueue中的等待时间是RequestQueueTime，RequestHandler具体的执行时间是LocalTime。当RequestHandler执行完毕后会将请求传递给DelayedPurgatory组件中，该组件是一个延时队列。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当触发某一个延时条件完成了以后会把请求写到ResponseQueue中，在DelayedPurgatory队列持续的时间为RemoteTime，Processor会不断的从ResponseQueue中将数据拉取出来发往客户端，标红的ResponseTime是可能会被客户端影响的，因为如果客户端接收能力不足，那么ResponseTime就会一直持续增加。从Kafka-Broker的视角，每一次请求总的耗时时RequestTotalTime，包含了刚才所有流程分阶段计时总和。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;597&quot; data-ratio=&quot;1.03203125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2CyqibVzfPBxSRlyMxBVjib1NasRrqHXZWxNFqIhpzxPOnVHlBdvspniaw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-7 Consumer异步化&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ResponseTime持续增加的主要问题是因为Kafka原生Consumer基于NIO的单线程模型存在缺陷。如图2-7所示，在Phase1，User首先发起Poll请求，Kafka-Client会同时向Broker1、Broker2和Broker3发送请求，Broker1的数据先就绪时，Kafka Client将数据写入CompleteQueue，并立即返回，而不是继续拉取Broker2和Broker3的数据。后续的Poll请求会直接从CompleteQueue中读取数据，然后直接返回，直到CompleteQueue被清空。在CompleteQueue被清空之前，即使Broker2和Broker3的端的数据已经就绪，也不会得到及时拉取。如图中Phase2，因为单线程模型存在缺陷导致WaitFetch这部分时长变大，导致Kafka-Broker的RespnseTime延时指标不断升高，带来的问题是无法对服务端的处理瓶颈进行精准的监控与细分。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;415&quot; data-ratio=&quot;0.71796875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj20YJA4AibxrkPW3nrjUw6xyKZ0UGgLzib9fBEqZvWofjQ5mPo0SSibB1qg/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-8 引入异步拉取线程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这个问题，我们的改进是引入异步拉取线程。异步拉取线程会及时地拉取就绪的数据，避免服务端延时指标受影响，而且原生Kafka并没有限制同时拉取的分区数，我们在这里做了限速，避免GC和OOM的发生。异步线程在后台持续不断地拉取数据并放到CompleteQueue中。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.3 系统层&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;① Raid卡加速&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;268&quot; data-ratio=&quot;0.4638888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj26JhuaiaaLMnxJbpRlNA16OlyL8GJib85tjkKFU1qaXmDPmRkCT5xlKrA/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-9 Raid卡加速&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;HDD存在随机写性能不足的问题，表现为延时升高，吞吐降低。针对这个问题我们引入了Raid卡加速。Raid卡自带缓存，与PageCache类似，在Raid这一层会把数据Merge成更大的Block写入Disk，更加充分利用顺序写HDD的带宽，借助Raid卡保证了随机写性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;② Cgroup隔离优化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;202&quot; data-ratio=&quot;0.34921875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2rZqr6Rs4nTZnZwxvQBWUiafZsVCCMAbEhJWKXyMWmaeohZiaWdtltcaw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-10 Cgroup隔离&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了提高资源利用率，美团数据平台将IO密集型应用和CPU密集型应用混合部署。IO密集型应用在这里指的就是Kafka，CPU密集型应用在这里指的是Flink和Storm。但是原有的隔离策略存在两个问题：首先是物理核本身会存在资源竞争，在同一个物理核下，共享的L1Cache和L2Cache都存在竞争，当实时平台CPU飙升时会导致Kafka读写延时受到影响；其次，Kafka的HT跨NUMA，增加内存访问耗时，如图2-10所示，跨NUMA节点是通过QPI去做远程访问，而这个远程访问的耗时是40ns。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这两个问题，我们改进了隔离策略，针对物理核的资源竞争，我们新的混布策略保证Kafka独占物理核，也就是说在新的隔离策略中，不存在同一个物理核被Kafka和Flink同时使用；然后是保证Kafka的所有超线程处于同一侧的NUMA，避免Kafka跨NUMA带来的访问延时。通过新的隔离策略，Kafka的读写延时不再受Flink CPU飙升的影响。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.4 混合层-SSD新缓存架构&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;211&quot; data-ratio=&quot;0.36484375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2fibwiadZs6cxoTvMGcmYibPZvgJaohozRrsMdwhksSZtqu8rm5lNDGibpg/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-11 Page污染引起的性能问题&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;背景和挑战&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kafka利用操作系统提供的ZeroCopy技术处理数据读取请求，PageCache容量充裕时数据直接从PageCache拷贝到网卡，有效降低了读取延时。但是实际上，PageCache的容量往往是不足的，因为它不会超过一个机器的内存。容量不足时，ZeroCopy就会触发磁盘读，磁盘读不仅显著变慢，还会污染PageCache影响其他读写。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图2-11中左半部分所示，当一个延迟消费者去拉取数据时，发现PageCache中没有它想要的数据，这个时候就会触发磁盘读。磁盘读后会将数据回写到PageCache，导致PageCache污染，延迟消费者消费延迟变慢的同时也会导致另一个实时消费受影响。因为对于实时消费而言，它一直读的是最新的数据，最新的数据按正常来说时不应该触发磁盘读的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;选型和决策&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这个问题，我们这边在做方案选型时提供了两种方案：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;方案一&lt;/strong&gt;，读磁盘时不回写PageCache，比如使用DirectIO，不过Java并不支持；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;方案二&lt;/strong&gt;，在内存和HDD之间引入中间层，比如SSD。众所周知，SSD和HDD相比具备良好的随机读写能力，非常适合我们的使用场景。针对SSD的方案我们也有两种选型：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.72265625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUAT8icebFDacQnwjohib3fj21EIrzGiaqFjhjDNPejt7QDnH3DJfaLBwdkC2hUr2giafBB8iacw95jgNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;方案一&lt;/strong&gt;，可以基于操作系统的内核实现，这种方案SSD与HDD存储空间按照固定大小分块，并且SSD与HDD建立映射关系，同时会基于数据局部性原理，Cache Miss后数据会按LRU和LFU替换SSD中部分数据，业界典型方案包括OpenCAS和FlashCache。其优势是数据路由对应用层透明，对应用代码改动量小，并且社区活跃可用性好；但是问题在于局部性原理并不满足Kafka的读写特性，而且缓存空间污染问题并未得到根本解决，因为它会根据LRU和LFU去替换SSD中的部分数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;方案二&lt;/strong&gt;，基于Kafka的应用层去实现，具体就是Kafka的数据按照时间维度存储在不同设备上，对于近实时数据直接放在SSD上，针对较为久远的数据直接放在HDD上，然后Leader直接根据Offset从对应设备读取数据。这种方案的优势是它的缓存策略充分考虑了Kafka的读写特性，确保近实时的数据消费请求全部落在SSD上，保证这部分请求处理的低延迟，同时从HDD读取的数据不回刷到SSD防止缓存污染，同时由于每个日志段都有唯一明确的状态，因此每次请求目的明确，不存在因Cache Miss带来的额外性能开销。同时劣势也很明显，需要在Server端代码上进行改进，涉及的开发以及测试的工作量较大。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;272&quot; data-ratio=&quot;0.4703125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj25azWiclDZhDplnRNqbZnNoIWumiaTAnM3L5dgB6EZm5hbibfUB3etS9icg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-13 KafkaSSD新缓存架构&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;具体实现&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面来介绍一下SSD新缓存架构的具体实现。&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先新的缓存架构会将Log内的多个Segment按时间维度存储在不同的存储设备上，如图2-14中的红圈1，新缓存架构数据会有三种典型状态，一种叫Only Cache，指的是数据刚写进SSD，还未同步到HDD上；第2个是Cached，指数据既同步到了HDD也有一部分缓存在SSD上；第三种类型叫WithoutCache，指的是同步到了HDD但是SSD中已经没有缓存了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;然后后台异步线程持续地将SSD数据同步到HDD上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随着SSD的持续写入，当存储空间达到阈值后，会按时间顺序删除距当前时间最久的数据，因为SSD的数据空间有限。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;副本可根据可用性要求灵活开启是否写入SSD。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从HDD读取的数据是不会回刷到SSD上的，防止缓存污染。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;239&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;302&quot; data-ratio=&quot;1.2652519893899203&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2vibOGzCvFoNy27lLfNf4Ehk7XpurCV0NJltQJlaicW1EDVTqJVHibViaag/640?wx_fmt=jpeg&quot; data-w=&quot;754&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2-14 SSD新缓存架构细节优化&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;细节优化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;介绍了具体实现之后，再来看一下细节优化。&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先是关于日志段同步，就是刚才说到的Segment，只同步Inactive的日志段，Inactive指的是现在并没有在写的日志段，低成本解决数据一致性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;其次是做同步限速优化，在SSD向HDD同步时是需要限速的，同时保护了两种设备，不会影响其他IO请求的处理。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 大规模集群管理优化&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1 隔离策略&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;美团大数据平台的Kafka服务于多个业务，这些业务的Topic混布在一起的话，很有可能造成不同业务的不同Topic之间相互影响。此外，如果Controller节点同时承担数据读写请求，当负载明显变高时，Controller可能无法及时控制类请求，例如元数据变更请求，最终可能会造成整个集群发生故障。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这些相互影响的问题，我们从业务、角色和优先级三个维度来做隔离优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;615&quot; data-ratio=&quot;1.0640625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2D3nGL0s7SXSGjZWX0owfLIbHKd7fxcoJpYvWCRibDib9HIsw7lBF55wA/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;p&gt;&lt;span&gt;图3-1 隔离优化&lt;/span&gt;&lt;/p&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.2 全链路监控&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;随着集群规模增长，集群管理碰到了一系列问题，主要包括两方面：&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Broker端延时指标无法及时反应用户问题。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;随着请求量的增长，Kafka当前提供的Broker端粒度的TP99甚至TP999延时指标都可能无法反应长尾延时。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Broker端的延时指标不是端到端指标，可能无法反应用户的真实问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;故障感知和处理不及时。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;502&quot; data-ratio=&quot;0.8671875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2c0pOrlkicVbJBicqaeQS8icCrHCbOAqs6GTOxiaog9xoa4DuIS1M1B2zDw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3-2 全链路监控&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这两个问题，我们采取的策略是全链路监控。全链路监控收集和监控Kafka核心组件的指标和日志。全链路监控架构如图3-2所示。当某一个客户端读写请求变慢时，我们通过全链路监控可以快速定位到具体慢在哪个环节，全链路指标监控如图3-3所示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;239&quot; data-ratio=&quot;0.412962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2weDFeOqdxu0LjVdTdDfricB70UWAB7TGHn4Zbs73et757Qdiaicwn5ceA/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3-3 全链路指标监控&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图3-4是一个根据全链路指标定位请求瓶颈的示例，可以看出服务端RemoteTime占比最高，这说明耗时主要花费在数据复制。日志和指标的解析服务可以自动实时感知故障和慢节点，大部分的故障（&lt;/span&gt;&lt;span&gt;内存、磁盘、Raid卡以及网卡等&lt;/span&gt;&lt;span&gt;）和慢节点都已经支持自动化处理，还有一类故障是计划外的故障，比如分区多个副本挂掉导致的不可用，迁移Hang住以及非预期的错误日志等，需要人工介入处理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;309&quot; data-ratio=&quot;0.534375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2J3gdNqwIbSD2L9cH1kY0FZBzA2w3ur45pSSoXkWCpHLCak7UP8noKQ/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3-4 全链路监控指标示例&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3 服务生命周期管理&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;384&quot; data-ratio=&quot;0.66328125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2P6Q8zQLmfZ4FoehZqNz9zp5lWzoSDiaWbATUPgshXiaLtFibFEYshIDbg/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3-5 服务生命周期管理&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;美团线上Kafka的服务器规模在万级别，随着服务规模的增长，我们对服务和机器本身的管理，也在不断迭代。我们的自动化运维系统能够处理大部分的机器故障和服务慢节点，但对于机器和服务本身的管理是割裂的，导致存在两类问题：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;状态语义存在歧义，无法真实反映系统状态，往往需要借助日志和指标去找到真实系统是否健康或者异常。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;状态不全面，异常Case需人工介入处理，误操作风险极大。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;为了解决这两类问题，我们引入了生命周期管理机制，确保能够真实反映系统状态。生命周期管理指的是从服务开始运行到机器报废停止服务的全流程管理，并且做到了服务状态和机器状态联动，无需人工同步变更。而且新的生命周期管理机制的状态变更由特定的自动化运维触发，禁止人工变更。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.4 TOR容灾&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;205&quot; data-ratio=&quot;0.3546875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2uyDLXxwcWc24YmP05yRsd1icg9lODl8gRiaUnxKjiad2tDXM28pXvYA6g/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3-6 TOR容灾挑战&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们从工程实现的角度，归纳总结了当前主流图神经网络模型的基本范式，实现一套通用框架，以期涵盖多种GNN模型。以下按照图的类型（&lt;/span&gt;&lt;span&gt;同质图、异质图和动态图&lt;/span&gt;&lt;span&gt;）分别讨论。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;318&quot; data-ratio=&quot;0.55&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsUAT8icebFDacQnwjohib3fj2rTQrSvyewmCpwzok7HKOnhcCeZI5spE4hauSUnVw5sXsvic1VXDiaibUw/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3-7 TOR容灾&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;TOR容灾保证同一个分区的不同副本不在同一个Rack下，如图3-7所示，即使Rack1整个发生故障，也能保证所有分区可用。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4 未来展望&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;过去一段时间，我们围绕降低服务端的读写延迟做了大量的优化，但是在服务高可用方面，依然有一些工作需要完成。未来一段时间，我们会将重心放在提升鲁棒性和通过各种粒度的隔离机制缩小故障域。比如，让客户端主动对一些故障节点进行避让，在服务端通过多队列的方式隔离异常请求，支持服务端热下盘，网络层主动反压与限流等等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;另外，随着美团实时计算业务整体的发展，实时计算引擎（&lt;/span&gt;&lt;span&gt;典型如Flink&lt;/span&gt;&lt;span&gt;）和流存储引擎（&lt;/span&gt;&lt;span&gt;典型如Kafka&lt;/span&gt;&lt;span&gt;）混合部署的模式越来越难以满足业务的需求。因此，我们需要在保持当前成本不变的情况下对Kafka进行独立部署。这就意味着需要用更少的机器（&lt;/span&gt;&lt;span&gt;在我们的业务模式下，用原来1/4的机器&lt;/span&gt;&lt;span&gt;）来承载不变的业务流量。如何在保障服务稳定的情况下，用更少的机器扛起业务请求，也是我们面临的挑战之一。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;最后，随着云原生趋势的来临，我们也在探索流存储服务的上云之路。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5 作者简介&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;海源、仕禄、肖恩、鸿洛、启帆、胡荣、李杰等，均来自美团数据科学与平台部。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;----------  END  ----------&lt;/span&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;也许你还想看&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651756933&amp;amp;idx=1&amp;amp;sn=a23c294fe1873d6b2c50730e47eda608&amp;amp;chksm=bd1240c88a65c9de720b8568bf7cf90a365c1df45732a36493eb58cc1ff8cf8461cb4829f102&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;基于SSD的Kafka应用层缓存架构设计与实现&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651756933&amp;amp;idx=1&amp;amp;sn=a23c294fe1873d6b2c50730e47eda608&amp;amp;chksm=bd1240c88a65c9de720b8568bf7cf90a365c1df45732a36493eb58cc1ff8cf8461cb4829f102&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;基于SSD的Kafka应用层缓存架构设计与实现&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;基于SSD的Kafka应用层缓存架构设计与实现&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt;&lt;/span&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=203083582&amp;amp;idx=1&amp;amp;sn=701022c664d42b54b55d43e6bc46056b&amp;amp;chksm=2f06167318719f65e90a8154a48e875f474c56e47b66aa6607f27c9ba6779ae062195720e6f6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团技术团队博客：Kafka文件存储机制那些事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团技术团队博客：Kafka文件存储机制那些事&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651761795&amp;amp;idx=1&amp;amp;sn=49a812ee8b9bf1cae5bd088c53772007&amp;amp;chksm=bd1275ce8a65fcd8cb960cf727125c8462022c39e50a314bc79a60737a75909b26791c37536e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团酒旅数据治理实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团酒旅数据治理实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阅读更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;---&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765958&amp;amp;idx=1&amp;amp;sn=8201546812e5a95a2bee9dffc6d12f00&amp;amp;chksm=bd12658b8a65ec9de2f5be1e96796dfb3c8f1a374d4b7bd91266072f557caf8118d4ddb72b07&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;前‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;前端&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt; &lt;/strong&gt; &lt;/span&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765981&amp;amp;idx=1&amp;amp;sn=c2dd86f15dee2cbbc89e27677d985060&amp;amp;chksm=bd1265908a65ec86d4d08f7600d1518b61c90f6453074f9b308c96861c045712280a73751c73&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;算‍法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;算法&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765982&amp;amp;idx=1&amp;amp;sn=231b41f653ac7959f3e3b8213dcec2b0&amp;amp;chksm=bd1265938a65ec85630c546169444d56377bc2f11401d251da7ca50e5d07e353aa01580c7216&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;后‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;后端&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765964&amp;amp;idx=1&amp;amp;sn=ab6d8db147234fe57f27dd46eec40fef&amp;amp;chksm=bd1265818a65ec9749246dd1a2eb3bf7798772cc4d5b4283b15eae2f80bc6db63a1471a9e61e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数‍据&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;数据&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765965&amp;amp;idx=1&amp;amp;sn=37e0c56c8b080146ce5249243bfd84d8&amp;amp;chksm=bd1265808a65ec96d3a2b2c87c6e27c910d49cb6b149970fb2db8bf88045a0a85fed2e6a0b84&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;安‍全&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;安全&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765972&amp;amp;idx=1&amp;amp;sn=afe02ec92762c1ce18740d03324c4ac3&amp;amp;chksm=bd1265998a65ec8f10d5f58d0f3681ddfc5325137218e568e1cda3a50e427749edb5c6a7dcf5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;And‍roid&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Android&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765973&amp;amp;idx=1&amp;amp;sn=32a23bf1d278dda0398f993ab60a697e&amp;amp;chksm=bd1265988a65ec8e630ef4d24b4946ab6bd7e66702c1d712481cf3c471468a059c470a14c30d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;iO‍S&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;iOS&lt;/span&gt;&lt;/a&gt;&lt;span&gt; &lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765963&amp;amp;idx=1&amp;amp;sn=a3de9ef267d07d94118c1611776a4b28&amp;amp;chksm=bd1265868a65ec906592d25ad65f2a8516338d07ec3217059e6975fc131fc0107d66a8cd2612&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;运‍维&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;运维&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765974&amp;amp;idx=1&amp;amp;sn=763c1e37d04acffd0142a2852ecfb000&amp;amp;chksm=bd12659b8a65ec8dfcfeb2028ef287fae7c38f134a665375ba420556ce5d2e4cf398147bd12e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测‍试&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;测试&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5NjQ5MTI5OA==&quot; data-alias=&quot;meituantech&quot; data-from=&quot;0&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVGibnsaEib3aNlqF0tOrA2RGEmNSbia2nnohE4Tpf95UyTiaSjDVbHRfY8WNBeTuLLTaVdSckkNyEx1Q/0?wx_fmt=png&quot; data-nickname=&quot;美团技术团队&quot; data-signature=&quot;10000+工程师，如何支撑中国领先的生活服务电子商务平台？数亿消费者、数百万商户、2000多个行业、几千亿交易额背后是哪些技术在支撑？这里是美团、大众点评、美团外卖、美团配送、美团优选等技术团队的对外窗口。&quot;/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>05755f578c83453bbea5c6cb373aef28</guid>
<title>解决方案 - 自动化单元测试</title>
<link>https://toutiao.io/k/0geaxdx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;前言&lt;/h2&gt;&lt;p&gt;收到读者的咨询，情况是这样的：&lt;/p&gt;&lt;p&gt;“亮哥，看了你最近的 8 篇关于持续交付的文章，想咨询一下对于研发人员有没有可落地的方案，我是 PHP 研发工程师，项目中使用的是 Laravel 框架，负责的是电商业务，如何将持续交付使用起来呢？”&lt;/p&gt;&lt;p&gt;今天有时间，简单整理一下，首先我们要知道持续交付涉及的事情很多，涉及的人员角色也很广，比如包括需求分析人员、技术人员、运维人员、测试人员、客户 等。关于这个问题，文章中理论的部分很到位，目前我们主要从技术人员的角度考虑，做一些 &lt;strong&gt;技术导向且支持开发过程的测试&lt;/strong&gt; ，实现一个可落地的方案，等拿到代码后就可以在此基础上编写，虽然不是很全面，但可以在此基础上进行扩展。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;约定测试 Case&lt;/h2&gt;&lt;p&gt;以电商业务为例，简单列举 2 个测试 Case：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;下单(从购物车下单) -&amp;gt; 支付(优惠券 + 余额) -&amp;gt; 发货 -&amp;gt; 收货 -&amp;gt; 评价；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;下单(直接下单) -&amp;gt; 支付(微信) -&amp;gt; 发货 -&amp;gt; 收货 -&amp;gt; 退款(售后)；&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;实际场景中有很多 Case，比如就支付这块就有很多种排列组合，退款这块也会有很多排列组合，原理都是一样的，只要上面的两个会写了，其他的也就都会写了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;项目分析&lt;/h2&gt;&lt;p&gt;Case 中的不同环节的不同操作，对于后端来说都是可供调用的 API 接口，其实我们要实现的就是如何自动化按照流程自定义流程顺序调用这些 API 接口。&lt;/p&gt;&lt;p&gt;项目的框架是 Laravel，那么我们考虑的就是在框架中如何编写单元测试代码？这个比较简单，在 &lt;code&gt;tests&lt;/code&gt; 目录就可以编写测试用例。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;用例编写&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;安装 orchestra/testbench&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;composer require --dev &lt;span&gt;&quot;orchestra/testbench&quot;&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;使用这个包，可以帮助编写 Laravel 项目测试，在这里面可以使用 Laravel 中的一些特性。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;创建 BaseTestCase.php&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;&amp;lt;?php&lt;br/&gt;&lt;br/&gt;namespace Tests;&lt;br/&gt;&lt;br/&gt;abstract class BaseTestCase extends \Orchestra\Testbench\TestCase&lt;br/&gt;{&lt;br/&gt;&lt;br/&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;要注意的是 extends &lt;code&gt;\Orchestra\Testbench\TestCase&lt;/code&gt; 而不是 &lt;code&gt;PHPUnit\Framework\TestCase&lt;/code&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;创建 OrderTest.php&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;&amp;lt;?php&lt;br/&gt;&lt;br/&gt;namespace Tests\Unit;&lt;br/&gt;&lt;br/&gt;use Tests\BaseTestCase;&lt;br/&gt;&lt;br/&gt;class OrderTest extends BaseTestCase&lt;br/&gt;{&lt;br/&gt;    /**&lt;br/&gt;     * 流程：&lt;br/&gt;     * 1.下单(从购物车下单)&lt;br/&gt;     * 2.支付(优惠券 + 余额)&lt;br/&gt;     * 3.发货&lt;br/&gt;     * 4.收货&lt;br/&gt;     * 5.评价&lt;br/&gt;     */&lt;br/&gt;    public &lt;span&gt;function&lt;/span&gt; &lt;span&gt;&lt;span&gt;testCase1&lt;/span&gt;&lt;/span&gt;()&lt;br/&gt;    {&lt;br/&gt;        // 1.下单(从购物车下单)&lt;br/&gt;&lt;br/&gt;        // 2.支付(优惠券 + 余额)&lt;br/&gt;&lt;br/&gt;        // 3.发货&lt;br/&gt;&lt;br/&gt;        // 4.收货&lt;br/&gt;&lt;br/&gt;        // 5.评价&lt;br/&gt;&lt;br/&gt;        /**&lt;br/&gt;         * 1.在每个流程中都模拟调用 HTTP API 接口；&lt;br/&gt;         * 2.断言 HTTP 状态码为 200；&lt;br/&gt;         * 3.如果还有业务状态码，需要断言业务状态码为正确返回的状态码；&lt;br/&gt;         */&lt;br/&gt;        &lt;br/&gt;        // 仅做效果演示，断言 200 = 200，总是真 &lt;br/&gt;        &lt;span&gt;$this&lt;/span&gt;-&amp;gt;assertEquals(200, 200);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 流程：&lt;br/&gt;     * 1.下单(直接下单)&lt;br/&gt;     * 2.支付(微信)&lt;br/&gt;     * 3.发货&lt;br/&gt;     * 4.收货&lt;br/&gt;     * 5.退款(售后)&lt;br/&gt;     */&lt;br/&gt;    public &lt;span&gt;function&lt;/span&gt; &lt;span&gt;&lt;span&gt;testCase2&lt;/span&gt;&lt;/span&gt;()&lt;br/&gt;    {&lt;br/&gt;        // 1.下单(直接下单)&lt;br/&gt;&lt;br/&gt;        // 2.支付(微信)&lt;br/&gt;&lt;br/&gt;        // 3.发货&lt;br/&gt;&lt;br/&gt;        // 4.收货&lt;br/&gt;&lt;br/&gt;        // 5.退款(售后)&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;$this&lt;/span&gt;-&amp;gt;assertEquals(200, 200);&lt;br/&gt;    }&lt;br/&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;输出结果美化&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;composer require --dev codedungeon/phpunit-result-printer&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;使用这个工具，可以让输出结果更加美观、清晰明了。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;phpunit.xml&lt;/code&gt; 中配置 &lt;code&gt;printerClass = &quot;Codedungeon\PHPUnitPrettyResultPrinter\Printer&quot;&lt;/code&gt;，例如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;&amp;lt;?xml version=&lt;span&gt;&quot;1.0&quot;&lt;/span&gt; encoding=&lt;span&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;&lt;br/&gt;&amp;lt;phpunit&lt;br/&gt;    printerClass=&lt;span&gt;&quot;Codedungeon\PHPUnitPrettyResultPrinter\Printer&quot;&lt;/span&gt;&lt;br/&gt;    colors=&lt;span&gt;&quot;true&quot;&lt;/span&gt;&amp;gt;&lt;br/&gt;    &amp;lt;testsuites&amp;gt;&lt;br/&gt;        &amp;lt;testsuite name=&lt;span&gt;&quot;Laravel Test Suite&quot;&lt;/span&gt;&amp;gt;&lt;br/&gt;            &amp;lt;directory suffix=&lt;span&gt;&quot;Test.php&quot;&lt;/span&gt;&amp;gt;./tests&amp;lt;/directory&amp;gt;&lt;br/&gt;        &amp;lt;/testsuite&amp;gt;&lt;br/&gt;    &amp;lt;/testsuites&amp;gt;&lt;br/&gt;&amp;lt;/phpunit&amp;gt;&lt;/p&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;效果&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;./vendor/bin/phpunit tests/Unit/OrderTest.php&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;185&quot; data-backw=&quot;535&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.34579439252336447&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/go9jpG3BuhT0YeicpYv8cf8HvGy2FE9M1C0K00HzpjfuVpHIxkAZobvs8qkmFQ4Rp3CjzJ0SmQLIMD92BrWYIdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;535&quot;/&gt;&lt;/p&gt;&lt;p&gt;两个绿色对勾，表示两个 Case 执行通过。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;疑问&lt;/h2&gt;&lt;p&gt;一、有同学会说了，这不是自动化的呀，需要手动执行一个命令才行，如果你们发布系统使用的 GitLab，那么在 GitLab 中增加一个环节即可，在这个环节中执行这个命令。&lt;/p&gt;&lt;p&gt;二、如果执行项目内全部的 case 怎么办？命令这样写就可以 &lt;code&gt;./vendor/bin/phpunit tests&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;三、Case 一定 API 测试吗？不一定，也可以测试自己的方法。&lt;/p&gt;&lt;p&gt;四、持续集成/持续交付与语言有关系吗？没关系。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;小结&lt;/h2&gt;&lt;p&gt;以上，就是一个可落地的方案，基本上跑通了，在此基础上编写就可以，根据自己的业务场景去完善吧。&lt;/p&gt;&lt;p&gt;在这做个小调查，大家在项目中都编写测试用例吗，为什么？欢迎大家在留言区评论。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;推荐阅读&lt;/h2&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836808&amp;amp;idx=1&amp;amp;sn=bd6315970e64e472d9796ac7e2888f09&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(1) - 软件交付的问题&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836813&amp;amp;idx=1&amp;amp;sn=540c11de05f6138fadf7d8b55d110577&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(2) - 配置管理&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836820&amp;amp;idx=1&amp;amp;sn=861b7ba1bf4d6e9563e564fb9403ad1b&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(3) - 持续集成&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836826&amp;amp;idx=1&amp;amp;sn=26174bd491f88d7e64ae1df26bd233c1&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(4) - 测试策略的实现&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836831&amp;amp;idx=1&amp;amp;sn=269d2cd64dbd698e3fb7396c878e2968&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(5) - 部署流水线解析&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836837&amp;amp;idx=1&amp;amp;sn=3b9950ca54d37c445af6caf420386bb4&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(6) - 构建与部署的脚本化&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836842&amp;amp;idx=1&amp;amp;sn=67f9f89f8b3574b146ce2263b89c7641&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(7) - 提交阶段&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;amp;mid=2448836847&amp;amp;idx=1&amp;amp;sn=bcf03ac871807f64fc5dfd87e8aa9393&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;持续交付(8) - 自动化验收测试&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5NDM4MDIwNw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/go9jpG3BuhQHrM0sshKxdaibyDNjXooZvnwwy0yRjdhlXrtVUkJSvQib4Ppwib1v5HucaRc8WPtgvhPBicMeiadAv9Q/0?wx_fmt=png&quot; data-nickname=&quot;新亮笔记&quot; data-alias=&quot;XinLiangTalk&quot; data-signature=&quot;日拱一卒&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;307&quot; data-backw=&quot;558&quot; data-ratio=&quot;0.5493333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/go9jpG3BuhSP7wibS4BHtlu4hduFYq8VbSAgRic8ib6hdd6qTRGxYSic7UFF9yPyGd4pGUw1XicibFRlGHBe9RJ09Smw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b249c61261f915729412663b3ff72f38</guid>
<title>浅谈数仓模型（维度建模）</title>
<link>https://toutiao.io/k/homv8cz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;傅一平评语：&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;文章通俗易懂，对于维度建模的介绍很清晰，要方法有方法，要案例有案例，而且还反着来，对数仓分层的误区、维度建模的缺点、宽表的误区都做了探讨，值得仔细读一读！&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;正文开始&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;本文目录：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、背景&lt;br/&gt;二、数据仓库介绍&lt;br/&gt;三、维度建模介绍&lt;br/&gt;四、维度建模案例&lt;br/&gt;五、数仓分层&lt;br/&gt;六、问题&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、背景&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据仓库的核心是展现层和提供优质的服务。ETL 及其规范、分层等所做的一切都是为了一个更清晰易用的展现层&lt;/strong&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 数仓架构的原则：&lt;/span&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;底层业务的数据驱动为导向同时结合业务需求驱动&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;便于数据分析&lt;br/&gt;屏蔽底层复杂业务&lt;br/&gt;简单、完整、集成的将数据暴露给分析层&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;底层业务变动与上层需求变动对模型冲击最小化&lt;br/&gt;业务系统变化影响削弱在基础数据层（资金订单改造）&lt;br/&gt;结合自上而下的建设方法削弱需求变动对模型的影响&lt;br/&gt;数据水平层次清晰化&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;高内聚松耦合&lt;br/&gt;主题之内或各个完整意义的系统内数据的高内聚&lt;br/&gt;主题之间或各个完整意义的系统间数据的松耦合&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;构建仓库基础数据层&lt;br/&gt;使得底层业务数据整合工作与上层应用开发工作相隔离，为仓库大规模开发奠定基础&lt;br/&gt;仓库层次更加清晰，对外暴露数据更加统一&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓模型不只是考虑如何设计和实现功能，设计原则应该从访问性能、数据成本、使用成本、数据质量、扩展性来考虑。如何搭建一个好的数据仓库：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23oFYliablaKnibkyFbWsiaUpeaQuAiadwv9JgblANYYSP7yLdSXIeQOObqA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.2712962962962963&quot; data-w=&quot;1080&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓设计的3个维度：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy2344LyRfKX33l9yKuWiajBm65ibdnTj6cZWvNxoARBOrXUFIWOwOK9Q8og/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 主流建模方法&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当前主流建模方法为：&lt;strong&gt;ER模型、维度模型&lt;/strong&gt;。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ER模型常用于OLTP数据库建模，应用到构建数仓时更偏重数据整合， 站在企业整体考虑，将各个系统的数据按相似性一致性、合并处理，为数据分析、决策服务，但并不便于直接用来支持分析。&lt;em&gt;缺陷&lt;/em&gt;：需要全面梳理企业所有的业务和数据流，周期长，人员要求高。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度建模是面向分析场景而生，针对分析场景构建数仓模型；重点关注快速、灵活的解决分析需求，同时能够提供大规模数据的快速响应性能。针对性强，主要应用于数据仓库构建和OLAP引擎低层数据模型。&lt;em&gt;优点&lt;/em&gt;：不需要完整的梳理企业业务流程和数据，实施周期根据主题边界而定，容易快速实现demo，而且相对来说便于理解、提高查询性能、对称并易扩展。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为大数据板块，数据来源更加广泛，针对的业务域也更加宽广，所以维度建模相对来说更加灵活并适用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在讨论维度建模之前，关注数仓和BI的基本目标是非常有意义的，在做日常的数据需求的时候，经常会遇到如下几个痛点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;收集了海量数据，不知道如何去做ETL；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;不同来源的数据该如何去聚合；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如何方便业务人员快速方便的获取数据；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如何定义重要的数据指标；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如何确保数据准确性；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据如何支持决策；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于上面的痛点，就需要搭建一套DW/BI系统（当然现在市面上有很多类似的产品，例如：如：QuickBI、GrowingIO、神策、猛犸等等），但是对于公司而言，适合自己的才是最好的，大部分公司选择自己搭建或者利用开源的软件（例如MateBase），这个系统必须满足：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DW/BI系统能够方便的存储信息（或者说能跟现在主流的数据库打通）。也就是说系统展现的内容必须是容易理解的，对于业务人员必须直观而且好操作，数据结构和标示必须符合业务思维过程和词汇，用户能够以各种形式切割和分析数据，同时能够快速的将查询结果反馈。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DW/BI系统必须以一致性的形式展现信息（指标的唯一性）。也就是说数据必须是可信的，同一指标定义在不同的数据源中，所含的意义必须相同，既同名同意性。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DW/BI系统能够适应变化（模块的低耦合）。当用户需求、业务维度需要调整的调整的时候，设计的DW模型必须能够兼容这些变化，已经存在数据和指标不应该被破坏或修改，就算一些指标的调整，也要以适当的方式描述变化，并对用户完全透明。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DW/BI系统必须保证数据安全（数据安全）。能展示的数据必须是统计的结果数据，一些详单展现和下载必须和平台的权限系统挂钩，避免数据泄漏。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DW/BI系统成功的标示是业务群体接收并使用，而且必须配套一个展现模块的监控系统，能够让产品方知道各个模块的使用情况，对一些访问量比较少的模块可以适当的调整和优化。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、数据仓库介绍&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 定义&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库，由数据仓库之父Bill Inmon 在1991 年出版的“Building the Data Warehouse”定义且被广泛接受的——面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策。从定义上来看，数据仓库的关键词为面向主题、集成、稳定、反映历史变化、支持管理决策，而这些关键词的实现就体现在分层架构内。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说到数仓不可避免的和传统的数据库进行比对：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6236111111111111&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zEQAb6icpZtVhMdgWAUM6qYOyEQF6o2bu7icEDBUDo98ZLRpypQeUvaPMfDXgH23jJ1iaPia6jAE8N33Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以数仓是面向分析型的，主要集中在数据的ETL、数仓模型的建立、数据治理、数据质量的监控、数据资产的沉淀、数据指标体系的搭建，为了方便快速的达到数据获取和数据支撑的目的，同时规避了数据指标不统一造成的数据准确性不足的问题以及重复建设的冗余而建立的一套公司层面或者业务支撑层面的一套规范化数据流向的方案。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2722222222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zEQAb6icpZtVhMdgWAUM6qYOqB2w25Z6XRR5xKpFiaaVm1kFQlQDQ1R7J0sRRUKj54riaLZjcSLm3KibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 目的&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓的核心是解决 ETL 任务及工作流的组织、数据的流向、读写权限的控制、不同需求的满足等各类问题，并提供给分析人员一个清晰可用的展现层，方便快速的业务支撑。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 特征&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. 集成（面向主题）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据是分散的，由于事务处理应用分散、蜘蛛网问题、数据不一致问题、外部数据和非结构化数据。数据仓库中的数据是为分析服务的，而分析需要多种广泛的不同数据源以便进行比较、鉴别，因此数据仓库中的数据必须从多个数据源中获取，这些数据源包括多种类型数据库以及文件系统等，它们通过数据集成而形成数据仓库中的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这块的集成主要集中在数据源大量的数据预处理工作（ETL），通常的模型方式是通过E-R模型进行数据整合。目的将各个系统中的数据以整个企业角度按主题进行相似性组合和合并，并进行一致性处理，为数据分析决策服务，但是并不能直接用于分析决策。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般是公司总栈层面的整合，所以需要全面了解企业业务和数据；实施周期非常长，需要整合全部的数据，并在企业业务角度对数据进行相似性组合和合并，并进行一致性处理；对建模人员的能力要求非常高；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. 相对稳定（非易失）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库中的数据是经过抽取而形成的分析型数据，不具有原始性，主要供企业决策分析之用，执行的主要是‘查询’操作，一般情况下不执行‘更新’操作。同时，一个稳定的数据环境也有利于数据分析操作和决策的制订。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但这也不等于数据仓库中的数据不需要‘更新’操作。一般来说会建立数仓模型一些数据的生命周期管理，依据数仓数据的重要程度、数据调用情况等等指标，对已有的数据进行规范化管理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3. 反映历史变化（全量或者增量变更）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库中的数据必须以一定时间段为单位进行统一更新，因为数仓数据是支撑公司层面业务数据从开始到发展过程中的所有数据变化，所以需要进行数据全量存储，并记录历史变化的过程，方便业务数据能够溯源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;合并全量数据的方式有三种，分别为&lt;strong&gt;全量更新、增量变更及增量流水&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;全量更新&lt;/strong&gt;，数据抽取时把源系统表的数据全量抽取过来，这个一般是每天建立一个时间分区，保留全量的数据，不过缺点很明显就是太占存储空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;增量变更及增量流水&lt;/strong&gt;，数据抽取时把源系统表内变化的数据抽取过来。两者区别是，增量变更的数据除了包含新增数据外，还包含对历史数据有变更的数据，而增量流水的数据只包含新增数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;增量流水的数据处理方法相对简单，直接把增量数据入库到表内即可。增量变更的数据一般采用拉链模型来处理，这样既保证可以查询到任意时刻的历史全量快照，也可以减少数仓的存储空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，&lt;strong&gt;拉链模型有两个明显的缺陷&lt;/strong&gt;，一个是当发现拉链表内某一扣环的数据异常时，拉链表应如何恢复准确性与完整性，另一个是随着数据不断增加，拉链表会越来越大，每日拉链操作的效率会越来越低。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以在拉链和全量更新的时候，是根据业务表的具体情况来进行选择的。一般来说，数据量很大，但是每天更新的占的比重很少，才会选择拉链的模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数仓建设解决的痛点：&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;使用门槛高&lt;/strong&gt;：数据工作是一个专业性特别强的一个工作，对于人员的要求比较高。在一些数据的工作当中需要人员有专业的数据基础能力，这样就导致了数据人力的缺失，可能会影响业务的数据支持力度；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;口径不一致&lt;/strong&gt;：在使用数据过程当中，口径不一致是特别常见的一种问题，这种问题可能会导致一种数据使用和分析的差异，而且会降低业务的数据分析效率，最终对业务决策造成严重影响；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;数据可靠性低&lt;/strong&gt;：在生产过程中，降低业务的数据分析效率，最终会对业务决策造成严重的影响，不仅数据链路过程很长，其中还会引入很多数据质量问题。并且，由于环节过多，也带来了生产时间延迟的问题，可能直接影响到后续核心报表，推荐、模型的优化；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;跨业务难度大&lt;/strong&gt;：因为缺少一个统一的数据建设的规划、标准和规范，所以难以指导各个业务或者整个生产链路的各个环节，以拥有一个标准化的生产和处理过程，就导致了多个业务的数据难以融合，难以发挥更大的数据价值；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;接入成本高&lt;/strong&gt;：这主要应用在一个新的业务场景下，也就是说，如果有新的业务接入或者新的场景需要使用数据，很多工作都需要人工处理。去申请各种资源、权限、找数据并且串联整个数据的采集、生产、计算、同步和展示等各个环节，这是一个耗时长、效率低，最终还是很容易出错的过程；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;获取数据难&lt;/strong&gt;：可能在大家日常工作中会发现，我们数据的生产到最终使用，中间可能要经历一个比较长的时间周期或者一个比较宽的团队跨度，用户可能无法很快地找到想要的数据，或者数据团队生产出来的数据并没有真正触达到业务，来达到它的数据价值；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;数据资产模糊&lt;/strong&gt;：这个点可能和获取数据难有一点点关联，数据资产模糊的话更多的是在说我们需要对公司的数据资产做一个整体的管理，如果没有这个整体的管理，就会导致对数据资产的级别和我们自己拥有什么数据资产都很模糊。最终就是导致数据的优势难以发挥出来，而且虽然我们耗费了很多计算资源、人力资源、存储资源，但没有带来相应的价值，最终导致资源效率极低。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对上面的痛点，一般来说先是能够达到快速的业务支撑的目的，在期间不可避免的出现重复建设和数据指标不统一的问题，在业务发展到一定程度再去补充数据治理的能力和数据指标监控能力能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;治理工作的内容主要包括对数据和任务进行日常审计，然后通过数据血缘和使用情况，对数据的冗余度进行有效评估，并进行相应的优化，以减少资源和人力的浪费。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同时在生产过程中，如果出现生产不稳定的情况，我们也可以快速地发现问题，进而优化整个的生产链路，提高整个数据生态的健康度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不过有一点，在数仓模型建设过程中，需要先规范好一些维度：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据表创建的约束性：比如我们需要对表有的命名规范要求，如果没有一个工具去管理，可能会因为大家对规范的理解不一致，最终导致落地过程中依然存在各种各样的差异性；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据信息的可描述性：指在创建表的过程中，为了快速地满足业务，很少去添加一些相关的描述信息，导致数据缺少描述性。所以需要要求用户在数据创建的过程中把信息描述的足够精细，方便后续的数据使用过程；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据建模体系的完整性：指在数据开发过程中，要有整体的业务考虑，落地一些通用性的维表，避免用户为了快速地满足业务需求跳过某些过程，最终导致建模的扩展性较差；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、数据关系的维度与指标管理的系统性：数据的血缘关系、数据指标建立的标准、对外输出统一的指标和维度，促使我们后续数据表和字段的相互关系是有记录可查询的，而且数仓的指标是唯一和准确的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4375&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zEQAb6icpZtVhMdgWAUM6qYOlNBRicGOpHpCa8sNPjZkbibBicWk8hMlFKpvuXllgdYufFa6kvpmQqrFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然上面针对具体的公司，数仓这块的侧重点可能不一样，需要做的工作也不尽相同。目前我们公司的架构如图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.40555555555555556&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zEQAb6icpZtVhMdgWAUM6qYOvQQ5ao0Y8uFm801r5h6Pbth1KD0OaZNfq9tuIUW9xCkjxMJVlmwgzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三、维度建模介绍&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. DW/BI架构：&lt;/span&gt;&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5398148148148149&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23fC4RWrNLiaqdkxyJFKNe0DNEY3o3hrzPY1NjqdbibkfDibt9wc0ElyibHw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;源事务&lt;/strong&gt;：业务库或者日志等各个方面的数据源，一般不维护历史信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;ETL&lt;/strong&gt;：目的是构建和加载数据到展现区的目标维度模型中，划分维度和事实。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;模型&lt;/strong&gt;：围绕业务过程度量事件进行构建，为满足用户无法预估的需求，必须包含详细的原子数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为避免数据的冗余存储造成的浪费和低效，并方便多业务部门查询方便以及同一指标的数据准确性和业务的扩展性，一般采取以下的架构模式：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23Jqp1yBCKoiaOdnL9Bib8FpVfNAZkxw4qVCIVMc9raBrVVyRa0SvVVRtg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5351851851851852&quot; data-w=&quot;1080&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 维度建模&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用于度量的事实表，事实表一般会有两个或者多个外健与维度表的主键进行关联。事实表的主键一般是组合健，表达多对多的关系。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用于描述环境的维度表，单一主键。维度表的属性是所有查询约束和报表标示的来源。维度提供数据的入口点，提供所有DW/BI分析的最终标识和分组。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以维度建模表示每个业务过程包含的事实表，事实表里面存储事件的数值化度量，围绕事实表的是多个维度表，维度表包含事件发生的实际存在的文本环境。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3351851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23QausxwIovncm5kiawFiaxD1FmEYh59VeMh7CPGbYmTIwRXiacumbk4drQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从图表中能看出来，维度模型（星型模型）比较简单，而且适于变化，各个维度的地位相同。可根据业务情况进行新增或者修改（只要维度的单一值已经存在事实表中）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;雪花模型&lt;/strong&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy238z1W7k9O0uCFntEfaW2moyHMtO1D8FDicLjubAEXX934ibmBydGQIL1g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.6481481481481481&quot; data-w=&quot;1080&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;维度建模主要是4个主要决策：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;选择业务过程&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;业务过程是通常表示的是业务执行的活动，与之相关的维度描述和每个业务过程事件关联的描述性环境。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通常由某个操作型系统支持，例如：订单系统。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;业务过程建立或获取关键性能度量。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;一系列过程产生一系列事实表。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;声明粒度&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;粒度传递的是与事实表度量有关的细节级别。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;精确定义某个事实表的每一行表示什么。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;对事实表的粒度要达成共识。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;确认维度&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;健壮的维度集合来粉饰事实表。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度表示承担每个度量环境中所有可能的单值描述符。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;4&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;确认事实&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;不同粒度的事实必须放在不同的事实表中。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;事实表的设计完全依赖物理活动，不受最终报表的影响。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;事实表通过外健关联与之相关的维度。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;查询操作主要是基于事实表开展计算和聚合。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;其中粒度是非常重要的&lt;/strong&gt;，粒度用于确定事实表的行表示什么，建议从关注原子级别的粒度数据开始设计，因为原子粒度能够承受无法预估的用户查询，而且原子数据可以以各种可能的方式进行上卷，而一旦选择了高粒度，则无法满足用户下钻细节的需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实是整个维度建模的核心，其中雪花模型或者星型模型都是基于一张事实表通过外健关联维表进行扩展，生成一份能够支撑可预知查询需求的模型宽表，而且最后的查询也是落在事实表中进行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前常见的维度模型：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;星型模型&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每一个维表都与都与事实表相关联。数据冗余量较大&lt;/p&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;雪花模型&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有些维表可能不与事实表直接关联，而是通过其他维表关联到事实表。数据冗余量较小&lt;/p&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;星座模型&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由多个事实表相组合，维表是公共的。企业中一般都是星座模型&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度表的唯一主键应该是代理健而不是来自系统的标示符，也就是所谓的自然健，因为自然键通常具有一定的业务含义，但日久天长，这些信息是有可能发生变化的，而代理健可以提高关联效率并将关系数据库设计和业务的解耦。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度表和事实表关联的每个连接应该基于无含义的整数代理健。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;固定深度层次在维度表中应该扁平化，规范化的雪花模型不利于多属性浏览，而且大量的表和连接操作会影响性能。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;非完全独立的维度应该合并为一个维度，将同一层次的元素标示为事实表中不同维度是错误的，会增加查询和存储负担，最后变成蜈蚣表，例如：日维度、周维度、月维度等可以合并为一个周期维度。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;四、维度建模案例&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;维度建模是一个迭代设计过程，设计工作从总线矩阵中抽取实体级别的初始图形化模型开始，详细建模过程要深入定义、资源、关系、数据质量问题以及每张表的数据转换，主要目标是建立满足用户需求的模型，校验可加载到模型中的数据，为ETL提供明确的方向。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 雪花模型案例&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是一个以客户创建为事实表的售前流程的雪花模型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实表：客户创建信息表&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;维度表：销售信息表、店铺信息表、跟进表/约见表/风控通过表/订单表的维度上卷。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23M7egLoIel21lAGlmgl3XXfoSnOjNjhG60hib7ic3QeL4Ry4ibjvE0dUCQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.9046296296296297&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上面的维度模型可以聚合出创建、跟进、风控等各个维度的上层展现的数据。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 扩展：实时即未来&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前不少公司都在尝试以Flink、Kudu为基础的实时数仓架构，里面的数仓分层模型和离线的数仓架构基本相同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下图为实时数仓架构，离线和实时的差不多，具体实时的架构图见：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23DGicdWcH3VhSz1XXsIicFmhnWAib1OC3UdGwhmzbSGLsJmfYKRfxsQOYg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.8138888888888889&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ODS原始层是存放原始数据，主要是埋点数据（日志数据）和业务操作数据（binlong），数据源主要是Mysql、HDFS、Kafka等&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DW中间层主要存放ETL和主题汇总之后的中间层数据，这块又分为：&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DWD：事实表（data warehouse detail） 数据仓库明细表，以业务过程作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细层事实表。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DWS：事实表 （data warehouse summary） 数据仓库轻度汇总层，按照各个业务域进行轻度汇总成分析某一个主题域的服务数据，一般是宽表。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;DIM：维度表，公共维度层，基于维度建模理念思想，建立整个业务过程的一致性维度，主要使用 MySQL、Hbase、Redis 三种存储引擎，对于维表数据比较少的情况可以使用 MySQL，对于单条数据大小比较小，查询 QPS 比较高的情况，可以使用 Redis 存储，降低机器内存资源占用，对于数据量比较大，对维表数据变化不是特别敏感的场景，可以使用HBase 存储。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;DM数据集市层，以数据域+业务域的理念建设公共汇总层，对于DM层比较复杂，需要综合考虑对于数据落地的要求以及具体的查询引擎来选择不同的存储方式，分为轻度汇总层和高度汇总层。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;轻度汇总层以宽表的形式存在，主要是针对业务域进行快速方便的查询；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;高度汇总层由明细数据层或轻度汇总层通过聚合计算后写入到存储引擎中，产出一部分实时数据指标需求，灵活性比较差，主要做大屏展现。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;4&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;理论上上面还一APP层，应用层，主要是通过这几层之后，生成轻度或者高度汇总的数据，然后根据业务域进行接口封装提供给上层使用。但是实时数仓面临以下几个实施关键点：&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;端到端数据延迟、数据流量的监控；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;故障的快速恢复能力；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据的回溯处理，系统支持消费指定时间段内的数据；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;实时数据从实时数仓中查询，T+1数据借助离线通道修正；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;业务数据质量的实时监控；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;思考&lt;/strong&gt;：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓架构和数据中台一样，虽然都是属于当前比较热门的概念，但是对于实时数仓的狂热追求大可不必。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，在技术上几乎没有难点，基于强大的开源中间件（例如：Flink、kudu等）实现实时数据仓库的需求已经变得没有那么困难。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次，实时数仓的建设一定是伴随着业务的发展而发展，武断的认为实时数仓架构最符合当前公司的需求是不对的。实际情况中随着业务的发展数仓的架构变得没有那么非此即彼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，如何顺畅的将传统的离线数仓+实时链路处理流程升级到实时数仓架构是个很大的问题，毕竟中间涉及到很多的数据模式、技术中间件、计算引擎都不太一样。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的数仓命名规则：前缀（ODS/DWD/MID）+主题域（user/shp）+业务类型+自定义表名+后缀（dd/ds/pi）&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23wMwibpSpPXJNU5g1icn8mXkf4sJgxBwgibiaObicYyDDiceoztRWvQHkibYOw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.687037037037037&quot; data-w=&quot;1080&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5574074074074075&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23MHuRDb4TxlRAQjIArFicpvQauayQJrsbm89ODAM8uU4J4pxbdq0QfCA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;五、数仓分层&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据仓库分层没有绝对的规范，适合的就是最好的，特别是企业已经有一个初版的数仓的时候，需要做好改造成本和可理解性之间的平衡。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据仓库是一套方法论，从规范定义、模型设计到数据服务，再到数据可管理、可追溯、可复用。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多人都关注数仓分层的具体分法和逻辑，而且目前市场上主流的分层方式眼花缭乱，不过看事情不能只看表面，还要看到内在的规律，不能因为分层而分层。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分层的目的解决当前业务快速的数据支撑目的，为未来抽象出共性的框架并能够赋能给其他业务线，同时为业务发展提供稳定、准确的数据支撑，并能够按照已有的模型为新业务发展提供方向，也就是数据驱动和赋能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好分层架构，有以下好处：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;清晰数据结构&lt;/strong&gt;：每一个数据分层都有对应的作用域，在使用数据的时候能更方便的定位和理解。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;数据血缘追踪&lt;/strong&gt;：提供给业务人员或下游系统的数据服务时都是目标数据，目标数据的数据来源一般都来自于多张表数据。若出现目标数据异常时，清晰的血缘关系可以快速定位问题所在。而且，血缘管理也是元数据管理重要的一部分。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;减少重复开发&lt;/strong&gt;：数据的逐层加工原则，下层包含了上层数据加工所需要的全量数据，这样的加工方式避免了每个数据开发人员都重新从源系统抽取数据进行加工。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;数据关系条理化&lt;/strong&gt;：源系统间存在复杂的数据关系，比如客户信息同时存在于核心系统、信贷系统、理财系统、资金系统，取数时该如何决策呢？数据仓库会对相同主题的数据进行统一建模，把复杂的数据关系梳理成条理清晰的数据模型，使用时就可避免上述问题了。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;屏蔽原始数据的影响&lt;/strong&gt;：数据的逐层加工原则，上层的数据都由下一层的数据加工获取，不允许跳级取数。而原始数据位于数仓的最底层，离应用层数据还有多层的数据加工，所以加工应用层数据的过程中就会把原始数据的变更消除掉，保持应用层的稳定性。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说数仓分层有以下几个共性：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;源系统数据归集到数仓的缓冲层，或称为贴源层（ODS）；&lt;/p&gt;&lt;p&gt;主要收集来自各业务线或行业内的外部数据并对数据进行汇总，ODS层不承担任何的数据清洗和治理的工作，在数据上和业务系统保持一致，ODS层采用分区表的形式按批次存储据,ODS层保留了业务系统的原始数据，不对外开放查询。&lt;/p&gt;&lt;p&gt;ODS层主要以全量方式同步数据，保留全量数据恢复的能力，同步的数据为T+1的新增和变更记录，永久保存历史数据。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据仓库层，具备数据标准化及合并全量数据的标准层，其中数仓建模主要集中在这一层（DW）。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;具备主题划分及明细数据整合的主题层（DM）。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;具备提供数据服务给下游系统使用的集市层，或称为应用层（APP）；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.575&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zEQAb6icpZtVhMdgWAUM6qYOkVSm9T2pO0ibQAFzhO669fGjgJbmeJna3YwC2QCpjtoRRnZ3XOBibUeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然这个分层可以进一步拆分，其中最主要的是DW层的模型建立：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.4638888888888888&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ZubDbBye0zEQAb6icpZtVhMdgWAUM6qYOOzx0vPc9efXGHQibaibNQniazxSIt1VcFPgic4DdL3A65vzIPsQWUiaY7TQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实相对来说数仓模型的建设并不复杂，只要关注以下几点就行：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;OneData&lt;/strong&gt;：数仓所有数据只加工一次，对应到数仓的设计层面，要求有统一的维度，对于明细层数据，相同粒度的度量只加工一次，对于汇总层的数据，相同粒度的指标只存在一份。避免重复建设的问题；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;OneIndex&lt;/strong&gt;：数仓指标体系都具有唯一性，通过原子指标+派生指标来规范所有的指标系统，避免数据不一致性的问题；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;OneService&lt;/strong&gt;：数据服务划清了数据和应用的边界，数据服务提供的是加工好的指标数据，应用通过数据服务，直接获取计算的结果，强制把公共计算逻辑下沉到数据层面，提高了数据的共享能力，避免通过不同层次获取数据导致的数据准确性和安全性的问题；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;OneLine&lt;/strong&gt;：最大程度上保障数据流转的透明性，不同层级做不同层级的数据处理逻辑，不可逆向依赖，方便后续数据血缘关系、数据地图的建立，避免数据杂乱，无法溯源；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;OneEntity&lt;/strong&gt;：这块主要是模型方面的建设，同一个用户，在同一个模型中，可能存在重复的记录，如何识别两个 ID 是同一个用户，做到所有用户只有唯一的 ID 标识，这个是 OneEntity 要解决的问题，其实归根结底就是ID-Mapping问题。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;六、问题&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 维度建模的缺点&lt;/span&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度建模之前需要进行大量的数据预处理，因此会导致大量的数据处理工作（ETL）。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当业务发生变化，需要重新进行维度的定义时，往往需要重新进行维度数据的预处理。而在这些与处理过程中，往往会导致大量的数据冗余。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如果只是依靠单纯的维度建模，不能保证数据来源的一致性和准确性，而且在数据仓库的底层，不是特别适用于维度建模的方法。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;维度建模的领域主要适用与数据集市层，它的最大的作用其实是为了解决数据仓库建模中的性能问题。维度建模很难能够提供一个完整地描述真实业务实体之间的复杂关系的抽象方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当前公司的数仓模型架构：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23U7MDplCdaP2GTaGcvDvKFAAwKwW8Kpu87lP6PoksrGnskSz3OkKcEQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.27037037037037037&quot; data-w=&quot;1080&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先对ETL得到的数据进行ER建模，关系建模，得到一个规范化的公司层面的数据仓库模式。然后用这个中心仓数据库为公司各部门建立基于维度建模的数据集市。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而维度建模都集中在各个DM层里面，也就是针对具体的业务线或者主题域，这样紧紧围绕着业务模型，可以直观的反映出业务模型中的业务问题。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 分层的误区&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓层内部的划分不是为了分层而分层，分层是为了解决 ETL 任务及工作流的组织、数据的流向、读写权限的控制、不同需求的满足等各类问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;业界较为通行的做法将整个数仓层又划分成了 dwd、dwb、dws、dim、mid 等等很多层。然而我们却始终说不清楚这几层之间清晰的界限是什么，或者说我们能说清楚它们之间的界限，复杂的业务场景却令我们无法真正落地执行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以数据分层这块一般来说三层是最基础的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23CM0a5LATQcK4qC12neqgB9ov6CvUHQIx8VIp8Ahau3SrEtw3dNEBjw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5654205607476636&quot; data-w=&quot;642&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于DW层如何进行切分，是根据具体的业务需求和公司场景自己去定义，一般来说需要：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;分层是解决数据流向和快速支撑业务的目的；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;必须按照主题域和业务域进行贯穿；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;层级之间不可逆向依赖。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如果依赖ODS层数据可以完成数据支撑，那么业务方直接使用落地层这也有利于快速、低成本地进行一些数据方面的探索和尝试。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;确定分层规范后，后续最好都遵循这个架构，约定成俗即可；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;血缘关系、数据依赖、数据字典、数据命名规范等配套先行；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DW 内的分层没有最正确的，只有最适合你的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 宽表的误区&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数仓层开始引入了宽表。所谓宽表，迄今为止并没有一个明确的定义。通常做法是把很多的维度、事实上卷或者下钻之后关联到某一个事实表中，形成一张既包含了大量维度又包含了相关事实的表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;宽表的使用，有其一定的便利性。使用方不需要再去考虑跟维度表的关联，也不需要了解维度表和事实表是什么东西。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是随着业务的增长，我们始终无法预见性地设计和定义宽表究竟该冗余多少维度，也无法清晰地定义出宽表冗余维度的底线在哪里。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个可能存在的情况是，为了满足使用上的需求，要不断地将维表中已经存在的列增加到宽表中。这直接导致了宽表的表结构频繁发生变动。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前我们所采用的做法是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;根据主题域和业务域，将某个业务的所有节点梳理清楚；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;将关键节点的数据作为事实表依据，然后横向扩充其他事实表上卷数据（包含一些统计指标），同时纵向的添加该节点上一些主键对应的维度；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;宽表的涉及不依赖具体的业务需求而是根据整体业务线相匹配；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;尽量用维度建模代替宽表；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么说尽量用维度建模代替宽表，就算字段和数据会冗余，维度建模的方式也会表全量数据的宽表模式较好，原因：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度建模是以某一个既定的事实为依据，既然是事实表，那么这块的业务如果不变动的情况下，事实表的粒度基本不会改变；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;事实表和维度表解耦，维度表的变更事实表基本不会影响，结果表也只需要回刷一下数据流程即可；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;新增维度完全可以按照星型模型或者雪花模型动态添加新维度；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;维度模型可以作为宽表的基础，一旦确定全部的数据流程，可以通过维度模型再生成对应宽表进行快速的业务支撑；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4. 指标管理&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数仓模型中，最重要的模块可能就是数据治理&lt;/strong&gt;，我们在建立数仓分层的时候，虽然解决 ETL 任务及工作流的组织、数据的流向、读写权限的控制、不同需求的满足等各类问题，但是在给业务方提供不同数据需求的情况下不可避免的会发生一下几个问题：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;指标定义不够清晰明确，两个页面上的指标定义其实是不同的，但是展示给商家看到的可能是同一个中文名称。又或者同样一个含义的指标在不同的界面上展示的名称却不相同，让人产生歧义。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;同一个指标因为由不同的数据开发同学来制作，可能会被重复开发，不但造成资源浪费，还会造成维护困难。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;对于需要新开发的指标，不仅缺少开发工具简化开发流程，甚至该使用哪些表，不该使用哪些表很大程度上都要凭借数据开发同学与数仓同学的经验。如果稍微马虎一点或者缺乏经验，比如使用了某些业务域下特有的表或者不是由数仓提供的统一中间层的表就可能会使用错误的数据，造成后期返工等情况。&lt;/p&gt;&lt;p&gt;而且在数据需求越来越多，数据中台提供的指标也日益丰富。但是指标定义混乱，描述不清会严重影响数据的可信度和数据开发的成本，所以就需要搭建一个指标系统，来维护已有的数据指标，并为未来可能新增的指标建立相应的规范。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何去建立好这个指标库或者指标系统呢。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说指标系统主要分为：&lt;strong&gt;原子指标和派生指标&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在数仓分层的时候，进行维度建模，那么就必须指定好相应的主题域和事实表处理的最小逻辑（也就是事实），那么在这个基础上可以先定义原子指标。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原子指标：原子指标和度量含义相同，基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名词 ，如支付金额。原子指标描述的其实是一种指标的类型，比如订单支付金额，支付订单数，下单订单数，PV，UV 等等。但是仅仅一个原子指标是不能直接取数的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但业务方更关心的指标，是有实际业务含义，可以直接取数据的指标。比如店铺近1天订单支付金额就是一个派生指标，会被直接在产品上展示给商家看。这个指标却不能直接从数仓的统一中间层里取数（因为没有现成的事实字段，数仓提供的一般都是大宽表）。需要有一个桥梁连接数仓中间层和业务方的指标需求，于是便有了派生指标。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;派生指标=维度+原子指标+修饰词。当维度，原子指标，修饰词都确定的时候就可以唯一确定一个派生指标，同时给出具体数值。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：店铺近1天订单支付金额中店铺是维度，近1天是一个时间类型的修饰词，支付金额是一个原子指标。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;业务方制作每一个派生指标都是通过选择维度，原子指标，修饰词三种元数据来定义的，相对于使用名称来区别不同指标，更可以保证指标的唯一性。如果2个派生指标是不同的，那他们的组成部分一定会有区别，或是不同维度，或是不同原子指标，修饰词。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以在指标管理的过程中，指标库给予每个指标一个精确且唯一的定义。通过指标库可以快速且规范的查询，开发和使用指标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;指标库主要提供如下服务：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过设置指标的组成要素来唯一精确定义每个指标（派生指标）。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过指标在业务域内唯一的性质，解决指标重复定义，重复开发，部分数据对不上的问题。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过将数仓中间层录入指标库为新制作指标提供指导性的 SQL 或库表推荐。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;打通其他各数据平台：&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;打通数据开发平台和统一数据服务平台，为指标的定义，调度，在线使用提供一条龙服务，简化开发流程。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;打通数据资产管理平台，沉淀指标的资产价值。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;打通 BI 平台，提供拖拽维度，指标生成报表的功能。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7481481481481481&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TwK74MzofXfeRyelgNjnYI0GdiaXUNy23tGzo7GPLPGnEAeUTCbnCGWloPHfsSv1v1fQJYH0yMn5HQLzibOfRWeQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中派生指标的生成是通过：业务域+维度+原子指标+修饰词来唯一确定的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数仓搭建的时候，业务域、维度、原子指标都是已经明确的，而修饰词是维度的某一些特殊的值，对应 SQL 中的 where 过滤条件。所以如果在数据产品的层面在某个业务域对指标数据定义、生产、使用等过程的流程规范化与平台化，那么就能够从源头上解决上面出现的数据指标不统一、重复开发、指标体系不好维护的问题。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;来源：知乎  作者：高威&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9934fbda64003105f271a67cccbe2fb0</guid>
<title>【突发】Nginx Log4j2 疑似存在严重漏洞紧急通报！</title>
<link>https://toutiao.io/k/ectmt30</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-style-type=&quot;5&quot; data-tools=&quot;新媒体排版&quot; data-id=&quot;965972&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;因公众号更改推送规则，请点“在看”并加“星标”&lt;span&gt;第一时间获取精彩技术分享&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击关注#互联网架构师公众号，领取&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247487508&amp;amp;idx=1&amp;amp;sn=78cf235aa9ba5f988c6922ca98f8bfd6&amp;amp;chksm=ea5cdd72dd2b54647cf55b4a73dcafa69fc7228205ad39ecc98fe57b39cdecb21c238c6d6cb6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;架构师全套资料&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;架构师全套资料&lt;/span&gt;&lt;/a&gt;&lt;span&gt; 都在这里&lt;/span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100029587&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iaajvl7fD4ZCicMcjhXMp1v6UibM134tIsO1j5yqHyNhh9arj090oAL7zGhRJRq6cFqFOlDZMleLl4pw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;64&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247487508&amp;amp;idx=1&amp;amp;sn=78cf235aa9ba5f988c6922ca98f8bfd6&amp;amp;chksm=ea5cdd72dd2b54647cf55b4a73dcafa69fc7228205ad39ecc98fe57b39cdecb21c238c6d6cb6&amp;amp;scene=21&amp;amp;token=171858062&amp;amp;lang=zh_CN#wechat_redirect&quot; textvalue=&quot;0、2T架构师学习资料干货分享&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;0、&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;2T架构师学习资料干货分&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;上一篇：&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247528749&amp;amp;idx=1&amp;amp;sn=456604bf1b2cd29211db9978bc96e7e3&amp;amp;chksm=ea5fbc4bdd28355d7cccd3e4880786e8fc42659ecc4f52031298f0e3627c2e399d5d3a50036c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;RabbitMQ、RocketMQ、Kafka 三元归一&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;RabbitMQ、RocketMQ、Kafka 三元归一&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;大家好，我是互联网架构师！&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h3/&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;来源：红队蓝军&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;nginx&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;漏洞描述：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;nginx 中间件通过堆栈溢出可以导致RCE&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;影响版本：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&amp;lt;=1.21.6&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;漏洞详细：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/R5ic1icyNBNd4D4XIAj0wicyRrGMaRJmJCaXm6k6327M71e3zuIrcCDAqhj4WGAleSqLjDRYC0mOFcafcUcO45zew/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;480&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;log4j&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;491&quot; data-backw=&quot;561&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/9mQQWOf4KRKDYRaHItdwKER3dOaNKuMS0kcicMkJCHd9Pjl8Sox3N4E7hL8Zf7JFibIkK3KteK3qhiaXb1Bj8lJew/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.8757142857142857&quot; data-w=&quot;700&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;*眼&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.先禁止访问漏洞路径： &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;/skyeye/home/security_service/heartbeat /skyeye/home/security_service/add_commands&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.检查所有安全流量监控设备是否存在对外映射，如有一律停止映射&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.添加攻击特征进行监控&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;/skyeye/home/security_service/heartbeat /skyeye/home/security_service/add_commands&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;1、&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247523205&amp;amp;idx=1&amp;amp;sn=89b261f829ce6c3487ce8b2ccf3ed06b&amp;amp;chksm=ea5f56e3dd28dff5238989d3e07d775d34c04a4e80a166059e92e84379274819203d72d1dc1d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Alibaba开源内网高并发编程手册.pdf&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Alibaba开源内网高并发编程手册.pdf&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2、&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247487508&amp;amp;idx=1&amp;amp;sn=78cf235aa9ba5f988c6922ca98f8bfd6&amp;amp;chksm=ea5cdd72dd2b54647cf55b4a73dcafa69fc7228205ad39ecc98fe57b39cdecb21c238c6d6cb6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;2T架构师学习资料干货分享&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;2T架构师学习资料干货分享&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3、&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247523100&amp;amp;idx=1&amp;amp;sn=82a70350577bde0bca6dd2dde811ca17&amp;amp;chksm=ea5f567add28df6cb6a780ff744c3ffdc79e498d2c2536ffb1853d8082ebfa986e1e5c43d532&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;10000+TB 资源，阿里云盘，牛逼！！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;10000+TB 资源，阿里云盘，牛逼！！&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;4、&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247523863&amp;amp;idx=1&amp;amp;sn=4d2a2b5da60f14f3e8947e174d485c03&amp;amp;chksm=ea5f5371dd28da6791af6cb3a164c8052f1e77d7392cbbc87c5a73ccc6916b76eab29dbc9991&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;基本涵盖了Spring所有核心知识点总结&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;基本涵盖了Spring所有核心知识点总结&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;  · END ·&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;最后，关注公众号互联网架构师，在后台回复：2T，可以获取我整理的 Java 系列面试题和答案，非常齐全&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9mQQWOf4KRL358RWHQSLbUws79uyGm5RJ6WZibYJMAKUQibz8aYNA5LPSmbo1boibnD3IhggQ2F7kS37xgk3WXQ8Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果这篇文章对您有所帮助，或者有所启发的话，帮忙扫描下发二维码关注一下，您的支持是我坚持写作最大的动力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;求一键三连：点赞、转发、在看。&lt;/p&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c807e2dafd9841f272490c6d23f47aa7</guid>
<title>以小窥大：IO 卡顿探寻苹果文件系统</title>
<link>https://toutiao.io/k/xbnkwtv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1575&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/j3gficicyOvasIjZpiaTNIPReJVWEJf7UGpmokI3LL4NbQDb8fO48fYROmYPXUhXFN8IdDqPcI1gA6OfSLsQHxB4w/640?wx_fmt=gif&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作者：rhythmzhang，腾讯 WXG 客户端开发工程师&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;从一个不寻常的 I/O 卡顿入手，发现苹果 APFS 的一个严重 bug。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;近期有用户反馈频繁遇到了一个奇怪的严重卡顿问题，微信刷朋友圈和查看聊天都非常卡，主线程卡在最普通的 access, rename 等常见 I/O 系统调用，并且经常卡上百 ms，而这种场景的底层接口一般都没干什么大量的 I/O 操作。比如 access 接口也就是获取文件是否存在的轻量操作，正常耗时都只有几十 us 而已，远达不到此时的上百 ms 耗时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、分析问题&lt;/span&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;寻找关键堆栈&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;堆栈上看，只是很常规的视频号卡片列表滑动时，触发了下载图片和查图片本地缓存的逻辑，通过 access 接口同步查本地图片是否存在，有则直接展示，否则从网络下载图片，下载完成时再尝试删除可能已有的旧文件。这完全是一个非常简单的图片缓存和加载逻辑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过搜寻卡顿报告，发现子线程都疑似存在大量的并发 I/O 操作，那是否卡顿的主因是和并发 I/O 有关呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尝试触发子线程并发 I/O 这个目录的图片，并打日志输出 access 接口的平均耗时，一切正常。走查功能也一切正常，毫无卡顿。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有同学说可能是目录下文件过多才会有 I/O 问题，在对应目录下构造了足够多的文件，再次走查业务功能，还是一切正常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最终在多次试验和猜测后，构造出了一个高概率复现的场景，在对应目录下写入10万个小图片伪造图片数据，并触发并发 I/O，此时问题终于复现了。这个时候如果触发视频号卡片滑动，朋友圈卡片滑动，就大概率必现严重的滑动掉帧和卡顿了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;构造必现代码&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大概知道了必现路径后，我们构造出了一个必现代码，打开 Instruments 的 System Trace 分析，结果如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3883089770354906&quot; data-type=&quot;jpeg&quot; data-w=&quot;958&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasbibnicqK54k5Nia6MYIWFjBianYnT2ldkOUKUyHqia9Fcs3YFD0mVB5ggu2qAKZXtLBicK9sjX9hW51dQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;发现 access 等常规 I/O 接口的平均耗时依旧很低只有几十 us，但等待耗时波动很大，可以达到140 ms，也就导致了主线程每次查询图片存在状态时，单次调用耗时超过了140 ms，而滑动过程中大概存在十几次这样的行为，那最终就是每次滑动都要因为这些 I/O wait time 导致滑动耗时数秒之久，甚至个别情况下还会因此滑动卡死触发 watchdog。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;继续分析 Instruments 报告，发现等待的主因如下：will wait for event/lock xxx.&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.31023784901758017&quot; data-type=&quot;jpeg&quot; data-w=&quot;967&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasbibnicqK54k5Nia6MYIWFjBiavwEBa6uibicabDp4IicV0nCOAiaF0RX5ia3iabM5ceqL03Z89iaEOy9VaTg5A/640?wx_fmt=jpeg&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过前面的研究，我们已经能够构造一个必现 demo 了。大概如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;特定目录下写入大约10万个文件&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;主线程触发频繁的 access 接口调用，统计平均耗时&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;子线程触发对该目录下的文件遍历并频繁的 rename 操作调用，统计平均耗时&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果2和3是同一个目录且当前目录文件数较多时，那么会高概率稳定复现平均 access 和 rename 等 I/O 接口调用 调用耗时过高的问题。而其它情况组合下，都不会复现这个问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;测试工程跑在 MacBook Pro(2019) macOS 12.3 上，会定时 benchmark 测 access 接口耗时。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;  int retry = 5;&lt;br/&gt;  long long duration = benchmark(retry,^{&lt;br/&gt;    access(path.UTF8String, F_OK);&lt;br/&gt;  });&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt;(duration &amp;gt; 1000 * retry) {&lt;br/&gt;    //avg &amp;gt;1 ms.&lt;br/&gt;    LOG_P(&lt;span&gt;&quot;lag: avg access %.3f ms&quot;&lt;/span&gt;,duration*1.f/1000/retry);&lt;br/&gt;  }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 APFS 分区的该目录下会频繁因大目录并发 I/O 遍历导致 access 超时问题，log输出如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;  lag: avg access 2.134 ms&lt;br/&gt;  lag: avg access 11.859 ms&lt;br/&gt;  lag: avg access 5.483 ms&lt;br/&gt;  lag: avg access 5.259 ms&lt;br/&gt;  lag: avg access 4.634 ms&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时在 x86 的 ssd 设备上都能稳定复现出 access 调用平均耗时 1ms 以上，个别情况下可以达到几十ms，确实令人费解。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;dtrace 分析&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然 Instruments 告诉我们耗时的主因是 wait for lock，那接下来我们尝试分析下到底在 wait 什么 lock 最多。这就需要借助于 dtrace 来进一步分析了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DTrace 即动态追踪技术（Dynamic Tracing），是内核提供的高级动态调试能力，可以帮助开发者快速调试定位一些奇怪的疑难杂症。操作系统会在内核的一些关键调用操作里提供 trace 代码执行的入口，我们可以通过注入 trace 命令或代码来实现自定义 trace 分析。Xcode Instruments 本质就是基于内核提供的 dtrace 能力来封装并实现的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 iOS 平台不支持自定义 dtrace （虽然Instruments 就是基于 dtrace 的，但 iOS 即便越狱了也没办法触发自定义 dtrace 行为），
我们只有基于 macOS 打开 dtrace 分析下这个时候到底发生了什么。运行 demo ，多次跑如下 dtrace 命令分析 demo 运行状态。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;sudo dtrace -n &lt;span&gt;&#x27;lockstat:::adaptive-block { @[stack()] = sum(arg1); }&#x27;&lt;/span&gt; -p 95637&lt;br/&gt;sudo dtrace -n &lt;span&gt;&#x27;profile-999 /arg0/ { @[stack()] = count(); }&#x27;&lt;/span&gt;  -p 95806&lt;br/&gt;sudo lockstat sleep 10&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;得到的 dtrace 相关数据如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;  kernel`0xffffff8005aa6990+0x72&lt;br/&gt;  apfs`apfs_vnop_rename+0x94&lt;br/&gt;  kernel`vn_rename+0x4ae&lt;br/&gt;  kernel`0xffffff8005d42020+0xb12&lt;br/&gt;  kernel`unix_syscall64+0x1fb&lt;br/&gt;  kernel`hndl_unix_scall64+0x16&lt;br/&gt;  1367&lt;br/&gt;&lt;br/&gt;  kernel`lck_mtx_lock_spinwait_x86+0x2be&lt;br/&gt;  kernel`vn_rename+0x4ae&lt;br/&gt;  kernel`0xffffff8005d42020+0xb12&lt;br/&gt;  kernel`unix_syscall64+0x1fb&lt;br/&gt;  kernel`hndl_unix_scall64+0x16&lt;br/&gt;  2242&lt;br/&gt;&lt;br/&gt;  kernel`0xffffff8005aa67f0+0x7e&lt;br/&gt;  kernel`namei+0x9f7&lt;br/&gt;  kernel`0xffffff8005d375a0+0x79&lt;br/&gt;  kernel`0xffffff8005d42020+0x35b&lt;br/&gt;  kernel`unix_syscall64+0x1fb&lt;br/&gt;  kernel`hndl_unix_scall64+0x16&lt;br/&gt;  2262&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;R/W writer blocked by readers: 239 events &lt;span&gt;in&lt;/span&gt; 10.048 seconds (24 events/sec)&lt;br/&gt;&lt;br/&gt;Count indv cuml rcnt      abs Lock                   Caller                  &lt;br/&gt;-------------------------------------------------------------------------------&lt;br/&gt;  227  95%  95% 0.00 13385718 0xffffff8b638223e0     apfs_vnop_lookup+0x2f6  &lt;br/&gt;   11   5% 100% 0.00  8140855 0xffffff8b638223e0     apfs_vnop_getattr+0xc4  &lt;br/&gt;    1   0% 100% 0.00  2610265 0xffffff90339a97b0     omap_get+0x7c           &lt;br/&gt;-------------------------------------------------------------------------------&lt;br/&gt;&lt;br/&gt;R/W reader blocked by writer: 192 events &lt;span&gt;in&lt;/span&gt; 10.021 seconds (19 events/sec)&lt;br/&gt;&lt;br/&gt;Count indv cuml rcnt      abs Lock                   Caller                  &lt;br/&gt;-------------------------------------------------------------------------------&lt;br/&gt;  129  67%  67% 0.00  6408120 0xffffff8b638223e0     IORWLockWrite+0x90      &lt;br/&gt;   22  11%  79% 0.00    23902 0xffffff99cd1fbc00     IORWLockWrite+0x90      &lt;br/&gt;   12   6%  85% 0.00    28194 0xffffff804e970608     IORWLockWrite+0x90      &lt;br/&gt;    4   2%  87% 0.00    18808 0xffffff8048892e08     IORWLockWrite+0x90      &lt;br/&gt;    3   2%  89% 0.00    41491 0xffffff803825e608     lck_rw_lock_exclusive_check_contended+0x93&lt;br/&gt;    2   1%  90% 0.00    22725 0xffffff99cd1fbc80     IORWLockWrite+0x90      &lt;br/&gt;    2   1%  91% 0.00    78215 0xffffff8b666c2610     IORWLockWrite+0x90      &lt;br/&gt;    2   1%  92% 0.00    34049 0xffffff8b666c22c8     IORWLockWrite+0x90      &lt;br/&gt;    2   1%  93% 0.00    23949 0xffffff8b666bc4c0     IORWLockWrite+0x90      &lt;br/&gt;    2   1%  94% 0.00    28546 0xffffff8b666b94c0     IORWLockWrite+0x90      &lt;br/&gt;    2   1%  95% 0.00    38088 0xffffff804e97ab08     lck_rw_lock_exclusive_check_contended+0x93&lt;br/&gt;    2   1%  96% 0.00    17158 0xffffff803dc78d08     0xffffff8005aa77d0      &lt;br/&gt;    2   1%  97% 0.00    18658 0xffffff803dc78d08     IORWLockWrite+0x90      &lt;br/&gt;    2   1%  98% 0.00    29096 tcbinfo+0x38           IORWLockWrite+0x90      &lt;br/&gt;    1   1%  98% 0.00    52994 0xffffff8b666be7a0     IORWLockWrite+0x90      &lt;br/&gt;    1   1%  99% 0.00    20135 0xffffff8048892e08     0xffffff8005aa77d0      &lt;br/&gt;    1   1%  99% 0.00    18584 0xffffff80345de608     IORWLockWrite+0x90      &lt;br/&gt;    1   1% 100% 0.00    13805 0xffffff803825e608     IORWLockWrite+0x90      &lt;br/&gt;-------------------------------------------------------------------------------&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 dtrace 的 lockstat 数据，大概率怀疑是 kernel 层的 APFS 相关的  lock 出了问题，那为什么 APFS lock 会导致如此严重的问题呢？&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Hopper 分析&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;rename 和 access 都是系统调用，他们都是 XNU 里 VFS 注册的系统服务。APFS 的系统支持是通过系统的 apfs.kext 内核扩展载入的，我们通过 Hopper 打开 apfs.kext，分析下 APFS 对应的 rename 或 access 里到底干了什么&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;_apfs_vnop_renamex&lt;br/&gt;{&lt;br/&gt;    r12 = arg0;&lt;br/&gt;    r14 = *(int32_t *)(arg0 + 0x40);&lt;br/&gt;    r14 = r14 &amp;amp; 0xfffffff7;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (r14 &amp;lt; 0x3) goto loc_5ad56;&lt;br/&gt;&lt;br/&gt;loc_5ad47:&lt;br/&gt;    rax = 0x2d;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (r14 != 0x4) goto .l17;&lt;br/&gt;&lt;br/&gt;loc_5ad56:&lt;br/&gt;    var_C8 = 0x0;&lt;br/&gt;    var_170 = 0x0;&lt;br/&gt;    var_190 = 0x0;&lt;br/&gt;    r15 = _vfs_fsprivate(_vnode_mount(*(r12 + 0x8))); //获取目录&lt;br/&gt;    r13 = _vnode_fsnode(*(r12 + 0x8));&lt;br/&gt;    var_58 = _vnode_fsnode(*(r12 + 0x20));&lt;br/&gt;    //... ....&lt;br/&gt;&lt;br/&gt;    rax = _current_thread();&lt;br/&gt;    var_120 = rax;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (rbx != rax) {&lt;br/&gt;            _lck_rw_lock_shared(var_108); // 获取锁&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;apf.kext 的代码里 vfs_fsprivate 返回了一个结构，这个结构存了每个 vnode 相关的附加字段，比如这里会疑似返回一个目录相关的锁，每次执行 rename 接口时，会取出目录锁，尝试加锁处理，而在 apfs.kext 代码里还有很多处额外的高频加锁逻辑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过进一步 System Trace 验证，当并发 I/O 遍历的文件目录是同一个时，Instruments 报告里的 will wait for lock xxx 会显示为同一个，大概率证明了 APFS 内部存在某种目录锁的结构，当对同一个目录的文件进行遍历 I/O 操作时，都会先请求加解锁。而在超大目录遍历时这个加锁导致的等待问题会急剧扩大，导致锁等待超时，最终可能导致了并发 I/O 速度骤降的问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;对比 HFS+&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在同一台电脑上构造了两个不同的磁盘分区：APFS 和 HFS+，分别在各自分区下的同一路径下写入了相同数据的10万个文件，接着开始跑同样的测试程序，又发现了更出人意料的结论：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HFS+ 测试如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43993231810490696&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasbibnicqK54k5Nia6MYIWFjBiaQ0kuw3PUuxz1GoDsgHrEXqkUB3XzibLVmut90OvUWwkBp0iarN3icoIFw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;591&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;APFS 测试如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45346869712351945&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasbibnicqK54k5Nia6MYIWFjBiaU6JC0QOynViaA0ibnYeicb1LvBhKpJPvn6vHQRyhdytL3KfERDTdicF0TA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;591&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过多次对比测试，发现在这种超大目录文件遍历的并发 I/O 情况下，HFS+ 的平均读写速度要比 APFS 快 8~20 倍，想不到 APFS 竟然反而比 HFS+ 要慢那么多。这个问题在 macOS 12.3 和 iOS 15.4 上都可以稳定构造出必现测试用例。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、解决问题&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回到开始的卡顿问题，通过构造 demo 我们稳定复现了该问题，同时继续分析用户的相关数据，确认了用户遇到问题时的情况的确和我们最终 demo 构造的基本一致，至此又一个奇怪的卡顿问题终于找到原因了：&lt;strong&gt;超大目录导致了并发 I/O 时性能急剧下降。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然我们已经明白了问题的根因超大目录结构导致的锁等待超时问题，那解决问题的办法就简单多了，将目录拆分为二级目录即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过部分统计分析发现的确有很大一批老用户也存在这个超大目录结构的问题，目前微信已经将大部分超大目录逐步拆分为二级目录了。通过每级1000 个文件/夹，二级目录可以存储100万个文件，绰绰有余了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过测试，将该目录拆分为二级目录并缓解单目录文件过多的情况后，再也没有遇到类似的并发 I/O 卡顿的情况了。另外，该问题已经反馈给苹果，苹果内部也开了 radar ，希望可以进一步提升 APFS 性能。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一些坑&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;结合已有数据分析，发现苹果的文件操作里还存在一些坑，如下：&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;tmp&lt;/span&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;苹果在 &lt;a href=&quot;https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/FileSystemOverview/FileSystemOverview.html#//apple_ref/doc/uid/TP40010672-CH2-SW2&quot; data-linktype=&quot;2&quot;&gt;File System Programming Guide&lt;/a&gt; 里建议 app 用 tmp/ 目录来存储临时文件，并且说系统会在 app 不运行时自动删除 tmp/ 目录的数据，但是实测，大概率不会，因为文档写的是 may purge。极端情况下该目录可能会存在 &amp;gt;90G 的占用。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;WebKit&lt;/span&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WebKit 的网络缓存默认在 /Library/Caches/WebKit/NetworkCache/ ，按照 WebKit 源码 NetworkCacheStorage 里的实现，WebKit 会采取一定随机+权重的方式删除网络缓存，但是极端情况下，个别用户会因此而占用 10G 或更多的存储空间。也就是这个随机删除存在很大的随机性。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;NSURLCache&lt;/span&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NSURLCache 自定义磁盘缓存路径时，如果 diskCapacity 设置过大，会导致占用超大存储空间，同时也会导致网络请求因为 I/O 读写慢而变慢。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;删除文件&lt;/span&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实测部分情况下删文件的 I/O 量基本等于写文件的 I/O 量，而且密集删文件时会容易导致 I/O 性能下降过快。因此业务应尽量避免短时间大量密集 I/O。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三、结论&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;System Trace 数据表明：当并发 I/O 遍历的文件目录是同一个时，Instruments 报告里的 will wait for lock xxx 会显示为同一个，也就进一步证明了 &lt;strong&gt;APFS 内部存在某种目录锁的结构，当对同一个目录的文件进行遍历 I/O 操作时，都会先请求加解锁。而在超大目录遍历时这个加锁导致的等待问题会急剧扩大，导致锁等待超时，最终可能导致了并发 I/O 速度骤降的问题&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了避免这种极端情况导致的 I/O 性能骤降问题，
移动端 app 也需要合理的设计存储结构。例如&lt;strong&gt;需要分层分级管理文件&lt;/strong&gt;，尽量&lt;strong&gt;不要将单个文件夹或单个文件搞的过大&lt;/strong&gt;，同时也&lt;strong&gt;需要定时清理临时缓存目录&lt;/strong&gt;，来进一步优化存储空间占用和优化 I/O 效率。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;四、附录&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;苹果从 iOS10.3 开始引入了 APFS，而在此之前 HFS+ 一直是作为 iOS 和 macOS 的文件系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;应用程序是如何从 ssd 等存储介质上读写文件的呢？如下图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7177835051546392&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasbibnicqK54k5Nia6MYIWFjBiasoibGoIxOhbHFfy9KX97lFKGKnbw91lgKXSse8oCIfglRQyxibKTD2tg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;776&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;VFS&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;VFS 统一并抽象了不同文件系统的接口，使得用户可以通过统一的系统调用接口去访问不同文件系统不同存储介质上的文件。VFS 主要可以被抽象为3层，vfstbllist 用于管理不同的文件系统，mount 管理文件系统的挂载，vnode 则抽象代表了文件和文件夹等对象。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;XNU 中主要使用 vfstbllist 来注册管理多个文件系统，典型的 vfstlblist 如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;/*&lt;br/&gt; * Set up the filesystem operations &lt;span&gt;for&lt;/span&gt; vnodes.&lt;br/&gt; */&lt;br/&gt;static struct vfstable vfstbllist[] = {&lt;br/&gt; /* HFS/HFS+ Filesystem */&lt;br/&gt;&lt;span&gt;#if HFS&lt;/span&gt;&lt;br/&gt; { &amp;amp;hfs_vfsops, &lt;span&gt;&quot;hfs&quot;&lt;/span&gt;, 17, 0, (MNT_LOCAL | MNT_DOVOLFS), hfs_mountroot, NULL, 0, 0, VFC_VFSLOCALARGS | VFC_VFSREADDIR_EXTENDED | VFS_THREAD_SAFE_FLAG | VFC_VFS64BITREADY | VFC_VFSVNOP_PAGEOUTV2 | VFC_VFSVNOP_PAGEINV2, NULL, 0},&lt;br/&gt;&lt;span&gt;#endif&lt;/span&gt;&lt;br/&gt;&lt;br/&gt; /* Sun-compatible Network Filesystem */&lt;br/&gt;&lt;span&gt;#if NFSCLIENT&lt;/span&gt;&lt;br/&gt; { &amp;amp;nfs_vfsops, &lt;span&gt;&quot;nfs&quot;&lt;/span&gt;, 2, 0, 0, NULL, NULL, 0, 0, VFC_VFSGENERICARGS | VFC_VFSPREFLIGHT | VFS_THREAD_SAFE_FLAG | VFC_VFS64BITREADY | VFC_VFSREADDIR_EXTENDED, NULL, 0},&lt;br/&gt;&lt;span&gt;#endif&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#ifndef __LP64__&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#endif /* __LP64__ */&lt;/span&gt;&lt;br/&gt;    ... ...&lt;br/&gt; {NULL, &lt;span&gt;&quot;&amp;lt;unassigned&amp;gt;&quot;&lt;/span&gt;, 0, 0, 0, NULL, NULL, 0, 0, 0, NULL, 0},&lt;br/&gt; {NULL, &lt;span&gt;&quot;&amp;lt;unassigned&amp;gt;&quot;&lt;/span&gt;, 0, 0, 0, NULL, NULL, 0, 0, 0, NULL, 0}&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核可以动态的通过 vfs_fsadd 等接口来加载不同的内核扩展，以启用并支持新的文件系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;文件系统只有被 mount 挂载后才可以被访问。对于内核支持的文件系统，macOS 会自动 从 /System/Library/FileSystems 里找到对应的内核扩展并挂载，而对于内核不支持的文件系统，则需要触发一次 kext 加载操作以支持对应的文件系统。macOS 上常见的 mount 操作如下图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4710467706013363&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasbibnicqK54k5Nia6MYIWFjBiaENc8cvZLf5xibMy2QbhbOFG82Y2l9gktHJARwvu9c3tHrw1MM8AROlw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;898&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;vnode 是 VFS 中最主要的组成。一个 vnode 可以代表一个文件或特定的一个文件系统对象。一个 vnode 一般对应实际的文件系统的对应 inode。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;HFS+&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HFS+(Hierarchical File System Plus) 是 Mac OS 8.1（1998年） 开始引入的文件系统，同时也是 iOS 10.3 以前默认的文件系统。HFS+ 能更好的利用磁盘空间，使用 unicode 存储文件编码，提供了更多当时来说更现代的文件系统支持。HFS+ 使用了 Catalog File 来存储目录结构。Catalog File 的引入极大的提升了文件系统的查找速度，但也导致了所有 I/O 都会因为频繁访问 Catalog File 而被迫串行等待，导致超大并发性能会有较大下降。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;APFS&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;APFS(Apple File System) 是苹果推出的最新文件系统，它是 HFS+ 的接任者，解决了 HFS+ 在更现代的文件系统上所缺失的能力。APFS 为 ssd 而设计和优化，新增了 cloning, snapshots, space sharing, fast directory sizing, atomic safe-save, sparse files等特性，并补齐了苹果在现代文件系统能力上的缺失。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;苹果的 APFS 和安卓设备的 F2FS 类似，都是专门为移动设备而优化的文件系统。二者设计上有很多异曲同工之处。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以 rename 调用为例，开发者通过触发 rename 系统调用向 VFS 请求文件操作，VFS 触发 vn_rename 调用，如果当前目录使用的分区是 APFS，则最终会触发 apfs_vnop_renamex，而如果是 HFS+ 分区，则会触发 hfs_vnop_rename 调用，最终完成 rename 操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;五、参考&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://www.amazon.com/Mac-OS-iOS-Internals-Apples/dp/1118057651&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Mac OS X and iOS Internals: To the Apple&#x27;s Core&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://www.amazon.com/MacOS-iOS-Internals-II-Kernel/dp/0991055578&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;MacOS and iOS Internals, Volume II: Kernel Mode&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://docs.oracle.com/cd/E37670_01/E37355/html/ol_dtrace.html&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;DTrace&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/FileSystemOverview/FileSystemOverview.html&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;File System Programming Guide&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://developer.apple.com/library/archive/technotes/tn/tn1150.html&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;HFS Plus Volume Format&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://developer.apple.com/support/downloads/Apple-File-System-Reference.pdf&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Apple File System Reference&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/APFS_Guide/FAQ/FAQ.html&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Apple File System Guide&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://github.com/darwin-on-arm/xnu/blob/master/bsd/hfs/hfs.h&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;XNU&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;七夕彩蛋&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe videosnap_video_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAASq0YgLDeYwAAAAstQy6ubaLX4KHWvLEZgBPE0KJ4OxAQBvyCzNPgMIs4UP_WvRrNg5tdEY9lQ778&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzLqhyKA03Vl1MAocId9PdpnwoIYTQusVCncn35P2jX0Hibud2Yx7v1JmmTnV0EDQea2JjX3Cr4cqp3T6tP47jS3w&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=AxricY7RBHdVCLrmwcbdS5YpD3kwVxrPZSlHNep8tyCvuOBZBOeGPXuk0lZg02uNFnYfgs3y4q98&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/I7awtksbibjQe7RZAy84xESOBAfIZ8xQ9ApXt4uTe8po/0&quot; data-username=&quot;v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder&quot; data-nickname=&quot;腾讯程序员&quot; data-desc=&quot;程序员的生活也可以很浪漫，祝大家七夕快乐！#七夕&quot; data-nonceid=&quot;11030318403157504517&quot; data-type=&quot;video&quot; data-width=&quot;1920&quot; data-height=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>