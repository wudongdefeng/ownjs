<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f82b9f319007b5345e90e563ae5e28f9</guid>
<title>如何用好免费的chatGPT</title>
<link>https://toutiao.io/k/j1qchny</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.425&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6qtpUicKafdGQywgqKPHbX2HlQYDMVl1SCelooS9G8f7T0f5UQl3XCjiaJ9SE564CYSzX6PNIrFgO9HWtJ8ZPKuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;前言&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近chatGPT爆火了，网友们纷纷赞不绝口，但在国内却没有相应的使用入口。本文将为大家介绍如何免费的使用chatGPT，并且教你如何善用chatGPT提高自己的效率。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;chatGPT使用入口&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于某些原因，ChatGPT并没有为中国大陆用户提供服务。但是，幸运的是，有很多热心的极客自掏腰包将chatGPT服务代理了回来，免费提供给国内的用户使用。这让一些不了解情况的小伙伴也能够体验到ChatGPT的魅力。我把这些免费的chatGPT服务进行了汇总，大家关注微信公众号【劼哥舍】即可马上获取。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你已经迫不及待地想要尝试chatGPT，可以先去体验一下，然后再回来看下面的部分。这里打个比喻：假如我们有了屠龙刀，但如果没有对应的功法，可能连屠龙刀都举不起来，所以下面的内容也是挺重要的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;重要提醒：国内代理的chatGPT服务，在使用体验上远不如chatGPT官网，有些服务提供者还可能会收取不菲的费用，大家一定要谨慎充钱不要被割韭菜！建议有能力的同学自己注册chatGPT账号，以获得最佳使用体验！&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;chatGPT简单介绍&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在具体讲解chatGPT使用技巧之前，需要先简单介绍一下chatGPT的概念。GPT是“Generative Pre-trained Transformer”的缩写，是一种预训练语言模型。而chatGPT则是一种基于GPT的聊天机器人，可以与人进行自然对话。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然chatGPT是一种非常有用的工具，它几乎可以涵盖互联网上所有的知识，帮助我们做出更好的决策。但是需要注意的是，在深度思考方面，它并不能像人类一样进行深度推理。对于那些具有科学深度的问题，它的回答可能会很流畅，但常常是“很一本正经的胡说八道”，因此在使用chatGPT时，需要先辨别真伪，再考虑是否采纳。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;chatGPT使用技巧&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1、提问技巧&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要让chatGPT产出有效的回答，需要遵循以下五个原则：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;提问清晰：请尽可能清晰地描述您的问题&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;简明扼要：请尽量使用简单的语言和简洁的句子来表达您的问题&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;确认问题：请确认您的问题是清晰、明确和完整&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;单一提问：请一个一个地问，而不是把所有问题放在一个问题中&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不要提供敏感信息：请不要在您的问题中提供任何个人敏感信息&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2、初级用法-日常问答&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以下均为我自己日常生活、学习、工作中能实际用到chatGPT场景。自从去年底开始使用ChatGPT以来，我感觉自己已经离不开它了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 问问题&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多时候我们会向搜索引擎提问，但目前的搜索引擎无法直接给出答案，而是给出一篇篇关联的文章，我们还需要进一步阅读文章来找到对应的答案。而chatGPT就能直接给出我们期望的答案，提高检索效率。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 写周报、写PPT&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;许多打工族和学生党每周都需要撰写周报，但由于工作任务繁重，很多人很难抽出时间来完成。使用chatGPT，我们可以快速生成周报，节省时间。示例脚本如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本周完成了电商项目核心接口的性能优化（包含缓存命中率、消息队列、慢SQL等），帮助某客户排查了3个线上问题，团队内部做了一个研发效率的技术分享，请帮我写一篇看起来非常专业的周报，要体现客户第一的价值观。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 写小说、写剧本&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于文科或媒体从业者来说，文案和剧本的创作是必不可少的。而使用Chatgpt，我们可以快速生成剧本，提高创作效率。我自己经常用它来给孩子写作文，示例脚本如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;帮我写一篇关于放风筝的作文，内容包含：7岁的小明和一群小朋友在草坪上欢声笑语的放风筝、阳光明媚、鸟语花香、有各种各样的风筝，要求：多使用拟人、比喻、排比等修辞手法。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4 写代码、做架构&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;写代码对于大部分非计算机专业的人来说是件很困难的事情，而chatGPT使得编程几乎变得零门槛。另外，对于程序员来说，使用chatGPT，我们可以快速生成代码，提高工作效率。示例脚本如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;帮我写一段文字转图片的代码，用go语言实现。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候我们想要开发一个新的系统，但因为缺乏经验而不知道如何开始。Chatgpt能够快速生成设计思路，帮助我们完成学习与工作任务。示例脚本如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如何设计一个电商秒杀系统？&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3、中级用法-领域专家&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://prompts.chat/ 是国外大神总结的chatGPT训练的引导语，可以让你把chatGPT训练成某个领域的专家，从更专业的角度回答你的问题，这里我挑几个常用角色的给大家做参考，英语不错小伙伴可以直接看原文。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 翻译专家&lt;span/&gt;&lt;/h4&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我希望你充当中文翻译、拼写纠正和改进者。我会用任何语言与你交谈，你会检测语言，翻译它并用我的文本的更正和改进版本用中文回答。我想要你把我简化的A0级单词和句子替换成更优美优雅的高级英语单词和句子。保持原意，但让它们更文艺。我要你只回复更正，改进，而不是其他，不要写解释。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 数学老师&lt;span/&gt;&lt;/h4&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我想让你扮演一名数学老师。我会提供一些数学方程式或概念，你的工作就是用通俗易懂的术语来解释它们。这可能包括提供解决问题的分步说明。问题，用视觉演示各种技术或建议在线资源以供进一步研究。我的第一个请求是“如果让小学生理解什么是勾股定理”&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3 词源学家&lt;span/&gt;&lt;/h4&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我希望你充当词源学家。我给你一个词，你要研究那个词的起源，追根溯源。你还应该提供有关这个词的含义如何随时间变化的信息，如果适用的话。我的第一个请求是“我想追溯‘狗头保命’这个词的起源。”&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.4 激励教练&lt;span/&gt;&lt;/h4&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我希望你充当激励教练。我会向你提供一些关于某人的目标和挑战的信息，你的工作就是想出可以帮助这个人实现目标的策略。这可能包括提供积极的肯定, 提供有用的建议或建议他们可以做些什么来达到他们的最终目标。我的第一个请求是“我需要帮助来激励自己在为即将到来的考试学习时保持纪律”。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4、高级用法-无限可能&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.1 智能助理&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过chatGPT+实时语音+MMD，可以生成你专属的神里凌华智能助理。https://www.bilibili.com/video/BV1UM4y1o71v&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2 颜值主播&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过chatGPT+MidJourney+D-ID+Mubert，可以生成一个带配乐的虚拟人开口说话的视频，不露脸也可以做颜值博主。https://www.bilibili.com/video/BV1Mj411N7vK&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3 无限可能&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了以上提到的用法，还有无限多的可能等着我们去挖掘。在未来的互联网世界中，chatGPT可能会无处不在~&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，我对chatGPT发出灵魂拷问：“AI会取代人类工作吗？”，chatGPT回答说：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;人工智能在某些领域能够取代人类工作，比如进行重复性的、需要高度精确度的任务，例如生产线上的装配工作、数据处理等。但是，在某些需要人类创造力、判断力和情感共鸣的领域，如艺术、教育、医疗等，人工智能目前还无法完全替代人类工作。&lt;/p&gt;&lt;p&gt;同时，尽管人工智能在某些方面已经取得了可喜的成果，但是在更加复杂的任务和环境下，人工智能仍然存在许多限制和局限性，需要人类的干预和指导。因此，未来人类和人工智能将会发展出更加紧密的合作关系，共同推进社会的进步和发展。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;参考&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;chatGPT提效7种用法：https://zhuanlan.zhihu.com/p/605878449&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;chatGPT有效对话技巧：https://zhuanlan.zhihu.com/p/608738482&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>187618495c9c5a58d54db4f698124f3a</guid>
<title>5 年工作经验，容器与 Pod 的区别和联系都说不清，你敢信？</title>
<link>https://toutiao.io/k/cfx43ii</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;刚开始接触 Kubernetes 时，你学到的第一件事就是每个 Pod 都有一个唯一的 IP 和主机名，并且在同一个 Pod 中，容器可以通过 localhost 相互通信。所以，显而易见，一个 Pod 就像一个微型的服务器。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;但是，过段时间，你会发现 Pod 中的每个容器都有一个隔离的文件系统，并且从一个容器内部，你看不到在同一 Pod 的其他容器中运行的进程。好吧！也许 Pod 不是一个微型的服务器，而只是一组具有共享网络堆栈的容器。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;但随后你会了解到，Pod 中的容器可以通过共享内存进行通信！所以，在容器之间，网络命名空间不是唯一可以共享的东西……&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;基于最后的发现，所以，我决定深入了解：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Pod 是如何在底层实现的&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Pod 和 Container 之间的实际区别是什么&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如何使用 Docker 创建 Pod&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在此过程中，我希望它能帮助我巩固我的 Linux、Docker 和 Kubernetes 技能。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索 Container&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;OCI 运行时规范并不将容器实现仅限于 Linux 容器，即使用 namespace 和 cgroup 实现的容器。但是，除非另有明确说明，否则本文中的容器一词指的是这种相当传统的形式。&lt;/span&gt;&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;设置实验环境（playground）&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在了解构成容器的 namespace 和 cgroups 之前，让我们快速设置一个实验环境：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ cat &amp;gt; Vagrantfile &amp;lt;&amp;lt;EOF&lt;br/&gt;&lt;span&gt;# -*- mode: ruby -*-&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# vi: set ft=ruby :&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Vagrant.configure(&lt;span&gt;&quot;2&quot;&lt;/span&gt;) &lt;span&gt;do&lt;/span&gt; |config|&lt;br/&gt;config.vm.box = &lt;span&gt;&quot;debian/buster64&quot;&lt;/span&gt;&lt;br/&gt;config.vm.hostname = &lt;span&gt;&quot;docker-host&quot;&lt;/span&gt;&lt;br/&gt;config.vm.define &lt;span&gt;&quot;docker-host&quot;&lt;/span&gt;&lt;br/&gt;config.vagrant.plugins = [&lt;span&gt;&#x27;vagrant-vbguest&#x27;&lt;/span&gt;]&lt;br/&gt;&lt;br/&gt;config.vm.provider &lt;span&gt;&quot;virtualbox&quot;&lt;/span&gt; &lt;span&gt;do&lt;/span&gt; |vb|&lt;br/&gt;vb.cpus = 2&lt;br/&gt;vb.memory = &lt;span&gt;&quot;2048&quot;&lt;/span&gt;&lt;br/&gt;end&lt;br/&gt;&lt;br/&gt;config.vm.provision &lt;span&gt;&quot;shell&quot;&lt;/span&gt;, inline: &amp;lt;&amp;lt;-SHELL&lt;br/&gt;apt-get update&lt;br/&gt;apt-get install -y curl vim&lt;br/&gt;SHELL&lt;br/&gt;&lt;br/&gt;config.vm.provision &lt;span&gt;&quot;docker&quot;&lt;/span&gt;&lt;br/&gt;end&lt;br/&gt;EOF&lt;br/&gt;&lt;br/&gt;$ vagrant up&lt;br/&gt;$ vagrant ssh&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最后让我们启动一个容器：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ docker run --name foo --rm -d --memory=&lt;span&gt;&#x27;512MB&#x27;&lt;/span&gt; --cpus=&lt;span&gt;&#x27;0.5&#x27;&lt;/span&gt; nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索容器的 namespace&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先我们来看一下，当容器启动后，哪些隔离原语（primitives）被创建了：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# Look up the container in the process tree.&lt;/span&gt;&lt;br/&gt;$ ps auxf&lt;br/&gt;USER       PID  ...  COMMAND&lt;br/&gt;...&lt;br/&gt;root      4707       /usr/bin/containerd-shim-runc-v2 -namespace moby -id cc9466b3e...&lt;br/&gt;root      4727        \_ nginx: master process nginx -g daemon off;&lt;br/&gt;systemd+  4781            \_ nginx: worker process&lt;br/&gt;systemd+  4782            \_ nginx: worker process&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# Find the namespaces used by 4727 process.&lt;/span&gt;&lt;br/&gt;$ sudo lsns&lt;br/&gt;        NS TYPE   NPROCS   PID USER    COMMAND&lt;br/&gt;...&lt;br/&gt;4026532157 mnt         3  4727 root    nginx: master process nginx -g daemon off;&lt;br/&gt;4026532158 uts         3  4727 root    nginx: master process nginx -g daemon off;&lt;br/&gt;4026532159 ipc         3  4727 root    nginx: master process nginx -g daemon off;&lt;br/&gt;4026532160 pid         3  4727 root    nginx: master process nginx -g daemon off;&lt;br/&gt;4026532162 net         3  4727 root    nginx: master process nginx -g daemon off;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们可以看到用于隔离以上容器的命名空间是以下这些：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;mnt（挂载）：&lt;span&gt;#容器有一个隔离的挂载表。&lt;/span&gt;&lt;br/&gt;uts（Unix 时间共享）：&lt;span&gt;#容器拥有自己的 hostname 和 domain。&lt;/span&gt;&lt;br/&gt;ipc（进程间通信）：&lt;span&gt;#容器内的进程可以通过系统级 IPC 和同一容器内的其他进程进行通信。&lt;/span&gt;&lt;br/&gt;pid（进程 ID）：&lt;span&gt;#容器内的进程只能看到在同一容器内或拥有相同的 PID 命名空间的其他进程。&lt;/span&gt;&lt;br/&gt;net（网络）：&lt;span&gt;#容器拥有自己的网络堆栈。&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;注意&lt;/span&gt;，用户（user）命名空间没有被使用，OCI 运行时规范提及了对用户命名空间的支持。不过，虽然 Docker 可以将此命名空间用于其容器，但由于固有的限制，它默认情况下没有使用。因此，容器中的 root 用户很可能是主机系统中的 root 用户。谨防！&lt;span&gt;小编为你们精心准备了2TB的各类学习资料，包括系统运维、数据库、redis、MogoDB、电子书、Java基础课程、Java实战项目、架构师综合教程、架构师实战项目、大数据、Docker容器、ELK Stack、机器学习、BAT面试精讲视频等。只需在「民工哥技术之路」的公众号后台回复“1024”，然后按照提示加入网盘的分享组即可。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;另一个没有出现在这里的命名空间是 cgroup。我花了一段时间才理解 cgroup 命名空间与 cgroups 机制（mechanism）的不同。Cgroup 命名空间仅提供一个容器的 cgroup 层次结构的孤立视图。同样，Docker 也支持将容器放入私有 cgroup 命名空间，但默认情况下没有这么做。&lt;/span&gt;&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索容器的 cgroups&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Linux 命名空间可以让容器中的进程认为自己是在一个专用的机器上运行。但是，看不到别的进程并不意味着不会受到其他进程的影响。一些耗资源的进程可能会意外的过多消耗宿主机上面共享的资源。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这时候就需要 cgroups 的帮助！&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;可以通过检查 cgroup 虚拟文件系统中的相应子树来查看给定进程的 cgroups 限制。Cgroupfs 通常被挂在 &lt;/span&gt;&lt;code&gt;&lt;span&gt;/sys/fs/cgroup &lt;/span&gt;&lt;/code&gt;&lt;span&gt;目录，并且进程特定相关的部分可以在 &lt;/span&gt;&lt;code&gt;&lt;span&gt;/proc//cgroup &lt;/span&gt;&lt;/code&gt;&lt;span&gt;中查看：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;PID=$(docker inspect --format &lt;span&gt;&#x27;{{.State.Pid}}&#x27;&lt;/span&gt; foo)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# Check cgroupfs node for the container main process (4727).&lt;/span&gt;&lt;br/&gt;$ cat /proc/&lt;span&gt;${PID}&lt;/span&gt;/cgroup&lt;br/&gt;11:freezer:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;10:blkio:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;9:rdma:/&lt;br/&gt;8:pids:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;7:devices:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;6:cpuset:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;5:cpu,cpuacct:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;4:memory:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;3:net_cls,net_prio:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;2:perf_event:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;1:name=systemd:/docker/cc9466b3eb67ca374c925794776aad2fd45a34343ab66097a44594b35183dba0&lt;br/&gt;0::/system.slice/containerd.service&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;似乎 Docker 使用 /docker/模式。好吧，不管怎样：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ID=$(docker inspect --format &lt;span&gt;&#x27;{{.Id}}&#x27;&lt;/span&gt; foo)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# Check the memory limit.&lt;/span&gt;&lt;br/&gt;$ cat /sys/fs/cgroup/memory/docker/&lt;span&gt;${ID}&lt;/span&gt;/memory.limit_in_bytes&lt;br/&gt;536870912  &lt;span&gt;# Yay! It&#x27;s the 512MB we requested!&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# See the CPU limits.&lt;/span&gt;&lt;br/&gt;ls /sys/fs/cgroup/cpu/docker/&lt;span&gt;${ID}&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;有趣的是在不明确设置任何资源限制的情况下启动容器都会配置一个 cgroup。实际中我没有检查过，但我的猜测是默认情况下，CPU 和 RAM 消耗不受限制，Cgroups 可能用来限制从容器内部对某些设备的访问。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这是我在调查后脑海中呈现的容器：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;568&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;312&quot; data-ratio=&quot;0.6144501278772379&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/NW4iaKVI4GNPduOGI7wC6wvQYWMoMvvGh9jXHL4bR9ickAJPicHySW6lyx4pQAjrRxcFP1C4oDtYd2ekINk8hXicDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1564&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索 Pod&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;现在，让我们来看看 Kubernetes Pod。与容器一样，Pod 的实现可以在不同的 CRI 运行时（runtime）之间变化。例如，当 Kata 容器被用来作为一个支持的运行时类时，某些 Pod 可以就是真实的虚拟机了！并且正如预期的那样，基于 VM 的 Pod 与传统 Linux 容器实现的 Pod 在实现和功能方面会有所不同。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;为了保持容器和 Pod 之间公平比较，我们会在使用 ContainerD/Runc 运行时的 Kubernetes 集群上进行探索。这也是 Docker 在底层运行容器的机制。&lt;/span&gt;&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;设置实验环境（playground）&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这次我们使用基于 VirtualBox driver 和 Containd 运行时的 minikube 来设置实验环境。要快速安装 minikube 和 kubectl，我们可以使用 Alex Ellis 编写的 arkade 工具：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# Install arkade ()&lt;/span&gt;&lt;br/&gt;$ curl -sLS https://get.arkade.dev | sh&lt;br/&gt;&lt;br/&gt;$ arkade get kubectl minikube&lt;br/&gt;&lt;br/&gt;$ minikube start --driver virtualbox --container-runtime containerd&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;实验的 Pod，可以按照下面的方式设置：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ kubectl --context=minikube apply -f - &amp;lt;&amp;lt;EOF&lt;br/&gt;apiVersion: v1&lt;br/&gt;kind: Pod&lt;br/&gt;metadata:&lt;br/&gt;  name: foo&lt;br/&gt;spec:&lt;br/&gt;  containers:&lt;br/&gt;    - name: app&lt;br/&gt;      image: docker.io/kennethreitz/httpbin&lt;br/&gt;      ports:&lt;br/&gt;        - containerPort: 80&lt;br/&gt;      resources:&lt;br/&gt;        limits:&lt;br/&gt;          memory: &lt;span&gt;&quot;256Mi&quot;&lt;/span&gt;&lt;br/&gt;    - name: sidecar&lt;br/&gt;      image: curlimages/curl&lt;br/&gt;      &lt;span&gt;command&lt;/span&gt;: [&lt;span&gt;&quot;/bin/sleep&quot;&lt;/span&gt;, &lt;span&gt;&quot;3650d&quot;&lt;/span&gt;]&lt;br/&gt;      resources:&lt;br/&gt;        limits:&lt;br/&gt;          memory: &lt;span&gt;&quot;128Mi&quot;&lt;/span&gt;&lt;br/&gt;EOF&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索 Pod 的容器&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;实际的 Pod 检查应在 Kubernetes 集群节点上进行：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ minikube ssh&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;让我们看看那里 Pod 的进程：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ ps auxf&lt;br/&gt;USER       PID  ...  COMMAND&lt;br/&gt;...&lt;br/&gt;root      4947         \_ containerd-shim -namespace k8s.io -workdir /mnt/sda1/var/lib/containerd/...&lt;br/&gt;root      4966             \_ /pause&lt;br/&gt;root      4981         \_ containerd-shim -namespace k8s.io -workdir /mnt/sda1/var/lib/containerd/...&lt;br/&gt;root      5001             \_ /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;root      5016                 \_ /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;root      5018         \_ containerd-shim -namespace k8s.io -workdir /mnt/sda1/var/lib/containerd/...&lt;br/&gt;100       5035             \_ /bin/sleep 3650d&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;基于运行的时间，上述三个进程组很有可能是在 Pod 启动期间创建。这很有意思，因为在清单文件中，只有两个容器，httpbin 和 sleep。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;可以使用名为 ctr 的 ContainerD 命令行来交叉检查上述的发现：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo ctr --namespace=k8s.io containers ls&lt;br/&gt;CONTAINER      IMAGE                                   RUNTIME&lt;br/&gt;...&lt;br/&gt;097d4fe8a7002  docker.io/curlimages/curl@sha256:1a220  io.containerd.runtime.v1.linux&lt;br/&gt;...&lt;br/&gt;dfb1cd29ab750  docker.io/kennethreitz/httpbin:latest   io.containerd.runtime.v1.linux&lt;br/&gt;...&lt;br/&gt;f0e87a9330466  k8s.gcr.io/pause:3.1                    io.containerd.runtime.v1.linux&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;的确是三个容器被创建了。同时，使用另一个和 CRI 运行时监控的命令行 crictl 检测发现，仅仅只有两个容器：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo crictl ps&lt;br/&gt;CONTAINER      IMAGE          CREATED            STATE    NAME     ATTEMPT  POD ID&lt;br/&gt;097d4fe8a7002  bcb0c26a91c90  About an hour ago  Running  sidecar  0        f0e87a9330466&lt;br/&gt;dfb1cd29ab750  b138b9264903f  About an hour ago  Running  app      0        f0e87a9330466&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;但是注意，上述的 POD ID 字段和 ctr 输出的 pause:3.1 容器 id 一致。好吧，看上去这个 Pod 是一个辅助容器。所以，它有什么用呢？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我还没有注意到在 OCI 运行时规范中有和 Pod 相对应的东西。因此，当我对 Kubernetes API 规范提供的信息不满意时，我通常直接进入 Kubernetes Container Runtime 接口（CRI）Protobuf 文件中查找相应的信息：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;// kubelet expects any compatible container runtime&lt;br/&gt;// to implement the following gRPC methods:&lt;br/&gt;&lt;br/&gt;service RuntimeService {&lt;br/&gt;    ...&lt;br/&gt;    rpc RunPodSandbox(RunPodSandboxRequest) returns (RunPodSandboxResponse) {}    &lt;br/&gt;    rpc StopPodSandbox(StopPodSandboxRequest) returns (StopPodSandboxResponse) {}    &lt;br/&gt;    rpc RemovePodSandbox(RemovePodSandboxRequest) returns (RemovePodSandboxResponse) {}    &lt;br/&gt;    rpc PodSandboxStatus(PodSandboxStatusRequest) returns (PodSandboxStatusResponse) {}&lt;br/&gt;    rpc ListPodSandbox(ListPodSandboxRequest) returns (ListPodSandboxResponse) {}&lt;br/&gt;&lt;br/&gt;    rpc CreateContainer(CreateContainerRequest) returns (CreateContainerResponse) {}&lt;br/&gt;    rpc StartContainer(StartContainerRequest) returns (StartContainerResponse) {}    &lt;br/&gt;    rpc StopContainer(StopContainerRequest) returns (StopContainerResponse) {}    &lt;br/&gt;    rpc RemoveContainer(RemoveContainerRequest) returns (RemoveContainerResponse) {}&lt;br/&gt;    rpc ListContainers(ListContainersRequest) returns (ListContainersResponse) {}    &lt;br/&gt;    rpc ContainerStatus(ContainerStatusRequest) returns (ContainerStatusResponse) {}    &lt;br/&gt;    rpc UpdateContainerResources(UpdateContainerResourcesRequest) returns (UpdateContainerResourcesResponse) {}    &lt;br/&gt;    rpc ReopenContainerLog(ReopenContainerLogRequest) returns (ReopenContainerLogResponse) {}&lt;br/&gt;&lt;br/&gt;    // ...    &lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;message CreateContainerRequest {&lt;br/&gt;    // ID of the PodSandbox &lt;span&gt;in&lt;/span&gt; &lt;span&gt;which&lt;/span&gt; the container should be created.&lt;br/&gt;    string pod_sandbox_id = 1;&lt;br/&gt;    // Config of the container.&lt;br/&gt;    ContainerConfig config = 2;&lt;br/&gt;    // Config of the PodSandbox. This is the same config that was passed&lt;br/&gt;    // to RunPodSandboxRequest to create the PodSandbox. It is passed again&lt;br/&gt;    // here just &lt;span&gt;for&lt;/span&gt; easy reference. The PodSandboxConfig is immutable and&lt;br/&gt;    // remains the same throughout the lifetime of the pod.&lt;br/&gt;    PodSandboxConfig sandbox_config = 3;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所以，&lt;span&gt;Pod 实际上就是由沙盒以及在沙盒中运行的容器组成的&lt;/span&gt;。沙盒管理 Pod 中所有容器的常用资源，pause 容器会在 RunPodSandbox() 调用中被启动。简单的互联网搜索就发现了该容器仅仅是一个 idle 进程。&lt;/span&gt;&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索 Pod 的命名空间&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;下面就是集群节点上的命名空间：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo lsns&lt;br/&gt;        NS TYPE   NPROCS   PID USER            COMMAND&lt;br/&gt;4026532614 net         4  4966 root            /pause&lt;br/&gt;4026532715 mnt         1  4966 root            /pause&lt;br/&gt;4026532716 uts         4  4966 root            /pause&lt;br/&gt;4026532717 ipc         4  4966 root            /pause&lt;br/&gt;4026532718 pid         1  4966 root            /pause&lt;br/&gt;4026532719 mnt         2  5001 root            /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;4026532720 pid         2  5001 root            /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;4026532721 mnt         1  5035 100             /bin/sleep 3650d&lt;br/&gt;4026532722 pid         1  5035 100             /bin/sleep 3650d&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;前面第一部分很像 Docker 容器，pause 容器有五个命名空间：net、mnt、uts、ipc 以及 pid。但是很明显，httpbin 和 sleep 容器仅仅有两个命名空间：mnt 和 pid。这是怎么回事？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;事实证明，lsns 不是检查进程名称空间的最佳工具。相反，要检查某个进程使用的命名空间，可以参考 &lt;/span&gt;&lt;code&gt;&lt;span&gt;/proc/${pid}/ns&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 位置：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# httpbin container&lt;/span&gt;&lt;br/&gt;sudo ls -l /proc/5001/ns&lt;br/&gt;...&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 24 14:05 ipc -&amp;gt; &lt;span&gt;&#x27;ipc:[4026532717]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 24 14:05 mnt -&amp;gt; &lt;span&gt;&#x27;mnt:[4026532719]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 24 14:05 net -&amp;gt; &lt;span&gt;&#x27;net:[4026532614]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 24 14:05 pid -&amp;gt; &lt;span&gt;&#x27;pid:[4026532720]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 24 14:05 uts -&amp;gt; &lt;span&gt;&#x27;uts:[4026532716]&#x27;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# sleep container&lt;/span&gt;&lt;br/&gt;sudo ls -l /proc/5035/ns&lt;br/&gt;...&lt;br/&gt;lrwxrwxrwx 1 100 101 0 Oct 24 14:05 ipc -&amp;gt; &lt;span&gt;&#x27;ipc:[4026532717]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 100 101 0 Oct 24 14:05 mnt -&amp;gt; &lt;span&gt;&#x27;mnt:[4026532721]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 100 101 0 Oct 24 14:05 net -&amp;gt; &lt;span&gt;&#x27;net:[4026532614]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 100 101 0 Oct 24 14:05 pid -&amp;gt; &lt;span&gt;&#x27;pid:[4026532722]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 100 101 0 Oct 24 14:05 uts -&amp;gt; &lt;span&gt;&#x27;uts:[4026532716]&#x27;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;虽然不太容易去注意到，但 httpbin 和 sleep 容器实际上重用了 pause 容器的 net、uts 和 ipc 命名空间！&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们可以用 crictl 交叉检测验证：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# Inspect httpbin container.&lt;/span&gt;&lt;br/&gt;$ sudo crictl inspect dfb1cd29ab750&lt;br/&gt;{&lt;br/&gt;  ...&lt;br/&gt;  &lt;span&gt;&quot;namespaces&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;pid&quot;&lt;/span&gt;&lt;br/&gt;    },&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;ipc&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;path&quot;&lt;/span&gt;: &lt;span&gt;&quot;/proc/4966/ns/ipc&quot;&lt;/span&gt;&lt;br/&gt;    },&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;uts&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;path&quot;&lt;/span&gt;: &lt;span&gt;&quot;/proc/4966/ns/uts&quot;&lt;/span&gt;&lt;br/&gt;    },&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;mount&quot;&lt;/span&gt;&lt;br/&gt;    },&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;network&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;path&quot;&lt;/span&gt;: &lt;span&gt;&quot;/proc/4966/ns/net&quot;&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  ...&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# Inspect sleep container.&lt;/span&gt;&lt;br/&gt;$ sudo crictl inspect 097d4fe8a7002&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我认为上述发现完美的解释了同一个 &lt;span&gt;Pod 中容器具有的能力&lt;/span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;能够互相通信&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;通过 localhost 和/或&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;使用 IPC（共享内存，消息队列等）&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;共享 domain 和 hostname&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;然而，在看过所有这些命名空间如何在容器之间自由重用之后，我开始怀疑默认边界可以被打破。实际上，在对 Pod API 规范的更深入阅读后发现，将 shareProcessNamespace 标志设置为 true 时，Pod 的容器将拥有四个通用命名空间，而不是默认的三个。但是有一个更令人震惊的发现 &lt;/span&gt;&lt;code&gt;&lt;span&gt;hostIPC&lt;/span&gt;&lt;/code&gt;&lt;span&gt;、&lt;/span&gt;&lt;code&gt;&lt;span&gt;hostNetwork&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 和 &lt;/span&gt;&lt;code&gt;&lt;span&gt;hostPID&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 标志可以使容器使用相应主机的命名空间。&lt;span&gt;小编为你们精心准备了2TB的各类学习资料，包括系统运维、数据库、redis、MogoDB、电子书、Java基础课程、Java实战项目、架构师综合教程、架构师实战项目、大数据、Docker容器、ELK Stack、机器学习、BAT面试精讲视频等。只需在「民工哥技术之路」的公众号后台回复“1024”，然后按照提示加入网盘的分享组即可。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;有趣的是，CRI API 规范似乎更加灵活。至少在语法上，它允许将 net、pid 和 ipc 命名空间限定为 CONTAINER、POD 或 NODE。因此，可以构建一个 Pod 使其容器无法通过 localhost 相互通信 。&lt;/span&gt;&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;探索 Pod 的 cgroups&lt;/span&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Pod 的 cgroups 是什么样的？systemd-cgls 可以很好地可视化 cgroups 层次结构：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo systemd-cgls&lt;br/&gt;Control group /:&lt;br/&gt;-.slice&lt;br/&gt;├─kubepods&lt;br/&gt;│ ├─burstable&lt;br/&gt;│ │ ├─pod4a8d5c3e-3821-4727-9d20-965febbccfbb&lt;br/&gt;│ │ │ ├─f0e87a93304666766ab139d52f10ff2b8d4a1e6060fc18f74f28e2cb000da8b2&lt;br/&gt;│ │ │ │ └─4966 /pause&lt;br/&gt;│ │ │ ├─dfb1cd29ab750064ae89613cb28963353c3360c2df913995af582aebcc4e85d8&lt;br/&gt;│ │ │ │ ├─5001 /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;│ │ │ │ └─5016 /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;│ │ │ └─097d4fe8a7002d69d6c78899dcf6731d313ce8067ae3f736f252f387582e55ad&lt;br/&gt;│ │ │   └─5035 /bin/sleep 3650d&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所以，&lt;span&gt;Pod 本身有一个父节点（Node）&lt;/span&gt;，每个容器也可以单独调整。这符合我的预期，因为在 Pod 清单中，可以为 Pod 中的每个容器单独设置资源限制。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;此刻，我脑海中的 Pod 看起来是这样的：&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;568&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;324&quot; data-ratio=&quot;0.627&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/NW4iaKVI4GNPduOGI7wC6wvQYWMoMvvGhia7iaxE8Ahw6ImQz1W13lPTNwe8IWaYm5kcm1jzFF3IONLxE61ahpsPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2000&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;利用 Docker 实现 Pod&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果 Pod 的底层实现是一组具有共同 cgroup 父级的半融合（emi-fused）容器，是否可以使用 Docker 生产类似 Pod 的构造？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最近我尝试做了一些类似的事情来让多个容器监听同一个套接字，我知道 Docker 可以通过 &lt;/span&gt;&lt;code&gt;&lt;span&gt;docker run —network container:&lt;/span&gt;&lt;/code&gt;&lt;span&gt;语法来创建一个可以使用已存在的网络命名空间容器。但我也知道 OCI 运行时规范只定义了 create 和 start 命令。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;因此，当你使用 docker exec在现有容器中执行命令时，实际上是在运行（即 create 然后 start）一个全新的容器，该容器恰好重用了目标容器的所有命名空间。这让我非常有信心可以使用标准 Docker 命令生成 Pod。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们可以使用仅仅安装了 Docker 的机器作为实验环境。但是这里我会使用一个额外的包来简化使用 cgroups：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo apt-get install cgroup-tools&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，让我们配置一个父 cgroup 条目。为了简洁起见，我将仅使用 CPU 和内存控制器：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;sudo cgcreate -g cpu,memory:/pod-foo&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# Check if the corresponding folders were created:&lt;/span&gt;&lt;br/&gt;ls -l /sys/fs/cgroup/cpu/pod-foo/&lt;br/&gt;ls -l /sys/fs/cgroup/memory/pod-foo/&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;然后我们创建一个沙盒容器：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ docker run -d --rm \&lt;br/&gt;  --name foo_sandbox \&lt;br/&gt;  --cgroup-parent /pod-foo \&lt;br/&gt;  --ipc &lt;span&gt;&#x27;shareable&#x27;&lt;/span&gt; \&lt;br/&gt;  alpine sleep infinity&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最后，让我们启动重用沙盒容器命名空间的实际容器：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# app (httpbin)&lt;/span&gt;&lt;br/&gt;$ docker run -d --rm \&lt;br/&gt;  --name app \&lt;br/&gt;  --cgroup-parent /pod-foo \&lt;br/&gt;  --network container:foo_sandbox \&lt;br/&gt;  --ipc container:foo_sandbox \&lt;br/&gt;  kennethreitz/httpbin&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# sidecar (sleep)&lt;/span&gt;&lt;br/&gt;$ docker run -d --rm \&lt;br/&gt;  --name sidecar \&lt;br/&gt;  --cgroup-parent /pod-foo \&lt;br/&gt;  --network container:foo_sandbox \&lt;br/&gt;  --ipc container:foo_sandbox \&lt;br/&gt;  curlimages/curl sleep 365d&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你注意到我省略了哪个命名空间吗？没错，我不能在容器之间共享 uts 命名空间。似乎目前在 docker run 命令中没法实现。嗯，是有点遗憾。但是除开 uts 命名空间之外，它是成功的！&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;cgroups 看上去很像 Kubernetes 创建的：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo systemd-cgls memory&lt;br/&gt;Controller memory; Control group /:&lt;br/&gt;├─pod-foo&lt;br/&gt;│ ├─488d76cade5422b57ab59116f422d8483d435a8449ceda0c9a1888ea774acac7&lt;br/&gt;│ │ ├─27865 /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;│ │ └─27880 /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;│ ├─9166a87f9a96a954b10ec012104366da9f1f6680387ef423ee197c61d37f39d7&lt;br/&gt;│ │ └─27977 sleep 365d&lt;br/&gt;│ └─c7b0ec46b16b52c5e1c447b77d67d44d16d78f9a3f93eaeb3a86aa95e08e28b6&lt;br/&gt;│   └─27743 sleep infinity&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;全局命名空间列表看上去也很相似：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ sudo lsns&lt;br/&gt;        NS TYPE   NPROCS   PID USER    COMMAND&lt;br/&gt;...&lt;br/&gt;4026532157 mnt         1 27743 root    sleep infinity&lt;br/&gt;4026532158 uts         1 27743 root    sleep infinity&lt;br/&gt;4026532159 ipc         4 27743 root    sleep infinity&lt;br/&gt;4026532160 pid         1 27743 root    sleep infinity&lt;br/&gt;4026532162 net         4 27743 root    sleep infinity&lt;br/&gt;4026532218 mnt         2 27865 root    /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;4026532219 uts         2 27865 root    /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;4026532220 pid         2 27865 root    /usr/bin/python3 /usr/&lt;span&gt;local&lt;/span&gt;/bin/gunicorn -b 0.0.0.0:80 httpbin:app -k gevent&lt;br/&gt;4026532221 mnt         1 27977 _apt    sleep 365d&lt;br/&gt;4026532222 uts         1 27977 _apt    sleep 365d&lt;br/&gt;4026532223 pid         1 27977 _apt    sleep 365d&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;httpbin&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 和 &lt;/span&gt;&lt;code&gt;&lt;span&gt;sidecar&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 容器看上去共享了 ipc 和 net 命名空间：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# app container&lt;/span&gt;&lt;br/&gt;$ sudo ls -l /proc/27865/ns&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 28 07:56 ipc -&amp;gt; &lt;span&gt;&#x27;ipc:[4026532159]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 28 07:56 mnt -&amp;gt; &lt;span&gt;&#x27;mnt:[4026532218]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 28 07:56 net -&amp;gt; &lt;span&gt;&#x27;net:[4026532162]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 28 07:56 pid -&amp;gt; &lt;span&gt;&#x27;pid:[4026532220]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 root root 0 Oct 28 07:56 uts -&amp;gt; &lt;span&gt;&#x27;uts:[4026532219]&#x27;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# sidecar container&lt;/span&gt;&lt;br/&gt;$ sudo ls -l /proc/27977/ns&lt;br/&gt;lrwxrwxrwx 1 _apt systemd-journal 0 Oct 28 07:56 ipc -&amp;gt; &lt;span&gt;&#x27;ipc:[4026532159]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 _apt systemd-journal 0 Oct 28 07:56 mnt -&amp;gt; &lt;span&gt;&#x27;mnt:[4026532221]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 _apt systemd-journal 0 Oct 28 07:56 net -&amp;gt; &lt;span&gt;&#x27;net:[4026532162]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 _apt systemd-journal 0 Oct 28 07:56 pid -&amp;gt; &lt;span&gt;&#x27;pid:[4026532223]&#x27;&lt;/span&gt;&lt;br/&gt;lrwxrwxrwx 1 _apt systemd-journal 0 Oct 28 07:56 uts -&amp;gt; &lt;span&gt;&#x27;uts:[4026532222]&#x27;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Container 和 Pod 是相似的。在底层，它们主要依赖 Linux 命名空间和 cgroup。但是，&lt;span&gt;Pod 不仅仅是一组容器&lt;/span&gt;。Pod 是一个自给自足的高级构造。所有 Pod 的容器都运行在同一台机器（集群节点）上，它们的生命周期是同步的，并且通过削弱隔离性来简化容器间的通信。这使得 Pod 更接近于传统的 VM，带回了熟悉的部署模式，如 sidecar 或反向代理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;---END---&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;推荐↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzI4MDEwNzAzNg==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/zYdZKiaLibic67sHnnpIbiaUZ4RWpClUiavPRn5ib37s9hNEnQE4dUca89nsFQV5kzibFwzAgBlcWmHXY53a8ouOEdnKQ/0?wx_fmt=png&quot; data-nickname=&quot;Linux学习&quot; data-alias=&quot;LoveLinux1024&quot; data-signature=&quot;专注分享Linux/Unix相关内容，包括Linux命令、Linux内核、Linux系统开发、Linux运维、网络编程、开发工具等Linux相关知识和技术&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>178bc510b0abd1639f13e802b4b9590a</guid>
<title>联邦学习开源框架 FATE 架构</title>
<link>https://toutiao.io/k/67p1qkb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h4&gt;作者：京东科技 葛星宇&lt;/h4&gt;

&lt;h1&gt;1.前言&lt;/h1&gt;

&lt;p&gt;本文除特殊说明外，所指的都是fate 1.9版本。&lt;/p&gt;

&lt;p&gt;fate资料存在着多处版本功能与发布的文档不匹配的情况，各个模块都有独立的文档，功能又有关联，坑比较多，首先要理清楚各概念、模块之间的关系。&lt;/p&gt;

&lt;h1&gt;2.网络互联架构&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ea43ad8e02342e9bced2d1d3d6d3c0f%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 概念解释：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RollSite是一个grpc通信组件，是eggroll引擎中的一个模块，相当于我们的grpc通信网关。&lt;/p&gt;

&lt;p&gt;Exchange是RollSite中的一个功能，用于维护各方网关地址，并转发消息。参考&lt;a href=&quot;https://github.com/FederatedAI/FATE/blob/v1.9.0/deploy/cluster-deploy/doc/fate_on_eggroll/fate-exchange_deployment_guide.zh.md&quot;&gt;《FATE exchange部署指南》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 对比解读：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;l 网状架构相当于我们的一体化版本模式，但没有dop平台来维护网关，每方需要在配置文件里维护其他参与方的网关地址。&lt;/p&gt;

&lt;p&gt;l 星型架构的好处是只在Exchange方维护所有参与方的网关地址，前提是需要信任Exchange，并且流量全部都需要从Exchange方中转，相当于我们的中心化版本。但不支持证书。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Exchange配置&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Exchange上配置路由表：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a7f598a022344b8d8bf7356ce399968d%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在各party方配置默认路由指向exchange，不需要再配置每个party的地址。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/adb412765185428b9c7782128bf04ff0%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;3.总体架构&lt;/h1&gt;

&lt;p&gt;FATE支持eggroll和spark两种计算引擎,搭配不同的通信组件，共五种组合，不同的通信模块不能兼容。&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方案名&lt;/th&gt;
&lt;th&gt;计算引擎&lt;/th&gt;
&lt;th&gt;存储&lt;/th&gt;
&lt;th&gt;通信&lt;/th&gt;
&lt;th&gt;是否支持exchange&lt;/th&gt;
&lt;th&gt;task调度&lt;/th&gt;
&lt;th&gt;特点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;EggRoll&lt;/td&gt;
&lt;td&gt;nodemanager&lt;/td&gt;
&lt;td&gt;nodemanager&lt;/td&gt;
&lt;td&gt;rollsite&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;clustermanager&lt;/td&gt;
&lt;td&gt;原生、最成熟&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spark_RabbitMQ&lt;/td&gt;
&lt;td&gt;spark&lt;/td&gt;
&lt;td&gt;hdfs&lt;/td&gt;
&lt;td&gt;nginx+ rabbit&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;yarn？&lt;/td&gt;
&lt;td&gt;简单易上手的MQ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Spark_Pulsar&lt;/td&gt;
&lt;td&gt;spark&lt;/td&gt;
&lt;td&gt;hdfs&lt;/td&gt;
&lt;td&gt;nginx+ pulsar&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;yarn？&lt;/td&gt;
&lt;td&gt;比RabbitMQ，可以支持更大规模的集群化部署&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Slim FATE&lt;/td&gt;
&lt;td&gt;spark_local&lt;/td&gt;
&lt;td&gt;localFS&lt;/td&gt;
&lt;td&gt;nginx+ pulsar&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;spark？&lt;/td&gt;
&lt;td&gt;最小资源。可用rabbit替代pulsar&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;参考：：&lt;a href=&quot;https://github.com/FederatedAI/KubeFATE/blob/v1.9.0/docs/Introduction_to_Engine_Architecture_zh.md&quot;&gt;《不同类型FATE的架构介绍》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;区别：&lt;/p&gt;

&lt;p&gt;l RabbitMQ是一个简单易上手的MQ&lt;/p&gt;

&lt;p&gt;l Pulsar相比RabbitMQ，可以支持更大规模的集群化部署，也支持exchange模式的网络结构。&lt;/p&gt;

&lt;p&gt;l Slim FATE相比其他模式，最大化减少集群所需的组件，可以使用在小规模联邦学习计算，IOT设备等情况。&lt;/p&gt;

&lt;h2&gt;3.1.基于EggRoll引擎的架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0658f49336254b4191a9f88e84e41968%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Eggroll是FATE原生支持的计算存储引擎，包括以下三个组件：&lt;/p&gt;

&lt;p&gt;l rollsite负责数据传输，以前的版本里叫 Proxy+Federation&lt;/p&gt;

&lt;p&gt;l nodemanager负责存储和计算&lt;/p&gt;

&lt;p&gt;l clustermanager负责管理nodemanager&lt;/p&gt;

&lt;h2&gt;3.2.基于spark+hdfs+rabbitMQ的架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/48aa31e718d34ad083cfd98713bd35d0%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;3.3. 基于spark+hdfs+Pulsar的架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/507970682c38462ea4a1325fb3dec113%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;3.4. spark_local (Slim FATE)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2d92603a1e8844bb9d3f2ddad0346452%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;支持rabbitMQ替换pulsar&lt;/p&gt;

&lt;h1&gt;4. 组件源码&lt;/h1&gt;

&lt;p&gt;所有的fate项目都在这个叫FederateAI社区的URL下：&lt;a href=&quot;https://github.com/FederatedAI&quot;&gt;https://github.com/FederatedAI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;主项目：&lt;a href=&quot;https://github.com/FederatedAI/FATE&quot;&gt;FATE&lt;/a&gt;是一个汇总的文档和超链集合，  &lt;a href=&quot;https://github.com/FederatedAI/FATE/blob/v1.9.0/README_zh.md&quot;&gt;学习入口&lt;/a&gt;，&lt;a href=&quot;https://fate.readthedocs.io/en/develop/_build_temp/python/fate_flow/README_zh.html&quot;&gt;在线文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;关联项目：&lt;/p&gt;

&lt;p&gt;•KubeFATE docker和k8s的部署&lt;/p&gt;

&lt;p&gt;•AnsibleFATE 相当于我们的图形化部署版的底层脚本  &lt;a href=&quot;https://github.com/FederatedAI/AnsibleFATE/blob/main/README_zh.md&quot;&gt;学习入口&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;•FATE-Flow 联合学习任务流水线管理模块，注册、管理和调度中心。&lt;/p&gt;

&lt;p&gt;•EggRoll 第一代fate的计算引擎&lt;/p&gt;

&lt;p&gt;•FATE-Board 联合学习过程可视化模块，目前只能查看一些记录&lt;/p&gt;

&lt;p&gt;•FATE-Serving 在线联合预测，&lt;a href=&quot;https://fate-serving.readthedocs.io/en/develop/&quot;&gt;学习入口&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;•FATE-Cloud 联邦学习云服务,类似于我们的dop平台，管理功能。&lt;/p&gt;

&lt;p&gt;•FedVision 联邦学习支持的可视化对象检测平台&lt;/p&gt;

&lt;p&gt;•FATE-Builder fate编译工具&lt;/p&gt;

&lt;p&gt;•FedLCM 新增的项目：创建 FATE 联邦并部署FATE实例。目前仅支持部署以Spark和Pulsar作为基础引擎，并使用Exchange实现互相连接的&lt;/p&gt;

&lt;h1&gt;5. FATE-Flow&lt;/h1&gt;

&lt;p&gt;FATE Flow是调度系统，根据用户提交的作业DSL，调度算法组件执行。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://fate-flow.readthedocs.io/en/latest/zh/fate_flow/&quot;&gt;官网文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;服务能力:&lt;/p&gt;

&lt;p&gt;· 数据接入&lt;/p&gt;

&lt;p&gt;· 任务组件注册中心&lt;/p&gt;

&lt;p&gt;· 联合作业&amp;amp;任务调度&lt;/p&gt;

&lt;p&gt;· 多方资源协调&lt;/p&gt;

&lt;p&gt;· 数据流动追踪&lt;/p&gt;

&lt;p&gt;· 作业实时监测&lt;/p&gt;

&lt;p&gt;· 联合模型注册中心&lt;/p&gt;

&lt;p&gt;· 多方合作权限管理&lt;/p&gt;

&lt;p&gt;· 系统高可用&lt;/p&gt;

&lt;p&gt;· CLI、REST API、Python API&lt;/p&gt;

&lt;h2&gt;5.1. 流程架构&lt;/h2&gt;

&lt;p&gt;旧版，图比较立体&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed5704434f6c4ed58ebe52fd42f27af8%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;· DSL Parser：是调度的核心，通过 DSL parser 可以拿到上下游关系、依赖等。&lt;/p&gt;

&lt;p&gt;· Job Scheduler：是 DAG 层面的调度，把 DAG 作为一个 Job，把 DAG 里面的节点 run 起来，就称为一个 task。&lt;/p&gt;

&lt;p&gt;· Federated Task Scheduler：最小调度粒度就是 task，需要调度多方运行同一个组件但参数算法不同的 task，结束后，继续调度下一个组件，这里就会涉及到协同调度的问题。&lt;/p&gt;

&lt;p&gt;· Job Controller：联邦任务控制器&lt;/p&gt;

&lt;p&gt;· Executor：联邦任务执行节点，支持不同的 Operator 容器，现在支持 Python 和 Script 的 Operator。Executor，在我们目前的应用中拉起 FederatedML 定义的一些组件，如 data io 数据输入输出，特征选择等模块，每次调起一个组件去 run，然后，这些组件会调用基础架构的 API，如 Storage 和 Federation Service ( API 的抽象 ) ，再经过 Proxy 就可以和对端的 FATE-Flow 进行协同调度。&lt;/p&gt;

&lt;p&gt;· Tracking Manager：任务输入输出的实时追踪，包括每个 task 输出的 data 和 model。&lt;/p&gt;

&lt;p&gt;· Model Manager：联邦模型管理器&lt;/p&gt;

&lt;h2&gt;5.2. api service&lt;/h2&gt;

&lt;p&gt;DataAccess 数据上传，下载，历史记录,参考&lt;a href=&quot;https://federatedai.github.io/FATE-Flow/latest/zh/fate_flow_data_access/&quot;&gt;示例&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Job 提交（并运行），停止，查询，更新，配置，列表，task查询&lt;/p&gt;

&lt;p&gt;Tracking&lt;/p&gt;

&lt;p&gt;Pipeline&lt;/p&gt;

&lt;p&gt;Model&lt;/p&gt;

&lt;p&gt;Table&lt;/p&gt;

&lt;p&gt;客户端命令行实际上是对api的包装调用，可以参考其&lt;a href=&quot;https://fate-flow.readthedocs.io/en/latest/zh/fate_flow_client/&quot;&gt;示例&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Python调用api&lt;a href=&quot;https://federatedai.github.io/FATE-Flow/latest/zh/fate_flow_http_api_call_demo/&quot;&gt;示例&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;5.3. 算法模块&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://fate.readthedocs.io/en/develop/_build_temp/python/federatedml/README_zh.html&quot;&gt;Federatedml&lt;/a&gt;模块包括许多常见机器学习算法联邦化实现。所有模块均采用去耦的模块化方法开发，以增强模块的可扩展性。具体来说，我们提供：&lt;/p&gt;

&lt;p&gt;1.联邦统计: 包括隐私交集计算，并集计算，皮尔逊系数, PSI等&lt;/p&gt;

&lt;p&gt;2.联邦特征工程：包括联邦采样，联邦特征分箱，联邦特征选择等。&lt;/p&gt;

&lt;p&gt;3.联邦机器学习算法：包括横向和纵向的联邦LR, GBDT， DNN，迁移学习等&lt;/p&gt;

&lt;p&gt;4.模型评估：提供对二分类，多分类，回归评估，聚类评估，联邦和单边对比评估&lt;/p&gt;

&lt;p&gt;5.安全协议：提供了多种安全协议，以进行更安全的多方交互计算。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a2ce57f7ed764c6db04a00d85805527c%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Figure 1： Federated Machine Learning Framework&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;可开发在fate框架下运行的算法：&lt;a href=&quot;https://github.com/FederatedAI/FATE/blob/v1.9.0/doc/develop/develop_guide.zh.md&quot;&gt;指南&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;6. FATE-Serving&lt;/h1&gt;

&lt;h2&gt;6.1. 功能架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bc6e4ea88807441b90b5fc8ed5e9a9a0%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;6.2. 部署逻辑架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d3b46328dea340c6995968286d33faf8%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Adatptor：默认的情况使用系统自带的MockAdatptor，仅返回固定数据用于简单测试，实际生产环境中需要使用者需要自行开发并对接自己的业务系统。（这部分可以看看能不能对接咱们自己的在线预测系统。）&lt;/p&gt;

&lt;p&gt;l 支持使用rollsite/nginx/fateflow作为多方任务协调通信代理&lt;/p&gt;

&lt;p&gt;l rollsite支持fate on eggroll的场景，仅支持grpc协议，支持P2P组网及星型组网模式&lt;/p&gt;

&lt;p&gt;l nginx支持所有引擎场景，支持http与grpc协议，默认为http，支持P2P组网及星型组网模式&lt;/p&gt;

&lt;p&gt;l fateflow支持所有引擎场景，支持http与grpc协议，默认为http，仅支持P2P组网模式，也即只支持互相配置对端fateflow地址&lt;/p&gt;

&lt;h2&gt;6.3. 部署实例图&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fd319d4c80e94cce813faa823acfdd47%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;6.4. 工作时序图&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9acb7f8c77a14930baef6e26b6a3fcc7%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;6.5. 模型推送流程&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2653b416725f436f9a72245d9f8a456b%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;蓝色为guest集群，灰色代表host集群&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1. 通过fate flow建模 2. 分别部署guest方 Fate-serving 与host方Fate-serving&lt;/p&gt;

&lt;p&gt;3. 分别配置好guest方Fate-flow与guest方Fate-serving、host方Fate-flow 与host方Fate-serving。&lt;/p&gt;

&lt;p&gt;4. Fate-flow推送模型&lt;/p&gt;

&lt;p&gt;5. Fate-flow将模型绑定serviceId&lt;/p&gt;

&lt;p&gt;6. 以上操作完成后，可以在serving-admin页面上查看模型相关信息（此步操作非必需）。&lt;/p&gt;

&lt;p&gt;7. 可以在serving-admin页面上测试调用（此步操作非必需）。&lt;/p&gt;

&lt;h2&gt;6.6. 搭配nginx代理&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://fate-serving.readthedocs.io/en/develop/example/nginx/&quot;&gt;https://fate-serving.readthedocs.io/en/develop/example/nginx/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;FATE-Serving 之间的交互可以通过nginx反向代理转发grpc请求，以下几种场景配置如下：&lt;/p&gt;

&lt;p&gt;· 场景一：双方不配置TLS，通过nginx四层代理转发&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dd585057082548e984b607f1d7698976%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;· 场景二：双方配置TLS，通过nginx四层代理转发，双方分别进行证书校验&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/52fa27392ecb40b0916236faf40edbe3%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;· 场景三：数据使用方配置Client端证书，Nginx配置Server端证书，Host不配置证书，通过nginx七层代理转发，由Client端和nginx进行证书校验&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/007118cb647b4810bf4318f6c11d6fbe%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;7. FATE Cloud&lt;/h1&gt;

&lt;p&gt;FATE Cloud由负责联邦站点管理的云管理端Cloud Manager和站点客户端管理端FATE Manager组成，提供了联邦站点的注册与管理、集群自动化部署与升级、集群监控、集群权限控制等核心功能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;联邦云管理端（Cloud Manager）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;联邦云管理端即联邦数据网络的管理中心，负责统一运营和管理FATE Manager及各站点，监控站点的服务与联邦合作建模，执行联邦各权限控制，保证联邦数据合作网络的正常运作；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;联邦站点管理端（FATE Manager）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;联邦站点管理端，负责管理和维护各自的联邦站点，为站点提供加入联邦组织、执行站点服务的自动化部署与升级，监控站点的联邦合作与集群服务，并管理站点用户角色与应用权限；&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/FederatedAI/FATE-Cloud/blob/master/docs/FATE-Cloud%E4%BA%A7%E5%93%81%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.pdf&quot;&gt;产品手册&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/620c9a4b76c74b38b34130e0fd738ae8%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;8. 部署测试&lt;/h1&gt;

&lt;p&gt;共有4类部署方式，单机的安装模式是只提供了单机的安装文档，也可以研究怎么扩展成集群模式。&lt;/p&gt;

&lt;p&gt;|  | 单机（不推荐生产用） | 集群（生产推荐） |
| 非容器 | AllinOne | ansible |
| 容器 | docker compose | k8s |&lt;/p&gt;

&lt;p&gt;部署时会要求配置机器对应的角色，只能选host，guest和Exchange，其中host和guest并没有区别，实际运行联邦时还是在job的配置中去配置哪一方是guest，哪一方是host，任务只能在guest方提交。&lt;/p&gt;

&lt;h2&gt;8.1. AllinOne&lt;/h2&gt;

&lt;p&gt;所有的组件都部署在一台机器上，比较适合开发调试，参考&lt;a href=&quot;https://github.com/FederatedAI/FATE/blob/v1.9.0/deploy/cluster-deploy/doc/fate_on_eggroll/fate-allinone_deployment_guide.zh.md&quot;&gt;链接&lt;/a&gt;。&lt;/p&gt;

&lt;h2&gt;8.2. ansible&lt;/h2&gt;

&lt;p&gt;尝试用ansible部署时遇到了python相关的错误，指导文档也缺少详细的步骤，没有相关错误的说明。&lt;/p&gt;

&lt;h2&gt;8.3. k8s&lt;/h2&gt;

&lt;p&gt;手上没有k8s环境，暂未测试。&lt;/p&gt;

&lt;p&gt;参考文档：&lt;a href=&quot;https://github.com/FederatedAI/KubeFATE/blob/v1.9.0/docs/Introduction_to_Engine_Architecture_zh.md&quot;&gt;《KubeFATE 部署FATE支持引擎介绍》&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;8.4. docker compose&lt;/h2&gt;

&lt;p&gt;容器部署尝试用docker compose方式部署了一对，比较顺利，参考了2篇官方文章，前边的准备步骤和安装过程参考&lt;a href=&quot;https://github.com/FederatedAI/KubeFATE/wiki/%E4%BD%BF%E7%94%A8Docker-Compose-%E9%83%A8%E7%BD%B2FATE-v1.5.0&quot;&gt;此文&lt;/a&gt;，“验证部署”及之后的步骤参考&lt;a href=&quot;https://github.com/FederatedAI/KubeFATE/blob/v1.9.0/docker-deploy/README_zh.md&quot;&gt;《Docker Compose 部署 FATE》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不同点如下：&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;8.4.1. 准备阶段&lt;/h3&gt;

&lt;p&gt;下载镜像较慢，如果大批量部署，可以搭建内网镜像服务。&lt;/p&gt;

&lt;p&gt;| Role | party-id | OS | IP |  |
| host | 20001 | Centos7.6 | 11.50.52.81 | 8C64G |
| guest | 20002 | Centos7.6 | 11.50.52.62 | 8C64G |
| 部署机 |  | Centos7.6 | 11.50.52.40 |  |&lt;/p&gt;

&lt;p&gt;以上内容替代文档中对应的部分内容。&lt;/p&gt;

&lt;p&gt;一开始我只部署了一台host，本来打算这2台做一个集群，后来发现文档里没提这种方式，只好先按文档实验一次，于是又部署了guest，这样在guest的配置里已经写好了host的地址，于是手动将配置更新到了host的/data/projects/fate/confs-20001/confs/eggroll/conf/route_table.json&lt;/p&gt;

&lt;p&gt;发现不需要重启容器后续步骤也没报错，说明可以动态修改路由信息。&lt;/p&gt;

&lt;h3&gt;8.4.2. hetero_lr测试&lt;/h3&gt;

&lt;p&gt;进入容器的时候，容器名包含的平台id需要修改成实际的。&lt;/p&gt;

&lt;p&gt;json格式定义&lt;a href=&quot;https://fate.readthedocs.io/en/latest/zh/tutorial/dsl_conf/dsl_conf_v2_setting_guide/&quot;&gt;说明文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fateflow/examples/lr/test_hetero_lr_job_conf.json 中不同点，&lt;/p&gt;

&lt;p&gt;修改对应的平台id&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &quot;initiator&quot;: {
 &quot;role&quot;: &quot;guest&quot;,
 &quot;party_id&quot;: 20002
 },
 &quot;role&quot;: {
 &quot;guest&quot;: [
 20002
 ],
 &quot;host&quot;: [
 20001
 ],
 &quot;arbiter&quot;: [
 20001
 ]
 },

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;按文档写资源不够运行不了,需要修改如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&quot;job_parameters&quot;: {
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;    &quot;common&quot;: {
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;      &quot;task_parallelism&quot;: 1,
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;      &quot;computing_partitions&quot;: 1,
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;      &quot;task_cores&quot;: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;    }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不要修改fateflow/examples/lr/test_hetero_lr_job_dsl.json文件，文档中的配置是旧版本的，修改了就不能执行了，里面的DataIO组件已废弃。&lt;/p&gt;

&lt;p&gt;运行测试后可以通过board查看，成功的id：202211031508511267810&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://11.50.52.62:8080/#/history&quot;&gt;http://11.50.52.62:8080/#/history&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://11.50.52.81:8080/#/history&quot;&gt;http://11.50.52.81:8080/#/history&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;8.4.3. 模型部署&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# flow model deploy --model-id arbiter-20001#guest-20002#host-20001#model --model-version 202211031508511267810
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出了产生的model_version是202211031811059832400&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 修改加载模型的配置&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# cat &amp;gt; fateflow/examples/model/publish_load_model.json &amp;lt;&amp;lt;EOF
{
  &quot;initiator&quot;: {
    &quot;party_id&quot;: &quot;20002&quot;,
    &quot;role&quot;: &quot;guest&quot;
  },
  &quot;role&quot;: {
    &quot;guest&quot;: [
      &quot;20002&quot;
    ],
    &quot;host&quot;: [
      &quot;20001&quot;
    ],
    &quot;arbiter&quot;: [
      &quot;20001&quot;
    ]
  },
  &quot;job_parameters&quot;: {
    &quot;model_id&quot;: &quot;arbiter-20001#guest-20002#host-20001#model&quot;,
    &quot;model_version&quot;: &quot;202211031811059832400&quot;
  }
}
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;2. 修改绑定模型的配置&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# cat &amp;gt; fateflow/examples/model/bind_model_service.json &amp;lt;&amp;lt;EOF
{
    &quot;service_id&quot;: &quot;test&quot;,
    &quot;initiator&quot;: {
        &quot;party_id&quot;: &quot;20002&quot;,
        &quot;role&quot;: &quot;guest&quot;
    },
    &quot;role&quot;: {
        &quot;guest&quot;: [&quot;20002&quot;],
        &quot;host&quot;: [&quot;20001&quot;],
        &quot;arbiter&quot;: [&quot;20001&quot;]
    },
    &quot;job_parameters&quot;: {
        &quot;work_mode&quot;: 1,
        &quot;model_id&quot;: &quot;arbiter-20001#guest-20002#host-20001#model&quot;,
        &quot;model_version&quot;: &quot;202211031811059832400&quot;
    }
}
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3. 在线测试&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;发送以下信息到&quot;GUEST&quot;方的推理服务&quot;{SERVING_SERVICE_IP}:8059/federation/v1/inference&quot;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# curl -X POST -H &#x27;Content-Type: application/json&#x27; -i &#x27;http://11.50.52.62:8059/federation/v1/inference&#x27; --data &#x27;{
  &quot;head&quot;: {
    &quot;serviceId&quot;: &quot;test&quot;
  },
  &quot;body&quot;: {
    &quot;featureData&quot;: {
        &quot;x0&quot;: 1.88669,
        &quot;x1&quot;: -1.359293,
        &quot;x2&quot;: 2.303601,
        &quot;x3&quot;: 2.00137,
        &quot;x4&quot;: 1.307686
    },
    &quot;sendToRemoteFeatureData&quot;: {
        &quot;phone_num&quot;: &quot;122222222&quot;
    }
  }
}&#x27;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;9.在Jupyther中构建任务&lt;/h1&gt;

&lt;p&gt;Jupyter Notebook是web界面IDE。已集成在fate-client容器中。&lt;/p&gt;

&lt;h1&gt;10. 总结&lt;/h1&gt;

&lt;p&gt;本文旨在从宏观的角度分析FATE的源码分布、总体架构、主要功能及核心流程，尚有许多细节和功能未深入研究，欢迎大家留言，互相学习。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c167e7a4cec9fb16c0133ef60020e3eb</guid>
<title>协同存储，为边缘计算创造更大价值</title>
<link>https://toutiao.io/k/w25kqnw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-1g0fqss&quot; options=&quot;[object Object]&quot;&gt;&lt;h2 data-first-child=&quot;&quot;&gt;01 数据的爆发为存储带来持续挑战&lt;/h2&gt;&lt;p data-pid=&quot;Y4bVbtni&quot;&gt;在5G时代下，视频和图片因其强大的信息承载力，已经成为数据内容的主要载体和信息传播的主要方式。而5G的大带宽、低时延、广连接的特性激活了云游戏、物联网、视频监控等场景应用，从消费互联网到产业互联网的延伸，更加促进了终端应用和数据的爆发。&lt;/p&gt;&lt;p data-pid=&quot;Gs7EC7Al&quot;&gt;这些终端和数据具有位置分散、规模大、以及价值密度相对较低等特点，典型的如：视频监控录像/截图、云游戏录像、海量临时日志文件等。一方面，我们需要提供就近、低延迟的数据接入与存储能力，另一方面，我们需要在边缘进行数据的精细化管理，与计算相结合，分析其中的关键片段以及其结构化信息。&lt;/p&gt;&lt;p data-pid=&quot;aahvgp4F&quot;&gt;这样的场景和需求对计算和存储的方式带来了严峻挑战和根本性变化。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d0f6621f53f709b90d1f7ec4e1150f95_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1574&quot; data-rawheight=&quot;760&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-d0f6621f53f709b90d1f7ec4e1150f95_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1574&quot; data-rawheight=&quot;760&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-d0f6621f53f709b90d1f7ec4e1150f95_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d0f6621f53f709b90d1f7ec4e1150f95_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h2&gt;02 基于边缘云构建位置无感的协同存储服务&lt;/h2&gt;&lt;p data-pid=&quot;BxhF0B_L&quot;&gt;用户在使用对象存储时，针对海量数据，提出了大流量、就近、低延迟的要求，边缘云在这些方面具备天然优势，但边缘云的对象存储在使用方式和体验上存在明显不足。相较于传统中心云的region化使用方式，边缘云的单点规模较小，并且节点数多了几个量级。&lt;/p&gt;&lt;p data-pid=&quot;jiFyz7pU&quot;&gt;如果每个边缘云节点独立进行对象存储服务，无异于将复杂的逻辑交给用户，用户使用时将面临节点资源管理、资源读写调度、单节点可用性运维等诸多复杂问题。这会对用户业务带来巨大的挑战，任何节点状态的变化，都可能带来业务的感知，处理不好甚至会对业务造成严重影响。&lt;/p&gt;&lt;p data-pid=&quot;fB8E51S7&quot;&gt;以摄像头数据上云为例，传统的方式，用户需要感知终端设备的地理位置，并且需要去维护海量终端设备和云上地址的对应关系，一旦出现单点故障，用户需要做大量的动作来进行调度和迁移。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-271c39832ec25905f89e87a3b930ed65_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1388&quot; data-rawheight=&quot;740&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-271c39832ec25905f89e87a3b930ed65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1388&quot; data-rawheight=&quot;740&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-271c39832ec25905f89e87a3b930ed65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-271c39832ec25905f89e87a3b930ed65_b.jpg&quot;/&gt;&lt;figcaption&gt;传统的数据上云架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-pid=&quot;vKJYRXyC&quot;&gt;而理想的架构中，用户无需关心具体的云上位置，希望与云只有一个交互面，就能实现全网设备的就近、低延迟接入，并且无需关心云上单节点的负载、水位、异常等情况。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3d4dd4988abd7abfe8ce628fc0e82bcf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1356&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-3d4dd4988abd7abfe8ce628fc0e82bcf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1356&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-3d4dd4988abd7abfe8ce628fc0e82bcf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3d4dd4988abd7abfe8ce628fc0e82bcf_b.jpg&quot;/&gt;&lt;figcaption&gt;理想的数据上云架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-pid=&quot;ZUP9WaXe&quot;&gt;边缘计算孵化了位置无感的协同存储(EOS)服务，通过中心管控和多个边缘节点进行协同，将分布在各地边缘节点的物理存储资源，组成一个逻辑统一的对象存储资源池。&lt;b&gt;用户无需关心读写位置和单节点可用性带来的运维和调度问题&lt;/b&gt;，即可得到与使用公有云对象存储一致的接口体验，以及由数量众多的边缘存储资源整合而带来的大容量、高弹性的存储资源池。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-26d4bf5d9ba34d999a0a14b15ed92e1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1142&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-26d4bf5d9ba34d999a0a14b15ed92e1b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1142&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-26d4bf5d9ba34d999a0a14b15ed92e1b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-26d4bf5d9ba34d999a0a14b15ed92e1b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h2&gt;03 协同存储核心模块&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f326ac882fae4200fba76d64698e64b0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;832&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-f326ac882fae4200fba76d64698e64b0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;832&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-f326ac882fae4200fba76d64698e64b0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f326ac882fae4200fba76d64698e64b0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;bRmpqHoZ&quot;&gt;协同存储采用了典型的云边协同架构，其核心包含中心管控与边缘节点两部分，其中，中心管控包含以下管理模块:&lt;/p&gt;&lt;ol&gt;&lt;li data-pid=&quot;5XqNC2GQ&quot;&gt;元数据管理：汇聚全网的元数据进行统一管理，与文件读写调度、文件生命周期等联动；&lt;/li&gt;&lt;li data-pid=&quot;zye92pr3&quot;&gt;资源调度：负责逻辑存储桶与物理存储桶的映射关系管理，根据节点状态、水位进行全局资源动态规划；&lt;/li&gt;&lt;li data-pid=&quot;ierTwnJK&quot;&gt;读写调度：根据用户地理位置、所需资源量、文件分布等因素进行全局文件读写调度；&lt;/li&gt;&lt;li data-pid=&quot;RJAvniXH&quot;&gt;多点数据协同：对节点数据进行跨节点复制或数据迁移，提高整体服务可用性；&lt;/li&gt;&lt;/ol&gt;&lt;p data-pid=&quot;XkW0XcbL&quot;&gt;边缘节点包含以下管理模块：&lt;/p&gt;&lt;p data-pid=&quot;P-E5U6hK&quot;&gt;1.节点网关：提供节点文件读写服务，如存储协议兼容、http/ https访问支持、动态配置、跨域管理、流控、日志监控等。&lt;/p&gt;&lt;p data-pid=&quot;ArryTYxm&quot;&gt;2.边缘管控&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;AIUpIizU&quot;&gt;与中心管控协同完成完整的管控逻辑，同时在节点范围内具备一定的边缘自治能力;&lt;/li&gt;&lt;li data-pid=&quot;G4Ufm4NZ&quot;&gt;负责节点内存储管理、跨节点数据复制/迁移等操作;&lt;/li&gt;&lt;li data-pid=&quot;Owx1jxjA&quot;&gt;负责节点内多引擎容灾。&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;LRhxy3gj&quot;&gt;3.存储引擎：提供基础的存储能力(文件读写等)以及文件容灾能力(EC、三副本等)。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h2&gt;04协同存储的关键技术&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cc7d51ce399e16c5fd96421bd4ec324d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1736&quot; data-rawheight=&quot;1028&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-cc7d51ce399e16c5fd96421bd4ec324d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1736&quot; data-rawheight=&quot;1028&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-cc7d51ce399e16c5fd96421bd4ec324d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cc7d51ce399e16c5fd96421bd4ec324d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;ZwWwjTTH&quot;&gt;基于边缘节点构建的位置无感分布式协同存储，关键技术在于以下几点：&lt;/p&gt;&lt;p data-pid=&quot;yXu9Og_y&quot;&gt;1.节点统一纳管与调度&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-54edfa8088e47945ae7b99261fc027d9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;832&quot; data-rawheight=&quot;218&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-54edfa8088e47945ae7b99261fc027d9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;832&quot; data-rawheight=&quot;218&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-54edfa8088e47945ae7b99261fc027d9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-54edfa8088e47945ae7b99261fc027d9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;Ui61UHyi&quot;&gt;对用户而言，和边缘云只有一个交互面，协同存储将多个物理节点抽象为一个逻辑节点，通过全网资源的统一纳管，进行多维度的协同调度，过程中会综合地理位置、节点带宽、存储空间、设备亲和性等众多因素，从而实现服务的高可用以及数据的就近存取，同时，协同存储提供了灵活的接入和调度策略供业务按需使用（全国、区域、运营商、单节点、自定义节点范围）。&lt;/p&gt;&lt;p data-pid=&quot;zUTia-ea&quot;&gt;2.文件读写调度&lt;/p&gt;&lt;p data-pid=&quot;938sI2Lc&quot;&gt;协同存储物理文件存储在边缘节点，存储空间、文件元信息等汇聚到中心，进行统一的管理和检索。&lt;/p&gt;&lt;p data-pid=&quot;_Hac_dVU&quot;&gt;使用方式上，文件写入和读取均可采用302调度方式，写入统一域名，协同存储经过地理位置、节点水位等综合调度后，将请求跳转到真实的物理节点进行读写，用户无需关心终端所在位置，即可快速就近、低延迟接入。&lt;/p&gt;&lt;p data-pid=&quot;udj63Tlz&quot;&gt;3.实时的节点状态和容量监测&lt;/p&gt;&lt;p data-pid=&quot;ODrYyCtY&quot;&gt;协同存储会对单个节点进行实时状态与水位检测，当单点不可写时，会自动将请求迁移到其他节点，完成服务无感漂移和切换，单点恢复后快速复制同步。&lt;/p&gt;&lt;p data-pid=&quot;TIgAADcF&quot;&gt;4.跨节点多副本&lt;/p&gt;&lt;p data-pid=&quot;PCVjX23Q&quot;&gt;为了应对节点割接、容灾等场景，协同存储提供了跨节点多副本的冗余能力，将数据进行节点间错峰同步。当单点不可用时，协同存储会进行流量的快速转移，同时也可以在访问量大时进行多节点读负载均衡，整个过程用户无感知。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29d9f094ee96fe19b76c29ecc790e257_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;832&quot; data-rawheight=&quot;750&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-29d9f094ee96fe19b76c29ecc790e257_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;832&quot; data-rawheight=&quot;750&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-29d9f094ee96fe19b76c29ecc790e257_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-29d9f094ee96fe19b76c29ecc790e257_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;fFtnhfZI&quot;&gt;5.边缘统一的存储访问网关&lt;/p&gt;&lt;p data-pid=&quot;-4ovK5hv&quot;&gt;在整体架构上，协同存储通过边缘统一网关进行异构资源的适配，不管是从API、SDK还是授权体系，完全兼容现有的使用方式，这对于海量的数据源来说，只需要简单配置，便可以快速将数据上传到协同存储，从而确保给用户云边一体化的使用体验，同时去除了Region概念，直接采用了统一的域名接入和管理方式，真正实现了只上一朵云、只存一朵云。&lt;/p&gt;&lt;p data-pid=&quot;ziOXG0H8&quot;&gt;目前协同存储已经在众多场景下落地，典型的如监控设备的截图/录像上传、车载场景的数据就近写入等。未来，我们将与边缘算力进行更加紧密结合，助力网、算、存一体化的边缘计算体系发展。协同存储的演进，必将为边缘更多场景的落地提供有力支撑，为边缘计算带来更多的可能性。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>afad3f756ef639df2c5e0def58d9f07e</guid>
<title>日均报错量降低 95%，携程小程序生态之自动化错误预警方案</title>
<link>https://toutiao.io/k/gjvezwf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;携程技术&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;ctriptech&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;携程技术官方账号，分享交流成长。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>