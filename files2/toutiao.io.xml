<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>7959db143b757f9d1a3e69acab17c6dd</guid>
<title>15000 字拆解 TiDB 和 OceanBase 并细数四代分布式数据库的变迁（主从、中间件、KV、计算与存储分离、列存储、CAP定理）</title>
<link>https://toutiao.io/k/39yvx6o</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;strong&gt;本文大约 16000 字，阅读需要一个小时。&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;上一篇文章啃硬骨头差点把我牙给崩了，本文我们还是回到舒适区来，继续挥舞架构大棒，欺负可怜的小数据库。本文虽然不太硬，但是量还是很大的，管饱。&lt;/section&gt;&lt;p&gt;说到后端系统对于数据库的要求，基本上和你老板一样：既要又要还要。数据库扮演的那个单点角色，在单机上已经如此的困难了，换到分布式环境下只会更困难。而分布式数据库的出现也是被迫的：应用规模越来越大，对性能和可用性的要求越来越高，不得不搞分布式数据库了。&lt;/p&gt;&lt;p&gt;接下来请大家坐稳扶好，我们正式开始分布式数据库历史变迁之旅。&lt;/p&gt;&lt;h2&gt;单机数据库的不可能三角&lt;/h2&gt;&lt;p&gt;正如经济政策的不可能三角“不可能同时实现资本流动自由，货币政策的独立性和汇率的稳定”那样，单机数据库也有一个不可能三角，那就是：①持久化 ②事务隔离 ③高性能。&lt;/p&gt;&lt;h3&gt;为什么不可能&lt;/h3&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;持久化需要每一次写数据都要落到磁盘上，宕机再启动以后，数据库可以自修复。如果只要求这一条，很好实现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;事务隔离需要每一次会话(session)的事务都拥有自己的数据库版本：既要多个并行的事务相互之间不会写到对方的虚拟数据库上(读提交)，又要不能读到对方的虚拟数据库上(可重复读)，还要在一个事务内不能读到别的事务已经提交的新增的数据(幻读)，终极需求则是完全串行化：我的读 session 不结束，你就不能读。这个需求和持久化需求结合以后，会大幅增加日志管理的复杂度，但，还是可以管理的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;读写都要尽量地快：单独实现也很快，Redis 嘛，但是加上持久化和事务隔离，就很难做了：需要对前两项进行妥协。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;MySQL 选择了哪两个？&lt;/h3&gt;&lt;p&gt;MySQL 首先选择了持久化：失去人性，失去很多，失去持久化，失去一切。没有持久化能力，那还当个毛的核心数据库，所以这一条是所有磁盘数据库的刚需，完全无法舍弃。&lt;/p&gt;&lt;p&gt;然后 MySQL 选择了一部分高性能：MyISAM 就是为了快速读写而创造的，早期 MySQL 在低配 PC 机上就有不错的性能。后来更高级的 InnoDB 出现了，小数据量时它的读取性能不如 MyISAM，写性能更是彻底拉胯，但是在面对大数据量场景时，读性能爆棚，还能提供很多后端程序员梦寐以求的高级功能（例如丰富的索引），承担了大部分互联网核心数据库的角色。&lt;/p&gt;&lt;p&gt;最后，MySQL 将事务隔离拆成了几个级别，任君挑选：你要强事务隔离，性能就差；你能接受弱事务隔离，性能就强。你说无事务隔离？那你用 MySQL 干什么，Redis 它不香吗。&lt;/p&gt;&lt;p&gt;所以 MySQL 其实选择了 持久化*1 + 高性能*0.8 + 事务隔离*0.5，算下来，还赚了 0.3 (￣▽￣)&quot;&lt;/p&gt;&lt;p&gt;不过，从 MySQL 也可以看出，“数据库的不可能三角”并不是完全互斥的，是可以相互妥协的。&lt;/p&gt;&lt;p&gt;在开始细数分布式数据库之前，我们先看一个非分布式的提升数据库性能的方案，读写分离，主从同步。&lt;/p&gt;&lt;h2&gt;读写分离&lt;/h2&gt;&lt;p&gt;由于 web 系统中读写需求拥有明显的二八分特征——读取流量占 80%，写入流量占 20%，所以如果我们能把读性能拆分到多台机器上，在同样的硬件水平下，数据库总 QPS 也是能提高五倍的。&lt;/p&gt;&lt;h3&gt;各种主从架构&lt;/h3&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.40625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxEInYCCHaz651NtKMeNKxjDqiasAeDK5e9otYU99Als9LYQwjXbgQ4dA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2176&quot;/&gt;&lt;/p&gt;&lt;p&gt;无论是远古时代谷歌的 MMM(Multi-Master Replication Manager for MySQL) 还是中古时代的 MySQL 官方的 MGR(MySQL Group Replication)，还是最近刚刚完成开发且收费的官方 InnoDB Cluster，这些主从架构的实现方式都是一致的：基于行同步或者语句同步，&lt;code&gt;近实时&lt;/code&gt;地从主节点向从节点同步新增和修改的数据。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5428571428571428&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxXoYgACAHianBa8m9wY465kpZ9sIKgM1rYrHLeQNOzAGKc6XguIPjVgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;由于这种方法必然会让主从之间存在有一段时间的延迟(数百毫秒到数秒)，所以一般在主从前面还要加一个网关进行语句分发：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;select&lt;/code&gt;等读语句默认发送到从节点，以尽量降低主节点负载&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;一旦出现&lt;code&gt;update&lt;/code&gt;、&lt;code&gt;insert&lt;/code&gt;等些语句，立刻发送到主节点&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;并且，本次会话(session)内的所有后续语句，必须全部发送给主节点，不然就会出现数据写入了但是读不到的情况&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7772020725388601&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxXiaicDXXZ8anUgVHr7XA5BeXyZvoFw7FHsucLnEPHicZR7NT7uMVWLo5g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1544&quot;/&gt;&lt;/p&gt;&lt;center&gt;一主四从架构图&lt;/center&gt;&lt;p&gt;搭建一个一主四从的 MySQL 集群，总 QPS 就能从单节点的 1 万提升到 5 万，顺便还能拥有主节点故障后高可用的能力。主从架构比较简单，也没有什么数据冲突问题，就是有一个很大的弱点：&lt;/p&gt;&lt;h4&gt;写入性能无法提升：由于数据库承载的单点功能实在是太多了(自增、时间先后、事务)，导致哪怕架构玩出了花，能写入数据的节点还是只能有一个，所有这些架构都只能提升读性能。&lt;/h4&gt;&lt;p&gt;那怎么提升写性能呢？这个时候就要掏出分布式数据库了。&lt;/p&gt;&lt;h2&gt;分布式数据库&lt;/h2&gt;&lt;p&gt;由于数据库的单点性非常强，所以在谷歌搞出 GFS、MapReduce、Bigtable 三驾马车之前，业界对于高性能数据库的主要解决方案是买 IOE 套件：IBM 小型机 + Oracle + EMC 商业存储。而当时的需求也确实更加适合商用解决方案。&lt;/p&gt;&lt;p&gt;后来搜索引擎成为了第一代全民网站，而搜索引擎的数据库却“不那么关系型”，所以谷歌搞出了自己的分布式 KV 数据库。后来谷歌发现 SQL 和事务隔离在很多情况下还是刚需，于是在 KV 层之上改了一个强一致支持事务隔离的 Spanner 分布式数据库。而随着云计算的兴起，分布式数据库已经成了云上的“刚需”：业务系统全部上云，总不能还用 Oracle 物理服务器吧？于是云上数据库又开始大踏步发展起来。&lt;/p&gt;&lt;p&gt;下面我们按照时间顺序，逐一梳理分布式数据库的发展史。&lt;/p&gt;&lt;h2&gt;第一代分布式数据库：中间件&lt;/h2&gt;&lt;h3&gt;在 MySQL 体系内演进&lt;/h3&gt;&lt;p&gt;关系型数据库为了解决不可能三角需求，其基本架构 40 年没有变过。&lt;/p&gt;&lt;p&gt;MySQL 自己其实已经是一个非常优秀的满足互联网业务场景的单体数据库了，所以基于 MySQL 的基本逻辑进行架构改进，是最稳妥的方案。&lt;/p&gt;&lt;p&gt;在没有分布式关系型数据库技术出现的时代，后端开发者们往往只能选择唯一的刀耕火种的路：在应用代码里调用多个数据库，以应对单个数据库性能不足的困境。后来，有人把这些调用多个数据的代码抽出来作为单独的一层，称作数据库中间件。&lt;/p&gt;&lt;h4&gt;数据库中间件&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7260034904013961&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxnibgjm2icd8Wxsx9RBwUCEVRCnBPjXmmbIqcib8dERzbxyfGtbr6mwefw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;3438&quot;/&gt;&lt;/p&gt;&lt;p&gt;首先，对数据表进行纵向分表：按照一定规则，将一张超多行数的表分散到多个数据库中。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5630099728014506&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxnKXlPb1R1XLyK9k7Lf5lyN7MkLGNibZ2ZBnEWAwbfrPYyMiaypellaaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2206&quot;/&gt;&lt;/p&gt;&lt;center&gt;ShardingSphere 中的 Sharding-Proxy 工作方式&lt;/center&gt;&lt;p&gt;然后，无论是插入、更新还是查询，都通过一个 proxy 将 SQL 进行重定向和拆分，发送给多个数据库，再将结果聚合，返回。&lt;/p&gt;&lt;p&gt;大名鼎鼎的数据库中间件，其基本原理一句话就能描述：使用一个常驻内存的进程，假装自己是个独立数据库，再提供全局唯一主键、跨分片查询、分布式事务等功能，将背后的多个数据库“包装”成一个数据库。&lt;/p&gt;&lt;p&gt;虽然“中间件”这个名字听起来像一个独立组件，但实际上它依然是强业务亲和性的：没有几家公司会自己研发数据库，但每家公司都会研发自己的所谓中间件，因为中间件基本上就代表了其背后的一整套“多数据库分库分表开发规范”。所以，中间件也不属于“通用数据库”范畴，在宏观架构层面，它依然属于应用的一部分。我称这个时代为刀耕火种时代。&lt;/p&gt;&lt;p&gt;那该怎么脱离刀耕火种呢？人类的大脑是相似的：既然应用代码做数据规划和逻辑判断很容易失控，那我们在数据库层面把这件事接管了行不行呢？当然可以，但是需要拿东西&lt;code&gt;找信息之神交换&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;历史上，第一个被放弃的是&lt;code&gt;事务隔离&lt;/code&gt;，而它带来的就是第二代分布式数据库：KV 数据库。&lt;/p&gt;&lt;h2&gt;第二代分布式数据库：KV&lt;/h2&gt;&lt;h3&gt;分布式时代的“新·不可能三角”&lt;/h3&gt;&lt;p&gt;在分布式数据库时代，持久化已经不是分布式数据库“真正的持久化”了，取而代之的是“数据一致性”：由于数据存在了多台机器上，那机器之间数据的一致性就成了新时代的“持久化”。于是新不可能三角出现了：①一致性 ②事务隔离 ③高性能。&lt;/p&gt;&lt;p&gt;你是不是在期待 CAP 理论呀？别着急，我们后面会说。&lt;/p&gt;&lt;h3&gt;分布式 KV 数据库放弃了事务隔离&lt;/h3&gt;&lt;p&gt;数据库技术一共获得过四次图灵奖，后面三次都在关系型数据库领域。事务隔离模型是关系型数据库的核心，非常地简洁、优美、逻辑自恰。&lt;/p&gt;&lt;p&gt;Google 是第一个全民搜索引擎，系统规模也达到了史上最大。但是，搜索引擎技术本身却不需要使用关系型数据库来存储：搜索结果中的网页链接之间是离散的。这块我要挖个坑，本系列完结以后，我会写一篇如何自己开发搜索引擎的文章。&lt;/p&gt;&lt;p&gt;由于搜索不需要关系型数据库，自然谷歌搞的分布式数据库就是 KV 模型。谷歌的三驾马车论文发布以后，业界迅速发展出了一个新的数据库门类 NoSQL(Not Only SQL)，专门针对非结构化和半结构化的海量数据。&lt;/p&gt;&lt;p&gt;目前，缓存（Redis）和文档/日志（MongoDB）大家一般都会用 NoSQL 来承载。在这个领域，最成功的莫过于基于 Hadoop 生态中 HDFS 构建的 HBase 了：它主要提供的是行级数据一致性，即 CAP 理论中的 CP，放弃了事务，可以高性能地存储海量数据。&lt;/p&gt;&lt;p&gt;KV 数据库结构简单，性能优异，扩展性无敌，但是它只能作为核心数据库的高性能补充，绝大多数场景下，核心数据库还是得用关系型。&lt;/p&gt;&lt;h2&gt;第三代分布式数据库：以 Spanner 为代表的 NewSQL&lt;/h2&gt;&lt;p&gt;从 2005 年开始，Google Adwords 开始基于 MySQL 搭建系统，这也推动了 MySQL 在 Google 内部的大规模使用。随着业务的发展，MySQL 集群越来越庞大，其中最痛苦的就是“数据再分片”，据说有一次谷歌对数据库的重新分片持续了 2 年才完成。于是谷歌痛定思痛，搞出了一个支持分布式事务和数据强一致性的分布式关系型数据库：Google Spanner。&lt;/p&gt;&lt;p&gt;2012 年，谷歌发布了 Spanner 论文¹，拉开了分布式强一致性关系型数据库的大幕。这个数据库是真的牛逼，当我第一次看到它机柜照片的时候直接震惊了：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2247946228528752&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGx52eWItSoeExcaxiciblWuQeTGD9eayzKRvoPg7NUuVxkSOQTzcuRzSsg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1339&quot;/&gt;&lt;/p&gt;&lt;p&gt;这套系统采用了 GPS 授时 + 2 台原子钟 + 4 台时间服务器，让分布在全球多个数据中心的 Spanner 集群进行相当精确的时间同步：基于 TrueTime 服务，时间差可以控制在 10ms 之内。这种真正的全球数据库可以做到即使单个数据中心完全失效，应用也完全无感知。&lt;/p&gt;&lt;p&gt;当然，如此规模的全球数据库全世界也没有几家公司有需求，如果我们只在一个数据中心内署数据库集群，时间同步可以很容易地做到 1ms 之内，原子钟这种高端货还用不到。&lt;/p&gt;&lt;h3&gt;还记得上篇文章中数据持久性的关键步骤——redo log 吗？&lt;/h3&gt;&lt;p&gt;为什么上篇文章要写一万多字，就是为本文打基础的，现在就用到了。&lt;/p&gt;&lt;p&gt;上文中我们说过，写入型 SQL 会在写入缓存页 + 写入磁盘 redo log 之后返回成功，此时，真正的 ibd 磁盘文件并未更新。所以，Spanner 使用 Paxos 协议在多个副本之间同步 redo log，只要 redo log 没问题，多副本数据的最终一致性就没有问题。&lt;/p&gt;&lt;h3&gt;事务的两阶段提交&lt;/h3&gt;&lt;p&gt;由于分布式场景下写请求需要所有节点都完成才算完成，所以两阶段提交是必须存在的。单机架构下的事务，也是某一旦一条 SQL 执行出错，整个事务都是要回滚的嘛。多机架构下这个需求所需要的成本又大幅增加了，两阶段提交的流程是这样的：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;告诉所有节点更新数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;收集所有节点的执行结果，如果有一台返回了失败，则再通知所有节点，取消执行该事务&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这个简单模型拥有非常恐怖的理论故障概率：一旦在第一步执行成功后某台机器宕机，则集群直接卡死：大量节点会被锁住。&lt;/p&gt;&lt;p&gt;Spanner 使用 Paxos 化解了这个问题：只要 leader 节点的事务执行成功了，即向客户端返回成功，而后续数据的一致性则会基于&lt;code&gt;prepare timestamp&lt;/code&gt;和&lt;code&gt;commit timestamp&lt;/code&gt;加上 Paxos 算法来保证。&lt;/p&gt;&lt;h4&gt;多版本并发控制（MVCC）&lt;/h4&gt;&lt;p&gt;Spanner 使用时间戳来进行事务之间的 MVCC：为每一次数据的变化分配一个全球统一的时间戳。这么做的本质依然是“空间+时间”换时间，而且是拿过去的时间换现在的时间，特别像支持事后对焦的光场相机。&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;传统的单机 MVCC 是基于单机的原子性实现的事务顺序，再实现的事务隔离，属于即时判断。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Spanner 基于 TrueTime 记录下了每行数据的更新时间，增加了每次写入的时间成本，同时也增加了存储空间。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在进行多节点事务同步时，就不需要再和拥有此行数据的所有节点进行网络通信，只依靠 TrueTime 就可以用 Paxos 算法直接进行数据合并：基于时间戳判断谁前谁后，属于事后判断。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Spanner 放弃了什么&lt;/h3&gt;&lt;p&gt;Spanner 是一个强一致的全球数据库，那他放弃了什么呢？这个时候就需要 CAP 理论登场了。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Google Spanner 数据库首先要保证的其实是分区容错性，这是“全球数据库”的基本要求，也最影响他们赚钱；然后是一致性，“强一致”是核心设计目标，也是 Spanner 的核心价值；谷歌放弃的是可用性(A)，只有 majority available。&lt;/p&gt;&lt;p&gt;除此之外，为了“外部一致性”，即客户端看到的全局强一致性，谷歌为每一个事务增加了 2 倍的时钟延迟，换句话说就是增加了写操作的返回时间，这就是分布式系统的代价：目前平均 TrueTime 的延迟为 3.5ms，所以对 Spanner 的每一次写操作都需要增加 7ms 的等待时间。&lt;/p&gt;&lt;h4&gt;Spanner 一致性的根本来源&lt;/h4&gt;&lt;p&gt;大家应该都发现了，其实 Spanner 是通过给 Paxos 分布式共识算法加了一个“本地外挂” TrueTime 实现的海量数据的分布式管理，它实现全局强一致性的根本来源是&lt;code&gt;Paxos&lt;/code&gt;和&lt;code&gt;TrueTime&lt;/code&gt;。而在普通单机房部署的分布式系统中，不需要 GPS 授时和原子钟，直接搞一个时间同步服务就行。&lt;/p&gt;&lt;h3&gt;NewSQL 时代&lt;/h3&gt;&lt;p&gt;Google Spanner 的推出代表着一个新时代到来了：基于分布式技术的 SQL 兼容数据库（NewSQL），而兼容到什么地步就看各家的水平了。&lt;/p&gt;&lt;p&gt;NewSQL 最大的特点就是使用非 B 树磁盘存储结构（一般为 LSM-Tree），在上面构筑一个兼容 SQL 常用语句和事务的兼容层，这样既可以享受大规模 LSM-Tree 集群带来的扩展性和高性能，也可以尽量少改动现有应用代码和开发习惯，把悲伤留给自己了属于是。&lt;/p&gt;&lt;p&gt;目前比较常见的 NewSQL 有 ClustrixDB、NuoDB、VoltDB，国内的 TiDB 和 OceanBase 也属于 NewSQL，但他们俩有本质区别，下面的番外篇会讨论。&lt;/p&gt;&lt;p&gt;在 NewSQL 时代之后，随着云计算的兴起，云上数据库突然成为了市场的宠儿，市场占有率迅速上涨。它们其实都是对 MySQL 的改造，并不属于 NewSQL 范畴，下面我们认识一下他们。&lt;/p&gt;&lt;h2&gt;第四代分布式数据库：云上数据库&lt;/h2&gt;&lt;p&gt;我实在是不想用“云原生”这个风口浪尖上的词来形容美丽的云上数据库们，它们就像 TCP/IP，简洁但有用。市场从来不会说谎，它们一定是有过人之处的。&lt;/p&gt;&lt;h3&gt;亚马逊 Aurora 开天辟地&lt;/h3&gt;&lt;p&gt;2014 年 10 月，亚马逊发布了 Aurora 云上数据库，开创性地在云环境中将计算节点和存储节点分离：基于云上资源的特点，将计算节点 scale up（增配），将存储节点 scale out（增加节点），实现了极佳的性能/成本平衡。Aurora 将云上关系型数据库产品推向了一个新的高度。&lt;/p&gt;&lt;h3&gt;计算与存储分离&lt;/h3&gt;&lt;p&gt;Aurora 提出的计算与存储分离可以说是目前数据库领域最火的方向，但是它火的原因我相信大多数人都认识的不对：不是因为性能强，而是因为便宜。&lt;/p&gt;&lt;h4&gt;挖掘云计算的价值点&lt;/h4&gt;&lt;p&gt;十年前我在 SAE 实习的时候，中午大家一起吃饭，组长说云计算就是云安全，这句话当然说的很对。从这句话推开，我们很容易就能找到云计算真正的商业价值在哪里：传统托管式部署，哪些资源浪费的最多，哪里就是云计算的商业价值所在。&lt;/p&gt;&lt;p&gt;为了满足业务波动而多采购的 CPU 和内存，可能浪费了 50%；网络安全设备，可以说 95% 以上的资源都是浪费；高端存储，这个已经不能用资源浪费来形容了，而是被云计算颠覆了：云厂商用海量的多地域多机房内廉价的 x86 服务器里面的廉价磁盘，基于软件，构建出了超级便宜、多副本、高可用的存储，唯一的问题是性能不是太好。亚马逊 S3 和阿里云 OSS 就是最佳代表，可以说这类对象存储服务，其单价已经低于本地机房的 2.5 寸 SAS 机械磁盘了，更不要说本地机房还需要另外采购昂贵的存储控制器和 SAN 交换机了。&lt;/p&gt;&lt;h4&gt;云计算与特斯拉&lt;/h4&gt;&lt;p&gt;云数据库可以算是云服务厂商最重要的产品：受众足够广，成本足够低，性能足够高。这一点很像特斯拉汽车，时至今日，特斯拉依然在疯狂地想各种办法压低生产成本，虽然在降价，但是单车毛利依然维持在 30% 以上，是 BBA 的 2-3 倍。&lt;/p&gt;&lt;p&gt;Aurora 和 PolarDB 的核心价值是用一种低成本的方式，制造了一个 Oracle 要高成本才能做出来的软件和服务，这才是真的“创造价值”。&lt;/p&gt;&lt;h4&gt;计算与存储分离是一种“低成本”技术&lt;/h4&gt;&lt;p&gt;计算与存储分离并不是什么“高性能”技术，而是一种“低成本”技术：关系型数据的存储引擎 InnoDB 本身就是面向低性能的磁盘而设计的，而 CPU 和内存却是越快越好、越大越好，如果还把磁盘和 MySQL 进程部署在同一台物理机内，一定会造成磁盘性能的浪费。计算与存储分离的真正价值在于大幅降低了存储的成本。&lt;/p&gt;&lt;h4&gt;计算与存储分离的技术优势&lt;/h4&gt;&lt;p&gt;虽然说这个架构的主要价值在于便宜，但是在技术上，它也是有优势的：&lt;/p&gt;&lt;p&gt;它显著降低了传统 MySQL 主从同步的延迟。传统架构下，无论是语句同步还是行同步，都要等到事务提交后，才能开始同步，这就必然带来很长时间的延迟，影响应用代码的编写。而计算和存储分离之后，基于 redo log 传递的主从同步就要快得多了，从 1-2s 降低到了 100ms 以下。由于主从延迟降低，集群中从节点的个数可以提升，总体性能可以达到更高。&lt;/p&gt;&lt;h4&gt;Aurora 的主从同步机制&lt;/h4&gt;&lt;p&gt;看了上篇文章的人应该都知道，在更新数据时，主节点在完成了 redo log 写入，并对内存缓存 Buffer Pool 中相应的数据页进行修改之后，就会返回成功。这个内存缓存给 Aurora 从节点的数据更新造成了不小的影响：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;主从节点之间只有 redo log 传递&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从节点在拿到 redo log 之后，会刷新自己 Buffer Pool 中存在的数据页，其它不存在的页的信息会丢弃&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;这带来了两个问题：&lt;/p&gt;&lt;/li&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;从节点的客户端在主从不同步的一段时间内，读到的是旧数据，这个需要网关或者应用代码来处理&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;从节点的 Buffer Pool 有效性变差，命中率下降，引发性能下降&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;h4&gt;Aurora 的架构局限&lt;/h4&gt;&lt;p&gt;Aurora 的出现确实独具慧眼，但是也会被时代所局限。&lt;/p&gt;&lt;p&gt;在 Aurora 论文²中，开篇就提到&lt;code&gt;Instead, the bottleneck moves to the network between the database tier requesting I/Os and the storage tier that performs these I/Os&lt;/code&gt;。Aurora 认为网络速度会成为云数据库的瓶颈，而在它研发的 2012-2013 年也确实如此，当时万兆网卡刚刚普及，CPU 单核性能也不足，软件也没有跟上，可以说速度比千兆网卡也快不了多少，所以亚马逊又搞了神奇的技术：存储节点具有自己将 redo log 写入 ibd 文件的能力。&lt;/p&gt;&lt;p&gt;由于这个神奇能力的存在，Aurora 的多机之间采用传输 redo log 的方式来同步数据，并用一种今天看起来不太靠谱的协议来保证最终一致性：consul 使用的那个 gossip 协议。由于 Aurora 采用六副本技术，所以每次写入都需要发起六次不怎么快的网络 IO，并且在其中 4 个成功以后才给客户端返回成功。Aurora 确实便宜，但是单节点的性能也确实捉鸡，这代表的就是写入性能差，进而限制了整个集群的性能上限。而且，经过比较长的时间(100ms)才能保证从&lt;code&gt;从节点&lt;/code&gt;上读到的数据是最新的，这会让主节点压力增大影响集群性能上限，或者让应用代码做长时间的等待，严重的会引起应用代码的执行逻辑变更，引入持久的技术债务。&lt;/p&gt;&lt;p&gt;那该怎么提升计算存储分离情况下的集群性能呢？我们看阿里云是怎么做的。&lt;/p&gt;&lt;h3&gt;阿里云 PolarDB 后来居上&lt;/h3&gt;&lt;p&gt;阿里云 RDS 集群的成本已经够低了，不需要再用计算存储分离技术降低成本了，而中国市场的用户，普遍需要高性能的 MySQL 数据库：ECS 价格太低了，如果不是运维方便和性能压力过大，谁愿意用你昂贵的数据库服务啊。&lt;/p&gt;&lt;p&gt;2015 年，PolarDB 开始研发，当时 25Gb RDMA 网络已经逐渐普及，所以阿里云将视角放在了网络速度之外：在 IO 速度没有瓶颈以后，基于内核提供的 syscall 所编写的旧代码将会成为新的性能瓶颈。&lt;/p&gt;&lt;p&gt;站在 2023 年初回头看，阿里云的判断是非常准确的。&lt;/p&gt;&lt;h4&gt;计算存储分离架构下的整体性能极限&lt;/h4&gt;&lt;p&gt;由于所有节点都使用了同一块“逻辑磁盘”，所以&lt;code&gt;双主可写&lt;/code&gt;想都不要想，一个计算存储分离的数据库集群的性能上限就是&lt;code&gt;主节点的写入性能上限&lt;/code&gt;。（Aurora 有多主可写数据库，对 ID 进行自动切分，使用时有一堆限制；PolarDB 也有多主可写数据库，但是更绝：每个库/表只支持绑定到一个可写节点，感情就是对多个数据库做了个逻辑聚合，还不如中间件呢。）&lt;/p&gt;&lt;p&gt;在主节点不接受读的情况下，主节点只承接写入操作，以及和写入操作在同一个会话 session 中的后续的读请求。&lt;/p&gt;&lt;p&gt;那 PolarDB 是如何提升主节点性能的呢？&lt;/p&gt;&lt;h4&gt;1. 共享的不是 redo log，而是 ibd 文件&lt;/h4&gt;&lt;p&gt;主从之间并不是依靠纯属 redo log 来同步数据的，而是直接共享同一个 ibd 文件，即真正的共享磁盘。而且，基于块设备的 Raft 算法也比基于文件的 gossip 协议要快很多。&lt;/p&gt;&lt;h4&gt;2. 绕过内核和网路栈：大幅提升存储性能，降低延迟，减少 CPU 消耗&lt;/h4&gt;&lt;p&gt;虽然对 redo log 的解析这一步在 Aurora 那边是存储做的，PolarDB 这边是主节点做的，看似增加了 CPU 消耗，但是这并不是真正的性能瓶颈所在，真正的瓶颈是网络栈和 UNIX 进程模型。看过我《性能之殇》系列文章的人应该都比较熟悉了，这是老生常谈了。那 PolarDB 是怎么优化的呢？&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;跳过 TCP/IP 网络栈，直接使用 RDMA 网络从存储节点读取数据，延迟暴降&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;跳过 kernel 的线程调度，自行开发绑定 CPU 核心的状态机，采用非阻塞 IO，在 CPU 占用下降的情况下，延迟进一步降低&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;3. 提出 ParallelRaft 协议，允许部分乱序提交&lt;/h4&gt;&lt;p&gt;ParallelRaft 协议让 Aurora 那边需要执行六次的网络 IO 变成了一次：只需要向 leader 节点写入成功，剩下的数据同步由 Raft 算法来执行，这和 Google Spanner 的两阶段提交优化是一个思路。&lt;/p&gt;&lt;p&gt;原始的 Raft 协议确实逻辑完备，实现简单，就是一个一个地协商太慢了。ParallelRaft 让收敛协商能够并行起来，加速 redo log 落入 ibd 文件的过程。&lt;/p&gt;&lt;h4&gt;4. 主从之间基于低延迟的共享存储同步 redo log 数据以刷新 Buffer Pool&lt;/h4&gt;&lt;p&gt;基于共享存储的低延迟优势，PolarDB 主从之间使用共享存储来同步 redo log 以刷新缓存，这一点逻辑上和 Aurora 一致，但是实际表现比较好，我实测主从同步时间在 20~70ms 范围内。&lt;/p&gt;&lt;h4&gt;5. 单机性能比标准 MySQL 更强&lt;/h4&gt;&lt;p&gt;RDMA 存储比本地存储更快，因为减少了计算和存储争抢中断的问题：IO 这个 CPU 不擅长的东西完全卸载给了 RDMA 网卡。同配置下 PolarDB 比标准 MySQL 的性能要高几倍。&lt;/p&gt;&lt;h4&gt;PolarDB 有这么多的优势，那它付出了什么代价呢？&lt;/h4&gt;&lt;p&gt;在各种实测里面，PolarDB 在相同规格下对其他的云上数据库都拥有 2 倍的性能优势，但是它基于 RDMA 存储的特点也让它付出了两个代价：1. 硬件成本高昂 2. 扩展性有上限。&lt;/p&gt;&lt;p&gt;是不是感觉很熟悉？Shared-Disk 的代表 Oracle RAC 也有这两个缺点。不知道大家有没有发现，PolarDB 就是云时代的 RAC 数据库：看起来是 Shared-Disk，其实是共享缓存让他们的性能变的超强。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5353191489361702&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxF6z4KAmu4odptnTrY2Atibpp1fcA27Y3dPCErIQ3SCcWn4xXd6bEZww/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1175&quot;/&gt;&lt;/p&gt;&lt;center&gt;各代分布式数据库的兼容性/扩展性对比&lt;/center&gt;&lt;h4&gt;一句话概括 PolarDB：利用了高性能云存储并且做了性能优化的一主多从 MySQL 集群。&lt;/h4&gt;&lt;h3&gt;简单讨论一下 CAP 理论&lt;/h3&gt;&lt;p&gt;一个分布式系统中，不可能完全满足①一致性、②可用性、③分区容错性。我们以一个两地三中心的数据库为例：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;一致性：同一个时刻发送到三个机房的同一个读请求返回的数据必须一致（强一致读），而且磁盘上的数据也必须在一段时间后变的完全逻辑一致（最终一致）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;可用性：一定比例的机器宕机，其它未宕机服务器必须能够响应客户端的请求（必须是正确格式的成功或失败），这个比例的大小就是可用性级别&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分区容错性：一个集群由于通信故障分裂成两个集群后，不能变成两个数据不一致的集群（脑裂），对外必须依然表现为一个逻辑集群&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在一个分布式数据库系统中，到底什么是可以放弃的呢？我觉得可以从分布式系统带来了什么优势这个问题开始思考。&lt;/p&gt;&lt;p&gt;相比于单体系统，一个分布式的数据库，在一致性上进步了吗？完全没有。在可用性上进步了吗？进步了很多。在分区容错性上呢？单体系统没有分区，不需要容错。所以，结论已经一目了然了：&lt;/p&gt;&lt;p&gt;①和③都是分布式系统带来的新问题，只有②是进步，那就取长补短，选择牺牲可用性来解决自己引发的一致性和分区容错性两个新问题。这也正是目前常见分布式数据库系统的标准做法。&lt;/p&gt;&lt;h2&gt;TiDB 和 OceanBase 该怎么选？&lt;/h2&gt;&lt;p&gt;TiDB 和 OceanBase 是目前中国 NewSQL 数据库的绝代双骄，争论一直不绝于耳。&lt;/p&gt;&lt;p&gt;TiDB 是承袭 Spanner 思想的 NewSQL，对 MySQL 的兼容性一般，基于&lt;code&gt;key+版本号&lt;/code&gt;的事务控制也比较弱，据说性能比较好，特别是写入性能。&lt;/p&gt;&lt;p&gt;OceanBase 是基于 Shared-Nothing 思想原生开发的分区存储数据库，其每个节点都支持完整的 SQL 查询，相互之间无需频繁通信。OceanBase 还支持多租户隔离，这明显就是为了云服务准备的(无论是公有云还是私有云)，和绝大多数企业无关。另外，OceanBase 对于 MySQL 的兼容性也几乎是 NewSQL 里面最高的，毕竟它需要支持支付宝的真实业务，兼容性是硬性要求，业务屎山可没人移得动 (づ｡◕‿‿◕｡)づ&lt;/p&gt;&lt;p&gt;下面我们详细对比一下两者的设计思路。&lt;/p&gt;&lt;h3&gt;TiDB 的设计思路&lt;/h3&gt;&lt;p&gt;我画的架构图如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5806845965770171&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxqc7YXlTroSa9xSDXGZeH7iaQ4JS5CtshcafOvaqtMXCcicVBg3cTibS0A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1636&quot;/&gt;&lt;/p&gt;&lt;p&gt;上图中的“SQL 层”就是解析 SQL 语句并将其转化为 KV 命令的一层，是无状态的，下面的存储层才是核心，它叫 TiKV。&lt;/p&gt;&lt;h4&gt;TiKV 如何存储数据&lt;/h4&gt;&lt;p&gt;TiKV 官方原理图如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45519203413940257&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxHyAQEFSEo9VJoD2BxIekoPPT5yo17JOLKnhEiaLjulniarop1PBjTD7w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot;/&gt;&lt;/p&gt;&lt;p&gt;TiKV 是 TiDB 的核心组件，一致性和事务隔离都是基于它的能力得以实现的。每个 TiKV 拥有两个独立的 RocksDB 实例，一个用于存储 Raft Log，另一个用于存储用户数据和多版本隔离数据（基于&lt;code&gt;key+版本号&lt;/code&gt;实现），从这里可以看出，TiDB 的存储存在大量冗余，所以 TiDB 的测试性能才会如此的高，符合空间换时间的基本原理。&lt;/p&gt;&lt;p&gt;和 TiKV 并列的还有一个 TiFlash 列存储引擎，是为了 OLAP 在线数据分析用的，我们在此不做详细讨论。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5709534368070953&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxWo4LwkDsSKlTbsmABQaibevVw2tiaPlT57w6CHkPsQu6eT6I14WjsAdw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;3608&quot;/&gt;&lt;/p&gt;&lt;center&gt;TiKV 数据分片&lt;/center&gt;&lt;p&gt;除此之外，TiKV 还发明了一层虚拟的“分片”(Region)，将数据切分成 96MB~144MB 的多个分片，并且用 Raft 算法将其分散到多个节点上存储。注意，在 TiKV 内部存储用户数据的那个 RocksDB 内部，多个分片是致密存储的，分片之间并没有逻辑关系。&lt;/p&gt;&lt;p&gt;TiDB 的实现风格比较狂野，所以不兼容的部分比较多：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6810193321616872&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxg3s3W4xBwwRTbdNAtlibgic9BLpf9OyU6MFIotnyJFSXEB5jAeST2dAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2276&quot;/&gt;&lt;/p&gt;&lt;center&gt;TiDB 和 MySQL 不兼容的部分&lt;/center&gt;&lt;h4&gt;TiDB 对 CAP 和不可能三角的抉择&lt;/h4&gt;&lt;p&gt;TiDB 放弃了新不可能三角中的事务隔离，和 Spanner 一样放弃了 CAP 理论中的“完全可用性”：一旦出现脑裂，就会出现意外的返回结果（如超时），因为 TiDB 选择了保证一致性：如果无法达到数据强一致，就要停止服务。&lt;/p&gt;&lt;h4&gt;一句话概括 TiDB：①搭建在 KV 数据库集群之上的②兼容部分 MySQL 语法的③有一些事务处理能力的高性能数据库。&lt;/h4&gt;&lt;h3&gt;OceanBase 设计思路&lt;/h3&gt;&lt;p&gt;我们以最新的 OceanBase 4.0 版本的架构为目标进行讨论。&lt;/p&gt;&lt;p&gt;TiDB 底层数据叫分片，那 OceanBase 为什么叫分区呢？因为分片的意思只是数据被分开了（本身 KV 数据之间也没关系），但分区表示的是分区内部的数据之间是有联系的：OceanBase 的每个节点本身，依然是一个关系型数据库，拥有自己的 SQL 引擎、存储引擎和事务引擎。&lt;/p&gt;&lt;h4&gt;简单的分区&lt;/h4&gt;&lt;p&gt;OceanBase 在建表时就需要设定数据分区规则，之后每一行数据都属于且仅属于某个分区。在数据插入和查询的时候，需要找到这一行数据所在的区，进行针对性地路由。这和第一代分布式——中间件的思想一致。这么做相当于简单地并行执行多条 SQL，以数据切分和数据聚合为代价，让数据库并行起来。而这个数据切分和数据聚合的代价，可以很小，也可以很大，需要 OceanBase 进行精细的性能优化，我们下面还会说到。&lt;/p&gt;&lt;p&gt;分区之间，通过 Multi-Paxos 协议来同步数据：每一个逻辑分区都会有多个副本分布在多台机器上，只有其中一个副本会成为 leader，并接受写请求。这里的架构和 PolarDB 一样了，此时，客户端的一致性读需要网关(OBProxy)来判断，主从之间的同步是有可感知的延迟的。&lt;/p&gt;&lt;h4&gt;节点存储架构&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.39636363636363636&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxGyox36znxdNI3NZEXicUibUiarmbbF0c4j1YSLZ6ZoMsNFQYII7HQkEGA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1650&quot;/&gt;&lt;/p&gt;&lt;center&gt;官方存储架构图&lt;/center&gt;&lt;blockquote&gt;&lt;p&gt;OceanBase 数据库的存储引擎基于 LSM Tree 架构，将数据分为静态基线数据（放在 SSTable 中）和动态增量数据（放在 MemTable 中）两部分，其中 SSTable 是只读的，一旦生成就不再被修改，存储于磁盘；MemTable 支持读写，存储于内存。数据库 DML 操作插入、更新、删除等首先写入 MemTable，等到 MemTable 达到一定大小时转储到磁盘成为 SSTable。在进行查询时，需要分别对 SSTable 和 MemTable 进行查询，并将查询结果进行归并，返回给 SQL 层归并后的查询结果。同时在内存实现了 Block Cache 和 Row cache，来避免对基线数据的随机读。&lt;/p&gt;&lt;p&gt;当内存的增量数据达到一定规模的时候，会触发增量数据和基线数据的合并，把增量数据落盘。同时每天晚上的空闲时刻，系统也会自动每日合并。&lt;/p&gt;&lt;p&gt;OceanBase 数据库本质上是一个基线加增量的存储引擎，在保持 LSM-Tree 架构优点的同时也借鉴了部分传统关系数据库存储引擎的优点。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;以上是官方描述，我本来想简化一下，读了一遍觉得还是放原文吧，原文描述的就非常的清晰精炼了：OceanBase 用内存 B+ 树和磁盘 LSM-Tree 共同构成了数据读写体系，和上一篇文章中的 InnoDB 是多么像啊！只是 OceanBase 做的更细：跟 TiDB 相比，就像是在 TiKV 上面加了一层 Buffer Pool 一样。&lt;/p&gt;&lt;p&gt;还有一个细节：OceanBase 除了记录日志(Redo Log)并修改内存缓存(MemTable)之外，只要内存充足，白天 OceanBase 不会主动将内存缓存中的数据刷洗到 SSTable 里的，官方更推荐每天凌晨定时刷洗。这是什么思想？可以说是空间(内存)换时间，也可以说是拿未来的时间换现在的时间。&lt;/p&gt;&lt;h4&gt;OceanBase 性能来源之一——充分的内存缓存&lt;/h4&gt;&lt;p&gt;从基础电气属性上讲，磁盘一定是慢的，内存一定是快的，所以在数据量大于机器的内存容量时，各种数据库的性能差别可以聚焦到一个点上：内存利用效率，即热数据命中内存缓存的概率。&lt;/p&gt;&lt;p&gt;为了提升缓存命中率，OceanBase 设计了很多层内存缓存，尽全力避免了对磁盘的随机读取，只让 LSM-Tree 的磁盘承担它擅长的连续读任务，包子有肉不在褶上，商用环境中捶打过的软件就是不一样，功夫都在细节里：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3379396984924623&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxS5kjFkzEj1f4hy2rZ5atR4tjibRRbXvFuK3RIyvJBqib2LpphFu6qdhQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1592&quot;/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;BloomFilter Cache：布隆过滤器缓存&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MemTable：同时使用 B+ 树和 HashTable 作为内存引擎，分别处理不同的场景&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Row Cache：存储 Get/MultiGet 查询的结果&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Block Index Cache：当需要访问某个宏块的微块时，提前装载这个宏块的微块索引&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Block Cache：像 Buffer Pool 一样缓存数据块(InnoDB 页)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Fuse Row Cache：在 LSM-Tree 架构中, 同一行的修改可能存在于不同的 SSTable 中，在查询时需要对各个 SSTable 查询的结果进行熔合，对于熔合结果缓存可以更大幅度地支持热点行查询&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Partition Location Cache：用于缓存 Partition 的位置信息，帮助对一个查询进行路由&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Schema Cache：缓存数据表的元信息，用于执行计划的生成以及后续的查询&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clog Cache：缓存 clog 数据，用于加速某些情况下 Paxos 日志的拉取&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;OceanBase 性能来源之二——直接变身内存数据库&lt;/h4&gt;&lt;p&gt;为了极致的性能，OceanBase 直接取消了 MySQL 中“后台进程每秒将 redo log 刷写到 ibd 文件”这一步，等于放大了集群宕机重启后恢复数据的时间（重启后需要大量的时间和磁盘 IO 将 redo log 刷写入磁盘），然后把这件事放到半夜去做：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;当内存的增量数据达到一定规模的时候，会触发增量数据和基线数据的合并，把增量数据落盘。同时每天晚上的空闲时刻，系统也会自动每日合并。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;把一整天的新增和修改的数据全部放到内存里，相当于直接变身成了内存数据库（还会用 B 树和 Hashtable 存两份），确实是一种终极的性能优化手段，OceanBase 真有你的。&lt;/p&gt;&lt;h4&gt;填坑：OceanBase 如何提升并行查询和数据聚合的性能&lt;/h4&gt;&lt;p&gt;传统的中间件 Sharding 技术中，也会做一些并行查询，但是他们做的都是纯客户端的查询：proxy 作为标准客户端，分别从多台机器拿到数据之后，用自己的内存进行数据处理，这个逻辑非常清晰，但有两个问题：1. 只能做简单的并行和聚合，复杂的做不了 2. 后端数据库相互之间无通信，没有很好地利用资源，总响应时间很长。&lt;/p&gt;&lt;p&gt;OceanBase 让一切尽可能地并行起来了：在某台机器上的 proxy(OBServer) 接到请求以后，它会担任协调者的角色，将任务并行地分发到多个其他的 OBServer 上执行；同时，将多个子计划划分到各个节点上以后，会在各节点之间建立 M*N 个网络通信 channel，并行地传输信息；此外，OceanBase 还对传统数据库的执行计划优化做了详细的拆分，对特定的关键词一个一个地做分布式优化，才最终达成了地表最强的成就。&lt;/p&gt;&lt;h4&gt;由于本身就是为了兼容 MySQL 而设计的一种新技术实现，所以它拥有非常优秀的兼容性：&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.22916666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/qehPQXlzsA23ANfc7akZ1PnsJAoDDTGxPoEicQicBtu9LZrfb3Umen0N7iaXgUSQtDFVgTp39HLecntiaF9kr1fEmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2016&quot;/&gt;&lt;/p&gt;&lt;center&gt;OceanBase 和 MySQL 不兼容的部分&lt;/center&gt;&lt;h4&gt;OceanBase 对 CAP 和不可能三角的抉择&lt;/h4&gt;&lt;p&gt;由于数据是分区的，所以当脑裂时，两个大脑的数据肯定已经不完整了，相当于两万行的表只剩一万行数据可以进行查询和更新，此时，如果 OceanBase 梗着脖子非要追求数据强一致，也是可以让所有的 OBProxy 拒绝服务的，但是 OceanBase 选择了继续苟着：互联网公司嘛，能实现最终一致性就行了，要啥自行车。&lt;/p&gt;&lt;p&gt;OceanBase 放弃了 CAP 和新不可能三角中的一致性，只能做到最终一致性：为了事务隔离和性能，哥忍了。&lt;/p&gt;&lt;p&gt;其实，不追求强一致和我们下一篇《站在地球表面》中的终极高并发架构在思想上是一致的，我想这就是经历过大规模生产应用的数据库，被现实世界毒打过后的痕迹吧。&lt;/p&gt;&lt;p&gt;&lt;span&gt;一句话概括 OceanBase：①世界第一性能的②高度兼容 MySQL 的③经历过生产系统考验的高性能分布式关系型数据库。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;分布式数据库，应该怎么选？&lt;/h2&gt;&lt;p&gt;其实，分布式数据库根本就轮不到你来选：应用准备好了吗？有足够的研发资源吗？性能问题已经大到压倒其他需求了吗？&lt;/p&gt;&lt;p&gt;如果你有一个正在成长的业务，影响最小、成本最低的方案就是选择 Aurora/PolarDB 这种高兼容性数据库，等到这类云数据库的主节点达到性能上限了，再对应用做逐步改造，滚动式地替换每个部分的数据库依赖。&lt;/p&gt;&lt;p&gt;如果压力大到必须换分布式数据库技术方案了，再看看你能获得什么样的分布式数据库呢？无非是在哪个云平台就用哪家呗。&lt;/p&gt;&lt;h2&gt;番外篇&lt;/h2&gt;&lt;h3&gt;Shared-Nothing、Shared-Memory 和 Shared-Disk&lt;/h3&gt;&lt;p&gt;Shared-Nothing 只是一种思想，并不是一种明确的数据库架构，它非常笼统，只是描述了一种状态。在这里我们简单讨论一下 Shared-Nothing。&lt;/p&gt;&lt;p&gt;Shared-Nothing 描述的是一种分布式数据库的运行状态：两台物理机，除了网络通信之外，不进行任何资源共享，CPU、内存、磁盘都是独立的。这样，整个系统的理论性能就可以达到单机的二倍。&lt;/p&gt;&lt;p&gt;怎么理解 Shared-Nothing 思想呢？把它和 Shared-Disk 放到一起就明白了：&lt;/p&gt;&lt;p&gt;Shared-Disk：多台机器通过共享 SAN 磁盘的方式协同工作，让系统整体性能突破单机的极限。Oracle RAC 是这个架构的佼佼者，不过它的成功并不在于磁盘，而在于它的分布式锁(CACHE FUSION)：RAC 利用时间戳和分布式锁实现了分布式事务和多台机器同时可写，大幅提升了集群的性能。注意，时间戳在这里又出现了。CACHE FUSION 其实已经可以被称作 Shared-Memory 了。感兴趣的可以自己了解，我们不再深入。&lt;/p&gt;&lt;p&gt;21 世纪初，Oracle 推出了 Shared-Disk 的 RAC，IBM 推出了 Shared-Nothing 的 DB2 ICE。十年后，Oracle RAC 发展的如火如荼，而 DB2 ICE 已经消失在了历史的长河中。&lt;/p&gt;&lt;p&gt;但是，2012 年 Google 发布了 Spanner 论文，在非常成熟的世界上最大规模的 KV 数据库之上，构建 SQL 层，实现持久化、事务和多版本并发控制，扛起了 Shared-Nothing 技术方向的大旗，直到今天。&lt;/p&gt;&lt;h3&gt;MongoDB 小故事&lt;/h3&gt;&lt;p&gt;十年前我在新浪云(SAE)实习的时候，听过一个关于 MongoDB 的技术小故事：当时，SAE 的 KV 服务是使用 MongoDB 实现的，在规模大到一定程度以后，性能会突然下降，SAE 自己解决不了这个问题，就给 MongoDB 开发组的各位大哥买机票请他们到北京理想国际大厦 17 层现场来帮忙，研究了几天，MongoDB 开发组的人说：你们换技术吧，MongoDB 解决不了你们这个规模的问题，然后 SAE 的 KV 就更换技术方案来实现了。&lt;/p&gt;&lt;h3&gt;DBA 晕倒砸烂花盆&lt;/h3&gt;&lt;p&gt;也是在 SAE，我坐在厕所附近临过道的工位（上厕所很方便），某天早上刚上班，我亲眼看到 SAE 的一名 MySQL DBA 从厕所里出来后，晕倒在我面前，砸烂了一个大花盆。数据库作为系统架构中最重要的那个单点的残酷，可见一斑。&lt;/p&gt;&lt;h3&gt;列存储思想&lt;/h3&gt;&lt;p&gt;与其将列存储认定为数据库的一种，我倒觉得它更应该被称作一种思想：观察数据到底是被如何读取，并加以针对性地优化。&lt;/p&gt;&lt;p&gt;列存储有点像第一性原理在数据库领域的应用：不被现实世界所束缚，没有屈服于 B 树和它亲戚们的淫威，勇敢地向更底层看去，思考着在我们大量读取数据时，数据怎样组织才能读的更快。&lt;/p&gt;&lt;p&gt;在读取一行数据时，显然 B+ 树的效率无人能及，但是当我们需要读取 100 万行数据中的某一列时，B+ 树就需要把这 100 万行数据全部载入内存：每次将一页 16KB 载入内存，循环这一页内的 14 行数据，把这个特定的字段复制出来；重复执行这个操作 71429 次，才能得到我们想要的结果。这显然是 B+ 树非常不擅长的需求。&lt;/p&gt;&lt;p&gt;而列存储将数据基于行的排布翻转过来了：所有数据基于列，致密地排列在磁盘上，这样对某一列的读取就变成了磁盘顺序读，即便是机械磁盘，顺序读也非常快。&lt;/p&gt;&lt;h4&gt;列存储数据库 clickhouse 颇有毛子暴力美学的典范，和 Nginx 的气质很像&lt;/h4&gt;&lt;p&gt;clickhouse 推荐使用尽量多的 CPU 核心，对单核性能无要求，我拿 E5-V2 旧服务器测过，速度确实非常惊人，8000 万行的表，查询起来不仅比 MySQL 快，比 Hadoop 也快特别多。&lt;/p&gt;&lt;h3&gt;还记得我们的目标吗？五百万数据库 QPS&lt;/h3&gt;&lt;p&gt;在中国，我们现在有下面两种方案可以选择：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;OceanBase 已经蝉联 TPC-C 数年的全球冠军了，每分钟可以处理 7.07 亿个订单，每秒订单数都已经过千万了，更不要说 QPS 500 万了，所以，如果你用 OceanBase，你的百万 QPS 的高并发系统已经搭建完成了！:-D&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果你用阿里云，那 1 主 4 从，88 vCore 710 GB * 5 个节点的 PolarDB 集群可以跑到大约 200 万 QPS³。那离 500 万还有不小的距离呢，不要着急，我们下篇文章解决这个问题。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;接下来&lt;/h3&gt;&lt;p&gt;接下来就是本系列最后一篇文章了：我们不仅要用架构顶住五百万数据库 QPS，还会找出一个哲学♂办法，打造能够服务全人类的系统。&lt;/p&gt;&lt;h3&gt;参考资料&lt;/h3&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;Google Spanner 论文（中文版） https://ying-zhang.github.io/time/2013-Spanner-cn.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;亚马逊 Aurora 论文 https://web.stanford.edu/class/cs245/readings/aurora.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;复盘：我在真实场景下对几款主流云原生数据库进行极限性能压测的一次总结 https://cloud.tencent.com/developer/article/2066823&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c46beae4050a8b572ab3df63490a3b68</guid>
<title>七款云上共享文件系统 POSIX 兼容性大比拼</title>
<link>https://toutiao.io/k/83x9jgr</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry&quot;&gt;
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;当用户在进行文件系统选型时，POSIX 语义兼容性是必不可缺的一项考察指标。JuiceFS 一直非常重视对 POSIX 标准的高度兼容，在持续完善功能、提高性能的同时，尽力保持最大程度的 POSIX 兼容性。&lt;/p&gt;&lt;p data-block-key=&quot;fujcb&quot;&gt;近期，就 POSIX 兼容性，&lt;b&gt;我们对腾讯云 CFS、阿里云 NAS、华为云SFS、 GCP Filestore、Amazon EFS、Azure Files 以及 JuiceFS 进行了一次测试&lt;/b&gt;，便于用户了解这些主流文件系统的兼容性表现。&lt;/p&gt;&lt;blockquote data-block-key=&quot;cukbu&quot;&gt;关于 POSIX&lt;br/&gt;POSIX 是可移植操作系统接口(Portable Operating System Interface) 的缩写， 简单来说是文操作系统包括件存储领域应用最广泛的操作系统接口规范。 更多关于POSIX 标准的讨论，可以参考 Quora 上的一个问答 &lt;a href=&quot;https://www.quora.com/What-does-POSIX-conformance-compliance-mean-in-the-distributed-systems-world&quot;&gt;“What does POSIX conformance/compliance mean in the distributed systems world?”&lt;/a&gt;&lt;/blockquote&gt;&lt;h3 data-block-key=&quot;7mciv&quot;&gt;测试方法&lt;/h3&gt;&lt;p data-block-key=&quot;273a&quot;&gt;针对文件系统 POSIX 兼容性的测试，比较流行的一个测试用例集是 &lt;a href=&quot;https://github.com/pjd/pjdfstest&quot;&gt;pjdfstest&lt;/a&gt;，来源于 FreeBSD，也适用于 Linux 等系统。&lt;/p&gt;&lt;h3 data-block-key=&quot;9m0p9&quot;&gt;测试结果&lt;/h3&gt;&lt;img alt=&quot;1&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/1_CnpuENI.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;9p8p3&quot;&gt;测试结果如上图显示，JuiceFS 的失败用例是0，展现出了最好的兼容性。GCP Filestore 次之，有两项失败；华为云 SFS，Amazon EFS 与 Azure Files 失败的测试用例相比其他产品大了几个数量级，为了方便比较，上图的横坐标使用了对数坐标。&lt;/p&gt;&lt;h3 data-block-key=&quot;fj9l3&quot;&gt;失败用例分析&lt;/h3&gt;&lt;p data-block-key=&quot;336s9&quot;/&gt;&lt;img alt=&quot;2&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/2_0ytIfBK.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;jbtc&quot;/&gt;&lt;p data-block-key=&quot;cjks4&quot;&gt;华为云 SFS，Amazon EFS 与 Azure Files 的失败用例无论从总数及类别均大大超出其它几种文件系统，无法放入同一图表对比，后面将单独分析。&lt;/p&gt;&lt;h4 data-block-key=&quot;46al3&quot;&gt;GCP Filestore&lt;/h4&gt;&lt;p data-block-key=&quot;467rs&quot;&gt;GCP Filestore 共失败 2 项测试，unlink 和 utimensat 这两个类别各一。&lt;/p&gt;&lt;p data-block-key=&quot;1utfg&quot;&gt;第一项是 unlink 测试集中的 &lt;a href=&quot;https://github.com/pjd/pjdfstest/blob/master/tests/unlink/14.t&quot;&gt;unlink/14.t&lt;/a&gt;， 对应日志如下。&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;/root/pjdfstest/tests/unlink/14.t ...........&amp;#13;
not ok 4 - tried &#x27;open pjdfstest_b03f52249a0c653a3f382dfe1237caa1 O_RDONLY : unlink pjdfstest_b03f52249a0c653a3f382dfe1237caa1 : fstat 0 nlink&#x27;, expected 0, got 1&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;该测试集（&lt;a href=&quot;https://github.com/pjd/pjdfstest/blob/master/tests/unlink/14.t&quot;&gt;unlink/14.t&lt;/a&gt;）用于验证 一个文件在打开状态下被删除 时的行为：&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;desc=&quot;An open file will not be immediately freed by unlink&quot;&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;删除文件的操作在系统层面实际对应于 unlink，即移除该文件名到对应 inode 的链接，对应 nlink 的值减 1，这个测试用例就是要验证这一点。&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;# A deleted file&#x27;s link count should be 0&amp;#13;
expect 0 open ${n0} O_RDONLY : unlink ${n0} : fstat 0 nlink&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;文件内容只有在链接数（nlink）减少至 0 并且没有打开的文件描述符（fd）指向该文件时才会被真正删除。如果 nlink 没有被正确更新，可能会导致本该删除的文件仍然残留在系统里。&lt;/p&gt;&lt;p data-block-key=&quot;7g4tr&quot;&gt;另一项是 utimensat 测试集中的&lt;a href=&quot;https://github.com/pjd/pjdfstest/blob/master/tests/utimensat/09.t&quot;&gt;utimensat/09.t&lt;/a&gt;，对应日志如下：&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;/root/pjdfstest/tests/utimensat/09.t ........&amp;#13;
not ok 5 - tried &#x27;lstat pjdfstest_909f188e5492d41a12208f02402f8df6 mtime&#x27;, expected 4294967296, got 4294967295&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;该测试用例要求支持 64 位时间戳。&lt;b&gt;GCP Filestore 支持 64 位时间戳，但是会在此基础上减少1，所以在此这个测试用例上虽然失败但是应该不影响使用。&lt;/b&gt;&lt;/p&gt;&lt;h4 data-block-key=&quot;dhgh4&quot;&gt;腾讯云 CFS&lt;/h4&gt;&lt;img alt=&quot;3&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/3_eQ3NTHw.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;f1qp9&quot;/&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;腾讯云 CFS 共失败 7 项，来自三个类别：utimensat, symlink 和 unlink。我们选取了一些重要的失败项进行了分析说明。&lt;/p&gt;&lt;p data-block-key=&quot;2ju53&quot;&gt;symlink 失败用例对应测试日志如下：&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;/root/pjdfstest/tests/symlink/03.t ..........&amp;#13;
not ok 1 - tried &#x27;symlink 7ea12171c487d234bef89d9d77ac8dc2929ea8ce264150140f02a77fc6dcad7c3b2b36b5ed19666f8b57ad861861c69cb63a7b23bcc58ad68e132a94c0939d5/.../... pjdfstest_57517a47d0388e0c84fa1915bf11fe4a&#x27;, expected 0, got EINVAL&amp;#13;
not ok 2 - tried &#x27;unlink pjdfstest_57517a47d0388e0c84fa1915bf11fe4a&#x27;, expected 0, got ENOENT&amp;#13;
Failed 2/6 subtests&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;该测试集（&lt;a href=&quot;https://github.com/pjd/pjdfstest/blob/master/tests/symlink/03.t&quot;&gt;symlink/03.t&lt;/a&gt;）用于测试路径超出 PATH_MAX 长度时 symblink 的行为&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;desc=&quot;symlink returns ENAMETOOLONG if an entire length of either path name exceeded {PATH_MAX} characters&quot;&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;失败的用例对应代码如下：&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;n0=`namegen`nx=`dirgen_max`nxx=&quot;${nx}x&quot;&amp;#13;
mkdir -p &quot;${nx%/*}&quot;&amp;#13;
expect 0 symlink ${nx} ${n0}&amp;#13;
expect 0 unlink ${n0}&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;该测试用例是要创建长度为 PATH_MAX (包括结尾的0在内）的符号链接，通不过表明无法在 腾讯云 NAS 上创建长度为 PATH_MAX 的符号链接。&lt;/p&gt;&lt;h4 data-block-key=&quot;88a06&quot;&gt;阿里云 NAS&lt;/h4&gt;&lt;p data-block-key=&quot;cdi1p&quot;/&gt;&lt;img alt=&quot;4&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/4_sZZuZsZ.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;8v81q&quot;&gt;阿里云 NAS 未能通过 chmod 、utimensat、unlink 上的几项测试用例。&lt;/p&gt;&lt;p data-block-key=&quot;5ok8f&quot;&gt;在 chmod &lt;a href=&quot;https://github.com/pjd/pjdfstest/blob/master/tests/chmod/12.t&quot;&gt;chmod/12.t&lt;/a&gt; 这个测试集中，阿里云 NAS 失败了以下几个项目&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;/root/pjdfstest/tests/chmod/12.t ............&amp;#13;
not ok 3 - tried &#x27;-u 65534 -g 65534 open pjdfstest_db85e6a66130518db172a8b6ce6d53da O_WRONLY : write 0 x : fstat 0 mode&#x27;, expected 0777, got 04777&amp;#13;
not ok 4 - tried &#x27;stat pjdfstest_db85e6a66130518db172a8b6ce6d53da mode&#x27;, expected 0777, got 04777&amp;#13;
not ok 7 - tried &#x27;-u 65534 -g 65534 open pjdfstest_db85e6a66130518db172a8b6ce6d53da O_RDWR : write 0 x : fstat 0 mode&#x27;, expected 0777, got 02777&amp;#13;
not ok 8 - tried &#x27;stat pjdfstest_db85e6a66130518db172a8b6ce6d53da mode&#x27;, expected 0777, got 02777&amp;#13;
not ok 11 - tried &#x27;-u 65534 -g 65534 open pjdfstest_db85e6a66130518db172a8b6ce6d53da O_RDWR : write 0 x : fstat 0 mode&#x27;, expected 0777, got 06777&amp;#13;
not ok 12 - tried &#x27;stat pjdfstest_db85e6a66130518db172a8b6ce6d53da mode&#x27;, expected 0777, got 06777&amp;#13;
Failed 6/14 subtests&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;该测试集（&lt;a href=&quot;https://github.com/pjd/pjdfstest/blob/master/tests/chmod/12.t&quot;&gt;chmod/12.t&lt;/a&gt;）用于测试 SUID/SGID 位的行为&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;desc=&quot;verify SUID/SGID bit behaviour&quot;&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;我们选取其中的第11和12个测试用例来详细解释一下，同时覆盖了这两个权限位&lt;/p&gt;
                        
                    
                        
                        &lt;pre class=&quot;line-numbers rounded-md&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;# Check whether writing to the file by non-owner clears the SUID+SGID.&amp;#13;
expect 0 create ${n0} 06777&amp;#13;
expect 0777 -u 65534 -g 65534 open ${n0} O_RDWR : write 0 x : fstat 0 mode&amp;#13;
expect 0777 stat ${n0} mode&amp;#13;
expect 0 unlink ${n0}&lt;/code&gt;&lt;/pre&gt;
                        
                    
                        
                            &lt;p data-block-key=&quot;esjf6&quot;&gt;此处，我们先以 06777 的权限创建目标文件，然后修改文件内容，检查 SUID 和 SGID 是否被正确清除。文件权限里的 777 大家会比较熟悉，分别对应 owner，group和 other 的 rwx，即可读、可写、可执行。最前面的 0 表示八进制数。&lt;/p&gt;&lt;p data-block-key=&quot;arq8n&quot;&gt;第二位 6 需要着重解释下，这个八位元组（octet）代表特殊权限位，其中前两位分别对应 setuid/setgid（或称 SUID/SGID），可以应用于可执行文件及公共目录。该权限位被设置时，任何用户都会以 owner （或 group）身份来运行该文件。这个特殊的属性允许用户获取通常只对 owner 开放的文件和目录访问权限。例如 passwd 命令就设置了 setuid 权限，这允许普通用户修改密码，因为保存密码的文件是只允许 root 访问的，用户不可直接修改。&lt;/p&gt;&lt;p data-block-key=&quot;7ofvp&quot;&gt;setuid/setgid 设计的出发点是提供一种方法，让用户以限定的方式（指定可执行文件）访问受限文件（非当前用户所有）。因此，当文件被非 owner 修改时应自动清除此权限位，以避免用户通过这个途径获取其他权限。&lt;/p&gt;&lt;p data-block-key=&quot;9nujk&quot;&gt;从测试结果中我们可以看到在阿里云 NAS 中，&lt;b&gt;文件被非 owner 修改时，setuid/setgid 均未被清除，这样实际上用户可以通过修改文件内容以该 owner 身份进行任意操作，这将会是个安全隐患。&lt;/b&gt;&lt;/p&gt;&lt;p data-block-key=&quot;44aj&quot;&gt;参考阅读： &lt;a href=&quot;https://docs.oracle.com/cd/E19683-01/816-4883/secfile-69/index.html&quot;&gt;Special File Permissions (setuid, setgid and Sticky Bit) (System Administration Guide: Security Services)&lt;/a&gt;&lt;/p&gt;&lt;h4 data-block-key=&quot;dhmtk&quot;&gt;华为云 SFS 与 Amazon EFS&lt;/h4&gt;&lt;p data-block-key=&quot;95se8&quot;&gt;华为云 SFS 与 Amazon Elastic File System (EFS) 在 pjdfstest 测试中失败内容类似。失败比例大概为21%，失败用例几乎覆盖了所有类别。&lt;/p&gt;&lt;p data-block-key=&quot;f68rl&quot;/&gt;&lt;img alt=&quot;5&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/5_uSMbcEv.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;86ah7&quot;/&gt;&lt;img alt=&quot;6&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/6_GcsqnKV.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;clbme&quot;&gt;两者都支持以 NFS 方式挂载，但对 NFS 特性的支持并不完整。比如都不支持块设备和字符设备，这直接导致了 pjdfstest 中大量测试用例的失败。排除这两类文件之后，仍然有上百项不同类别的失败，&lt;b&gt;所以在复杂场景中应用二者必须慎之又慎。&lt;/b&gt;&lt;/p&gt;&lt;h4 data-block-key=&quot;45rf9&quot;&gt;Azure Files&lt;/h4&gt;&lt;p data-block-key=&quot;70a9c&quot;/&gt;&lt;img alt=&quot;1111&quot; class=&quot;richtext-image full-width&quot; src=&quot;https://static1.juicefs.com/images/1111_3pla2Xu.width-800.png&quot;/&gt;&lt;p data-block-key=&quot;fne6f&quot;/&gt;&lt;p data-block-key=&quot;382nn&quot;&gt;而 Azure Files 失败率达到了 62%，这说明一些基本的 POSIX 场景可能都会有不兼容的问题。比如 Azure Files 文件与文件夹默认权限 0777，所有者为 root，且都不支持修改，也就是说没有任何权限限制。另外 Azure File shares 也不支持硬链接与符号链接。&lt;b&gt;所以使用 Azure Files 需要仔细测试并慎重考虑场景是否足够简单。&lt;/b&gt;&lt;/p&gt;&lt;h3 data-block-key=&quot;1e71n&quot;&gt;总结&lt;/h3&gt;&lt;ul&gt;&lt;li data-block-key=&quot;387qj&quot;&gt;JuiceFS 在兼容性方面表现最好，通过了全部的测试项。&lt;/li&gt;&lt;li data-block-key=&quot;athg1&quot;&gt;Google Filestore 次之，有两类未能通过，其中有一项不影响实际使用。&lt;/li&gt;&lt;li data-block-key=&quot;82mog&quot;&gt;腾讯云 CFS 与阿里云 NAS 相差不多，皆有 7-8 项未通过。&lt;/li&gt;&lt;li data-block-key=&quot;dj0jf&quot;&gt;华为云 SFS ，Amazon EFS 与 Azure Files的兼容性较差，有大量的兼容性测试通不过，其中包括有严重安全隐患的若干个测试用例，使用前建议做安全性评估。&lt;/li&gt;&lt;/ul&gt;
                        
                    
                    &lt;/div&gt;
                    &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>432dfb8e1eb26e74e0558acb4a5e2136</guid>
<title>从实战出发，聊聊缓存数据库一致性</title>
<link>https://toutiao.io/k/bp2hkj2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;又拍云&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;upaiyun&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;加速在线业务。为客户提供CDN、PrismCDN、云存储、SSL证书、云处理、直播云、点播云等服务。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a30383b5648518bcdf64d7cf315cf706</guid>
<title>JVM G1GC 小册子</title>
<link>https://toutiao.io/k/9y33xk8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;content&quot; class=&quot;content&quot;&gt;
                    &lt;main&gt;
                        
&lt;p&gt;最近在看中村成洋的《深入 Java 虚拟机 -- JVM G1GC 的算法与实现》，把 G1 算法介绍得比较明白。这本书算是读书笔记，也算是教程，把自己之前的理解结合书里讲解的内容，重新表述，进而增进自己的理解，也算是在践行费曼学习法。&lt;/p&gt;
&lt;p&gt;有很多看书时认为理解的内容，在写作过程中发现其实一窍不通，只能不断通过查其它资料、源码来增进自己的理解。因此读者如果时间允许，也欢迎像我一样写个教程来增进自己的理解。&lt;/p&gt;
&lt;p&gt;GC 一直在不断发展，一些机制、源码都在不断更新。《深入 Java 虚拟机》里的一些内容也已经过时，本书的一些内容基于对 OpenJDK 11 源码的理解做了更新。当然这些内容可能在最新的 JDK 中也已经有了变化，这点也请读者注意。&lt;/p&gt;
&lt;p&gt;另外由于我并不是专业做虚拟机的，对 GC 中一些机制的理解难免有误，欢迎批评指正。&lt;/p&gt;

                    &lt;/main&gt;

                    &lt;nav class=&quot;nav-wrapper&quot; aria-label=&quot;Page navigation&quot;&gt;
                        
                        

                        
                            &lt;a rel=&quot;next&quot; href=&quot;algo/gcs.html&quot; class=&quot;mobile-nav-chapters next&quot; title=&quot;Next chapter&quot; aria-label=&quot;Next chapter&quot; aria-keyshortcuts=&quot;Right&quot;&gt;
                                &lt;i class=&quot;fa fa-angle-right&quot;/&gt;
                            &lt;/a&gt;
                        

                        &lt;p/&gt;
                    &lt;/nav&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>07c2b54819b29365749476e7050e33c2</guid>
<title>现代 C++ 并发编程基础</title>
<link>https://toutiao.io/k/2dogx44</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             defaultNoSetting&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5118110236220472&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/0m4YX595Fom7dUgDLM0OJCxo425I9OKv3jfAgDFAcZH1cfSbV7rKJYKF8qgPJ7phxn55jLQhyRnicECicm1mOzIQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;508&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你好，我是飞宇。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天分享一些现代C++并发编程基础的知识。&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://mp.weixin.qq.com/s?__biz=MzkxNzQzNDM2Ng==&amp;amp;mid=2247494314&amp;amp;idx=1&amp;amp;sn=1e03593dc5ba6fc9ff62d261ef73af7f&amp;amp;chksm=c142103bf635992dded667f4fcc080afe522b60fbca0f6eeee110408086fd102568850af3c8e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;分享一个我自己维护的Linux C/C++学习仓库以及计算机免费PDF电子书仓库&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;分享一个我自己维护的Linux C/C++学习仓库以及计算机免费PDF电子书仓库&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，点此查看详情&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;h3&gt;&lt;span&gt;并行基础&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;std::thread&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 用于创建一个执行的线程实例，所以它是一切并发编程的基础，使用时需要包含 &lt;strong&gt;&amp;lt;thread&amp;gt;&lt;/strong&gt; 头文件， 它提供了很多基本的线程操作，例如&lt;strong&gt; get_id() &lt;/strong&gt;来获取所创建线程的线程 ID，使用&lt;strong&gt; join() &lt;/strong&gt;来加入一个线程等等，例如：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre&gt;&lt;span&gt;#include &amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;thread&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::thread &lt;span&gt;t&lt;/span&gt;([](){&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;hello world.&quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    });&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    t.join();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;span/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;互斥量与临界区&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;我们在操作系统、亦或是数据库的相关知识中已经了解过了有关并发技术的基本知识，mutex 就是其中的核心之一。&lt;strong&gt;C++11 引入了 mutex 相关的类&lt;/strong&gt;，其所有相关的函数都放在 &lt;strong&gt;&amp;lt;mutex&amp;gt;&lt;/strong&gt; 头文件中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;std::mutex &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是 C++11 中最基本的 mutex 类，通过实例化 &lt;strong&gt;std::mutex &lt;/strong&gt;可以创建互斥量， 而通过其成员函数 lock() 可以进行上锁，unlock() 可以进行解锁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是在实际编写代码的过程中，最好不去直接调用成员函数， 因为调用成员函数就需要在每个临界区的出口处调用 unlock()，当然，还包括异常。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时候 C++11 还为互斥量提供了一个 RAII 语法的模板类 std::lock_guard。RAII 在不失代码简洁性的同时，很好的保证了代码的异常安全性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 RAII 用法下，对于临界区的互斥量的创建只需要在作用域的开始部分，例如：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre&gt;&lt;span&gt;#include &amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;thread&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; v = &lt;span&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;critical_section&lt;/span&gt;(&lt;span&gt;int&lt;/span&gt; change_v) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;static&lt;/span&gt; &lt;span&gt;std&lt;/span&gt;::mutex mtx;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::lock_guard&amp;lt;&lt;span&gt;std&lt;/span&gt;::mutex&amp;gt; &lt;span&gt;lock&lt;/span&gt;(mtx);&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 执行竞争操作&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    v = change_v;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 离开此作用域后 mtx 会被释放&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    std::thread t1(critical_section, 2), t2(critical_section, 3);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    t1.join();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    t2.join();&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; v &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;由于 C++ 保证了所有栈对象在生命周期结束时会被销毁，所以这样的代码也是异常安全的。无论 critical_section() 正常返回、还是在中途抛出异常，都会引发堆栈回退，也就自动调用了 unlock()。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;而 std::unique_lock 则相对于 std::lock_guard 出现的，std::unique_lock 更加灵活， std::unique_lock 的对象会以独占所有权&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;（没有其他的 unique_lock 对象同时拥有某个 mutex 对象的所有权） 的方式管理 mutex 对象上的上锁和解锁的操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;所以在并发编程中，推荐使用 std::unique_lock。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;std::lock_guard 不能显式的调用 lock 和 unlock， 而 std::unique_lock 可以在声明后的任意位置调用， 可以缩小锁的作用范围，提供更高的并发度&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你用到了条件变量 std::condition_variable::wait 则必须使用 std::unique_lock 作为参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre&gt;&lt;span&gt;#include &amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;thread&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; v = &lt;span&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;critical_section&lt;/span&gt;(&lt;span&gt;int&lt;/span&gt; change_v) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;static&lt;/span&gt; &lt;span&gt;std&lt;/span&gt;::mutex mtx;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::unique_lock&amp;lt;&lt;span&gt;std&lt;/span&gt;::mutex&amp;gt; &lt;span&gt;lock&lt;/span&gt;(mtx);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 执行竞争操作&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    v = change_v;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; v &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 将锁进行释放&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    lock.unlock();&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 在此期间，任何人都可以抢夺 v 的持有权&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 开始另一组竞争操作，再次加锁&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    lock.lock();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    v += &lt;span&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; v &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    std::thread t1(critical_section, 2), t2(critical_section, 3);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    t1.join();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    t2.join();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;期物&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;期物（Future）表现为 std::future，它提供了一个访问异步操作结果的途径&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，这句话很不好理解。为了理解这个特性，我们需要先理解一下在 C++11 之前的多线程行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试想，如果我们的主线程 A 希望新开辟一个线程 B 去执行某个我们预期的任务，并返回我一个结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这时候，线程 A 可能正在忙其他的事情，无暇顾及 B 的结果， 所以&lt;strong&gt;我们会很自然的希望能够在某个特定的时间获得线程 B 的结果&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 C++11 的 std::future 被引入之前，通常的做法是：创建一个线程 A，在线程 A 里启动任务 B，当准备完毕后发送一个事件，并将结果保存在全局变量中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而主函数线程 A 里正在做其他的事情，当需要结果的时候，调用一个线程等待函数来获得执行的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;而 C++11 提供的 std::future 简化了这个流程，可以用来获取异步任务的结果&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。自然地，我们很容易能够想象到把它作为一种简单的线程同步手段，即屏障（barrier）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了看一个例子，我们这里额外使用 std::packaged_task，它可以用来封装任何可以调用的目标，从而用于实现异步的调用。举例来说：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre&gt;&lt;span&gt;#include &amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;future&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;thread&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 将一个返回值为7的 lambda 表达式封装到 task 中&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// std::packaged_task 的模板参数为要封装函数的类型&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::packaged_task&amp;lt;&lt;span&gt;int&lt;/span&gt;()&amp;gt; &lt;span&gt;task&lt;/span&gt;([](){&lt;span&gt;return&lt;/span&gt; &lt;span&gt;7&lt;/span&gt;;});&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 获得 task 的期物&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;future&lt;/span&gt;&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; result = task.get_future(); &lt;span&gt;// 在一个线程中执行 task&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::thread(&lt;span&gt;std&lt;/span&gt;::move(task)).detach();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;waiting...&quot;&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    result.wait(); &lt;span&gt;// 在此设置屏障，阻塞到期物的完成&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 输出执行结果&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;done!&quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;:: &lt;span&gt;endl&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;future result is &quot;&lt;/span&gt; &amp;lt;&amp;lt; result.get() &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;在封装好要调用的目标后，&lt;strong&gt;可以使用 get_future() 来获得一个 std::future 对象&lt;/strong&gt;，以便之后实施线程同步。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;条件变量&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;条件变量 std::condition_variable 是为了解决死锁而生，当互斥操作不够用而引入的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。比如，线程可能需要等待某个条件为真才能继续执行， 而一个忙等待循环中可能会导致所有其他线程都无法进入临界区使得条件为真时，就会发生死锁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，&lt;strong&gt;condition_variable 实例被创建出现主要就是用于唤醒等待线程从而避免死锁&lt;/strong&gt;。 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;std::condition_variable的 notify_one() 用于唤醒一个线程；notify_all() 则是通知所有线程。下面是一个生产者和消费者模型的例子：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre&gt;&lt;span&gt;#include &amp;lt;queue&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;chrono&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;mutex&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;thread&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#include &amp;lt;condition_variable&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;queue&lt;/span&gt;&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; produced_nums;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::mutex mtx;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::condition_variable cv;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;bool&lt;/span&gt; notified = &lt;span&gt;false&lt;/span&gt;;  &lt;span&gt;// 通知信号&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 生产者&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;auto&lt;/span&gt; producer = [&amp;amp;]() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; ; i++) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;std&lt;/span&gt;::this_thread::sleep_for(&lt;span&gt;std&lt;/span&gt;::chrono::milliseconds(&lt;span&gt;900&lt;/span&gt;));&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;std&lt;/span&gt;::unique_lock&amp;lt;&lt;span&gt;std&lt;/span&gt;::mutex&amp;gt; &lt;span&gt;lock&lt;/span&gt;(mtx);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;producing &quot;&lt;/span&gt; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            produced_nums.push(i);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            notified = &lt;span&gt;true&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            cv.notify_all(); &lt;span&gt;// 此处也可以使用 notify_one&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        }&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    };&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 消费者&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;auto&lt;/span&gt; consumer = [&amp;amp;]() {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;std&lt;/span&gt;::unique_lock&amp;lt;&lt;span&gt;std&lt;/span&gt;::mutex&amp;gt; lock(mtx);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;while&lt;/span&gt; (!notified) {  &lt;span&gt;// 避免虚假唤醒&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;                cv.wait(lock);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            }&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;// 短暂取消锁，使得生产者有机会在消费者消费空前继续生产&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            lock.unlock();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;std&lt;/span&gt;::this_thread::sleep_for(&lt;span&gt;std&lt;/span&gt;::chrono::milliseconds(&lt;span&gt;1000&lt;/span&gt;)); &lt;span&gt;// 消费者慢于生产者&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            lock.lock();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            &lt;span&gt;while&lt;/span&gt; (!produced_nums.empty()) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;                &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;consuming &quot;&lt;/span&gt; &amp;lt;&amp;lt; produced_nums.front() &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;                produced_nums.pop();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            }&lt;/span&gt;&lt;br/&gt;&lt;span&gt;            notified = &lt;span&gt;false&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        }&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    };&lt;/span&gt;&lt;br/&gt;&lt;span/&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;// 分别在不同的线程中运行&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::thread &lt;span&gt;p&lt;/span&gt;(producer);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;std&lt;/span&gt;::thread cs[&lt;span&gt;2&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;2&lt;/span&gt;; ++i) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        cs[i] = &lt;span&gt;std&lt;/span&gt;::thread(consumer);&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    }&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    p.join();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;2&lt;/span&gt;; ++i) {&lt;/span&gt;&lt;br/&gt;&lt;span&gt;        cs[i].join();&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    }&lt;/span&gt;&lt;br/&gt;&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;值得一提的是，&lt;strong&gt;在生产者中我们虽然可以使用 notify_one()，但实际上并不建议在此处使用， 因为在多消费者的情况下，我们的消费者实现中简单放弃了锁的持有，这使得可能让其他消费者 争夺此锁&lt;/strong&gt;，从而更好的利用多个消费者之间的并发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;话虽如此，但实际上因为 std::mutex 的排他性， 我们根本无法期待多个消费者能真正意义上的并行消费队列的中生产的内容，我们仍需要粒度更细的手段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自：现代 C++ 教程：高速上手 C++ 11/14/17/20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://changkun.de/modern-cpp/zh-cn/07-thread/&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-custom=&quot;rgb(172, 29, 16)&quot; data-style=&quot;white-space: normal; background-color: rgb(255, 255, 255); font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; caret-color: rgb(51, 51, 51); color: rgb(160, 160, 160); widows: 1; letter-spacing: 0.54px; text-align: center; font-size: 18px; line-height: 28.8px;&quot;&gt;&lt;section data-style=&quot;margin-right: auto; margin-bottom: 10px; margin-left: auto; border-bottom: 1px solid rgb(221, 221, 221);&quot;&gt;&lt;section data-style=&quot;margin-bottom: -1px; padding-right: 5px; padding-bottom: 6px; padding-left: 5px; line-height: 1.1; border-bottom: 2px solid rgb(34, 18, 166); display: inline-block; text-align: left;&quot;&gt;&lt;span data-style=&quot;letter-spacing: 0.544px; font-size: 12px; color: rgb(2, 30, 170);&quot;&gt;&lt;span&gt;—&lt;/span&gt;—&lt;/span&gt;&lt;/section&gt;&lt;section data-style=&quot;margin-bottom: -1px; padding-right: 5px; padding-bottom: 6px; padding-left: 5px; line-height: 1.1; border-bottom: 2px solid rgb(34, 18, 166); display: inline-block; text-align: left;&quot;&gt;&lt;span&gt;EOF&lt;/span&gt;&lt;/section&gt;&lt;section data-style=&quot;margin-bottom: -1px; padding-right: 5px; padding-bottom: 6px; padding-left: 5px; line-height: 1.1; border-bottom: 2px solid rgb(34, 18, 166); display: inline-block; text-align: left;&quot;&gt;&lt;span data-style=&quot;letter-spacing: 0.544px; font-size: 12px; color: rgb(2, 30, 170);&quot;&gt;—&lt;span&gt;—&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9908883826879271&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibLeYZx8Co5IVdlbI2kibmkpdP1oZRJibUNW3AIzx3wHsCEfnIahm9WlDwUbicMNRKL3LpdcgeHOlrdJFVhicwBPM0Q/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;878&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我的私人微信&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是飞宇，本硕均于某中流985 CS就读，先后于百度搜索以及字节某电商部门担任Linux C/C++后端研发工程师。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;同时，我也是知乎博主@韩飞宇，日常分享C/C++、计算机学习经验、工作体会，欢迎点击&lt;span&gt;阅读原文&lt;/span&gt;围观我分享的C/C++学习知识&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;546&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;66&quot; data-ratio=&quot;0.15789473684210525&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_gif/ociaaribHd5oeoAmgtZ7uuu57CCa12tmv1nHO32caCXZ71hZFDIX22ZEia27lfeFHTPrLjsKjetibblCZBWdhcK3lQ/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;gif&quot; data-w=&quot;950&quot;/&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;👇点击&lt;/span&gt;&lt;span&gt;&lt;span&gt;阅读原文&lt;/span&gt;&lt;/span&gt;&lt;span&gt;查看你错过的C/C++知识&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;10000&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>