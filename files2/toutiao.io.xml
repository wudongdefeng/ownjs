<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>c3b9416ca1642323e15e9cca641347f6</guid>
<title>只会 git log ？ 其实 git 还有两个好用的 log 命令</title>
<link>https://toutiao.io/k/c9hdywp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git log &lt;span&gt;是经常用的 git 命令，&lt;/span&gt;用于展示 commit 历史的，除了它之外，git 还有两个 log 命令：git shortlog、git reflog。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后两个命令也很有用，但是很多人都不知道。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章我们就过一下这 3 个 git 的 log 命令吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用 git branch 看一下本地的分支，有 main、0.5-stable 这两个，当前在 main 分支：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5054347826086957&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOzQnItcicRrYMYyhyMXPcicEE2ykWWQMN9biaSpFav3iaG07Sg6cSxJibHuw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;736&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是这样的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6905487804878049&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANO8MibictVEmVgmfWibCXVDxWqsujbj3YcaiamqYn4K0HWFfHtu336Pf8KPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1312&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 commit 都有自己的 hash，并且记录着父 commit 的 hash。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分支名记录着它指向的 commit。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HEAD 指针指向当前的分支，这里就是 main 分支。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 .git 的 HEAD 文件里也可以看到 HEAD 指针的指向：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6387959866220736&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOyJjiaib7PiaCpAVSjtLcbHyvY3fpbqmnagLnUafIp2ICCuliaQvfxZgD8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1196&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了分支之外，tag 也是指向 commit 的一个指针。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 git tag -l 可以看到我本地有这些 tag：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7391304347826086&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOdic7RKial5ofROYxyQFZibpdCgPRfc8m5xDSMCoVL3T7JcNg4xQQC9C5g/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;782&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实这些也就是指向某个 commit 的指针：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.766497461928934&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOPf9ib8CApAcQZVX10aO6ma53sREVj86icse1zdZhEmFHvUhWVA2Fv6Tg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1182&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HEAD、branch、tag 这些都是指针，在 git 里叫做 ref。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git log 默认是打印的 HEAD 指针指向的 commit 的历史。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5449490268767377&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOnk5mgLPk3FQTmv6nrbVdmFgPGPiciaCKhwXziaOEibzUOlyf9Hic11FzUuQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1079&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你也可以加任何一个 ref 来打印那个指针指向的 commit 的历史：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.575187969924812&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOzJqVrTtOjagqrZKFic7mgqJZaa2ibpos5COe6MmZZUYM68C0nTSJyWJw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1064&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如我加了 branch 的名字，那 log 的就是 0.5-stable 这个 branch 的历史。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也可以加 tag 的名字，或者某个具体 commit 的 hash 来打印它的历史：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6287037037037037&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANO9eJ9PxfzCCRibmhcLOq6o9POHt16ZVXcBUYH0ZZbGeZnZrkkZKZ9nwg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5657407407407408&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOgcFguKBKECs9RD3DWvd4Rq1JUTJfhJlbdqV8me8veZqPrHVKQtYYGA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面就是分别打印了某个 tag 的、某个 commit 的历史。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git log 支持一些 option 来对输出的 log 做限定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如你可以根据作者过滤：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --author=&lt;span&gt;&quot;xxx&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/figure&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6524559777571826&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOV1341shfYjcNoOYzKgLXhjqibyXLUTe37bhjcBWK4ofMxsmusejtnUQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1079&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;支持模糊搜索。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你也可以根据 commit 的内容来过滤：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --grep=&lt;span&gt;&quot;xxx&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.535681186283596&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOSZoq4UwSp4DLtRewZNDt6wr2fNU6vnDPT70yHcpkznp9CRF6WWMFCQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1079&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;--grep 和 --author 不一样，它是支持正则的，你可以根据正则来过滤 commit message&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --grep=&lt;span&gt;&quot;Add.*runtime&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就是过滤 commit message 里有 Add 开头、中间任意个字符然后加 runtime 的 commit：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5814814814814815&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOe7mJAclSKVrM6k1jdqK7fRdL0hqvn3xj3ynLHpuj0UiayKQ2z7HwOibw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为支持了正则，所以这个 --grep 是挺强大的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，还可以根据时间来过滤，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --after=&lt;span&gt;&quot;2022-01-01&quot;&lt;/span&gt; --before=&lt;span&gt;&quot;2022-01-31&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就可以过滤 2022 年 1 月份的 commit：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5055658627087198&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANO83GwibyaaGtwph5U0HPYyibB2rA5p6gibOLuImyhGVib6FfS3PJThKIdLg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1078&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的 --before、--after 可以换成 --until、--since，一样的含义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我个人更习惯 before、after。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了过滤之外，还可以控制打印的格式，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --format=&lt;span&gt;&quot;%h %as %s %an&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的 %h 是缩写的 commit hash，%as 是日期的一种格式，%s 是 commit 的主题，%an 是 commit 的作者。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打印出来的就是这样的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4397031539888683&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOA1o9nvgQvONMmXBDxVWs95xjXo3tacEDRySqiarQ4UbjswtBYWBAT9Q/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1078&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以给它加上一些换行，通过 %n：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --format=&lt;span&gt;&quot;hash: %h %n日期: %as %n主题: %s %n作者: %an %n&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就是这样的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.448563484708063&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOkNevxs2icfqQQbMX9z247dOBrT7qAlzKcGz5C6J3LtX9icEQQzCSibpxw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1079&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还可以用 %Cred %Creset 包裹来把中间字符串变红，或者 %Cblue %Creset 包裹，把中间字符串变蓝：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --format=&lt;span&gt;&quot;hash:%Cred %h %Creset%n日期: %as %n主题:%Cblue %s %Creset%n作者: %an %n&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;效果是这样的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4202226345083488&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOibK9rmHib6bja6UsuxK8QicBNOLL57ljRQiaDXoL7Eq4MvLT9tGHQkDxww/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1078&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体有哪些变量、哪些颜色，可以去看文档。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之，log 输出的格式和颜色是可以控制的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;学了这些 option 之后，我们来做个综合的需求吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;周会的时候，我想看看某个同学上一周的 commit，应该怎么做呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --author=&lt;span&gt;&quot;guang&quot;&lt;/span&gt; --after=&lt;span&gt;&quot;2022-01-01&quot;&lt;/span&gt; --before=&lt;span&gt;&quot;2022-01-07&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样其实有问题，因为他可能不是在 main 分支开发的，可能是在某个 feture 分支开发的，然后合并到了 main。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何查看他在所有分支的过去一周的 commit 呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加个 --all 就好了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --author=&lt;span&gt;&quot;guang&quot;&lt;/span&gt; --after=&lt;span&gt;&quot;2022-01-01&quot;&lt;/span&gt; --before=&lt;span&gt;&quot;2022-01-07&quot;&lt;/span&gt; --all&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但这里面免不了多了一个 merge 的 commit，而这些 commit 其实没啥具体内容。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以可以加个 --no-merges。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;--merges 是只保留 merge 的 commit：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5351851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANO2CkuJFXLhjLE10f4NwFyWTVhlVPL66bmSGphlKRdmSuy5u6ibqWNePQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;--no-merges 正好反过来，只保留非 merge 的 commit：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6443594646271511&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOsIvbYxMMDbgYzNhVqumqFjlhO6u1XOFicBmjibtgXdoFvKJPSt3PAuxw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1046&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以可以这样写：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git &lt;span&gt;log&lt;/span&gt; --author=&lt;span&gt;&quot;guang&quot;&lt;/span&gt; --after=&lt;span&gt;&quot;2022-01-01&quot;&lt;/span&gt; --before=&lt;span&gt;&quot;2022-01-07&quot;&lt;/span&gt; --all --no-mreges&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是 guang 在 2022-01-01 到 2022-01-07 这一周的在所有分支的 commit（排除了 merge 的 commit）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但我如果想看所有同学的一周的 commit 这样也太麻烦了吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有没有什么按照人来分组统计的命令呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还真有，就是 git shortlog。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5990740740740741&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOx1zf1YIcY4JHntEsAbbiaicMthavchRIhCuZFnNVFkFy4HSvo0Xqsr9w/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1080&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它展示的就是每个作者提交了多少个 commit，都是啥。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;是一个 git log 的统计结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认是按照作者名的字母顺序来排列的，也可以按照 commit 数来倒序排列：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git shortlog -n&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/figure&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5996292863762743&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOxDbicebqmBU0Erj3Ws0cMq7LhQ297ugkyl2DwVy47hZ9mwFhdI4IvVw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1079&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;‍&lt;/span&gt;&lt;span&gt;‍&lt;/span&gt;这样我如果想看某段时间内，谁提交了哪些 commit，就可以这样写：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git shortlog -n --after=&lt;span&gt;&quot;2022-01-01&quot;&lt;/span&gt; --before=&lt;span&gt;&quot;2022-01-31&quot;&lt;/span&gt; --all --no-merges&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就是输出在 2022-01-01 到 2022-01-31 这一个月内，所有人的 commit 的统计结果，包含所有分支的除去 merge commit 的 commit，按照 commit 数倒序排列。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.39053803339517623&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOtCw2FQic6qtNZNfmY08dcRsGnBrzcXr2cgrDW66tWyiawYotxA754Zeg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1078&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的 log 也可以修改格式：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git shortlog -n --after=&lt;span&gt;&quot;2022-01-01&quot;&lt;/span&gt; --before=&lt;span&gt;&quot;2022-01-31&quot;&lt;/span&gt; --all --no-merges --format=&lt;span&gt;&quot;%h %as %s&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如我只要 hash、日期、主题，就可以 --format=&quot;%h %as %s&quot;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.362708719851577&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOGMjrWf5arbBj4NugAdXXsKXeZFAf1GO4uH8e9ZmDKKoK2SCibaibB2vg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1078&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之， git log 是查看 commit 历史的，而 git shortlog 是查看分组的统计结果的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那 git reflog 是干啥的呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它是记录 ref 的修改历史的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;什么 ref 前面讲过了，branch、HEAD、tag 这些都是。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如你新增了一个 commit、新建了一个 branch、新增了一个 tag、刚 pull 下来一个分支，这些都是对 ref 的修改。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git 会把它记录在 reflog 里。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.49166666666666664&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOT7ibXmHzOSYrh7HHVn4GYfxFABb4FP2hxa04q0WG51cjEPwJic6zicmWw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如这里的新的 commit、reset 到历史 commit、checkout 新分支等都是 ref 的变动。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.27324913892078073&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOXozX6UGLWF6VuT0ryiaxIKvFPzjbLT9VsGlUj84ia67IcojzREW5WXCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1742&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但默认只显示 HEAD 指针的变化历史。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想看到所有分支的 ref 变化历史，可以加个 --all。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4763670064874884&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOUm1gqjsy3DIxGqL2u4ux57sZ8BnF4P5kgODSU7Z6SbXVCiaGAquiaIwA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1079&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样就多了别的分支的 ref 变化历史：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.513317191283293&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOQFmBTzBEg8vLY4W9nh0G6RUT0Nfb5T1H8ib5eGkyYoGAuHvb7ncJtDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1652&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有的同学可能会问，记录 ref 变化历史干啥用？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如说当你 git reset 到了一个之前的分支，又想恢复回去，这时候不知道之前的那个 commit 的 hash 是啥了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候就可以看 reflog 里的 ref 变化历史，找到之前的 commit 的 hash。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后 git reset 到那个 hash。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是 git reflog 的作用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那这些 reflog 保存在哪里呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 .git 的 logs/refs 目录下：&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOqNrZCQ1CPRw34K5em5iaBxSXaaSib5mMJW6FPmpviaJLAj3FORH1QXO4Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2220&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 HEAD 的 reflog，对比下是不是一毛一样（顺序是反的）：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6381048387096774&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YprkEU0TtGgWAsaiaVN3kWnssicRS2eANOnlQbH4ujmqiaG9KYrYmHpnv3Oz9IHMQnnsRcprrfPNHaSAAGhibjhcBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1984&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里就是 reflog 保存的地方。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git 有 3 个 log 命令：git log、git shortlog、git reflog。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git log 是查看 commit 历史的，可以指定 branch、tag、某个 commit 等来查看对应的 commit 历史。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以通过 --author、--before、--after、--grep、--merges、--no-merges、--all 来过滤某个作者、某段时间内、某个 commit 内容、非 merge 的 commit、全部分支的 commit 等 commit。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还可以通过 --format 来指定输出的颜色和格式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git shortlog 是 git log 的统计结果，可以按照作者来分组统计。比如查看上一周每个人提交了多少个 commit。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git reflog 记录的是 ref 的变化历史，比如分支切换、reset、新的 commit 等都会记录下来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以通过 git reflog 命令来查看，也可以直接在 .git/logs/refs 下查看。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;git 的 3 个 log 命令各有各自的用途，都是很常用的 git 命令。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>897f3b855f001b8a0fa36b0a1ebabed5</guid>
<title>作为移动开发你不能不了解的编译流程</title>
<link>https://toutiao.io/k/4i7qt5u</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;&lt;strong&gt;作者：京东零售 李臣臣&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;阅读本文，或许能够了解关于以下的几个问题： 1、编译器是什么？为什么会有编译器这样一个东西？ 2、编译器做了哪些工作？整个编译过程又是什么？ 3、Apple的编译器发展历程以及为什么会抛弃GCC换成自研的LLVM？ 4、从编译器角度看Swift与OC能够实现混编的底层逻辑&lt;/p&gt;

&lt;h2&gt;一、找个翻译官，说点计算机能懂的语言&lt;/h2&gt;

&lt;p&gt;说点常识，众所周知，作为开发者我们能看懂这样的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int a = 10;
int b = 20;
int c = a + b;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;而对于计算机貌似只能明白这样的内容:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-50jWov9bT0CTk9sLM.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;注：使用 &lt;code&gt;od -tx1 /tmp/binary.bin&lt;/code&gt; 可以根据需要输出二进制、八进制或者十六进制的内容&lt;/p&gt;

&lt;p&gt;这样看的话，计算机除了知道1与0的含义，其他的字符内容完全不知道。为了去给计算机下达我们需要的指令，我们又不得不得按照计算机能够懂得语言与其进行通信交流，怎么办呢？我们貌似需要找一个翻译，将我们的想要下达的指令内容交给翻译让其成计算机能够识别的指令进行内容传达，这样计算机就能通过翻译来一步步执行我们的指令动作了，那这个翻译其实就是我们经常说到的编译器。&lt;/p&gt;

&lt;p&gt;说到编译器呢？它的历史还是很悠久的，早期的计算机软件都是用汇编语言直接编写的，这种状况持续了数年。当人们发现为不同类型的中央处理器CPU编写可重用软件的开销要明显高于编写编译器时，人们发明了高级编程语言。简单说就是由于中央处理器CPU的差异，使得软件的开发成本很高，我们要针对不同的CPU编写不同的汇编代码，而且不同的CPU架构呢相对应的汇编的指令集也有差异。如果在汇编体系之上定义一套与汇编无关的编码语言，通过对通用的这样语言进行转换，将其转换成不同类型的CPU的汇编指令，是不是就能解决不同CPU架构适配的问题呢？那其中的定义的通用编码语言就是我们所说的高级语言，比如C/C++、Object-C、Swift、Java等等，而其中的汇编翻译转换工作呢则交由具体的编译器进行实现。&lt;/p&gt;

&lt;h2&gt;二、说到编译器当然少不了Apple&lt;/h2&gt;

&lt;p&gt;对于Apple的编译器，就不得不说一下GCC与LLVM的相爱相杀了。由于编译器涉及到从高级开发语言到低级语言的转换处理，复杂度自然不必多说。我们都知道Apple产品软件的开发语言是Objective-C，可以认为是对C语言的扩展。而C语言所使用的编译器则是大名鼎鼎的GCC，此时的GCC肯定是妥妥的大哥了，所以早些年为了不必要的资源投入，对于自家OC（Objective-C简称OC）编译器的开发索性直接拿大哥的代码GCC进行二次开发了，没错，从主干版本中拉个独立分支搞起。这么看的话，Apple早期就已经开始了降本增效了？&lt;/p&gt;

&lt;p&gt;随着OC语言的不断迭代发展，语言特性也就愈来愈多，那编译器的新特性能力支持当然也得跟得上啊？但是C也在不断的迭代发展，GCC编译器的主干功能当然也越来越多，OMG！单独维护的OC编译器版本对GCC主干的新功能并没有很好的同步，关键在合并功能的时候不可避免的出现种种冲突。为此，Apple曾多次申请与GCC主干功能合并同步，GCC乍一看都是OC 特性feature，跟C有毛线关系？所以关于合并的优先级总是排到最低，Apple也是没有办法，结果只能是差异化的东西越来越多，编译器的维护成本也变得异常之高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-52ZG0H7tqjCk9U0YP.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;除了以上的问题之外，GCC整体的架构设计也是非模块化的，那什么是模块化呢？比如我们通常在系统设计的时候，会将各个系统的功能进行模块化分割设计，不同的模块能够单独为系统内部提供不同的功能。同时呢，我们还能把这些模块单独抽离出来提供给外部使用，这就增大了系统的底层的灵活度，简单说就是能够直接使用模块化的接口能力。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-52zpYVCUUj0PuLzyM.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;所以Apple深知定制化的GCC编译器将是后续语言迭代升级的绊脚石，内部也在不断的探索能够替代GCC的替代品。在编译器的探索路上，这里不得不说一下Apple的一位神级工程师 Chris Lattner(&lt;strong&gt;克里斯·拉特纳&lt;/strong&gt;)，可能光说名字的话可能没有太多人知道他，那如果要说Swift语言的创始人是不是就有所耳闻了？由于克里斯在大学期间对编译器的细致的研究，发起了LLVM（Low Level Virtual Machine）项目对编译的源代码进行了整体的优化。Apple将目光放在了克里斯团队身上，同时直接顾用了他们团队，当然克里斯也没有辜负众望，在 Xcode从 3.1实现了llvm-gcc compiler，到 3.2实现了Clang 1.0， 再到4.0实现了Clang 2.0 ，后来在Mac OS X 10.6 开始使用LLVM的编译技术，到现在已经将LLVM发展成为了Apple的核心编译器。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-53KVSs53ZBsJq9FuaS.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;三、LLVM编译器的编译过程与特点&lt;/h2&gt;

&lt;p&gt;对于传统的编译器，主要分为前端、优化器和后端，引用一张通用的简洁的编译过程图，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-53iHNlC6dFMLVWWYH.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;简单来说，针对于源代码翻译成计算机底层代码的过程中呢要经历三个阶段：前端编译、优化器优化、后端编译。通过前端编译之后，针对编译的产物进行优化处理，最后通过后端完成机器码的生成。而对于LLVM编译器来说，这里我们以OC的前端编译器Clang为例，它负责LLVM的前端的整体编译流程（预处理、词法分析、语法分析和语义分析），生成中间产物LLVMIR，最后由后端进行架构处理生成目标代码，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-54sgYIvefLhZAX8YC.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;可以看出LLVM将编译的前后端独立分开了，前端负责不同语言的编译操作，如果增加一个语言的编译支持，只需要扩展支持当前语言的前端编译支持（Clang负责OC前端编译、SwiftC负责Swift前端编译）即可，优化器与后端编译器整体均不用修改即可完成新增语言的支持。同理，对于后端，如果需要新增新的架构设备的支持，只需要扩展后端架构对应编译器的支持即可完成新架构设备的支持，这也是LLVM编译器的优点之一。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-5410x33K8XqdlABAO0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;3.1、编译器前端&lt;/h3&gt;

&lt;p&gt;在XCode中针对于OC与Swift的编译有着不同的前端编译器，OC采用Clang进行编译，而Swift则采用SwiftC编译器，两种不同的编译器前端在编译之后，生成的中间产物都是LLVMIR。这也就解释了对于高级语言Swift或者OC开发，哪怕是混编，在经过各自的编译器前端编译之后，最终的编译产物都是一样的，所以选用哪种开发语言对于最终生成的中间代码IR都是通用的。对于Clang的整体编译过程，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-560RkakBCG6pfm240f.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;预处理&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;通过对源代码中以“#”号开头如包含#include，宏定义制定#define等扫描。然后进行源代码定义替换，进行头文件内容的展开。通过预处理器把源文件处理成&lt;code&gt;.i&lt;/code&gt;文件。&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;词法分析&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;在词法分析完成之后会生成 &lt;code&gt;token&lt;/code&gt; 产物，它是做什么的？这里不贴官方的解释了，简单点说就是对源代码的原子切分，切分成能够底层描述的单个原子，就是所谓的&lt;code&gt;token&lt;/code&gt;，至于&lt;code&gt;token&lt;/code&gt;长什么样子？可以通过 &lt;code&gt;clang&lt;/code&gt; 的命令执行编译查看生成的原子内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;clang -fmodules -E -Xclang -dump-tokens xxx.m
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#import &amp;lt;UIKit/UIKit.h&amp;gt;
#import &quot;AppDelegate.h&quot;

int main(int argc, char * argv[]) {
    NSString * appDelegateClassName;
    @autoreleasepool {
        // Setup code that might create autoreleased objects goes here.
        appDelegateClassName = NSStringFromClass([AppDelegate class]);
        int a = 0;
    }
    return UIApplicationMain(argc, argv, nil, appDelegateClassName);
}


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们拿工程的main.m 做个测试，编译生成的内容如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-22-57zuAcmidg57iUqbUl.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;注：如果遇到 main.m:8:9: fatal error: &#x27;UIKit/UIKit.h&#x27; file not found 错误，可以加上系统基础库路径如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;clang \
-fmodules \
-E \
-Xclang \
-dump-tokens  \
-isysroot \
/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk  \
main.m 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以发现，计算机在进行源码处理的时候，并不能像人一样能够理解整个源码内容的含义。所以为了进行转换，在进行源码分析的时候，将整体的内容进行单词切分，形成原子为后续的语义分析做准备，整体的切分过程大致采用的是状态机原理。&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;语法分析&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;在完成词法分析之后，编译器大致理解了每个源码中的单词的意思，但是对于单词组合起来的语句内容并不能理解。所以接下来需要对单词组合起来的内容进行识别，也就是我们所说的&lt;code&gt;**语法分析**&lt;/code&gt;。 语法分析的原理有点模板匹配的意思，怎么理解呢？就是我们常说的语法规则，在编译器中预置了相关语言的语法规则模板，如果匹配了相关的规则，则按照相关语法规则进行解析。举个例子，比如我们在OC中写一个这样的语句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int a = 100;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一种通用的赋值语法格式，所以在编译器进行语法分析的时候，将其按照赋值语法的规则进行解析，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-23-00xtkbeHNvTtXv11Qz.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;通过对原子token的组合解析，最终会生成了一个抽象语法树（AST），AST抽象语法树将源代码转换成树状的数据结构，它描述了源代码的内容含义以及内容结构，它的生成能够让计算机更好的理解和处理中间产物。以XCode生成的默认项目的main.m内容为例，在 &lt;code&gt;clang&lt;/code&gt; 中我们依旧可以查看具体的抽象生成树（AST）的样子，可以对源码进行如下的编译：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;clang \
-isysroot \
/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk \
-fmodules \
-fsyntax-only \
-Xclang \
-ast-dump \
main.m
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译后的结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-23-017OIn8rCHSLHLiJu.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;简单转换一下树形视图，大致长这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-23-01sTZ40caZBmCKJO7K.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;可以发现，经历过语法分析之后，源代码转换成了具体的数据结构，而数据结构的整体生成是后续进行语义分析生成中间代码的基础前提。&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;语义分析&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;在经历过语法分析之后，编译器会对语法分析之后生成的抽象语法树（AST）再次进行处理，需要注意的是编译器并不会直接通过AST编译成目标代码，主要原因是因为编译器将编译过程拆分了前后端，而前后端的通信的媒介就是IR，没错就是之前提到过的LLVMIR这样一个中间产物。该中间产物与语言无关，同时与cpu的架构也无关，那么为什么要加上中间产物这个环节，直接生成目标代码难道不是更好吗？我们都知道cpu的不同架构直接影响cpu的指令集，不同的指令集对应不同的汇编指令，所以针对于不同的cpu架构要对应生成不同适配的汇编指令才能正常的运行到不同的cpu架构的机器上。如果将前后端的编译过程绑定死，那么就会导致每增加一个新的编译前端，同时增加对所有cpu架构的后端的支持（1对n的关系），同理，如果增加新的一个cpu架构支持，编译前端也需要通通再实现一遍，这个工作量是很重复以及繁琐的。所以为了避免这样的问题，Apple对编译器的前后端进行了拆分，用中间产物来进行前后端的逻辑适配。&lt;/p&gt;

&lt;p&gt;对于语义分析生成中间产物的过程，也可以通过 &lt;code&gt;Clang&lt;/code&gt; 的编译命令查看，具体如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 生成扩展为.ll的便于阅读的文本格式
clang \
-isysroot \
/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk \
-S \
-emit-llvm \
main.m \
-o \
main.ll

# 生成二进制格式，扩展为.bc
clang \
-isysroot \
/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk \
-emit-llvm \
-c \
main.m \
-o \
main.bc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译后生成的内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;; ModuleID = &#x27;main.m&#x27;
source_filename = &quot;main.m&quot;
target datalayout = &quot;e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128&quot;
target triple = &quot;x86_64-apple-ios16.2.0-simulator&quot;

%0 = type opaque
%struct._class_t = type { %struct._class_t*, %struct._class_t*, %struct._objc_cache*, i8* (i8*, i8*)**, %struct._class_ro_t* }
%struct._objc_cache = type opaque
%struct._class_ro_t = type { i32, i32, i32, i8*, i8*, %struct.__method_list_t*, %struct._objc_protocol_list*, %struct._ivar_list_t*, i8*, %struct._prop_list_t* }
%struct.__method_list_t = type { i32, i32, [0 x %struct._objc_method] }
%struct._objc_method = type { i8*, i8*, i8* }
%struct._objc_protocol_list = type { i64, [0 x %struct._protocol_t*] }
%struct._protocol_t = type { i8*, i8*, %struct._objc_protocol_list*, %struct.__method_list_t*, %struct.__method_list_t*, %struct.__method_list_t*, %struct.__method_list_t*, %struct._prop_list_t*, i32, i32, i8**, i8*, %struct._prop_list_t* }
%struct._ivar_list_t = type { i32, i32, [0 x %struct._ivar_t] }
%struct._ivar_t = type { i64*, i8*, i8*, i32, i32 }
%struct._prop_list_t = type { i32, i32, [0 x %struct._prop_t] }
%struct._prop_t = type { i8*, i8* }

@&quot;OBJC_CLASS_$_AppDelegate&quot; = external global %struct._class_t
@&quot;OBJC_CLASSLIST_REFERENCES_$_&quot; = internal global %struct._class_t* @&quot;OBJC_CLASS_$_AppDelegate&quot;, section &quot;__DATA,__objc_classrefs,regular,no_dead_strip&quot;, align 8
@llvm.compiler.used = appending global [1 x i8*] [i8* bitcast (%struct._class_t** @&quot;OBJC_CLASSLIST_REFERENCES_$_&quot; to i8*)], section &quot;llvm.metadata&quot;

; Function Attrs: noinline optnone ssp uwtable
define i32 @main(i32 %0, i8** %1) #0 {
  %3 = alloca i32, align 4
  %4 = alloca i32, align 4
  %5 = alloca i8**, align 8
  %6 = alloca %0*, align 8
  %7 = alloca i32, align 4
  store i32 0, i32* %3, align 4
  store i32 %0, i32* %4, align 4
  store i8** %1, i8*** %5, align 8
  %8 = call i8* @llvm.objc.autoreleasePoolPush() #1
  %9 = load %struct._class_t*, %struct._class_t** @&quot;OBJC_CLASSLIST_REFERENCES_$_&quot;, align 8
  %10 = bitcast %struct._class_t* %9 to i8*
  %11 = call i8* @objc_opt_class(i8* %10)
  %12 = call %0* @NSStringFromClass(i8* %11)
  store %0* %12, %0** %6, align 8
  store i32 0, i32* %7, align 4
  call void @llvm.objc.autoreleasePoolPop(i8* %8)
  %13 = load i32, i32* %4, align 4
  %14 = load i8**, i8*** %5, align 8
  %15 = load %0*, %0** %6, align 8
  %16 = call i32 @UIApplicationMain(i32 %13, i8** %14, %0* null, %0* %15)
  ret i32 %16
}

; Function Attrs: nounwind
declare i8* @llvm.objc.autoreleasePoolPush() #1

declare %0* @NSStringFromClass(i8*) #2

declare i8* @objc_opt_class(i8*)

; Function Attrs: nounwind
declare void @llvm.objc.autoreleasePoolPop(i8*) #1

declare i32 @UIApplicationMain(i32, i8**, %0*, %0*) #2

attributes #0 = { noinline optnone ssp uwtable &quot;frame-pointer&quot;=&quot;all&quot; &quot;min-legal-vector-width&quot;=&quot;0&quot; &quot;no-trapping-math&quot;=&quot;true&quot; &quot;stack-protector-buffer-size&quot;=&quot;8&quot; &quot;target-cpu&quot;=&quot;core2&quot; &quot;target-features&quot;=&quot;+cx16,+cx8,+fxsr,+mmx,+sahf,+sse,+sse2,+sse3,+ssse3,+x87&quot; &quot;tune-cpu&quot;=&quot;generic&quot; }
attributes #1 = { nounwind }
attributes #2 = { &quot;frame-pointer&quot;=&quot;all&quot; &quot;no-trapping-math&quot;=&quot;true&quot; &quot;stack-protector-buffer-size&quot;=&quot;8&quot; &quot;target-cpu&quot;=&quot;core2&quot; &quot;target-features&quot;=&quot;+cx16,+cx8,+fxsr,+mmx,+sahf,+sse,+sse2,+sse3,+ssse3,+x87&quot; &quot;tune-cpu&quot;=&quot;generic&quot; }

!llvm.module.flags = !{!0, !1, !2, !3, !4, !5, !6, !7, !8, !9, !10, !11}
!llvm.ident = !{!12}

!0 = !{i32 2, !&quot;SDK Version&quot;, [2 x i32] [i32 16, i32 2]}
!1 = !{i32 1, !&quot;Objective-C Version&quot;, i32 2}
!2 = !{i32 1, !&quot;Objective-C Image Info Version&quot;, i32 0}
!3 = !{i32 1, !&quot;Objective-C Image Info Section&quot;, !&quot;__DATA,__objc_imageinfo,regular,no_dead_strip&quot;}
!4 = !{i32 1, !&quot;Objective-C Garbage Collection&quot;, i8 0}
!5 = !{i32 1, !&quot;Objective-C Is Simulated&quot;, i32 32}
!6 = !{i32 1, !&quot;Objective-C Class Properties&quot;, i32 64}
!7 = !{i32 1, !&quot;Objective-C Enforce ClassRO Pointer Signing&quot;, i8 0}
!8 = !{i32 1, !&quot;wchar_size&quot;, i32 4}
!9 = !{i32 7, !&quot;PIC Level&quot;, i32 2}
!10 = !{i32 7, !&quot;uwtable&quot;, i32 1}
!11 = !{i32 7, !&quot;frame-pointer&quot;, i32 2}
!12 = !{!&quot;Apple clang version 13.1.6 (clang-1316.0.21.2.5)&quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从编译的产物来看，其中也包含了常见的内存分配、所用到的标识定义等内容，可以明显的发现生成的中间产物已经没有任何源代码语言的影子了。同时我们会发现针对于中间代码，寄存器（%+数字）的使用好像没有个数限制，为什么呢？因为中间代码只是将源代码进行了中间代码的描述转义，此时并没有相关的目标架构信息可供参考使用，所以针对于变量的引用也仅仅是中间层的标识。在后端编译的过程中会将中间的这些寄存器的引用再次进行指令的转换，最终会生成对应CPU架构指令集的汇编代码。&lt;/p&gt;

&lt;p&gt;还记得XCode中的BitCode开关选项吗？它决定了编译生成的中间产物IR是否需要保存，如果保存的话，会把当前的中间产物插入到可执行文件的数据段中，保留这些中间产物内容又有什么作用呢？我们知道在没有保留中间产物之前，为了确保所有cpu架构的机型能够正常安装打出的安装包，在打包的时候会把能够支持的所有cpu架构的集合进行合并打包，生成一个Fat Binary，确保安装包能够适配所有的机型，这样会有一个问题，比如ARM64架构的机器在安装的时候只需要ARM64的架构二进制文件即可，但是由于安装包里兼容了所有的cpu架构，其他的架构代码实际上根本没有用到，这也就间接的导致了安装包的体积变大。而苹果在应用分发的时候，是知道目标机器的cpu架构的，所以如果能够将中间的编译产物交给AppStore后台，由Appstore后台通过编译后端优化生成目标机器的二进制可执行文件，去除无用的兼容架构代码，进而缩减安装包的体积大小。这也即是BitCode的出现目的，为了解决编译架构冗余的问题，同时也为APP的瘦身提供参考。&lt;/p&gt;

&lt;p&gt;编译器在进行语义分析期间还有一个重要的过程叫做静态分析（Static Analysis），llvm官方文档是这样介绍静态分析的：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The term &quot;static analysis&quot; is conflated, but here we use it to mean a collection of algorithms and techniques used to analyze source code in order to automatically find bugs. The idea is similar in spirit to compiler warnings (which can be useful for finding coding errors) but to take that idea a step further and find bugs that are traditionally found using run-time debugging techniques such as testing.↳&lt;/p&gt;

&lt;p&gt;Static analysis bug-finding tools have evolved over the last several decades from basic syntactic checkers to those that find deep bugs by reasoning about the semantics of code. The goal of the Clang Static Analyzer is to provide a industrial-quality static analysis framework for analyzing C, C++, and Objective-C programs that is freely available, extensible, and has a high quality of implementation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;静态分析它能够帮助我们在编译期间自动查找错误，比起运行时的时候去找出错误要更早一步，可以用于分析 C、C++ 和 Objective-C 程序。编译器通过静态分析依据AST中节点与节点之间的关系，找出有问题的节点并抛出警告错误，达到修改提醒的目的。比如官方文档中介绍的内存泄露的静态分析的案例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-23-05tKR6hXSkWIxBhT5.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;除了官方的静态分析，我们常用的OCLint也是在编译器生成AST抽象语法树之后，对抽象语法树进行遍历分析，达到校验规范的目的，总结一下编译前端的所经历的流程：&lt;strong&gt;通过源码输入，对源码进行词法分析将源码进行内容切割生成原子token。通过语法分析对原子token的组合进行语法模板匹配，生成抽象语法树（AST）。通过语义分析，对抽象语法树进行遍历生成中间代码IR与符号表信息内容。&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;3.2、编译器后端&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;编译器后端主要做了两件重要的事情： 1、优化中间层代码LLVMIR（经历多次的Pass操作） 2、生成汇编代码，最终链接生成机器码&lt;/p&gt;

&lt;p&gt;编译器前端完成编译后，生成了相关的编译产物LLVMIR，LLVMIR会经过优化器进行优化，优化的过程会经历一个又一个的Pass操作，什么是Pass呢？引用官方的解释：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The LLVM Pass Framework is an important part of the LLVM system, because LLVM passes are where most of the interesting parts of the compiler exist. Passes perform the transformations and optimizations that make up the compiler, they build the analysis results that are used by these transformations, and they are, above all, a structuring technique for compiler code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们可以理解为一个个的中间过程的优化，比如指令选择、指令调度、寄存器的分配等，输入输出也都是IR，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-12-23-099ddX7119qxG8JVcG.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在最终优化完成之后，会生成一张DAG图给到后端。我们知道DAG是一张有向的非环图，这个特性可以用来标识硬件的特定顺序，方便后端的内容处理。我们也可以根据自己的需要通过继承Pass来写一些自定义的Pass用于自定义的优化，官方对于自定义的Pass也有相关的说明，感兴趣的同学可以去看看（链接放在本文最后了）。在经过优化之后，后端依据不同架构的编译器生成对应的汇编代码，最终通过链接完成机器码的整体生成。&lt;/p&gt;

&lt;h2&gt;四、编译器让计算机更懂人类&lt;/h2&gt;

&lt;p&gt;可以发现编译器是计算机高级语言的中梁砥柱，现在随着高级语言的发展越来越迅速，向着简单高效灵活的方向不断前进，这里面与编译器的发展有着密切的联系。同时随着编译器的发展升级，让高级语言到低级语言的转换变得更高效，同时也为诸多的跨平台语言实现提供了诸多可能。通过对计算机底层语言的层层抽象，诞生了我们所熟知的计算机高级语言，让我们能够用人类的思维逻辑进行指令输入，而抽象的层层翻译处理则交给了编译器，它的存在建立了人类与计算机沟通的重要桥梁。&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.aosabook.org/en/llvm.html&quot;&gt;The Architecture of Open Source Applications: LLVM (aosabook.org)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://llvm.org/docs/LangRef.html&quot;&gt;LLVM Language Reference Manual — LLVM 17.0.0git documentation&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b7f45fe8160714a4ee33d387d91e06c9</guid>
<title>流式数据处理 vs 实时 OLAP vs 流式数据库</title>
<link>https://toutiao.io/k/cgimwne</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-1g0fqss&quot; options=&quot;[object Object]&quot;&gt;&lt;p data-first-child=&quot;&quot; data-pid=&quot;kgDv5s_1&quot;&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//hubertdulay.substack.com/p/stream-processing-vs-real-time-olap&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;&lt;p data-pid=&quot;aiv8HfOr&quot;&gt;&lt;i&gt;作者：&lt;/i&gt;Hubert Dulay&lt;/p&gt;&lt;blockquote data-pid=&quot;A3ZQttK3&quot;&gt;&lt;i&gt;Hubert 是即将出版的新书 O’Reilly Streaming Data Mesh 的作者，曾在 Confluent, Decodable, Cloudera 等从事大数据、尤其是流式数据领域工作二十多年。最近他关于 Streaming Database 与 Real-time OLAP 的博客清楚解释了这两个领域的相关性，Timeplus 有幸成为第一个把实时和流处理融合一体的流数据库，能更好、更快、更简化解决用户实际问题！&lt;/i&gt;&lt;/blockquote&gt;&lt;hr/&gt;&lt;p data-pid=&quot;MODGiERV&quot;&gt;近期，人们对实时流式数据的关注越来越紧密，也自然而然地引发了很多问题，尤其是关于如何处理和分析实时数据的问题。如果你在搜索引擎上搜索这个问题，会发现这个领域有许多不同的产品和供应商，会非常困惑。&lt;/p&gt;&lt;p data-pid=&quot;rPDtbtHH&quot;&gt;那么我们应该如何选择合适的工具呢？如何判断这个工具适合自己的使用场景呢？&lt;/p&gt;&lt;p data-pid=&quot;a1KQqOtR&quot;&gt;这篇文章通过描述流式数据处理、实时 OLAP 数据库和流式数据库之间的区别，将会抛砖引玉地为你提供一些思路。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;典型的实时解决方案&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;kmptLZmA&quot;&gt;图 1 是一个典型的实时数据流 —— 它从数据源中捕获数据，对其进行转换，并使用实时 OLAP 数据库为其提供服务，最后通过实时可视化展现给用户。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-72d22cb3f1fa5c53fc1017903a04b57f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-72d22cb3f1fa5c53fc1017903a04b57f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-72d22cb3f1fa5c53fc1017903a04b57f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-72d22cb3f1fa5c53fc1017903a04b57f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;aZoQSO8K&quot;&gt;我们重点关注图 1 中左二和左三的图标：实时转换和实时 OLAP。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实时转换流处理&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;wnkuLk_s&quot;&gt;实时转换引擎是分布式的、有状态的流式数据处理系统，可以对实时数据执行复杂的转换。它可以处理任何规模化的高吞吐量数据。在这篇文章中，我们只关注支持标准 SQL 的流式处理系统。&lt;/p&gt;&lt;p data-pid=&quot;feNg6oba&quot;&gt;这里说的流式数据处理的角色是在数据到达实时 OLAP 数据库之前对流式数据进行的预处理。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实时 OLAP&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;M0WMl3n8&quot;&gt;实时 OLAP (RTOLAP) 是可以提供每秒高并发查询 (QPS) 的数据库。这里的 QPS 是对最终用户（实际用户或其他应用程序）体验是否良好的重要指标 —— QPS 越高，最终用户的体验就越好。&lt;/p&gt;&lt;p data-pid=&quot;YkuU0e89&quot;&gt;流式数据处理解决了 OLAP 数据库对流式数据进行预处理的需要，使这些 OLAP 系统的资源集中在更高的 QPS 上。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;流式数据库&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;B-14GOMw&quot;&gt;刚刚，我们了解了流式数据处理和实时 OLAP 系统。&lt;/p&gt;&lt;p data-pid=&quot;g2XONWfw&quot;&gt;流式数据库希望可以做到上面两点 —— 具有流式数据处理功能以及以高 QPS 提供实时数据分析的能力，比如图 2 所展示的流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9f876205bfadb688c648454a30d46da9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;398&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-9f876205bfadb688c648454a30d46da9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;398&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-9f876205bfadb688c648454a30d46da9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-9f876205bfadb688c648454a30d46da9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;oFrp26c8&quot;&gt;但是，流式数据库不能简单把 SQL 流式数据处理和实时 OLAP 相加在一起来创建。它们需要共享相同的 SQL 处理器引擎来转换数据和提供数据。它为面向用户的应用程序提供了一个统一的 SQL 接口，这些应用程序从具有高 QPS 的实时 OLAP 中提取数据，并为开发人员构建将数据推送到数据管道下游的转换能力。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Push 和 Pull 查询&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;JEr2151g&quot;&gt;转换数据和服务数据的查询在流式数据库中分别称为 Push 查询和 Pull 查询。&lt;/p&gt;&lt;p data-pid=&quot;und_ZfD7&quot;&gt;Push 查询将它们的结果向下游“推送”到某个运算符或存储中。这些查询有利于预处理实时数据，为最终用户的分析查询做好准备。这也是流处理器在图 1 中所实现的。&lt;/p&gt;&lt;p data-pid=&quot;-3evKwR-&quot;&gt;分析查询是 Pull 查询，因为最终用户从数据库中“拉取”预处理数据。这正是实时 OLAP 在图 1 中所实现的。&lt;/p&gt;&lt;p data-pid=&quot;Lr1zxO6V&quot;&gt;流式数据库能够实时完成这两项任务。如下面的图 3， Push 查询可以推送到表或 Kafka Topic，这样最终用户中应用程序可以订阅 Topic 来获得信息，实际用户可以从实时 OLAP 表中提取分析查询。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6bd953927d7cecc6d43bf88ca34501ec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-6bd953927d7cecc6d43bf88ca34501ec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-6bd953927d7cecc6d43bf88ca34501ec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6bd953927d7cecc6d43bf88ca34501ec_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;6V6y4Z2x&quot;&gt;在许多流式数据库中，Kafka Topic 就像另一种形式的表。使用流式数据库的开发者需要知道其中的区别。这使事情开始变得有些迷惑，因为每个流式数据库都有自己“固执己见”的定义方法。&lt;/p&gt;&lt;p data-pid=&quot;A-GU9n0W&quot;&gt;实际上，Kafka Topic 的表有时称为“流”、“添加流”或“仅添加流”。如果你要查询其中一个表，那将是一个无限的结果 —— 结果不会结束，因为流不会结束。&lt;/p&gt;&lt;p data-pid=&quot;I4UZxMPs&quot;&gt;用于执行分析拉取（Push &amp;amp; Pull）查询的表通常称为“物化视图”。这是因为聚合和预处理总是被推入“具体化”结果的表中。该结果由最终用户进行拉取（Push &amp;amp; Pull）查询。如果你要查询这些表中的一个，将得到有限的结果 —— 返回的结果最终会结束。&lt;/p&gt;&lt;p data-pid=&quot;N3nGSb7C&quot;&gt;文章说到这里，你应该可以理解流式数据库作为数据管道的一部分提供分析查询和处理数据流的过程。如果你对这个主题感兴趣，可以去找一些深入探究的书籍/博客，限于篇幅，我们在这里就不多展开说明了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;图表&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;l9AwrbaK&quot;&gt;这一部分将会对具体的项目进行说明。图 4 描绘了提供流式数据处理引擎、实时 OLAP 数据库，以及流式数据库的供应商和开源项目。&lt;/p&gt;&lt;p data-pid=&quot;eMgW_VPK&quot;&gt;x 轴衡量产品执行流式数据处理能力，包括：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;3-6zaAQp&quot;&gt;处理高吞吐量流式数据。&lt;/li&gt;&lt;li data-pid=&quot;OiWp9Q1G&quot;&gt;与 Kafka、Redpanda、Pulsar、Kinesis 等流式数据平台的配合使用。&lt;/li&gt;&lt;li data-pid=&quot;SkMZ0Vx7&quot;&gt;能处理集群节点或客户端的故障。&lt;/li&gt;&lt;li data-pid=&quot;A2xzk_s1&quot;&gt;使用 SQL 定义转换。&lt;/li&gt;&lt;li data-pid=&quot;XnnCdokT&quot;&gt;能保持复杂转换、连接和聚合的状态。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a71659243a641f711ee1226fda85f3e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;828&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-a71659243a641f711ee1226fda85f3e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;828&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-a71659243a641f711ee1226fda85f3e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a71659243a641f711ee1226fda85f3e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;N251rV2H&quot;&gt;y 轴衡量产品的 QPS 性能，这些通常是实时 OLAP 数据库。&lt;/p&gt;&lt;p data-pid=&quot;Kgc4tNBT&quot;&gt;在 x 轴的最右侧和 y 轴下方是只支持流式数据处理的产品，y 轴大而 x 轴靠左的产品是支持实时 OLAP 的数据库。篮框内或附近的产品更接近于流式数据库。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3abf61da1464645b164e88a11f562678_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1240&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-3abf61da1464645b164e88a11f562678_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1240&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-3abf61da1464645b164e88a11f562678_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3abf61da1464645b164e88a11f562678_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;fs3ncf-R&quot;&gt;一些附加信息：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;e8IzNEH-&quot;&gt;&lt;b&gt;Rockset&lt;/b&gt; - 具有转换功能的 RocksDB 数据库。&lt;/li&gt;&lt;li data-pid=&quot;8aFyjnuq&quot;&gt;&lt;b&gt;RisingWave&lt;/b&gt; - 类似于 ksqlDB 的流处理器，但使用 Hummock（一种 LSM - 基于 Rust 构建的基于树的存储引擎）。事实上，所有 RisingWave 都是使用 Rust 构建的。初步基准测试将其置于 ksqlDB 的 QPS 之上。&lt;/li&gt;&lt;li data-pid=&quot;hXR64gYw&quot;&gt;&lt;b&gt;Materialise&lt;/b&gt; - 在 Rust 中使用内存存储实现的流式数据库。SaaS 版本使用对象存储。&lt;/li&gt;&lt;li data-pid=&quot;FjWlZbLB&quot;&gt;&lt;b&gt;Timeplus&lt;/b&gt; - 一个支持流式数据和历史数据分析的融合数据库，用 C++ 编写。数据处理部分可以通过流式数据处理层完成，也可以把历史查询在底层的实时 OLAP 部分完成。 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.timeplus.com/post/unify-streaming-and-historical-data-processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;详见此处&lt;/a&gt;。&lt;/li&gt;&lt;li data-pid=&quot;JV1pBxS_&quot;&gt;&lt;b&gt;StarRocks&lt;/b&gt; - 开源实时 OLAP，也可以用作数据仓库，提供转换功能，供应商是 CelerData。&lt;/li&gt;&lt;li data-pid=&quot;776KNFsn&quot;&gt;&lt;b&gt;Tinybird&lt;/b&gt; - 使用 Clickhouse 作为其底层实时 OLAP，并将 REST 端点公开给实时数据，提供转换功能。Decodable、Delta Stream 和 Popsink 都使用 Apache Flink。Delta Stream 有能力用替代的流处理解决方案替换 Flink。&lt;/li&gt;&lt;li data-pid=&quot;2IFJui58&quot;&gt;&lt;b&gt;Apache Pinot&lt;/b&gt; - 开源实时 OLAP。在所有可用的实时 OLAP 数据库中提供最高的 QPS，供应商是 StarTree。&lt;/li&gt;&lt;li data-pid=&quot;zenWFKvn&quot;&gt;&lt;b&gt;Clickhouse&lt;/b&gt; - 开源实时 OLAP。&lt;/li&gt;&lt;li data-pid=&quot;8l6ukrKd&quot;&gt;&lt;b&gt;Apache Druid&lt;/b&gt; - 开源实时 OLAP，供应商是 Imply。&lt;/li&gt;&lt;li data-pid=&quot;U-bm8_UD&quot;&gt;&lt;b&gt;Striim 和 GCP Dataflow&lt;/b&gt; - 托管的云端流处理系统。&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;NAs4jjqr&quot;&gt;一个没有出现在表上但值得一提的产品是 Memgraph。它是一个流式图数据库，与本文中讨论的流式数据库略有不同。&lt;/p&gt;&lt;p data-pid=&quot;DjjjZrat&quot;&gt;*本文中用来构建图表的信息来自于供应商网站、开源网站、Github 项目文档以及相应技术社区中的问题等。&lt;/p&gt;&lt;hr/&gt;&lt;p data-pid=&quot;WA3jO9FY&quot;&gt;感谢阅读！如果觉得好不妨转发给身边的同事，这样可以帮助你们一起针对当下的用户案例，做出最佳的产品决策。免费注册使用 Timeplus &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.timeplus.com.cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;请戳这里&lt;/a&gt;。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1f6d19a7b93edda8677a53cf1202579a</guid>
<title>我与消息队列的八年情缘</title>
<link>https://toutiao.io/k/1cy3512</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content               autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;大家好呀，我是楼仔。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;周末读完了勇哥的这篇消息队列，让我对大佬有了新的认知，受益匪浅，非常感谢勇哥，下面是原文。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;谈起消息队列，内心还是会有些波澜。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;消息队列&lt;/strong&gt;，缓存，分库分表是高并发解决方案三剑客，而消息队列是我最喜欢，也是思考最多的技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我想按照下面的四个阶段分享我与消息队列的故事，同时也是对我技术成长经历的回顾。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;初识：ActiveMQ&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;进阶：Redis&amp;amp;RabbitMQ&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;升华：MetaQ&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;钟情：RocketMQ&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1 初识ActiveMQ&lt;/span&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.1 异步&amp;amp;解耦&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2011年初，我在一家互联网彩票公司做研发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我负责的是用户中心系统，提供用户注册，查询，修改等基础功能。用户注册成功之后，需要给用户发送短信。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为原来都是面向过程编程，我就把新增用户模块和发送短信模块都揉在一起了。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.21428571428571427&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDG0Zg3YbPMs20iciaepEB9ond95Ct9Hibo75VDEjNickT6b97bBpAW7PImA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;起初都还好，但问题慢慢的显现出来。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;短信渠道不够稳定，发送短信会达到5秒左右，这样用户注册接口耗时很大，影响前端用户体验;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;短信渠道接口发生变化，用户中心代码就必须修改了。但用户中心是核心系统。每次上线都必要谨小慎微。这种感觉很别扭，非核心功能影响到核心系统了。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个问题，我可以采取线程池的方法来做，主要是&lt;strong&gt;异步化&lt;/strong&gt;。但第二个问题却让我束手无措。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是我向技术经理请教，他告诉我引入消息队列去解决这个问题。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;将发送短信功能单独拆成独立的Job服务;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;用户中心用户注册成功后，发送一条消息到消息队列，Job服务收到消息调用短信服务发送短信即可。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14543726235741444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDKTTvCZNK3icqZ8WdXAQqasr5KUxZ198bYicTnqSHmy971HPA8ickhRkVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1052&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时，我才明白: 消息队列最核心的功能就是&lt;span&gt;&lt;strong&gt;异步&lt;/strong&gt;&lt;/span&gt;和&lt;span&gt;&lt;strong&gt;解耦&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.2 调度中心&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;彩票系统的业务是比较复杂的。在彩票订单的生命周期里，经过创建，拆分子订单，出票，算奖等诸多环节。每一个环节都需要不同的服务处理，每个系统都有自己独立的表，业务功能也相对独立。假如每个应用都去修改订单主表的信息，那就会相当混乱了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;公司的架构师设计了&lt;span&gt;&lt;strong&gt;调度中心&lt;/strong&gt;&lt;/span&gt;的服务，调度中心的职责是维护订单核心状态机，订单返奖流程，彩票核心数据生成。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.33055555555555555&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDyIC4mxSSaNq9oLicrsNBhBLC8AiaOSE2411kjD8Es9axeCKPK1ggncMw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;调度中心通过&lt;strong&gt;消息队列&lt;/strong&gt;和出票网关，算奖服务等系统传递和交换信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种设计在那个时候青涩的我的眼里，简直就是水滴vs人类舰队，降维打击。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着我对业务理解的不断深入，我隐约觉得：“好的架构是简洁的，也是应该易于维护的”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当彩票业务日均千万交易额的时候，调度中心的研发维护人员也只有两个人。调度中心的源码里业务逻辑，日志，代码规范都是极好的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我日后的程序人生里，我也会下意识模仿调度中心的编码方式，“不玩奇技淫巧，代码是给人阅读的”。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.3 重启大法&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着彩票业务的爆炸增长，每天的消息量从30万激增到150~200万左右，一切看起来似乎很平稳。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;某一天双色球投注截止，调度中心无法从消息队列中消费数据。消息总线处于只能发，不能收的状态下。整个技术团队都处于极度的焦虑状态，“要是出不了票，那可是几百万的损失呀，要是用户中了两个双色球？那可是千万呀”。大家急得像热锅上的蚂蚁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这也是整个技术团队第一次遇到消费堆积的情况，大家都没有经验。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先想到的是多部署几台调度中心服务，部署完成之后，调度中心消费了几千条消息后还是Hang住了。这时，架构师只能采用&lt;strong&gt;重启&lt;/strong&gt;的策略。你没有看错，就是重启大法。说起来真的很惭愧，但当时真的只能采用这种方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;调度中心重启后，消费了一两万后又Hang住了。只能又重启一次。来来回回持续20多次，像挤牙膏一样。而且随着出票截止时间的临近，这种思想上的紧张和恐惧感更加强烈。终于，通过1小时的手工不断重启，消息终于消费完了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我当时正好在读毕玄老师的《分布式java应用基础与实践》，猜想是不是线程阻塞了，于是我用Jstack命令查看堆栈情况。果然不出所料，线程都阻塞在提交数据的方法上。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDZ9rbDC8SWThL6WsZClJck6LyS7s71aHDE3Sficw0d70gb6sGVppGRVw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;350&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们马上和DBA沟通，发现oracle数据库执行了非常多的大事务，每次大的事务执行都需要30分钟以上，导致调度中心的调度出票线程阻塞了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;技术部后来采取了如下的方案规避堆积问题：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;生产者发送消息的时候，将超大的消息拆分成多批次的消息，减少调度中心执行大事务的几率;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据源配置参数，假如事务执行超过一定时长，自动抛异常，回滚。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.4 复盘&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Spring封装的ActiveMQ的API非常简洁易用，使用过程中真的非常舒服。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;受限于当时彩票技术团队的技术水平和视野，我们在使用ActiveMQ中遇到了一些问题。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;高吞吐下，堆积到一定消息量易Hang住；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;技术团队发现在吞吐量特别高的场景下，假如消息堆积越大，ActiveMQ有较小几率会Hang住的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;出票网关的消息量特别大，有的消息并不需要马上消费，但是为了规避消息队列Hang住的问题，出票网关消费数据的时候，先将消息先持久化到本地磁盘，生成本地XML文件，然后异步定时执行消息。通过这种方式，我们大幅度提升了出票网关的消费速度，基本杜绝了出票网关队列的堆积。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但这种方式感觉也挺怪的，消费消息的时候，还要本地再存储一份数据，消息存储在本地，假如磁盘坏了，也有丢消息的风险。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;高可用机制待完善&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们采用的master/slave部署模式，一主一从，服务器配置是4核8G 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种部署方式可以同时运行两个ActiveMQ， 只允许一个slave连接到Master上面，也就是说只能有2台MQ做集群，这两个服务之间有一个数据备份通道，利用这个通道Master向Slave单向地数据备份。这个方案在实际生产线上不方便， 因为当Master挂了之后， Slave并不能自动地接收Client发来的请来，需要手动干预，且要停止Slave再重启Master才能恢复负载集群。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一些很诡异丢消息的事件，生产者发送消息成功，但master控制台查询不到，但slave控制台竟然能查询到该消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但消费者没有办法消费slave上的消息，还得通过人工介入的方式去处理。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2 进阶Redis&amp;amp;RabbitMQ&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2014年，我在艺龙网从事红包系统和优惠券系统优化相关工作。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.1 Redis可以做消息队列吗&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;酒店优惠券计算服务使用的是初代流式计算框架&lt;strong&gt;Storm&lt;/strong&gt;。Storm这里就不详细介绍，可以参看下面的逻辑图：&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.49074074074074076&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDaL4naMMvhQAJQlNDcvfd5HStrex09Am95fKtOvtRcL8VjYbjTRP9lA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们的Storm集群的水源头（数据源）是redis集群，使用&lt;strong&gt;list&lt;/strong&gt;数据结构实现了消息队列的push/pop功能。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2222222222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDl3gDduLIlcpfUaFz0nrc7WtFPwzkMgCkkkCicjS4kGxicgAQibyQgfeYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;639&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;流式计算的整体流程：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;酒店信息服务发送酒店信息到Redis集群A/B;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Storm的spout组件从Redis集群A/B获取数据, 获取成功后，发送tuple消息给Bolt组件;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Bolt组件收到消息后，通过运营配置的规则对数据进行清洗;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;最后Storm把处理好的数据发送到Redis集群C;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;入库服务从Redis集群C获取数据,存储数据到数据库;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;搜索团队扫描数据库表，生成索引。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.30277777777777776&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDPaIvgtX5Vxfhvxq3VicIb9Fk5N21xfgQjodAyjCcqezvCicMfXqSlT9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;storm说明&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这套流式计算服务每天处理千万条数据，处理得还算顺利。但方案在团队内部还是有不同声音:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;storm的拓扑升级时候，或者优惠券服务重启的时候，偶尔出现丢消息的情况。但消息的丢失，对业务来讲没有那么敏感，而且我们也提供了手工刷新的功能，也在业务的容忍范围内;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;团队需要经常关注Redis的缓存使用量，担心Redis队列堆积, 导致out of memory;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;架构师认为搜索团队直接扫描数据库不够解耦，建议将Redis集群C替换成Kafka，搜索团队从kafka直接消费消息，生成索引;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我认为使用Redis做消息队列应该满足如下条件：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;容忍小概率消息丢失，通过定时任务/手工触发达到最终一致的业务场景;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消息堆积概率低，有相关的报警监控;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消费者的消费模型要足够简单。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.2 RabbitMQ是管子不是池子&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RabbitMQ是用&lt;strong&gt;erlang&lt;/strong&gt;语言编写的。RabbitMQ满足了我的两点需求：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;高可用机制。艺龙内部是使用的镜像高可用模式，而且这种模式在艺龙已经使用了较长时间了，稳定性也得到了一定的验证。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我负责的红包系统里，RabbitMQ每天的吞吐也在百万条消息左右，消息的发送和消费都还挺完美。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优惠券服务原使用&lt;strong&gt;SqlServer&lt;/strong&gt;，由于数据量太大，技术团队决定使用分库分表的策略，使用公司自主研发的分布式数据库DDA。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3627906976744186&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDvagWgaqJdKRucn8xkYJKJayUOroytcPG8jMibic7RHrDvhQzrx9IHcQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;645&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为是第一次使用分布式数据库，为了测试DDA的稳定性，我们模拟发送1000万条消息到RabbitMQ，然后优惠券重构服务消费消息后，按照用户编号hash到不同的mysql库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RabbitMQ集群模式是镜像高可用，3台服务器，每台配置是4核8G 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们以每小时300万条消息的速度发送消息，最开始1个小时生产者和消费者表现都很好，但由于消费者的速度跟不上生产者的速度，导致消息队列有积压情况产生。第三个小时，消息队列已堆积了500多万条消息了， 生产者发送消息的速度由最开始的2毫秒激增到500毫秒左右。RabbitMQ的控制台已血溅当场，标红报警。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是一次无意中的测试，从测试的情况来看，RabbitMQ很优秀，但&lt;span&gt;&lt;strong&gt;RabbitMQ对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有的朋友对我讲：“RabbitMQ明明是管子，你非得把他当池子？”&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着整个互联网数据量的激增, 很多业务场景下是允许适当堆积的，只要保证消费者可以平稳消费，整个业务没有大的波动即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我心里面越来越相信：消息队列既可以做&lt;strong&gt;管子&lt;/strong&gt;，也可以当做&lt;strong&gt;池子&lt;/strong&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.54&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpD5h9yg3v8yibv9OWY7FQa0goW4DWZlsQhuiaHCE0b8LB9De696Bbib5VtQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot;/&gt;&lt;/figure&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3 升华MetaQ&lt;/span&gt;&lt;/h1&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Metamorphosis的起源是我从对linkedin的开源MQ–现在转移到apache的kafka的学习开始的，这是一个设计很独特的MQ系统，它采用pull机制，而 不是一般MQ的push模型，它大量利用了zookeeper做服务发现和offset存储，它的设计理念我非常欣赏并赞同，强烈建议你阅读一下它的设计文档，总体上说metamorphosis的设计跟它是完全一致的。--- MetaQ的作者庄晓丹&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1 惊艳消费者模型&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2015年，我主要从事神州专车订单研发工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MetaQ满足了我对于消息队列的幻想：“&lt;span&gt;分布式，高吞吐，高堆积&lt;/span&gt;”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MetaQ支持两种消费模型：&lt;strong&gt;集群消费&lt;/strong&gt;和&lt;strong&gt;广播消费&lt;/strong&gt; ，因为以前使用过的消费者模型都是用队列模型，当我第一次接触到这种发布订阅模型的时候还是被惊艳到了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 集群消费&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3770833333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpD4dZpMzMAxoAVG3vINaCJReQC94hKoEzyvALhsjGl2tibzqD8dxwzPvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;480&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;订单创建成功后，发送一条消息给MetaQ。这条消息可以被派单服务消费，也可以被BI服务消费。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 广播消费&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;派单服务在讲订单指派给司机的时候，会给司机发送一个推送消息。推送就是用广播消费的模式实现的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2163588390501319&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpD0WzFGIr2kYs80oPV6QIW1kWl7OFbFsUDOJ9JP1QfrbFhjUIDj6rZzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;379&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大体流程是:&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;司机端推送服务是一个TCP服务，启动后，采用的是广播模式消费MetaQ的PushTopic;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;司机端会定时发送TCP请求到推送服务，鉴权成功后，推送服务会保存司机编号和channel的引用；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;派单服务发送推送消息到MetaQ；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;推送服务的每一台机器都会收到该消息，然后判断内存中是否存在该司机的channel引用，若存在，则推送消息。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是非常经典的广播消费的案例。我曾经研读京麦TCP网关的设计，它的推送也是采用类似的方式。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.2 激进的消峰&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2015年是打车大战硝烟弥漫的一年。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对神州专车来讲，随着订单量的不断增长，欣喜的同时，性能的压力与日俱增。早晚高峰期，用户打车的时候，经常点击下单经常无响应。在系统层面来看，专车api网关发现大规模超时，订单服务的性能急剧下降。数据库层面压力更大，高峰期一条记录插入竟然需要8秒的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个技术团队需要尽快提升专车系统的性能，此前已经按照模块领域做了数据库的拆分。但系统的瓶颈依然很明显。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们设计了现在看来有点激进的方案：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;设计订单缓存。缓存方案大家要有兴趣，我们可以以后再聊，里面有很多可以详聊的点;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在订单的载客生命周期里，订单的修改操作先修改缓存，然后发送消息到MetaQ，订单落盘服务消费消息，并判断订单信息是否正常（比如有无乱序)，若订单数据无误，则存储到数据库中。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.17962962962962964&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDBicRcSQLibZx0zk4WPatClfZsFj0drbhUQVFW2IibuCRu30vPPk0Cbib5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有两个细节：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;消费者消费的时候需要顺序消费，实现的方式是按照&lt;span&gt;订单号&lt;/span&gt;路由到不同的partition，同一个订单号的消息，每次都发到同一个partition;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.40021008403361347&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDIDaFbreWu7Vu2iclDXd4Re9j1L2MbVV8ZBTh5IlB0R9SS3uQmKpQ60Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;952&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;一个守护任务，定时轮询当前正在进行的订单，当缓存与数据不一致时候，修复数据，并发送报警。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这次优化大大提升订单服务的整体性能，也为后来订单服务库分库分表以及异构打下了坚实的基础，根据我们的统计数据，基本没有发生过缓存和数据库最后不一致的场景。但这种方案对缓存高可用有较高的要求，还是有点小激进吧。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3 消息SDK封装&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;做过基础架构的同学可能都有经验：“三方组件会封装一层”，神州架构团队也是将metaq-client封装了一层。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我的思维里面，封装一层可以减少研发人员使用第三方组件的心智投入，统一技术栈，也就如此了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直到发生一次意外，我的思维升级了。那是一天下午，整个专车服务崩溃较长时间。技术团队发现：&quot;专车使用zookeeper做服务发现。zk集群的leader机器挂掉了，一直在选主。&quot;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;临时解决后，我们发现MetaQ和服务发现都使用同一套zk集群，而且consumer的offset提交，以及负载均衡都会对zk集群进行大量的写操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了减少MetaQ对zk集群的影响，我们的目标是：“MetaQ使用独立的zk集群”。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;需要部署新的zk集群；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MetaQ的zk数据需要同步到新的集群；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;保证切换到新的集群，应用服务基本无感知。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我很好奇向架构部同学请教，他说新的集群已经部署好了，但需要同步zk数据到新的集群。他在客户端里添加了&lt;strong&gt;双写&lt;/strong&gt;的操作。也就是说：我们除了会写原有的zk集群一份数据，同时也会在新的zk集群写一份。过了几周后，MetaQ使用独立的zk集群这个任务已经完成了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5607476635514018&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDqibhKUpM9ZvnlWfZjoHwnIRxKTyyX8451XdiafKU4ejuKNnbuSnFux7w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;535&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这一次的经历带给我很大的感慨：“还可以这么玩？”&lt;/span&gt; ，也让我思考着：三方组件封装没有想像中那么简单。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看下&lt;strong&gt;快手&lt;/strong&gt;消息的SDK封装策略：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;对外只提供最基本的 API，所有访问必须经过SDK提供的接口。简洁的 API 就像冰山的一个角，除了对外的简单接口，下面所有的东西都可以升级更换，而不会破坏兼容性 ;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;业务开发起来也很简单，只要需要提供 Topic（全局唯一）和 Group 就可以生产和消费，不用提供环境、NameServer 地址等。SDK 内部会根据 Topic 解析出集群 NameServer 的地址，然后连接相应的集群。生产环境和测试环境环境会解析出不同的地址，从而实现了隔离；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;上图分为 3 层，第二层是通用的，第三层才对应具体的 MQ 实现，因此，理论上可以更换为其它消息中间件，而客户端程序不需要修改；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;SDK 内部集成了热变更机制，可以在不重启 Client 的情况下做动态配置，比如下发路由策略（更换集群 NameServer 的地址，或者连接到别的集群去），Client 的线程数、超时时间等。通过 Maven 强制更新机制，可以保证业务使用的 SDK 基本上是最新的。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7842931937172775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDWouQSorBV7oicNFedliaMZRPRIYgAyWc68XmDRjRXvdFzwxic7gvV77Ig/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.4 重构MetaQ , 自成体系&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我有一个习惯 : &quot;经常找运维，DBA，架构师了解当前系统是否有什么问题，以及他们解决问题的思路。这样，我就有另外一个视角来审视公司的系统运行情况&quot;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MetaQ也有他的缺点。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;MetaQ的基层通讯框架是gecko，MetaQ偶尔会出现rpc无响应，应用假死的情况，不太好定位问题；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MetaQ的运维能力薄弱，只有简单的Dashboard界面，无法实现自动化主题申请，消息追踪等功能。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有一天，我发现测试环境的一台消费者服务器启动后，不断报链接异常的问题，而且cpu占用很高。我用netstat命令马上查一下，发现已经创建了几百个链接。出于好奇心，我打开了源码，发现网络通讯框架gecko已经被替换成了netty。我们马上和架构部的同学联系。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我这才明白：他们已经开始重构MetaQ了。我从来没有想过重构一个开源软件，因为距离我太远了。或者那个时候，我觉得自己的能力还达不到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来，神州自研的消息队列自成体系了，已经在生产环境运行的挺好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;时至今天，我还是很欣赏神州架构团队。他们自研了消息队列，DataLink（数据异构中间件），分库分表中间件等。他们愿意去创新，有勇气去做一个更好的技术产品。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我从他们身上学到很多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也许在看到他们重构MetaQ的那一刻，我的心里埋下了种子。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5092592592592593&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpD2GZXdKD3iazy3IqZMv9GaOj5ag4acEa9y4dP6K0r7DCe8q6n8TtgBWw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4 钟情RocketMQ&lt;/span&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1 开源的盛宴&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2014年，我搜罗了很多的淘宝的消息队列的资料，我知道MetaQ的版本已经升级MetaQ 3.0，只是开源版本还没有放出来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大约秋天的样子，我加入了RocketMQ技术群。誓嘉(RocketMQ创始人)在群里说：“最近要开源了，放出来后，大家赶紧fork呀”。他的这句话发在群里之后，群里都炸开了锅。我更是欢喜雀跃，期待着能早日见到阿里自己内部的消息中间件。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3306930693069307&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDWGXUDEN4AaeiadzZ3lGk8kpFnyrbJlG9TNkPxnwVm3vDuxygvu592NQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;505&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;终于，RocketMQ终于开源了。我迫不及待想一窥他的风采。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为我想学网络编程，而RocketMQ的通讯模块remoting底层也是Netty写的。所以，RocketMQ的通讯层是我学习切入的点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我模仿RocketMQ的remoting写了一个玩具的rpc，这更大大提高我的自信心。正好，艺龙举办技术创新活动。我想想，要不尝试一下用Netty改写下Cobar的通讯模块。于是参考Cobar的源码花了两周写了个netty版的proxy，其实非常粗糙，很多功能不完善。后来，这次活动颁给我一个鼓励奖，现在想想都很好玩。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为在神州优车使用MetaQ的关系，我学习RocketMQ也比较得心应手。为了真正去理解源码，我时常会参考RocketMQ的源码，写一些轮子来验证我的学习效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然自己做了一些练习，但一直没有在业务环境使用过。2018年是我真正使用RocketMQ的一年，也是有所得的一年。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 短信服务&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;短信服务应用很广泛，比如用户注册登录验证码，营销短信，下单成功短信通知等等。最开始设计短信服务的时候，我想学习业界是怎么做的。于是把目标锁定在腾讯云的短信服务上。腾讯云的短信服务有如下特点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;统一的SDK，后端入口是http/https服务 ,  分配appId/appSecret鉴权；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;简洁的API设计：单发，群发，营销单发，营销群发，模板单发，模板群发。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是，我参考了这种设计思路。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;模仿腾讯云的SDK设计，提供简单易用的短信接口；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;设计短信服务API端，接收发短信请求，发送短信信息到消息队列；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;worker服务消费消息，按照负载均衡的算法，调用不同渠道商的短信接口；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Dashboard可以查看短信发送记录，配置渠道商信息。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2390011890606421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDzUmFQPQgukWrzkic1makPflyFZEamcW8KtXYzoWP1icCCnoZ95z8X95w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;841&quot;/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;短信服务是我真正意义第一次生产环境使用RocketMQ，当短信一条条发出来的时候，还是蛮有成就感的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ MQ控制台&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDgP5icdM0sCo8pibhX1NZnPAvFS9icZQN4cTy4cNOQjblkBLia0fpPzmwFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用过RocketMQ的朋友，肯定对上图的控制台很熟悉。当时团队有多个RocketMQ集群，每组集群都需要单独部署一套控制台。于是我想着：能不能稍微把控制台改造一番，能满足支持多组集群。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是，撸起袖子干了起来。大概花了20天的时间，我们基于开源的版本改造了能支持多组集群的版本。做完之后，虽然能满足我最初的想法，但是做的很粗糙。而且搜狐开源了他们自己的MQCloud ，我看了他们的设计之后， 觉得离一个消息治理平台还很远。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来我读了《网易云音乐的消息队列改造之路》，《今日头条在消息服务平台和容灾体系建设方面的实践与思考》这两篇文章，越是心痒难耐，蛮想去做的是一个真正意义上的消息治理平台。一直没有什么场景和机会，还是有点可惜。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近看了哈罗单车架构专家梁勇的一篇文章《哈啰在分布式消息治理和微服务治理中的实践》，推荐大家一读。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;https://mp.weixin.qq.com/s/N-vd6he4nsZp-G3Plc4m6A&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 一扇窗子，开始自研组件&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来，我尝试进一步深入使用RocketMQ。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;仿ONS风格封装消息SDK；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;运维侧平滑扩容消息队列；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;生产环境DefaultMQPullConsumer消费模式尝试&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些做完之后，我们又自研了注册中心、配置中心，任务调度系统。设计这些系统的时候，从RocketMQ源码里汲取了很多的营养，虽然现在看来有很多设计不完善的地方，代码质量也有待提高，但做完这些系统后，还是大大提升我的自信心。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RocketMQ给我打开了一扇窗子，让我能看到更广阔的Java世界。对我而言，这就是&lt;span&gt;开源的盛宴&lt;/span&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.2 Kafka: 大数据生态的不可或缺的部分&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka是一个拥有高吞吐、可持久化、可水平扩展，支持流式数据处理等多种特性的分布式消息流处理中间件，采用分布式消息发布与订阅机制，在日志收集、流式数据传输、在线/离线系统分析、实时监控等领域有广泛的应用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 日志同步&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在大型业务系统设计中，为了快速定位问题，全链路追踪日志，以及故障及时预警监控，通常需要将各系统应用的日志集中分析处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka设计初衷就是为了应对大量日志传输场景，应用通过可靠异步方式将日志消息同步到消息服务，再通过其他组件对日志做实时或离线分析，也可用于关键日志信息收集进行应用监控。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日志同步主要有三个关键部分：日志采集客户端，Kafka消息队列以及后端的日志处理应用。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;日志采集客户端，负责用户各类应用服务的日志数据采集，以消息方式将日志“批量”“异步”发送Kafka客户端。Kafka客户端批量提交和压缩消息，对应用服务的性能影响非常小。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Kafka将日志存储在消息文件中，提供持久化。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;日志处理应用，如Logstash，订阅并消费Kafka中的日志消息，最终供文件搜索服务检索日志，或者由Kafka将消息传递给Hadoop等其他大数据应用系统化存储与分析。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日志同步示意图：&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.16395222584147665&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDTr4fYkqfFmictBCgo6bDA0pia1GXQJeaKUeibbUtfhBayxOp3hWoK1dvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;921&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;▍&lt;strong&gt;流计算处理&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在很多领域，如股市走向分析、气象数据测控、网站用户行为分析，由于数据产生快、实时性强且量大，您很难统一采集这些数据并将其入库存储后再做处理，这便导致传统的数据处理架构不能满足需求。Kafka以及Storm、Samza、Spark等流计算引擎的出现，就是为了更好地解决这类数据在处理过程中遇到的问题，流计算模型能实现在数据流动的过程中对数据进行实时地捕捉和处理，并根据业务需求进行计算分析，最终把结果保存或者分发给需要的组件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 数据中转枢纽&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;近10多年来，诸如KV存储（HBase）、搜索（ElasticSearch）、流式处理（Storm、Spark、Samza）、时序数据库（OpenTSDB）等专用系统应运而生。这些系统是为单一的目标而产生的，因其简单性使得在商业硬件上构建分布式系统变得更加容易且性价比更高。通常，同一份数据集需要被注入到多个专用系统内。例如，当应用日志用于离线日志分析时，搜索单个日志记录同样不可或缺，而构建各自独立的工作流来采集每种类型的数据再导入到各自的专用系统显然不切实际，利用消息队列Kafka版作为数据中转枢纽，同份数据可以被导入到不同专用系统中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下图是美团 MySQL 数据实时同步到 Hive 的架构图，也是一个非常经典的案例。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1591355599214146&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/V71JNV78n2iciaAhY3aGXG4b2PNsPlnjpDDWXsewtDcYsC0VNyKVrG00KG12HQP09n2bTsLEibCBV2icC5hsHJBBog/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;509&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.3 如何技术选型&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2018年去哪儿QMQ开源了，2019年腾讯TubeMQ开源了，2020年Pulsar如火如荼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消息队列的生态是如此的繁荣，那我们如何选型呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我想我们不必局限于消息队列，可以再扩大一下。简单谈一谈我的看法。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Databases are specializing – the “one size fits all” approach no longer applies ----- MongoDB设计哲学&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一点：先有场景，然后再有适配这种场景的技术。什么样的场景选择什么样的技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二点：现实往往很复杂，当我们真正做技术选型，并需要落地的时候，&lt;strong&gt;技术储备&lt;/strong&gt;和&lt;strong&gt;成本&lt;/strong&gt;是两个我们需要重点考量的因素。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 技术储备&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;技术团队有无使用这门技术的经验，是否踩过生产环境的坑，以及针对这些坑有没有完备的解决方案；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;架构团队是否有成熟的SDK，工具链，甚至是技术产品。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;▍ 成本&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;研发，测试，运维投入人力成本；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务器资源成本；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;招聘成本等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后一点是&lt;strong&gt;人&lt;/strong&gt;的因素，特别是管理者的因素。每一次大的技术选型考验技术管理者的视野，格局，以及管理智慧。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5 写到最后&lt;/span&gt;&lt;/h1&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我觉得这个世界上没有什么毫无道理的横空出世，真的，如果没有大量的积累大量的思考是不会把事情做好的。。。总之，在经历了这部电影以后，我觉得我要学的太多了，这世界上有太多的能人，你以为的极限，弄不好，只是别人的起点。所以只有不停地进取，才能不丢人。那，人可以不上学，但一定要学习，真的。------ 韩寒《后会无期》演讲&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我学习消息队列的过程是不断思考，不断实践的过程，虽然&lt;span&gt;我以为的极限，弄不好，只是别人的起点&lt;/span&gt;，但至少现在，当我面对这门技术的时候，我的内心充满了好奇心，同时也是无所畏惧的。&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;Mzg3OTU5NzQ1Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLFTdSvrrpJnCZ0Fp5Z1wKkhKFQBxTaFfxOpib3E2zgUu39BFbsBqqJbEpxicUvz3H6csoL2JQ9EP1yQ/0?wx_fmt=png&quot; data-nickname=&quot;楼仔&quot; data-alias=&quot;&quot; data-signature=&quot;8 年一线大厂（百度小米美团）开发/架构/管理经验，专注硬核文章输出！&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5816dd026b78d4e937c716a20a85d204</guid>
<title>Siri ChatGPT 使用教程</title>
<link>https://toutiao.io/k/g5lb073</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;code_content__j1rBT code_open__faT8b bg-neutral-1&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;1&lt;/span&gt;&lt;span&gt;// @see https://docs.aircode.io/guide/functions/&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;2&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; aircode = &lt;/span&gt;&lt;span&gt;require&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;aircode&#x27;&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;3&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; { Configuration, OpenAIApi } = &lt;/span&gt;&lt;span&gt;require&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;openai&#x27;&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;4&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; { &lt;/span&gt;&lt;span&gt;v4&lt;/span&gt;&lt;span&gt;: uuidv4 } = &lt;/span&gt;&lt;span&gt;require&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;uuid&#x27;&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;6&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; { db } = aircode;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;7&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; ChatTable = db.table(&lt;/span&gt;&lt;span&gt;&#x27;chat&#x27;&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;8&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;9&lt;/span&gt;&lt;span/&gt;&lt;span&gt;// Setup OpenAI configurations&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;10&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; OPENAI_KEY = process.env.OPENAI_KEY || &lt;/span&gt;&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;11&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; OPENAI_MODEL = process.env.MODEL || &lt;/span&gt;&lt;span&gt;&quot;gpt-3.5-turbo&quot;&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;12&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; MAX_MESSAGES_PER_CHAT = &lt;/span&gt;&lt;span&gt;40&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;13&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;14&lt;/span&gt;&lt;span/&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; systemContent = &lt;/span&gt;&lt;span&gt;&#x27;You are a helpful assistant.&#x27;&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;15&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;16&lt;/span&gt;&lt;span/&gt;&lt;span&gt;module&lt;/span&gt;&lt;span&gt;.exports = &lt;/span&gt;&lt;span&gt;async&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span class=&quot;hljs-function&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;hljs-function&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;hljs-function hljs-params&quot;&gt;params, context&lt;/span&gt;&lt;span class=&quot;hljs-function&quot;&gt;) &lt;/span&gt;&lt;span&gt;{
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;17&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;.log(&lt;/span&gt;&lt;span&gt;&#x27;Received params:&#x27;&lt;/span&gt;&lt;span&gt;, params);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;18&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; { question, cid } = params;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;19&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;20&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;// Create a chat ID if not provided&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;21&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; chatId = cid ? cid : uuidv4();
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;22&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;23&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;// Save user&#x27;s question to the ChatTable&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;24&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; ChatTable.save({ chatId, &lt;/span&gt;&lt;span&gt;role&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;&#x27;user&#x27;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;content&lt;/span&gt;&lt;span&gt;: question });
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;25&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;26&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;// Retrieve chat history&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;27&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; chats = &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; ChatTable
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;28&lt;/span&gt;    .where({ chatId })
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;29&lt;/span&gt;&lt;span&gt;    .sort({ &lt;/span&gt;&lt;span&gt;createdAt&lt;/span&gt;&lt;span&gt;: -&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt; })
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;30&lt;/span&gt;    .limit(MAX_MESSAGES_PER_CHAT)
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;31&lt;/span&gt;    .find();
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;32&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;33&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;// Construct message array for GPT-3.5 Turbo&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;34&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; messages = [
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;35&lt;/span&gt;&lt;span&gt;    { &lt;/span&gt;&lt;span&gt;role&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;&#x27;system&#x27;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;content&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;&#x27;You are a helpful assistant.&#x27;&lt;/span&gt;&lt;span&gt; },
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;36&lt;/span&gt;&lt;span&gt;    ...chats.reverse().map(&lt;/span&gt;&lt;span class=&quot;hljs-function hljs-params&quot;&gt;one&lt;/span&gt;&lt;span class=&quot;hljs-function&quot;&gt; =&amp;gt;&lt;/span&gt;&lt;span&gt; ({ &lt;/span&gt;&lt;span&gt;role&lt;/span&gt;&lt;span&gt;: one.role, &lt;/span&gt;&lt;span&gt;content&lt;/span&gt;&lt;span&gt;: one.content })),
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;37&lt;/span&gt;  ];
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;38&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;39&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; openai = &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; OpenAIApi(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Configuration({ &lt;/span&gt;&lt;span&gt;apiKey&lt;/span&gt;&lt;span&gt;: OPENAI_KEY }));
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;40&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;41&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;42&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Request completion from GPT-3.5 Turbo&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;43&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; completion = &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; openai.createChatCompletion({
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;44&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;model&lt;/span&gt;&lt;span&gt;: OPENAI_MODEL,
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;45&lt;/span&gt;      messages,
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;46&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;temperature&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;47&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;n&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;48&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;stream&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;49&lt;/span&gt;    });
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;50&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;51&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; responseMessage = completion.data.choices[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;].message;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;52&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;53&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Save generated response to ChatTable&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;54&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; ChatTable.save({ chatId, ...responseMessage });
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;55&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;56&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Return response message and chat ID&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;57&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; { &lt;/span&gt;&lt;span&gt;reply&lt;/span&gt;&lt;span&gt;: responseMessage.content, &lt;/span&gt;&lt;span&gt;cid&lt;/span&gt;&lt;span&gt;: chatId };
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;58&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;59&lt;/span&gt;&lt;span&gt;  } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (error) {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;60&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Set the response status to 500 (Internal Server Error)&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;61&lt;/span&gt;&lt;span&gt;    context.status(&lt;/span&gt;&lt;span&gt;500&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;62&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Log the error&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;63&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;.log(&lt;/span&gt;&lt;span&gt;&#x27;error&#x27;&lt;/span&gt;&lt;span&gt;, error.response || error);
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;64&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;65&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Initialize an error message variable&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;66&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;let&lt;/span&gt;&lt;span&gt; errorMessage;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;67&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;68&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// If there is a response object in the error,&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;69&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// it means the request was made and the server responded with an error status&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;70&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (error.response) {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;71&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;const&lt;/span&gt;&lt;span&gt; { status, statusText, data } = error.response;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;72&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;73&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (status === &lt;/span&gt;&lt;span&gt;401&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;74&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;// If the status code is 401, set a specific error message related to the OpenAI API key&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;75&lt;/span&gt;&lt;span&gt;        errorMessage = &lt;/span&gt;&lt;span&gt;&#x27;Unauthorized: Invalid OpenAI API key, please check your API key in the AirCode Environments tab.&#x27;&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;76&lt;/span&gt;&lt;span&gt;      } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (data.error &amp;amp;&amp;amp; data.error.message) {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;77&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;// If there is an error message in the data, use it as the error message&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;78&lt;/span&gt;        errorMessage = data.error.message;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;79&lt;/span&gt;&lt;span&gt;      } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;80&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;// Otherwise, use the status code and status text as the error message&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;81&lt;/span&gt;&lt;span&gt;        errorMessage = &lt;/span&gt;&lt;span&gt;`Request failed with status code &lt;/span&gt;&lt;span&gt;${status}&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;${statusText}&lt;/span&gt;&lt;span&gt;`&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;82&lt;/span&gt;      }
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;83&lt;/span&gt;&lt;span&gt;    } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (error.request) {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;84&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;// If there is a request object in the error,&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;85&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;// it means the request was made but no response was received&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;86&lt;/span&gt;&lt;span&gt;      errorMessage = &lt;/span&gt;&lt;span&gt;&#x27;No response received from the server&#x27;&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;87&lt;/span&gt;&lt;span&gt;    } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (error.code === &lt;/span&gt;&lt;span&gt;&#x27;ENOTFOUND&#x27;&lt;/span&gt;&lt;span&gt; || error.code === &lt;/span&gt;&lt;span&gt;&#x27;ECONNREFUSED&#x27;&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;88&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;// If there is a network error, such as DNS resolution or connection refused&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;89&lt;/span&gt;&lt;span&gt;      errorMessage = &lt;/span&gt;&lt;span&gt;`Network error: &lt;/span&gt;&lt;span&gt;${error.message}&lt;/span&gt;&lt;span&gt;`&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;90&lt;/span&gt;&lt;span&gt;    } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;91&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;// If none of the above conditions are met,&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;92&lt;/span&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;// it means there was an error setting up the request&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;93&lt;/span&gt;&lt;span&gt;      errorMessage = &lt;/span&gt;&lt;span&gt;`Request setup error: &lt;/span&gt;&lt;span&gt;${error.message}&lt;/span&gt;&lt;span&gt;`&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;94&lt;/span&gt;    }
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;95&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;96&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// Return an object containing the error message&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;97&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; { &lt;/span&gt;&lt;span&gt;error&lt;/span&gt;&lt;span&gt;: errorMessage };
&lt;/span&gt;&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;98&lt;/span&gt;  }
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;99&lt;/span&gt;};
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;comment linenumber react-syntax-highlighter-line-number&quot;&gt;101&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>