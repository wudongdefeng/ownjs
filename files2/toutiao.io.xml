<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>78669479e21204250589955e342c23ae</guid>
<title>2023年的Rust与Go[译]</title>
<link>https://toutiao.io/k/goxltnz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文译自&lt;span&gt;《Rust vs Go in 2023》&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注：从2022年下半年开始，我们研发团队的产品研发不再局限于云端，车端也是将来的一个重要方向。于是我除了继续对Go语言保持常规的高度关注之外，也逐步开始留意Rust语言的发展。&lt;/p&gt;&lt;/blockquote&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go哪个更好？Go还是Rust？在2023年，你应该为你的下一个项目选择哪种语言，为什么？两者在性能、简单性、安全性、功能、规模和并发性等方面如何比较？它们的共同点是什么，它们有哪些根本性的不同？让我们在这个友好而公平的Rust和Go的比较中找到答案。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go都很棒&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，我必须要说的是，&lt;strong&gt;Go和Rust都是绝对优秀的编程语言&lt;/strong&gt;。它们都是现代的、强大的、被广泛采用的编程语言，并且都提供出色的性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可能读过一些说Go比Rust好的文章，或者相反。但这真的没有意义；每一种编程语言都代表了一系列的权衡和取舍。每种语言都有自己的优化重点，所以你对语言的选择应该由适合你的东西和你想用它解决的问题决定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这篇文章中，我将尝试告诉你何时使用Go是理想选择以及何时使用Rust更佳。我也会试着介绍一下这两种语言的本质（如果你愿意的话，就是&lt;span&gt;Go和Rust的道&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然它们在语法和风格上有很大不同，但Rust和Go都是构建软件的一流工具。接下来，让我们仔细看看这两种语言。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Go和Rust的相似之处&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go有很多共同点，这也是你经常听到它们一起被提及的原因之一。两种语言的共同目标是什么呢？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Rust是一种低级静态类型的多范式编程语言，专注于安全和性能。 - &lt;span&gt;Gints Dreimanis&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Go是一种开源的编程语言，可以轻松构建简单、可靠、高效的软件。 - &lt;span&gt;go.dev&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;内存安全&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go和Rust都属于现代编程语言，它们的首要任务是内存安全。经过几十年对C和C++等旧语言的使用，我们可以清楚地看到，导致错误和安全漏洞的最大原因之一是不安全地或不正确地访问内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go以不同的方式处理这个问题，但它们的目标都是在管理内存方面比其他语言更聪明、更安全，并帮助你写出&lt;span&gt;正确&lt;/span&gt;&lt;sup&gt;[5]&lt;/sup&gt;和&lt;span&gt;高性能&lt;/span&gt;&lt;sup&gt;[6]&lt;/sup&gt;的程序。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;快速、紧凑的可执行文件&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go和Rust都是编译型语言，这意味着你的程序被直接翻译成可执行的机器码，因此你可以以单一二进制文件形式来部署你的程序；与&lt;span&gt;Python&lt;/span&gt;&lt;sup&gt;[7]&lt;/sup&gt;和Ruby等解释型语言不同，你不需要将解释器和大量的库和依赖关系与你的程序一起分发，这是一个很大的优点。这也使得Rust和Go的程序与解释型语言相比都非常快。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;通用语言&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go都是强大的、可扩展的通用编程语言，你可以用它们来开发各种现代软件，从网络应用到分布式微服务，或者从嵌入式微控制器到移动应用程序。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;两者都有优秀的标准库、繁荣的第三方生态系统以及巨大的商业支持和庞大的用户基础。它们都已经存在了很多年，并将在未来几年内继续被广泛使用。今天学习Go或Rust将是对你时间和精力的合理投资。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;务实的编程风格&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go和Rust都不是&lt;span&gt;以函数式编程为主的语言&lt;/span&gt;&lt;sup&gt;[8]&lt;/sup&gt;（例如像Scala或Elixir），也不是完全面向对象的语言（像Java和C#）。相反，虽然Go和Rust都有与函数式和面向对象编程相关的特性，但它们是务实的语言，旨在以最合适的方式解决问题，而不是强迫你采用特定的做事方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你喜欢函数式编程风格，你会在Rust中发现更多对这种风格的支持，因为Rust在语法特性数量上要比Go更多。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我们可以讨论什么是“面向对象”语言，但可以说C++、Java或C#用户所期望的面向对象编程风格在Go或Rust中都不存在。 - Jack Mott&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;规模化的开发&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go都有一些有用的特性，使它们适合于大规模的编程，不管是指大型团队，还是大型代码库，或者两者兼具。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，C语言的程序员们多年来一直在争论将括号放在哪里，以及代码应该用制表符还是空格缩进，而Rust和Go通过使用标准的格式化工具（Go为gofmt，Rust为rustfmt）使用规范的风格自动重写你的代码，完全消除了这些问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这并不是说这种特殊的风格本身有多好：而是Rust和Go的程序员都喜欢这种&lt;strong&gt;标准化&lt;/strong&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;gofmt的风格是没有人喜欢的，但gofmt却是所有人的最爱。 - &lt;span&gt;Rob Pike&lt;/span&gt;&lt;sup&gt;[9]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;两种语言的另一个高分领域是**构建管道(pipeline)**。两种语言都有优秀的、内置的、高性能的标准构建和依赖管理工具；不再需要与复杂的第三方构建系统搏斗，也不再需要每隔几年就学习一个新的系统。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;对于早期职业生涯以Java和Ruby为背景的我而言，构建Go和Rust代码感觉就像从我的肩上卸下了一个不可能的重担。当我在谷歌工作时，遇到用Go编写的服务是一种解脱，因为我知道它很容易构建和运行。Rust也是如此，尽管我只在较小规模的Rust项目上工作过。我希望可无限配置的构建系统的时代已经过去了，所有语言都会有自己专门的构建工具，开箱即可使用。- &lt;span&gt;山姆-罗斯&lt;/span&gt;&lt;sup&gt;[10]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Rust还是Go？&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上可知，这两种语言都设计得很好、很强大，那么你可能会想知道那些关于两门语言的“圣战”究竟是怎么回事（我也是）。为什么人们对“Go vs.Rust”如此大惊小怪，在社交媒体上大打出手，并且写长篇博文说只有傻瓜才会使用Rust，或者Go不是真正的编程语言，或者其他什么。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这可能会让他们感觉好些，但这并不能完全帮助你，因为你正试图决定在你的项目中使用哪种语言，或者你应该学习哪种语言来推动你的编程生涯。一个明智的人不会根据谁喊得声最大来做出重要的选择。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在让我们继续我们成熟的讨论，看看在某些领域，一个有理智的人可能更喜欢哪一种语言。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Go与Rust的性能对比&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们已经说过，Go和Rust都能生产出高性能的程序，因为它们被编译成了本地机器代码，而不必通过解释器或虚拟机。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，Rust的性能尤其突出。它可以与C和C++相媲美，这两种语言通常被认为是性能最高的编译语言，但与这些老语言不同的是，Rust还提供了内存安全和并发安全，并且基本上不会给执行速度上带去没有任何开销。Rust还允许你创建复杂的抽象，而不需要在运行时付出任何性能上的代价。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相比之下，尽管Go程序的性能也非常好，但Go主要是为开发速度（包括编译）而设计的，而不是执行速度。Go程序员&lt;span&gt;更倾向于清晰的代码而不是快速的代码&lt;/span&gt;&lt;sup&gt;[11]&lt;/sup&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go编译器也不会花很多时间去尝试生成最有效的机器代码；它更关心的是快速编译大量代码。所以Rust通常会在运行时基准测试中击败Go。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust的运行时性能也是一致和可预测的，因为它不使用垃圾收集。Go的垃圾收集器非常高效，并且经过优化，使其“STW(停止世界)”的停顿时间尽可能短（每一个新的Go版本都会越来越短）。但是垃圾收集不可避免地在程序的行为方式中引入了一些不可预测的因素，这在某些应用中可能是一个严重的问题，例如嵌入式系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为Rust旨在让程序员完全控制底层硬件，所以有可能将Rust程序优化到相当接近机器的最大理论性能。这使得Rust在执行速度胜过所有其他考虑因素的领域是一个很好的选择，比如游戏编程、操作系统内核、网络浏览器组件和实时控制系统。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;简单性&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果没有人能够弄清楚如何使用一种编程语言，那么这种语言有多快也无所谓。Go语言是为了应对C++等语言不断增长的复杂性而特意设计的；它的语法非常少，关键字也非常少，事实上，功能特性也很少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这意味着&lt;span&gt;学习Go语言&lt;/span&gt;&lt;sup&gt;[12]&lt;/sup&gt;不需要很长时间，就可以用它来编写有用的程序。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Go是非常容易学习的。我知道这是一个经常被吹捧的好处，但我真的很惊讶于我能够如此迅速地提高工作效率。多亏了这个语言、文档和工具，我在两天后就写出了有趣的、可提交的代码。 - &lt;span&gt;一个Rust程序员对Go的早期印象&lt;/span&gt;&lt;sup&gt;[13]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的关键词是&lt;strong&gt;简单性&lt;/strong&gt;。当然，简单并不等同于容易，但是小而简单的语言比大而复杂的语言更容易学习。Go语言没有提供那么多不同的方法来做一件事情，所以所有写得好的Go代码往往看起来都一样。快速学习一个不熟悉的服务并理解它在做什么很容易。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;fmt.Println(&lt;span&gt;&quot;Gopher&#x27;s Diner Breakfast Menu&quot;&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; dish, price := range menu {&lt;br/&gt;    fmt.Println(dish, price)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我的&lt;span&gt;代码俱乐部视频系列&lt;/span&gt;&lt;sup&gt;[14]&lt;/sup&gt;中，我正是这样做的：从GitHub上半随机地挑选Go项目，并与一群Go初学者一起探索它们，看看我们能理解多少的代码。结果总是比我们预期的要多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然核心语言很小，但Go的标准库却非常强大。这意味着你的学习曲线也需要包括你需要的标准库的部分，而不仅仅是Go语法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一方面，将功能从语言中转移到标准库中，意味着你可以只专注于学习与你现在相关的库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go也是为大规模的软件开发而设计的，支持有大型代码库的大型团队。在这种情况下，新的开发人员能够尽快上手是非常重要的。出于这个原因，Go社区十分看重：&lt;span&gt;简单、明显、常规、直接的程序&lt;/span&gt;&lt;sup&gt;[15]&lt;/sup&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;使用Go，你可以快速完成工作。Go是我所使用过的生产力最高的语言之一。它的口号是：今天解决实际问题。 - &lt;span&gt;马蒂亚斯-恩德勒&lt;/span&gt;&lt;sup&gt;[16]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;特性&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Rust比其他几种编程语言支持更多的复杂语法特性，因此，你可以用它实现更多。 - &lt;span&gt;devathon&lt;/span&gt;&lt;sup&gt;[17]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust是专门设计用来帮助程序员用最少的代码做最多的事情，它包括很多强大而有用的功能特性。例如，Rust的match功能可以让你以十分简洁地方式写出灵活的、富有表现力的逻辑：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;fn is_prime(n: u64) -&amp;gt; bool {&lt;br/&gt;    match n {&lt;br/&gt;        0...1 =&amp;gt; &lt;span&gt;false&lt;/span&gt;,&lt;br/&gt;        _ =&amp;gt; !(2..n).any(|d| n % d == 0),&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为Rust做了很多事情，这意味着有很多东西需要学习，特别是在开始的时候。但这没关系：在C++或Java中也有很多东西要学，而且你不会得到Rust的高级特性，比如内存安全。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批评Rust是一种复杂的语言忽略了一点：它被设计成具有表现力，这意味着有很多功能，而在许多情况下，这正是你想要的编程语言。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，Rust有一个学习曲线，但一旦你开始使用它，你就会好起来。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;对于那些准备接受更复杂的语法和语义（以及可能更高的可读性成本）以换取最大可能的性能的程序员来说，Rust将与C++和D语言争夺思想份额。 - &lt;span&gt;戴夫-切尼&lt;/span&gt;&lt;sup&gt;[18]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然Rust采用了Go的一些特性，而Go也在采用Rust的一些特性（尤其是&lt;span&gt;泛型&lt;/span&gt;&lt;sup&gt;[19]&lt;/sup&gt;），但可以说Rust的特性很重，而Go的特性相对较轻。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;并发&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大多数语言都对并发编程（同时做多件事情）有某种形式的支持，但Go从一开始就是为这项工作而设计的。Go不使用操作系统的线程，而是提供了一个轻量级的替代方案：&lt;strong&gt;goroutine&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个goroutine是一个独立执行的Go函数，Go调度器会将其映射到其控制下的一个操作系统线程中。这意味着调度器可以非常有效地管理大量并发的goroutine，只使用有限的操作系统线程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，你可以在一个程序中运行数百万个并发的goroutine，而不会产生严重的性能问题。这使得Go成为高规模并发应用程序的完美选择，如网络服务器和微服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go还具有快速、安全、高效的功能特性，可以使用channel让goroutines进行通信和共享数据。Go的并发支持感觉设计得很好，使用起来也很愉快。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说，对并发程序进行推断是很难的，而且在任何语言中建立可靠、正确的并发程序都是一个挑战。但由于它从一开始就内置于语言中，而不是事后才想到的，Go中的并发编程是最简单、最完整的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Go语言可以很容易地建立一个很好的多因素的应用程序，充分利用并发性，同时作为一组微服务进行部署。Rust也可以做这些事情，但可以说它更难。 在某些方面，Rust对防止与内存有关的安全漏洞的痴迷意味着程序员必须不遗余力地执行那些在其他语言（包括Go）中会更简单的任务。 - &lt;span&gt;Sonya Koptyev&lt;/span&gt;&lt;sup&gt;[20]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相比之下，Rust中的并发故事是非常新的，而且还在稳定中，但它正处于非常积极的开发中，所以请关注这个领域。例如，Rust的&lt;span&gt;rayon库&lt;/span&gt;&lt;sup&gt;[21]&lt;/sup&gt;提供了一种非常优雅和轻量级的方式来将顺序计算转化为并行计算。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;拥有goroutines和使用channel的轻量级语法真的很好。这真的显示了语法的力量，这些小细节使并发编程比其他语言感觉好得多 - &lt;span&gt;一个Rust程序员对Go的早期印象&lt;/span&gt;&lt;sup&gt;[22]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然在Rust中实现并发程序可能不那么简单，但还是有可能的，而且这些程序可以利用Rust的安全保证。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个很好的例子是标准库的Mutex类：在Go中，你可以忘记在访问某些东西之前获得一个Mutex锁，但Rust不会让你这样做。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Go专注于将并发性作为一个一等公民的概念。这并不是说你不能在Rust中找到Go的面向actor的并发性，但这是留给程序员的一个练习。 - &lt;span&gt;Dave Cheney&lt;/span&gt;&lt;sup&gt;[23]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;安全&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在前面看到，Go和Rust都以不同的方式来防止一大类与内存管理有关的常见编程错误。但是Rust尤其努力确保你不会做一些你不想做的不安全的事情。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Rust的编译器非常严格和学究派，它检查你使用的每个变量和你引用的每个内存地址。它避免了可能的数据竞争条件，并告知你未定义的行为。并发和内存安全问题在Rust的安全子集中根本不可能发生。 - &lt;span&gt;为什么是Rust？&lt;/span&gt;&lt;sup&gt;[24]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这将使Rust编程成为与几乎所有其他语言不同的体验，而且一开始可能是一种挑战。但对很多人来说，这种辛苦是值得的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;对我来说，Rust的关键优势是一种感觉，即编译器是我的后盾，不会让它可能检测到的任何错误通过（说真的，有时感觉就像魔法一样）。 - Grzegorz Nosek&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;包括Go在内的许多语言都有帮助程序员避免错误的设施，但Rust将这一点提高到了一个新的水平，因此可能不正确的程序甚至不会被编译。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;有了Rust，库程序员有很多工具来防止他/她的用户犯错。Rust让我们有能力说，我们拥有一块特定的数据；其他东西不可能声称拥有，所以我们知道没有其他东西能够修改它。我想不出以前有什么时候我被赋予过这么多工具来防止意外的误用。这是一种奇妙的感觉。 - &lt;span&gt;山姆-罗斯&lt;/span&gt;&lt;sup&gt;[25]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“与借用检查器(borrow checker)斗争”是Rust程序员新手的常见综合症，但在大多数情况下，它所发现的问题是你的代码中真正的bug（或至少是潜在的bug）。它可能会迫使你从根本上重构你的程序，以避免遇到这些问题；而当正确性和可靠性是你的首要任务时，这是件好事。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个不改变你编程方式的语言有什么意义呢？当你用其他语言工作时，Rust所教授的关于安全的课程也是有用的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果你选择了Rust，通常你需要该语言提供的保证：针对空指针和数据竞争的安全，可预测的运行时行为，以及对硬件的完全控制。如果你不需要这些功能，Rust可能是你下一个项目的糟糕选择。这是因为这些保证是有代价的：入门时间。你需要戒掉坏习惯，学习新概念。有可能的是，当你开始的时候，你会经常和借用检查器斗争。 - &lt;span&gt;Matthias Endler&lt;/span&gt;&lt;sup&gt;[26]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你觉得Rust的编程模型有多大的挑战性，可能取决于你以前有哪些其他语言的经验。Python或Ruby程序员可能会发现它的限制性；其他人会很高兴。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果你是一个花了几周的时间来追寻内存安全漏洞的C/C++程序员，你会非常欣赏Rust。&quot;与借用检查器斗争&quot;变成了&quot;编译器可以检测到这个？酷！&quot; -Grzegorz Nosek&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;规模化&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;今天的服务器程序由数千万行代码组成，由数百甚至数千名程序员进行构建，而且每天都在更新。Go的设计和开发是为了使在这种环境中工作更有成效。Go的设计考虑包括严格的依赖性管理，随着系统的发展，软件架构的适应性，以及组件之间的健壮性。 - &lt;span&gt;Rob Pike&lt;/span&gt;&lt;sup&gt;[27]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你一个人或在小团队中处理问题时，选择简单的语言还是功能丰富的语言是一个偏好的问题。但是当软件越来越大，越来越复杂，团队越来越大时，差异就开始显现出来了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于大型应用程序和分布式系统来说，执行速度不如开发速度重要：像Go这样刻意简化的语言可以减少新开发人员的启动时间，并使他们更容易处理大型代码库的工作。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;有了Go，作为初级开发者更容易提高工作效率，而作为中级开发者则更难引入会导致后续问题的脆弱抽象。由于这些原因，Rust在企业软件开发方面不如Go有说服力。 - &lt;span&gt;Loris Cro&lt;/span&gt;&lt;sup&gt;[28]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当涉及到大型的软件开发时，清晰的比聪明的好。Go的局限性实际上使它比Rust等更复杂和强大的语言更适合企业和大机构。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Rust和Go的不同点&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然Rust和Go都是流行的、现代的、广泛使用的语言，但它们并不是真正的竞争对手，因为它们故意针对的是完全不同的使用情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Go的整个编程方法&lt;/span&gt;&lt;sup&gt;[29]&lt;/sup&gt;与Rust的完全不同，每一种语言都适合一些人，同时也会刺激另一些人。这完全没问题，如果Rust和Go都能以或多或少相同的方式做同样的事情，我们就不会真的需要两种不同的语言。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么，我们是否可以通过发现Rust和Go所采取的截然不同的方法来了解它们各自的本性呢？让我们拭目以待。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;垃圾回收&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“要不要垃圾回收”是一个没有正确答案的问题。垃圾回收，以及一般的自动内存管理，使得开发可靠、高效的程序变得快速和容易，对于一些人来说，这至关重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但也有人说，垃圾回收及其性能开销和停顿，使程序在运行时表现得不可预测，并引入了不可接受的延迟。争论还在继续。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Go是一种与Rust非常不同的语言。虽然两者都可以被模糊地描述为系统语言或C语言的替代品，但它们有不同的目标和应用、语言设计的风格以及优先级。垃圾回收是一个真正巨大的区别。Go中的GC使语言更简单，更小，更容易推理。在Rust中没有GC会让它变得非常快（尤其是当你需要保证延迟，而不仅仅是高吞吐量的时候），并且可以实现Go中不可能实现的功能和编程模式（或者至少是在不牺牲性能的情况下）。 - &lt;span&gt;PingCAP&lt;/span&gt;&lt;sup&gt;[30]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;接近机器&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;计算机编程的历史是一个越来越复杂的抽象的故事，它让程序员在解决问题时不用太担心底层机器的实际运作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这使得程序更容易编写，也许更容易移植。但是对于许多程序来说，对硬件的访问以及对程序执行方式的精确控制更为重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Rust的目标是让程序员“更接近机器”，有更多的控制权，但Go抽象了架构细节，让程序员更接近问题。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;两种语言都有不同的适用范围。Go在编写微服务和典型的&quot;DevOps&quot;任务方面表现出色，但它不是一种系统编程语言。Rust对于那些看重并发性、安全性和性能的任务中更强；但它的学习曲线比Go更陡峭。 - &lt;span&gt;Matthias Endler&lt;/span&gt;&lt;sup&gt;[31]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;必须运行更快&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;许多人同意，对于大多数程序来说，&lt;span&gt;性能不如可读性重要&lt;/span&gt;&lt;sup&gt;[32]&lt;/sup&gt;。但当性能确实重要时，它真的很重要。Rust做了一些设计上的权衡，以达到尽可能好的执行速度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相比之下，Go更关注简单性，它愿意为此牺牲一些（运行时）性能。但是Go的构建速度是无可匹敌的，这对于大型代码库来说是非常重要的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Rust比Go快。在基准测试中，Rust更快，在某些情况下，甚至是数量级的快。但在你选择用Rust写所有东西之前，考虑一下Go在许多基准测试中并不落后于它，而且它仍然比Java、C#、JavaScript、Python等快得多。如果你需要的是顶级的性能，那么选择这两种语言中的任何一种，你都会在游戏中领先。如果你正在构建一个处理高负载的网络服务，你希望能够在纵向和横向上进行扩展，那么这两种语言都会非常适合你。- &lt;span&gt;安德鲁-拉德&lt;/span&gt;&lt;sup&gt;[33]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;正确性&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一方面，如果一个程序不需要正常工作的话，它可以任意地快。大多数代码不是为长期而写的，但有些程序能在生产中运行多长时间往往是令人惊讶的：在某些情况下，可以保持几十年。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这种情况下，值得在开发中多花一点时间，以确保程序的正确性、可靠性，并在未来不需要大量的维护。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go和Rust都旨在帮助你编写正确的程序，但方式不同。例如，Go提供了一个极好的内置测试框架，而Rust则专注于使用其借用检查器消除运行时的错误。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;我认为。Go适用于明天必须交付的代码，而Rust适用于必须在未来五年内保持运行不动的代码。 - Grzegorz Nosek&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然Go和Rust对于任何严肃的项目来说都是很好的选择，但是让自己尽可能地了解每种语言及其特点是一个好主意。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;归根结底，别人怎么想并不重要：只有你能决定哪种语言适合你和你的团队。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果你想加快开发速度，也许是因为你有许多不同的服务需要编写，或者你有一个庞大的开发团队，那么Go是你的首选语言。Go把并发性作为第一等公民给你，并且不容忍不安全的内存访问（Rust也是如此），但不强迫你管理每一个细节。Go是快速和强大的，但它避免了使开发者陷入困境，而是专注于简单性和统一性。如果在另一方面，拧出每一盎司的性能是必要的，那么Rust应该是你的选择。 - &lt;span&gt;安德鲁-拉德&lt;/span&gt;&lt;sup&gt;[34]&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;结论&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我希望这篇文章能让你相信Rust和Go都值得你认真考虑。如果可能的话，你应该争取在这两种语言中至少获得一定程度的经验，因为它们对你的任何技术职业都会有极大的帮助，甚至如果你仅把编程作为一种业余爱好的话。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你只有时间投资学习一门语言，在你将Go和Rust用于各种不同类型的大小程序之前，不要做出最终决定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而编程语言的知识实际上只是成为一名成功的软件工程师的一小部分。到目前为止，你需要的最重要的技能是设计、工程、架构、沟通和协作。如果你在这些方面表现出色，无论你选择哪种语言，你都会成为一名优秀的软件工程师。学习愉快!&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;“Gopher部落”知识星球&lt;/span&gt;&lt;sup&gt;[35]&lt;/sup&gt;旨在打造一个精品Go学习和进阶社群！高品质首发Go技术文章，“三天”首发阅读权，每年两期Go语言发展现状分析，每天提前1小时阅读到新鲜的Gopher日报，网课、技术专栏、图书内容前瞻，六小时内必答保证等满足你关于Go语言生态的所有需求！2023年，Gopher部落将进一步聚焦于如何编写雅、地道、可读、可测试的Go代码，关注代码质量并深入理解Go核心技术，并继续加强与星友的互动。欢迎大家加入！&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.247167868177137&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cH6WzfQ94mYbN4SR0aJeoKt82pr7ibmCk1icF8xqVslY1JfrDvW4fJKB5RIWtClXGPn5Y0qsJvSibnQd6Bb9EtYWg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;971&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6484620213433773&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cH6WzfQ94mYKSeNd014VMtNhYulia0OHrHVoyrVYb2JvBa5ycFaeDfscQdubicnZkxB6je42bo3J4cZcx0FticLmQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1593&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48884976525821594&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cH6WzfQ94mb54jsFJZ3Knmz8obUsf3PBShthmdSw5E01TcYmUReGkj0BWpxHak1HlnlzHvLmKax53YSGr7aNlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1704&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4444444444444444&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/cH6WzfQ94mb54jsFJZ3Knmz8obUsf3PBDKyzaL44T9g1YiaYeujWa3QRrVC21SnO9h9qc2ia6ibyicc6LUdnD0ibymw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Gopher Daily(Gopher每日新闻)归档仓库 - https://github.com/bigwhite/gopherdaily&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我的联系方式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;微博(暂不可用)：https://weibo.com/bigwhite20xx&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;微博2：https://weibo.com/u/6484441286&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;博客：tonybai.com&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;github: https://github.com/bigwhite&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3436123348017621&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cH6WzfQ94maBibN71XTUmP14icYzhnEiaCpte6aEn35YSBjQqI3HVFHuua8guicBd9iaol1AQEHNEU9jEg2LePCmXHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1816&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;商务合作方式：撰稿、出书、培训、在线课程、合伙创业、咨询、广告合作。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1] &lt;/span&gt;&lt;p&gt;《Rust vs Go in 2023》: &lt;em&gt;https://bitfieldconsulting.com/golang/rust-vs-go&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2] &lt;/span&gt;&lt;p&gt;Go和Rust的道: &lt;em&gt;https://tonybai.com/2022/09/25/the-tao-of-go&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3] &lt;/span&gt;&lt;p&gt;Gints Dreimanis: &lt;em&gt;https://serokell.io/blog/rust-guide&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4] &lt;/span&gt;&lt;p&gt;go.dev: &lt;em&gt;https://go.dev&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[5] &lt;/span&gt;&lt;p&gt;正确: &lt;em&gt;https://bitfieldconsulting.com/golang/crisp-code&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[6] &lt;/span&gt;&lt;p&gt;高性能: &lt;em&gt;https://bitfieldconsulting.com/golang/slower&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[7] &lt;/span&gt;&lt;p&gt;Python: &lt;em&gt;https://bitfieldconsulting.com/golang/go-vs-python&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[8] &lt;/span&gt;&lt;p&gt;以函数式编程为主的语言: &lt;em&gt;https://bitfieldconsulting.com/golang/functional&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[9] &lt;/span&gt;&lt;p&gt;Rob Pike: &lt;em&gt;https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;amp;t=8m43s&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[10] &lt;/span&gt;&lt;p&gt;山姆-罗斯: &lt;em&gt;https://samwho.dev/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[11] &lt;/span&gt;&lt;p&gt;更倾向于清晰的代码而不是快速的代码: &lt;em&gt;https://bitfieldconsulting.com/golang/slower&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[12] &lt;/span&gt;&lt;p&gt;学习Go语言: &lt;em&gt;http://gk.link/a/10AVZ&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[13] &lt;/span&gt;&lt;p&gt;一个Rust程序员对Go的早期印象: &lt;em&gt;https://medium.com/better-programming/early-impressions-of-go-from-a-rust-programmer-f4fd1074c410&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[14] &lt;/span&gt;&lt;p&gt;代码俱乐部视频系列: &lt;em&gt;https://bitfieldconsulting.com/code-club&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[15] &lt;/span&gt;&lt;p&gt;简单、明显、常规、直接的程序: &lt;em&gt;https://bitfieldconsulting.com/golang/commandments&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[16] &lt;/span&gt;&lt;p&gt;马蒂亚斯-恩德勒: &lt;em&gt;https://endler.dev/2017/go-vs-rust/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[17] &lt;/span&gt;&lt;p&gt;devathon: &lt;em&gt;https://devathon.com/blog/rust-vs-go-which-programming-language-to-choose/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[18] &lt;/span&gt;&lt;p&gt;戴夫-切尼: &lt;em&gt;https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[19] &lt;/span&gt;&lt;p&gt;泛型: &lt;em&gt;https://bitfieldconsulting.com/golang/generics&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[20] &lt;/span&gt;&lt;p&gt;Sonya Koptyev: &lt;em&gt;https://sdtimes.com/softwaredev/the-developers-dilemma-choosing-between-go-and-rust/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[21] &lt;/span&gt;&lt;p&gt;rayon库: &lt;em&gt;https://github.com/rayon-rs/rayon&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[22] &lt;/span&gt;&lt;p&gt;一个Rust程序员对Go的早期印象: &lt;em&gt;https://medium.com/better-programming/early-impressions-of-go-from-a-rust-programmer-f4fd1074c410&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[23] &lt;/span&gt;&lt;p&gt;Dave Cheney: &lt;em&gt;https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[24] &lt;/span&gt;&lt;p&gt;为什么是Rust？: &lt;em&gt;https://bitbucket.org/blog/why-rust&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[25] &lt;/span&gt;&lt;p&gt;山姆-罗斯: &lt;em&gt;https://samwho.dev/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[26] &lt;/span&gt;&lt;p&gt;Matthias Endler: &lt;em&gt;https://endler.dev/2017/go-vs-rust/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[27] &lt;/span&gt;&lt;p&gt;Rob Pike: &lt;em&gt;https://talks.golang.org/2012/splash.article&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[28] &lt;/span&gt;&lt;p&gt;Loris Cro: &lt;em&gt;https://kristoff.it/blog/why-go-and-not-rust&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[29] &lt;/span&gt;&lt;p&gt;Go的整个编程方法: &lt;em&gt;https://tonybai.com/2022/09/25/the-tao-of-go&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[30] &lt;/span&gt;&lt;p&gt;PingCAP: &lt;em&gt;https://medium.com/better-programming/early-impressions-of-go-from-a-rust-programmer-f4fd1074c410&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[31] &lt;/span&gt;&lt;p&gt;Matthias Endler: &lt;em&gt;https://endler.dev/2017/go-vs-rust/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[32] &lt;/span&gt;&lt;p&gt;性能不如可读性重要: &lt;em&gt;https://bitfieldconsulting.com/golang/slower&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[33] &lt;/span&gt;&lt;p&gt;安德鲁-拉德: &lt;em&gt;https://codeburst.io/should-i-rust-or-should-i-go-59a298e00ea9&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[34] &lt;/span&gt;&lt;p&gt;安德鲁-拉德: &lt;em&gt;https://codeburst.io/should-i-rust-or-should-i-go-59a298e00ea9&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[35] &lt;/span&gt;&lt;p&gt;“Gopher部落”知识星球: &lt;em&gt;https://wx.zsxq.com/dweb2/index/group/51284458844544&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>136a4a57d202fedcb32d20ce19a83dc4</guid>
<title>精华推荐 |【算法数据结构专题】「延时队列算法」史上非常详细分析和介绍如何通过时间轮（TimingWheel）实现延时队列的原理指南_洛神灬殇的博客-CSDN博客</title>
<link>https://toutiao.io/k/djkj0p4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;content_views&quot; class=&quot;markdown_views prism-atom-one-dark&quot;&gt;
                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
                        &lt;path stroke-linecap=&quot;round&quot; d=&quot;M5,0 0,2.5 5,5z&quot; id=&quot;raphael-marker-block&quot;/&gt;
                    &lt;/svg&gt;
                    &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/b8743f70b89045499e88e3fb539464bb.jpeg#pic_center&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;p/&gt;
&lt;div class=&quot;toc&quot;&gt;
 &lt;h3&gt;精华推荐 |【算法数据结构专题】「延时队列算法」史上非常详细分析和介绍如何通过时间轮（TimingWheel）实现延时队列的原理指南&lt;/h3&gt;
 
&lt;/div&gt;
&lt;p/&gt; 
&lt;hr/&gt; 
&lt;h2&gt;&lt;a id=&quot;_9&quot;/&gt;时间轮的介绍&lt;/h2&gt; 
&lt;p&gt;时间轮（TimeWheel）是一种实现延迟功能（定时器）的精妙的高级算法，其算法应用范围非常广泛，在Java开发过程中常用的Dubbo、Netty、Akka、Quartz、ZooKeeper 、Kafka等各种框架中，各种操作系统的定时任务crontab调度都有用到，甚至Linux内核中都有用到，不夸张的是几乎所有和时间任务调度都采用了时间轮的思想。&lt;/p&gt; 
&lt;h2&gt;&lt;a id=&quot;_13&quot;/&gt;时间轮的作用&lt;/h2&gt; 
&lt;h3&gt;&lt;a id=&quot;_15&quot;/&gt;高效处理批量任务&lt;/h3&gt; 
&lt;p&gt;时间轮可以高效的利用线程资源来进行批量化调度，把大批量的调度任务全部都绑定时间轮上，通过时间轮进行所有任务的管理，触发以及运行。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_19&quot;/&gt;降低时间复杂度&lt;/h3&gt; 
&lt;p&gt;时间轮算法可以将插入和删除操作的时间复杂度都降为O(1)，在大规模问题下还能够达到非常好的运行效果。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_23&quot;/&gt;高效管理延时队列&lt;/h3&gt; 
&lt;p&gt;能够高效地管理各种延时任务，周期任务，通知任务等，相比于JDK自带的Timer、DelayQueue + ScheduledThreadPool来说，时间轮算法是一种非常高效的调度模型。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_27&quot;/&gt;缺点：时间精确度的问题&lt;/h3&gt; 
&lt;p&gt;时间轮调度器的时间的精度可能不是很高，对于精度要求特别高的调度任务可能不太适合。因为时间轮算法的精度取决于时间段“指针”单元的最小粒度大小，比如时间轮的格子是一秒跳一次，那么调度精度小于一秒的任务就无法被时间轮所调度。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;精度问题我们可以考虑后面提出的优化方案：多级时间轮。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;a id=&quot;_33&quot;/&gt;时间轮的使用场景&lt;/h2&gt; 
&lt;ul&gt;&lt;li&gt;调度模型，时间轮是为解决高效调度任务而产生的调度模型。例如，周期任务。&lt;/li&gt;&lt;li&gt;数据结构，通常由hash table和链表实现的数据结构。&lt;/li&gt;&lt;li&gt;延时任务、周期性任务应用场景主要在延迟大规模的延时任务、周期性的定时任务等。&lt;/li&gt;&lt;li&gt;通知任务等等。&lt;/li&gt;&lt;/ul&gt; 
&lt;h2&gt;&lt;a id=&quot;_40&quot;/&gt;时间轮的实现方案&lt;/h2&gt; 
&lt;p&gt;为了充分发挥时间轮算法的效果和优势，我们要从基础上去分析和优化时间轮算法对比定时任务、任务队列模式的运作基底。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;_44&quot;/&gt;减少线程分配&lt;/h3&gt; 
&lt;p&gt;时间轮是一种高效来利用线程资源来进行批量化调度的一种调度模型，把大批量的调度任务全部都绑定到同一个的调度器上面，使用这一个调度器（线程）来进行所有任务的管理（manager），触发（trigger）以及运行（runnable）。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;CPU_48&quot;/&gt;CPU的负载和资源浪费减少&lt;/h3&gt; 
&lt;p&gt;承接上面减少线程分配，最后可以使得当我们需要进行大量的调度任务或者延时任务，可以大大减少线程的分配，如果按照任务调度模式，每个任务都使用自己的调度器来管理任务的生命周期的话，可能会进行分配很多线程，从而会消耗CPU的资源并且很低效。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;注意：问题就是如果这个调度器的调度线程出现了问题，会导致整体全局崩溃。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;a id=&quot;_54&quot;/&gt;延时任务或定时任务实现原理&lt;/h2&gt; 
&lt;p&gt;如何实现定时任务 / 延时任务，定时的任务调度分两种：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;延时任务：一段时间后执行，即：相对时间。&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;定时任务：指定某个确定的时间执行，即：绝对时间。&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;对于延时任务和定时任务两者之间是可以相互转换的，例如当前时间是12点，定时在5分钟之后执行，其实绝对时间就是：12:05，定时在12:05执行，相对时间就是5分钟之后执行&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;a id=&quot;_63&quot;/&gt;时间轮功能设计&lt;/h2&gt; 
&lt;p&gt;时间轮实现定时/延时任务队列，最终需要向上层提供如下接口：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;添加定时/延时任务&lt;/li&gt;&lt;li&gt;删除定时/延时任务&lt;/li&gt;&lt;li&gt;执行定时/延时任务&lt;/li&gt;&lt;/ul&gt; 
&lt;h2&gt;&lt;a id=&quot;_71&quot;/&gt;时间轮的数据结构&lt;/h2&gt; 
 
&lt;h3&gt;&lt;a id=&quot;_77&quot;/&gt;单时间轮基本逻辑模型&lt;/h3&gt; 
&lt;p&gt;时间轮算法是：不再任务队列作为数据结构，轮询线程不再负责遍历所有任务，而是仅仅遍历时间刻度。时间轮算法好比指针不断在时钟上旋转、遍历，如果一个发现某一时刻上有任务（任务队列），那么就会将任务队列上的所有任务都执行一遍。&lt;/p&gt; 
&lt;p&gt;时间轮由多个时间格组成，每个时间格代表当前时间轮的基本时间跨度（tickDuration），时间轮的时间格个数是固定的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/a001e62397958ace28203d9dcb26abde.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;如上图中相邻bucket到期时间的间隔为bucket=1s，从0s开始计时，1s时到期的定时任务挂在bucket=1下，2s时到期的定时任务挂在bucket=2下，当检查到时间过去了1s时，bucket=1下所有节点执行超时动作，当时间到了2s时，bucket=2下所有节点执行超时动作等等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/5718c0867207982f7da9e232e514570a.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;如上图的时间轮通过数组实现，可以很方便地通过下标定位到定时任务链路，因此，添加、删除、执行定时任务的时间复杂度为O(1)。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_91&quot;/&gt;时间轮数据结构模型&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;pointer : 指针，随着时间的推移，指针不停地向前移动。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;bucket : 时间轮由bucket组成，如上图，有12个bucket。每个bucket都挂载了未来要到期的节点（即: 定时任务/延时任务）。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;slot : 指相邻两个bucket的时间间隔。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;tickDuration：slot的单位，1s（1HZ），如上图，总共12个bucket，那么两个相邻的bucket的时间间隔就是一秒。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;时间轮使用一个表盘指针（pointer），用来表示时间轮当前指针跳动的次数，可以用tickDuration * (pointer + 1)来表示下一次到期的任务，需要处理此时间格所对应的 TimeWheel中的所有任务&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;a id=&quot;_103&quot;/&gt;时间轮处理逻辑&lt;/h4&gt; 
&lt;h5&gt;&lt;a id=&quot;_105&quot;/&gt;计算延时时间存储&lt;/h5&gt; 
&lt;p&gt;时间轮在启动的时候会记录一下当前启动的时间赋值给startTime。时间轮在添加任务的时候首先会计算延迟时间（delayTime），比如一个任务的延迟时间为24ms，那么会将当前的时间（currentTime）+24ms-时间轮启动时的时间（startTime）。然后将任务封装成TimeWheelElement加入到bucket队列中。&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;TimeWheelElement的总共延迟的次数：将每个任务的延迟时间（delayTime）/ tickDuration计算出pointer需要总共跳动的次数以及计算出该任务需要放置到时间轮（wheel）的槽位，然后加入到槽位链表最后将任务放置到时间轮wheel中。&lt;/li&gt;&lt;/ul&gt; 
&lt;h5&gt;&lt;a id=&quot;_111&quot;/&gt;读取延时数据任务队列&lt;/h5&gt; 
&lt;p&gt;时间轮在运行的时候会将bucket队列中存放的TimeWheelElement任务取出来进行遍历，从而进行执行对应的任务体系机制。计算出当前时针走到的槽位的位置，并取出槽位中的链表数据，防止万一，还可以再delayTime和当前的时间做对比，运行过期的数据。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_115&quot;/&gt;单时间轮的问题和弊端&lt;/h4&gt; 
 
&lt;h5&gt;&lt;a id=&quot;_121&quot;/&gt;内存和资源的消耗巨大&lt;/h5&gt; 
&lt;p&gt;但这种单时间轮是存在限制的，只能设置定时任务到期时间在12s内的，这显然是无法满足实际的业务需求的。当然也可以通过扩充bucket的范围来实现。例如，将bucket设置成 2^32个，但是这样会带来巨大的内存消耗，显然需要优化改进。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;_125&quot;/&gt;轮询线程仍然还会慢慢的出现遍历效率低问题&lt;/h5&gt; 
&lt;p&gt;当时间刻度增多，而任务数较少时，轮询线程的遍历效率会下降，例如，如果只有 50 个时间刻度上有任务，但却需要遍历 1440 个时间刻度。这违背了我们提出时间轮算法的初衷：解决遍历轮询线程遍历效率低的问题。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;_129&quot;/&gt;浪费内存空间问题&lt;/h5&gt; 
&lt;p&gt;在时间刻度密集，任务数少的情况下，大部分时间刻度所占用的内存空间是没有任何意义的。如果要将时间精度设为秒，那么整个时间轮将需要 86400 个单位的时间刻度，此时时间轮算法的遍历线程将遇到更大的运行效率低的问题。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;&lt;a id=&quot;_135&quot;/&gt;轮数时间轮基本逻辑模型&lt;/h3&gt; 
&lt;p&gt;时间轮的时间刻度随着时间精度而增加并不是一个好的问题解决思路，所以计划将时间轮的精度设置为秒，时间刻度个数固定为60。每一个任务拥有一个round 字段，基于单时间轮原理之下，我们在每个bucket块下不单单存储到期时间expire时间的任务，还会存储一个新字段round（expire%N=bucket的定时器(N为bucket个数)）。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_139&quot;/&gt;主要由一下两个字段组成&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt;expire：代表到期时间&lt;/li&gt;&lt;li&gt;round：表示时间轮要在转动几圈之后才执行任务&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;bucket_144&quot;/&gt;执行bucket下的延时逻辑&lt;/h4&gt; 
&lt;p&gt;当指针转到某个bucket时，不能像简单的单时间轮那样直接执行bucket下所有的定时器，而是要去遍历该bucket下的链表，判断判断时间轮转动的次数是否等于节点中的round值，只有当expire和round都相同的情况下，才能执行该任务。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/db7009f15e2c8907e79808bf3e12e131.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;轮询线程的执行逻辑是每隔一秒处理一个时间刻度上任务队列中的所有任务，任务的 round字段减 1，接着判断如果 round 字段的值变为 0，那么将任务移出任务队列，交给异步线程池来执行对应任务。如果是重复执行任务，那么再将任务添加到任务队列中。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/48b7130be2306a9636a110b5df34973d.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_154&quot;/&gt;轮数计算的公式&lt;/h4&gt; 
&lt;p&gt;轮询线程遍历一次时间轮需要60 秒，如果一个任务需要间隔x秒执行一次，那么其 round 字段的值为 x/60（整除），任务位于第 (x%60)（取余）个刻度对应的任务队列中。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;例如，任务需要间隔 130 秒执行一次，那么 round 字段的值为 2，此任务位于第 10 号时间刻度的任务队列中。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;时间轮round次数：根据计算的需要走的（总次数- 当前tick数量）/ 时间格个数（wheel.length）。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;bucket_162&quot;/&gt;提取计算对应的bucket下的任务数据&lt;/h4&gt; 
&lt;p&gt;比如，tickDuration为1ms，时间格个数为20个，那么时间轮走一圈需要20ms，那么添加进一个延时为24ms的数据，如果当前的tick为0，那么计算出的轮数为1，指针没运行一圈就会将round取出来-1，所以需要转动到第二轮之后才可以将轮数round减为0之后才会运行。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_166&quot;/&gt;轮数时间轮的问题和缺点&lt;/h4&gt; 
&lt;p&gt;改进版单时间轮是时间和空间折中的方案，不像单时间轮那样有O(1)的时间复杂度，也不会像单时间轮那样，为了满足需求产生大量的bucket。但是这种方式虽然简化了时间轮的刻度个数，但是并没有简化运行效率不高的问题。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;_170&quot;/&gt;运行效率不高的问题&lt;/h5&gt; 
&lt;p&gt;改进版的时间轮如果某个bucket上挂载的定时器特别多，那么需要花费大量的时间去遍历这些节点，如果bucket下的链表每个节点的round都不相同，那么一次遍历下来可能只有极少数的定时器需要立刻执行的，因此很难在时间和空间上都达到理想效果。&lt;/p&gt; 
&lt;p&gt;时间轮每次处理一个时间刻度，就需要处理其上任务队列的所有任务。其运行效率甚至与基于普通任务队列实现的定时任务框架没有区别。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;&lt;a id=&quot;_178&quot;/&gt;层级时间轮基本逻辑模型&lt;/h3&gt; 
&lt;p&gt;为了解决单时轮和轮数时间轮引起的性能问题和资源问题的另一种方式是在层次结构中使用多个定时轮，由多个层级来进行多次hash进行任务数据的传递，从而减少对应的时间和空间的复杂程度。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;_182&quot;/&gt;多级时间轮&lt;/h4&gt; 
&lt;p&gt;【年、月、日、小时、分钟、秒】级别的6个时间轮，每个时间轮分别有（10-年暂时定为10年）、12（月）、24（时）、60（分钟）、60（秒）个刻度。子轮转动一圈，父轮转动一格，从父向子前进，无子过期。分层时间轮如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/2a0e9a744441daf2d43d9d90a0dbb2dd.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;_188&quot;/&gt;案例流程执行体系&lt;/h5&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;任务需要在当天的17:30:20执行&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt;&lt;li&gt;任务添加于秒级别时钟轮的第20号Bucket上，当其轮询线程访问到第20号Bucket时，就将此任务转移到分钟级别时钟轮的第30号Bucket上。&lt;/li&gt;&lt;li&gt;当分钟级别的时钟轮线程访问到第30号Bucket，就将此任务转移到小时级别时钟轮的第 7号Bucket上。&lt;/li&gt;&lt;li&gt;当小时级别时钟轮线程访问到第7号bucket时。&lt;/li&gt;&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;最终会将任务交给异步线程负责执行，然后将任务再次注册到秒级别的时间轮中&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;&lt;a id=&quot;_198&quot;/&gt;分层时钟轮算法设计具有如下的优点&lt;/h5&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;轮询线程效率变高：首先不再需要计算round值，其次任务队列中的任务一旦被遍历，就是需要被处理的（没有空轮询问题）。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;线程并发性好：虽然引入了并发线程，但是线程数仅仅和时钟轮的级数有关，并不随着任务数的增多而改变。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;如果任务按照分钟级别来定时执行，那么当分钟时间轮达到对应刻度时，就会将任务交给异步线程来处理，然后将任务再次注册到秒级别的时钟轮上。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;分层时间轮中的任务从一个时间轮转移到另一个时间轮，实现层级轮算法可以借鉴了生活中水表的度量方法，通过低刻度走得快的轮子带动高一级刻度轮子走动的方法，达到了仅使用较少刻度即可表示很大范围度量值的效果。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                &lt;/div&gt;
                
                
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e7e841f097f8ac78a44a797580747cae</guid>
<title>ChatGPT的前世今生：OpenAI的技术「执拗」与「豪赌」</title>
<link>https://toutiao.io/k/cc4vkod</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             defaultNoSetting&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; data-style=&quot;white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; data-style=&quot;margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：追一科技&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;blockquote data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;100&quot; data-source-title=&quot;&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;本文全方位地介绍了 ChatGPT 的能力特征、发展历程以及 OpenAI 一路走来所坚守的技术路线，并对 ChatGPT 出现之后 NLP 领域的范式转换进行了展望，即 ChatGPT 开启「文本生成 + 指令」的范式。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、ChatGPT，不再「愚蠢」的人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT 的相关话题应该算是继 AlphaGo 以来，最出圈的人工智能热点了。简单来说，它是一个可以用自然语言对话的机器人，你可以问它任何问题（当然它有可能会答错，但你可以引导并纠正它），它都会以非常流畅、标准的自然语言回答你。不仅如此，它还能回答代码问题、数学问题等等，你可以和它在关于任何问题上聊得不亦乐乎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以用一个经典的鸡兔同笼问题来感性地认识一下 ChatGPT 的能力：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.0148698884758365&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydvobX77V0EbfHkaVKpoic0JsZ4xhTXUA7J9VhbuGlCTFodtKLM7XUjHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;807&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这个回答可以观察到几个特点。首先是对自然语言的理解和转换为数学问题的能力，其次它通过将一个较为复杂的推理问题分步拆解，一步步获得最后的答案。这个能力被业内称作「思维链」（Chain of thought）。接下来换一下问法，看看它会怎么回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.3358778625954197&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydzaJb659gFNfxX3Jb7OQRagHV6SvxGBUuYvNWOsSenwgrQwIsCH7XRw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;655&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这个图中可以发现，ChatGPT 对自己所说的内容是有感知的，并且可以给出这么说的原因。&lt;/span&gt;&lt;span&gt;另外也可以发现，它确实也会出错（第一次计算耳朵数量错了。&lt;/span&gt;&lt;span&gt;此处有个冷知识，鸡是有类似于「耳朵」一样的功能器官），但可以通过引导的方式让它给出正确的答案，并且会告诉你自己为什么错了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果不事先告诉你这是一个人工智能模型，ChatGPT 给人的感觉确实像一个真正有逻辑思维和语言交流能力的真人。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;它的出现第一次让大家觉得，人工智能似乎终于能够和人正常交流了，虽然有时候会出错，但在交流的过程中至少没有语言和逻辑上的障碍，它能「懂」你在说什么，并且按照人类的思维模式和语言规范给你&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;反馈&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。这种非常智能的体验感，是它突破业界小圈子，给大众带来冲击感的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里还希望再次强调这种体验感的问题，因为也许过去业界由于技术的限制，为了完成场景中的特定任务而忽略了这一点。如今 ChatGPT 的出现代表了人工智能不再是过去那种「有用，但是也挺蠢」的形态了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好地理解 ChatGPT 这种非常智能的感觉是怎么产生的，难免要从过去那种「很蠢」的人工智能说起。准确地说，ChatGPT 背后使用的依然是自然语言处理（NLP）技术，但却打破了原有的范式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要理解这一点，可以先看看目前的主流做法是怎样的。人类交流依托的是语言，甚至也有很多人认为人类的思维也是建立在语言上的。因此，理解运用自然语言一直是人工智能的重要课题。但语言实在太复杂，因此为了让计算机理解运用语言，通常会将这个过程拆分为很多的细分项，这就是在技术领域中常说的「任务」。举几个例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的任务还有很多，都是从某个细分的侧面去对自然语言进行分析、处理。这样做有很多好处，比如有了这些拆分，就可以从不同的维度来考察一个自然语言处理系统的细分能力；也可以针对某一个细分的项专门做系统或者模型的设计等。从技术的角度来说，将一个复杂的任务（理解并运用自然语言）拆分为很多的简单任务（各种各样的 NLP 任务）确实是一种比较典型的解决复杂问题的路径，这也是目前的主流做法。然而在 ChatGPT 出现之后，以马后炮视角去看，也许在让计算机理解并运用自然语言这条路上，这种拆分并不是最有效的途径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为在单个任务上的优秀表现，并不能代表系统就掌握了自然语言。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;人对于人工智能体的「智能感」，是基于对它应用自然语言的整体能力而产生的，这一点在 ChatGPT 上有明显的体现&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。虽然 OpenAI 没有开放 ChatGPT 的 API 服务，外界还无法测评它在各个细分 NLP 任务上的具体效果，但以过往外界对它的前身 GPT-3、InstructGPT 等模型的测试情况表明，对于某些特定的任务，一个用专门数据精调过的小模型，确实可以获得更好的效果（详细分析请参考《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864784&amp;amp;idx=3&amp;amp;sn=fb8ad092ad32623af7ea822652cd14cc&amp;amp;chksm=84e538eeb392b1f8ff40fa10dc2c84b56904fed261ff15f97f36a1023f887807af62ea39bde7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;深入理解语言模型的突现能力&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;深入理解语言模型的突现能力&lt;/a&gt;》）。但这些在单个任务上有更好表现的小模型，并没有引起很大的出圈效应。归根结底，是因为它们只有单一的能力。单个的能力出众并不能代表它们具有了理解和运用自然语言的能力，从而也无法独自在实际应用场景中发挥作用。正因如此，通常在一个真实的应用场景中，都是多个具有单点能力的模块经过人为的设计拼凑而成，这种人为的拼凑方式是过去的人工智能系统让人感觉并不智能的原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从人类理解和运用自然语言的视角去看，这个现象其实很好理解。普通人在理解、运用自然语言的时候，并不会在脑内将它拆分为很多步不同的任务，逐个任务进行分析，然后再汇总，这不是人类使用自然语言的方式。就好比一个人，在听到一句话的时候，并不会对它的句法结构、实体内容与关系、情感倾向等这些内容逐一分析，然后拼凑出这句话的含义，人对语言的理解过程是一个整体过程。再进一步，人对这句话的整体理解，会以自然语言的形式，通过回复的方式整体地表现出来。这个过程并不是像人工智能系统那样，拆分单个任务，然后逐一输出情感分析的标签、实体信息的片段、或是别的某个单个任务的结果，然后用这些东西拼凑出回复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而&lt;/span&gt;&lt;span&gt;&lt;strong&gt;以 ChatGPT 为代表，GPT 系列模型所做的事情才真正接近了人类理解和运用语言的能力 —— 直接接收自然语言，然后直接回复自然语言，并保证了语言的流畅性与逻辑性&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。这是人与人的交流方式，所以大家对它抱以「很智能」的体验感。也许很多人会认为，如果能做到 ChatGPT 这样当然很好，过去那种对任务的拆分是因为技术的限制不得已而为之。从技术应用的视角来看，这样迂回的方式当然是需要的，这种方法也在很长的一段时间内被采用，并且确实也能够解决很多实际场景中的问题。但如果回顾 GPT 系列模型的发展过程，就会发现 OpenAI「赌」了另一条路，并且他们「赌」赢了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、OpenAI 的「赌局」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPT 初代，一切开始的地方&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早在 2018 年，OpenAI 就发布了最初版本的 GPT 模型，从 OpenAI 公开的论文（Improving Language Understanding by Generative Pre-Training）可以了解到，这个模型采用了 12 层的 Transformer Decoder 结构，用了大约 5GB 的无监督文本数据进行语言模型任务的训练。虽然&lt;/span&gt;&lt;span&gt;&lt;strong&gt;初代 GPT 模型采用的就已经是生成式的预训练（这也是 GPT 名字的由来，Generative Pre-Training，即生成式预训练），但使用的是无监督预训练 + 下游任务微调的范式&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。这一范式其实并不是什么新的发明，它在 CV（计算机视觉）领域已经有比较广泛的应用，只是由于当年 ELMo 模型的出色表现，把它重新「介绍」到了 NLP 领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPT 模型的出现在那一年确实引来了一些业内的关注，但它并不是那一年的 C 位主角。因为就在同年，Google 的 BERT 模型横空出世，以优异的效果吸引了几乎全部的目光（这个景象有点像现在的 ChatGPT，不禁感叹 Google 和 OpenAI 之间的「恩恩怨怨」真是天道好轮回）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.40703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydV9zNB9Cice666KIv7UiaOnXqHp2GSahcM9u8NiaoBa5fMehfiakUBwDNHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片来自 BERT 论文，从图示中可以一窥当年 BERT 对标的就是 GPT，并引以为傲地指出双向编码能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BERT 模型虽然也是采用和 GPT 一样的 Transformer 模型结构，但它几乎就是为「无监督预训练 + 下游任务微调」的范式量身定制的模型。和 GPT 相比，BERT 所使用的掩码语言模型任务（Masked Language Model）虽然让它失去了直接生成文本的能力，但换来的是双向编码的能力，这让模型拥有了更强的文本编码性能，直接的体现则是下游任务效果的大幅提升。而 GPT 为了保留生成文本的能力，只能采用单向编码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以当年的眼光来看，BERT 绝对是一个更加优秀的模型。因为既然 BERT 和 GPT 两者都是采用「预训练 + 微调」的范式，并且下游任务依然是分类、匹配、序列标注等等「经典」的 NLP 任务形式，那么像 BERT 模型这种更注重特征编码的质量，下游任务选一个合适的损失函数去配合任务做微调，显然比 GPT 这种以文本生成方式去「迂回地」完成这些任务更加直接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 BERT 模型出来以后，「无监督训练 + 下游任务微调」的范式便奠定了它的霸主地位，各类沿着 BERT 的思路，琢磨「如何获得更好的文本特征编码」的方法大量涌现，以至于 GPT 这个以生成式任务为目标的模型显得像一个「异类」。马后炮地说，如果当时 OpenAI「顺应大势」，放弃生成式预训练这条路，也许我们要等更长的时间才能见到 ChatGPT 这样的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPT-2 带来的希望&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我们现在见到了 ChatGPT，所以 OpenAI 没有放弃生成式预训练的路线。实际上坚持的「回报」隐约出现在了第二年，也就是 2019 年。OpenAI 发布了有 48 层 Transformer 结构的 GPT-2 模型。在发布的论文（Language Models are Unsupervised Multitask Learners）中，他们发现通过无监督数据配合生成式训练后，GPT 展示出了零样本（zero-shot）的多任务能力。而奇妙的是，这些多任务的能力并不是显式地、人为地加入到训练数据中的。用通俗的话来举个例子，GPT-2 其中一个展示出来的能力是做翻译，但令人吃惊的是，通常专门用来做翻译的模型是需要大量的平行语料（即两种不同语种之间配对的数据）进行监督训练，但 GPT-2 并没有使用这种数据，而仅仅是在大量的语料上进行生成式的训练，然后它就「突然」会做翻译了。这个发现或多或少地带有点颠覆性的意味，它向人们展示了三个重要的现象：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;想让模型去完成一种 NLP 任务，也许并不需要和任务匹配的标注数据&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。例如 GPT-2 训练时没有用标注的翻译数据，但它会做翻译；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;想让模型去完成一种 NLP 任务，也许并不需要和任务匹配的训练目标&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。例如 GPT-2 训练的时候并没有设计翻译任务和相关的损失函数，它只是在做语言模型任务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;仅仅用语言模型任务（即生成式任务）训练的模型，也可以具有多任务的能力&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。例如 GPT-2 展现出了翻译、问答、阅读理解等等的能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然以现在的眼光来看，当时的 GPT-2 所展示出来的各种能力还比较初级，效果距离使用监督数据微调后的一些其它模型还有明显的差距，但这并没有妨碍 OpenAI 对它所蕴含的潜在能力充满期待，以至于在论文摘要中的最后一句话中，他们提出了对 GPT 系列模型未来的期望：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;142&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;“These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.”&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来一系列事情的发展也证明了他们确实是一直朝着这个 promising path 的方向在前进。如果说在 2018 年，GPT 初代模型出来的时候，GPT 的生成式预训练还面临着被 BERT 这类以「提取特征」为目地的预训练模型在各方面碾压，那么在 GPT-2 中的发现，给了生成式预训练一个 BERT 类模型无法替代的潜在优势，即语言模型任务所带来的多任务能力，且这种多任务能力是无需标注数据的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，在那个时间点上，生成式的技术路径依然面临风险和挑战。毕竟当时的 GPT-2 在各任务上的表现还是差于经过微调的模型，这导致了 GPT-2 虽然有着翻译、摘要等等能力，但效果太差以至于无法实际使用。因此，如果在当时想要一个可用的翻译模型，最好的选择依然是老老实实用标注数据训练一个专门用来翻译的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPT-3，数据飞轮的开始&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 ChatGPT 时代往回看，也许 OpenAI 在 GPT-2 中的发现确实坚定了他们对 GPT 系列模型的信心，并决定加大研发投入力度。因为在随后的 2020 年他们发布了 1750 亿参数量的 GPT-3，一个即便以现在的眼光去看也大得让人惊叹的模型。虽然 OpenAI 没有明确公开训练这个模型的费用，但大家的估算是当时花了 1200 万美元。同时公开的还有一篇长达 60 多页的论文（Language Models are Few-Shot Learners），其中详细阐述了这个新的庞然巨物所展示出来的新能力。最重要的发现莫过于论文标题中所说的，语言模型具有小样本（few-shot）学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小样本学习是一个机器学习领域的专业术语，但它有着很朴素的理念，即「人类是可以通过少量的几个例子就学会一个新的语言任务」。想象一下在语文课上学习怎么掌握「把」字句换成「被」字句样（雨把衣服淋湿了 —— 衣服被雨淋湿了）的情形，老师会给出几个例子，同学们就能够掌握这项能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但对于深度学习模型来说，它通常需要学习（训练）成千上万的例子才能掌握一项新的能力，但大家发现 GPT-3 却像人类一样具有类似的能力。而且重点在于，只需要给它展示几个例子，它就会「有样学样」地完成例子给出的任务，而不需要进行额外的训练（即不需要进行常规训练中的梯度反传和参数更新）。后来的研究表明，这种能力是巨型模型所特有的，被业内叫做「在上下文中学习」（in context learning）的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.7180156657963446&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydWtO1koIXcSbXP2zGDDUQQOeNKyADic76V3ldEu0JdOLI5lC4bf9vIKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;766&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;GPT-3 论文中所展示的英语翻译法语的 In context learning 能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，小样本学习能力本身并不是很惊人的发现。毕竟业内一直都在对小样本学习进行研究，很多专攻小样本学习的模型都有出色的小样本学习能力。但 GPT-3 展示出来的这种「在上下文中学习」的小样本能力却非常出人意料，其原因也和 GPT-2 所展示的多任务能力一样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了这个能力以外，GPT-3 还展示出了优秀的文本生成能力，相比 GPT-2，它生成的内容更加流畅，而且可以生成很长的内容。这些能力综合体现在一个模型上，让 GPT-3 在当时成为了大家的关注焦点，它也成为 OpenAI 正式对外提供服务的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但随着这个模型服务的开放，越来越多的人尝试使用这个模型。从这时起，OpenAI 通过开放给公众的方式，同时也在收集着更具有多样性的数据（用户使用时输入的内容可能会被用于模型的训练，这一点是写在用户条款中的），这些数据在后来的模型迭代中也发挥着重要的作用。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;自此 GPT 系列模型的数据飞轮便转动了起来，越多优质的用户数据，迭代出效果越好的模型&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与 ChatGPT 不同的是，GTP-3 并不是采用对话的形式交互的模型，而是一个文本的续写模型（也就是在你输入的文字后面接着往下写），因此它并不具备如今的 ChatGPT 所拥有的多轮对话能力。但它已经能够干很多的事情，例如编写故事、给邮件做自动补全等等。但同时，大家也慢慢发现了一些问题，例如它会一本正经地输出不符合事实的内容，并且会输出一些有害的言论等等。这是这种文本生成模型最突出的弊端，虽然经过多次迭代，但 ChatGPT 如今也依然面临类似的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;CodeX，让计算机自己写代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 在对 GPT-3 的研究中还有一个意外的发现，它能够根据一些注释生成很简单的代码。因此在随后的 2021 年，他们对生成代码这件事情进行了专门的研究投入，并发布了 CodeX 模型。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;它可以看作是一个有着代码专精能力的 GPT 模型，能够根据自然语言输入生成比较复杂的代码&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从外部视角来看，我们无法判断代码生成的研究与 GPT 系列模型的研发是否在同时进行。但放在当时，让模型具有生成代码的能力，从实用化的角度来说确实更加具有意义，毕竟 GPT-3 还未拥有如今 ChatGPT 这般强悍的能力。另一方面，让模型去生成代码也能规避它生成有危害文本内容带来的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 CodeX 论文中提及了几个要点，首先是让经过文本数据预训练的 GPT 模型在专门的代码数据（数据来自 github 的开源代码，一共 159G）上训练确实能够明显提升模型对代码的理解和输出能力。其次是论文中用的是一个 120 亿参数的「小」模型，这个信息从侧面反映出 OpenAI 内部除了对外开放接口的 1750 亿参数的 GPT-3 模型外，还有别的不同大小的模型版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而加入代码训练，让模型获得理解和生成代码的决定，原本的初衷也许只是希望 GPT 能够多一种应用场景。它看似与 GPT 系列模型在理解和运用自然语言的能力没有太大的联系，但根据后续的研究（详细的分析请参考文章《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864144&amp;amp;idx=4&amp;amp;sn=1270624988d70f44d4059af7ac4ae4e0&amp;amp;chksm=84e53e6eb392b7785418e8257952284cfe6dd801d84404958fb917c461da792039626e172c31&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;拆解追溯 GPT-3.5 各项能力的起源&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;拆解&lt;/span&gt;&lt;span&gt;追溯 GPT-3.5 各项能力的起源&lt;/span&gt;&lt;/a&gt;》），增加对代码数据的训练很有可能触发了后来的 GPT 模型在自然语言上的复杂推理和思维链的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许在 OpenAI 做 CodeX 之初并没有预料到会有这样的结果，但就像他们一直使用文本生成任务来做 GPT 模型，然后在 GPT-2 和 GPT-3 中「解锁」了「多任务的能力」和「在上下文中学习的能力」那样，代码数据的引入又一次让他们获得了意料之外的收获。虽然看上去似乎有一些偶然，但对技术路线的前瞻性认知，加上坚持与持续的投入显然是一个至关重要的因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;InstructGPT，让 GPT 好好说话&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前面我们提到了 GPT-3 虽然已经有很强的能力，但上线以后随着使用的人越来越多，也发现了很多问题，最严重的应该要数「一本正经地胡说八道」和「输出带有危害性的内容」这两点了。虽然在 2021 年 OpenAI 似乎暂时将重点放在了让模型理解和生成代码这件事情上，但他们应该一直在尝试解决 GPT-3 的这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2022 年初，OpenAI 发表了 InstructGPT 的论文（Training language models to follow instructions with human feedback），从中我们可以一窥解决这些问题的方法。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;论文的核心理念是让模型接受人类的教导（反馈），这一点在标题中就已经开宗明义了&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPT-3 之所以会出现「一本正经地胡说八道」和「输出有害的内容」这样的问题，其根源来自于它所使用的训练数据。像 GPT-3 这样的庞然大物，对数据的需求量是海量的。我们从 GPT-3 的论文中可以找到它的数据来源，大致可以划分为三类：网页内容、百科内容以及书籍。虽然网页内容的量非常大，但也非常「脏、乱、差」，自然会包含很多非真实性和有害的内容。GPT-3 在这些数据上进行训练，自然也就学到了这些东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但作为一款对外提供服务的产品，GPT-3 的回答应该更小心一些。要解决这个问题，其中的一难点在于怎么去定义模型应该怎么说话。因为生成模型的输出内容是自然语言本身，而不是一个分类的标签或一个实体名词这种有明确的、客观对错的内容。没有明确的对错，就导致无法像训练经典的 NLP 模型那样直接针对目标设计训练任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 InstructGPT 给出的解决思路是非常直接的，既然对于「好的回答」这个评价指标有很多不同的影响因素，这些因素又相互交织在一起，那就让人来教它怎么写回答。因为人类是比较善于处理这种「既有明确的要求，又有模糊的范围」的问题的，让真人写一些「优秀范例」，让模型去学习这些「优秀范例」，这正是 InstructGPT 提出的总体思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体而言，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;InstructGPT 提出了两个阶段的路径来让 GPT 学习人类给出的「优秀范例」，第一阶段是监督学习，第二阶段是强化学习&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。在第一阶段中（对应下图中最左边的 Step 1），让真人根据不同的 Prompt（粗浅可以认为是我们使用 ChatGPT 时，在对话框里输入的那条文本，在业界这个东西叫做指令）写真实的、无害的、有用的回答。实际操作过程中，为了保证这些内容的质量，会给写回答的标注人员一些规范性的指引，然后让已经经过预训练的 GPT 模型在这些人类编辑的数据上继续训练。这一阶段可以看作是对模型的一种「规训」，用一个不严谨的类比来说，就像语文老师让你默写优秀范文那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5885167464114832&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydIe1NVEDJB96pRuouyHxP1Rd0UHNv624rDylHCe5qbEmfK2C78ngGicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1045&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片来自 InstructGPT 论文，提出通过监督式的指令微调 + 人类反馈的强化学习来让模型的输出变得合理。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二阶段是强化学习，技术上分为两步。第一步（对应上图中间的 Step 2）是让被「规训」后的模型根据不同的 Prompt 生成多个不同的回答，并由人来给这些回答按照好与差的标准来排序。然后用这些标注了优劣之分的数据训练一个打分模型，让它可以自动给更多的数据进行排序打分。强化学习阶段的第二步（对应上图中右边的 Step 3）就是利用这个打分模型作为强化学习中的环境反馈，以策略梯度（Policy Gradient，准确地说是 PPO 算法）的方式对已经「规训」后的 GPT 模型进行训练。整个第二阶段的过程可以看作是对模型的一种「强化」，再用一个不严谨的类比来说，就像语文老师给你写的作文打分，让你从分数中分辨什么是好与不好，然后不断进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;用一种非常不严谨，但普通人或许也能够理解的方式来说，InstructGPT 先是让一个「口无遮拦」的 GPT 通过「默写人类的优秀范文」的方式初步学会「好好说话」，然后再「给它独自写出来的东西打个分，让它回去好好领悟，继续进步」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。当然，在技术上牵涉事情会更复杂一些，比如「优秀范文」的具体规范和数量等数据上的问题，以及强化学习中打分模型的选择，算法参数的设置等算法上的问题，都会对最后的效果产生影响。但最终的结果表明，这种方式是非常有效的，论文中也指出一个通过上述方式训练出来的 13 亿的小模型，效果就能够超过没有经过这种训练的更大的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外论文中还有一些非常值得一提的内容。首先是关于 Prompt 的一些发现。InstructGPT 训练时所使用的 Prompt 主要由两部分构成，一部分是专门的 AI 训练师编写的，另一部分自来 OpenAI 的模型在线服务期间，由用户使用中编写的内容，这时数据飞轮的作用就体现了。可以发现，无论是哪种，这些 Prompt 都是由真人写出来的，虽然文章中没有对这些 Prompt 的具体涵盖范围、分布情况以及提问的方式展开详细的分析，但可以合理地猜测这些 Prompt 具有一定的多样性和较高的质量。其实文章中对比了使用这些真人编写的 Prompt 训练的模型和使用一些开源 NLP 任务数据集中构建的 Prompt（例如 T0 数据集、FLAN 数据集）训练出来的模型，结论是由真人编写 Prompt 训练出来的模型，给出的答案更加能被评测的人接受。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一点是关于训练好的模型对新的 Prompt 的泛化能力的问题，可想而知的是，如果训练完成的模型无法产生 Prompt 的泛化能力，那么现在 ChatGPT 所表现出来的，几乎百问百答的能力是不太可能产生的。因为在模型做微调的阶段，即便是再多的数据，也不可能把人们有可能会输入的内容都覆盖完整。而 InstrctGPT 论文中点明了文中所采用的方法是可以产生 Prompt 的泛化能力的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之所以花了更多的文字对 InstructGPT 做介绍，因为根据 ChatGPT 官方页面的介绍，InstructGPT 中的方法正是用来训练 ChatGPT 的方法，不同的只是 ChatGPT 使用了对话式的数据组织方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPT-3.5 时代和 ChatGPT 的诞生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在随后的时间内，OpenAI 发布了多个被称为 GPT-3.5 系列的模型，虽然这些模型并未有相关的论文跟随发表，但根据&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864144&amp;amp;idx=4&amp;amp;sn=1270624988d70f44d4059af7ac4ae4e0&amp;amp;chksm=84e53e6eb392b7785418e8257952284cfe6dd801d84404958fb917c461da792039626e172c31&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;这篇文章《拆解追溯 GPT-3.5 各项能力的起源》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;这篇文章&lt;/a&gt;的分析，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;GPT-3.5 系列应该是融合了 OpenAI 在 GPT-3 时代积累的技术、数据以及经验开发出来的&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。由于没有详细的官方公开信息参考，关于这些模型的具体资料，外界主要是通过分析使用的体验、相关的技术论文以及 OpenAI 的 API 文档介绍来进行推测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据分析，GPT-3.5 系列的模型有可能并不是在 GPT-3 上继续微调而来，而很可能是将代码和自然语言的数据融合在一起，重新从零开始训练了一个基础模型。这个模型可能比 GPT-3 的 1750 亿参数量更大，它在 OpenAI 的 API 中被命名为 codex-davinci-002。然后在这个基础模型上，通过指令微调和人类反馈得到了一系列后续的模型，包括 ChatGPT。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7015625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydxWqtxCCPMGHvLRKhArkzGB7Ie3ibzWJa6Yk5ESOEEZ5hEfJaoicwVicTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;GPT 系列模型的发展路径。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简要地说，从 code-davince-002 这个模型开始，经过有监督的指令微调得到 text-davinci-002。以及后续的 text-davinci-003 和 ChatGPT，也是在 GPT-3.5 系列的某个模型上通过指令微调以及人类强化学习反馈得到的。并且 text-davinci-003 和 ChatGPT 都是在 2022 年 11 月发布的，不同的是 text-davinci-003 和 GPT-3 一样，是一个文本补全模型。而根据 ChatGPT 的官方介绍，它是通过将过往的数据处理成对话交互的形式，并增加了新的对话数据训练出来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至此，我们大致回顾了 OpenAI GPT 系列模型从 2018 年的初代 GPT 到现在的 ChatGPT，一路发展迭代的过程。在这个过程中，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;OpenAI 一直保持着对生成式预训练模型这一技术路径的「执拗」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，并且也一直从不断发展的 NLP 技术中吸纳新的方法，从最初的 Transformer 模型结构，到后来的指令微调（Prompt tuning）等技术的出现，这些因素共同促成了如今 ChatGPT 的成功。有了对 GPT 系列模型发展的了解，我们可以再回过头来看看如今的 ChatGPT。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3、走近再看 ChatGPT&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一章节中我们阐述了 ChatGPT 出圈的原因主要是：「它以流畅、符合逻辑的自然语言来反馈人类对它输入的自然语言」，从而给与它交流的人带来了很强的「智能感」。在第二章节中通过回顾 GPT 系列模型的发展历史来了解 ChatGPT 成功之路。而这一章节会尝试以尽可能让圈外人都能理解的方式，稍微深入一些技术的内容，并且探讨一下当前的一些大型文本生成式模型为什么未能做到相同的效果。这一部份的主要参考来自于《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864784&amp;amp;idx=3&amp;amp;sn=fb8ad092ad32623af7ea822652cd14cc&amp;amp;chksm=84e538eeb392b1f8ff40fa10dc2c84b56904fed261ff15f97f36a1023f887807af62ea39bde7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;深入理解语言模型的突现能力&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;深入理解语言模型的突现能力&lt;/span&gt;&lt;/a&gt;》和《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864144&amp;amp;idx=4&amp;amp;sn=1270624988d70f44d4059af7ac4ae4e0&amp;amp;chksm=84e53e6eb392b7785418e8257952284cfe6dd801d84404958fb917c461da792039626e172c31&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;拆解追溯 GPT-3.5 各项能力的起源&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;拆解追溯 GPT-3.5 各项能力的起源&lt;/span&gt;&lt;/a&gt;》这两篇文章以及相关的一些论文，建议希望详细了解细节的读者阅读原文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然在第一章中指出，ChatGPT 所带来的惊艳效果是由许多不同的 NLP 任务综合体现出来的，但在分析它背后的技术时，还是通过将它的能力进行拆解会更加清晰明了一些。总体而言，ChatGPT 所体现出来的能力可以大致划分为以下几个维度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;- 文本生成的能力：ChatGPT 的所有输出都是即使生成出来的文本，所以文本生成的能力是它最基本的要求。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一项能力实际上是来自于它的训练方式，ChatGPT 在预训练时，是一个标准的自回归语言模型任务，这是 OpenAI 所有 GPT 系列模型的基底。所谓的自回归语言模型任务，通俗的理解是这样的：它可以根据已经输入的文本，预测下一个 token 应该是什么。这里所说的 token，所代表的是模型所使用的最小单位的字符片段，它可以是字（在中文里采用字是很常见的），也可以是词（英文的每个词天然地被空格隔开了，所以常采用词），甚至是字母。但现在的方法通常采用的是子词（subword，介于字母和词之间，主要的目的是减少词表数量）。但不论是哪种，自回归语言模型任务的基本思路都是根据已经输入的文本，预测下一个要输出的文本是什么，就像下图的例子中那样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.653125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydp6qJD8TTSIlqdfPiagGjT1obC9ABLxuVJDMNqpzu6l3WwbNe84P0rPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这个例子中，BOS 代表了输入的开头，而每个 token 是一个词，GPT 模型根据输入的「今天」和 「天气」两个词，预测下一个要输出的是「不错」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练的时候，会准备很多文本数据，比如网页上的文章、各类书籍等等，只要是正常的文字内容，都可以用来训练。值得说明的是，这种数据不需要进行额外的人工标注，因为这类数据本来就是人写的，模型要做的事情就是根据这些人写出的文本，去学习「给定了前面的文字，接着这些文字后面这个地方应该是什么」的问题。这便是业内所称的「无监督训练」，实际上模型并不是真的没有监督（不然模型学什么呢？），只是它的数据不需要额外的人工标注。也正因为这个任务是不需要额外标注的，因此可以「免费」获得大量的数据，得益于互联网的普及，可以「轻松地」获得海量的由真人写出的文本内容用来训练。这一点也是 GPT 系列模型的特点之一，用海量的数据，去训练很大的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么在我们使用 ChatGPT 的时候，它是怎么工作的呢？其实也和它的训练方式一样，模型会根据我们在对话框里输入的内容，去预测接在这些内容的下一个 token 是什么，得到这个 token 后，会将它与前面的内容拼接成一个新的文本给模型，模型再预测下一个 token，如此反复，直到满足某个条件后停止。这个停止的条件有很多不同的设计方式，比如可以是输出的文本达到特定的长度，又或者是模型预测出某个用来代表停止的特殊 token。另外值得一提的是，模型预测下一个 token 时，其实背地里是一个采样的过程。换句话说，模型在预测 token 时，输出的其实是所有可能出现的 token 的概率，然后从这个概率分布里采样一个 token。因此，在使用 ChatGPT 时，会发现即便对于相同的输入，它的输出每次也会不一样，因为在背地里它采样了不一样的 token 作为输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解这些之后，可以再回过头来思考一下模型在学什么。它在学习怎么回答问答吗？又或者说它在学习怎么理解自然语言所蕴含的信息、逻辑、情感？还是说它在学习海量的知识？从训练任务的设计来看，似乎都没有，它只是从海量的文本数据里，学习了「根据输入的这些文本，一个人类在后面会接着写什么」这件事。但正是这样的模型，在「进化」到 ChatGPT 时，它却掌握了丰富的知识、复杂的逻辑推理等等，它似乎掌握了一个人类运用语言所需要的几乎所有的能力。这是一件非常神奇的事情，它的「进化」历程将会在下一章节中做更加深入的介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;- 丰富的知识储备：ChatGPT 能够正确回答非常多的问题，包括历史、文学、数学、物理、编程等等。因为目前版本的 ChatGPT 并没有利用外部知识，因此这些知识的内容是「储存」在模型内部的。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT 所拥有的丰富知识储备，来自于它的训练数据，以及它足够大的体量，以便学会这些内容。虽然官方并没有公开 ChatGPT 所使用的训练数据的具体细节，但从它的前身 GPT-3 的论文可以推测，这些数据大致可以分为三个大的范畴：网页内容、书籍内容以及百科内容。可想而知的是，这些内容天然地蕴含了大量的知识，百科和书籍自然不必说，而网页内容也包含了许多新闻、评论、观点等，并且网页也包括了很多专门的问答垂直类网站，这些都是 ChatGPT 的知识来源。在官方的介绍里指出 ChatGPT 无法回答 2021 年以后发生的事情，因此合理的猜测是训练的数据收集截止到 2021 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但数据量只是其中一个方面，要让模型「掌握」这些数据，其自身的体量是不可能小的。以 GPT-3 为例，它有 1750 亿参数，可以粗浅地理解为，这些数据的内容以及模型的各项能力，都以这一个个参数的具体数值的形式，固定在了训练完成的模型中。感性的理解是，假设一个模型只有 1 个参数，那它什么也干不了。更严谨的分析和对比可以参考这篇论文《Holistic Evaluation of Language Models》的测评，方向性的结论是越大的模型，在需要知识来完成的任务上表现得越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://arxiv.org/pdf/2211.09110.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;- 逻辑推理与思维链的能力：从第一章图片中的鸡兔同笼的例子可以看出，ChatGPT 具有很强的逻辑推理能力。并且它能够将复杂的内容，通过拆解，分成多个小的步骤，一步步地进行推理，获得最后的答案，这种能力被称为思维链。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从前面的介绍我们知道，模型在训练的时候并没有针对逻辑推理以及思维链做特定的设计。而当前的主流观点认为，逻辑推理和思维链很可能和两个因素相关，第一个是模型的体量，第二个是模型是否在代码数据上进行过训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于模型体量与推理、思维链能力的关系，在《深入理解语言模型的突现能力》中有对应的介绍。下面这张图展示了思维链能力与模型体量的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.3445378151260505&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydFxgzn18UCbGEC2oXOEM4wZYOR4zUN3AjU6STsKIpY2SAaavV6KsqCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;952&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;不同模型不同尺寸的思维链效果对比，图来自论文。GSM8K，SVAMP 和 MAWPS 是三个需要逻辑推理的数学应用题数据集，LaMDA，GPT 和 PaLM 分别是 3 个不同的模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简要地说，图表中给出了三个不同的模型，在三个数学应用题数据集上的答对率。而值得关注的是以下几个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;思维链的能力（蓝色实线）在模型体量够大的时候产生了效果上的突变；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;思维链的能力在模型够大的前提下，效果超过了标准的指令（Standard prompting，黑色实线）方法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;思维链的能力在模型够大的情况下，可以接近甚至超过有监督的方法（橙色虚线）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用通俗的话来说，就是在模型足够大的时候，思维链的能力突然展现了出来，能够达到、甚至超过那些在推理数据集上专门进行有监督训练的模型。这个图也许部分解释了现在我们看到的 ChatGPT 所具有的优异推理和思维链能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而另一个关于推理以及思维链能力的产生因素，与模型是否在代码数据上做过训练有关。目前这一点只是一个推论，《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864144&amp;amp;idx=4&amp;amp;sn=1270624988d70f44d4059af7ac4ae4e0&amp;amp;chksm=84e53e6eb392b7785418e8257952284cfe6dd801d84404958fb917c461da792039626e172c31&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;拆解追溯 GPT-3.5 各项能力的起源&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;拆解追溯 GPT-3.5 各项能力的起源&lt;/a&gt;》中的分析表明体量类似的大型模型，没有在代码上做过训练的话，只有很弱或几乎没有思维链和推理能力。而 ChatGPT 确实是在代码数据上进行过训练的，这一点从它能够理解并生成代码也可以看出来。在第二章回顾发展历程中提到了，OpenAI 在 2021 年就发布了专门针对代码的 CodeX 模型，将代码数据加入 GPT 的训练数据应该就是从那时开始的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;- 按照人的提问或者指令给予回复的能力：ChatGPT 除了可以用狭义的基于「问答」形式的交互以外，还能够按照输入的要求进行回复。例如，在应对「帮我写一封信」这类指令式的要求时，它同样也展现出了优秀的能力。这种能力让它不仅是一个提供答案的「高级搜索引擎」，更是一种可以用自然语言来交互的文字处理工具。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然目前大众普遍把目光聚焦在将 ChatGPT 作为一种类搜索引擎的工具，但查阅相关知识并给予回答并不是它的唯一能力。实际上，单就 ChatGPT 本身而言，回答知识性的问题并不是它的强项，毕竟它本身的训练数据被定格在了 2021 年。即便用更新的数据去训练，但它终究跟不上时事的变化，因此要将它用作知识性的问答工具，还是需要与搜索引擎等外部知识源做结合，就像现在 Bing 做的一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但换一个角度来看，ChatGPT 像是一个「语言完备」的文本工具，也就是它能够按照你给它的要求，完成指定的、可以用文本形式表达出来的内容，就像下面这个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.770940170940171&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydY8bVcMibJCc3icWZMYbiasPspAH4ibsIkHwTGeKu6vfpcicyibYIiaEzibr7SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1170&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;按照给定的计划内容生成英文邮件进行汇报。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里所说的「语言完备」，指的是运用语言的能力。可以看出上面这个例子里，其实不涉及知识性的内容，因为需要它写的内容已经提供给它了。但要写出这封邮件，涉及到的是运用语言的能力，比如遣词造句、语种切换、邮件格式等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们回过头来，尝试分析它的这种「按照指令完成任务」的能力是怎么获得的。在学界中，这种指令被称为 prompt，实际上对话中的用户输入、问答中的问题也是一种 prompt，因此可以粗浅地理解为，在聊天框里输入的所有内容都是 prompt。如果了解我们在本章第一节介绍语言模型的内容，那么更严谨一些的说法应该是「输入给模型的上文」都是 prompt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT 根据输入的指令（prompt）进行回复的能力，是来自于一种被称为指令微调的模型训练方式（prompt tuning）。其实原理很简单，模型依然还是「根据输入的内容，预测下一个 token 是什么」，只是在指令微调的阶段，输入的内容被换成了这些事先写好的 prompt，而 prompt 后面需要生成的内容，则是事先写好的答案。因此在这一阶段和一开始所说的无监督自回归语言模型训练，最大的不同在于数据。这里的数据，也就是 prompt 以及对应的回复，都是人写的，换句话说，这一阶段用的是人工标注的数据进行的监督训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提到人工标注的数据，就自然牵涉到了所需要的数据量了，因为每一条标注数据都是需要成本的。如果是不需要标注（就像第一阶段的训练），那么自然有海量的文本数据可供训练，但如果要标注，那到底需要多少这种数据呢？要知道，让标注人员手写一个 prompt，然后再手写一个几百字的、真实详尽的回答，成本是很高的。根据论文《Training language models to follow instructions with human feedback》的介绍，所需要的数据其实不需要太多（相比于无监督阶段所使用的数据来说）。虽然具体到 ChatGPT 到底使用了多少没有确切的信息公开，但可以确定的是在数量级上一定远比用来进行无监督训练的网页、百科和书籍所构成的数据集要小非常多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://arxiv.org/pdf/2203.02155.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只需要相对少量的人工标注的 prompt 数据就能达到让模型按照指令做出回复的目的，这一点背后其实隐含了一个现象，在学界内被称为 prompt 的泛化能力。可以想象一下，如今全世界都在不停的向 ChatGPT 提问，所提的问题也必定是千奇百怪的，这些问题其实就是一个个的 prompt。但用来对 ChatGPT 进行指令微调的 prompt 肯定不会有这么多，这说明模型在学习到了一定量的 prompt 和相应的答案以后，它能够「举一反三」地对它没有见过的 prompt 进行回答，这就是 prompt 的泛化能力。文章《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650864144&amp;amp;idx=4&amp;amp;sn=1270624988d70f44d4059af7ac4ae4e0&amp;amp;chksm=84e53e6eb392b7785418e8257952284cfe6dd801d84404958fb917c461da792039626e172c31&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;拆解追溯 GPT-3.5 各项能力的起源&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;拆解追溯 GPT-3.5 各项能力的起源&lt;/a&gt;》分析指出，这种泛化能力与在指令微调阶段让模型学习的标注数据数量以及多样性相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，用少量的 prompt 数据就能微调出类似于 ChatGPT 这样拥有强大能力的模型，背后还隐含了另一个猜测，即模型所表现出来的各项能力，可能在无监督训练的阶段就已经存在于模型当中了。其实这也很好理解，毕竟相比于无监督的数据，这些人工标注的 prompt 数量太少了，很难想象模型是通过对这些仅有的标注数据学习而产生了各种各样的能力。从这个角度来说，指令微调的过程更多只是让模型学会按一定的规范来进行回复，而它的知识、逻辑等能力是早已存在的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;- 「客观公正」的能力：如果对 ChatGPT 询问一些有害或者有争议的问题，可以看到 ChatGPT 的回答都是非常「小心」的，很像是经过训练的新闻发言人般的回答。虽然它目前依然做得不够好，但这种能力是 OpenAI 敢将它公开作为一款产品使用的核心因素。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让模型的输出符合人类的价值观是 OpenAI 一直在做的事情。早在 2020 年 GPT-3 的时候，OpenAI 就发现这种通过网上的数据训练出来的模型，会生成带有歧视、危险、争议的内容。作为一个对外提供服务的产品，这些有害的内容显然是不合适的。而现在的 ChatGPT 在这一点上有着明显的改善，让模型做出这种「行为改变」的主要方法也来自于 InstructGPT 的论文，更确切地说，是通过有监督的指令微调加上人类反馈的强化学习共同完成的，这一点在第二章中也已经做过介绍了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上述的分析可以发现，从技术方法的角度来说，ChatGPT 相关的内容都是已知的，但为什么当前只有它拥有如此惊艳的表现呢。实际上从 ChatGPT 推出之后，NLP 社区就一直在分析这其中的原因，虽然很多结论是推测性的，但也为同类模型的国产化带来一些启示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型体量的因素&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能力涌现出现的前提是模型体量达到一定的规模，虽然没有具体的指标指引，但从目前的事实情况来看，类似于思维链等比较「高级」的能力，需要在数百亿参数量以上的模型中才表现得足够优异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据量的因素&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的大小不是唯一的因素。DeepMind 在这篇论文《Training Compute-Optimal Large Language Models》提供了一些分析性的结论，指出训练的数据量需要随着模型的体量相应地增加，更确切地说，是模型训练时「见过的 token」数量，需要随着模型体量增加。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://arxiv.org/pdf/2203.15556.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据质量的因素&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于无监督的数据，数据量相对而言并不是很大的障碍，但数据质量往往更加容易被忽视。实际上在 GPT-3 的论文中，就有专门的内容介绍数据的处理工作。为了清洗 GPT-3 的训练数据，OpenAI 专门训练了一个数据过滤模型，来从海量的网页数据中获取更高质量的数据。相比而言，与 GPT-3 体量相当的一些开源模型，例如 Meta 的 Opt 和 BigScience 的 Bloom，似乎没有进行这一步清洗。这也许是这两个开源模型效果劣于 GPT-3 的原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，数据质量的衡量维度不是单一的，诸如数据的多样性、内容重复度以及数据的分布情况都是需要考虑的因素。例如虽然 GPT-3 所使用的网页、百科、书籍这三大类数据中，网页数据的总量是最多的，但在训练时这三类数据的采样并不是按照实际数据的多寡进行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外值得一提的是，在指令微调的阶段，采用人工编写指令也许是一个重要的影响因素。InstructGPT 的论文明确指出在测评过程中，采用人工编写的指令训练出来的模型，比采用现有的 NLP 数据集通过模版的方式构建指令训练出来的模型有更好的效果。这也许解释了在 T0、FLAN 等由 NLP 数据集构成的指令数据集训练出来的模型为什么效果会差一些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练过程的影响&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这类巨型模型在训练时通过集群进行训练，同时采用数据并行、模型并行以及 ZeRO 优化器（一种降低训练过程显存占用的方法），这些方式为训练的稳定性引入了更多的变量。如下这篇分析指出甚至模型是否采用 bfloat16 精度都对结果有明显的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分析链接：https://jingfengyang.github.io/gpt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相信了解了上面的这些内容，大家对复刻一个类 ChatGPT 的方式以及会面临的问题会有一个大致的了解。有幸的是 OpenAI 已经证明了这技术路径是能够走通的，ChatGPT 的出现也确实正在改变 NLP 技术的发展走向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4、未来的展望&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT 从 2022 年 11 月上线以来，引起了极大的关注。相信即便是非专业领域，甚至是与计算机也很少打交道的群体，或多或少地都知道它的存在，这个现象本身就已经反映出它的出现有些不同寻常。圈外的大众更多的是以好奇、惊讶或者惊叹的方式来感性地认识它的出现。而对从业者来说，它的出现更多的是对未来技术走向的思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;从技术的角度来说，ChatGPT 的出现标志着 NLP 领域的又一次范式切换&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。之所以说是「又」一次，是因为在 2018 年，也就是初代 GPT 发布的那一年，与之同年发布的 BERT 模型以自身优异的表现，开创了 NLP 的「预训练 + 微调」范式的时代，具体内容在第二章中已经做过介绍了。这里主要介绍&lt;/span&gt;&lt;span&gt;&lt;strong&gt;由 ChatGPT 开启的「文本生成 + 指令」的范式&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。具体来说，就是利用训练好的 ChatGPT 或类似的文本生成模型，通过输入适当的指令（prompt）来完成某一项具体的场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种范式与此前的 NLP 技术应用有很大的不同。不论是早期的利用 LDA、RNN 等统计模型或很小的深度学习模型的时代，还是后来利用 BERT 等预训练配合微调的时代，技术所提供的能力是相对原子化的，距离实际的应用场景有一定的距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就拿前面举的让 ChatGPT 根据要求写英文邮件的例子，按照此前的做法，可能需要先抽取实体、事件等内容（比如时间、地点、事件等），然后通过模版或是模型形成邮件的样式，再通过一个翻译模型转化为英文。当然如果数据量足够训练端到端模型的情况下，也可以跳过中间的若干步骤。但不论采用哪种方式，要么需要将最终的场景拆解成原子化的 NLP 任务，要么需要对应的标注数据。而对于 ChatGPT 来说，只需要一个合适的指令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.84453125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjyddldrF8qia7abltJOUvDdBGXqJTReE9RwujUBKAU9QZlyyMibXvHh9ZIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;三个阶段的 NLP 技术范式。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;这种生成式模型搭配 prompt 的方式，直接略过了中间的各项 NLP 能力组件，用最直接的方式解决应用场景的问题&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。在这种范式下，完成终端应用的技术路径将不再是用单点 NLP 能力模块通过搭积木的方式组合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这个过程不是一蹴而就的，也不意味着 NLP 的单点能力变得不重要。从测评的角度来说，每一个单点能力的好坏依然可作为评价模型效果的指标。并且，就某些场景来说单点能力依旧是一个强需求。例如在订票系统中本身就需要针对时间、地点进行提取。但与此前不同的是，ChatGPT 本身也可以完成单点能力，而不需要使用额外的功能模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5310173697270472&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjydVQ2mak5AID53pFbzCoWmeKOonbtaO81TwOAvwXwS3gpc0EEDxwQic1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;806&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;ChatGPT 进行信息提取。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.43137254901960786&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8N5ibibTOibMribS9gC8L7kjyd0as3RD84pibR38qEg2otbg9OYgv3Vn1TmaUnj8Sozibiat3ibeicich4mibIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;816&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;ChatGPT 进行情感判断。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这个角度来说，可以把 ChatGPT 看作是一个以自然语言作为交互媒介的 NLP 工具。如果说在过去，我们是通过模型 + 数据 + 设计训练任务的方式来完成某项 NLP 能力，那么 ChatGPT 则是通过设计指令来完成这些能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可想而知，ChatGPT 的出现大大降低了 NLP 技术的应用门槛。但它目前还不是全能的。最重要的一点在于它缺乏准确可靠的垂直领域知识，为了让它的回答可靠，最直接的方式是为它提供外部的知识来源，就像微软将 Bing 的搜索结果作为它回答的信息来源那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，「传统」的 NLP 技术并不会就此完全消亡，而是会以「辅助」的角色，作为目前 ChatGPT 短板的补充，这也许会是未来 NLP 技术应用的新范式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;90835&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-autoskip=&quot;1&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650868160&amp;amp;idx=1&amp;amp;sn=95ccb1570292217d65443dbc82965d90&amp;amp;chksm=84e4cdbeb39344a80a5400690907e99eca0544bacc5e7a3d0dcd9aced93cba201a6a4a668b0d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;全面学习 ChatGPT，机器之心准备了 89 篇文章合集&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;全面学习ChatGPT，机器之心准备了 89 篇文章合集&lt;/strong&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这是一份全面、系统且高质量的 ChatGPT 文章合集，我们筛选出来了 89 篇相关文章，设计了阅读框架与学习路径，大家可以根据自己的需求进行浏览与研读。合集内容包括：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;ChatGPT 及 OpenAI  大事件时间轴&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;概念·真正搞懂 ChatGPT：共 3 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;研究·GPT 家族更迭：共 16 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;八年·OpenAI 的历史与现在：共 13 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;干货·GPT 相关研究与技术：共 18 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;观点·专家谈 ChatGPT：共 8 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;行业·应用与探索：共 23 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;行业·同类产品：共 8 篇文章&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;点击阅读原文，开始学习ChatGPT。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;© THE END &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;投稿或寻求报道：content@jiqizhixin.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;10000&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5162d2ee43183182df9b8594ca7c1b4b</guid>
<title>分享7 个VUE项目超级好用的库，看源码都能学习很多！</title>
<link>https://toutiao.io/k/1omcprm</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;blockquote data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;模拟面试、简历指导可私信找我，最低的价格收获最高的指导~&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;大家好，我是林三心，&lt;strong&gt;用最通俗易懂的话讲最难的知识点&lt;/strong&gt;是我的座右铭，&lt;strong&gt;基础是进阶的前提&lt;/strong&gt;是我的初心。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.010204081632653&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TZL4BdZpLdjpwPfAfiaDWibzfb2uDicfgvkP1OQs8dEcjGT8EaMyPevs1bXj2AjI8n8Ve3cC7cwO6bHh0N4rEKFrw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;196&quot;/&gt;&lt;/figure&gt;&lt;p&gt;借助开源库加速VUE项目的开发进度是现代前端开发比较常见的方式，平常收集一些JavaScript库介绍，在遇到需要的时候可以信手拈来。&lt;/p&gt;&lt;p&gt;VUE 生态有很多不错的依赖库或者组件，是使用VUE开发前端的原因之一。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;1. vueuse&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;这是 GitHub 上星最多的库之一，拥有超过 &lt;code&gt;12.8k&lt;/code&gt; 颗星，这是一组基于&lt;span&gt;组合式 API&lt;/span&gt;&lt;span&gt;[1]&lt;/span&gt; 的实用函数库。&lt;/p&gt;&lt;p&gt;它的初衷就是将一切原本并不支持响应式的 JS API 变得支持响应式，省去程序员自己写相关代码。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { useLocalStorage, useMouse, usePreferredDark } from &lt;span&gt;&quot;@vueuse/core&quot;&lt;/span&gt;;&lt;span&gt;export&lt;/span&gt; default {    &lt;span&gt;&lt;span&gt;setup&lt;/span&gt;&lt;/span&gt;() {        // tracks mouse position        const { x, y } = useMouse();        // is user prefers dark theme        const isDark = usePreferredDark();        // persist state &lt;span&gt;in&lt;/span&gt; localStorage        const store = useLocalStorage(&lt;span&gt;&quot;my-storage&quot;&lt;/span&gt;, {            name: &lt;span&gt;&quot;Apple&quot;&lt;/span&gt;,            color: &lt;span&gt;&quot;red&quot;&lt;/span&gt;,        });        &lt;span&gt;return&lt;/span&gt; { x, y, isDark, store };    },};复制代码&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;span&gt;2. vue-js-modal&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;这是一个易于使用、高度可定制的 Vue.js 模态库，该库支持静态和动态两种类型的模态，静态是通过模板明确定义的，动态是根据传递给“显示模态”函数的配置生成的。这个库在 Github 上有超过 &lt;code&gt;4.2k&lt;/code&gt; 星。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1162790697674418&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TZL4BdZpLdjpwPfAfiaDWibzfb2uDicfgvk1mYdL9USnthAtJxotPHic6XWlYebicPiavGxV7yy6kQLev1UMD6X4M5gw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;430&quot;/&gt;&lt;figcaption&gt;vue-js-modal.gif&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;3. vue-wait&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;这个库可以在没有任何冲突的情况下控制页面上的各种加载状态。它的核心原理是管理一个具有多个加载状态的数组（或者，可选地，一个 Vuex 存储）。集成加载器组件开始监听其注册的加载器并立即进入加载状态。这个库在 Github 上有超过 &lt;code&gt;1.9k&lt;/code&gt; 颗星。&lt;/p&gt;&lt;figure&gt;&lt;br/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;4. good-table&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;表格是软件开发中最常用的组件之一，这是一个易于使用的强大数据表，具有高级自定义功能，包括排序、列过滤、分页、分组等。它在 GitHub 上拥有超过 &lt;code&gt;2k&lt;/code&gt; 星。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;5. vue-notification&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;向用户显示消息是应用程序的基本功能之一，这个库将帮助构建漂亮的通知。它提供了许多功能，如动画、自定义位置、自定义样式等等。这个库在 Github 上有超过 &lt;code&gt;2.3K&lt;/code&gt; 颗星。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2060301507537687&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TZL4BdZpLdjpwPfAfiaDWibzfb2uDicfgvkUwiaBlicmWWKosKxE2S6oRa37ichHMbtxlVhRVUbB8V4aAUD5HHHmKoJQ/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;398&quot;/&gt;&lt;figcaption&gt;vue-notification.gif&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;GitHub：&lt;span&gt;github.com/euvl/vue-no…&lt;/span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;6. tree select&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;顾名思义，这是一个带有嵌套选项的多选组件。它包括许多功能，如支持嵌套选项的单选和多选、模糊匹配、异步搜索、延迟加载（仅在需要时加载深层选项的数据）等等。它在 GitHub 上拥有超过 &lt;code&gt;2.6K&lt;/code&gt; 颗星。&lt;/p&gt;&lt;p&gt;GitHub：&lt;span&gt;github.com/riophae/vue…&lt;/span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;7. egjs-infinite grid&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;如果必须使用网格布局，那么这个库是一个很好的资源，该库用于根据网格类型无限排列包括内容的元素。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.580253723110866&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TZL4BdZpLdjpwPfAfiaDWibzfb2uDicfgvkdPF8QAX3iaXmtiat0ClLlFjpfM4PAsYyVRrA2hH3K9c9lwwEfXFek1lA/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1813&quot;/&gt;&lt;figcaption&gt;grid.jpg&lt;/figcaption&gt;&lt;/figure&gt;&lt;pre&gt;&lt;code&gt;import { MasonryInfiniteGrid } from &lt;span&gt;&quot;@egjs/infinitegrid&quot;&lt;/span&gt;;&lt;span&gt;function&lt;/span&gt; getItems(nextGroupKey, count) {    const nextItems = [];    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;let&lt;/span&gt; i = 0; i &amp;lt; count; ++i) {        const num = nextGroupKey * count + i;        nextItems.push(`&amp;lt;div class=&lt;span&gt;&quot;item&quot;&lt;/span&gt;&amp;gt;&amp;lt;/div&amp;gt;`);    }    &lt;span&gt;return&lt;/span&gt; nextItems;}const ig = new MasonryInfiniteGrid(&lt;span&gt;&quot;.container&quot;&lt;/span&gt;, {    gap: 5,});ig.on(&lt;span&gt;&quot;requestAppend&quot;&lt;/span&gt;, (e) =&amp;gt; {    const nextGroupKey = (+e.groupKey || 0) + 1;    ig.append(getItems(nextGroupKey, 10), nextGroupKey);});ig.renderItems();复制代码&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;作者：天行无忌&lt;/p&gt;&lt;p&gt;链接：https://juejin.cn/post/7175905647018377277&lt;/p&gt;&lt;p&gt;来源：稀土掘金&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;span&gt;结语&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;我是林三心，一个热心的前端菜鸟程序员。如果你上进，喜欢前端，想学习前端，那咱们可以交朋友，一起摸鱼哈哈，摸鱼群，关注我，拉你进群，有5000多名前端小伙伴在等着一起学习哦 --&amp;gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;模拟面试、简历指导可私信找我，价格超级实惠~&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6d101f99d8c6cc30aceb4762462b0984</guid>
<title>面试官：谈谈 Tomcat 架构及启动过程，我一脸懵逼。。</title>
<link>https://toutiao.io/k/uebwias</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;pre&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-paragraph-type=&quot;ignored&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-paragraph-type=&quot;ignored&quot;&gt;&lt;section&gt;&lt;span&gt;点击上方 &lt;/span&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;java那些事 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，选择 &lt;/span&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;星标 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;公众号&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;pre&gt;&lt;pre&gt;&lt;section&gt;&lt;span&gt;重磅资讯，干货，第一时间送达&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;---&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/h4&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个题目命的其实是很大的，写的时候还是很忐忑的，但我尽可能把这个过程描述清楚。因为这是读过源码以后写的总结，在写的过程中可能会忽略一些前提条件，如果有哪些比较突兀就出现，或不好理解的地方可以给我提 Issue，我会尽快补充修订相关内容。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多东西在时序图中体现的已经非常清楚了，没有必要再一步一步的作介绍，所以本文以图为主，然后对部分内容加以简单解释。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;绘制图形使用的工具是 PlantUML + Visual Studio Code + PlantUML Extension&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文对 Tomcat 的介绍以 Tomcat-9.0.0.M22 为标准。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247507113&amp;amp;idx=1&amp;amp;sn=90d0fb468bfadcd07c68625110c5fd32&amp;amp;chksm=ea5f11cfdd2898d96b5a0b2d171300ffaea38c8baa4672f5bf50b61a06c9a6584411151f1e56&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;https://tomcat.apache.org/tomcat-9.0-doc/index.html&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;https://tomcat.apache.org/tomcat-9.0-doc/index.html&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Overview&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-backh=&quot;634&quot; data-backw=&quot;558&quot; data-croporisrc=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TNUwKhV0JpS3nRJsYhb2p3LsNLBWdmTQ3CtEdopnlbHGVPa8GqeN9dF61y2DmHsereazOBFKvC4YEWgx6aQQnQ/640?wx_fmt=jpeg&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;932&quot; data-cropy1=&quot;0&quot; data-cropy2=&quot;1002.9284627092848&quot; data-ratio=&quot;1.0751072961373391&quot; data-type=&quot;jpeg&quot; data-w=&quot;932&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/9mQQWOf4KRLM1JEiaDiaMk1WcYsrmfIEqPgjEmeBRnOk2o08gro3gzc0W3Dd7S3anrNA4TqWeicXUnwVVnAsPw8qw/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Bootstrap 作为 Tomcat 对外界的启动类,在 $CATALINA_BASE/bin 目录下，它通过反射创建 Catalina 的实例并对其进行初始化及启动。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Catalina 解析 $CATALINA_BASE/conf/server.xml 文件并创建 StandardServer、StandardService、StandardEngine、StandardHost 等&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardServer 代表的是整个 Servlet 容器，他包含一个或多个 StandardService&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardService 包含一个或多个 Connector，和一个 Engine，Connector 和 Engine 都是在解析 conf/server.xml 文件时创建的，Engine 在 Tomcat 的标准实现是 StandardEngine&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MapperListener 实现了 LifecycleListener 和 ContainerListener 接口用于监听容器事件和生命周期事件。该监听器实例监听所有的容器，包括 StandardEngine、StandardHost、StandardContext、StandardWrapper，当容器有变动时，注册容器到 Mapper。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Mapper 维护了 URL 到容器的映射关系。当请求到来时会根据 Mapper 中的映射信息决定将请求映射到哪一个 Host、Context、Wrapper。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Http11NioProtocol 用于处理 HTTP/1.1 的请求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;NioEndpoint 是连接的端点，在请求处理流程中该类是核心类，会重点介绍。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;CoyoteAdapter 用于将请求从 Connctor 交给 Container 处理。使 Connctor 和 Container 解耦。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardEngine 代表的是 Servlet 引擎，用于处理 Connector 接受的 Request。包含一个或多个 Host（虚拟主机）, Host 的标准实现是 StandardHost。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardHost 代表的是虚拟主机，用于部署该虚拟主机上的应用程序。通常包含多个 Context (Context 在 Tomcat 中代表应用程序)。Context 在 Tomcat 中的标准实现是 StandardContext。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardContext 代表一个独立的应用程序，通常包含多个 Wrapper，一个 Wrapper 容器封装了一个 Servlet，Wrapper的标准实现是 StandardWrapper。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardPipeline 组件代表一个流水线，与 Valve（阀）结合，用于处理请求。StandardPipeline 中含有多个 Valve， 当需要处理请求时，会逐一调用 Valve 的 invoke 方法对 Request 和 Response 进行处理。特别的，其中有一个特殊的 Valve 叫 basicValve,每一个标准容器都有一个指定的 BasicValve，他们做的是最核心的工作。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;StandardEngine 的是 StandardEngineValve，他用来将 Request 映射到指定的 Host;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardHost 的是 StandardHostValve, 他用来将 Request 映射到指定的 Context;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardContext 的是 StandardContextValve，它用来将 Request 映射到指定的 Wrapper；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StandardWrapper 的是 StandardWrapperValve，他用来加载 Rquest 所指定的 Servlet,并调用 Servlet 的 Service 方法。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Tomcat init&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6666666666666666&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TNUwKhV0JpS3nRJsYhb2p3LsNLBWdmTQQtY4X0nP1nDJbLRvz3hmJPw5zNcC2bNIYwTjoskzwia698Fm1vE1sOQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;通过从 CatalinaProperties 类中获取 common.loader 等属性，获得类加载器的扫描仓库。CatalinaProperties 类在的静态块中调用了 loadProperties() 方法，从 conf/catalina.properties 文件中加载了属性.(即在类创建的时候属性就已经加载好了)。&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;通过 ClassLoaderFactory 创建 URLClassLoader 的实例&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;EngineConfig。LifecycleListener 的实现类,触发 Engine 的生命周期事件后调用，这个监听器没有特别大的作用，就是打印一下日志&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;HostConfig。LifecycleListener 的实现类，触发 Host 的生命周期事件后调用。这个监听器的作用就是部署应用程序，这包括 conf/&lt;/span&gt;&lt;/a&gt;&lt;engine&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;/&lt;/span&gt;&lt;/a&gt;&lt;host&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;/ 目录下所有的 Context xml 文件 和 webapps 目录下的应用程序，不管是 war 文件还是已解压的目录。另外后台进程对应用程序的热部署也是由该监听器负责的。&lt;/span&gt;&lt;/a&gt;&lt;/host&gt;&lt;/engine&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505653&amp;amp;idx=2&amp;amp;sn=0de924fc385f24e8920b015af9dc4d88&amp;amp;chksm=ea5f1b93dd2892859344750ab4aef13c0d16feb8a4c58f9f59b6e6e7474e3ac0de9481630535&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;ContextConfig。LifecycleListener 的实现类，触发 Context 的生命周期事件时调用。这个监听器的作用是配置应用程序，它会读取并合并 conf/web.xml 和 应用程序的 web.xml，分析 /WEB-INF/classes/ 和 /WEB-INF/lib/*.jar中的 Class 文件的注解，将其中所有的 Servlet、ServletMapping、Filter、FilterMapping、Listener 都配置到 StandardContext 中，以备后期使用。当然了 web.xml 中还有一些其他的应用程序参数，最后都会一并配置到 StandardContext 中。&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Tomcat Start[Deployment]&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6666666666666666&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TNUwKhV0JpS3nRJsYhb2p3LsNLBWdmTQQtY4X0nP1nDJbLRvz3hmJPw5zNcC2bNIYwTjoskzwia698Fm1vE1sOQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505575&amp;amp;idx=1&amp;amp;sn=fea1514a1918c1721f38a01557eabb1b&amp;amp;chksm=ea5f1bc1dd2892d7678d54d3529d82e408ae37bdf39d50c75ed3a40f116ce3a1b24f1044cca6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图中从 StandardHost Start StandardContext 的这步其实在真正的执行流程中会直接跳过，因为 conf/server.xml 文件中并没有配置任何的 Context，所以在 findChildren() 查找子容器时会返回空数组，所以之后遍历子容器来启动子容器的 for 循环就直接跳过了。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;解析 $CATALINA_BASE/conf/&lt;/span&gt;&lt;/a&gt;&lt;engine&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505575&amp;amp;idx=1&amp;amp;sn=fea1514a1918c1721f38a01557eabb1b&amp;amp;chksm=ea5f1bc1dd2892d7678d54d3529d82e408ae37bdf39d50c75ed3a40f116ce3a1b24f1044cca6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图中从 StandardHost Start StandardContext 的这步其实在真正的执行流程中会直接跳过，因为 conf/server.xml 文件中并没有配置任何的 Context，所以在 findChildren() 查找子容器时会返回空数组，所以之后遍历子容器来启动子容器的 for 循环就直接跳过了。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;/&lt;/span&gt;&lt;/a&gt;&lt;host&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505575&amp;amp;idx=1&amp;amp;sn=fea1514a1918c1721f38a01557eabb1b&amp;amp;chksm=ea5f1bc1dd2892d7678d54d3529d82e408ae37bdf39d50c75ed3a40f116ce3a1b24f1044cca6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图中从 StandardHost Start StandardContext 的这步其实在真正的执行流程中会直接跳过，因为 conf/server.xml 文件中并没有配置任何的 Context，所以在 findChildren() 查找子容器时会返回空数组，所以之后遍历子容器来启动子容器的 for 循环就直接跳过了。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;/ 目录下所有定义 Context 的 XML 文件，并添加到 StandardHost。这些 XML 文件称为应用程序描述符。正因为如此，我们可以配置一个虚拟路径来保存应用程序中用到的图片，详细的配置过程请参考 开发环境配置指南 – 6.3. 配置图片存放目录&lt;/span&gt;&lt;/a&gt;&lt;/host&gt;&lt;/engine&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505575&amp;amp;idx=1&amp;amp;sn=fea1514a1918c1721f38a01557eabb1b&amp;amp;chksm=ea5f1bc1dd2892d7678d54d3529d82e408ae37bdf39d50c75ed3a40f116ce3a1b24f1044cca6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图中从 StandardHost Start StandardContext 的这步其实在真正的执行流程中会直接跳过，因为 conf/server.xml 文件中并没有配置任何的 Context，所以在 findChildren() 查找子容器时会返回空数组，所以之后遍历子容器来启动子容器的 for 循环就直接跳过了。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;部署 $CATALINA_BASE/webapps 下所有的 WAR 文件，并添加到 StandardHost。&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505575&amp;amp;idx=1&amp;amp;sn=fea1514a1918c1721f38a01557eabb1b&amp;amp;chksm=ea5f1bc1dd2892d7678d54d3529d82e408ae37bdf39d50c75ed3a40f116ce3a1b24f1044cca6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图中从 StandardHost Start StandardContext 的这步其实在真正的执行流程中会直接跳过，因为 conf/server.xml 文件中并没有配置任何的 Context，所以在 findChildren() 查找子容器时会返回空数组，所以之后遍历子容器来启动子容器的 for 循环就直接跳过了。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;部署 $CATALINA_BASE/webapps 下所有已解压的目录，并添加到 StandardHost。&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;特别的，添加到 StandardHost 时，会直接调用 StandardContext 的 start() 方法来启动应用程序。启动应用程序步骤请看 Context Start 一节。另外，MySQL 系列面试题和答案全部整理好了，微信搜索互联网架构师，在后台发送：2T，可以在线阅读。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505146&amp;amp;idx=2&amp;amp;sn=0c6c3fd1637f23b1e0eb2596e6b5fb45&amp;amp;chksm=ea5f199cdd28908a258d4450c0960cd85237608c0c09ab26a9c56680668b77b28169f048356c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;在 StandardEngine 和 StandardContext 启动时都会调用各自的 threadStart() 方法，该方法会创建一个新的后台线程来处理该该容器和子容器及容器内各组件的后台事件。StandardEngine 会直接创建一个后台线程，StandardContext 默认是不创建的，和 StandardEngine 共用同一个。后台线程处理机制是周期调用组件的 backgroundProcess() 方法。详情请看 Background process 一节。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;addListeners(engine) 方法会将该监听器添加到 StandardEngine 和它的所有子容器中&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505146&amp;amp;idx=2&amp;amp;sn=0c6c3fd1637f23b1e0eb2596e6b5fb45&amp;amp;chksm=ea5f199cdd28908a258d4450c0960cd85237608c0c09ab26a9c56680668b77b28169f048356c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;在 StandardEngine 和 StandardContext 启动时都会调用各自的 threadStart() 方法，该方法会创建一个新的后台线程来处理该该容器和子容器及容器内各组件的后台事件。StandardEngine 会直接创建一个后台线程，StandardContext 默认是不创建的，和 StandardEngine 共用同一个。后台线程处理机制是周期调用组件的 backgroundProcess() 方法。详情请看 Background process 一节。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;registerHost() 会注册所有的 Host 和他们的子容器到 Mapper 中，方便后期请求处理时使用。&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247505146&amp;amp;idx=2&amp;amp;sn=0c6c3fd1637f23b1e0eb2596e6b5fb45&amp;amp;chksm=ea5f199cdd28908a258d4450c0960cd85237608c0c09ab26a9c56680668b77b28169f048356c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;在 StandardEngine 和 StandardContext 启动时都会调用各自的 threadStart() 方法，该方法会创建一个新的后台线程来处理该该容器和子容器及容器内各组件的后台事件。StandardEngine 会直接创建一个后台线程，StandardContext 默认是不创建的，和 StandardEngine 共用同一个。后台线程处理机制是周期调用组件的 backgroundProcess() 方法。详情请看 Background process 一节。&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;当有新的应用(StandardContext)添加进来后，会触发 Host 的容器事件，然后通过 MapperListener 将新应用的映射注册到 Mapper 中。&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Context Start&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6222222222222222&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TNUwKhV0JpS3nRJsYhb2p3LsNLBWdmTQozgkm8bC6OKLmA19piau4cD383Ecea2KqLxXAFeFWboyUt3d31fk3KQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;StandRoot 类实现了 WebResourceRoot 接口，它容纳了一个应用程序的所有资源，通俗的来说就是部署到 webapps 目录下对应 Context 的目录里的所有资源。因为我对 Tomcat 的资源管理部分暂时不是很感兴趣，所以资源管理相关类只是做了简单了解，并没有深入研究源代码。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;resourceStart() 方法会对 StandardRoot 进行初始配置&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;postWorkDirectory() 用于创建对应的工作目录 $CATALINA_BASE/work/&lt;engine&gt;/&lt;host&gt;/&lt;context&gt;, 该目录用于存放临时文件。&lt;/context&gt;&lt;/host&gt;&lt;/engine&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StardardContext 只是一个容器，而 ApplicationContext 则是一个应用程序真正的运行环境，相关类及操作会在请求处理流程看完以后进行补充。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;StardardContext 触发 CONFIGURE_START_EVENT 生命周期事件，ContextConfig 开始调用 configureStart() 对应用程序进行配置。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;这个过程会解析并合并 conf/web.xml &amp;amp; conf/&lt;engine&gt;/&lt;host&gt;/web.xml.default &amp;amp; webapps/&lt;context&gt;/WEB-INF/web.xml 中的配置。&lt;/context&gt;&lt;/host&gt;&lt;/engine&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;配置配置文件中的参数到 StandardContext, 其中主要的包括 Servlet、Filter、Listener。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;因为从 Servlet3.0 以后是直接支持注解的，所以服务器必须能够处理加了注解的类。Tomcat 通过分析 WEB-INF/classes/ 中的 Class 文件和 WEB-INF/lib/ 下的 jar 包将扫描到的 Servlet、Filter、Listerner 注册到 StandardContext。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;setConfigured(true)，是非常关键的一个操作，它标识了 Context 的成功配置，若未设置该值为 true 的话，Context 会启动失败。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Background process&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.49444444444444446&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/TNUwKhV0JpS3nRJsYhb2p3LsNLBWdmTQl7fSUKbEMs4yv2ic3KxPkxc8BrtKWuO8rpibPKzwbcRiaMSTjUkVH5NZQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;后台进程的作用就是处理一下 Servlet 引擎中的周期性事件，处理周期默认是 10s。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;特别的 StandardHost 的 backgroundProcess() 方法会触发 Host 的 PERIODIC_EVENT 生命周期事件。然后 HostConfig 会调用其 check() 方法对已加载并进行过重新部署的应用程序进行 reload 或对新部署的应用程序进行热部署。热部署跟之前介绍的部署步骤一致， reload() 过程只是简单的顺序调用 setPause(true)、stop()、start()、setPause(false)，其中 setPause(true) 的作用是暂时停止接受请求。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;How to read excellent open source projects&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247507170&amp;amp;idx=1&amp;amp;sn=bde225ad3ce570c98c8d8e636b9f4991&amp;amp;chksm=ea5f1184dd289892c61a068961d382123721fd3ac23ddb3a208104ba80454f62c8b079394470&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;真正的第一次阅读开源项目源代码，收获还是很大的。让我在架构设计、面向对象思想、设计模式、Clean Code等等各个方面都有了进步。阅读优秀的开源项目其实是一件很爽的事，因为时不时的会发现一个新的设计思路，然后不由自主的感叹一声居然还可以这样！&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;真正的第一次阅读开源项目源代码，收获还是很大的。让我在架构设计、面向对象思想、设计模式、Clean Code等等各个方面都有了进步。阅读优秀的开源项目其实是一件很爽的事，因为时不时的会发现一个新的设计思路，然后不由自主的感叹一声居然还可以这样！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MTIzMzY3Mw==&amp;amp;mid=2247507170&amp;amp;idx=1&amp;amp;sn=bde225ad3ce570c98c8d8e636b9f4991&amp;amp;chksm=ea5f1184dd289892c61a068961d382123721fd3ac23ddb3a208104ba80454f62c8b079394470&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;真正的第一次阅读开源项目源代码，收获还是很大的。让我在架构设计、面向对象思想、设计模式、Clean Code等等各个方面都有了进步。阅读优秀的开源项目其实是一件很爽的事，因为时不时的会发现一个新的设计思路，然后不由自主的感叹一声居然还可以这样！&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;当然了，读的时候还是会有一些痛点的，比如说碰到一个变量，但是死活就是找不到初始化的位置，有时通过 Find Usage 工具可以找到，但有些找不到的只能从头开始再过一边源码。有时碰到一个设计思路死活都想不明白为什么这样设计等等，这种情况就只能通过分析更高一层的架构来解决了等等。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;下面我简单分享一下我是如何阅读开源项目源码的。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;先找一些介绍该项目架构的书籍来看，项目架构是项目核心中的核心，读架构读的是高层次的设计思路，读源码读的是低层次的实现细节。有了高层次的设计思路做指导，源码读起来才会得心应手，因为读的时候心里很清楚现在在读的源码在整个项目架构中处于什么位置。我在读 Tomcat 源码之前先把 《How Tomcat works》 一书过了一边，然后又看了一下 《Tomcat 架构解析》 的第二章，对 Tomcat 的架构有了初步了解。（PS:《How Tomcat works》一书是全英文的，但读起来非常流畅，虽然它是基于 Tomcat 4 和 5 的，但 Tomcat 架构没有非常大的变化，新版的 Tomcat 只是增加了一些组件，如果你要学习 Tomcat 的话，首推这本书！）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果实在找不到讲架构的书，那就自己动手画类图吧！一般来说，开源项目都是为了提供服务的，我们把提供服务的流程作为主线来分析源代码，这样目的性会更强一些，将该流程中涉及到的类画到类图中，最后得到的类图就是架构！不过分析之前你要先找到流程的入口点，否则分析就无从开始。以 Tomcat 为例，他的主线流程大致可以分为 3 个：启动、部署、请求处理。他们的入口点就是 Bootstrap 类和 接受请求的 Acceptor 类！&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;有了阅读思路我们下面来说说工具吧。我使用的阅读工具是 IntelliJ IDEA，一款十分强大的 IDE，可能比较重量级，如果你有其他更加轻量级的 Linux 平台源码阅读工具，可以推荐给我～&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;Structure 栏目可以自定义列出类中的域、方法，然后还可以按照继承结构对域和方法进行分组，这样就可以直接看出来域和方法是在继承结构中哪个类里定义的。当你点击方法和域时，还可以自动滚动到源代码等等。&lt;/p&gt;&lt;p&gt;在源代码中 点击右键 -&amp;gt; Diagrams -&amp;gt; show Diagram 可以显示类的继承结构，图中包含了该类所有的祖先和所有的接口。在该图中选择指定的父类和接口，点击右键 -&amp;gt; show Implementations， IDEA 会列出接口的实现类或该类的子类。&lt;/p&gt;&lt;p&gt;FindUsage、Go To Declaration 等等就不再多说了。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;更多精彩内容，&lt;strong&gt;关注我们&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;▼▼&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile data-weui-theme=&quot;light&quot; class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-id=&quot;MjM5MTM0NjQ2MQ==&quot; data-pluginname=&quot;mpprofile&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/jNmCBexQlC5YGTbia3dRd6YFXWAlPsJK3gZQap6oK8Vk7BLiaBbsvq3BwicyEKwJiaIfeAYXzucAvXP00PKQKVLzJQ/0?wx_fmt=png&quot; data-nickname=&quot;java那些事&quot; data-alias=&quot;csh624366188&quot; data-signature=&quot;分享java开发中常用的技术，分享软件开发中各种新技术的应用方法。每天推送java技术相关或者互联网相关文章。关注“java那些事”，让自己做一个潮流的java技术人！《java程序员由笨鸟到菜鸟》系列文章火热更新中。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;如果看到这里，说明你喜欢这篇文章，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;标星（置顶）&lt;/span&gt;&lt;span&gt;本公众号可以第一时间接受到博文推送。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt; “分享、点赞&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;在看” 支持一波&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/lolOWBY1tkwzw3lDgVHOcuEv7IVq2gCXN5rPlfruYGicNRAP8M5fbZZk7VHjtM8Yv1XVjLFxXnrCQKicmser8veQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;64&quot;/&gt; &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>