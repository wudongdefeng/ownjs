<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ba72e519805f51ba6690b8a27e95e1aa</guid>
<title>OpenAI 掌门人：关于获得非凡成就的 13 条思考</title>
<link>https://toutiao.io/k/hzrip1v</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;殿堂级风险投资人、硅谷创业教父、YC创始人Paul Graham对Sam Altman极度称赞，并在2014年选择Sam作为他的继任者。&lt;/span&gt;&lt;span&gt;要知道YC在当时的硅谷极有号召力，而Sam成为YC的新任掌门人时还不到30岁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Paul的眼里，Sam是最优秀以及最具有战略野心的超级个体标杆。Sam的野心表现在他对很多 YC 公司打造产品的具体细节缺乏兴趣，他更关注这些产品对世界会产生的潜在影响。Sam Altman高效、直接，他的强大之处是他清晰的思维，以及能迅速掌握一个复杂事物的直觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天推荐的这篇内容源自Sam Altman三年前的一篇博文，今天来看依旧非常有启发且适用。作为YC曾经的掌门人，Sam观察了成千上万富有创造力的创业者，并与这个星球上最优秀的一批创始人保持深度的交流和合作。基于这些大量的观察和思考，Sam总结了13条关于如何获得非凡成就的思考。我认为在一定程度上这13条思考也折射了Sam的人生算法，常读常新，所以我建议可以收藏后，间隔的多读几遍，相信会给你带来启发和价值，Enjoy：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我观察了成千上万的创业者，思考了很多关于如何才能赚到大钱或是创造出有意义的事业。通常，人们一开始想要的是赚大钱，而后想要的是成就一番伟业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是关于如何获得非凡成就的13条思考。如果你是已经取得了一定成就基础（不管是因为幸运的出身带来的特权还是后天个人努力取得的），并且想要投入工作将其转化为非凡成就，那么这些建议对你来说会更容易实现。不过总的来说，大部分内容适用于任何人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01：善用“复利效应”加持人生&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“复利效应”如同魔法一样具有神奇魔力，你会发现它无处不在。指数曲线的发展模型，是吃透红利创造财富的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个市值年增长率达50%的中型企业在很短的时间内就可以发展壮大。然而，世界上很少有企业能拥有真正的网络效应和极高规模化扩张的能力。但随着科技的发展，这样的企业会越来越多。想要发掘和创造出这样的企业，背后需要我们付出极大的努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你自身的发展希望也符合指数型增长的曲线——你为自己人生设定的目标应该是遵循一个不断向上增长的正确轨迹前行。在一个符合复利效应的职业道路上前进是非常有价值的，因为大多数职业都是线性发展的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你肯定不想在一个工作两年和工作二十年无差别的职业上碌碌无为——你应该一直保持着高速的学习状态。随着你事业的发展，你所做的每一项工作都应该产出越来越多的成果。有很多方法可以达到这样的杠杆效果，比如资本、科技、品牌、网络效应和管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专注于将自己所定义的成功指标再提升一个数量级是非常有效的，不管这些指标是金钱、地位、对世界的影响力还是其他等等。我愿意在项目之间花尽可能多的时间，去确定我下一步做什么。但我特别希望能找到那种“一旦成功，将使我的职业生涯其余部分看起来都像是铺垫”的大项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人都陷入在那些只能线性增长的机会中，但不要丢了西瓜捡芝麻，你要专注在实现指数型增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;我认为，无论是对公司还是对个人的职业生涯来说，&lt;/span&gt;&lt;span&gt;商业中最大的竞争优势是，要有长远的思考——能从广阔的视角去理解如何将世界上不同体系进行整合。&lt;/span&gt;&lt;span&gt;复利增长最显著的特点之一是，未来之后的几年才是最重要的。这个世界很少人能做到将眼光放长远，而那些有长远眼光的人会得到市场的丰厚回报。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相信复利效应的指数力量，保持耐心，最终你将收获惊喜。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02：保持蜜汁自信&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自信的力量是非常强大的。我所认识的最成功的人，他们极度相信自己几乎到了“蜜汁自信”的地步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;越早培养这种自信心越好。随着你掌握的经验和数据越来越多，它们证明你的判断是正确的，并且你不断得到正向结果反馈的时候，你可以更加相信你自己。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你不相信自己，就很难让自己对未来产生不一样的逆向思维。而与众不同的观点恰恰能创造最多的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我记得多年前埃隆·马斯克 (Elon Musk) 带我参观SpaceX工厂的时候，他非常细致地讲解了制造火箭的每一个部件。但最让我印象深刻的是，当他谈到要将大型火箭发射至火星时，脸上那种坚定的神情。我当时就在想：“啊，坚定做一件事的样子就该是这样的。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何管理好自己的斗志以及团队的士气，是大多数人在努力过程中遇到的最大挑战之一。如果没有足够的自信，这几乎是不可能处理好的。不幸的是，你越有野心，这个世界就越要把你打倒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数成功人士应该至少会有一次面对他人不看好，但最终证明他对未来的预判是正确的经历。如若不然，他们其实会面临更多的竞争。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自信必须与自知相平衡。之前我很讨厌别人任何形式的批评，并有意识地避免这些批评。现在我会试着去听取批评并假设这些批评都是对的，然后决定我是否要采取行动。寻求真理往往是艰难且痛苦的，但也正是真理将自信和自欺区分开来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种自信和自知的平衡也会避免给人留下“清高”和不接地气的形象。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03：学会独立思&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;考&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;教会别人如何创业是一件非常困难的事，因为你很难教别人如何产生原创想法。授人以鱼易，但授人以渔难。学校并不是为了教授学生自主思考而设立的，事实上学校传递的思想通常是相反的。所以你得自己培养独立思考的思维模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于第一性原理去思考，并尝试产生新的想法是很有趣的过程，而在这个过程中找到可以与之交换彼此看法的人，可以帮助自己更好地思考。之后则是在现实世界中找到简单又快速的方法来验证这些想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;“我有可能会失败很多次，但我一定能成功一次”&lt;/span&gt;&lt;span&gt;这便是创业者精神。在获得幸运眷顾之前，你必须要给自己足够多的机会来尝试。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些失败和尝试带来的最重要的经验教训是，山穷水尽疑无路，柳暗花明又一村，即使前方看起来并无解决之道，处在绝境中你能找到出路。你这样做的次数越多，你就越会相信自己能找到出路。而相信的勇气来自于，你知道自己被击倒后还能重新站起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;04：擅长“推销”&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅仅有自信是不够的，你还必须能够说服别人相信你所相信的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有伟大的事业，在某种程度上都属于推销工作。你必须向客户、潜在员工、媒体、投资者等传达你的理念和计划。这就需要有令人眼前一亮的愿景，强大的沟通技巧，一定程度的领袖魅力和执行能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提升沟通能力是非常值得去做的投资，尤其是提高书面沟通能力。要想清晰地表达自己，对此我能给出的最佳建议是，首先确保你的思路清晰，然后用简洁扼要的语言表达出来&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;要想提高销售能力，最好的办法就是发自内心地相信你所推销的东西。&lt;/span&gt;&lt;span&gt;推销你真正认可的东西会感觉很愉快，而推销“水货”会让你感觉很糟糕。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提高销售能力与提高其他技能一样，任何人都可以通过刻意练习来获得进步。但出于某种原因，也许是因为推销的过程让人反感，许多人认为他们学不会推销技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我另一个重要的推销心得是，重要场合一定要亲自到场面谈。当我刚开始创业的时候，我非常愿意搭上飞机说走就走。其实很多时候不必这么大费周章，但有三次，这么勤快地走动为我的事业生涯带来了转折点，否则我的职业生涯可能会走向另一个方向，变得完全不同。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;05：让冒险变得容易&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;大多数人做事高估了风险而低估了回报。&lt;/span&gt;&lt;span&gt;冒险之所以重要是因为你不可能永远都是对的——你必须得多尝试很多事情，并在学习的过程中迅速适应它们。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在创业早期，冒险通常是比较容易的。冒险失败了，你也没有太多能失去的东西，但冒险成功了，你却有可能受益很多。在确保自己做好本职义务且让自己有保障的情况下，你就应该更轻松地去尝试冒险。你可以先小试牛刀，如果错了你输1x，如果成功了就能赢得100x收益。接下来你就可以朝这个方向押注更多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;不要在舒适区待太久。在YC，我们经常注意到那些花了很多时间在Google或Facebook工作的创始人都有这么一个通病。当人们习惯了舒适的生活，稳定的工作，以及在自己所做事业上拥有成功的声誉时，就很难把这些东西抛在身后（而且人们有一种不可思议的能力，不管第二年的薪水是多少，他们总能找到相匹配的生活方式）。即使这些人真的离开了舒适区，回归安逸的诱惑也变得非常大。&lt;/span&gt;&lt;span&gt;比起长远利益成就，人们更容易优先考虑短期利益和便利性，这也是人的本性所趋。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但当你不再重复单调乏味的工作时，你可以跟随自己的直觉，把时间花在可能真正有趣的事情上。尽可能地让你的生活保持朴素和灵活性是一种有效的方法，但显然，安逸生活和长远成就不可兼得，你需要进行取舍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;06：保持专注&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专注是工作的助力器，专注可以让工作事半功倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;几乎所有我认识的那些愿意花更多时间思考应该对什么事情保持专注的人，都从中受益匪浅。&lt;/span&gt;&lt;span&gt;把时间花在做正确的事上，比花长时间进行工作更重要。&lt;/span&gt;&lt;span&gt;大多数人把大部分时间浪费在无关紧要的事情上。一旦你弄清楚了要做什么，就马不停蹄地优先完成你那一小部分任务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我还没有遇到过做事拖延却非常成功的人。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;07：努力工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以通过聪明或努力地工作超过你所在领域90%的竞争对手，这已经是很了不起的成就了。但要想超越99%的人，你需要才华和勤奋两者兼具——你的竞争对手不仅非常有才华，有很棒的点子，而且他们任劳任怨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;追求极致的人会收获极致的成果。工作和生活不可兼得，因此如果你不愿为工作牺牲太多私人生活时间，这也是情有可原的。但对工作的付出一定会让你获益匪浅。在大多数情况下，生活与工作相辅相成，生活成功也会带来工作的成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且这通常很有意思。生活中最大的乐趣之一就是找到自己的目标并做到出色，你将会发现你可以影响到更重要的人和事。YC的一位创始人最近分享到，离开一家大公司，并开始真正朝着能发挥自己最大影响力的方向努力，他感到更快乐、更满足。为此付出努力真是太值得了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我不是很理解为什么努力工作反而在美国某些地区成了一件“坏事”，但在世界其他地方肯定不是这样的——在美国之外，其他地方的创业者展现出的精力和干劲，正在迅速成为新一代标杆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;你必须找到如何努力工作而不被工作耗尽的方式。&lt;/span&gt;&lt;span&gt;不同人有他们自己的策略，但有一个几乎都能奏效的策略是，做你喜欢的工作，和志同道合的伙伴一起共事。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为，那些假装在事业上不费吹灰之力（不用花费大量人生精力和时间）就能取得非凡成就的人是在给人一种误导和错觉。事实上，工作耐力似乎是取得长期成功的最大因素之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于努力工作我还有一点想说的：在你职业生涯开端就要努力工作。努力工作就像银行利息，你越早努力，你就能享受更长的受益时间。当你身上其他担子少的时候，你更容易投入地工作，这种情况在年轻时比较常见，但也并不总是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;08：大胆出击&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我相信创立一家充满挑战的公司比创立一家简单的公司要更容易一些。人们都想加入到令人振奋的项目当中，这样他们才能感受到自己的工作其实很重要，很有意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你在重要关口取得了进展，你将得到源源不断的帮助。让自己变得更有雄心壮志，不要害怕去做你真正想做的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如其他人都在创办表情包编辑公司，而你想创办一家基因编辑公司，那就毫不犹豫地放手一搏吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟着你的好奇心走。因为对你来说兴奋的事情对其他人来说也同样兴奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;09：相信心想事成&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;告诉你一个大秘密，你会比你想象中更容易按照你的意愿去改变世界——但大多数人甚至连尝试都没做过，就接受世界就是这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实人是有巨大潜能的，可以改变很多事情。然而自我怀疑、过早放弃、不够努力这些因素结合起来，使得大多数人无法发挥自己的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想要什么就去争取。哪怕大多数情况下你都不能如愿，也许被拒绝的感觉不好受。但当你一旦成功，则会效果惊人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几乎总是那些说“我要坚持下去直到成功为止，不管遇到什么挑战，我都要把它们解决掉”的人能获得成功，因为他们对待所说的都是认真的。他们足够有耐性，坚持得足够久使得好运最终降临。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Airbnb的做法就如我刚刚说的。Airbnb背后可以说的故事太多了（几乎透支了所有的信用卡，每顿都吃廉价的麦片粥充饥，与相关的利益方始终不停的抗争），我不建议照搬他们的做法。不过他们确实在创业生死线上坚持挣扎了很长的时间，直到幸运之神眷顾了他们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要相信心想事成，保持乐观是非常有必要的——这是有望通过练习来改善的品质特征。我从来没有遇到过哪一个非常成功的人是悲观主义者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;10：努力做到难以被超越&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人都明白，公司越难被超越就越有价值。具有高竞争力很重要，而且显然这是大实话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种说法对个人也同样适用。如果你所做的事情可以由别人来做，那么最终你将被更廉价的劳动力给替代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让自己更具有竞争力的最好的办法就是提高自己的影响力。例如，你可以通过创立强大的个人品牌，或者熟悉多个不同的交叉领域来搭建人际关系网络。还有很多其他的策略可以增强竞争力，但你得找到适合自己的并将它实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人会和周围的人做一样的事。这种模仿行为通常是错误的——如果你做的是其他人都在做的事情，那你不见得更具有竞争力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;11：搭建人际网络&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;伟大的事业需要团队合作。建立一个既可以紧密合作又可以宽松相处的优秀人才网络，是完成伟大事业里不可或缺的部分。你成功的上限往往取决于你人才网络的规模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建立人际网络的一个有效方法是尽可能多地帮助他人。在很长一段时间里，我因为尽可能多地帮助他人而从中受益；职业生涯中大部分最好的机会也是因为这样的人际网络；四项最佳投资中的三项投资也是得益于帮助他人。我总是惊讶于好事经常发生在我身上，而最初的起因仅仅是因为十年前我帮助了一位创始人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;树立真正关心工作伙伴的名声也是建立人际网络的方法之一。慷慨地向身边伙伴们分享资源和美好的一面吧，你将收获10倍的回报。同时，要学会知人善任，唯才所宜。(尽管我没有涉猎太多管理方面的书籍，不过这是我从管理学中学到的最重要的一课。)你应该树立的形象是那种督促员工努力，让他们完成超乎他们想象的事情，但又不至于把他们逼到筋疲力尽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个人都有自己的长处。用你的优点来定义自己，而不是你的缺点。承认你的弱点，并找出解决它们的方法，但不要让你的弱点成为你的绊脚石。我最常从其他创业者那里听到的令人吃惊话是，“我做不了X，因为我不擅长Y”，这样的话恰恰反映出他们缺乏创造力。弥补弱点最好的方法是吸纳和你互补的团队成员，而不是只雇佣那些和你一样的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要想搭建好关系网络最重要的是能慧眼识珠，善于发现未被发现的人才。通过实践，你能更容易更快地发现那些富有智慧、动力和创造力的人。要学习这种能力，最简单的方法就是结识更多的人，然后复盘谁给你留下了好印象谁没有。记住，你主要是在挖掘一个人的潜力，不要太看重他们的过往经验或当前的成就。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我新认识一个人的时候，我总是试着问自己，“这个人生来就如此吗？”这一问题极具启发性，能够帮助你找到志同道合，可以一起成就一番事业的伙伴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一个特殊方法可以发展人脉，找到敢于押注你的伯乐，这最好是在你职业生涯早期。毫无疑问，要想实现这一点的最佳方式就是不遗余力让自己变得有价值有用处。（记住，之后要把这份关照传递给更多人！）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，记得把时间花在那些支持你的抱负且积极的人身上。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;12：资产让人更富有&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我儿时对经济学最大的误解是人们是靠高薪致富的。虽然也有一些例外——比如娱乐行业——但纵观福布斯榜的历史，几乎没有人是通过拿高薪跻身榜单的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真正让人变得富有的是拥有能迅速增值的东西。这可以是商业，房地产，自然资源，知识产权，或其他类似的东西。但无论如何，你需要拥有这些东西的股权，而不仅仅靠出售自己的时间。出售时间带来的收益仅仅是线性增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让产品迅速增值的最佳办法是规模化生产人们想要的产品。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;13：成为内驱型的人&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人都是外驱型的人，他们做事的动因是他们想给别人留下深刻印象。这种做法很不好，其中糟糕的两点原因如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，你会试图跟别人保持一致，不管是职业轨迹还是想法。这么做的话，你会无比在意别人对你的看法，可能你都没有意识到你有多在意。这可能会妨碍你找到真正有趣的工作，即使你做了你认为有趣的工作，那也是别人早就做过的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，你很有可能会错误地预估风险。因为在很短的时间内，你的关注点都是在如何追赶别人，确保自己不会在竞争游戏中落后。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;聪明人似乎更容易受到这种外因驱动行为的影响。意识到这一点会对你有所帮助，但是帮助不会太大——你可能需要付出极大的努力，才能避免落入这样的模仿陷阱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我所认识的那些成功人士大多都是内因驱动的，他们所做的事情是为了给自己留下深刻印象，因为他们觉得他们必须要在这世界上有所作为。当你赚到足够多的钱能随便买买买，也获得了足够的社会地位，赚再多的钱和地位对你来说就显得没劲了，而内在驱动则是我所知道的唯一能够继续激励你再创新高的力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是为什么一个人的努力动机如此重要的原因。当我想了解别人，我想了解的第一件事就是他的工作动机。很难定义一套规则来评判什么是正确的动机，但当你遇到的时候你自然就会明白。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jessica Livingston和Paul Graham是我的标杆。YC成立之初备受嘲讽，刚开始的时候，几乎没有人看好，没人认为它会取得巨大的成功。但Jessica和Paul认为，如果YC成功了，对世界来说是一件好事，他们俩喜欢帮助人们，他们也相信他们的新模式比现有的模式更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，你将在你所热爱的领域定义自己的成功，因为只有热爱才能表现出色。越早朝这个方向努力，你就能走得更远。如果没有真正的热爱和痴迷，你很难获得巨大成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzAxMDM3Mg==&amp;amp;mid=2649104265&amp;amp;idx=1&amp;amp;sn=2e1f315def4b2420a2701951137cbd69&amp;amp;chksm=87072222b070ab349ecaffd9f674e27a5556afb03f5b601ff535a9da6340edd092e77dde4499&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;爆火的ChatGPT太强了！马斯克盛赞：好得吓人 | 创干货&quot; linktype=&quot;image&quot; imgurl=&quot;https://mmbiz.qpic.cn/mmbiz_png/heQPgWHHOGhzv4M874kibC1ua1x5njpQdic2xZvQ44SMPZt1FxlrN5Y6opHbMiaDrCahLTAfmPSOy9yXAFM7jhvPA/0?wx_fmt=png&quot; imgdata=&quot;[object Object]&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/heQPgWHHOGhzv4M874kibC1ua1x5njpQdic2xZvQ44SMPZt1FxlrN5Y6opHbMiaDrCahLTAfmPSOy9yXAFM7jhvPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NTE5NzUwMA==&amp;amp;mid=2650983980&amp;amp;idx=1&amp;amp;sn=9a1739540e9c00827790cdf90e01cb3b&amp;amp;chksm=bd0a497f8a7dc069d7daeacd4c03169adc61e08a266da4038204db8392a122e3903012601bc6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;认清现实，专注成长是当下年轻人最好的做法&quot; linktype=&quot;image&quot; imgurl=&quot;http://mmbiz.qpic.cn/mmbiz_png/heQPgWHHOGhzv4M874kibC1ua1x5njpQdUVKjEgRZe0t7q7OIhJYRTNuWcjwA8IlydlK9RndhR8Ys07YZVSZ2xw/0?wx_fmt=png&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/heQPgWHHOGhzv4M874kibC1ua1x5njpQdUVKjEgRZe0t7q7OIhJYRTNuWcjwA8IlydlK9RndhR8Ys07YZVSZ2xw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NTE5NzUwMA==&amp;amp;mid=2650983814&amp;amp;idx=1&amp;amp;sn=f10a5deb59b4dea022a68d3bab1ea9df&amp;amp;chksm=bd0a4ad58a7dc3c32762309e8e9341e6a894062f706ff1cbc83893758bf62baf4757020a5c3b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;李开复预测未来20年：年轻人要寻找工作之外的意义&quot; linktype=&quot;image&quot; imgurl=&quot;http://mmbiz.qpic.cn/mmbiz_png/heQPgWHHOGjTAZGgI2kP341v3QJVjWLInSWCquyiaIrfDTW53tUy2bAmoPzaJluH3ichWqciatuRd7h10ibBbUgznQ/640?wx_fmt=png&quot; imgdata=&quot;[object Object]&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/heQPgWHHOGjTAZGgI2kP341v3QJVjWLInSWCquyiaIrfDTW53tUy2bAmoPzaJluH3ichWqciatuRd7h10ibBbUgznQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ff118749f25cccecdec55b14e4ebd09d</guid>
<title>DevOps 最佳实践之应用开发和部署</title>
<link>https://toutiao.io/k/yfyugiq</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot; itemprop=&quot;articleBody&quot;&gt;&amp;#13;
&lt;h2&gt;关于最佳实践&lt;/h2&gt;
&lt;p&gt;本系列内容是我们在不同项目的维护过程中总结的关于DevOps/SRE方面的最佳实践，我们将致力于在项目上尽最大的努力来推行这些最佳实践。我们希望这些最佳实践能对项目的稳定运营提供帮助，也希望刚接触DevOps/SRE的新人能通过学习这些最佳实践来提升自己在这方面的水平。&lt;/p&gt;
&lt;p&gt;因为DevOps/SRE涉及到的方方面面比较多，一次性完成的工作量太大，所以我们决定分阶段来完成，这一次发布的是“应用开发和部署”这个部分的内容，后续我们将逐步发布“云平台与网络”，“操作系统和服务”，“用户与权限”，“监控与可视化”，“数据与备份”，“敏感数据”，“故障与应急响应”这几部分的内容。&lt;/p&gt;
&lt;p&gt;所谓“最佳实践”应该是最适合自己的实践，而不一定是最先进的，而且每一种实践本身也存在一定的局限性，所以我们在描述了对应实践的优点的同时，也把可能存在的缺点写了出来，就是希望大家在看到它的好处的时候，也能知道可能存在的风险在那里，理性地去评估到底是不是要采用相应的实践，所以这里总结的最佳实践请适度取用，不要为了“最佳”而实践。&lt;/p&gt;
&lt;p&gt;我们深知自己在诸多方面存在一定的局限性，相关的内容可能存在一些不足，而且最佳实践本身会随着技术更新等因素不停地变化，我们将会把蓝皮书内容同步发布在Github上（&lt;a href=&quot;https://github.com/toc-lib/DevOps-SRE-best-practice&quot;&gt;https://github.com/toc-lib/DevOps-SRE-best-practice&lt;/a&gt;） ，希望引发更广范围的传播和讨论。也请使用PR或Issue的方式来提出你的不同的观点和更好的建议，谢谢。&lt;/p&gt;
&lt;h2&gt;应用开发和部署&lt;/h2&gt;
&lt;h3&gt;使用牲口模式&lt;/h3&gt;
&lt;p&gt;在传统的运维环境中，由于条件的限制无法快速的提供新的基础设施和环境，所以通常在业务的依赖环境如操作系统内核，服务，类库，运行时版本等需要变化时，我们会根据需要在现有的环境上做持续性变更。而且我们还可能会在机器上运行一些临时任务，做调试和排错等，很多的时候，这些操作对应的变化并不具有可追溯性，甚至不可以恢复到之前的状态。这样，刚开始统一配置的无差别的一批机器随着时间的推移慢慢的就会变得各自具有一些独有的特性。另外还有一些类型的服务，比如数据库，存储等，其业务本质就导致了集群中的每一台机器具有独特的属性。当我们在维护这些服务的时候，需要根据每台机器的特性来做不同的管理和配置，而且一旦机器出现故障的时候，也很难去创建出一样的机器来替代。因为这种情形和养宠物类似，比如我们会给宠物起一个名字，它也需要悉心照料，生病的时候要带去看病，所以我们称这种服务模式为宠物模式。&lt;/p&gt;
&lt;p&gt;而在具有云原生能力的平台上，我们可以按需定制基础镜像，也能快速的从这个基础镜像中创建出运行环境，我们的变更就可以基于基础镜像来做更新和版本迭代。这样当某一台机器发生了故障，我们可以快速的复制出一台一模一样的机器来替代。如果需要做一些临行性的操作和变化，在任务结束之后，也可以销毁这台已经发生了变化的机器，使用一台新的机器来替代，使整个集群恢复到一个最初的收敛状态。这个场景和我们现实生活中的规模化牲口养殖类似，对应的我们称这种服务模式为牲口模式。&lt;/p&gt;
&lt;p&gt;大家所熟知的无状态应用，就是牲口模式的最常用的一种实现方式。在业务的设计和实施过程中，我们建议把逻辑和数据分离，在逻辑运行环境不要兼顾数据存储工作，比如请求的session相关的数据，不要保存在本地，而是把它放在一个共享数据服务中，从而达到无状态的目的，这样就可以对逻辑运行环境进行牲口化的管理方式。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;可随时被销毁或替换，结合自动化基础设施和监控，自动完成对故障机器或节点的替换。&lt;/li&gt;
&lt;li&gt;配合自动化基础设施和监控，可实现自动水平伸缩，从容应对业务峰谷，节约成本。&lt;/li&gt;
&lt;li&gt;在不影响服务稳定性的前提下可部署所需要版本的应用、进行系统升级或者打补丁。&lt;/li&gt;
&lt;li&gt;监控和管理的重心不再是具体的单一资源的使用率，而是整体的承载能力和更深层次的性能关注点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;需要基础设施平台具有相应的能力支撑，否则很难实现。&lt;/li&gt;
&lt;li&gt;不是所有的业务类型都能做牲口模式设计，比如数据库。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施要点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;除计算和业务处理过程中的临时产生的数据，数据的来源和最终的持久化应由外部服务来提供，如独立的内存型数据库或者关系型数据库。&lt;/li&gt;
&lt;li&gt;可以使用客户端Cookie、cache取代外部数据服务。如果有敏感数据，服务器端可以加密后交由客户端存储，在之后的请求时发回服务器解密使用。&lt;/li&gt;
&lt;li&gt;通过锁或者幂等性设计，使得应用能正确、快速、自动地解决对同一份数据的竞争而导致的流程异常、数据不一致等问题。例如，多个定时任务同时处理一批数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;使业务升级向前兼容&lt;/h3&gt;
&lt;p&gt;向前兼容指低版本的系统、程序或技术能优雅处理（例如：忽略其不理解的部分）高版本的系统、程序或技术。向前兼容技术的目标是让旧系统能够识别为新系统生成的数据，简单的说就是旧版本的系统可以接受新版本的数据，是旧版本对新版本的兼容。&lt;/p&gt;
&lt;p&gt;我们建议在做业务升级时候，设计你的业务具有向前兼容的能力，以应对升级失败时某一功能模块或者依赖无法随之回滚的风险。比如说在有数据库字段变化的升级中，在正式对数据库做变动之前，基于旧的业务流程做代码层面更新，使其可以兼容数据库将要发生的改动并加以部署。在数据库升级完成之后，如果新的业务流程上线后不幸出现重大的问题等情况需要回滚时，回滚之后的代码仍然可以兼容数据库的变化，而不用对数据库也进行回滚，毕竟数据库的回滚成本非常高。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;可以在新版本出现不容易修复和存在重大的风险的时候快速当回滚到旧的版本，业务中断的可能性会大大降低。&lt;/li&gt;
&lt;li&gt;即使整个系统中存在不可回滚的部分，但我们不用花费很多的精力去考虑和解决完全不可回滚的问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;设计成本：要做到兼容未来的变化。这听起来就很难。一开始很难获知所有用例、极端案例和业务理解。回顾过去并说这是一个错误的决定很容易，今天做出明天不会后悔的决定要困难得多。&lt;/li&gt;
&lt;li&gt;为了同时兼容两种数据格式，需要在代码中增加额外的处理逻辑，增加复杂度和投入的成本。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施要点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;select语句只获取需要的字段，避免使用select * from语句，有效防止新增字段对应用逻辑的影响，还能减少对性能的影响。&lt;/li&gt;
&lt;li&gt;对数据库表结构变更通过新增字段实现。&lt;/li&gt;
&lt;li&gt;尽量新增接口，避免对现有接口做修改，如需要修改现有接口，可尝试在接口上增加版本标识。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;使用唯一性标识给镜像打标签&lt;/h3&gt;
&lt;p&gt;当生成容器镜像时，应当使用唯一性标识来给容器镜像打标签，唯一标识可以更好的标记当次生成的镜像，避免出现多个同名标签但不同的版本镜像被使用的情况。例如多次部署都使用了latest标签的镜像，可能因为拉取和缓存策略导致不同节点使用了不同版本的镜像，从而导致功能上的不一致，在这种情况下，并不能很方便地判断出某个节点部署的是哪一个版本。&lt;/p&gt;
&lt;p&gt;唯一标识最好有一定的含义，不仅可以用来区分产物，还可以获取到本次构建的关键信息。比如git提交哈希等关联性比较强的标识。虽然时间戳也是一个唯一性比较强的标识，但是关联性相对较差，如果长度不足，也有一定的几率产生碰撞。可以考虑使用组合型标签，比如使用时间戳，build号，版本号等根据自己的需求来组合生成唯一标识，这样的标签本身就包含了很丰富的信息。&lt;/p&gt;
&lt;p&gt;不建议单纯使用pipeline的build序号来作为镜像的标签，如果需要更换CI工具或者重建pipeline时，这个序号将会被重置而可能产生重复，除非在构建脚本中加入偏移量。而且不同的CI工具获取这个序号的方法也有所不同，对于迁移并不友好。虽然它的可追溯性看起来较好，但是单纯的Build序号和代码之间并没有直接的关联。&lt;/p&gt;
&lt;p&gt;如果不是需要对外公开发布的镜像，并不建议对同一镜像打上多个不同标签。因为绝大部分的情况下，我们只会选用其中一个标签在所有的地方使用，多个标签的实际意义并不会很大。&lt;/p&gt;
&lt;p&gt;如果制品库支持immutable特性，强烈建议开启这个功能，防止因为意外情况导致对已上传的镜像的覆盖。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;可以准确对应的到源代码具体版本，在溯源时可以对应到特定的提交而不是可能存在的多个提交。&lt;/li&gt;
&lt;li&gt;不需要使用SHA256等额外的信息来区分同一标签的不同版本。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;一些类型的唯一性标识可读性不是很高，比如git提交哈希。&lt;/li&gt;
&lt;li&gt;一些类型的标识受时间影响，不能使用同一命令获得一致结果，需要使用其他的方式来传递给后续阶段，比如时间戳。&lt;/li&gt;
&lt;li&gt;制品库immutable功能开启之后，重跑已完成构建镜像的pipeline会发生上传镜像失败的错误，有可能会导致后续任务不能继续。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施示例：&lt;/strong&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env bash

GIT_HASH=$(git rev-parse HEAD)

docker build --rm -t &quot;myapp:${GIT_HASH}&quot; .&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;在所有环境中使用同一个构建产物&lt;/h3&gt;
&lt;p&gt;应该在不同环境中使用相同的构建产物来部署，避免对不同的环境生成不同的构建产物，以确保环境的一致性，同时也保证部署在不同环境中的业务代码是测试和验证通过的。比如某次的构建产物，在测试环境部署后经由测试人员和相关的自动化测试工具完成相关的测试验证，如果没有问题才会继续部署到后续环境中，应继续使用该产物部署后面的环境，不建议重新构建新的产物来做后续环境的部署，也不建议覆盖之前的构建产物标识。因为在现有流行的语言和框架中，普遍存在大量的第三方依赖，即便是同一份源代码，由于其依赖以及构建环境的不同，会有一定几率出现由于外部依赖的更新导致构建产物存在差异，从而产生非预期的情况出现。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;确保所有的环境部署的构建产物是一样的，尽可能的保证环境的一致性。&lt;/li&gt;
&lt;li&gt;确保部署到生产环境的产物是测试验证之后并无变化的，避免出现非预期的差异。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;对于如前端这类纯静态资源的应用，由于不同的环境需要连接不同的后端服务地址，因此无法直接使用唯一的构建产物。可以考虑在业务启动阶段，用一些额外的启动脚本或命令配合传入环境变量或参数来修改配置文件，从而达到所有环境使用同一个构建产物的目的。&lt;/p&gt;
&lt;p&gt;下面例子展示了在使用nginx的容器镜像里，通过在CMD指令里面先执行一段脚本来对配置进行修改，来达到在容器运行时根据传入的环境变量WEB_ENV的值来访问对应环境的后端服务的目的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM nginx:1.21.3-alpine

COPY dist /app/

CMD sed -i -e &quot;s/VUE_APP_ENV/${WEB_ENV}/g&quot; /app/env-config.js \
&amp;amp;&amp;amp; nginx -g &#x27;daemon off;&#x27;&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于移动端app，也存在与前端应用类似的问题，需要开发人员做额外设计和开发，在app启动时判断需要进入什么样的运行模式。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施要点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;在设计CICD流水线时，将构建产物同步到制品库时，给该产物打上唯一标识。&lt;/li&gt;
&lt;li&gt;如制品库支持，开启制品库的immutable特性。&lt;/li&gt;
&lt;li&gt;将该唯一标识传递到在后面所有的部署流水线任务中，所有的部署任务都使用该唯一标识所指向的构建产物。&lt;/li&gt;
&lt;li&gt;如果需要在多个制品库保存同一个构建产物，建议在上传成功之后对构建产物做完整性检查。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;减少脚本/工具对环境的依赖&lt;/h3&gt;
&lt;p&gt;一般情况下，脚本都会或多或少的使用到一些外部工具。而我们的脚本很有可能会运行在不同的环境中，不同环境中提供的工具也会有版本和用法的差异。如果需要在环境中维护某一工具的多个版本的，工具本身的版本管理，以及多个工具之间的依赖冲突和升级更新也会产生较高的管理和维护成本。&lt;/p&gt;
&lt;p&gt;我们建议尽可能的减少所使用的工具对环境的依赖，尤其是系统不会默认安装的工具。另外在编写脚本的时候，也尽量避免使用只有某些版本特有的语法特性。这些情况都会导致脚本有可能出现一些不可预期的结果。我们建议使用容器化工具或者容器化环境管理工具如Batect来替代对应的需求。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CI/CD agent中只需要安装容器运行时即可，可以减小agent的体积。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;容器化的工具因为对环境的依赖非常低，所以不论是工具升级还是降级都非常简单，同时也解耦了对agent特性的依赖，提高agent利用率。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最大化的保证环境一致性，使用容器化的工具消除了环境差异可能导致的非预期异常。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;新人友好，新加入的团队成员可以快速的配置好可运行的环境，无需过多的考虑具体工具的安装，配置等。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解耦对CI/CD工具的依赖，虽然在实际项目中很少会有更换CI/CD工具的情况，但是如果需要迁移，我们也只需在新的工具环境中构建出容器运行环境即可，大大减少了切换工具工作量，提高迁移的速度。 &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;因为没有预装构建所需要的各种软件，如果本地没有镜像缓存，在运行容器化的工具时都需要去容器仓库中获取对应的工具镜像，会有额外的带宽压力。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;因为需要获取工具镜像，容器启动也比二进制的程序要慢，所以整个任务运行过程需要的时间会更长。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;理论上来讲，容器化技术性能损耗很小，工具的性能和二进制程序的差别不会很大，但是在实际的使用中，我们发现因为容器引擎配置不当等原因会导致一些工具性能变差甚至无响应的情况出现。 &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施示例：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在使用 terraform 时，不同版本之间的 terraform 并不兼容，那么如何保证所有人与 CI 都使用相同的 terraform 版本就是一个非常麻烦的事情。那么如果我们无论在 CI 还是本地都基于 docker 去运行 terraform 就可以解决这个问题。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env bash

function terraform() {
  docker run --rm -it \
      -v $(pwd):/app -w /app \
      hashicorp/terraform:1.1.4 -c &quot;$@&quot;
}

terraform init
terraform plan &amp;amp;&amp;amp; terraform apply&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;使用auto/ACTION模式来维护管理脚本&lt;/h3&gt;
&lt;p&gt;auto/ACTION是我们在项目实践中总结并希望可以广泛推广的一个经验总结，在和客户合作过程中，尤其是有很多团队的大型项目上，我们从这个模式中受益匪浅。auto/ACTION模式的核心是使用统一语义能表明脚本目的的ACTION来命名管理脚本，如应用的测试(test)，验证(validate)，打包(build)，发布(deploy)等相关任务，统一把这些管理脚本归放在auto目录下来维护。&lt;/p&gt;
&lt;p&gt;因为类unix系统在运行的时候并不真正使用文件后缀来识别文件的类型，我们建议脚本名字不要加后缀。这个建议是基于管理脚本有可能会在多个地方被使用，而不同的开发和维护人员对于语言的偏好不同，如果在需要使用另外一种语言重写脚本的时候，使用这个脚本的地方就不需要做更新，消除了因为文件名变化可能导致的自动化任务的错误和中断。虽然没有后缀可能会带来一些不便，比如编辑器的语言类型识别错误等，但是相对于它带来的优点，还是非常值得的。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;管理代码和业务代码放在同一代码库，使用版本控制，便于进行更新，回退。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个脚本只做一件事，职责单一，同时便于理解和管理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以方便的知道所有可用的脚本。如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls -l auto/
auto/validate
auto/test
auto/build
auto/release
auto/deploy&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果跨团队合作，或者团队成员有轮换的时候，可以更快速的掌握业务管理的上下文。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;每个项目都有一套自己的auto脚本，如果有基础性变化，改动成本较高，可以考虑使用git submodule等模式来管理。&lt;/li&gt;
&lt;li&gt;没有后缀的文件名会带来一些管理上的不便。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施要点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;脚本满足既可在本地执行，又能在CI流水线上执行，便于验证。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;脚本中的变量内容尽可能从环境变量中读取，避免向脚本中传入参数，方便运行。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;专属于CI/CD平台的脚本不要放在auto根目录下，建议创建一个对应的子目录，例如 .buildkite, .github, .travis来做管理。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可根据团队的需求适当的扩展脚本的名字使之更容易理解，建议使用-而非_ 来分隔单词， 如auto/upload-image-to-ecr。 &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;管理脚本和业务脚本分离&lt;/h3&gt;
&lt;p&gt;我们的应用中一般都会有一些脚本来做一些辅助性的工作。这些脚本通常会和业务代码放在同一个代码仓库，使用版本控制来进行管理。这些脚本大致分为两种：管理脚本和业务脚本。&lt;/p&gt;
&lt;p&gt;管理脚本是用来做应用打包，部署等管理相关工作工作，这种类型的脚本是无需打包进业务运行所需的产出物中的；业务脚本是辅助业务运行，比如说初始化环境和配置，结束时的清理工作等，这些脚本需要打包到业务运行的产出物中。&lt;/p&gt;
&lt;p&gt;我们建议除了一些有特殊要求的脚本外，不要把脚本放在根目录。并且把这两种不同类型的脚本存放在不同的目录中。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;在封装镜像时，业务脚本和业务代码同等重要，需要封装在镜像中。将管理脚本和业务脚本分离可以减少镜像中的文件数量。&lt;/li&gt;
&lt;li&gt;在软件开发过程中，针对业务运行和自动化管理关注信息不一样，将管理脚本和业务脚本分离，让团队成员更加清楚脚本的类型和目的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;将管理脚本和业务脚本分离，会增加仓库的层次结构。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施要点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;推荐将管理脚本放置在auto目录，将业务脚本放置在scripts目录。&lt;/li&gt;
&lt;li&gt;脚本中的变量采用从环境变量中读取，避免向脚本中传入参数，方便运行。&lt;/li&gt;
&lt;li&gt;推荐脚本名称即表明脚本的作用，不建议使用auto/script这样不表意的脚本命名。&lt;/li&gt;
&lt;li&gt;不在文件名中使用文件类型后缀。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;及时更新容器的基础镜像&lt;/h3&gt;
&lt;p&gt;基础镜像是业务镜像的地基，其包含了我们业务和应用所必需的基础库、二进制文件和配置文件等。一个良好维护的基础镜像通常会根据需要做更新，这些更新通常包含安全补丁，新功能或对操作系统或框架的改进等，我们建议及时的更新容器的基础镜像来保障业务的安全性。除非有特定原因需要继续使用旧版本镜像，否则应及时跟进使用经过充分评估和测试的最新版本镜像。&lt;/p&gt;
&lt;p&gt;在Dockerfile和compose等文件中，可以通过指定镜像中的标识和sha256值组合来指定基础镜像的版本。当镜像有了更新之后，及时沿用了如latest或大版本号这类通用性比较高的标签时，其sha256的值也会发生变化，通过更新这个组合可以更新使用最新版本的基础镜像。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;最新的镜像通常带有可以增强应用程序安全性的补丁修复，降低安全风险。&lt;/li&gt;
&lt;li&gt;最新的镜像通常包括可以提高应用程序性能的新功能或改进功能。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;新功能可能存在不可预期的bug。&lt;/li&gt;
&lt;li&gt;新的功能有非常小的概率存在未知的安全漏洞，如果有特殊的安全需求，请在安全部门的指导下升级。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施示例：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;可以使用&lt;a href=&quot;https://github.com/realestate-com-au/dfresh&quot;&gt;dfresh&lt;/a&gt;或者类似的工具来检查和更新基础镜像。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;检查基础镜像是否有更新&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ dfresh check Dockerfile
Dockerfile:1: mysql
old sha256:5e515d337402579571c19a2a34a9b733d26788805429b5b3bdca12b76e7cc208
new sha256:fbe848f5738001063a89367adb747e7f283f9c87b20e74ccb6db3b13ec6e35cd&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新基础镜像 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ dfresh update Dockerfile
Dockerfile:1: mysql
old sha256:5e515d337402579571c19a2a34a9b733d26788805429b5b3bdca12b76e7cc208
new sha256:fbe848f5738001063a89367adb747e7f283f9c87b20e74ccb6db3b13ec6e35cd&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回退方法 在需要回退基础镜像版本时，可从代码库的提交找到上一个可用版本的相应信息。 &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;定期检查和升级依赖包&lt;/h3&gt;
&lt;p&gt;随着 Bug 修复、新功能的开发或者其他更新，我们应用的依赖包可能会过时。此时应用的依赖项越多，就越难跟上这些更新。过时的依赖包可能对安全构成威胁，并对性能产生负面影响。最新的软件包可防止漏洞，这意味着定期的依赖性检查和更新很重要。我们建议定期的对应用的依赖包做更新和安全检查，并升级到一个合适的版本。并且我们建议在应用的 pipeline 中加入这些检查任务，并在常规的开发过程中及时发现和升级。如果应用已经处于维护阶段，我们也建议定期执行这些检查并在需要的时候加以升级。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;定期升级依赖可以让应用的安全性和代码的可用性都有保障。&lt;/li&gt;
&lt;li&gt;定期升级依赖会让解决依赖版本冲突和代码兼容性变得容易。&lt;/li&gt;
&lt;li&gt;更新依赖项可以获得新的依赖项版本提供的所有性能改进。 这些改进可以有多种形式，例如修复以前的性能问题、改进了实现和算法等。&lt;/li&gt;
&lt;li&gt;升级依赖项不仅可以改进现有功能，还可以使用到以前不存在的新功能。这些新功能最终可能让我们更好的实现自己应用的新功能。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;如果不及时更新依赖，将会使得产品难以维护，并可能导致开发人员的时间被常规的、无意义的工作占用。&lt;/li&gt;
&lt;li&gt;如果长期不更新依赖，会使应用面临无人问津的风险，之后在某一天需要进行改动的时候，面临大量的依赖包过期无法获取和版本升级造成的接口变化。这时就需要投入非常高的成本来让代码重新变得可用，甚至完全无法更新而变成遗留系统。&lt;/li&gt;
&lt;li&gt;当进行大的版本升级时，需要对应用程序进行更多的更改才能与较新的库兼容。这使得付出代价比及时更新依赖大得多。&lt;/li&gt;
&lt;li&gt;如果忽略升级依赖项，那么会面临无法在自己喜欢的平台上运行软件的可能。 例如，如果停止升级软件中的数据库驱动程序，那么将无法使用旧版本的数据库系统。这不仅会使应用变得过时且易受攻击，而且甚至可能无法从该数据库系统提供商处获得任何支持。&lt;/li&gt;
&lt;li&gt;如果应用依赖于过时的依赖项而导致升级困难变得很难维护，会使得项目很难找到对这些旧技术有经验的人，甚至失去现有的维护者。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;实施示例:&lt;/strong&gt;&lt;/h4&gt;
&lt;h5&gt;&lt;strong&gt;1. 手动检查&lt;/strong&gt;&lt;/h5&gt;
&lt;h6&gt;&lt;strong&gt;      JS 篇&lt;/strong&gt;&lt;/h6&gt;

&lt;h6&gt;&lt;strong&gt;    Java 篇&lt;/strong&gt;&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;在 build.gradle中配置 owasp.dependency-check&lt;/li&gt;
&lt;li&gt;执行./gradlew dependencyCheckAnalyze&lt;/li&gt;
&lt;li&gt;查看报告： 项目根目录&amp;gt;build&amp;gt;reports&amp;gt;dependency-check-report.html&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;&lt;strong&gt;2. CI Pipeline 集成&lt;/strong&gt;&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Dockerfile
FROM node:18.7.0
WORKDIR app
COPY [&quot;package.json&quot;, &quot;package-lock.json*&quot;, &quot;./&quot;]
RUN npm install -g npm-check-updates&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## docker-compose
version: &quot;2&quot;
services:
node-version-check:
  build: .
  command: sh -c &quot;ncu&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## auto/dependency-check.sh
#!/usr/bin/env bash
set -ex
docker-compose run --rm node-version-check&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## buildkite script
steps
 - label: &#x27;node version dependency-check&#x27;
   command: auto/dependency-check.sh
   agents:
     queue: &#x27;xxxx&#x27;
 - block: &#x27;Please check node-version-check&#x27;&lt;/code&gt;&lt;/pre&gt;

&lt;h5&gt;&lt;strong&gt;3. 工具集成检查&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;如果项目 code 托管在 Github，我们可以使用 Dependabot 和 Renovate 工具和 Github 集成来做依赖检查。这两个工具都会做定期扫描，创建依赖版本升级的 PR。&lt;/p&gt;
&lt;h6&gt;&lt;strong&gt;配置 Dependabot 进行版本更新&lt;/strong&gt;&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;在 GitHub 的代码仓库的主页，找到代码仓库名称下的 setting；&lt;/li&gt;
&lt;li&gt;在边栏的安全性部分中，单击代码安全性和分析；&lt;/li&gt;
&lt;li&gt;在代码安全和分析下，在Dependabot version updates右侧，单击启用以打开存储库 .github 目录中的基本 dependabot.yml 配置文件；&lt;/li&gt;
&lt;li&gt;添加version；&lt;/li&gt;
&lt;li&gt;添加 updates 部分，并输入希望 Dependabot 监视的每个包管理器的条目；&lt;/li&gt;
&lt;li&gt;对于每个包管理器，可使用：
&lt;ul&gt;
&lt;li&gt;package-ecosystem 指定包管理器。&lt;/li&gt;
&lt;li&gt;directory 指定清单或其他定义文件的位置。&lt;/li&gt;
&lt;li&gt;schedule.interval 指定检查新版本的频率。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在代码仓库的根目录创建.github目录；&lt;/li&gt;
&lt;li&gt;创建 dependabot.yml文件并且存储到.github目录下。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;示例 dependabot.yml&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 2
updates:
  # Enable version updates for npm
  - package-ecosystem: &quot;npm&quot;
    # Look for &lt;/code&gt;&lt;code&gt;package.json&lt;/code&gt; and &lt;code&gt;lock&lt;/code&gt; files in the &lt;code&gt;root&lt;/code&gt; directory
    directory: &quot;/&quot;
    # Check the npm registry for updates every day (weekdays)
    schedule:
      interval: &quot;daily&quot;&lt;/pre&gt;
&lt;h6&gt;&lt;strong&gt;配置 Renovate&lt;/strong&gt;&lt;/h6&gt;

&lt;h3&gt;定期的重新部署维护阶段的应用&lt;/h3&gt;
&lt;p&gt;在应用处于维护阶段，如果业务不再会增加新的功能，抑或因为某些原因无法做定期的应用依赖升级，我们也建议你定期的重新部署这个应用，以应对平台等更底层的变化带来的部署失败的风险。定期部署可以确保你的应用在新的平台环境中也可以正常的部署，如果在周期性的部署过程中发现应用无法在新的环境部署，你也会有一个缓冲期来制订应对策略，而不是在平台完成升级之后的某一天，应用发生了问题才发现已经无法部署。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;定期部署应用是对部署工具和流程的有效验证，CI/CD Agent的一些升级有可能会导致我们在部署流程中使用工具发生兼容性问题，定期部署可以及早的发现这些问题。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;定期部署应用也能够有效缩短我们的依赖获取未验证的窗口期。虽然我们的应用依赖可以锁定版本，也可以将依赖保存到私有仓库，但长时间没有运行相关部署流程，我们无法保证应用的依赖能够在需要的时候可正常获取且可用。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现在的应用的基础设施很多都基于各类云平台，服务提供商会定期的对自己的基础设施做升级和换代，定期部署应用可以让我们及早的获知基础设施变化带来的兼容性风险。 &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;定期部署会对系统的稳定运行造成一些影响，变化本身就会带来一定的未知风险。 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;自动化的发布一般情况下都需要配有完善的回归测试流程来确保业务的可用性，会带来成本的增加 &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;感谢&lt;/h2&gt;
&lt;p&gt;蓝皮书在编撰的过程中，有很多热心的小伙伴加入贡献了自己的力量和知识，在这里非常感谢他们。&lt;/p&gt;
&lt;p&gt;常卉、冯炜、甘霖静、高语越、何水平、何蔚、毛灵、毛远鑫、钱文涛、乔伟星、石昆、孙瑞、许乐、杨伟健、赵浩、赵佩、周瑞丰、朱翔&lt;/p&gt;
&amp;#13;
&lt;/div&gt;&amp;#13;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ba4836a81e0ab5b8be493c122df98249</guid>
<title>一步一图带你深入理解 Linux 物理内存管理</title>
<link>https://toutiao.io/k/6jx7p35</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 前文回顾&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上篇文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486732&amp;amp;idx=1&amp;amp;sn=435d5e834e9751036c96384f6965b328&amp;amp;chksm=ce77cb4bf900425d33d2adfa632a4684cf7a63beece166c1ffedc4fdacb807c9413e8c73f298&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《深入理解 Linux 虚拟内存管理》&lt;/a&gt; 中，笔者分别从进程用户态和内核态的角度详细深入地为大家介绍了 Linux 内核如何对进程虚拟内存空间进行布局以及管理的相关实现。在我们深入理解了虚拟内存之后，那么何不顺带着也探秘一下物理内存的管理呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以本文的目的是在深入理解虚拟内存管理的基础之上继续带大家向前奋进，一举击破物理内存管理的知识盲区，使大家能够俯瞰整个 Linux 内存管理子系统的整体全貌。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而在正式开始物理内存管理的主题之前，笔者觉得有必须在带大家回顾下上篇文章中介绍的虚拟内存管理的相关知识，方便大家来回对比虚拟内存和物理内存，从而可以全面整体地掌握 Linux 内存管理子系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上篇文章的一开始，笔者首先为大家展现了我们应用程序频繁接触到的虚拟内存地址，清晰地为大家介绍了到底什么是虚拟内存地址，以及虚拟内存地址分别在 32 位系统和 64 位系统中的具体表现形式：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.35&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlictvBLweFic6O06wOP9rsw963GyicHkDTUNNd4mesqYnVzxnVCvdoocDfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2806451612903226&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPliczZ6wY6ib4iag5edibf5olrzJmqzlBiahKOia1Hjialq9sgfSJK8Oly0kc6cA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们清楚了虚拟内存地址这个基本概念之后，随后笔者又抛出了一个问题：为什么我们要通过虚拟内存地址访问内存而不是直接通过物理地址访问？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原来是在多进程系统中直接操作物理内存地址的话，我们需要精确地知道每一个变量的位置都被安排在了哪里，而且还要注意当前进程在和多个进程同时运行的时候，不能共用同一个地址，否则就会造成地址冲突。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.36774193548387096&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic20Oj66Ugl6RXib7sN2scRtI0rFczJx5K2DplZsHYRyicKWM8WJqWviaYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而虚拟内存空间的引入正是为了解决多进程地址冲突的问题，使得进程与进程之间的虚拟内存地址空间相互隔离，互不干扰。每个进程都认为自己独占所有内存空间，将多进程之间的协同相关细节统统交给内核中的内存管理模块来处理，极大地解放了程序员的心智负担。这一切都是因为虚拟内存能够为进程提供内存地址空间隔离的功劳。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7258064516129032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPliclL76yNyK91MwYvEiax4TzakymT9QQZSLKQB0qC5CVjMwRu7rpicWIr0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们清楚了虚拟内存空间引入的意义之后，笔者紧接着为大家介绍了&lt;strong&gt;进程用户态&lt;/strong&gt;虚拟内存空间分别在 32 位机器和 64 位机器上的布局情况：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9048387096774193&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicITribS5tWuoT1qhcpIeho9tBRSNFgFbhsYFcE1eMQAAHLV2HQuxXauA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;32 位机器.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9919354838709677&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicswWcTSQKsDyeFL8GhBFz0dnMgsyhQnnFtZTMibWaCaKwKQ3HpP7icHJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;64 位机器.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在了解了用户态虚拟内存空间的布局之后，紧接着我们又介绍了 Linux 内核如何对用户态虚拟内存空间进行管理以及相应的管理数据结构：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7741935483870968&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicaiaITkMuXjz27tBe7oqxxS5YSZntfA8ibHQ4BdIGHSbM38sHibVbuOGHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在介绍完用户态虚拟内存空间的布局以及管理之后，我们随后又介绍了&lt;strong&gt;内核态&lt;/strong&gt;虚拟内存空间的布局情况，并结合之前介绍的&lt;strong&gt;用户态&lt;/strong&gt;虚拟内存空间，得到了 Linux 虚拟内存空间分别在 32 位和 64 位系统中的整体布局情况：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1096774193548387&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic7brE9uln9lDAfPoEJ023FqhNGAEPIpMY4tQRT3pPoLARMka6Pn47wA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;32位系统中虚拟内存空间整体布局.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1024193548387098&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicvB2J2MJAib7g2dqwSjEzAxG1l61E1as4ASBmQRCoLmNVpjwTAqeO7Gg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;64位系统中虚拟内存空间整体布局.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在虚拟内存全部介绍完毕之后，为了能够承上启下，于是笔者继续在上篇文章的最后一个小节从计算机组成原理的角度介绍了物理内存的物理组织结构，方便让大家理解到底什么是真正的物理内存 ？物理内存地址到底是什么 ？由此为本文的主题 —— 物理内存的管理 ，埋下伏笔~~~&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4685483870967742&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlictkIAkCGJiapzLW0SPvBu40ibxnI4LhdFC2aBNILzx015zgiaOicwAmDUeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;内存IO单位.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后笔者介绍了 CPU 如何通过物理内存地址向物理内存读写数据的完整过程：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4596774193548387&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicswiaj2qYFJYicD0ia9ISgrn4cCASqdWFyGFGknqB07EiaQdgsQbspJXGSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;CPU读取内存.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们回顾完上篇文章介绍的用户态和内核态虚拟内存空间的管理，以及物理内存在计算机中的真实组成结构之后，下面笔者就来正式地为大家介绍本文的主题 —— Linux 内核如何对物理内存进行管理&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.775&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicYztpEeUfMvwhrpz4k8gBxwGwcpKzLVc1ziaDodBxOjOSTqibZNhia0xsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 从 CPU 角度看物理内存模型&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在前边的文章中，笔者曾多次提到内核是以页为基本单位对物理内存进行管理的，通过将物理内存划分为一页一页的内存块，每页大小为 4K。一页大小的内存块在内核中用 struct page 结构体来进行管理，struct page 中封装了每页内存块的状态信息，比如：组织结构，使用信息，统计信息，以及与其他结构的关联映射信息等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而为了快速索引到具体的物理内存页，内核为每个物理页 struct page 结构体定义了一个索引编号：PFN（Page Frame Number）。PFN 与 struct page 是一一对应的关系。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核提供了两个宏来完成 PFN 与 物理页结构体 struct page 之间的相互转换。它们分别是 page_to_pfn 与 pfn_to_page。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核中如何组织管理这些物理内存页 struct page 的方式我们称之为做物理内存模型，不同的物理内存模型，应对的场景以及 page_to_pfn 与 pfn_to_page 的计算逻辑都是不一样的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 FLATMEM 平坦内存模型&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先把物理内存想象成一片地址连续的存储空间，在这一大片地址连续的内存空间中，内核将这块内存空间分为一页一页的内存块 struct page 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于这块物理内存是连续的，物理地址也是连续的，划分出来的这一页一页的物理页必然也是连续的，并且每页的大小都是固定的，所以我们很容易想到用一个数组来组织这些连续的物理内存页 struct page 结构，其在数组中对应的下标即为 PFN 。这种内存模型就叫做平坦内存模型 FLATMEM 。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5766129032258065&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicYWFtjK8cL1wibeb7iaNibeicoYNNxibm9pJQpYfURibfyGNibjLXUVlN5xBLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核中使用了一个 mem_map 的全局数组用来组织所有划分出来的物理内存页。mem_map 全局数组的下标就是相应物理页对应的 PFN 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在平坦内存模型下 ，page_to_pfn 与 pfn_to_page 的计算逻辑就非常简单，本质就是基于 mem_map 数组进行偏移操作。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;if&lt;/span&gt; defined(CONFIG_FLATMEM)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; __pfn_to_page(pfn) (mem_map + ((pfn)-ARCH_PFN_OFFSET))&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; __page_to_pfn(page) ((unsigned long)((page)-mem_map) + ARCH_PFN_OFFSET)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;ARCH_PFN_OFFSET 是 PFN 的起始偏移量。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Linux 早期使用的就是这种内存模型，因为在 Linux 发展的早期所需要管理的物理内存通常不大（比如几十 MB），那时的 Linux 使用平坦内存模型 FLATMEM 来管理物理内存就足够高效了。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;内核中的默认配置是使用 FLATMEM 平坦内存模型。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 DISCONTIGMEM 非连续内存模型&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;FLATMEM 平坦内存模型只适合管理一整块连续的物理内存，而对于多块非连续的物理内存来说使用 FLATMEM 平坦内存模型进行管理则会造成很大的内存空间浪费。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为 FLATMEM 平坦内存模型是利用 mem_map 这样一个全局数组来组织这些被划分出来的物理页 page 的，而对于物理内存存在大量不连续的内存地址区间这种情况时，这些不连续的内存地址区间就形成了内存空洞。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于用于组织物理页的底层数据结构是 mem_map 数组，数组的特性又要求这些物理页是连续的，所以只能为这些内存地址空洞也分配 struct page 结构用来填充数组使其连续。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而每个 struct page 结构大部分情况下需要占用 40 字节（struct page 结构在不同场景下内存占用会有所不同，这一点我们后面再说），如果物理内存中存在的大块的地址空洞，那么为这些空洞而分配的 struct page 将会占用大量的内存空间，导致巨大的浪费。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47661290322580646&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic8wE3JcO7eaqkd66mKsGkCteRPMkM5ud0xnJrlAvG0bgZhjTmejoEnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了组织和管理这些不连续的物理内存，内核于是引入了 DISCONTIGMEM 非连续内存模型，用来消除这些不连续的内存地址空洞对 mem_map 的空间浪费。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 DISCONTIGMEM 非连续内存模型中，内核将物理内存从宏观上划分成了一个一个的节点 node （微观上还是一页一页的物理页），每个 node 节点管理一块连续的物理内存。这样一来这些连续的物理内存页均被划归到了对应的 node 节点中管理，就避免了内存空洞造成的空间浪费。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2532258064516129&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic597fF8g2c5lAxLxVXibkFz4RZWe69dTVmmESxYPq6fW0XEtE0W59lLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核中使用 struct pglist_data 表示用于管理连续物理内存的 node 节点（内核假设 node 中的物理内存是连续的），既然每个 node 节点中的物理内存是连续的，于是在每个 node 节点中还是采用 FLATMEM 平坦内存模型的方式来组织管理物理内存页。每个 node 节点中包含一个  &lt;code&gt;struct page *node_mem_map&lt;/code&gt; 数组，用来组织管理 node 中的连续物理内存页。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_FLATMEM&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; *&lt;span&gt;node_mem_map&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看出 DISCONTIGMEM 非连续内存模型其实就是 FLATMEM 平坦内存模型的一种扩展，在面对大块不连续的物理内存管理时，通过将每段连续的物理内存区间划归到 node 节点中进行管理，避免了为内存地址空洞分配 struct page 结构，从而节省了内存资源的开销。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于引入了 node 节点这个概念，所以在 DISCONTIGMEM 非连续内存模型下 page_to_pfn 与 pfn_to_page 的计算逻辑就比 FLATMEM 内存模型下的计算逻辑多了一步定位 page 所在 node 的操作。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过 arch_pfn_to_nid 可以根据物理页的 PFN 定位到物理页所在 node。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过 page_to_nid 可以根据物理页结构 struct page 定义到 page 所在 node。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当定位到物理页 struct page 所在 node 之后，剩下的逻辑就和 FLATMEM 内存模型一模一样了。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;if&lt;/span&gt; defined(CONFIG_DISCONTIGMEM)&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; __pfn_to_page(pfn)   \&lt;br/&gt;({ unsigned long __pfn = (pfn);  \&lt;br/&gt; unsigned long __nid = arch_pfn_to_nid(__pfn);  \&lt;br/&gt; NODE_DATA(__nid)-&amp;gt;node_mem_map + arch_local_page_offset(__pfn, __nid);\&lt;br/&gt;})&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; __page_to_pfn(pg)      \&lt;br/&gt;({ const struct page *__pg = (pg);     \&lt;br/&gt; struct pglist_data *__pgdat = NODE_DATA(page_to_nid(__pg)); \&lt;br/&gt; (unsigned long)(__pg - __pgdat-&amp;gt;node_mem_map) +   \&lt;br/&gt;  __pgdat-&amp;gt;node_start_pfn;     \&lt;br/&gt;})&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 SPARSEMEM 稀疏内存模型&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着内存技术的发展，内核可以支持物理内存的热插拔了（后面笔者会介绍），这样一来物理内存的不连续就变为常态了，在上小节介绍的 DISCONTIGMEM 内存模型中，其实每个 node 中的物理内存也不一定都是连续的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.3072580645161291&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicbV0x8Mclo5D6yNUf4OWZLvTejIGZD0EJSDIiabibdxTdypxjQ2ic1mJpg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且每个 node 中都有一套完整的内存管理系统，如果 node 数目多的话，那这个开销就大了，于是就有了对连续物理内存更细粒度的管理需求，为了能够更灵活地管理粒度更小的连续物理内存，SPARSEMEM 稀疏内存模型就此登场了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;SPARSEMEM 稀疏内存模型的核心思想就是对粒度更小的连续内存块进行精细的管理，用于管理连续内存块的单元被称作 section 。物理页大小为 4k 的情况下， section 的大小为 128M ，物理页大小为 16k 的情况下， section 的大小为 512M。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内核中用 struct mem_section 结构体表示 SPARSEMEM 模型中的 section。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;mem_section&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; section_mem_map;&lt;br/&gt;        ...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 section 被用作管理小粒度的连续内存块，这些小的连续物理内存在 section 中也是通过数组的方式被组织管理，每个 struct mem_section 结构体中有一个 section_mem_map 指针用于指向 section 中管理连续内存的 page 数组。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;SPARSEMEM 内存模型中的这些所有的 mem_section 会被存放在一个全局的数组中，并且每个 mem_section 都可以在系统运行时改变 offline / online （下线 / 上线）状态，以便支持内存的热插拔（hotplug）功能。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_SPARSEMEM_EXTREME&lt;/span&gt;&lt;br/&gt;&lt;span&gt;extern&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;mem_section&lt;/span&gt; *&lt;span&gt;mem_section&lt;/span&gt;[&lt;span&gt;NR_SECTION_ROOTS&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6903225806451613&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic6iblU63CMRWttzhzk8gbKBAJSbrFsf9qvXq8ETokK68QuKHzua4lhMw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 SPARSEMEM 稀疏内存模型下 page_to_pfn 与 pfn_to_page 的计算逻辑又发生了变化。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在 page_to_pfn 的转换中，首先需要通过 page_to_section 根据 struct page 结构定位到 mem_section 数组中具体的 section 结构。然后在通过 section_mem_map 定位到具体的 PFN。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在 struct page 结构中有一个 &lt;code&gt;unsigned long flags&lt;/code&gt; 属性，在 flag 的高位 bit 中存储着 page 所在 mem_section 数组中的索引，从而可以定位到所属 section。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在 pfn_to_page 的转换中，首先需要通过 __pfn_to_section 根据 PFN 定位到 mem_section 数组中具体的 section 结构。然后在通过 PFN 在 section_mem_map 数组中定位到具体的物理页 Page 。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;PFN  的高位 bit 存储的是全局数组 mem_section 中的 section 索引，PFN 的低位 bit 存储的是 section_mem_map 数组中具体物理页 page 的索引。&lt;/p&gt;&lt;/blockquote&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;if&lt;/span&gt; defined(CONFIG_SPARSEMEM)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;/*&lt;br/&gt; * Note: section&#x27;s mem_map is encoded to reflect its start_pfn.&lt;br/&gt; * section[i].section_mem_map == mem_map&#x27;s address - start_pfn;&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; __page_to_pfn(pg)     \&lt;br/&gt;({ const struct page *__pg = (pg);    \&lt;br/&gt; int __sec = page_to_section(__pg);   \&lt;br/&gt; (unsigned long)(__pg - __section_mem_map_addr(__nr_to_section(__sec))); \&lt;br/&gt;})&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; __pfn_to_page(pfn)    \&lt;br/&gt;({ unsigned long __pfn = (pfn);   \&lt;br/&gt; struct mem_section *__sec = __pfn_to_section(__pfn); \&lt;br/&gt; __section_mem_map_addr(__sec) + __pfn;  \&lt;br/&gt;})&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从以上的内容介绍中，我们可以看出 SPARSEMEM 稀疏内存模型已经完全覆盖了前两个内存模型的所有功能，因此稀疏内存模型可被用于所有内存布局的情况。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3.1 物理内存热插拔&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面提到随着内存技术的发展，物理内存的热插拔 hotplug 在内核中得到了支持，由于物理内存可以动态的从主板中插入以及拔出，所以导致了物理内存的不连续已经成为常态，因此内核引入了 SPARSEMEM 稀疏内存模型以便应对这种情况，提供对更小粒度的连续物理内存的灵活管理能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本小节笔者就为大家介绍一下物理内存热插拔 hotplug 功能在内核中的实现原理，作为 SPARSEMEM 稀疏内存模型的扩展内容补充。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在大规模的集群中，尤其是现在我们处于云原生的时代，为了实现集群资源的动态均衡，可以通过物理内存热插拔的功能实现集群机器物理内存容量的动态增减。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;集群的规模一大，那么物理内存出故障的几率也会大大增加，物理内存的热插拔对提供集群高可用性也是至关重要的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从总体上来讲，内存的热插拔分为两个阶段：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;物理热插拔阶段：这个阶段主要是从物理上将内存硬件插入（hot-add），拔出（hot-remove）主板的过程，其中涉及到硬件和内核的支持。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;逻辑热插拔阶段：这一阶段主要是由内核中的内存管理子系统来负责，涉及到的主要工作为：如何动态的上线启用（online）刚刚 hot-add 的内存，如何动态下线（offline）刚刚 hot-remove 的内存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;物理内存拔出的过程需要关注的事情比插入的过程要多的多，实现起来也更加的困难, 这就好比在&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247485290&amp;amp;idx=1&amp;amp;sn=58d7eb2c25c2e51b41e35a4ce4dab517&amp;amp;chksm=ce77c12df900483bf5a0edc6b31e710d6e3019deeeb788ed89faa69f9055872e85d518ee52f6&amp;amp;token=65686925&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《Java 技术栈中间件优雅停机方案设计与实现全景图》&lt;/a&gt; 一文中我们讨论服务优雅启动，停机时提到的：优雅停机永远比优雅启动要考虑的场景要复杂的多，因为停机的时候，线上的服务正在承载着生产的流量需要确保做到业务无损。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样的道理，物理内存插入比较好说，困难的是物理内存的动态拔出，因为此时即将要被拔出的物理内存中可能已经为进程分配了物理页，如何妥善安置这些已经被分配的物理页是一个棘手的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前边我们介绍 SPARSEMEM 内存模型的时候提到，每个 mem_section 都可以在系统运行时改变 offline ，online 状态，以便支持内存的热插拔（hotplug）功能。 当 mem_section offline 时, 内核会把这部分内存隔离开, 使得该部分内存不可再被使用, 然后再把 mem_section 中已经分配的内存页迁移到其他 mem_section 的内存上. 。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.582258064516129&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicd98kiaExbS3BNpEeZOow48BPhWX9GNQJuhUXTyk52KicMiaMkjrNqBiahg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是这里会有一个问题，就是并非所有的物理页都可以迁移，因为迁移意味着物理内存地址的变化，而内存的热插拔应该对进程来说是透明的，所以这些迁移后的物理页映射的虚拟内存地址是不能变化的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一点在进程的用户空间是没有问题的，因为进程在用户空间访问内存都是根据虚拟内存地址通过页表找到对应的物理内存地址，这些迁移之后的物理页，虽然物理内存地址发生变化，但是内核通过修改相应页表中虚拟内存地址与物理内存地址之间的映射关系，可以保证虚拟内存地址不会改变。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4508064516129032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic6yKlY5dvicFfLEesNMy8pj1Y7AVTkCCJRibyn6sPx2wSKXFw714X17MA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是在内核态的虚拟地址空间中，有一段直接映射区，在这段虚拟内存区域中虚拟地址与物理地址是直接映射的关系，虚拟内存地址直接减去一个固定的偏移量（0xC000 0000 ） 就得到了物理内存地址。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直接映射区中的物理页的虚拟地址会随着物理内存地址变动而变动, 因此这部分物理页是无法轻易迁移的，然而不可迁移的页会导致内存无法被拔除，因为无法妥善安置被拔出内存中已经为进程分配的物理页。那么内核是如何解决这个头疼的问题呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然是这些不可迁移的物理页导致内存无法拔出，那么我们可以把内存分一下类，将内存按照物理页是否可迁移，划分为不可迁移页，可回收页，可迁移页。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;大家这里需要记住一点，内核会将物理内存按照页面是否可迁移的特性进行分类，笔者后面在介绍内核如何避免内存碎片的时候还会在提到&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后在这些可能会被拔出的内存中只分配那些可迁移的内存页，这些信息会在内存初始化的时候被设置，这样一来那些不可迁移的页就不会包含在可能会拔出的内存中，当我们需要将这块内存热拔出时, 因为里边的内存页全部是可迁移的, 从而使内存可以被拔除。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3. 从 CPU 角度看物理内存架构&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上小节中笔者为大家介绍了三种物理内存模型，这三种物理内存模型是从 CPU 的视角来看待物理内存内部是如何布局，组织以及管理的，主角是物理内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在本小节中笔者为大家提供一个新的视角，这一次我们把物理内存看成一个整体，从 CPU 访问物理内存的角度来看一下物理内存的架构，并从 CPU 与物理内存的相对位置变化来看一下不同物理内存架构下对性能的影响。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 一致性内存访问 UMA 架构&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在上篇文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486732&amp;amp;idx=1&amp;amp;sn=435d5e834e9751036c96384f6965b328&amp;amp;chksm=ce77cb4bf900425d33d2adfa632a4684cf7a63beece166c1ffedc4fdacb807c9413e8c73f298&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《深入理解 Linux 虚拟内存管理》&lt;/a&gt;的 “ 8.2 CPU 如何读写主存” 小节中提到 CPU 与内存之间的交互是通过总线完成的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4443548387096774&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicDy41sf2ALIjgRxMLnHm8DsI4icgcicJKn4XTLIycbc1asxeoccuaPjFw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;CPU与内存之间的总线结构.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;首先 CPU 将物理内存地址作为地址信号放到系统总线上传输。随后 IO bridge 将系统总线上的地址信号转换为存储总线上的电子信号。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;主存感受到存储总线上的地址信号并通过存储控制器将存储总线上的物理内存地址 A 读取出来。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;存储控制器通过物理内存地址定位到具体的存储器模块，从 DRAM 芯片中取出物理内存地址对应的数据。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;存储控制器将读取到的数据放到存储总线上，随后 IO bridge 将存储总线上的数据信号转换为系统总线上的数据信号，然后继续沿着系统总线传递。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;CPU 芯片感受到系统总线上的数据信号，将数据从系统总线上读取出来并拷贝到寄存器中。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上图展示的是单核 CPU 访问内存的架构图，那么在多核服务器中多个 CPU 与内存之间的架构关系又是什么样子的呢？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5008064516129033&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicMGImzU51jibjbFNhicibne1XXQcFYsmicZRapLA1xgXaKN6dFMMVFYxkaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 UMA 架构下，多核服务器中的多个 CPU 位于总线的一侧，所有的内存条组成一大片内存位于总线的另一侧，所有的 CPU 访问内存都要过总线，而且距离都是一样的，由于所有 CPU 对内存的访问距离都是一样的，所以在 UMA 架构下所有 CPU 访问内存的速度都是一样的。这种访问模式称为 SMP（Symmetric multiprocessing），即对称多处理器。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;这里的一致性是指同一个 CPU 对所有内存的访问的速度是一样的。即一致性内存访问 UMA（Uniform Memory Access）。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是随着多核技术的发展，服务器上的 CPU 个数会越来越多，而 UMA 架构下所有 CPU 都是需要通过总线来访问内存的，这样总线很快就会成为性能瓶颈，主要体现在以下两个方面：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;总线的带宽压力会越来越大，随着 CPU 个数的增多导致每个 CPU 可用带宽会减少&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;总线的长度也会因此而增加，进而增加访问延迟&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;UMA 架构的优点很明显就是结构简单，所有的 CPU 访问内存速度都是一致的，都必须经过总线。然而它的缺点笔者刚刚也提到了，就是随着处理器核数的增多，总线的带宽压力会越来越大。解决办法就只能扩宽总线，然而成本十分高昂，未来可能仍然面临带宽压力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决以上问题，提高 CPU 访问内存的性能和扩展性，于是引入了一种新的架构：非一致性内存访问 NUMA（Non-uniform memory access）。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 非一致性内存访问 NUMA 架构&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 NUMA 架构下，内存就不是一整片的了，而是被划分成了一个一个的内存节点 （NUMA 节点），每个 CPU 都有属于自己的本地内存节点，CPU 访问自己的本地内存不需要经过总线，因此访问速度是最快的。当 CPU 自己的本地内存不足时，CPU 就需要跨节点去访问其他内存节点，这种情况下 CPU 访问内存就会慢很多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 NUMA 架构下，任意一个 CPU 都可以访问全部的内存节点，访问自己的本地内存节点是最快的，但访问其他内存节点就会慢很多，这就导致了 CPU 访问内存的速度不一致，所以叫做非一致性内存访问架构。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.525&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicDxwiaoTnGNcLbGwVibpKR5mPxianNrFznqs4VHuuEqK7UECicl6Micicjscw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如上图所示，CPU 和它的本地内存组成了 NUMA 节点，CPU 与 CPU 之间通过 QPI（Intel QuickPath Interconnect）点对点完成互联，在 CPU  的本地内存不足的情况下，CPU 需要通过 QPI 访问远程 NUMA 节点上的内存控制器从而在远程内存节点上分配内存，这就导致了远程访问比本地访问多了额外的延迟开销（需要通过 QPI 遍历远程 NUMA 节点）。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在 NUMA 架构下，只有 DISCONTIGMEM 非连续内存模型和 SPARSEMEM 稀疏内存模型是可用的。而 UMA 架构下，前面介绍的三种内存模型都可以配置使用。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.1 NUMA 的内存分配策略&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NUMA 的内存分配策略是指在 NUMA 架构下 CPU 如何请求内存分配的相关策略，比如：是优先请求本地内存节点分配内存呢 ？还是优先请求指定的 NUMA 节点分配内存 ？是只能在本地内存节点分配呢 ？还是允许当本地内存不足的情况下可以请求远程 NUMA 节点分配内存 ？&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;内存分配策略&lt;/th&gt;&lt;th&gt;策略描述&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;MPOL_BIND&lt;/td&gt;&lt;td&gt;必须在绑定的节点进行内存分配，如果内存不足，则进行 swap&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MPOL_INTERLEAVE&lt;/td&gt;&lt;td&gt;本地节点和远程节点均可允许分配内存&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MPOL_PREFERRED&lt;/td&gt;&lt;td&gt;优先在指定节点分配内存，当指定节点内存不足时，选择离指定节点最近的节点分配内存&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MPOL_LOCAL (默认)&lt;/td&gt;&lt;td&gt;优先在本地节点分配，当本地节点内存不足时，可以在远程节点分配内存&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以在应用程序中通过 libnuma 共享库中的 API 调用 set_mempolicy 接口设置进程的内存分配策略。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;numaif.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;long&lt;/span&gt; &lt;span&gt;set_mempolicy&lt;/span&gt;&lt;span&gt;(&lt;span&gt;int&lt;/span&gt; mode, &lt;span&gt;const&lt;/span&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; *nodemask,&lt;br/&gt;                          &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; maxnode)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;mode : 指定 NUMA 内存分配策略。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;nodemask：指定 NUMA 节点 Id。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;maxnode：指定最大 NUMA 节点 Id，用于遍历远程节点，实现跨 NUMA 节点分配内存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;libnuma 共享库 API 文档：https://man7.org/linux/man-pages/man3/numa.3.html#top_of_page&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;set_mempolicy 接口文档：https://man7.org/linux/man-pages/man2/set_mempolicy.2.html&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.2 NUMA 的使用简介&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们理解了物理内存的 NUMA 架构，以及在 NUMA 架构下的内存分配策略之后，本小节笔者来为大家介绍下如何正确的利用 NUMA  提升我们应用程序的性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前边我们介绍了这么多的理论知识，但是理论的东西总是很虚，正所谓眼见为实，大家一定想亲眼看一下 NUMA 架构在计算机中的具体表现形式，比如：在支持 NUMA 架构的机器上到底有多少个 NUMA 节点？每个 NUMA 节点包含哪些 CPU 核，具体是怎样的一个分布情况？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面也提到 CPU 在访问本地 NUMA 节点中的内存时，速度是最快的。但是当访问远程 NUMA 节点，速度就会相对很慢，那么到底有多慢？本地节点与远程节点之间的访问速度差异具体是多少 ？&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.2.1 查看 NUMA 相关信息&lt;span/&gt;&lt;/h4&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;numactl 文档：https://man7.org/linux/man-pages/man8/numactl.8.html&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对以上具体问题，&lt;code&gt;numactl -H&lt;/code&gt; 命令可以给出我们想要的答案：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;available: 4 nodes (0-3)&lt;br/&gt;node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 &lt;br/&gt;node 0 size: 64794 MB&lt;br/&gt;node 0 free: 55404 MB&lt;br/&gt;&lt;br/&gt;node 1 cpus: 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31&lt;br/&gt;node 1 size: 65404 MB&lt;br/&gt;node 1 free: 58642 MB&lt;br/&gt;&lt;br/&gt;node 2 cpus: 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47&lt;br/&gt;node 2 size: 65404 MB&lt;br/&gt;node 2 free: 61181 MB&lt;br/&gt;&lt;br/&gt;node 3 cpus:  48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63&lt;br/&gt;node 3 size: 65402 MB&lt;br/&gt;node 3 free: 55592 MB&lt;br/&gt;&lt;br/&gt;node distances:&lt;br/&gt;node   0   1   2   3&lt;br/&gt;  0:  10  16  32  33&lt;br/&gt;  1:  16  10  25  32&lt;br/&gt;  2:  32  25  10  16&lt;br/&gt;  3:  33  32  16  10&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;numactl -H&lt;/code&gt; 命令可以查看服务器的 NUMA 配置，上图中的服务器配置共包含 4 个 NUMA 节点（0 - 3），每个 NUMA 节点中包含 16个 CPU 核心，本地内存大小约为 64G。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家可以关注下最后 &lt;code&gt;node distances:&lt;/code&gt; 这一栏，node distances 给出了不同 NUMA 节点之间的访问距离，对角线上的值均为本地节点的访问距离 10 。比如 [0,0] 表示 NUMA 节点 0 的本地内存访问距离。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以很明显的看到当出现跨 NUMA 节点访问的时候，访问距离就会明显增加，比如节点 0 访问节点 1 的距离 [0,1] 是16，节点 0 访问节点 3 的距离 [0,3] 是 33。距离越远，跨 NUMA 节点内存访问的延时越大。应用程序运行时应减少跨 NUMA 节点访问内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外我们还可以通过 &lt;code&gt;numactl -s&lt;/code&gt; 来查看 NUMA 的内存分配策略设置：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;policy: default&lt;br/&gt;preferred node: current&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 &lt;code&gt;numastat&lt;/code&gt; 还可以查看各个 NUMA 节点的内存访问命中率：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;                           node0           node1            node2           node3&lt;br/&gt;numa_hit              1296554257       918018444         1296574252       828018454&lt;br/&gt;numa_miss                8541758        40297198           7544751        41267108&lt;br/&gt;numa_foreign            40288595         8550361          41488585         8450375&lt;br/&gt;interleave_hit             45651           45918            46654           49718&lt;br/&gt;local_node            1231897031       835344122         1141898045       915354158&lt;br/&gt;other_node              64657226        82674322           594657725       82675425 &lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;numa_hit ：内存分配在该节点中成功的次数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;numa_miss : 内存分配在该节点中失败的次数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;numa_foreign：表示其他 NUMA 节点本地内存分配失败，跨节点（numa_miss）来到本节点分配内存的次数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;interleave_hit : 在 MPOL_INTERLEAVE 策略下，在本地节点分配内存的次数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;local_node：进程在本地节点分配内存成功的次数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;other_node：运行在本节点的进程跨节点在其他节点上分配内存的次数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;numastat 文档：https://man7.org/linux/man-pages/man8/numastat.8.html&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.2.2 绑定 NUMA 节点&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;numactl 工具可以让我们应用程序指定运行在哪些 CPU 核心上，同时也可以指定我们的应用程序可以在哪些 NUMA 节点上分配内存。通过将应用程序与具体的 CPU 核心和 NUMA  节点绑定，从而可以提升程序的性能。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;numactl --membind=nodes  --cpunodebind=nodes  command&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过 &lt;code&gt;--membind&lt;/code&gt; 可以指定我们的应用程序只能在哪些具体的 NUMA 节点上分配内存，如果这些节点内存不足，则分配失败。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过 &lt;code&gt;--cpunodebind&lt;/code&gt; 可以指定我们的应用程序只能运行在哪些 NUMA 节点上。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;numactl --physcpubind=cpus  command&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外我们还可以通过 &lt;code&gt;--physcpubind&lt;/code&gt; 将我们的应用程序绑定到具体的物理 CPU 上。这个选项后边指定的参数我们可以通过 &lt;code&gt;cat /proc/cpuinfo&lt;/code&gt; 输出信息中的 processor 这一栏查看。例如：通过 &lt;code&gt;numactl --physcpubind= 0-15 ./numatest.out&lt;/code&gt; 命令将进程 numatest 绑定到 0~15 CPU 上执行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过 numactl 命令将 numatest 进程分别绑定在相同的 NUMA 节点上和不同的 NUMA 节点上，运行观察。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;numactl --membind=0 --cpunodebind=0 ./numatest.out&lt;br/&gt;numactl --membind=0 --cpunodebind=1 ./numatest.out&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家肯定一眼就能看出绑定在相同 NUMA 节点的进程运行会更快，因为通过前边对 NUMA 架构的介绍，我们知道 CPU 访问本地 NUMA 节点的内存是最快的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;除了 numactl 这个工具外，我们还可以通过共享库 libnuma 在程序中进行 NUMA 相关的操作。这里笔者就不演示了，感兴趣可以查看下 libnuma 的 API 文档：https://man7.org/linux/man-pages/man3/numa.3.html#top_of_page&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4. 内核如何管理 NUMA 节点&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在前边我们介绍物理内存模型和物理内存架构的时候提到过：在 NUMA 架构下，只有 DISCONTIGMEM 非连续内存模型和 SPARSEMEM 稀疏内存模型是可用的。而 UMA 架构下，前面介绍的三种内存模型均可以配置使用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;无论是 NUMA 架构还是 UMA 架构在内核中都是使用相同的数据结构来组织管理的，在内核的内存管理模块中会把 UMA 架构当做只有一个 NUMA 节点的伪 NUMA 架构。这样一来这两种架构模式就在内核中被统一管理起来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面笔者先从最顶层的设计开始为大家介绍一下内核是如何管理这些 NUMA 节点的~~&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.525&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicDxwiaoTnGNcLbGwVibpKR5mPxianNrFznqs4VHuuEqK7UECicl6Micicjscw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;NUMA  节点中可能会包含多个 CPU，这些 CPU 均是物理 CPU，这点大家需要注意一下。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.1 内核如何统一组织 NUMA 节点&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们来看第一个问题，在内核中是如何将这些 NUMA 节点统一管理起来的？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核中使用了 struct pglist_data 这样的一个数据结构来描述 NUMA 节点，&lt;strong&gt;在内核 2.4 版本之前&lt;/strong&gt;，内核是使用一个 pgdat_list 单链表将这些 NUMA 节点串联起来的，单链表定义在 &lt;code&gt;/include/linux/mmzone.h&lt;/code&gt; 文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;extern&lt;/span&gt; &lt;span&gt;pg_data_t&lt;/span&gt; *pgdat_list;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 NUMA 节点的数据结构 struct pglist_data 中有一个 next 指针，用于将这些 NUMA 节点串联起来形成 pgdat_list 单链表，链表的末尾节点 next 指针指向 NULL。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; *&lt;span&gt;pgdat_next&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;在内核 2.4 之后的版本中&lt;/strong&gt;，内核移除了 struct pglist_data 结构中的 pgdat_next 之指针, 同时也删除了 pgdat_list 单链表。取而代之的是，内核使用了一个大小为 MAX_NUMNODES ，类型为 struct pglist_data 的全局数组 node_data[] 来管理所有的 NUMA 节点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3548387096774194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicYOmNGPRIJR09xc4cG3X3RdVHgkeibiajMTyhvoxLj9jRFiaTFzZIWA4Jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;全局数组 node_data[] 定义在文件 &lt;code&gt;/arch/arm64/include/asm/mmzone.h&lt;/code&gt;中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_NUMA&lt;/span&gt;&lt;br/&gt;&lt;span&gt;extern&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; *&lt;span&gt;node_data&lt;/span&gt;[];&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; NODE_DATA(nid)  (node_data[(nid)])&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;NODE_DATA(nid) 宏可以通过 NUMA 节点的 nodeId，找到对应的 struct pglist_data 结构。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;node_data[] 数组大小 MAX_NUMNODES 定义在 &lt;code&gt;/include/linux/numa.h&lt;/code&gt;文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_NODES_SHIFT&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; NODES_SHIFT     CONFIG_NODES_SHIFT&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; NODES_SHIFT     0&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; MAX_NUMNODES    (1 &amp;lt;&amp;lt; NODES_SHIFT)&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;UMA  架构下 NODES_SHIFT 为 0 ，所以内核中只用一个 NUMA 节点来管理所有物理内存。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2 NUMA 节点描述符  pglist_data 结构&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// NUMA 节点id&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; node_id;&lt;br/&gt;    &lt;span&gt;// 指向 NUMA 节点内管理所有物理页 page 的数组&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; *&lt;span&gt;node_mem_map&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// NUMA 节点内第一个物理页的 pfn&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; node_start_pfn;&lt;br/&gt;    &lt;span&gt;// NUMA 节点内所有可用的物理页个数（不包含内存空洞）&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; node_present_pages;&lt;br/&gt;    &lt;span&gt;// NUMA 节点内所有的物理页个数（包含内存空洞）&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; node_spanned_pages; &lt;br/&gt;    &lt;span&gt;// 保证多进程可以并发安全的访问 NUMA 节点&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;spinlock_t&lt;/span&gt; node_size_lock;&lt;br/&gt;        .............&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;node_id  表示 NUMA 节点的 id，我们可以通过 numactl -H 命令的输出结果查看节点 id。从 0 开始依次对 NUMA 节点进行编号。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct page 类型的数组 node_mem_map 中包含了 NUMA节点内的所有的物理内存页。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1830645161290323&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicN4Ne8Qc6KmZDnHaiaxpicWl55C5yjCa1zLCQh7tZbAg4bqJHt1OjNBKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;node_start_pfn 指向 NUMA 节点内第一个物理页的 PFN，系统中所有 NUMA 节点中的物理页都是依次编号的，每个物理页的 PFN 都是&lt;strong&gt;全局唯一的&lt;/strong&gt;（不只是其所在 NUMA 节点内唯一）&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0830645161290322&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicl9nLVLtqZdUkjgGY4mjKT8rQ06z3uGC4lCyb0fRr0j5hQMnIliaZCicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;node_present_pages 用于统计 NUMA 节点内所有真正可用的物理页面数量（不包含内存空洞）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 NUMA 节点内包含的物理内存并不总是连续的，可能会包含一些内存空洞，node_spanned_pages 则是用于统计 NUMA 节点内所有的内存页，包含不连续的物理内存地址（内存空洞）的页面数。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.096774193548387&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicxNgbn9Q0ct3vpcRfibLPpu7GE8xNxgagObq6vhpjUb0Je4Y3B0n8yXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上内容是笔者从整体上为大家介绍的 NUMA 节点如何管理节点内部的本地内存。事实上内核还会将 NUMA 节点中的本地内存做近一步的划分。那么为什么要近一步划分呢？&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3 NUMA  节点物理内存区域的划分&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们都知道内核对物理内存的管理都是以页为最小单位来管理的，每页默认 4K 大小，理想状况下任何种类的数据都可以存放在任何页框中，没有什么限制。比如：存放内核数据，用户数据，磁盘缓冲数据等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是实际的计算机体系结构受到硬件方面的制约，间接导致限制了页框的使用方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如在 X86 体系结构下，ISA 总线的 DMA （直接内存存取）控制器，只能对内存的前16M 进行寻址，这就导致了 ISA 设备不能在整个 32 位地址空间中执行 DMA，只能使用物理内存的前 16M 进行 DMA 操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此直接映射区的前 16M 专门让内核用来为 DMA 分配内存，这块 16M 大小的内存区域我们称之为 ZONE_DMA。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;用于 DMA 的内存必须从 ZONE_DMA 区域中分配。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4508064516129032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic6yKlY5dvicFfLEesNMy8pj1Y7AVTkCCJRibyn6sPx2wSKXFw714X17MA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而直接映射区中剩下的部分也就是从 16M 到 896M（不包含 896M）这段区域，我们称之为 ZONE_NORMAL。从字面意义上我们可以了解到，这块区域包含的就是正常的页框（没有任何使用限制）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZONE_NORMAL 由于也是属于直接映射区的一部分，对应的物理内存 16M 到 896M 这段区域也是被直接映射至内核态虚拟内存空间中的 3G + 16M 到 3G + 896M 这段虚拟内存上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而物理内存 896M 以上的区域被内核划分为 ZONE_HIGHMEM 区域，我们称之为高端内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于内核虚拟内存空间中的前 896M 虚拟内存已经被直接映射区所占用，而在 32 体系结构下内核虚拟内存空间总共也就 1G 的大小，这样一来内核剩余可用的虚拟内存空间就变为了 1G - 896M = 128M。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;显然物理内存中剩下的这 3200M 大小的 ZONE_HIGHMEM 区域无法继续通过直接映射的方式映射到这 128M 大小的虚拟内存空间中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样一来物理内存中的 ZONE_HIGHMEM 区域就只能采用动态映射的方式映射到 128M 大小的内核虚拟内存空间中，也就是说只能动态的一部分一部分的分批映射，先映射正在使用的这部分，使用完毕解除映射，接着映射其他部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以内核会根据各个物理内存区域的功能不同，将 NUMA 节点内的物理内存主要划分为以下四个物理内存区域：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_DMA：用于那些无法对全部物理内存进行寻址的硬件设备，进行 DMA 时的内存分配。例如前边介绍的 ISA 设备只能对物理内存的前 16M 进行寻址。该区域的长度依赖于具体的处理器类型。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_DMA32：与 ZONE_DMA 区域类似，该区域内的物理页面可用于执行 DMA 操作，不同之处在于该区域是提供给 32 位设备（只能寻址 4G 物理内存）执行 DMA 操作时使用的。该区域只在 64 位系统中起作用，因为只有在 64 位系统中才会专门为 32 位设备提供专门的 DMA 区域。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_NORMAL：这个区域的物理页都可以直接映射到内核中的虚拟内存，由于是线性映射，内核可以直接进行访问。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_HIGHMEM：这个区域包含的物理页就是我们说的高端内存，内核不能直接访问这些物理页，这些物理页需要动态映射进内核虚拟内存空间中（非线性映射）。该区域只在 32 位系统中才会存在，因为 64 位系统中的内核虚拟内存空间太大了（128T），都可以进行直接映射。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上这些物理内存区域的划分定义在 &lt;code&gt;/include/linux/mmzone.h&lt;/code&gt; 文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;enum&lt;/span&gt; zone_type {&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_ZONE_DMA&lt;/span&gt;&lt;br/&gt; ZONE_DMA,&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_ZONE_DMA32&lt;/span&gt;&lt;br/&gt; ZONE_DMA32,&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt; ZONE_NORMAL,&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_HIGHMEM&lt;/span&gt;&lt;br/&gt; ZONE_HIGHMEM,&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt; ZONE_MOVABLE,&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_ZONE_DEVICE&lt;/span&gt;&lt;br/&gt; ZONE_DEVICE,&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 充当结束标记, 在内核中想要迭代系统中所有内存域时, 会用到该常量&lt;/span&gt;&lt;br/&gt; __MAX_NR_ZONES&lt;br/&gt;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家可能注意到内核中定义的 zone_type 除了上边为大家介绍的四个物理内存区域，又多出了两个区域：ZONE_MOVABLE 和 ZONE_DEVICE。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZONE_DEVICE 是为支持热插拔设备而分配的非易失性内存（ Non Volatile Memory ），也可用于内核崩溃时保存相关的调试信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZONE_MOVABLE 是内核定义的一个&lt;strong&gt;虚拟内存区域&lt;/strong&gt;，该区域中的物理页可以来自于上边介绍的几种真实的物理区域。该区域中的页全部都是可以迁移的，主要是为了防止内存碎片和支持内存的热插拔。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;既然有了这些实际的物理内存区域，那么内核为什么又要划分出一个 ZONE_MOVABLE 这样的虚拟内存区域呢&lt;/strong&gt; ？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为随着系统的运行会伴随着不同大小的物理内存页的分配和释放，这种内存不规则的分配释放随着系统的长时间运行就会导致内存碎片，内存碎片会使得系统在明明有足够内存的情况下，依然无法为进程分配合适的内存。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1338709677419355&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic9y7po4Hb6SNe0yvqbmTHDNFlFIpdvCnhAFpEHy2tggmSGIE07nuyLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如上图所示，假如现在系统一共有 16 个物理内存页，当前系统只是分配了 3 个物理页，那么在当前系统中还剩余 13 个物理内存页的情况下，如果内核想要分配 8 个连续的物理页的话，就会由于内存碎片的存在导致分配失败。（只能分配最多 4 个连续的物理页）&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;内核中请求分配的物理页面数只能是 2 的次幂！！&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果这些物理页处于 ZONE_MOVABLE 区域，它们就可以被迁移，内核可以通过迁移页面来避免内存碎片的问题：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47419354838709676&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicbODibmAicfcvbiat4DpYmPNp6IibK9mDicXZbHqDU5qt4ibhNOXpvsTQuvRQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核通过迁移页面来规整内存，这样就可以避免内存碎片，从而得到一大片连续的物理内存，以满足内核对大块连续内存分配的请求。&lt;strong&gt;所以这就是内核需要根据物理页面是否能够迁移的特性，而划分出 ZONE_MOVABLE 区域的目的&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，我们已经清楚了 NUMA 节点中物理内存区域的划分，下面我们继续回到 struct pglist_data 结构中看下内核如何在 NUMA 节点中组织这些划分出来的内存区域：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;// NUMA 节点中的物理内存区域个数&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; nr_zones; &lt;br/&gt;  &lt;span&gt;// NUMA 节点中的物理内存区域&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; &lt;span&gt;node_zones&lt;/span&gt;[&lt;span&gt;MAX_NR_ZONES&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;// NUMA 节点的备用列表&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zonelist&lt;/span&gt; &lt;span&gt;node_zonelists&lt;/span&gt;[&lt;span&gt;MAX_ZONELISTS&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;} &lt;span&gt;pg_data_t&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nr_zones 用于统计 NUMA 节点内包含的物理内存区域个数，&lt;strong&gt;不是每个 NUMA 节点都会包含以上介绍的所有物理内存区域，NUMA 节点之间所包含的物理内存区域个数是不一样的&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上只有第一个 NUMA 节点可以包含所有的物理内存区域，其它的节点并不能包含所有的区域类型，因为有些内存区域比如：ZONE_DMA，ZONE_DMA32 必须从物理内存的起点开始。这些在物理内存开始的区域可能已经被划分到第一个 NUMA 节点了，后面的物理内存才会被依次划分给接下来的 NUMA 节点。因此后面的 NUMA 节点并不会包含 ZONE_DMA，ZONE_DMA32 区域。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4508064516129032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic6yKlY5dvicFfLEesNMy8pj1Y7AVTkCCJRibyn6sPx2wSKXFw714X17MA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZONE_NORMAL、ZONE_HIGHMEM 和 ZONE_MOVABLE 是可以出现在所有 NUMA 节点上的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.785483870967742&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicsVOBYPApMroOgrjEGBs12ZAvdUPx2pwqbfC0h50MWlr5xCFhbygaXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;node_zones[MAX_NR_ZONES] 数组包含了 NUMA 节点中的所有物理内存区域，物理内存区域在内核中的数据结构是 struct zone 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;node_zonelists[MAX_ZONELISTS] 是 struct zonelist 类型的数组，它包含了备用 NUMA 节点和这些备用节点中的物理内存区域。备用节点是按照访问距离的远近，依次排列在 node_zonelists 数组中，数组第一个备用节点是访问距离最近的，这样当本节点内存不足时，可以从备用 NUMA 节点中分配内存。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;各个 NUMA 节点之间的内存分配情况我们可以通过前边介绍的 &lt;code&gt;numastat &lt;/code&gt; 命令查看。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.4 NUMA 节点中的内存规整与回收&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存可以说是计算机系统中最为宝贵的资源了，再怎么多也不够用，当系统运行时间长了之后，难免会遇到内存紧张的时候，这时候就需要内核将那些不经常使用的内存页面回收起来，或者将那些可以迁移的页面进行内存规整，从而可以腾出连续的物理内存页面供内核分配。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核会为每个 NUMA 节点分配一个 kswapd 进程用于回收不经常使用的页面，还会为每个 NUMA 节点分配一个 kcompactd 进程用于内存的规整避免内存碎片。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;        .........&lt;br/&gt;    &lt;span&gt;// 页面回收进程&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;task_struct&lt;/span&gt; *&lt;span&gt;kswapd&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;wait_queue_head_t&lt;/span&gt; kswapd_wait;&lt;br/&gt;    &lt;span&gt;// 内存规整进程&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;task_struct&lt;/span&gt; *&lt;span&gt;kcompactd&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;wait_queue_head_t&lt;/span&gt; kcompactd_wait;&lt;br/&gt;&lt;br/&gt;        ..........&lt;br/&gt;} &lt;span&gt;pg_data_t&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NUMA 节点描述符 struct pglist_data 结构中的 struct task_struct *kswapd 属性用于指向内核为 NUMA  节点分配的 kswapd 进程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kswapd_wait 用于 kswapd 进程周期性回收页面时使用到的等待队列。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同理 struct task_struct *kcompactd 用于指向内核为 NUMA  节点分配的 kcompactd 进程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kcompactd_wait 用于 kcompactd 进程周期性规整内存时使用到的等待队列。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本小节笔者主要为大家介绍 NUMA 节点的数据结构 struct pglist_data。详细的内存回收会在本文后面的章节单独介绍。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5 NUMA 节点的状态 node_states&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果系统中的 NUMA 节点多于一个，内核会维护一个位图 node_states，用于维护各个 NUMA 节点的状态信息。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果系统中只有一个 NUMA  节点，则没有节点位图。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;节点位图以及节点的状态掩码值定义在 &lt;code&gt;/include/linux/nodemask.h&lt;/code&gt; 文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt; DECLARE_BITMAP(bits, MAX_NUMNODES); } &lt;span&gt;nodemask_t&lt;/span&gt;;&lt;br/&gt;&lt;span&gt;extern&lt;/span&gt; &lt;span&gt;nodemask_t&lt;/span&gt; node_states[NR_NODE_STATES];&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;节点的状态可通过以下掩码表示：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;enum&lt;/span&gt; node_states {&lt;br/&gt; N_POSSIBLE,  &lt;span&gt;/* The node could become online at some point */&lt;/span&gt;&lt;br/&gt; N_ONLINE,  &lt;span&gt;/* The node is online */&lt;/span&gt;&lt;br/&gt; N_NORMAL_MEMORY, &lt;span&gt;/* The node has regular memory */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_HIGHMEM&lt;/span&gt;&lt;br/&gt; N_HIGH_MEMORY,  &lt;span&gt;/* The node has regular or high memory */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br/&gt; N_HIGH_MEMORY = N_NORMAL_MEMORY,&lt;br/&gt;#endif&lt;br/&gt;#ifdef CONFIG_MOVABLE_NODE&lt;br/&gt; N_MEMORY,  &lt;span&gt;/* The node has memory(regular, high, movable) */&lt;/span&gt;&lt;br/&gt;#&lt;span&gt;else&lt;/span&gt;&lt;br/&gt; N_MEMORY = N_HIGH_MEMORY,&lt;br/&gt;#endif&lt;br/&gt; N_CPU,  &lt;span&gt;/* The node has one or more cpus */&lt;/span&gt;&lt;br/&gt; NR_NODE_STATES&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;N_POSSIBLE 表示 NUMA 节点在某个时刻可以变为 online 状态，N_ONLINE 表示 NUMA 节点当前的状态为 online 状态。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在本文《2.3.1 物理内存热插拔》小节中提到，在稀疏内存模型中，NUMA 节点的状态可以在系统运行的过程中随时切换 online ，offline 的状态，用来支持内存的热插拔。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5661290322580645&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicRjmAmoed0KMMDBbfaicAYIibgnQOe5BQPFvFSqicCMkKKeGaQ9eYiaicauQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;N_NORMAL_MEMORY 表示节点没有高端内存，只有 ZONE_NORMAL 内存区域。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;N_HIGH_MEMORY 表示节点有 ZONE_NORMAL 内存区域或者有 ZONE_HIGHMEM 内存区域。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;N_MEMORY 表示节点有 ZONE_NORMAL，ZONE_HIGHMEM，ZONE_MOVABLE 内存区域。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;N_CPU 表示节点包含一个或多个 CPU。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外内核还提供了两个辅助函数用于设置或者清除指定节点的特定状态：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;node_set_state&lt;/span&gt;&lt;span&gt;(&lt;span&gt;int&lt;/span&gt; node, &lt;span&gt;enum&lt;/span&gt; node_states state)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;node_clear_state&lt;/span&gt;&lt;span&gt;(&lt;span&gt;int&lt;/span&gt; node, &lt;span&gt;enum&lt;/span&gt; node_states state)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核提供了 for_each_node_state 宏用于迭代处于特定状态的所有 NUMA 节点。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; for_each_node_state(__node, __state) \&lt;br/&gt; for_each_node_mask((__node), node_states[__state])&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如：for_each_online_node 用于迭代所有 online 的 NUMA 节点：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; for_each_online_node(node) for_each_node_state(node, N_ONLINE)&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5. 内核如何管理 NUMA 节点中的物理内存区域&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.785483870967742&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicsVOBYPApMroOgrjEGBs12ZAvdUPx2pwqbfC0h50MWlr5xCFhbygaXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在前边《4.3 NUMA 节点物理内存区域的划分》小节的介绍中，由于实际的计算机体系结构受到硬件方面的制约，间接限制了页框的使用方式。于是内核会根据各个物理内存区域的功能不同，将 NUMA 节点内的物理内存划分为：ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_HIGHMEM 这几个物理内存区域。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;ZONE_MOVABLE 区域是内核从逻辑上的划分，区域中的物理页面来自于上述几个内存区域，目的是避免内存碎片和支持内存热插拔（前边笔者已经介绍过了）。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过 &lt;code&gt;cat /proc/zoneinfo | grep Node&lt;/code&gt; 命令来查看 NUMA 节点中内存区域的分布情况：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.16446124763705103&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic92icjo70KcLqZgyPRaKhgWFRVkFu60NmKNXNH0tndM6hRGcbx4zSIag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;笔者使用的服务器是 64 位，所以不包含 ZONE_HIGHMEM 区域。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 &lt;code&gt;cat /proc/zoneinfo&lt;/code&gt; 命令来查看系统中各个 NUMA 节点中的各个内存区域的内存使用情况：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;下图中我们以 NUMA Node 0 中的 ZONE_NORMAL 区域为例说明，大家只需要浏览一个大概，图中每个字段的含义笔者会在本小节的后面一一为大家介绍~~~&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7516129032258064&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlics4pddq3icDJKJhTtOg46hWhBsGblgIycfqoYRBGIPzCDMThpsIXGZKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核中用于描述和管理 NUMA 节点中的物理内存区域的结构体是 struct zone，上图中显示的 ZONE_NORMAL 区域中，物理内存使用统计的相关数据均来自于 struct zone 结构体，我们先来看一下内核对 struct zone 结构体的整体布局情况：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    .............省略..............&lt;br/&gt;&lt;br/&gt;    ZONE_PADDING(_pad1_)&lt;br/&gt;&lt;br/&gt;    .............省略..............&lt;br/&gt;&lt;br/&gt;    ZONE_PADDING(_pad2_)&lt;br/&gt;&lt;br/&gt;    .............省略..............&lt;br/&gt;&lt;br/&gt;    ZONE_PADDING(_pad3_)&lt;br/&gt;&lt;br/&gt;    .............省略..............&lt;br/&gt;&lt;br/&gt;} ____cacheline_internodealigned_in_smp;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 struct zone 结构体在内核中是一个访问非常频繁的结构体，在多处理器系统中，会有不同的 CPU 同时大量频繁的访问 struct zone 结构体中的不同字段。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此内核对 struct zone 结构体的设计是相当考究的，将这些频繁访问的字段信息归类为 4 个部分，并通过 ZONE_PADDING 来分割。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目的是通过 ZONE_PADDING 来填充字节，将这四个部分，分别填充到不同的 CPU 高速缓存行（cache line）中，使得它们各自独占 cache line，提高访问性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据前边物理内存区域划分的相关内容介绍，我们知道内核会把 NUMA 节点中的物理内存区域顶多划分为 ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_HIGHMEM 这几个物理内存区域。因此 struct zone 的实例在内核中会相对比较少，通过 ZONE_PADDING 填充字节，带来的 struct zone 结构体实例内存占用增加是可以忽略不计的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在结构体的最后内核还是用了 &lt;code&gt;____cacheline_internodealigned_in_smp &lt;/code&gt; 编译器关键字来实现最优的高速缓存行对齐方式。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;关于 CPU 高速缓存行对齐的详细内容，感兴趣的同学可以回看下笔者之前的文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247484304&amp;amp;idx=1&amp;amp;sn=54bf0d07e69c5621c145afaece8f50d6&amp;amp;chksm=ce77c5d7f9004cc1249a03dfd0fb12b7d75171f1b87acea1fa44bbb11ca374b6f42a66fa274d&amp;amp;token=174519396&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《一文聊透对象在JVM中的内存布局，以及内存对齐和压缩指针的原理及应用》&lt;/a&gt; 。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;笔者为了使大家能够更好地理解内核如何使用 struct zone 结构体来描述内存区域，从而把结构体中的字段按照一定的层次结构重新排列介绍，这并不是原生的字段对齐方式，这一点需要大家注意！！！&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 防止并发访问该内存区域&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;spinlock_t&lt;/span&gt;      lock;&lt;br/&gt;    &lt;span&gt;// 内存区域名称：Normal ，DMA，HighMem&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;char&lt;/span&gt;      *name;&lt;br/&gt;    &lt;span&gt;// 指向该内存区域所属的 NUMA 节点&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt;  *&lt;span&gt;zone_pgdat&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 属于该内存区域中的第一个物理页 PFN&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;       zone_start_pfn;&lt;br/&gt;    &lt;span&gt;// 该内存区域中所有的物理页个数（包含内存空洞）&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;       spanned_pages;&lt;br/&gt;    &lt;span&gt;// 该内存区域所有可用的物理页个数（不包含内存空洞）&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;       present_pages;&lt;br/&gt;    &lt;span&gt;// 被伙伴系统所管理的物理页数&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;atomic_long_t&lt;/span&gt;       managed_pages;&lt;br/&gt;    &lt;span&gt;// 伙伴系统的核心数据结构&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;free_area&lt;/span&gt;    &lt;span&gt;free_area&lt;/span&gt;[&lt;span&gt;MAX_ORDER&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 该内存区域内存使用的统计信息&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;atomic_long_t&lt;/span&gt;       vm_stat[NR_VM_ZONE_STAT_ITEMS];&lt;br/&gt;} ____cacheline_internodealigned_in_smp;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct zone 是会被内核频繁访问的一个结构体，在多核处理器中，多个 CPU 会并发访问 struct zone，为了防止并发访问，内核使用了一把 spinlock_t   lock 自旋锁来防止并发错误以及不一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;name 属性会根据该内存区域的类型不同保存内存区域的名称，比如：Normal ，DMA，HighMem 等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前边我们介绍 NUMA 节点的描述符 struct pglist_data 的时候提到，pglist_data 通过 struct zone 类型的数组 node_zones 将 NUMA 节点中划分的物理内存区域连接起来。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;typedef&lt;/span&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;pglist_data&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// NUMA 节点中的物理内存区域个数&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; nr_zones; &lt;br/&gt;    &lt;span&gt;// NUMA 节点中的物理内存区域&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; &lt;span&gt;node_zones&lt;/span&gt;[&lt;span&gt;MAX_NR_ZONES&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些物理内存区域也会通过 struct zone 中的 zone_pgdat 指向自己所属的 NUMA 节点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6241935483870967&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicspkgYcHX4KH25pDRahqQkIvP22cIehdPYGP4iaq290Iq5DASEg0TdyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NUMA 节点 struct pglist_data 结构中的 node_start_pfn 指向 NUMA 节点内第一个物理页的 PFN。同理物理内存区域 struct zone 结构中的 zone_start_pfn 指向的是该内存区域内所管理的第一个物理页面 PFN 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后面的属性也和 NUMA 节点对应的字段含义一样，比如：spanned_pages 表示该内存区域内所有的物理页总数（包含内存空洞），通过 &lt;code&gt;spanned_pages = zone_end_pfn - zone_start_pfn&lt;/code&gt; 计算得到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;present_pages 则表示该内存区域内所有实际可用的物理页面总数（不包含内存空洞），通过 &lt;code&gt;present_pages = spanned_pages - absent_pages(pages in holes)&lt;/code&gt; 计算得到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 NUMA 架构下，物理内存被划分成了一个一个的内存节点（NUMA 节点），在每个 NUMA 节点内部又将其所管理的物理内存按照功能不同划分成了不同的内存区域，每个内存区域管理一片用于具体功能的物理内存，而内核会为每一个内存区域分配一个伙伴系统用于管理该内存区域下物理内存的分配和释放。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;物理内存在内核中管理的层级关系为：&lt;code&gt;None -&amp;gt; Zone -&amp;gt; page&lt;/code&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4798387096774194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicrYBjP2hiaRwBLYeCniaSic44IIksFicbdCWrUCbvnLcOiaExKSJsZVLPkGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct zone 结构中的 managed_pages 用于表示该内存区域内被伙伴系统所管理的物理页数量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数组 free_area[MAX_ORDER]  是伙伴系统的核心数据结构，笔者会在后面的系列文章中详细为大家介绍伙伴系统的实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;vm_stat 维护了该内存区域物理内存的使用统计信息，前边介绍的 &lt;code&gt;cat /proc/zoneinfo&lt;/code&gt;命令的输出数据就来源于这个 vm_stat。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7516129032258064&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlics4pddq3icDJKJhTtOg46hWhBsGblgIycfqoYRBGIPzCDMThpsIXGZKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1 物理内存区域中的预留内存&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了前边介绍的关于物理内存区域的这些基本信息之外，每个物理内存区域 struct zone 还为操作系统预留了一部分内存，这部分预留的物理内存用于内核的一些核心操作，这些操作无论如何是不允许内存分配失败的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;什么意思呢？内核中关于内存分配的场景无外乎有两种方式：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当进程请求内核分配内存时，如果此时内存比较充裕，那么进程的请求会被立刻满足，如果此时内存已经比较紧张，内核就需要将一部分不经常使用的内存进行回收，从而腾出一部分内存满足进程的内存分配的请求，在这个回收内存的过程中，进程会一直阻塞等待。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;另一种内存分配场景，进程是不允许阻塞的，内存分配的请求必须马上得到满足，比如执行中断处理程序或者执行持有自旋锁等临界区内的代码时，进程就不允许睡眠，因为中断程序无法被重新调度。这时就需要内核提前为这些核心操作预留一部分内存，当内存紧张时，可以使用这部分预留的内存给这些操作分配。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;             ...........&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; nr_reserved_highatomic;&lt;br/&gt;    &lt;span&gt;long&lt;/span&gt; lowmem_reserve[MAX_NR_ZONES];&lt;br/&gt;            &lt;br/&gt;             ...........&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nr_reserved_highatomic 表示的是该内存区域内预留内存的大小，范围为 128 到 65536 KB 之间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;lowmem_reserve 数组则是用于规定每个内存区域必须为自己保留的物理页数量，防止更高位的内存区域对自己的内存空间进行过多的侵占挤压。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么什么是高位内存区域 ？什么是低位内存区域 ？ 高位内存区域为什么会对低位内存区域进行侵占挤压呢 ？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为物理内存区域比如前边介绍的 ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_HIGHMEM 这些都是针对物理内存进行的划分，所谓的低位内存区域和高位内存区域其实还是按照物理内存地址从低到高进行排列布局：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4508064516129032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlic6yKlY5dvicFfLEesNMy8pj1Y7AVTkCCJRibyn6sPx2wSKXFw714X17MA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据物理内存地址的高低，低位内存区域到高位内存区域的顺序依次是：ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_HIGHMEM。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;高位内存区域为什么会对低位内存区域进行挤压呢&lt;/strong&gt; ？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一些用于特定功能的物理内存必须从特定的内存区域中进行分配，比如外设的 DMA 控制器就必须从 ZONE_DMA 或者 ZONE_DMA32 中分配内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是一些用于常规用途的物理内存则可以从多个物理内存区域中进行分配，当 ZONE_HIGHMEM 区域中的内存不足时，内核可以从 ZONE_NORMAL 进行内存分配，ZONE_NORMAL 区域内存不足时可以进一步降级到 ZONE_DMA 区域进行分配。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而低位内存区域中的内存总是宝贵的，内核肯定希望这些用于常规用途的物理内存从常规内存区域中进行分配，这样能够节省 ZONE_DMA 区域中的物理内存保证 DMA 操作的内存使用需求，但是如果内存很紧张了，高位内存区域中的物理内存不够用了，那么内核就会去占用挤压其他内存区域中的物理内存从而满足内存分配的需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是内核又不会允许高位内存区域对低位内存区域的无限制挤压占用，因为毕竟低位内存区域有它特定的用途，所以每个内存区域会给自己预留一定的内存，防止被高位内存区域挤压占用。而每个内存区域为自己预留的这部分内存就存储在 lowmem_reserve 数组中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个内存区域是按照一定的比例来计算自己的预留内存的，这个比例我们可以通过 &lt;code&gt;cat /proc/sys/vm/lowmem_reserve_ratio&lt;/code&gt; 命令查看：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.06997742663656885&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicIaNZ795tUk4fnsFxsyLsff5YRE4OxPicTVTeIvp2HWZhQILxvmEFFmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;886&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从左到右分别代表了 ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_MOVABLE，ZONE_DEVICE 物理内存区域的预留内存比例。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;笔者使用的服务器是 64 位，所以没有 ZONE_HIGHMEM 区域。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么每个内存区域如何根据各自的 lowmem_reserve_ratio 来计算各自区域中的预留内存大小呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了让大家更好的理解，下面我们以 ZONE_DMA，ZONE_NORMAL，ZONE_HIGHMEM 这三个物理内存区域举例，它们的 lowmem_reserve_ratio 分别为 256，32，0。它们的大小分别是：8M，64M，256M，按照每页大小 4K 计算它们区域里包含的物理页个数分别为：2048, 16384, 65536。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;br/&gt;&lt;/th&gt;&lt;th&gt;lowmem_reserve_ratio&lt;/th&gt;&lt;th&gt;内存区域大小&lt;/th&gt;&lt;th&gt;物理内存页个数&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ZONE_DMA&lt;/td&gt;&lt;td&gt;256&lt;/td&gt;&lt;td&gt;8M&lt;/td&gt;&lt;td&gt;2048&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ZONE_NORMAL&lt;/td&gt;&lt;td&gt;32&lt;/td&gt;&lt;td&gt;64M&lt;/td&gt;&lt;td&gt;16384&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ZONE_HIGHMEM&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;256M&lt;/td&gt;&lt;td&gt;65536&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_DMA 为防止被 ZONE_NORMAL 挤压侵占，而为自己预留的物理内存页为：&lt;code&gt;16384 / 256 = 64&lt;/code&gt;。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_DMA 为防止被 ZONE_HIGHMEM 挤压侵占而为自己预留的物理内存页为：&lt;code&gt;(65536 + 16384) / 256 = 320&lt;/code&gt;。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ZONE_NORMAL 为防止被 ZONE_HIGHMEM 挤压侵占而为自己预留的物理内存页为：&lt;code&gt;65536 / 32 = 2048&lt;/code&gt;。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;各个内存区域为防止被高位内存区域过度挤压占用，而为自己预留的内存大小，我们可以通过前边 &lt;code&gt;cat /proc/zoneinfo&lt;/code&gt; 命令来查看，输出信息的 &lt;code&gt;protection：&lt;/code&gt;则表示各个内存区域预留内存大小。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicyzoWFoibykM79P19UaWZhQur7jIhFWDw9PqMPh4iaocrnsIkJ8DIyH5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1116&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外我们还可以通过 &lt;code&gt;sysctl &lt;/code&gt;对内核参数 &lt;code&gt;lowmem_reserve_ratio&lt;/code&gt; 进行动态调整，这样内核会根据新的 lowmem_reserve_ratio 动态重新计算各个内存区域的预留内存大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面介绍的物理内存区域内被伙伴系统所管理的物理页数量 managed_pages 的计算方式就通过 present_pages 减去这些预留的物理内存页 reserved_pages 得到的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;调整内核参数的多种方法，笔者在&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt; 一文中的 &quot;13.6 脏页回写参数的相关配置方式&quot; 小节中已经详细介绍过了，感兴趣的同学可以在回看下。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2 物理内存区域中的水位线&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存资源是系统中最宝贵的系统资源，是有限的。当内存资源紧张的时候，系统的应对方法无非就是三种：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;产生 OOM，内核直接将系统中占用大量内存的进程，将 OOM 优先级最高的进程干掉，释放出这个进程占用的内存供其他更需要的进程分配使用。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;内存回收，将不经常使用到的内存回收，腾挪出来的内存供更需要的进程分配使用。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;内存规整，将可迁移的物理页面进行迁移规整，消除内存碎片。从而获得更大的一片连续物理内存空间供进程分配。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们都知道，内核将物理内存划分成一页一页的单位进行管理（每页 4K 大小）。内存回收的单位也是按页来的。在内核中，物理内存页有两种类型，针对这两种类型的物理内存页，内核会有不同的回收机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一种就是文件页，所谓文件页就是其物理内存页中的数据来自于磁盘中的文件，当我们进行文件读取的时候，内核会根据局部性原理将读取的磁盘数据缓存在 page cache 中，page cache 里存放的就是文件页。当进程再次读取读文件页中的数据时，内核直接会从 page cache 中获取并拷贝给进程，省去了读取磁盘的开销。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于文件页的回收通常会比较简单，因为文件页中的数据来自于磁盘，所以当回收文件页的时候直接回收就可以了，当进程再次读取文件页时，大不了再从磁盘中重新读取就是了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是当进程已经对文件页进行修改过但还没来得及同步回磁盘，此时文件页就是脏页，不能直接进行回收，需要先将脏页回写到磁盘中才能进行回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以在进程中通过  fsync()  系统调用将指定文件的所有脏页同步回写到磁盘，同时内核也会根据一定的条件唤醒专门用于回写脏页的 pflush 内核线程。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;关于文件页相关的详细内容，感兴趣的同学可以回看下笔者的这篇文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt; 。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而另外一种物理页类型是匿名页，所谓匿名页就是它背后并没有一个磁盘中的文件作为数据来源，匿名页中的数据都是通过进程运行过程中产生的，比如我们应用程序中动态分配的堆内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当内存资源紧张需要对不经常使用的那些匿名页进行回收时，因为匿名页的背后没有一个磁盘中的文件做依托，所以匿名页不能像文件页那样直接回收，无论匿名页是不是脏页，都需要先将匿名页中的数据先保存在磁盘空间中，然后在对匿名页进行回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并把释放出来的这部分内存分配给更需要的进程使用，当进程再次访问这块内存时，在重新把之前匿名页中的数据从磁盘空间中读取到内存就可以了，而这块磁盘空间可以是单独的一片磁盘分区（Swap 分区）或者是一个特殊的文件（Swap 文件）。匿名页的回收机制就是我们经常看到的 Swap 机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所谓的页面换出就是在 Swap 机制下，当内存资源紧张时，内核就会把不经常使用的这些匿名页中的数据写入到 Swap 分区或者 Swap 文件中。从而释放这些数据所占用的内存空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所谓的页面换入就是当进程再次访问那些被换出的数据时，内核会重新将这些数据从 Swap 分区或者 Swap 文件中读取到内存中来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上所述，物理内存区域中的内存回收分为文件页回收（通过 pflush 内核线程）和匿名页回收（通过 kswapd 内核进程）。Swap 机制主要针对的是匿名页回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么当内存紧张的时候，内核到底是该回收文件页呢？还是该回收匿名页呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上 Linux 提供了一个 swappiness 的内核选项，我们可以通过 &lt;code&gt;cat /proc/sys/vm/swappiness&lt;/code&gt;  命令查看，swappiness 选项的取值范围为 0 到 100，默认为 60。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;swappiness 用于表示 Swap 机制的积极程度，数值越大，Swap 的积极程度越高，内核越倾向于回收匿名页。数值越小，Swap 的积极程度越低。内核就越倾向于回收文件页。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意： swappiness 只是表示 Swap 积极的程度，当内存非常紧张的时候，即使将 swappiness 设置为 0 ，也还是会发生 Swap 的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么到底什么时候内存才算是紧张的？紧张到什么程度才开始 Swap 呢？这一切都需要一个量化的标准，于是就有了本小节的主题 —— 物理内存区域中的水位线。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核会为每个 NUMA 节点中的每个物理内存区域定制三条用于指示内存容量的水位线，分别是：WMARK_MIN（页最小阈值）， WMARK_LOW （页低阈值），WMARK_HIGH（页高阈值）。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4798387096774194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicrYBjP2hiaRwBLYeCniaSic44IIksFicbdCWrUCbvnLcOiaExKSJsZVLPkGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这三条水位线定义在 &lt;code&gt;/include/linux/mmzone.h&lt;/code&gt; 文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;enum&lt;/span&gt; zone_watermarks {&lt;br/&gt; WMARK_MIN,&lt;br/&gt; WMARK_LOW,&lt;br/&gt; WMARK_HIGH,&lt;br/&gt; NR_WMARK&lt;br/&gt;};&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; min_wmark_pages(z) (z-&amp;gt;_watermark[WMARK_MIN] + z-&amp;gt;watermark_boost)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; low_wmark_pages(z) (z-&amp;gt;_watermark[WMARK_LOW] + z-&amp;gt;watermark_boost)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; high_wmark_pages(z) (z-&amp;gt;_watermark[WMARK_HIGH] + z-&amp;gt;watermark_boost)&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这三条水位线对应的 watermark 数值存储在每个物理内存区域 struct zone 结构中的 _watermark[NR_WMARK] 数组中。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 物理内存区域中的水位线&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; _watermark[NR_WMARK];&lt;br/&gt;    &lt;span&gt;// 优化内存碎片对内存分配的影响，可以动态改变内存区域的基准水位线。&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; watermark_boost;&lt;br/&gt;&lt;br/&gt;} ____cacheline_internodealigned_in_smp;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：下面提到的物理内存区域的剩余内存是需要刨去上小节介绍的 lowmem_reserve 预留内存大小。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0443548387096775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicVEWe42vYricicowskG2dt8f11cdDTcbuDoUjGJiaE6osibVhNp0L3dkgCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当该物理内存区域的剩余内存容量高于  _watermark[WMARK_HIGH] 时，说明此时该物理内存区域中的内存容量非常充足，内存分配完全没有压力。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当剩余内存容量在 _watermark[WMARK_LOW] 与_watermark[WMARK_HIGH] 之间时，说明此时内存有一定的消耗但是还可以接受，能够继续满足进程的内存分配需求。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当剩余内容容量在 _watermark[WMARK_MIN] 与 _watermark[WMARK_LOW]  之间时，说明此时内存容量已经有点危险了，内存分配面临一定的压力，但是还可以满足进程的内存分配要求，当给进程分配完内存之后，就会唤醒 kswapd 进程开始内存回收，直到剩余内存高于 _watermark[WMARK_HIGH] 为止。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在这种情况下，进程的内存分配会触发内存回收，但请求进程本身不会被阻塞，由内核的 kswapd 进程异步回收内存。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;当剩余内容容量低于 _watermark[WMARK_MIN] 时，说明此时的内容容量已经非常危险了，如果进程在这时请求内存分配，内核就会进行&lt;strong&gt;直接内存回收&lt;/strong&gt;，这时请求进程会同步阻塞等待，直到内存回收完毕。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;位于 _watermark[WMARK_MIN] 以下的内存容量是预留给内核在紧急情况下使用的，这部分内存就是我们在 《5.1 物理内存区域中的预留内存》小节中介绍的预留内存 nr_reserved_highatomic。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过 &lt;code&gt;cat /proc/zoneinfo&lt;/code&gt; 命令来查看不同 NUMA 节点中不同内存区域中的水位线：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.471563981042654&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicVUmYFvwmPys4bvfmd9qGqynJl6uJUibXRdXqQiapsVziaTcT2maD3eMvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;844&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中大部分字段的含义笔者已经在前面的章节中为大家介绍过了，下面我们只介绍和本小节内容相关的字段含义：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;free 就是该物理内存区域内剩余的内存页数，它的值和后面的 nr_free_pages 相同。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;min、low、high 就是上面提到的三条内存水位线：_watermark[WMARK_MIN]，_watermark[WMARK_LOW] ，_watermark[WMARK_HIGH]。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;nr_zone_active_anon 和 nr_zone_inactive_anon 分别是该内存区域内活跃和非活跃的匿名页数量。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;nr_zone_active_file 和 nr_zone_inactive_file 分别是该内存区域内活跃和非活跃的文件页数量。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.3 水位线的计算&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上小节中我们介绍了内核通过对物理内存区域设置内存水位线来决定内存回收的时机，那么这三条内存水位线的值具体是多少，内核中是根据什么计算出来的呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上 WMARK_MIN，WMARK_LOW ，WMARK_HIGH 这三个水位线的数值是通过内核参数  &lt;code&gt;/proc/sys/vm/min_free_kbytes&lt;/code&gt; 为基准分别计算出来的，用户也可以通过 &lt;code&gt;sysctl&lt;/code&gt; 来动态设置这个内核参数。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;内核参数 min_free_kbytes 的单位为 KB 。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07710280373831775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicY1icPUAAIw1aHDibmkwVDa8npjfJRJ72OiaaJxbBtTAojibKCI0TOu57Tw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;856&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通常情况下 WMARK_LOW 的值是 WMARK_MIN 的 1.25 倍，WMARK_HIGH 的值是 WMARK_LOW 的 1.5 倍。而 WMARK_MIN 的数值就是由这个内核参数 min_free_kbytes 来决定的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们就来看下内核中关于 min_free_kbytes 的计算方式：&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4 min_free_kbytes 的计算逻辑&lt;span/&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;以下计算逻辑是针对 64 位系统中内存区域水位线的计算，在 64 位系统中没有高端内存  ZONE_HIGHMEM 区域。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;min_free_kbytes 的计算逻辑定义在内核文件 &lt;code&gt;/mm/page_alloc.c&lt;/code&gt; 的 &lt;code&gt;init_per_zone_wmark_min&lt;/code&gt; 方法中，用于计算最小水位线 WMARK_MIN 的数值也就是这里的 min_free_kbytes （单位为 KB）。 水位线的单位是物理内存页的数量。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; __meminit &lt;span&gt;init_per_zone_wmark_min&lt;/span&gt;&lt;span&gt;(&lt;span&gt;void&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// 低位内存区域（除高端内存之外）的总和&lt;/span&gt;&lt;br/&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; lowmem_kbytes;&lt;br/&gt;  &lt;span&gt;// 待计算的 min_free_kbytes&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; new_min_free_kbytes;&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;// 将低位内存区域内存容量总的页数转换为 KB&lt;/span&gt;&lt;br/&gt; lowmem_kbytes = nr_free_buffer_pages() * (PAGE_SIZE &amp;gt;&amp;gt; &lt;span&gt;10&lt;/span&gt;);&lt;br/&gt;  &lt;span&gt;// min_free_kbytes 计算逻辑：对 lowmem_kbytes * 16 进行开平方&lt;/span&gt;&lt;br/&gt; new_min_free_kbytes = int_sqrt(lowmem_kbytes * &lt;span&gt;16&lt;/span&gt;);&lt;br/&gt;  &lt;span&gt;// min_free_kbytes 的范围为 128 到 65536 KB 之间&lt;/span&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (new_min_free_kbytes &amp;gt; user_min_free_kbytes) {&lt;br/&gt;  min_free_kbytes = new_min_free_kbytes;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (min_free_kbytes &amp;lt; &lt;span&gt;128&lt;/span&gt;)&lt;br/&gt;   min_free_kbytes = &lt;span&gt;128&lt;/span&gt;;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (min_free_kbytes &amp;gt; &lt;span&gt;65536&lt;/span&gt;)&lt;br/&gt;   min_free_kbytes = &lt;span&gt;65536&lt;/span&gt;;&lt;br/&gt; } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;  pr_warn(&lt;span&gt;&quot;min_free_kbytes is not updated to %d because user defined value %d is preferred\n&quot;&lt;/span&gt;,&lt;br/&gt;    new_min_free_kbytes, user_min_free_kbytes);&lt;br/&gt; }&lt;br/&gt;  &lt;span&gt;// 计算内存区域内的三条水位线&lt;/span&gt;&lt;br/&gt; setup_per_zone_wmarks();&lt;br/&gt;  &lt;span&gt;// 计算内存区域的预留内存大小，防止被高位内存区域过度挤压占用&lt;/span&gt;&lt;br/&gt; setup_per_zone_lowmem_reserve();&lt;br/&gt;        .............省略................&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;core_initcall(init_per_zone_wmark_min)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们需要先计算出当前 NUMA 节点中所有低位内存区域（除高端内存之外）中内存总容量之和。也即是说 lowmem_kbytes 的值为： ZONE_DMA 区域中 managed_pages + ZONE_DMA32 区域中 managed_pages + ZONE_NORMAL 区域中 managed_pages 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;lowmem_kbytes 的计算逻辑在 &lt;code&gt;nr_free_zone_pages&lt;/code&gt; 方法中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * nr_free_zone_pages - count number of pages beyond high watermark&lt;br/&gt; * @offset: The zone index of the highest zone&lt;br/&gt; *&lt;br/&gt; * nr_free_zone_pages() counts the number of counts pages which are beyond the&lt;br/&gt; * high watermark within all zones at or below a given zone index.  For each&lt;br/&gt; * zone, the number of pages is calculated as:&lt;br/&gt; *     managed_pages - high_pages&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; &lt;span&gt;nr_free_zone_pages&lt;/span&gt;&lt;span&gt;(&lt;span&gt;int&lt;/span&gt; offset)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zoneref&lt;/span&gt; *&lt;span&gt;z&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; *&lt;span&gt;zone&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; sum = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;// 获取当前 NUMA 节点中的所有物理内存区域 zone&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zonelist&lt;/span&gt; *&lt;span&gt;zonelist&lt;/span&gt; = &lt;span&gt;node_zonelist&lt;/span&gt;(&lt;span&gt;numa_node_id&lt;/span&gt;(), &lt;span&gt;GFP_KERNEL&lt;/span&gt;);&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 计算所有物理内存区域内 managed_pages - high_pages 的总和&lt;/span&gt;&lt;br/&gt; for_each_zone_zonelist(zone, z, zonelist, offset) {&lt;br/&gt;  &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; size = zone-&amp;gt;managed_pages;&lt;br/&gt;  &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; high = high_wmark_pages(zone);&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (size &amp;gt; high)&lt;br/&gt;   sum += size - high;&lt;br/&gt; }&lt;br/&gt;    &lt;span&gt;// lowmem_kbytes 的值&lt;/span&gt;&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; sum;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nr_free_zone_pages 方法上面的注释大家可能看的有点蒙，这里需要为大家解释一下，nr_free_zone_pages 方法的计算逻辑本意是给定一个 zone index （方法参数 offset），计算范围为：这个给定 zone 下面的所有低位内存区域。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nr_free_zone_pages 方法会计算这些低位内存区域内在 high watermark 水位线之上的内存容量（ managed_pages - high_pages ）之和。作为该方法的返回值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但此时我们正准备计算这些水位线，水位线还没有值，所以此时这个方法的语义就是计算低位内存区域内被伙伴系统所管理的内存容量（ managed_pages ）之和。也就是我们想要的 lowmem_kbytes。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来在 init_per_zone_wmark_min  方法中会对 lowmem_kbytes * 16 进行开平方得到 new_min_free_kbytes。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.056451612903225805&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicO7aibEGSkSHeVR7FkibFq1hIx3xdZW7SN4HTNKYQlwmr1xibrDS6nf4OQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果计算出的 new_min_free_kbytes 大于用户设置的内核参数值 &lt;code&gt;/proc/sys/vm/min_free_kbytes&lt;/code&gt; ，那么最终 min_free_kbytes 就是 new_min_free_kbytes。如果小于用户设定的值，那么就采用用户指定的 min_free_kbytes 。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;min_free_kbytes 的取值范围限定在 128 到 65536 KB 之间。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随后内核会根据这个 min_free_kbytes 在 setup_per_zone_wmarks() 方法中计算出该物理内存区域的三条水位线。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后在 setup_per_zone_lowmem_reserve() 方法中计算内存区域的预留内存大小，防止被高位内存区域过度挤压占用。该方法的逻辑就是我们在《5.1 物理内存区域中的预留内存》小节中提到的内容。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.5 setup_per_zone_wmarks 计算水位线&lt;span/&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;这里我们依然不会考虑高端内存区域 ZONE_HIGHMEM。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;物理内存区域内的三条水位线：WMARK_MIN，WMARK_LOW，WMARK_HIGH 的最终计算逻辑是在 &lt;code&gt;__setup_per_zone_wmarks&lt;/code&gt; 方法中完成的：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; __setup_per_zone_wmarks(&lt;span&gt;void&lt;/span&gt;)&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;// 将 min_free_kbytes 转换为页&lt;/span&gt;&lt;br/&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; pages_min = min_free_kbytes &amp;gt;&amp;gt; (PAGE_SHIFT - &lt;span&gt;10&lt;/span&gt;);&lt;br/&gt;  &lt;span&gt;// 所有低位内存区域 managed_pages 之和&lt;/span&gt;&lt;br/&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; lowmem_pages = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; *&lt;span&gt;zone&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; flags;&lt;br/&gt;&lt;br/&gt; &lt;span&gt;/* Calculate total number of !ZONE_HIGHMEM pages */&lt;/span&gt;&lt;br/&gt; for_each_zone(zone) {&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (!is_highmem(zone))&lt;br/&gt;   lowmem_pages += zone-&amp;gt;managed_pages;&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;// 循环计算各个内存区域中的水位线&lt;/span&gt;&lt;br/&gt; for_each_zone(zone) {&lt;br/&gt;  u64 tmp;&lt;br/&gt;  tmp = (u64)pages_min * zone-&amp;gt;managed_pages;&lt;br/&gt;  &lt;span&gt;// 计算 WMARK_MIN 水位线的核心方法&lt;/span&gt;&lt;br/&gt;  do_div(tmp, lowmem_pages);&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (is_highmem(zone)) {&lt;br/&gt;            ...........省略高端内存区域............&lt;br/&gt;  } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;// WMARK_MIN水位线&lt;/span&gt;&lt;br/&gt;   zone-&amp;gt;watermark[WMARK_MIN] = tmp;&lt;br/&gt;  }&lt;br/&gt;  &lt;span&gt;// 这里可暂时忽略&lt;/span&gt;&lt;br/&gt;  tmp = &lt;span&gt;max_t&lt;/span&gt;(u64, tmp &amp;gt;&amp;gt; &lt;span&gt;2&lt;/span&gt;,&lt;br/&gt;       mult_frac(zone-&amp;gt;managed_pages,&lt;br/&gt;          watermark_scale_factor, &lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;&lt;br/&gt;  zone-&amp;gt;watermark[WMARK_LOW]  = min_wmark_pages(zone) + tmp;&lt;br/&gt;  zone-&amp;gt;watermark[WMARK_HIGH] = min_wmark_pages(zone) + tmp * &lt;span&gt;2&lt;/span&gt;;&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 for_each_zone 循环内依次遍历 NUMA 节点中的所有内存区域 zone，计算每个内存区域 zone 里的内存水位线。其中计算 WMARK_MIN 水位线的核心逻辑封装在 do_div 方法中，在 do_div 方法中会先计算每个 zone 内存容量之间的比例，然后根据这个比例去从 min_free_kbytes 中划分出对应 zone 的 WMARK_MIN 水位线来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如：当前 NUMA 节点中有两个 zone ：ZONE_DMA 和 ZONE_NORMAL，内存容量大小分别是：100 M 和 800 M。那么 ZONE_DMA 与 ZONE_NORMAL 之间的比例就是 1 ：8。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据这个比例，ZONE_DMA 区域里的 WMARK_MIN 水位线就是：min_free_kbytes  *  &lt;code&gt;1 / 8&lt;/code&gt; 。ZONE_NORMAL 区域里的 WMARK_MIN 水位线就是：min_free_kbytes  *  &lt;code&gt;7 / 8 &lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;计算出了 WMARK_MIN 的值，那么接下来 WMARK_LOW， WMARK_HIGH 的值也就好办了，它们都是基于 WMARK_MIN 计算出来的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WMARK_LOW 的值是 WMARK_MIN 的 1.25 倍，WMARK_HIGH 的值是 WMARK_LOW 的 1.5 倍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，大家可能对下面这段代码比较有疑问?&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;      &lt;span&gt;/*&lt;br/&gt;         * Set the kswapd watermarks distance according to the&lt;br/&gt;         * scale factor in proportion to available memory, but&lt;br/&gt;         * ensure a minimum size on small systems.&lt;br/&gt;         */&lt;/span&gt;&lt;br/&gt;        tmp = &lt;span&gt;max_t&lt;/span&gt;(u64, tmp &amp;gt;&amp;gt; &lt;span&gt;2&lt;/span&gt;,&lt;br/&gt;                mult_frac(zone-&amp;gt;managed_pages,&lt;br/&gt;                      watermark_scale_factor, &lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这段代码主要是通过内核参数 watermark_scale_factor 来调节水位线：WMARK_MIN，WMARK_LOW，WMARK_HIGH 之间的间距，那么为什么要调整水位线之间的间距大小呢？&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.6 watermark_scale_factor  调整水位线的间距&lt;span/&gt;&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0443548387096775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicVEWe42vYricicowskG2dt8f11cdDTcbuDoUjGJiaE6osibVhNp0L3dkgCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了避免内核的直接内存回收 direct reclaim 阻塞进程影响系统的性能，所以我们需要尽量保持内存区域中的剩余内存容量尽量在 WMARK_MIN 水位线之上，但是有一些极端情况，比如突然遇到网络流量增大，需要短时间内申请大量的内存来存放网络请求数据，此时 kswapd 回收内存的速度可能赶不上内存分配的速度，从而造成直接内存回收 direct reclaim，影响系统性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内存分配过程中，剩余内存容量处于 WMARK_MIN 与 WMARK_LOW 水位线之间会唤醒 kswapd 进程来回收内存，直到内存容量恢复到 WMARK_HIGH 水位线之上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;剩余内存容量低于 WMARK_MIN 水位线时就会触发直接内存回收 direct reclaim。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而剩余内存容量高于 WMARK_LOW 水位线又不会唤醒 kswapd 进程，因此 kswapd 进程活动的关键范围在 WMARK_MIN 与 WMARK_LOW 之间，而为了应对这种突发的网络流量暴增，我们需要保证 kswapd 进程活动的范围大一些，这样内核就能够时刻进行内存回收使得剩余内存容量较长时间的保持在 WMARK_HIGH 水位线之上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样一来就要求  WMARK_MIN 与 WMARK_LOW 水位线之间的间距不能太小，因为 WMARK_LOW 水位线之上就不会唤醒 kswapd 进程了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此内核引入了 &lt;code&gt;/proc/sys/vm/watermark_scale_factor&lt;/code&gt; 参数来调节水位线之间的间距。该内核参数默认值为 10，最大值为 3000。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.06576402321083172&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicciaDm7GqkpG6GjEgmcEhksiaicUJpyebd5jvcu7JNAMGJJe0hJLWeibabw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1034&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么如何使用 watermark_scale_factor 参数调整水位线之间的间距呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;水位线间距计算公式：(watermark_scale_factor / 10000) * managed_pages 。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;        zone-&amp;gt;watermark[WMARK_MIN] = tmp;&lt;br/&gt;        &lt;span&gt;// 水位线间距的计算逻辑&lt;/span&gt;&lt;br/&gt;        tmp = &lt;span&gt;max_t&lt;/span&gt;(u64, tmp &amp;gt;&amp;gt; &lt;span&gt;2&lt;/span&gt;,&lt;br/&gt;                mult_frac(zone-&amp;gt;managed_pages,&lt;br/&gt;                      watermark_scale_factor, &lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;&lt;br/&gt;        zone-&amp;gt;watermark[WMARK_LOW]  = min_wmark_pages(zone) + tmp;&lt;br/&gt;        zone-&amp;gt;watermark[WMARK_HIGH] = min_wmark_pages(zone) + tmp * &lt;span&gt;2&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内核中水位线间距计算逻辑是：(WMARK_MIN / 4) 与 (zone_managed_pages * watermark_scale_factor / 10000) 之间较大的那个值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用户可以通过 &lt;code&gt;sysctl&lt;/code&gt; 来动态调整 watermark_scale_factor 参数，内核会动态重新计算水位线之间的间距，使得 WMARK_MIN 与 WMARK_LOW 之间留有足够的缓冲余地，使得 kswapd 能够有时间回收足够的内存，&lt;strong&gt;从而解决直接内存回收导致的性能抖动问题&lt;/strong&gt;。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.7 物理内存区域中的冷热页&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前笔者在&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247484304&amp;amp;idx=1&amp;amp;sn=54bf0d07e69c5621c145afaece8f50d6&amp;amp;chksm=ce77c5d7f9004cc1249a03dfd0fb12b7d75171f1b87acea1fa44bbb11ca374b6f42a66fa274d&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《一文聊透对象在JVM中的内存布局，以及内存对齐和压缩指针的原理及应用》&lt;/a&gt; 一文中为大家介绍 CPU 的高速缓存时曾提到过，根据摩尔定律：芯片中的晶体管数量每隔 18 个月就会翻一番。导致 CPU 的性能和处理速度变得越来越快，而提升 CPU 的运行速度比提升内存的运行速度要容易和便宜的多，所以就导致了 CPU 与内存之间的速度差距越来越大。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CPU 与 内存之间的速度差异到底有多大呢？ 我们知道寄存器是离 CPU 最近的，CPU 在访问寄存器的时候速度近乎于 0 个时钟周期，访问速度最快，基本没有时延。而访问内存则需要 50 - 200 个时钟周期。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以为了弥补 CPU 与内存之间巨大的速度差异，提高CPU的处理效率和吞吐，于是我们引入了 L1 , L2 , L3 高速缓存集成到 CPU 中。CPU 访问高速缓存仅需要用到 1 - 30 个时钟周期，CPU 中的高速缓存是对内存热点数据的一个缓存。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6556451612903226&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicPnHSZLWSFpuWasx31zw4SUvpQQSpOBtzhiauBSvFmxlfxpYMSkCO9icw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;CPU缓存结构.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CPU 访问高速缓存的速度比访问内存的速度快大约10倍，引入高速缓存的目的在于消除CPU与内存之间的速度差距，CPU 用高速缓存来用来存放内存中的热点数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外我们根据程序的时间局部性原理可以知道，内存的数据一旦被访问，那么它很有可能在短期内被再次访问，如果我们把经常访问的物理内存页缓存在 CPU 的高速缓存中，那么当进程再次访问的时候就会直接命中 CPU 的高速缓存，避免了进一步对内存的访问，极大提升了应用程序的性能。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;程序局部性原理表现为：时间局部性和空间局部性。时间局部性是指如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某块数据被访问，则不久之后该数据可能再次被访问。空间局部性是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文我们的主题是 Linux 物理内存的管理，那么在 NUMA 内存架构下，这些 NUMA 节点中的物理内存区域 zone 管理的这些物理内存页，哪些是在 CPU 的高速缓存中？哪些又不在 CPU 的高速缓存中呢？内核如何来管理这些加载进 CPU 高速缓存中的物理内存页呢？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.785483870967742&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicsVOBYPApMroOgrjEGBs12ZAvdUPx2pwqbfC0h50MWlr5xCFhbygaXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本小节标题中所谓的热页就是已经加载进 CPU 高速缓存中的物理内存页，所谓的冷页就是还未加载进 CPU 高速缓存中的物理内存页，冷页是热页的后备选项。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;笔者先以内核版本 2.6.25 之前的冷热页相关的管理逻辑为大家讲解，因为这个版本的逻辑比较直观，大家更容易理解。在这个基础之上，笔者会在介绍内核 5.0 版本对于冷热页管理的逻辑，差别不是很大。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;per_cpu_pageset&lt;/span&gt; &lt;span&gt;pageset&lt;/span&gt;[&lt;span&gt;NR_CPUS&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 2.6.25 版本之前的内核源码中，物理内存区域 struct zone 包含了一个 struct per_cpu_pageset 类型的数组 pageset。其中内核关于冷热页的管理全部封装在 struct per_cpu_pageset 结构中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为每个 CPU 都有自己独立的高速缓存，所以每个 CPU 对应一个 per_cpu_pageset 结构，pageset 数组容量 NR_CPUS 是一个可以在编译期间配置的宏常数，表示内核可以支持的最大 CPU个数，注意该值并不是系统实际存在的 CPU 数量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 NUMA 内存架构下，每个物理内存区域都是属于一个特定的 NUMA 节点，NUMA  节点中包含了一个或者多个 CPU，NUMA  节点中的每个内存区域会关联到一个特定的 CPU 上，但 struct zone 结构中的 pageset 数组包含的是系统中所有 CPU 的高速缓存页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为虽然一个内存区域关联到了 NUMA 节点中的一个特定 CPU 上，但是其他CPU 依然可以访问该内存区域中的物理内存页，因此其他 CPU 上的高速缓存仍然可以包含该内存区域中的物理内存页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 CPU 都可以访问系统中的所有物理内存页，尽管访问速度不同（这在前边我们介绍 NUMA 架构的时候已经介绍过），因此特定的物理内存区域 struct zone 不仅要考虑到所属 NUMA 节点中相关的 CPU，还需要照顾到系统中的其他 CPU。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在表示每个 CPU 高速缓存结构 struct per_cpu_pageset  中有一个 struct per_cpu_pages 类型的数组 pcp，容量为 2。 数组 pcp 索引 0 表示该内存区域加载进 CPU 高速缓存的热页集合，索引 1 表示该内存区域中还未加载进 CPU 高速缓存的冷页集合。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;per_cpu_pageset&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;per_cpu_pages&lt;/span&gt; &lt;span&gt;pcp&lt;/span&gt;[2];&lt;/span&gt; &lt;span&gt;/* 0: hot.  1: cold */&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct per_cpu_pages 结构则是最终用于管理 CPU 高速缓存中的热页，冷页集合的数据结构：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;per_cpu_pages&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; count;  &lt;span&gt;/* number of pages in the list */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; high;  &lt;span&gt;/* high watermark, emptying needed */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; batch;  &lt;span&gt;/* chunk size for buddy add/remove */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;list&lt;/span&gt;;&lt;/span&gt; &lt;span&gt;/* the list of pages */&lt;/span&gt;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;int count ：表示集合中包含的物理页数量，如果该结构是热页集合，则表示加载进 CPU 高速缓存中的物理页面个数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;struct list_head list ：该 list 是一个双向链表，保存了当前 CPU 的热页或者冷页。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;int batch：每次批量向 CPU 高速缓存填充或者释放的物理页面个数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;int high：如果集合中页面的数量 count 值超过了 high 的值，那么表示 list 中的页面太多了，内核会从高速缓存中释放 batch 个页面到物理内存区域中的伙伴系统中。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;int low : 在之前更老的版本中，per_cpu_pages 结构还定义了一个 low 下限值，如果 count 低于 low 的值，那么内核会从伙伴系统中申请 batch 个页面填充至当前 CPU  的高速缓存中。之后的版本中取消了 low ，内核对容量过低的页面集合并没有显示的使用水位值 low，当列表中没有其他成员时，内核会重新填充高速缓存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上则是内核版本 2.6.25 之前管理 CPU 高速缓存冷热页的相关数据结构，我们看到在 2.6.25 之前，内核是使用两个 per_cpu_pages 结构来分别管理冷页和热页集合的&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来内核开发人员通过测试发现，用两个列表来管理冷热页，并不会比用一个列表集中管理冷热页带来任何的实质性好处，因此在内核版本 2.6.25 之后，将冷页和热页的管理合并在了一个列表中，热页放在列表的头部，冷页放在列表的尾部。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内核 5.0 的版本中， struct zone 结构中去掉了原来使用 struct per_cpu_pageset 数，因为 struct per_cpu_pageset 结构中分别管理了冷页和热页。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;zone&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;per_cpu_pages&lt;/span&gt; __&lt;span&gt;percpu&lt;/span&gt; *&lt;span&gt;per_cpu_pageset&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; pageset_high;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; pageset_batch;&lt;br/&gt;&lt;br/&gt;} ____cacheline_internodealigned_in_smp;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直接使用 struct per_cpu_pages 结构的链表来集中管理系统中所有 CPU 高速缓存冷热页。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;per_cpu_pages&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; count;  &lt;span&gt;/* number of pages in the list */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; high;  &lt;span&gt;/* high watermark, emptying needed */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;int&lt;/span&gt; batch;  &lt;span&gt;/* chunk size for buddy add/remove */&lt;/span&gt;&lt;br/&gt;        &lt;br/&gt;        .............省略............&lt;br/&gt;&lt;br/&gt; &lt;span&gt;/* Lists of pages, one per migrate type stored on the pcp-lists */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;lists&lt;/span&gt;[&lt;span&gt;NR_PCP_LISTS&lt;/span&gt;];&lt;/span&gt;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我们提到，内核为了最大程度的防止内存碎片，将物理内存页面按照是否可迁移的特性分为了多种迁移类型：可迁移，可回收，不可迁移。在 struct per_cpu_pages 结构中，每一种迁移类型都会对应一个冷热页链表。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6. 内核如何描述物理内存页&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4798387096774194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicrYBjP2hiaRwBLYeCniaSic44IIksFicbdCWrUCbvnLcOiaExKSJsZVLPkGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过前边几个小节的介绍，我想大家现在应该对 Linux 内核整个内存管理框架有了一个总体上的认识。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如上图所示，在 NUMA 架构下内存被划分成了一个一个的内存节点（NUMA Node），在每个 NUMA 节点中，内核又根据节点内物理内存的功能用途不同，将 NUMA 节点内的物理内存划分为四个物理内存区域分别是：ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_HIGHMEM。其中 ZONE_MOVABLE 区域是逻辑上的划分，主要是为了防止内存碎片和支持内存的热插拔。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;物理内存区域中管理的就是物理内存页（ Linux 内存管理的最小单位），前面我们介绍的内核对物理内存的换入，换出，回收，内存映射等操作的单位就是页。内核为每一个物理内存区域分配了一个伙伴系统，用于管理该物理内存区域下所有物理内存页面的分配和释放。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Linux 默认支持的物理内存页大小为 4KB，在 64 位体系结构中还可以支持 8KB，有的处理器还可以支持 4MB，支持物理地址扩展 PAE 机制的处理器上还可以支持 2MB。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么 Linux 为什么会默认采用 4KB 作为标准物理内存页的大小呢&lt;/strong&gt; ？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先关于物理页面的大小，Linux 规定必须是 2 的整数次幂，因为 2 的整数次幂可以将一些数学运算转换为移位操作，比如乘除运算可以通过移位操作来实现，这样效率更高。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么系统支持  4KB，8KB，2MB，4MB 等大小的物理页面，它们都是 2 的整数次幂，为啥偏偏要选 4KB 呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为前面提到，在内存紧张的时候，内核会将不经常使用到的物理页面进行换入换出等操作，还有在内存与文件映射的场景下，都会涉及到与磁盘的交互，数据在磁盘中组织形式也是根据一个磁盘块一个磁盘块来管理的，4kB 和 4MB 都是磁盘块大小的整数倍，但在大多数情况下，内存与磁盘之间传输小块数据时会更加的高效，所以综上所述内核会采用 4KB 作为默认物理内存页大小。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设我们有 4G 大小的物理内存，每个物理内存页大小为 4K，那么这 4G 的物理内存会被内核划分为 1M 个物理内存页，内核使用一个 struct page 的结构体来描述物理内存页，而每个 struct page 结构体占用内存大小为 40 字节，那么内核就需要用额外的 40 * 1M = 40M 的内存大小来描述物理内存页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于 4G 物理内存而言，这额外的 40M 内存占比相对较小，这个代价勉强可以接受，但是对内存锱铢必较的内核来说，还是会尽最大努力想尽一切办法来控制 struct page 结构体的大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为对于 4G 的物理内存来说，内核就需要使用 1M 个物理页面来管理，1M 个物理页的数量已经是非常庞大的了，因此在后续的内核迭代中，对于 struct page  结构的任何微小改动，都可能导致用于管理物理内存页的 struct page 实例所需要的内存暴涨。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回想一下我们经历过的很多复杂业务系统，由于业务逻辑已经非常复杂，在加上业务版本日积月累的迭代，整个业务系统已经变得异常复杂，在这种类型的业务系统中，我们经常会使用一个非常庞大的类来包装全量的业务响应信息用以应对各种复杂的场景，但是这个类已经包含了太多太多的业务字段了，而且这些业务字段在有的场景中会用到，在有的场景中又不会用到，后面还可能继续临时增加很多字段。系统的维护就这样变得越来越困难。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相比上面业务系统开发中随意地增加改动类中的字段，在内核中肯定是不会允许这样的行为发生的。struct page 结构是内核中访问最为频繁的一个结构体，就好比是 Linux 世界里最繁华的地段，在这个最繁华的地段租间房子，那租金可谓是相当的高，同样的道理，内核在 struct page 结构体中增加一个字段的代价也是非常之大，该结构体中每个字段中的每个比特，内核用的都是淋漓尽致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是 struct page 结构同样会面临很多复杂的场景，结构体中的某些字段在某些场景下有用，而在另外的场景下却没有用，而内核又不可能像业务系统开发那样随意地为 struct page 结构增加字段，那么内核该如何应对这种情况呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们即将会看到 struct page 结构体里包含了大量的 union 结构，而 union 结构在 C 语言中被用于同一块内存根据不同场景保存不同类型数据的一种方式。内核之所以在 struct page 结构中使用 union，是因为一个物理内存页面在内核中的使用场景和使用方式是多种多样的。在这多种场景下，利用 union 尽最大可能使 struct page 的内存占用保持在一个较低的水平。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct page 结构可谓是内核中最为繁杂的一个结构体，应用在内核中的各种功能场景下，在本小节中一一解释清楚各个字段的含义是不现实的，下面笔者只会列举 struct page 中最为常用的几个字段，剩下的字段笔者会在后续相关文章中专门介绍。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 存储 page 的定位信息以及相关标志位&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; flags;        &lt;br/&gt;&lt;br/&gt;    &lt;span&gt;union&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;    &lt;span&gt;/* Page cache and anonymous pages */&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 用来指向物理页 page 被放置在了哪个 lru 链表上&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;lru&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 如果 page 为文件页的话，低位为0，指向 page 所在的 page cache&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 如果 page 为匿名页的话，低位为1，指向其对应虚拟地址空间的匿名映射区 anon_vma&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;address_space&lt;/span&gt; *&lt;span&gt;mapping&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 如果 page 为文件页的话，index 为 page 在 page cache 中的索引&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 如果 page 为匿名页的话，表示匿名页在对应进程虚拟内存区域 VMA 中的偏移&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;pgoff_t&lt;/span&gt; index;&lt;br/&gt;            &lt;span&gt;// 在不同场景下，private 指向的场景信息不同&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; &lt;span&gt;private&lt;/span&gt;;&lt;br/&gt;        };&lt;br/&gt;        &lt;br/&gt;        &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;    &lt;span&gt;/* slab, slob and slub */&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;union&lt;/span&gt; {&lt;br/&gt;                &lt;span&gt;// 用于指定当前 page 位于 slab 中的哪个具体管理链表上。&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;slab_list&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;// 当 page 位于 slab 结构中的某个管理链表上时，next 指针用于指向链表中的下一个 page&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; *&lt;span&gt;next&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_64BIT&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;// 表示 slab 中总共拥有的 page 个数&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;int&lt;/span&gt; pages;  &lt;br/&gt;                    &lt;span&gt;// 表示 slab 中拥有的特定类型的对象个数&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;int&lt;/span&gt; pobjects;   &lt;br/&gt;&lt;span&gt;#&lt;span&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                    short &lt;span&gt;int&lt;/span&gt; pages;&lt;br/&gt;                    short &lt;span&gt;int&lt;/span&gt; pobjects;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                };&lt;br/&gt;            };&lt;br/&gt;            &lt;span&gt;// 用于指向当前 page 所属的 slab 管理结构&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;kmem_cache&lt;/span&gt; *&lt;span&gt;slab_cache&lt;/span&gt;;&lt;/span&gt; &lt;br/&gt;        &lt;br/&gt;            &lt;span&gt;// 指向 page 中的第一个未分配出去的空闲对象&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;void&lt;/span&gt; *freelist;     &lt;br/&gt;            &lt;span&gt;union&lt;/span&gt; {&lt;br/&gt;                &lt;span&gt;// 指向 page 中的第一个对象&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;void&lt;/span&gt; *s_mem;    &lt;br/&gt;                &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;            &lt;span&gt;/* SLUB */&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;// 表示 slab 中已经被分配出去的对象个数&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; inuse:&lt;span&gt;16&lt;/span&gt;;&lt;br/&gt;                    &lt;span&gt;// slab 中所有的对象个数&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; objects:&lt;span&gt;15&lt;/span&gt;;&lt;br/&gt;                    &lt;span&gt;// 当前内存页 page 被 slab 放置在 CPU 本地缓存列表中，frozen = 1，否则 frozen = 0&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; frozen:&lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;                };&lt;br/&gt;            };&lt;br/&gt;        };&lt;br/&gt;        &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;    &lt;span&gt;/* 复合页 compound page 相关*/&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 复合页的尾页指向首页&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; compound_head;    &lt;br/&gt;            &lt;span&gt;// 用于释放复合页的析构函数，保存在首页中&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;char&lt;/span&gt; compound_dtor;&lt;br/&gt;            &lt;span&gt;// 该复合页有多少个 page 组成&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;char&lt;/span&gt; compound_order;&lt;br/&gt;            &lt;span&gt;// 该复合页被多少个进程使用，内存页反向映射的概念，首页中保存&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;atomic_t&lt;/span&gt; compound_mapcount;&lt;br/&gt;        };&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 表示 slab 中需要释放回收的对象链表&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;rcu_head&lt;/span&gt; &lt;span&gt;rcu_head&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    };&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;union&lt;/span&gt; {     &lt;span&gt;/* This union is 4 bytes in size. */&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 表示该 page 映射了多少个进程的虚拟内存空间，一个 page 可以被多个进程映射&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;atomic_t&lt;/span&gt; _mapcount;&lt;br/&gt;&lt;br/&gt;    };&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 内核中引用该物理页的次数，表示该物理页的活跃程度。&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;atomic_t&lt;/span&gt; _refcount;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;if&lt;/span&gt; defined(WANT_PAGE_VIRTUAL)&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;void&lt;/span&gt; *&lt;span&gt;virtual&lt;/span&gt;;  &lt;span&gt;// 内存页对应的虚拟内存地址&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt; &lt;span&gt;/* WANT_PAGE_VIRTUAL */&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;} _struct_page_alignment;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面笔者就来为大家介绍下 struct page 结构在不同场景下的使用方式：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一种使用方式是内核直接分配使用一整页的物理内存，在《5.2 物理内存区域中的水位线》小节中我们提到，内核中的物理内存页有两种类型，分别用于不同的场景：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;一种是匿名页，匿名页背后并没有一个磁盘中的文件作为数据来源，匿名页中的数据都是通过进程运行过程中产生的，匿名页直接和进程虚拟地址空间建立映射供进程使用。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;另外一种是文件页，文件页中的数据来自于磁盘中的文件，文件页需要先关联一个磁盘中的文件，然后再和进程虚拟地址空间建立映射供进程使用，使得进程可以通过操作虚拟内存实现对文件的操作，这就是我们常说的内存文件映射。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 如果 page 为文件页的话，低位为0，指向 page 所在的 page cache&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 如果 page 为匿名页的话，低位为1，指向其对应虚拟地址空间的匿名映射区 anon_vma&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;address_space&lt;/span&gt; *&lt;span&gt;mapping&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 如果 page 为文件页的话，index 为 page 在 page cache 中的索引&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 如果 page 为匿名页的话，表示匿名页在对应进程虚拟内存区域 VMA 中的偏移&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;pgoff_t&lt;/span&gt; index; &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们首先来介绍下 struct page 结构中的 struct address_space *mapping 字段。提到 struct address_space 结构，如果大家之前看过笔者 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt; 这篇文章的话，一定不会对 struct address_space 感到陌生。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6056451612903225&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicYiadP4Ieu0rkNN5pSmejopWlOVtWsAqvJGcTr3IfqUrGib9tmU8DsCuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内核中每个文件都会有一个属于自己的 page cache（页高速缓存），页高速缓存在内核中的结构体就是这个 struct address_space。它被文件的 inode 所持有。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果当前物理内存页 struct page 是一个文件页的话，那么 mapping 指针的最低位会被设置为 0 ，指向该内存页关联文件的 struct address_space（页高速缓存），pgoff_t index 字段表示该内存页 page 在页高速缓存 page cache 中的 index 索引。内核会利用这个 index 字段从 page cache 中查找该物理内存页，&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24516129032258063&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicQPMaiaMbOW2RYSXgXXCjjmzYONYvCMtvMfhpLjVbyHmP4ZFJnicpSExQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同时该 pgoff_t index 字段也表示该内存页中的文件数据在文件内部的偏移 offset。偏移单位为 page size。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;对相关查找细节感兴趣的同学可以在回看下笔者  &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt; 文章中的《8. page cache 中查找缓存页》小节。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果当前物理内存页 struct page 是一个匿名页的话，那么 mapping 指针的最低位会被设置为 1 ， 指向该匿名页在进程虚拟内存空间中的匿名映射区域 struct anon_vma 结构（每个匿名页对应唯一的 anon_vma 结构），用于物理内存到虚拟内存的反向映射。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6.1 匿名页的反向映射&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们通常所说的内存映射是正向映射，即从虚拟内存到物理内存的映射。而反向映射则是从物理内存到虚拟内存的映射，用于当某个物理内存页需要进行回收或迁移时，此时需要去找到这个物理页被映射到了哪些进程的虚拟地址空间中，并断开它们之间的映射。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在没有反向映射的机制前，需要去遍历所有进程的虚拟地址空间中的映射页表，这个效率显然是很低下的。有了反向映射机制之后内核就可以直接找到该物理内存页到所有进程映射的虚拟地址空间 VMA ，并从 VMA 使用的进程页表中取消映射，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;谈到 VMA 大家一定不会感到陌生，VMA 相关的内容笔者在  &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486732&amp;amp;idx=1&amp;amp;sn=435d5e834e9751036c96384f6965b328&amp;amp;chksm=ce77cb4bf900425d33d2adfa632a4684cf7a63beece166c1ffedc4fdacb807c9413e8c73f298&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《深入理解 Linux 虚拟内存管理》&lt;/a&gt; 这篇文章中详细的介绍过。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，进程的虚拟内存空间在内核中使用 struct mm_struct 结构表示，进程的虚拟内存空间包含了一段一段的虚拟内存区域 VMA，比如我们经常接触到的堆，栈。内核中使用 struct vm_area_struct 结构来描述这些虚拟内存区域。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7741935483870968&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicaiaITkMuXjz27tBe7oqxxS5YSZntfA8ibHQ4BdIGHSbM38sHibVbuOGHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里笔者只列举出 struct vm_area_struct 结构中与匿名页反向映射相关的字段属性：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;vm_area_struct&lt;/span&gt; {&lt;/span&gt;  &lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;anon_vma_chain&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt;;&lt;/span&gt;   &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里大家可能会感到好奇，既然内核中有了 struct vm_area_struct 结构来描述虚拟内存区域，那不管是文件页也好，还是匿名页也好，都可以使用 struct vm_area_struct  结构体来进行描述，这里为什么有会出现 struct anon_vma 结构和 struct anon_vma_chain 结构？这两个结构到底是干嘛的？如何利用它俩来完成匿名内存页的反向映射呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据前几篇文章的内容我们知道，进程利用 fork 系统调用创建子进程的时候，内核会将父进程的虚拟内存空间相关的内容拷贝到子进程的虚拟内存空间中，此时子进程的虚拟内存空间和父进程的虚拟内存空间是一模一样的，其中虚拟内存空间中映射的物理内存页也是一样的，在内核中都是同一份，在父进程和子进程之间共享（包括 anon_vma 和 anon_vma_chain）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当进程在向内核申请内存的时候，内核首先会为进程申请的这块内存创建初始化一段虚拟内存区域 struct vm_area_struct 结构，但是并不会为其分配真正的物理内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当进程开始访问这段虚拟内存时，内核会产生缺页中断，在缺页中断处理函数中才会去真正的分配物理内存（这时才会为子进程创建自己的 anon_vma 和 anon_vma_chain），并建立虚拟内存与物理内存之间的映射关系（正向映射）。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;vm_fault_t&lt;/span&gt; &lt;span&gt;handle_pte_fault&lt;/span&gt;&lt;span&gt;(struct vm_fault *vmf)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;        .............&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (!vmf-&amp;gt;pte) {&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (vma_is_anonymous(vmf-&amp;gt;vma))&lt;br/&gt;            &lt;span&gt;// 处理匿名页缺页&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;return&lt;/span&gt; do_anonymous_page(vmf);&lt;br/&gt;  &lt;span&gt;else&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 处理文件页缺页&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;return&lt;/span&gt; do_fault(vmf);&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt;        .............&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (vmf-&amp;gt;flags &amp;amp; (FAULT_FLAG_WRITE|FAULT_FLAG_UNSHARE)) {&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (!pte_write(entry))&lt;br/&gt;            &lt;span&gt;// 子进程缺页处理&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;return&lt;/span&gt; do_wp_page(vmf);&lt;br/&gt; }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们主要关注 do_anonymous_page 函数，正是在这里内核完成了 struct anon_vma 结构和 struct anon_vma_chain 结构的创建以及相关匿名页反向映射数据结构的相互关联。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;vm_fault_t&lt;/span&gt; &lt;span&gt;do_anonymous_page&lt;/span&gt;&lt;span&gt;(struct vm_fault *vmf)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;vm_area_struct&lt;/span&gt; *&lt;span&gt;vma&lt;/span&gt; = &lt;span&gt;vmf&lt;/span&gt;-&amp;gt;&lt;span&gt;vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; *&lt;span&gt;page&lt;/span&gt;;&lt;/span&gt; &lt;br/&gt;&lt;br/&gt;        ........省略虚拟内存到物理内存正向映射相关逻辑.........&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (unlikely(anon_vma_prepare(vma)))&lt;br/&gt;  &lt;span&gt;goto&lt;/span&gt; oom;&lt;br/&gt;&lt;br/&gt; page = alloc_zeroed_user_highpage_movable(vma, vmf-&amp;gt;address);&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (!page)&lt;br/&gt;  &lt;span&gt;goto&lt;/span&gt; oom;&lt;br/&gt;  &lt;span&gt;// 建立反向映射关系&lt;/span&gt;&lt;br/&gt; page_add_new_anon_rmap(page, vma, vmf-&amp;gt;address);&lt;br/&gt;&lt;br/&gt;        ........省略虚拟内存到物理内存正向映射相关逻辑.........&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 do_anonymous_page 匿名页缺页处理函数中会为 struct vm_area_struct 结构创建匿名页相关的  struct anon_vma 结构和 struct anon_vma_chain 结构。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并在 anon_vma_prepare 函数中实现 anon_vma 和 anon_vma_chain 之间的关联 ，随后调用 alloc_zeroed_user_highpage_movable 从伙伴系统中获取物理内存页 struct page，并在 page_add_new_anon_rmap 函数中完成 struct page 与 anon_vma 的关联（这里正是反向映射关系建立的关键）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在介绍匿名页反向映射源码实现之前，笔者先来为大家介绍一下相关的两个重要数据结构 struct anon_vma 和 struct anon_vma_chain，方便大家理解为何 struct page 与 anon_vma 关联起来就能实现反向映射？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我们提到，匿名页的反向映射关键就是建立物理内存页 struct page 与进程虚拟内存空间 VMA 之间的映射关系。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;匿名页的 struct page 中的 mapping 指针指向的是 struct anon_vma 结构。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;address_space&lt;/span&gt; *&lt;span&gt;mapping&lt;/span&gt;;&lt;/span&gt; &lt;br/&gt;    &lt;span&gt;pgoff_t&lt;/span&gt; index;  &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只要我们实现了 anon_vma 与 vm_area_struct 之间的关联，那么 page 到 vm_area_struct 之间的映射就建立起来了，struct anon_vma_chain 结构做的事情就是建立 anon_vma 与 vm_area_struct 之间的关联关系。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma_chain&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 匿名页关联的进程虚拟内存空间（vma属于一个特定的进程，多个进程多个vma）&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;vm_area_struct&lt;/span&gt; *&lt;span&gt;vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 匿名页 page 指向的 anon_vma&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;same_vma&lt;/span&gt;;&lt;/span&gt;   &lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;rb_node&lt;/span&gt; &lt;span&gt;rb&lt;/span&gt;;&lt;/span&gt;         &lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; rb_subtree_last;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_DEBUG_VM_RB&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; cached_vma_start, cached_vma_last;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct anon_vma_chain 结构通过其中的 vma 指针和 anon_vma 指针将相关的匿名页与其映射的进程虚拟内存空间关联了起来。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6225806451612903&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicFgYwgx5ics7Pml9OicvQQJjD5MuK9a7p7rzkhxP5Agibr5ogpUAibvC5Jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从目前来看匿名页 struct page 算是与 anon_vma 建立了关系，又通过 anon_vma_chain 将 anon_vma 与 vm_area_struct 建立了关系。那么就剩下最后一道关系需要打通了，就是如何通过 anon_vma 找到 anon_vma_chain 进而找到 vm_area_struct 呢？这就需要我们将 anon_vma 与 anon_vma_chain 之间的关系也打通。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们知道每个匿名页对应唯一的 anon_vma 结构，但是一个匿名物理页可以映射到不同进程的虚拟内存空间中，每个进程的虚拟内存空间都是独立的，也就是说不同的进程就会有不同的 VMA。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7258064516129032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPliclL76yNyK91MwYvEiax4TzakymT9QQZSLKQB0qC5CVjMwRu7rpicWIr0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不同的 VMA 意味着同一个匿名页 anon_vma 就会对应多个 anon_vma_chain。那么如何通过一个 anon_vma 找到和他关联的所有 anon_vma_chain 呢？找到了这些 anon_vma_chain 也就意味着 struct page 找到了与它关联的所有进程虚拟内存空间 VMA。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们看看能不能从 struct anon_vma 结构中寻找一下线索：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;root&lt;/span&gt;;&lt;/span&gt;      &lt;span&gt;/* Root of this anon_vma tree */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;rw_semaphore&lt;/span&gt; &lt;span&gt;rwsem&lt;/span&gt;;&lt;/span&gt; &lt;br/&gt;    &lt;span&gt;atomic_t&lt;/span&gt; refcount;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; degree;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;parent&lt;/span&gt;;&lt;/span&gt;    &lt;span&gt;/* Parent of this anon_vma */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;rb_root&lt;/span&gt; &lt;span&gt;rb_root&lt;/span&gt;;&lt;/span&gt; &lt;span&gt;/* Interval tree of private &quot;related&quot; vmas */&lt;/span&gt;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们重点来看 struct anon_vma 结构中的 rb_root 字段，struct anon_vma 结构中管理了一颗红黑树，这颗红黑树上管理的全部都是与该 anon_vma 关联的 anon_vma_chain。我们可以通过 struct page 中的 mapping 指针找到 anon_vma，然后遍历 anon_vma 中的这颗红黑树 rb_root ，从而找到与其关联的所有 anon_vma_chain。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma_chain&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 匿名页关联的进程虚拟内存空间（vma属于一个特定的进程，多个进程多个vma）&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;vm_area_struct&lt;/span&gt; *&lt;span&gt;vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 匿名页 page 指向的 anon_vma&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 指向 vm_area_struct 中的 anon_vma_chain 列表&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;same_vma&lt;/span&gt;;&lt;/span&gt;   &lt;br/&gt;    &lt;span&gt;// anon_vma 管理的红黑树中该 anon_vma_chain 对应的红黑树节点&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;rb_node&lt;/span&gt; &lt;span&gt;rb&lt;/span&gt;;&lt;/span&gt;         &lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct anon_vma_chain 结构中的 rb 字段表示其在对应 anon_vma 管理的红黑树中的节点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5290322580645161&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicnH8UdfG3Kzfnz0sd20hFvp6flPPYc9svheqDORSWalLrMw9vkf9CLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到目前为止，物理内存页 page 到与其映射的进程虚拟内存空间 VMA，这样一种一对多的映射关系现在就算建立起来了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而 vm_area_struct 表示的只是进程虚拟内存空间中的一段虚拟内存区域，这块虚拟内存区域中可能会包含多个匿名页，所以 VMA 与物理内存页 page 也是有一对多的映射关系存在。而这个映射关系在哪里保存呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家注意 struct anon_vma_chain 结构中还有一个列表结构 same_vma，从这个名字上我们很容易就能猜到这个列表 same_vma 中存储的 anon_vma_chain 对应的 VMA 全都是一样的，而列表元素 anon_vma_chain 中的 anon_vma 却是不一样的。内核用这样一个链表结构 same_vma 存储了进程相应虚拟内存区域 VMA 中所包含的所有匿名页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct vm_area_struct 结构中的 &lt;code&gt; struct list_head anon_vma_chain&lt;/code&gt; 指向的也是这个列表 same_vma。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;vm_area_struct&lt;/span&gt; {&lt;/span&gt;  &lt;br/&gt;    &lt;span&gt;// 存储该 VMA 中所包含的所有匿名页 anon_vma&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;anon_vma_chain&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 用于快速判断 VMA 有没有对应的匿名 page&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 一个 VMA 可以包含多个 page，但是该区域内的所有 page 只需要一个 anon_vma 来反向映射即可。&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt;;&lt;/span&gt;   &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47258064516129034&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPliczvTA72x3UwRXTYkfAkptRjcVzf1HwUibx9jeErmgyIgEHeFCPfHiabsA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在整个匿名页到进程虚拟内存空间的反向映射链路关系，笔者就为大家梳理清楚了，下面我们接着回到 do_anonymous_page 函数中，来一一验证上述映射逻辑：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;vm_fault_t&lt;/span&gt; &lt;span&gt;do_anonymous_page&lt;/span&gt;&lt;span&gt;(struct vm_fault *vmf)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;vm_area_struct&lt;/span&gt; *&lt;span&gt;vma&lt;/span&gt; = &lt;span&gt;vmf&lt;/span&gt;-&amp;gt;&lt;span&gt;vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; *&lt;span&gt;page&lt;/span&gt;;&lt;/span&gt; &lt;br/&gt;&lt;br/&gt;        ........省略虚拟内存到物理内存正向映射相关逻辑.........&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (unlikely(anon_vma_prepare(vma)))&lt;br/&gt;  &lt;span&gt;goto&lt;/span&gt; oom;&lt;br/&gt;&lt;br/&gt; page = alloc_zeroed_user_highpage_movable(vma, vmf-&amp;gt;address);&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (!page)&lt;br/&gt;  &lt;span&gt;goto&lt;/span&gt; oom;&lt;br/&gt;&lt;br/&gt; page_add_new_anon_rmap(page, vma, vmf-&amp;gt;address);&lt;br/&gt;&lt;br/&gt;        ........省略虚拟内存到物理内存正向映射相关逻辑.........&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 do_anonymous_page 中首先会调用 anon_vma_prepare 方法来为匿名页创建 anon_vma 实例和 anon_vma_chain 实例，并建立它们之间的关联关系。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;int&lt;/span&gt; __anon_vma_prepare(struct vm_area_struct *vma)&lt;br/&gt;{&lt;br/&gt;    &lt;span&gt;// 获取进程虚拟内存空间&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;mm_struct&lt;/span&gt; *&lt;span&gt;mm&lt;/span&gt; = &lt;span&gt;vma&lt;/span&gt;-&amp;gt;&lt;span&gt;vm_mm&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 准备为匿名页分配 anon_vma 以及 anon_vma_chain&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt;, *&lt;span&gt;allocated&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma_chain&lt;/span&gt; *&lt;span&gt;avc&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 分配 anon_vma_chain 实例&lt;/span&gt;&lt;br/&gt; avc = anon_vma_chain_alloc(GFP_KERNEL);&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (!avc)&lt;br/&gt;  &lt;span&gt;goto&lt;/span&gt; out_enomem;&lt;br/&gt;    &lt;span&gt;// 在相邻的虚拟内存区域 VMA 中查找可复用的 anon_vma&lt;/span&gt;&lt;br/&gt; anon_vma = find_mergeable_anon_vma(vma);&lt;br/&gt; allocated = &lt;span&gt;NULL&lt;/span&gt;;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (!anon_vma) {&lt;br/&gt;        &lt;span&gt;// 没有可复用的 anon_vma 则创建一个新的实例&lt;/span&gt;&lt;br/&gt;  anon_vma = anon_vma_alloc();&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (unlikely(!anon_vma))&lt;br/&gt;   &lt;span&gt;goto&lt;/span&gt; out_enomem_free_avc;&lt;br/&gt;  allocated = anon_vma;&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; anon_vma_lock_write(anon_vma);&lt;br/&gt; &lt;span&gt;/* page_table_lock to protect against threads */&lt;/span&gt;&lt;br/&gt; spin_lock(&amp;amp;mm-&amp;gt;page_table_lock);&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; (likely(!vma-&amp;gt;anon_vma)) {&lt;br/&gt;        &lt;span&gt;// VMA 中的 anon_vma 属性就是在这里赋值的&lt;/span&gt;&lt;br/&gt;  vma-&amp;gt;anon_vma = anon_vma;&lt;br/&gt;        &lt;span&gt;// 建立反向映射关联&lt;/span&gt;&lt;br/&gt;  anon_vma_chain_link(vma, avc, anon_vma);&lt;br/&gt;  &lt;span&gt;/* vma reference or self-parent link for new root */&lt;/span&gt;&lt;br/&gt;  anon_vma-&amp;gt;degree++;&lt;br/&gt;  allocated = &lt;span&gt;NULL&lt;/span&gt;;&lt;br/&gt;  avc = &lt;span&gt;NULL&lt;/span&gt;;&lt;br/&gt; }&lt;br/&gt;        .................&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;anon_vma_prepare 方法中调用 anon_vma_chain_link 方法来建立 anon_vma，anon_vma_chain，vm_area_struct 三者之间的关联关系：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;anon_vma_chain_link&lt;/span&gt;&lt;span&gt;(struct vm_area_struct *vma,&lt;br/&gt;    struct anon_vma_chain *avc,&lt;br/&gt;    struct anon_vma *anon_vma)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;// 通过 anon_vma_chain 关联 anon_vma 和对应的 vm_area_struct&lt;/span&gt;&lt;br/&gt; avc-&amp;gt;vma = vma;&lt;br/&gt; avc-&amp;gt;anon_vma = anon_vma;&lt;br/&gt;    &lt;span&gt;// 将 vm_area_struct 中的 anon_vma_chain 链表加入到 anon_vma_chain 中的 same_vma 链表中&lt;/span&gt;&lt;br/&gt; list_add(&amp;amp;avc-&amp;gt;same_vma, &amp;amp;vma-&amp;gt;anon_vma_chain);&lt;br/&gt;    &lt;span&gt;// 将初始化好的 anon_vma_chain 加入到 anon_vma 管理的红黑树 rb_root 中&lt;/span&gt;&lt;br/&gt; anon_vma_interval_tree_insert(avc, &amp;amp;anon_vma-&amp;gt;rb_root);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47258064516129034&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPliczvTA72x3UwRXTYkfAkptRjcVzf1HwUibx9jeErmgyIgEHeFCPfHiabsA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到现在为止还缺关键的最后一步，就是打通匿名内存页 page 到 vm_area_struct 之间的关系，首先我们就需要调用 alloc_zeroed_user_highpage_movable 方法从伙伴系统中申请一个匿名页。当获取到 page 实例之后，通过 page_add_new_anon_rmap 最终建立起 page 到 vm_area_struct 的整条反向映射链路。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; __page_set_anon_rmap(struct page *page,&lt;br/&gt;    struct vm_area_struct *vma, &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; address, &lt;span&gt;int&lt;/span&gt; exclusive)&lt;br/&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt; = &lt;span&gt;vma&lt;/span&gt;-&amp;gt;&lt;span&gt;anon_vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;           .........省略..............&lt;br/&gt;    &lt;span&gt;// 低位置 1&lt;/span&gt;&lt;br/&gt;    anon_vma = (&lt;span&gt;void&lt;/span&gt; *) anon_vma + PAGE_MAPPING_ANON;&lt;br/&gt;    &lt;span&gt;// 转换为 address_space 指针赋值给 page 结构中的 mapping 字段&lt;/span&gt;&lt;br/&gt;    page-&amp;gt;mapping = (struct address_space *) anon_vma;&lt;br/&gt;    &lt;span&gt;// page 结构中的 index 表示该匿名页在虚拟内存区域 vma 中的偏移&lt;/span&gt;&lt;br/&gt;    page-&amp;gt;index = linear_page_index(vma, address);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在让我们再次回到本小节 《6.1 匿名页的反向映射》的开始，再来看这段话，是不是感到非常清晰了呢~~&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果当前物理内存页 struct page 是一个匿名页的话，那么 mapping 指针的最低位会被设置为 &lt;code&gt;1&lt;/code&gt; ， 指向该匿名页在进程虚拟内存空间中的匿名映射区域 struct anon_vma 结构（每个匿名页对应唯一的 anon_vma 结构），用于物理内存到虚拟内存的反向映射。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果当前物理内存页 struct page 是一个文件页的话，那么 mapping 指针的最低位会被设置为 &lt;code&gt;0&lt;/code&gt; ，指向该内存页关联文件的 struct address_space（页高速缓存）。pgoff_t index 字段表示该内存页 page 在页高速缓存中的 index 索引，也表示该内存页中的文件数据在文件内部的偏移 offset。偏移单位为 page size。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct page 结构中的 &lt;code&gt;struct address_space *mapping&lt;/code&gt; 指针的最低位如何置 1 ，又如何置 0 呢？关键在下面这条语句：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;anon_vma&lt;/span&gt; *&lt;span&gt;anon_vma&lt;/span&gt; = &lt;span&gt;vma&lt;/span&gt;-&amp;gt;&lt;span&gt;anon_vma&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 低位置 1&lt;/span&gt;&lt;br/&gt;    anon_vma = (&lt;span&gt;void&lt;/span&gt; *) anon_vma + PAGE_MAPPING_ANON;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;anon_vma 指针加上 PAGE_MAPPING_ANON ，并转换为 address_space 指针，这样可确保 address_space 指针的低位为 1 表示匿名页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;address_space 指针在转换为 anon_vma 指针的时候可通过如下语句实现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;anon_vma = (struct anon_vma *) (mapping - PAGE_MAPPING_ANON)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;PAGE_MAPPING_ANON 常量定义在内核 &lt;code&gt;/include/linux/page-flags.h&lt;/code&gt; 文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; PAGE_MAPPING_ANON 0x1&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而对于文件页来说，page 结构的 mapping 指针最低位本来就是 0 ，因为 address_space 类型的指针实现总是对齐至 &lt;code&gt;sizeof(long)&lt;/code&gt;，因此在 Linux 支持的所有计算机上，指向 address_space 实例的指针最低位总是为 0 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;内核可以通过这个技巧直接检查 page 结构中的 mapping 指针的最低位来判断该物理内存页到底是匿名页还是文件页&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面说了文件页的 page 结构的 index 属性表示该内存页 page 在磁盘文件中的偏移 offset ，偏移单位为 page size 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那匿名页的 page 结构中的 index 属性表示什么呢？我们接着来看 linear_page_index 函数：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;pgoff_t&lt;/span&gt; &lt;span&gt;linear_page_index&lt;/span&gt;&lt;span&gt;(struct vm_area_struct *vma,&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; address)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;pgoff_t&lt;/span&gt; pgoff;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (unlikely(is_vm_hugetlb_page(vma)))&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; linear_hugepage_index(vma, address);&lt;br/&gt;    pgoff = (address - vma-&amp;gt;vm_start) &amp;gt;&amp;gt; PAGE_SHIFT;&lt;br/&gt;    pgoff += vma-&amp;gt;vm_pgoff;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; pgoff;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;逻辑很简单，就是表示匿名页在对应进程虚拟内存区域 VMA 中的偏移。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在本小节最后，还有一个与反向映射相关的重要属性就是 page 结构中的 _mapcount。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;address_space&lt;/span&gt; *&lt;span&gt;mapping&lt;/span&gt;;&lt;/span&gt; &lt;br/&gt;    &lt;span&gt;pgoff_t&lt;/span&gt; index;  &lt;br/&gt;    &lt;span&gt;// 表示该 page 映射了多少个进程的虚拟内存空间，一个 page 可以被多个进程映射&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;atomic_t&lt;/span&gt; _mapcount&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过本小节详细的介绍，我想大家现在已经猜到 _mapcount 字段的含义了，我们知道一个物理内存页可以映射到多个进程的虚拟内存空间中，比如：共享内存映射，父子进程的创建等。page 与 VMA 是一对多的关系，这里的 _mapcount 就表示该物理页映射到了多少个进程的虚拟内存空间中。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6.2 内存页回收相关属性&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们接着来看 struct page 中剩下的其他属性，我们知道物理内存页在内核中分为匿名页和文件页，在《5.2 物理内存区域中的水位线》小节中，笔者还提到过两个重要的链表分别为：active 链表和 inactive 链表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中 active 链表用来存放访问非常频繁的内存页（热页）， inactive 链表用来存放访问不怎么频繁的内存页（冷页），当内存紧张的时候，内核就会优先将  inactive 链表中的内存页置换出去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核在回收内存的时候，这两个列表中的回收优先级为：inactive 链表尾部 &amp;gt; inactive 链表头部 &amp;gt; active 链表尾部 &amp;gt; active 链表头部。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过 &lt;code&gt;cat /proc/zoneinfo&lt;/code&gt; 命令来查看不同 NUMA 节点中不同内存区域中的 active 链表和 inactive 链表中物理内存页的个数：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.471563981042654&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicVUmYFvwmPys4bvfmd9qGqynJl6uJUibXRdXqQiapsVziaTcT2maD3eMvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;844&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;nr_zone_active_anon 和 nr_zone_inactive_anon 分别是该内存区域内活跃和非活跃的匿名页数量。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;nr_zone_active_file 和 nr_zone_inactive_file 分别是该内存区域内活跃和非活跃的文件页数量。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;为什么会有 active 链表和 inactive 链表&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存回收的关键是如何实现一个高效的页面替换算法 PFRA (Page Frame Replacement Algorithm) ，提到页面替换算法大家可能立马会想到  LRU (Least-Recently-Used) 算法。LRU 算法的核心思想就是那些最近最少使用的页面，在未来的一段时间内可能也不会再次被使用，所以在内存紧张的时候，会优先将这些最近最少使用的页面置换出去。在这种情况下其实一个 active 链表就可以满足我们的需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是这里会有一个严重的问题，LRU 算法更多的是在时间维度上的考量，突出最近最少使用，但是它并没有考量到使用频率的影响，假设有这样一种状况，就是一个页面被疯狂频繁的使用，毫无疑问它肯定是一个热页，但是这个页面最近的一次访问时间离现在稍微久了一点点，此时进来大量的页面，这些页面的特点是只会使用一两次，以后将再也不会用到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这种情况下，根据 LRU 的语义这个之前频繁地被疯狂访问的页面就会被置换出去了（本来应该将这些大量一次性访问的页面置换出去的），当这个页面在不久之后要被访问时，此时已经不在内存中了，还需要在重新置换进来，造成性能的损耗。这种现象也叫 Page Thrashing（页面颠簸）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，内核为了将页面使用频率这个重要的考量因素加入进来，于是就引入了 active 链表和 inactive 链表。工作原理如下：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;首先 inactive 链表的尾部存放的是访问频率最低并且最少访问的页面，在内存紧张的时候，这些页面被置换出去的优先级是最大的。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;对于文件页来说，当它被第一次读取的时候，内核会将它放置在 inactive 链表的头部，如果它继续被访问，则会提升至 active 链表的尾部。如果它没有继续被访问，则会随着新文件页的进入，内核会将它慢慢的推到  inactive 链表的尾部，如果此时再次被访问则会直接被提升到 active 链表的头部。大家可以看出此时页面的使用频率这个因素已经被考量了进来。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;对于匿名页来说，当它被第一次读取的时候，内核会直接将它放置在 active 链表的尾部，注意不是 inactive 链表的头部，这里和文件页不同。因为匿名页的换出 Swap Out 成本会更大，内核会对匿名页更加优待。当匿名页再次被访问的时候就会被被提升到 active 链表的头部。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当遇到内存紧张的情况需要换页时，内核会从 active 链表的尾部开始扫描，将一定量的页面降级到  inactive 链表头部，这样一来原来位于 inactive 链表尾部的页面就会被置换出去。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;内核在回收内存的时候，这两个列表中的回收优先级为：inactive 链表尾部 &amp;gt; inactive 链表头部 &amp;gt; active 链表尾部 &amp;gt; active 链表头部。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;为什么会把 active 链表和 inactive 链表分成两类，一类是匿名页，一类是文件页&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在本文 《5.2 物理内存区域中的水位线》小节中，笔者为大家介绍了一个叫做 swappiness 的内核参数， 我们可以通过 &lt;code&gt;cat /proc/sys/vm/swappiness&lt;/code&gt;  命令查看，swappiness 选项的取值范围为 0 到 100，默认为 60。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;swappiness 用于表示 Swap 机制的积极程度，数值越大，Swap 的积极程度，越高越倾向于&lt;strong&gt;回收匿名页&lt;/strong&gt;。数值越小，Swap 的积极程度越低，越倾向于&lt;strong&gt;回收文件页&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为回收匿名页和回收文件页的代价是不一样的，回收匿名页代价会更高一点，所以引入 swappiness 来控制内核回收的倾向。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意： swappiness 只是表示 Swap 积极的程度，当内存非常紧张的时候，即使将 swappiness 设置为 0 ，也还是会发生 Swap 的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设我们现在只有 active 链表和 inactive 链表，不对这两个链表进行匿名页和文件页的归类，在需要页面置换的时候，内核会先从  active 链表尾部开始扫描，当  swappiness 被设置为 0 时，内核只会置换文件页，不会置换匿名页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 active 链表和 inactive 链表没有进行物理页面类型的归类，所以链表中既会有匿名页也会有文件页，如果链表中有大量的匿名页的话，内核就会不断的跳过这些匿名页去寻找文件页，并将文件页替换出去，这样从性能上来说肯定是低效的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此内核将 active 链表和 inactive 链表按照匿名页和文件页进行了归类，当  swappiness 被设置为 0 时，内核只需要去 nr_zone_active_file 和 nr_zone_inactive_file 链表中扫描即可，提升了性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实除了以上笔者介绍的四种 LRU 链表（匿名页的 active 链表，inactive 链表和文件页的active 链表， inactive 链表）之外，内核还有一种链表，比如进程可以通过 mlock() 等系统调用把内存页锁定在内存里，保证该内存页无论如何不会被置换出去，比如出于安全或者性能的考虑，页面中可能会包含一些敏感的信息不想被 swap 到磁盘上导致泄密，或者一些频繁访问的内存页必须一直贮存在内存中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当这些被锁定在内存中的页面很多时，内核在扫描 active 链表的时候也不得不跳过这些页面，所以内核又将这些被锁定的页面单独拎出来放在一个独立的链表中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在笔者为大家介绍五种用于存放 page 的链表，内核会根据不同的情况将一个物理页放置在这五种链表其中一个上。那么对于物理页的 struct page 结构中就需要有一个属性用来标识该物理页究竟被内核放置在哪个链表上。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;lru&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;atomic_t&lt;/span&gt; _refcount;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct list_head lru 属性就是用来指向物理页被放置在了哪个链表上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;atomic_t _refcount 属性用来记录内核中引用该物理页的次数，表示该物理页的活跃程度。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6.3 物理内存页属性和状态的标志位 flag&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; flags;&lt;br/&gt;} &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在本文 《2.3 SPARSEMEM 稀疏内存模型》小节中，我们提到，内核为了能够更灵活地管理粒度更小的连续物理内存，于是就此引入了 SPARSEMEM 稀疏内存模型。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6588709677419354&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicy0jNaUxkBDTB5977TGbsRiaT7ol1ffXoDetJf8Ew7ScKhHndEyHzuIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;SPARSEMEM 稀疏内存模型的核心思想就是提供对粒度更小的连续内存块进行精细的管理，用于管理连续内存块的单元被称作 section 。内核中用于描述 section 的数据结构是 struct mem_section。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 section 被用作管理小粒度的连续内存块，这些小的连续物理内存在 section 中也是通过数组的方式被组织管理（图中 struct page 类型的数组）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 struct mem_section 结构体中有一个 section_mem_map 指针用于指向连续内存的 page 数组。而所有的 mem_section 也会被存放在一个全局的数组 mem_section 中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么给定一个具体的 struct page，在稀疏内存模型中内核如何定位到这个物理内存页到底属于哪个 mem_section 呢&lt;/strong&gt; ？这是第一个问题~~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;笔者在《5. 内核如何管理 NUMA 节点中的物理内存区域》小节中讲到了内存的架构，在 NUMA 架构下，物理内存被划分成了一个一个的内存节点（NUMA 节点），在每个 NUMA 节点内部又将其所管理的物理内存按照功能不同划分成了不同的内存区域 zone，每个内存区域管理一片用于特定具体功能的物理内存 page。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;物理内存在内核中管理的层级关系为：None -&amp;gt; Zone -&amp;gt; page&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4798387096774194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicrYBjP2hiaRwBLYeCniaSic44IIksFicbdCWrUCbvnLcOiaExKSJsZVLPkGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么在 NUMA 架构下，给定一个具体的 struct page，内核又该如何确定该物理内存页究竟属于哪个 NUMA 节点，属于哪块内存区域 zone 呢&lt;/strong&gt;？ 这是第二个问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于以上笔者提出的两个问题所需要的定位信息全部存储在 struct page 结构中的 flags 字段中。前边我们提到，struct page 是 Linux  世界里最繁华的地段，这里的地价非常昂贵，所以 page 结构中这些字段里的每一个比特内核都会物尽其用。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; flags;&lt;br/&gt;} &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此这个 unsigned long 类型的 flags 字段中不仅包含上面提到的定位信息还会包括物理内存页的一些属性和标志位。flags 字段的高 8 位用来表示 struct page 的定位信息，剩余低位表示特定的标志位。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.32661290322580644&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicqqYe2FAT5ibD4m5LvOLiaWCkd2MIgiao3XqgQXcUjThJtuQhkC18XGJ5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;struct page 与其所属上层结构转换的相应函数定义在 &lt;code&gt;/include/linux/mm.h&lt;/code&gt; 文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; &lt;span&gt;page_to_section&lt;/span&gt;&lt;span&gt;(&lt;span&gt;const&lt;/span&gt; struct page *page)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; (page-&amp;gt;flags &amp;gt;&amp;gt; SECTIONS_PGSHIFT) &amp;amp; SECTIONS_MASK;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;pg_data_t&lt;/span&gt; *&lt;span&gt;page_pgdat&lt;/span&gt;&lt;span&gt;(&lt;span&gt;const&lt;/span&gt; struct page *page)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; NODE_DATA(page_to_nid(page));&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; struct zone *&lt;span&gt;page_zone&lt;/span&gt;&lt;span&gt;(&lt;span&gt;const&lt;/span&gt; struct page *page)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &amp;amp;NODE_DATA(page_to_nid(page))-&amp;gt;node_zones[page_zonenum(page)];&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们介绍完了 flags 字段中高位存储的位置定位信息之后，接下来就该来介绍下在低位比特中表示的物理内存页的那些标志位~~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;物理内存页的这些标志位定义在内核 &lt;code&gt;/include/linux/page-flags.h&lt;/code&gt;文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;enum&lt;/span&gt; pageflags {&lt;br/&gt; PG_locked,  &lt;span&gt;/* Page is locked. Don&#x27;t touch. */&lt;/span&gt;&lt;br/&gt; PG_referenced,&lt;br/&gt; PG_uptodate,&lt;br/&gt; PG_dirty,&lt;br/&gt; PG_lru,&lt;br/&gt; PG_active,&lt;br/&gt; PG_slab,&lt;br/&gt; PG_reserved,&lt;br/&gt;    PG_compound,&lt;br/&gt; PG_private,  &lt;br/&gt; PG_writeback,  &lt;br/&gt; PG_reclaim,  &lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_MMU&lt;/span&gt;&lt;br/&gt; PG_mlocked,  &lt;span&gt;/* Page is vma mlocked */&lt;/span&gt;&lt;br/&gt; PG_swapcache = PG_owner_priv_1, &lt;br/&gt;&lt;br/&gt;        ................&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_locked 表示该物理页面已经被锁定，如果该标志位置位，说明有使用者正在操作该 page , 则内核的其他部分不允许访问该页， 这可以防止内存管理出现竞态条件，例如：在从硬盘读取数据到 page 时。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_mlocked 表示该物理内存页被进程通过 mlock 系统调用锁定常驻在内存中，不会被置换出去。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_referenced 表示该物理页面刚刚被访问过。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_active 表示该物理页位于 active list 链表中。PG_referenced 和 PG_active 共同控制了系统使用该内存页的活跃程度，在内存回收的时候这两个信息非常重要。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_uptodate  表示该物理页的数据已经从块设备中读取到内存中，并且期间没有出错。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_readahead 当进程在顺序访问文件的时候，内核会预读若干相邻的文件页数据到 page 中，物理页 page 结构设置了该标志位，表示它是一个正在被内核预读的页。相关详细内容可回看笔者之前的这篇文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_dirty 物理内存页的脏页标识，表示该物理内存页中的数据已经被进程修改，但还没有同步会磁盘中。笔者在 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt; 一文中也详细介绍过。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_lru 表示该物理内存页现在被放置在哪个 lru 链表上，比如：是在 active list 链表中 ？ 还是在 inactive list 链表中 ？&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_highmem 表示该物理内存页是在高端内存中。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_writeback 表示该物理内存页正在被内核的 pdflush 线程回写到磁盘中。详情可回看文章&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&amp;amp;mid=2247486623&amp;amp;idx=1&amp;amp;sn=0cafed9e89b60d678d8c88dc7689abda&amp;amp;chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&amp;amp;token=1468822011&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《从 Linux 内核角度探秘 JDK NIO 文件读写本质》&lt;/a&gt; 。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_slab 表示该物理内存页属于 slab 分配器所管理的一部分。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_swapcache 表示该物理内存页处于 swap cache 中。 struct page 中的 private 指针这时指向 swap_entry_t 。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_reclaim 表示该物理内存页已经被内核选中即将要进行回收。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_buddy 表示该物理内存页是空闲的并且被伙伴系统所管理。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_compound 表示物理内存页属于复合页的其中一部分。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PG_private 标志被置位的时候表示该 struct page 结构中的 private 指针指向了具体的对象。不同场景指向的对象不同。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外内核还定义了一些标准宏，用来检查某个物理内存页 page 是否设置了特定的标志位，以及对这些标志位的操作，这些宏在内核中的实现都是原子的，命名格式如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;PageXXX(page)：检查 page 是否设置了 PG_XXX 标志位&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;SetPageXXX(page)：设置 page 的 PG_XXX 标志位&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ClearPageXXX(page)：清除 page 的 PG_XXX 标志位&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;TestSetPageXXX(page)：设置 page 的 PG_XXX 标志位，并返回原值&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外在很多情况下，内核通常需要等待物理页 page 的某个状态改变，才能继续恢复工作，内核提供了如下两个辅助函数，来实现在特定状态的阻塞等待：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;wait_on_page_locked&lt;/span&gt;&lt;span&gt;(struct page *page)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;inline&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;wait_on_page_writeback&lt;/span&gt;&lt;span&gt;(struct page *page)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当物理页面在锁定的状态下，进程调用了 wait_on_page_locked 函数，那么进程就会阻塞等待知道页面解锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当物理页面正在被内核回写到磁盘的过程中，进程调用了 wait_on_page_writeback 函数就会进入阻塞状态直到脏页数据被回写到磁盘之后被唤醒。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6.4 复合页 compound_page 相关属性&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们都知道 Linux 管理内存的最小单位是 page，每个 page 描述 4K 大小的物理内存，但在一些对于内存敏感的使用场景中，用户往往期望使用一些巨型大页。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;巨型大页就是通过两个或者多个物理上连续的内存页 page 组装成的一个比普通内存页 page 更大的页，&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为这些巨型页要比普通的 4K 内存页要大很多，所以遇到缺页中断的情况就会相对减少，由于减少了缺页中断所以性能会更高。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，由于巨型页比普通页要大，所以巨型页需要的页表项要比普通页要少，页表项里保存了虚拟内存地址与物理内存地址的映射关系，当 CPU 访问内存的时候需要频繁通过 MMU 访问页表项获取物理内存地址，由于要频繁访问，所以页表项一般会缓存在 TLB 中，因为巨型页需要的页表项较少，所以节约了 TLB 的空间同时降低了 TLB 缓存 MISS 的概率，从而加速了内存访问。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一个使用巨型页受益场景就是，当一个内存占用很大的进程（比如 Redis）通过 fork 系统调用创建子进程的时候，会拷贝父进程的相关资源，其中就包括父进程的页表，由于巨型页使用的页表项少，所以拷贝的时候性能会提升不少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上就是巨型页存在的原因以及使用的场景，但是在 Linux 内存管理架构中都是统一通过 struct page 来管理内存，而巨型大页却是通过两个或者多个物理上连续的内存页 page 组装成的一个比普通内存页 page 更大的页，那么巨型页的管理与普通页的管理如何统一呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就引出了本小节的主题-----复合页 compound_page，下面我们就来看下 Linux 如果通过统一的 struct page 结构来描述这些巨型页（compound_page）：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然巨型页（compound_page）是由多个物理上连续的普通 page 组成的，但是在内核的视角里它还是被当做一个特殊内存页来看待。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下图所示，是由 4 个连续的普通内存页 page 组成的一个 compound_page：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.20887096774193548&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPliccOV9eY3v3uVZEEVicgFjlicDQJvNoRIXjBQ5pgicDJtW5BBnicCuI9Lzgw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;组成复合页的第一个 page 我们称之为首页（Head Page），其余的均称之为尾页（Tail Page）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们来看一下 struct page 中关于描述 compound_page 的相关字段：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;      &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;      &lt;br/&gt;            &lt;span&gt;// 首页 page 中的 flags 会被设置为 PG_head 表示复合页的第一页&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; flags; &lt;br/&gt;            &lt;span&gt;// 其余尾页会通过该字段指向首页&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; compound_head;   &lt;br/&gt;            &lt;span&gt;// 用于释放复合页的析构函数，保存在首页中&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;char&lt;/span&gt; compound_dtor;&lt;br/&gt;            &lt;span&gt;// 该复合页有多少个 page 组成，order 还是分配阶的概念，首页中保存&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// 本例中的 order = 2 表示由 4 个普通页组成&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;unsigned&lt;/span&gt; &lt;span&gt;char&lt;/span&gt; compound_order;&lt;br/&gt;            &lt;span&gt;// 该复合页被多少个进程使用，内存页反向映射的概念，首页中保存&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;atomic_t&lt;/span&gt; compound_mapcount;&lt;br/&gt;            &lt;span&gt;// 复合页使用计数，首页中保存&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;atomic_t&lt;/span&gt; compound_pincount;&lt;br/&gt;      }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首页对应的 struct page 结构里的 flags 会被设置为 PG_head，表示这是复合页的第一页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外首页中还保存关于复合页的一些额外信息，比如用于释放复合页的析构函数会保存在首页 struct page 结构里的 compound_dtor 字段中，复合页的分配阶 order 会保存在首页中的 compound_order 中，以及用于指示复合页的引用计数 compound_pincount，以及复合页的反向映射个数（该复合页被多少个进程的页表所映射）compound_mapcount 均在首页中保存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;复合页中的所有尾页都会通过其对应的 struct page 结构中的 compound_head 指向首页，这样通过首页和尾页就组装成了一个完整的复合页 compound_page 。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.40241935483870966&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicBrGLpPGYpxajgWiaf2ibUhw1pJgevfn1icEUGhibX7OUp0jDVjUzOtHy0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6.5 Slab 对象池相关属性&lt;span/&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本小节只是对 slab 的一个简单介绍，大家有个大概的印象就可以了，后面笔者会有一篇专门的文章为大家详细介绍 slab 的相关实现细节，到时候还会在重新详细介绍 struct page 中的相关属性。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内核中对内存页的分配使用有两种方式，一种是一页一页的分配使用，这种以页为单位的分配方式内核会向相应内存区域 zone 里的伙伴系统申请以及释放。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一种方式就是只分配小块的内存，不需要一下分配一页的内存，比如前边章节中提到的 struct page ，anon_vma_chain ，anon_vma ，vm_area_struct 结构实例的分配，这些结构通常就是几十个字节大小，并不需要按页来分配。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了满足类似这种小内存分配的需要，Linux 内核使用 slab allocator 分配器来分配，slab 就好比一个对象池，内核中的数据结构对象都对应于一个 slab 对象池，用于分配这些固定类型对象所需要的内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它的基本原理是从伙伴系统中申请一整页内存，然后划分成多个大小相等的小块内存被 slab 所管理。这样一来 slab 就和物理内存页 page 发生了关联，由于 slab 管理的单元是物理内存页 page 内进一步划分出来的小块内存，所以当 page 被分配给相应 slab 结构之后，struct page 里也会存放 slab 相关的一些管理数据。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;    &lt;span&gt;/* slab, slob and slub */&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;union&lt;/span&gt; {&lt;br/&gt;                &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;list_head&lt;/span&gt; &lt;span&gt;slab_list&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;    &lt;span&gt;/* Partial pages */&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;page&lt;/span&gt; *&lt;span&gt;next&lt;/span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;ifdef&lt;/span&gt; CONFIG_64BIT&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;int&lt;/span&gt; pages;  &lt;span&gt;/* Nr of pages left */&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;int&lt;/span&gt; pobjects;   &lt;span&gt;/* Approximate count */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                    short &lt;span&gt;int&lt;/span&gt; pages;&lt;br/&gt;                    short &lt;span&gt;int&lt;/span&gt; pobjects;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;endif&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                };&lt;br/&gt;            };&lt;br/&gt;            &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;kmem_cache&lt;/span&gt; *&lt;span&gt;slab_cache&lt;/span&gt;;&lt;/span&gt; &lt;span&gt;/* not slob */&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;/* Double-word boundary */&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;void&lt;/span&gt; *freelist;     &lt;span&gt;/* first free object */&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;union&lt;/span&gt; {&lt;br/&gt;                &lt;span&gt;void&lt;/span&gt; *s_mem;    &lt;span&gt;/* slab: first object */&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;struct&lt;/span&gt; {&lt;/span&gt;            &lt;span&gt;/* SLUB */&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; inuse:&lt;span&gt;16&lt;/span&gt;;&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; objects:&lt;span&gt;15&lt;/span&gt;;&lt;br/&gt;                    &lt;span&gt;unsigned&lt;/span&gt; frozen:&lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;                };&lt;br/&gt;            };&lt;br/&gt;        };&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;struct list_head slab_list ：slab 的管理结构中有众多用于管理 page 的链表，比如：完全空闲的 page 链表，完全分配的 page 链表，部分分配的 page 链表，slab_list 用于指定当前 page 位于 slab 中的哪个具体链表上。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;struct page *next ： 当 page 位于 slab 结构中的某个管理链表上时，next 指针用于指向链表中的下一个 page。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;int pages : 表示 slab 中总共拥有的 page 个数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;int pobjects ： 表示 slab 中拥有的特定类型的对象个数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;struct kmem_cache *slab_cache ： 用于指向当前 page 所属的 slab 管理结构，通过 slab_cache 将 page 和 slab 关联起来。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;void *freelist ： 指向 page 中的第一个未分配出去的空闲对象，前面介绍过，slab 向伙伴系统申请一个或者多个 page，并将一整页 page 划分出多个大小相等的内存块，用于存储特定类型的对象。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;void *s_mem ： 指向 page 中的第一个对象。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;unsigned inuse ： 表示 slab 中已经被分配出去的对象个数，当该值为 0 时，表示 slab 中所管理的对象全都是空闲的，当所有的空闲对象达到一定数目，该 slab 就会被伙伴系统回收掉。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;unsigned objects ： slab 中所有的对象个数。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;unsigned frozen : 当前内存页 page 被 slab 放置在 CPU 本地缓存列表中，frozen = 1，否则 frozen = 0 。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，关于 Linux 物理内存管理的相关内容笔者就为大家介绍完了，本文的内容比较多，尤其是物理内存页反向映射相关的内容比较复杂，涉及到的关联关系比较多，现在笔者在带大家总结一下本文的主要内容，方便大家复习回顾：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在本文的开始，笔者首先从 CPU 角度为大家介绍了三种物理内存模型：FLATMEM 平坦内存模型，DISCONTIGMEM 非连续内存模型，SPARSEMEM 稀疏内存模型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随后笔者又接着介绍了两种物理内存架构：一致性内存访问 UMA 架构，非一致性内存访问 NUMA 架构。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个基础之上，又按照内核对物理内存的组织管理层次，分别介绍了 Node 节点，物理内存区域 zone 等相关内核结构。它们的层次如下图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4798387096774194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZm4mTxzz1C0UOzTmK4PPlicrYBjP2hiaRwBLYeCniaSic44IIksFicbdCWrUCbvnLcOiaExKSJsZVLPkGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在把握了物理内存的总体架构之后，又引出了众多细节性的内容，比如：物理内存区域的管理与划分，物理内存区域中的预留内存，物理内存区域中的水位线及其计算方式，物理内存区域中的冷热页。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，笔者详细介绍了内核如何通过 struct page 结构来描述物理内存页，其中匿名页反向映射的内容比较复杂，需要大家多多梳理回顾一下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，本文的内容到这里就全部结束了，感谢大家的耐心观看，我们下篇文章见~~~&lt;/p&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg2MzU3Mjc3Ng==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/sOIZXFW0vUZ9qpdibKBrYASLXXicypdMcnlrAGcicnHQyWYNZvic3C5OpgEicMDGsAcibZTKiaNECcNXDKJiaIBr2XGTow/0?wx_fmt=png&quot; data-nickname=&quot;bin的技术小屋&quot; data-alias=&quot;&quot; data-signature=&quot;专注源码解析系列原创技术文章，分享自己的技术感悟。谈笑有鸿儒，往来无白丁。无丝竹之乱耳，无案牍之劳形。斯是陋室，惟吾德馨。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>543841f939dfc4b0dd8b55b2ec62ed5b</guid>
<title>数据指标设计的奥妙</title>
<link>https://toutiao.io/k/5nclfur</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100029782&quot; data-ratio=&quot;0.11875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/5olT2uiaWT4QQU0dIF3xGEh6nnoNWEGORVcHe9QVXSttMXPOsjicaviclVIdKBRwcoZTqoicDPBn4TiaMl4S0I2SzWw/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot; title=&quot;兔子红箭头引导关注&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzU5ODQ1OTI4NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/5olT2uiaWT4RO0fK6WpuC7XLoz8lqvMkon0ibUdErIpoXL0V98nuXFTWavgxYuBcJxd12QXch35Dh7RlicOAJR1Ag/0?wx_fmt=png&quot; data-nickname=&quot;数据工匠俱乐部&quot; data-alias=&quot;zgsjgjjlb&quot; data-signature=&quot;发展数据治理行业，普及数据治理知识，构建数据治理体系，改变企业数据管理现状，提高企业数据质量，推动企业走进大数据时代。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;就像人走路的时候需要看到前方的道路，产品和运营在做决策前也需要睁开“双眼”。左眼，是数据；右眼，是用研。（哎，别问我为什么不是左眼用研，右眼数据……）&lt;/p&gt;&lt;p&gt;通过线上数据反馈，我们可以准确地发现问题，找到规律，求证猜想，平息主观之争，为产品改进和运营优化的制定和实施提供明确的方向。&lt;/p&gt;&lt;h2&gt;一、互联网公司数据职能设置&lt;/h2&gt;&lt;p&gt;互联网公司普遍十分重视数据，数据部门职能设置却各不相同。大多会设置独立的BI部门（如携程、京东），有些（如亚马逊）也会把数据人员分散在各个团队。&lt;/p&gt;&lt;p&gt;数据职能常见的有三个主要角色：&lt;/p&gt;&lt;p&gt;a. 数据工程师，负责搭建底层数据架构，定义数据埋点规范、编写埋点代码（有时也会由开发人员植入埋点代码）、以及建立和管理数据库报表。&lt;/p&gt;&lt;p&gt;b. BI，负责根据业务需求在数据库中抓取对应数据项，编写SQL代码，生成各类报表。（注：传统的数据库管理员（DBA）的职能更类似于数据工程师 + BI – 埋点）&lt;/p&gt;&lt;p&gt;c. BA，负责对BI生成的报表进行分析，结合业务知识对数据进行透彻解读，输出有明确指导意义的观察和建议。BA人员通常需要有较强的业务背景知识，能够准确地理解数据背后的业务状况和波动原因，并用业务“语言”输出分析结论。&lt;/p&gt;&lt;p&gt;我在实践中的体会是：两种组织架构方式各有明显的利弊，优缺点截然相反。&lt;/p&gt;&lt;p&gt;当数据人员集中在一个部门时，数据库管理和报表定制均十分专业高效。但因为离业务部门较远，业务理解受到影响，在数据定义和解读上相对偏薄弱。&lt;/p&gt;&lt;p&gt;数据职能分散在各个业务线时，正好相反。并有较严重的数据重复拉取，人力浪费不说，还因口径定义上的差异，导致同一数据在不同部门各不相同。例如转化率=订单数／访客数，有的部门在访客数中去除“疑似机器人”部分，有的部门则统一访客数为“二跳访客”，带来转化率数据的明显差异。&lt;/p&gt;&lt;p&gt;一个比较好的做法是把数据工程师和BI集中在数据部门，在各个业务线分别设置BA人员，两边对接。&lt;/p&gt;&lt;h2&gt;二、数据使用方式&lt;/h2&gt;&lt;p&gt;互联网需要进行数据观察的领域十分广泛，每个细分领域都有不同的核心KPI，应当根据核心目标拆分背后的影响因素，有针对性地提出数据需求，制定数据报表。&lt;/p&gt;&lt;p&gt;通常数据的使用方式分为如下情况：&lt;/p&gt;&lt;h3&gt;1. 常规数据报表&lt;/h3&gt;&lt;p&gt;常规数据报表主要用于需要长期持续观察的核心数据。例如：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;流量漏斗监控，可分为首页跳失率、商详页到达率（分为浏览-商详、搜索-商详两大分支）、加车率、结算率、结算完成率等核心环节漏斗数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;用户渠道来源情况，如各渠道来源的用户数、新客数、订单占比、转化情况等等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;品类转化率波动，如各品类的流量、订单、SKU销售数量等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;流量分发效率，如各频道／栏目的CTR、商详页到达、转化、复访率等。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当常规监控的核心数据项发生超阈值波动或趋势性波动时，通常会触发专题分析，并根据分析结果采取相应对策，以推动数据回到常规范围。&lt;/p&gt;&lt;p&gt;常规数据报表建议通过公司的BI系统定制在线报表，按监控频度进行观察分析。&lt;/p&gt;&lt;h3&gt;2. 专题分析&lt;/h3&gt;&lt;p&gt;专题数据分析通常按专题的主要影响因素确定数据项，拆分观察维度，抓取多维度数据，对某个专题目标进行分析，找到影响因素所在的数据维度，得出结论，指导后续动作。例如：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;针对某个重大事件的状况或效果分析，如双11大促后的数据总结盘点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;核心数据出现重大波动，如Web平台转化率持续提升的原因分析。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;出现趋势性状况，如某付费渠道来源的用户数量持续下降。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;某个专题研究，如95后导购特征和消费特征分析。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. AB测试&lt;/h3&gt;&lt;p&gt;产品经理常有的困惑是，当上线了某一个功能或者频道后，目标数据出现了某种变化。然而，变化背后的影响因素非常多，例如时间因素导致的差异（如工作日的转化率高于周末）、竞争对手的动作、季节性因素等等。核心数据的波动往往是这些影响因素综合作用的结果，很难准确界定该功能本身带来了多少直接影响。&lt;/p&gt;&lt;p&gt;运营也常有类似的诉求，例如当首页图标做了飘红，或者引导文案做了一些调整，数据出现了波动，但却很难确定多大程度为该特定运营动作的效果。&lt;/p&gt;&lt;p&gt;上述情况下，最好的方法就是做AB测试：取两个数据集，在数据集样本的选取中对各种影响因素做均匀的随机分布（如地域、用户群体特性），并对其中一个数据集实施特定产品功能或运营动作；在同一时段中，观测目标数据在两个测试集上的差异，从而精确判定待观测功能／动作的准确效果。&lt;/p&gt;&lt;p&gt;这里要特别注意两点：&lt;/p&gt;&lt;p&gt;1. 为了确保统计效果的准确性，需要有较大的样本量和统计时长（结果数量=用户量*统计时长，要么用户量足够大，统计周期可以略短；如果用户量较小，则需要更长的统计周期）。&lt;/p&gt;&lt;p&gt;2. 如果某一个样本中存在少数对均值影响巨大的样本（例如一个金额巨大的订单），需要予以排除，以减少偶然性带来的偏差。&lt;/p&gt;&lt;h3&gt;4. 个性化&lt;/h3&gt;&lt;p&gt;这是个大数据的时代，差异巨大的用户群体面对海量的商品和选择，“千人一面”带来的糟糕体验已不再适用。&lt;/p&gt;&lt;p&gt;每个用户在系统中都会留下自己的线索和足迹，体现自己在商品品类、价格段、品牌偏好等方面的阶段性需求。系统可以通过数据有效发现当前用户的当前需求，进行有效的推荐，而用户也会感受到系统“懂我”，产生良好的购物体验。&lt;/p&gt;&lt;p&gt;亚马逊早年的“Everything Store”理念，在当前时代下，也逐渐转化为“Everyone Store”，也就是我们常说的“千人千面”。&lt;/p&gt;&lt;p&gt;数据是千人千面的基础，通过机器学习和算法设计，让系统在各个模块中进行智能化推荐，自动组装匹配当前用户的场景，是数据使用的最重要方式之一。这部分我会在后续文章中结合实际案例重点展开。&lt;/p&gt;&lt;h2&gt;三、常规性数据报表的定制及数据监控&lt;/h2&gt;&lt;p&gt;为了最优使用BI资源并突出自身专注点，在定制常规性数据报表时，切勿大而全。需要完全考虑清楚的主要有两点：北极星指标、指标监控频度。&lt;/p&gt;&lt;h3&gt;1. 北极星指标&lt;/h3&gt;&lt;p&gt;任何一个业务要能不断优化和提升，做出更好的效果，都需要正确设立核心指标，持续监控，并根据实际数据与阶段性预期进展之间的差距进行分析，触发相应的调整动作，以使得业务的发展和计划保持一致。&lt;/p&gt;&lt;p&gt;这套思路在项目管理理论中被总结为PDCA ，即计划（Plan）、执行（Do）、校验（Check）、响应（Act），在项目管理和持续质量改善中也被称为戴明循环。该体系是业务目标管理的核心方法，感兴趣的同学可以查阅项目管理理论，本文不进行赘述。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8296059637912673&quot; data-type=&quot;jpeg&quot; data-w=&quot;939&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/D70DM5WYawVEvrTBxe1q0qibzN9NumaRsltnPyqu9pp6ZnjPz55VLfHAuAomkBXr6IjaVRkR9Mg3ynqEeFmjkxA/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/p&gt;&lt;p&gt;从PDCA概念中可以看到，目标的制定、执行成效的判断以及纠偏动作的效果，都需要好的数据指标进行衡量，并作为最终目标达成与否的判断依据。这个可度量的指标，与目标呈直接的正相关关系，该指标被称为北极星指标。&lt;/p&gt;&lt;p&gt;北极星指标体系通常分为多级，每一级指标的设立选取，都是为了更好的支持上一级指标的达成，以最终共同实现公司顶层战略（公司级的北极星指标）。&lt;/p&gt;&lt;p&gt;在这里举个实际例子。一个电商公司的经营规模往往通过公司的年营业额（GMV）来衡量，也即GMV是整个公司的北极星指标之一。营业额有多种拆分计算方式，在此列出常见的一种简化计算方式：&lt;/p&gt;&lt;p&gt;GMV = AC * Freq * Conversion * AOS&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;AC：活跃顾客数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Freq：顾客平均访问频度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Conversion：转化率&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AOS：平均单均价&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面四个核心指标，则为第二级核心指标，通常可下达到各个部门分别负责。&lt;/p&gt;&lt;p&gt;例如，市场部负责流量和用户数及其活跃度，产品和运营负责转化率指标，类目线负责单均价指标。于是这些指标成为各个部门的北极星指标。如果一个指标的核心影响因素分散在多个部门，也由同一个部门牵头负责。&lt;/p&gt;&lt;p&gt;为了达到上述各个二级指标，还可以进一步拆分。以活跃顾客数为例：&lt;/p&gt;&lt;p&gt;AC = RC + NC – EC&lt;/p&gt;&lt;p&gt;于是这些指标又可以进一步分配到负责拉新和留存的职能团队，成为这些团队的北极星指标，由这些团队各自牵头负责。&lt;/p&gt;&lt;p&gt;负责拉新的团队，又可以进一步把拉新指标拆分到渠道，如付费渠道、免费渠道等，进行下一级的核心指标定义和目标制定。&lt;/p&gt;&lt;p&gt;同样地，下一级负责付费渠道的职能团队或人员，则可以进一步拆分到具体渠道，如网盟、SEM、应用商店等，进一步制定各个渠道的具体目标。如此层层往下，直到直接可控的最下一层。&lt;/p&gt;&lt;p&gt;以此类推，产品和运营负责的转化率指标，则可以沿转化漏斗拆分为首页到商详、搜索到商详、商详加车率、购物车结算率、支付成功率等，通过逐层递进的拆分具体到各个团队进行分解，成为各自的北极星指标。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6719914802981896&quot; data-type=&quot;jpeg&quot; data-w=&quot;939&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/D70DM5WYawVEvrTBxe1q0qibzN9NumaRsTZksyibMbn439pvDFVJuuT9faOeNicoQiabK00BBibNvYg0cw3vxLf6BpQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/p&gt;&lt;p&gt;对于各个职能部门／团队来说，自己所负责的这一级指标以及下一级指标情况，应当成为常规数据报表的监控内容，由此制定报表格式，向BI部门提出数据需求。&lt;/p&gt;&lt;p&gt;站在宏观维度来看，三级指标的达成可以确保二级指标的达成，二级指标的达成可以确保顶层指标的达成，从而为业务目标提供保障。因此，指标体系的合理拆分和严密监控纠偏对公司目标实现至关重要。&lt;/p&gt;&lt;h3&gt;2. 指标监控频度&lt;/h3&gt;&lt;p&gt;常规数据报表的周期通常为日报、周报、月报、季报。实时数据监控通常为应急响应需要（如故障宕机、突发事件处理），而半年报、年报则大多为业务结果的统计，周期过长，发现的问题及响应过慢，通常不在常规数据报表的范围。&lt;/p&gt;&lt;p&gt;每个业务单元都具有各不相同的特点，需要进行有针对性的数据统计频度设定。下面以产品和运营层面对转化率的监控为例：&lt;/p&gt;&lt;p&gt;在大促期间观察活动效果，流量变化迅速，高峰此起彼伏，爆品库存时有告罄，此时数据观察应当精确到最小颗粒度甚至实时监控数据曲线，对数据体现的问题（如售罄、宕机、技术故障、黄金资源位单品滞销、页面陈列错误、价格设置错误导致的波动等）迅速响应，优化促销品及资源位，并使用赛马机制，调整会场流量分发，以把大促效果推到极致。&lt;/p&gt;&lt;p&gt;对于日常促销活动，可以以天为单位，对促销品类和促销方式在整体转化漏斗中的表现进行观察，定位问题点并迅速进行针对性优化；如换品，换促销规则，更新活动页／活动栏目，配置促销标签等，以达到最佳活动效果。&lt;/p&gt;&lt;p&gt;运营方面，例如首页或频道运营，可以以周或月为单位，通过各板块CTR、停留时间、商详到达率、加车率、转化率、复访频度等维度观察栏目用户的兴趣指数，对于薄弱环节通过数据进行深入分析（如用户动线跟踪、区域点击热度分析、跳失分析等），并适当结合用研的定性定量深访对频道入口交互设计、页面信息架构设计、频道子栏目铺设、信息展示、营销文案等进行优化，以达到最佳效果。&lt;/p&gt;&lt;p&gt;移动时代受到移动端发包频度的限制（大多为每两周到一个月发一个包），高度依赖技术功能的核心指标往往以月或季为单位进行统计。&lt;/p&gt;&lt;p&gt;例如，对于核心转化漏斗模块的功能迭代和新产品模块的效率效果，可以以月或季为单位（与技术发版周期和新栏目用户教育养成周期有关），结合季节性因素，纵向对比同比和环比相应数据的波动，找到可以发力优化提升的环节。&lt;/p&gt;&lt;p&gt;运营动作一般带来较快速的数据响应，侧重于日报、周报对运营的指导；而产品动作一般受技术发版影响，数据响应周期适中，更偏重月或季为周期的报表，但都谋求发现问题后迅速响应。&lt;/p&gt;&lt;p&gt;年报总体来说可能更适用于公司战略和业务线的财务考量，除了成果和得失总结，产品和运营侧的使用相对较少。&lt;/p&gt;&lt;p&gt;上述是针对转化率的举例。&lt;/p&gt;&lt;p&gt;如果是用户运营和增长，同样可以根据频度对用户的渠道来源和激活情况、传播效果（短周期，如天或周）、活跃度、品类渗透率、交易情况、人均价值（中周期，如月）、留存率、流失返回率、生命周期情况（长周期，如季或半年／年）进相应的数据报表制定和监控，并触发响应的调整动作。&lt;/p&gt;&lt;p&gt;最后，在报表制定时，建议不要把太多级别的数据放在同一个报表上，造成数据的汪洋大海，表格过度复杂，也会迷失专注点。通常一个报表含两级指标为最佳。&lt;/p&gt;&lt;p&gt;例如，一级指标的报表只含一、二级指标数据，对于一级指标的波动从二级指标进行观察，找到波动原因。如果需要继续深入，建议另外定制二级指标报表，含二、三级指标数据。以此类推。&lt;/p&gt;&lt;h2&gt;四、专题分析&lt;/h2&gt;&lt;p&gt;工作中常会碰到一些突发异常情况，例如某阶段用户转化率大幅波动、交易金额飙升或锐减、某栏目CTR暴跌等，再或者观察到某些趋势性的变化（如消费者导购偏好演变、品牌消费趋势变化）。此时通常会进行专题性分析，以明确下一步解决问题的思路。&lt;/p&gt;&lt;h3&gt; 1. 专题分析触发原因&lt;/h3&gt;&lt;p&gt;专题分析主要由如下情况触发：&lt;/p&gt;&lt;p&gt;a. 在数据报表中，我们常常看到一些核心数据指标产生波动，当波动范围超过一个预定义的警戒阈值时，就应该触发分析（无论正向的还是负向的波动），以理解波动背后的原因，并采取相应的对策。&lt;/p&gt;&lt;p&gt;多大幅度的波动值得触发分析因指标本身特性对应的业务敏感度而定。阈值设置没有固定规则，大家可以根据影响的承受力来设定。这里有一个常见错误，就是对正常的小幅波动太过敏感，触发频繁的分析，最终却没有有价值的发现，属于自然波动，浪费了人力。&lt;/p&gt;&lt;p&gt;什么是正常幅度的波动，可以对一个大时间段的同一指标进行同比环比的统计后判断。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4185303514376997&quot; data-type=&quot;jpeg&quot; data-w=&quot;939&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/D70DM5WYawVEvrTBxe1q0qibzN9NumaRsibzKKpBf09f9Jr9icSFoXUHkXypn9ssrvZ5fOWlEGZ3szou81aiaAOKicA/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/p&gt;&lt;p&gt;例如，上图是我们在某五周期间观察到到流量按时间段到分布情况。大家仔细看下有什么异常？&lt;/p&gt;&lt;p&gt;猜对了，0点出现大流量！9点，14点，19点的流量峰值符合移动端用户在早晨通勤时间、下午回到座位、傍晚通勤时间的访问规律。但0点出现如此之大的流量，十分异常，就应当触发专题分析。&lt;/p&gt;&lt;p&gt;b. 在数据报表中，数据体现出某个同趋势性的连续变化，例如，连续7次正向或负向的增长。此时，即使还没有达到预设的异常警戒阈值，都应当进行分析，以理解趋势背后的原因。&lt;/p&gt;&lt;p&gt;可能有同学会问，为什么是7次呢？&lt;/p&gt;&lt;p&gt;其实这不是绝对的，当一个连续趋势出现时，同向的数据点越多，表明背后有某种非偶然因素的可能性越大。从统计学角度，如果是偶然因素导致连续7个点往同一个方向发展，可能性只有1/128，大约为8%。因此，7点同趋势变化背后存在非偶然因素的置信度已经足够高了。如果是特别关键的指标，连续5个点同向发展（97%的确定性）也许就该进行分析了。想要深入了解的同学可以搜索“7点原则”，查阅PMP或者统计学有关的理论知识。&lt;/p&gt;&lt;p&gt;当然，背后应当去除已经理解的影响因素，例如越来越靠近春节时流量持续下滑，或者接近换季时新一季的服装销售持续上升，都是正常现象，除非波动过大严重脱离同比情况，否则这样的趋势并不值得浪费人力进行分析。&lt;/p&gt;&lt;p&gt;c. 对某个数据背后的原因感兴趣，需要分析和理解该数据背后蕴含的信息。这个和数据的波动本身没有关系，只是深入去理解数据背后的原因或因素。&lt;/p&gt;&lt;p&gt;例如，分析为什么在平台上第三方商家的流量达到48%，以制定更平衡的流量分发策略来扶持自营或第三方业务；分析为什么付费渠道来源的用户占比偏低或单客成本过高，以做更精准更高性价比的流量采买投放。&lt;/p&gt;&lt;h3&gt;2. 专题分析常用方法&lt;/h3&gt;&lt;p&gt;简单概括，专题性分析的主要做法是，按多个维度全面对波动数据指标的下层构成进行拆分，观察对比各个下层数据，找到在哪个细分维度出现异常波动，并锁定该维度，层层递进，深入分解，直到最终找到答案。&lt;/p&gt;&lt;p&gt;在拆分到下层维度过程中，需要考虑从多个角度出发，反复对比。例如，如果某一周发现转化率产生异常波动，可以按如下维度进行拆分观察：&lt;/p&gt;&lt;p&gt;维度一：商品品类&lt;/p&gt;&lt;p&gt;拆分到各个品类，观察是否由某个品类的转化率大幅波动带动了整体转化率的波动。&lt;/p&gt;&lt;p&gt;案例1：&lt;/p&gt;&lt;p&gt;某一周我们发现全站转化率飙升近2%，通过二级报表对各品类转化率进行观察后发现，转化率波动主要出现在美妆品类。进一步对美妆品类各SKU的销售进行观察，发现洁面仪、水牙线、和某款面膜等三个商品短时间销量巨大。这三个单品的上线价格远比京东和天猫更为低价，并与市场部确认，市场部有在“什么值得买”网站进行投放，导致大量用户涌入，销量激增，通过这三个热销爆款的销售推动了全站转化率的波动。&lt;/p&gt;&lt;p&gt;案例2：&lt;/p&gt;&lt;p&gt;有一次服装线的采销对某品牌服装在设置促销券时忘记设置互斥，导致用户可以反复领券和叠加用券。而该技术漏洞被人在乌云平台所披露，导致大规模的用户和黄牛涌入抢购，零元购买，极短的时间里卖出数千件，造成转化率瞬时飙升。因为人工设置价格和促销时错误难以绝对避免，此类问题在各个电商平台时有发生。&lt;/p&gt;&lt;p&gt;维度二：用户群体&lt;/p&gt;&lt;p&gt;拆分到各个用户群体，观察是否由于某个用户群体的购买情况变化造成了转化率的波动。注意用户本身就可以按很多个维度拆分：&lt;/p&gt;&lt;p&gt;案例3：&lt;/p&gt;&lt;p&gt;某一周的数据观察中我们发现全站转化率的飙升，通过地域和品类的分析，发现是由于华东地区高温，导致空调风扇等商品在华东的销售飙升，推高全站转化率。北京地区雾霾爆表也曾导致净化器、口罩等商品在北京地区销售猛增。&lt;/p&gt;&lt;p&gt;维度三：渠道来源&lt;/p&gt;&lt;p&gt;拆分到各个用户来源渠道，按渠道对应的销售情况进行观察。&lt;/p&gt;&lt;p&gt;例如，有时转化率大幅提升，分析发现是因为市场部在某些导购网站的黄金资源位进行了爆款投放，从该渠道产生了巨大的流量和销售进而推高了整体转化率。当然部分渠道的刷单现象也常常会引起整体转化率波动。&lt;/p&gt;&lt;p&gt;维度四：转化漏斗&lt;/p&gt;&lt;p&gt;观察首页到商详，商详到购物车，购物车到结算，结算到支付等转化漏斗环节的细分转化率的变化情况。&lt;/p&gt;&lt;p&gt;案例4：&lt;/p&gt;&lt;p&gt;有一周转化率低于警戒值，通过漏斗分析发现支付环节成功率大幅下滑。对支付渠道进行分解后发现某银行渠道的支付成功率下降到零。与该银行沟通后确认，该银行对支付接口进行了升级，升级版本存在问题，导致该支付渠道支付失败，导致整体转化率产生波动。&lt;/p&gt;&lt;p&gt;案例5：&lt;/p&gt;&lt;p&gt;有一次技术团队上线新版本后，发现转化率下跌，通过漏斗分析发现，在新用户注册环节有较大的注册成功率下降。进一步通过注册流程的分析，看到产品功能上增加了一步强制实名认证，导致部分用户在这一步由于各种考虑而放弃了注册。在与产品经理沟通后把实名认证改为可跳过，改为在后续阶段进行引导认证。这一步改变使注册成功率得以恢复，问题解决。&lt;/p&gt;&lt;p&gt;维度五：设备平台&lt;/p&gt;&lt;p&gt;观察iOS，Android，PC，Web等各个平台以及各个app版本的转化率情况。例如，我们有时发现，新发的Android包存在技术故障，导致用户大规模登录失败，进而影响整体转化率。&lt;/p&gt;&lt;p&gt;维度六：销售渠道&lt;/p&gt;&lt;p&gt;很多平台会对接下一级分销渠道，各个渠道的销售情况变化也会带来整体转化率波动。有时某个渠道进行了效果极佳广告投放，会重大促进该渠道的销售，进而影响整体转化率。&lt;/p&gt;&lt;p&gt;维度七：流量或销售时段分布&lt;/p&gt;&lt;p&gt;拆分到各个用户来源渠道，按渠道对应的销售情况进行观察。&lt;/p&gt;&lt;p&gt;例如，有时转化率大幅提升，分析发现是因为市场部在“什么值得买”的黄金资源位进行了爆款投放，从该渠道产生了巨大的流量和销售进而推高了整体转化率。当然部分渠道的刷单现象也常常会引起整体转化率波动。&lt;/p&gt;&lt;p&gt;案例6：&lt;/p&gt;&lt;p&gt;有一次转化率下降报警，数据分析表明销售情况在用户、渠道、品类等方面都分布均匀。最后产品经理与BA联合排查，发现在0点到7点之间有大流量出现，并且流量集中在整点刚到时爆发，由此基本可以推测这些流量并非真实顾客，而是某种程序脚本整点触发导致。最后与技术团队跟进分析，确认是某搜索引擎爬虫开始集中爬取平台商品、价格信息。&lt;/p&gt;&lt;p&gt;维度八：用户账号或商户&lt;/p&gt;&lt;p&gt;有时某个商户，或某些用户，出现异常大规模订单，导致整体转化率、单均价等出现巨大波动（此类现象往往是刷单导致）。通过按商户或用户账号的销售情况拆分，可以发现此类问题。&lt;/p&gt;&lt;p&gt;在我和数据团队所做过的实际的分析中，以上八种维度都经常发现问题。并不排除还有更多维度，大家可以按自己的业务特性进行类推。&lt;/p&gt;&lt;p&gt;以上只是对转化率进行分解分析的一个例子。任何一种指标通常都可以向下拆解，直到最后发现问题所在，而上面列举的八个维度，通用于绝大部分的线上状况分析。&lt;/p&gt;&lt;p&gt;具体的做法是：按各个维度对指标拆分到下一级后，观察下级各维度指标是否均匀体现该波动。如果是，则基本可以排除是该维度的因素所导致。对同级的各个维度逐一拆分观察，通常会发现某个维度下的某个次级指标剧烈波动，锁定该指标，再次对其下层指标进行分解观察，层层递进，最终可以找到结论。&lt;/p&gt;&lt;p&gt;&lt;span&gt;来源网址：&lt;/span&gt;&lt;span&gt;https://coffee.pmcaff.com/article/1900050815295616?newwindow=1&lt;/span&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;R92C-1656560098273&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;AenD-1656560098272&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;简明为本——它是极力简化不必要的工作量的技艺。&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}],&amp;quot;state&amp;quot;:{}}]&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;h1&gt;&lt;section data-support=&quot;96编辑器&quot; data-style-id=&quot;24373&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;免责声明：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;本公众号所有分享的软件和资料来自网络收集和整理，所有文字和图片版权归属于原作者所有，且仅代表作者个人观点，与&lt;/strong&gt;&lt;strong&gt;数据工匠俱乐部&lt;/strong&gt;&lt;strong&gt;无关，文章仅供读者学习交流使用，并请自行核实相关内容，&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;如&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;文章内容涉及侵权，请联系后台管理员删除&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/article&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;R92C-1656560098273&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;AenD-1656560098272&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;简明为本——它是极力简化不必要的工作量的技艺。&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}],&amp;quot;state&amp;quot;:{}}]&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100029984&quot; data-ratio=&quot;1.350140056022409&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5olT2uiaWT4SDWJuDpaTLficEG74RVKs0U3ic5rMm1dL8xOaqaoic0licFSnYoibLQnDWq1WS7wJxBnc96gjk19KKMxQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;357&quot;/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;(欢迎大家加入数据工匠知识星球获取更多资讯。)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;87560&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span class=&quot;js_img_placeholder&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/5olT2uiaWT4SDWJuDpaTLficEG74RVKs0Ug2qyykvwib8iarmMS7KCpPxIgSIVqwqBxIria8ljCBmK4sTU8yPzFicsNA/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-index=&quot;15&quot;&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;94155&quot;&gt;&lt;section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;91597&quot;&gt;&lt;section data-role=&quot;paragraph&quot; data-custom=&quot;#757576&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;strong&gt;联系我们&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100029981&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;430&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5olT2uiaWT4SG8S8qC26ichtcbL8moVwxZJCWS4BBT5PHXCRLjicU4tfwQAOVftQhNQjSSzIUcyuyZAI2NApm8ficQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;扫描二维码关注我们&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;strong&gt;微信：&lt;strong&gt;SZH9543&lt;/strong&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;邮箱：ccjiu@163.com&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;QQ：&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;2286075659&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;85891&quot; data-custom=&quot;rgb(172, 29, 16)&quot;&gt;&lt;section&gt;&lt;section data-bgless=&quot;lighten&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;87704&quot; data-custom=&quot;rgb(172, 29, 16)&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span data-brushtype=&quot;text&quot;&gt;热门文章&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODQ1OTI4NQ==&amp;amp;mid=2247524849&amp;amp;idx=1&amp;amp;sn=f6f601b308f62b3791a514779900ae8d&amp;amp;chksm=fe41f70bc9367e1d64c370b1cb19a74195ee7647efbb1257f050219527bda540795f0985b22c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数据治理领域最容易混淆的16组术语概念辨析&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;数据治理领域最容易混淆的16组术语概念辨析&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODQ1OTI4NQ==&amp;amp;mid=2247524849&amp;amp;idx=2&amp;amp;sn=b56a4a12adafc8d73e3b57001be7347c&amp;amp;chksm=fe41f70bc9367e1db883905ffe1daf3aea458f2cc0be85348dfd18ce5635e36559ed5b5ad898&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;12项最新数据安全国标全文来了（内附下载链接）&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;12项最新数据安全国标全文来了（内附下载链接）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODQ1OTI4NQ==&amp;amp;mid=2247524748&amp;amp;idx=1&amp;amp;sn=9e8c1fab6d2667203afb619e97284606&amp;amp;chksm=fe41f776c9367e6096889dd7b5147c9d2af8a77374c8b14eb0de59104e6a27c647f98ebe8e21&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;建议收藏|深度解析主数据治理—主数据标准体系建设&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;建议收藏|深度解析主数据治理—主数据标准体系建设&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODQ1OTI4NQ==&amp;amp;mid=2247524748&amp;amp;idx=2&amp;amp;sn=ddc12ff95326fd1a3e4c4fd0a6af3a5b&amp;amp;chksm=fe41f776c9367e60d6b4a8076c798fb6f511c5152578296d460fdbe9332d9267dcaa4dc20ca6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;速速收藏！首个数字化转型国家标准全文公布！（内附下载链接）&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;速速收藏！首个数字化转型国家标准全文公布！（内附下载链接）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODQ1OTI4NQ==&amp;amp;mid=2247524548&amp;amp;idx=1&amp;amp;sn=e7275648b545aa5699953a9fab151823&amp;amp;chksm=fe41f63ec9367f284659ad473cad1b215b092f2424c8b960d30f8c097c21049602e62daa70dd&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数据分类分级体系建设是数据安全管理“护身符”&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数据分类分级体系建设是数据安全管理“护身符”&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODQ1OTI4NQ==&amp;amp;mid=2247524525&amp;amp;idx=1&amp;amp;sn=e7d2f6fd138864a6e61a1ae1150a5e48&amp;amp;chksm=fe41f657c9367f4171689056942ea64889e463a9e9e3b636452341250854ab24852176051d85&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;【财务数据价值链】第六步：数据可视化&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【财务数据价值链】第六步：数据可视化&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span class=&quot;js_img_placeholder&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/5olT2uiaWT4SDWJuDpaTLficEG74RVKs0U7YqMjYgWB6LaEJXhE0AfOJnzCBR0NtFXTtU0BibvndHIXMWur6yYsFg/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-index=&quot;11&quot;&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;94095&quot; data-width=&quot;77%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-autoskip=&quot;1&quot;&gt;&lt;p&gt;&lt;strong&gt;我们的使命：&lt;/strong&gt;&lt;strong&gt;发展数据治理行业、普及数据治理知识、改变企业数据管理现状、提高企业数据质量、推动企业走进大数据时代。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们的愿景：&lt;/strong&gt;&lt;strong&gt;打造数据治理专家、数据治理平台、数据治理生态圈。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们的价值观：&lt;/strong&gt;&lt;strong&gt;凝聚行业力量、打造数据治理全链条平台、改变数据治理生态圈。&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span class=&quot;js_img_placeholder&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/5olT2uiaWT4SDWJuDpaTLficEG74RVKs0U7YqMjYgWB6LaEJXhE0AfOJnzCBR0NtFXTtU0BibvndHIXMWur6yYsFg/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-index=&quot;6&quot;&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;了解更多精彩内容&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100029986&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot; title=&quot;35955bc4231278c0547010d784696b8.jpg&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/5olT2uiaWT4SDWJuDpaTLficEG74RVKs0UC1DdmCHib0mPDnCjUvY5LZrFWmHZBs9ZlmS43WpflcFLxr9l0gkJl2A/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长按，识别二维码，关注我们吧！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据工匠俱乐部&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;微信号：zgsjgjjlb&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专注数据治理，推动大数据发展&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/article&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>150470ce07b5f1823696a31f79c54fdb</guid>
<title>解 Bug 之路集锦</title>
<link>https://toutiao.io/k/bt1x1ja</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;解Bug之路&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;alchemystar2&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;各种高质量技术干货尽在解Bug之路&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>