<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>770313a345ab45d13e84b1e582fde733</guid>
<title>网易二面：CPU 狂飙 900%，该怎么处理？</title>
<link>https://toutiao.io/k/uazuhjy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大家好，我是不才陈某~&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;amp;mid=2247523057&amp;amp;idx=1&amp;amp;sn=32b42c6b0ac41b48785b7c0d24ce344a&amp;amp;chksm=fcf7453ccb80cc2a4a6cf38d5b9ab0354f09f270418bf4ff5eeb832b020aedabd561979b712d&amp;amp;token=1260267649&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;星球&lt;/a&gt;&lt;span&gt;一位小伙伴面试了 网易，遇到了一个 性能类的面试题：CPU飙升900%，该怎么处理？&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;amp;mid=2247523057&amp;amp;idx=1&amp;amp;sn=32b42c6b0ac41b48785b7c0d24ce344a&amp;amp;chksm=fcf7453ccb80cc2a4a6cf38d5b9ab0354f09f270418bf4ff5eeb832b020aedabd561979b712d&amp;amp;token=1260267649&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;星球&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可惜的是，以上的问题，这个小伙没有回答理想。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最终，导致他网易之路，终止在二面，非常可惜&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;首先，说明一下问题：CPU飙升200% 以上是生产容易发生的场景&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;场景:1：MySQL进程飙升900%&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家在使用MySQL过程，想必都有遇到过CPU突然过高，或者达到200%以上的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据库执行查询或数据修改操作时，系统需要消耗大量的CPU资源维护从存储系统、内存数据中的一致性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并发量大并且大量SQL性能低的情况下，比如字段是没有建立索引，则会导致快速CPU飙升，如果还开启了慢日志记录，会导致性能更加恶化。生产上有MYSQL 飙升900% 的恶劣情况。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;场景2：Java进程飙升900%&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说Java 进程不做大量 CPU 运算，正常情况下，CPU 应该在 100~200% 之间，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，一旦高并发场景，要么走到了死循环，要么就是在做大量的 GC,  容易出现这种 CPU 飙升的情况，CPU飙升900%，是完全有可能的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;其他场景：其他的类似进程飙升900%的场景&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如Redis、Nginx等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;陈某提示：大家介绍场景的时候，就说自己主要涉及了两个场景， Java进程飙升900%、MySQL进程飙升900%两种场景，其实，这两个场景就足够讲半天了， 其他的，使用规避技巧规避一下就行。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;场景一：MySQL进程CPU飙升到900%，怎么处理？&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;定位过程：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;使用top 命令观察，确定是mysqld导致还是其他原因。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;处理过程：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;kill 掉这些线程(同时观察 cpu 使用率是否下降)， 一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;进行相应的调整(比如说加索引、改 sql、改内存参数)&lt;/p&gt;&lt;p&gt;index 是否缺失，如果是，则  建立索引。也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等；关注公z号：码猿技术专栏，回复关键词：1111 获取阿里内部Java性能调优手册&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;优化的过程，往往不是一步完成的，而是一步一步，执行一项优化措辞，再观察，再优化。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;场景1的真实案例：MySQL数据库优化的真实案例&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;陈某提示：以下案例，来自互联网。大家参考一下，准备一个自己的案例。&lt;/em&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本问题亲身经历过。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前开发同事编写的SQL语句，就导致过线上CPU过高，MySQL的CPU使用率达到900%+，通过优化最后降低到70%~80%。下面说说个人在这个过程中的排查思路。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，我们要对问题定位而不是盲目的开启什么 慢日志，在并发量大并且大量SQL性能低的情况下，开启慢日志无意是将MySQL推向崩溃的边缘。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当时遇到这个情况，分析了当前的数据量、索引情况、缓存使用情况。目测数据量不大，也就几百万条而已。接下来就去定位索引、缓存问题。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;经过询问，发现很多查询都是走MySQL，没有用到缓存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;既然没有用到缓存，则是大量请求全部查询MySQL导致。通过下面的命令查看:&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;show&lt;/span&gt; &lt;span&gt;processlist&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;发现类似很多相同的SQL语句，一直处于query状态中。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;id&lt;/span&gt; &lt;span&gt;form&lt;/span&gt; &lt;span&gt;user&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; user_code = &lt;span&gt;&#x27;xxxxx&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;初步分析可能是 user_code 字段没有索引导致。接着查询user表的索引情况：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;show&lt;/span&gt; &lt;span&gt;index&lt;/span&gt; &lt;span&gt;form&lt;/span&gt; &lt;span&gt;user&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;发现这个字段是没有建立索引。增加索引之后，该条SQL查询能够正常执行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、没隔一会，又发生大量的请求超时问题。接着进行分析，发现是开启了 慢日志查询。大量的SQL查询语句超过慢日志设置的阀值，于是将慢日志关闭之后，速度瞬间提升。CPU的使用率基本保持在300%左右。但还不是理想状态。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、紧接着将部分实时查询数据的SQL语句，都通过缓存(redis)读写实现。观察一段时间后，基本维持在了70%~80%。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结：其实本次事故的解决很简单，就是添加索引与缓存结合使用。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;不推荐在这种CPU使用过高的情况下进行慢日志的开启。因为大量的请求，如果真是慢日志问题会发生日志磁盘写入，性能贼低。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;直接通过MySQL show processlist命令查看，基本能清晰的定位出部分查询问题严重的SQL语句，在针对该SQL语句进行分析。一般可能就是索引、锁、查询大量字段、大表等问题导致。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;再则一定要使用缓存系统，降低对MySQL的查询频次。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对于内存调优，也是一种解决方案。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;场景2展开：Java进程CPU飙升到900%，怎么处理？&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;定位过程：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CPU飙升问题定位的一般步骤是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;首先通过top指令查看当前占用CPU较高的进程PID；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;查看当前进程消耗资源的线程PID：top -Hp PID&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过print命令将线程PID转为16进制，根据该16进制值去打印的堆栈日志内查询，查看该线程所驻留的方法位置。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过jstack命令，查看栈信息，定位到线程对应的具体代码。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分析代码解决问题。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;处理过程：&lt;/span&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如果是空循环，或者空自旋。&lt;/p&gt;&lt;p&gt;处理方式：可以使用Thread.sleep或者加锁，让线程适当的阻塞。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;在循环的代码逻辑中，创建大量的新对象导致频繁GC。比如，从mysql查出了大量的数据，比如100W以上等等。&lt;/p&gt;&lt;p&gt;处理方式：可以减少对象的创建数量，或者，可以考虑使用 对象池。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;其他的一些造成CPU飙升的场景，比如  selector空轮训导致CPU飙升 。&lt;/p&gt;&lt;p&gt;处理方式：参考Netty源码，无效的事件查询到了一定的次数，进行 selector 重建。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Java的CPU 飙升700%优化的真实案例&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;陈某提示：以下案例，来自互联网。大家参考一下，准备一个自己的案例。&lt;/em&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近负责的一个项目上线，运行一段时间后发现对应的进程竟然占用了700%的CPU，导致公司的物理服务器都不堪重负，频繁宕机。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么,针对这类java进程CPU飙升的问题，我们一般要怎么去定位解决呢？、&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;采用top命令定位进程&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;登录服务器，执行top命令，查看CPU占用情况，找到进程的pid&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;top&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2898148148148148&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xlgvgPaib7WOKzrSSLzfB5yGN8uD3zCHsU2tVM8dOsJibl2SCB7OHhpMXGPKsUsR5ZZNaSxKtVBGhzSaJibD8lYicQ/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很容易发现，PID为29706的java进程的CPU飙升到700%多，且一直降不下来，很显然出现了问题。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用top -Hp命令定位线程&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 top -Hp命令（为Java进程的id号）查看该Java进程内所有线程的资源占用情况（按shft+p按照cpu占用进行排序，按shift+m按照内存占用进行排序）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此处按照cpu排序：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;top -Hp 23602&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.26481481481481484&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xlgvgPaib7WOKzrSSLzfB5yGN8uD3zCHsq1qkRyxmOLicmKvSImHqqJD49yKIGxHY7p1ANhUuILpR1kRgFbGUgvw/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很容易发现，多个线程的CPU占用达到了90%多。我们挑选线程号为30309的线程继续分析。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用jstack命令定位代码&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.线程号转换5为16进制&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;printf “%x\n” 命令（tid指线程的id号）将以上10进制的线程号转换为16进制：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;printf &quot;%x\n&quot;  30309&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.09907407407407408&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xlgvgPaib7WOKzrSSLzfB5yGN8uD3zCHs1fDmlmNLgGNEu6uX4Mq7gpXQvLCo4AsAHiaV1jGHAe2e3WXMK4qpxkQ/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;转换后的结果分别为7665，由于导出的线程快照中线程的nid是16进制的，而16进制以0x开头，所以对应的16进制的线程号nid为0x7665&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.采用jstack命令导出线程快照&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过使用dk自带命令jstack获取该java进程的线程快照并输入到文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt; jstack -l 进程ID &amp;gt; ./jstack_result.txt &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命令（为Java进程的id号）来获取线程快照结果并输入到指定文件。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;jstack -l 29706 &amp;gt; ./jstack_result.txt&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.根据线程号定位具体代码&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在jstack_result.txt 文件中根据线程好nid搜索对应的线程描述&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cat jstack_result.txt |grep -A 100  7665&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.18703703703703703&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xlgvgPaib7WOKzrSSLzfB5yGN8uD3zCHskfKlGEOf6lL1ZMF0yEiapmNg4QLMOTsAc3DqKlMkcfBibUUgKhLLOGIg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据搜索结果，判断应该是ImageConverter.run()方法中的代码出现问题&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，这里也可以直接采用&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;jstack &amp;lt;pid&amp;gt; |grep -A 200 &amp;lt;nid&amp;gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;来定位具体代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;$jstack &lt;span&gt;44529&lt;/span&gt; |grep -A &lt;span&gt;200&lt;/span&gt; ae24&lt;br/&gt;&lt;span&gt;&quot;System Clock&quot;&lt;/span&gt; #&lt;span&gt;28&lt;/span&gt; daemon prio=&lt;span&gt;5&lt;/span&gt; os_prio=&lt;span&gt;0&lt;/span&gt; tid=&lt;span&gt;0x00007efc19e8e800&lt;/span&gt; nid=&lt;span&gt;0xae24&lt;/span&gt; waiting on condition [&lt;span&gt;0x00007efbe0d91000&lt;/span&gt;]&lt;br/&gt;   java.lang.Thread.State: TIMED_WAITING (sleeping)&lt;br/&gt;    at java.lang.Thread.sleep(Native Method)&lt;br/&gt;    at java.lang.Thread.sleep(Thread.java:&lt;span&gt;340&lt;/span&gt;)&lt;br/&gt;    at java.util.concurrentC.TimeUnit.sleep(TimeUnit.java:&lt;span&gt;386&lt;/span&gt;)&lt;br/&gt;    at com.*.order.Controller.OrderController.detail(OrderController.java:&lt;span&gt;37&lt;/span&gt;)  &lt;span&gt;//业务代码阻塞点&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;分析代码解决问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面是ImageConverter.run()方法中的部分核心代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;逻辑说明：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/存储minicap的socket连接返回的数据   (改用消息队列存储读到的流数据) ，设置阻塞队列长度，防止出现内存溢出&lt;br/&gt;&lt;span&gt;//全局变量&lt;/span&gt;&lt;br/&gt;&lt;span&gt;private&lt;/span&gt; BlockingQueue&amp;lt;&lt;span&gt;byte&lt;/span&gt;[]&amp;gt; dataQueue = &lt;span&gt;new&lt;/span&gt; LinkedBlockingQueue&amp;lt;&lt;span&gt;byte&lt;/span&gt;[]&amp;gt;(&lt;span&gt;100000&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;//消费线程&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;run&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;//long start = System.currentTimeMillis();&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (isRunning) {&lt;br/&gt;        &lt;span&gt;//分析这里从LinkedBlockingQueue&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (dataQueue.isEmpty()) {&lt;br/&gt;            &lt;span&gt;continue&lt;/span&gt;;&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;byte&lt;/span&gt;[] buffer = device.getMinicap().dataQueue.poll();&lt;br/&gt;       &lt;span&gt;int&lt;/span&gt; len = buffer.length;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在while循环中，不断读取堵塞队列dataQueue中的数据，如果数据为空，则执行continue进行下一次循环。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不为空，则通过poll()方法读取数据，做相关逻辑处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;初看这段代码好像每什么问题，但是如果dataQueue对象长期为空的话，这里就会一直空循环，导致CPU飙升。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么如果解决呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分析LinkedBlockingQueue阻塞队列的API发现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;//取出队列中的头部元素，如果队列为空则调用此方法的线程被阻塞等待，直到有元素能被取出，如果等待过程被中断则抛出InterruptedException&lt;/span&gt;&lt;br/&gt;&lt;span&gt;E &lt;span&gt;take&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; InterruptedException&lt;/span&gt;;&lt;br/&gt;&lt;span&gt;//取出队列中的头部元素，如果队列为空返回null&lt;/span&gt;&lt;br/&gt;&lt;span&gt;E &lt;span&gt;poll&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这两种取值的API，显然take方法更时候这里的场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;代码修改为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;while&lt;/span&gt; (isRunning) {&lt;br/&gt;   &lt;span&gt;/* if (device.getMinicap().dataQueue.isEmpty()) {&lt;br/&gt;        continue;&lt;br/&gt;    }*/&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;byte&lt;/span&gt;[] buffer = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[&lt;span&gt;0&lt;/span&gt;];&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;        buffer = device.getMinicap().dataQueue.take();&lt;br/&gt;    } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;        e.printStackTrace();&lt;br/&gt;    }&lt;br/&gt;……&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;重启项目后，测试发现项目运行稳定，对应项目进程的CPU消耗占比不到10%。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.287962962962963&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xlgvgPaib7WOKzrSSLzfB5yGN8uD3zCHsuQUr7MK2zNausticsJ4V54NvKj4UqxgJysRZFUA12ntrh7Otoib8P3bQ/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;来源：技术自由圈&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;最后说一句（别白嫖，求关注）&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;陈某每一篇文章都是精心输出，如果这篇文章对你有所帮助，或者有所启发的话，帮忙&lt;span&gt;点赞&lt;/span&gt;、&lt;span&gt;在看&lt;/span&gt;、&lt;span&gt;转发&lt;/span&gt;、&lt;span&gt;收藏&lt;/span&gt;，你的支持就是我坚持下去的最大动力！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外陈某的&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;amp;mid=2247523057&amp;amp;idx=1&amp;amp;sn=32b42c6b0ac41b48785b7c0d24ce344a&amp;amp;chksm=fcf7453ccb80cc2a4a6cf38d5b9ab0354f09f270418bf4ff5eeb832b020aedabd561979b712d&amp;amp;token=1260267649&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;知识星球&lt;/a&gt;开通了，公众号回复关键词：&lt;span&gt;知识星球&lt;/span&gt; 获取限量&lt;span&gt;30元&lt;/span&gt;优惠券加入只需&lt;span&gt;89&lt;/span&gt;元，一顿饭钱，但是星球回馈的价值却是巨大，目前更新了&lt;span&gt;Spring全家桶实战系列&lt;/span&gt;、&lt;span&gt;亿级数据分库分表实战&lt;/span&gt;、&lt;span&gt;DDD微服务实战专栏&lt;/span&gt;、&lt;span&gt;我要进大厂、Spring，Mybatis等框架源码、架构实战22讲&lt;/span&gt;等....每增加一个专栏价格将上涨20元&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0398148148148147&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/19cc2hfD2rBvqdy8J18dlib7KepGcvuW08g7COtYpQvVoZzRtQFLgaW1GxibV1vsWMQ27S4wsOlt1ySoh3uEAeIw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关注公众号：【码猿技术专栏】，公众号内有超赞的粉丝福利，回复：加群，可以加入技术讨论群，和大家一起讨论技术，吹牛逼！&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6de3366a21616cd9b1935a8f00e0ba1a</guid>
<title>浅谈 Kafka</title>
<link>https://toutiao.io/k/rxrrgf3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;作者：京东科技 徐拥&lt;/p&gt;

&lt;h1&gt;入门&lt;/h1&gt;

&lt;h2&gt;1、什么是kafka?&lt;/h2&gt;

&lt;p&gt;apache Kafka is a distributed streaming platform. What exactly dose that mean?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-22Jtx0VcbUpPmiWcU.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Apache Kafka 是消息引擎系统，也是一个分布式流处理平台（Distributed Streaming Platform）&lt;/p&gt;

&lt;h2&gt;2、kafka全景图：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-23l6EiUjbO7wefuNY.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;3、Kafka的版本演进：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-23NQEfKZPj7Z9ZIIr.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-26ANbXnBrbO6hP10eR.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;4、kafka选型:&lt;/h2&gt;

&lt;p&gt;Apache Kafka：也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。（如果你仅仅需要一个消息引擎系统亦或是简单的流处理应用场景，同时需要对系统有较大把控度，那么我推荐你使用 Apache Kafka）&lt;/p&gt;

&lt;p&gt;Confluent Kafka ：Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。（如果你需要用到 Kafka 的一些高级特性，那么推荐你使用 Confluent Kafka。）&lt;/p&gt;

&lt;p&gt;CDH/HDP Kafka：大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。（如果你需要快速地搭建消息引擎系统，或者你需要搭建的是多框架构成的数据平台且 Kafka 只是其中一个组件，那么我推荐你使用这些大数据云公司提供的 Kafka）&lt;/p&gt;

&lt;h2&gt;5、Kafka的基本概念：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-2710okuwPbjRFpspd10.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;6、Kafka的基本结构：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-27vXrCxEsmw9ULaPY.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;7、Kafka的集群结构：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-28AObChdjhewcHqNI.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;8、kafka的应用场景(用户注册/异步)：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-28TWOlj8JVcyqqXhu.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;9、kafka队列模式---点对点：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-29CSi3YckohCdK63X.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;10、kafka队列模式---发布/订阅：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-29jHAMnKmnRDqNWif.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;11、kafka构成角色：&lt;/h2&gt;

&lt;h3&gt;1、broker：&lt;/h3&gt;

&lt;p&gt;消息格式: 主题 - 分区 - 消息 、主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份&lt;/p&gt;

&lt;p&gt;这样设计的原因是：不使用多topic做负载均衡，意义在于对业务屏蔽该逻辑。业务只需要对topic进行发送，指定负载均衡策略即可 同时 topic分区是实现负载均衡以及高吞吐量的关键&lt;/p&gt;

&lt;p&gt;Topic的创建流程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-31gSYeRvLtLrYRtRe.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;2、Producer：&lt;/h3&gt;

&lt;p&gt;发送消息流程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-35RQDxubChniY6eMg.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;3、Consumer：&lt;/h3&gt;

&lt;p&gt;Kafka消费者对象订阅主题并接收Kafka的消息，然后验证消息并保存结果。Kafka消费者是消费者组的一部分。一个消费者组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。消费者组的设计是对消费者进行的一个横向伸缩，用于解决消费者消费数据的速度跟不上生产者生产数据的速度的问题，通过增加消费者，让它们分担负载，分别处理部分分区的消息&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-35t33lQyxQsMO3hQha.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;4、Consumer Group：&lt;/h3&gt;

&lt;p&gt;它是kafka提供的具有可扩展且可容错的消费者机制&lt;/p&gt;

&lt;p&gt;特性：&lt;/p&gt;

&lt;p&gt;1、 Consumer Group下可以有一个或多个 Consumer实例；&lt;/p&gt;

&lt;p&gt;2、在一个Katka集群中，Group ID标识唯一的一个Consumer Group;&lt;/p&gt;

&lt;p&gt;3、 Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的 某个Consumer实例消费。&lt;/p&gt;

&lt;p&gt;Consumer Group 两大模型：&lt;/p&gt;

&lt;p&gt;1、如果所有实例都属于同一个Group，那么它实现的是消息队列模型；&lt;/p&gt;

&lt;p&gt;2、如果所有实例分别属于不同的GrouD，那么它实现的就是发布/订阅模型。&lt;/p&gt;

&lt;h2&gt;12、Kafka的工作流程：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-36WpTSBX3aWjhpeln.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;13、Kafka常用命令：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-38dx10vVjFaJlOaM10F.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;进阶&lt;/h1&gt;

&lt;h2&gt;14、Kafka的文件存储机制—log：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-38nCwbM52rJw52c6b38r.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;15、Kafka的文件存储机制—分片/索引：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-11-15CEalWwbhc3VYeJi.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;16、Kafka的文件存储机制—index/log：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-396xy107lRrw10w3IG6.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;17、kafka 如何支持百万QPS？&lt;/h2&gt;

&lt;h4&gt;顺序读写 :&lt;/h4&gt;

&lt;p&gt;生产者写入数据和消费者读取数据都是顺序读写的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-39kKaWvi639vyFQdK8.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;Batch Data（数据批量处理）：&lt;/h4&gt;

&lt;p&gt;当消费者（consumer）需要消费数据时，首先想到的是消费者需要一条，kafka发送一条，消费者再要一条kafka再发送一条。但实际上 Kafka 不是这样做的，Kafka 耍小聪明了。Kafka 把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候 Kafka 直接把文件发送给消费者。比如说100万条消息放在一个文件中可能是10M的数据量，如果消费者和Kafka之间网络良好，10MB大概1秒就能发送完，既100万TPS，Kafka每秒处理了10万条消息。&lt;/p&gt;

&lt;h4&gt;MMAP（内存映射文件）：&lt;/h4&gt;

&lt;p&gt;MMAP也就是内存映射文件，在64位操作系统中一般可以表示 20G 的数据文件，它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射，完成映射之后对物理内存的操作会被同步到硬盘上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-41oY6b4110scQ9qlsRo.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;通过MMAP技术进程可以像读写硬盘一样读写内存（逻辑内存），不必关心内存的大小，因为有虚拟内存兜底。这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销。也有一个很明显的缺陷，写到MMAP中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。&lt;/p&gt;

&lt;h4&gt;Zero Copy（零拷贝）：&lt;/h4&gt;

&lt;p&gt;如果不使用零拷贝技术，消费者（consumer）从Kafka消费数据，Kafka从磁盘读数据然后发送到网络上去，数据一共发生了四次传输的过程。其中两次是 DMA 的传输，另外两次，则是通过 CPU 控制的传输。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-44nWpVwp6BRWIn6R9.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一次传输&lt;/strong&gt;：从硬盘上将数据读到操作系统内核的缓冲区里，这个传输是通过 DMA 搬运的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二次传输&lt;/strong&gt;：从内核缓冲区里面的数据复制到分配的内存里面，这个传输是通过 CPU 搬运的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三次传输&lt;/strong&gt;：从分配的内存里面再写到操作系统的 Socket 的缓冲区里面去，这个传输是由 CPU 搬运的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第四次传输&lt;/strong&gt;：从 Socket 的缓冲区里面写到网卡的缓冲区里面去，这个传输是通过 DMA 搬运的。&lt;/p&gt;

&lt;p&gt;实际上在kafka中只进行了两次数据传输，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-44Q19s6oNOoiEaZr6z.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一次传输&lt;/strong&gt;：通过 DMA从硬盘直接读到操作系统内核的读缓冲区里面。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二次传输&lt;/strong&gt;：根据 Socket 的描述符信息直接从读缓冲区里面写入到网卡的缓冲区里面。&lt;/p&gt;

&lt;p&gt;我们可以看到同一份数据的传输次数从四次变成了两次，并且没有通过 CPU 来进行数据搬运，所有的数据都是通过 DMA 来进行传输的。没有在内存层面去复制（Copy）数据，这个方法称之为零拷贝（Zero-Copy）。&lt;/p&gt;

&lt;p&gt;无论传输数据量的大小，传输同样的数据使用了零拷贝能够缩短 65%的时间，大幅度提升了机器传输数据的吞吐量，这也是Kafka能够支持百万TPS的一个重要原因&lt;/p&gt;

&lt;h2&gt;18、压缩：&lt;/h2&gt;

&lt;h3&gt;特性：&lt;/h3&gt;

&lt;p&gt;节省网络传输带宽以及 Kafka Broker 端的磁盘占用。&lt;/p&gt;

&lt;h4&gt;生产者配置 ：&lt;/h4&gt;

&lt;p&gt;compression.type&lt;/p&gt;

&lt;p&gt;Properties props = new Properties();&lt;/p&gt;

&lt;p&gt;props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);&lt;/p&gt;

&lt;p&gt;props.put(&quot;acks&quot;, &quot;all&quot;);&lt;/p&gt;

&lt;p&gt;props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);&lt;/p&gt;

&lt;p&gt;props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);&lt;/p&gt;

&lt;p&gt;// 开启GZIP压缩&lt;/p&gt;

&lt;p&gt;props.put(&quot;compression.type&quot;, &quot;gzip&quot;);&lt;/p&gt;

&lt;p&gt;Producerproducer = new KafkaProducer&amp;lt;&amp;gt;(props)&lt;/p&gt;

&lt;h4&gt;broker开启压缩：&lt;/h4&gt;

&lt;p&gt;Broker 端也有一个参数叫 compression.type 默认值为none，这意味着发送的消息是未压缩的。否则，您指定支持的类​​型：gzip、snappy、lz4或zstd。 Producer 端压缩、Broker 端保持、Consumer 端解压缩。&lt;/p&gt;

&lt;h4&gt;broker何时压缩：&lt;/h4&gt;

&lt;p&gt;情况一：Broker 端指定了和 Producer 端不同的压缩算法。（风险：可能会发生预料之外的压缩 / 解压缩操作，表现为 Broker 端 CPU 使用率飙升）&lt;/p&gt;

&lt;p&gt;想象一个对话：&lt;/p&gt;

&lt;p&gt;Producer 说：“我要使用 GZIP 进行压缩。&lt;/p&gt;

&lt;p&gt;Broker 说：“不要，我这边接收的消息必须使用配置的 lz4 进行压缩&lt;/p&gt;

&lt;p&gt;情况二： Broker 端发生了消息格式转换 （风险：涉及额外压缩/解压缩，且 Kafka 丧失 Zero Copy 特性）&lt;/p&gt;

&lt;p&gt;Kafka 共有两大类消息格式，社区分别称之为 V1 版本和 V2 版本&lt;/p&gt;

&lt;p&gt;为了兼容老版本的格式，Broker 端会对新版本消息执行向老版本格式的转换。这个过程中会涉及消息的解压缩和重新压缩&lt;/p&gt;

&lt;h4&gt;消息何时解压缩：&lt;/h4&gt;

&lt;p&gt;Consumer：收到到压缩过的消息会解压缩还原成之前的消息。&lt;/p&gt;

&lt;p&gt;broker：收到producer的消息 压缩算法和自己的不一致/兼容新老版本的消息格式&lt;/p&gt;

&lt;h4&gt;压缩算法对比：&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-44mofpyPt8XdgDacc.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;以 Kafka 为例,吞吐量方面：LZ4 &amp;gt; Snappy &amp;gt; zstd 和 GZIP；压缩比方面，zstd &amp;gt; LZ4 &amp;gt; GZIP &amp;gt; Snappy；&lt;/p&gt;

&lt;p&gt;具体到物理资源，使用 Snappy 算法占用的网络带宽最多，zstd 最少，这是合理的，毕竟 zstd 就是要提供超高的压缩比；&lt;/p&gt;

&lt;p&gt;在 CPU 使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU；&lt;/p&gt;

&lt;h2&gt;19、Exactly-Once（ACK应答机制）：&lt;/h2&gt;

&lt;h4&gt;1、At Least Once&lt;/h4&gt;

&lt;p&gt;最少发送一次，Ack级别为-1，保证数据不丢失&lt;/p&gt;

&lt;h4&gt;2、At Most Once&lt;/h4&gt;

&lt;p&gt;最多发送一次，Ack级别为1，保证数据不重复&lt;/p&gt;

&lt;h4&gt;3、幂等性&lt;/h4&gt;

&lt;p&gt;保证producer发送的数据在broker只持久化一条&lt;/p&gt;

&lt;h4&gt;4、Exactly Once（0.11版本）&lt;/h4&gt;

&lt;p&gt;At Least Once + 幂等性 = Exactly Once&lt;/p&gt;

&lt;p&gt;要启用幂等性，只需要将Producer的参数中 enable.idompotence设置为 true即可。 Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。&lt;/p&gt;

&lt;h2&gt;20、producer如何获取metadata：&lt;/h2&gt;

&lt;p&gt;1：在创建KafkaProducer实例时 第一步：生产者应用会在后台创建并启动一个名为Sender的线程，&lt;/p&gt;

&lt;p&gt;2：该Sender线程开始运行时，首先会创建与Broker的连接。 第二步：此时不知道要连接哪个Broker，kafka会通过METADATA请求获取集群的元数据，连接所有的Broker。&lt;/p&gt;

&lt;p&gt;3：Producer 通过 metadata.max.age.ms定期更新元数据，在连接多个broker的情况下，producer的InFlightsRequests中维护着每个broker的等待回复消息的队列，等待数量越少说明broker处理速度越快，负载越小，就会发到哪个broker上&lt;/p&gt;

&lt;h2&gt;21、kafka真的会丢消息吗？&lt;/h2&gt;

&lt;h3&gt;kafka最优配置：&lt;/h3&gt;

&lt;h4&gt;Producer：&lt;/h4&gt;

&lt;p&gt;如果是Java客户端 建议使用 producer.send(msg, callback) ，callback（回调）它能准确地告诉你消息是否真的提交成功了。&lt;/p&gt;

&lt;p&gt;设置 acks = all。acks 是 Producer 的参数，如果设置成 all，需要所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。&lt;/p&gt;

&lt;p&gt;设置 retries 为一个较大的值。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &amp;gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。&lt;/p&gt;

&lt;h4&gt;Consumer：&lt;/h4&gt;

&lt;p&gt;消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。&lt;/p&gt;

&lt;h4&gt;broker ：&lt;/h4&gt;

&lt;p&gt;设置 unclean.leader.election.enable = false。它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。&lt;/p&gt;

&lt;p&gt;设置 replication.factor &amp;gt;= 3,目前防止消息丢失的主要机制就是冗余。&lt;/p&gt;

&lt;p&gt;设置 min.insync.replicas &amp;gt; 1,控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 确保 replication.factor &amp;gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。&lt;/p&gt;

&lt;h2&gt;22、kafka Replica：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-45j45rFFVXnQKGPe6q.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;本质就是一个只能追加写消息的提交日志。根据 Kafka 副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的 Broker 上，从而能够对抗部分 Broker 宕机带来的数据不可用&lt;/p&gt;

&lt;h4&gt;3个特性：&lt;/h4&gt;

&lt;p&gt;第一，在 Kafka 中，副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。&lt;/p&gt;

&lt;p&gt;第二，Kafka 的副本机制比其他分布式系统要更严格一些。在 Kafka 中，追随者副本是不对外提供服务的。这就是说，任何一个追随者副本都不能响应消费者和生产者的读写请求。所有的请求都必须由领导者副本来处理，或者说，所有的读写请求都必须发往领导者副本所在的 Broker，由该 Broker 负责处理。追随者副本不处理客户端请求，它唯一的任务就是从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。&lt;/p&gt;

&lt;p&gt;第三，当领导者副本挂掉了，或者说领导者副本所在的 Broker 宕机时，Kafka 依托于监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老 Leader 副本重启回来后，只能作为追随者副本加入到集群中。&lt;/p&gt;

&lt;h4&gt;意义： 方便实现“Read-your-writes”&lt;/h4&gt;

&lt;p&gt;（1）含义：当使用生产者API向Kafka成功写入消息后，马上使用消息者API去读取刚才生产的消息。 （2）如果允许追随者副本对外提供服务，由于副本同步是异步的，就可能因为数据同步时间差，从而使客户端看不到最新写入的消息。 B ：方便实现单调读（Monotonic Reads） （1）单调读：对于一个消费者用户而言，在多处消息消息时，他不会看到某条消息一会存在，一会不存在。 （2）如果允许追随者副本提供读服务，由于消息是异步的，则多个追随者副本的状态可能不一致。若客户端每次命中的副本不同，就可能出现一条消息一会看到，一会看不到&lt;/p&gt;

&lt;h2&gt;23、ISR（In-Sync Replica Set）LEO&amp;amp;HW 机制：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-466NUv9odkxoJwRBE.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;HW(High Watermark)是所有副本中最小的LEO。&lt;/p&gt;

&lt;p&gt;比如： 一个分区有3个副本，一个leader，2个follower。producer向leader写了10条消息，follower1从leader处拷贝了5条消息，follower2从leader处拷贝了3条消息，那么leader副本的LEO就是10，HW=3；follower1副本的LEO就是5&lt;/p&gt;

&lt;p&gt;HW作用：保证消费数据的一致性和副本数据的一致性 通过HW机制。leader处的HW要等所有follower LEO都越过了才会前移&lt;/p&gt;

&lt;p&gt;ISR： 所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-Sync Replicas）&lt;/p&gt;

&lt;h4&gt;1、Follower故障：&lt;/h4&gt;

&lt;p&gt;当follower挂掉之后，会被踢出ISR；&lt;/p&gt;

&lt;p&gt;当follower恢复后，会读取本地磁盘记录的HW，然后截掉HW之后的部分，从HW开始从leader继续同步数据，当该follower的LEO大于等于该partition的HW的时候，就是它追上leader的时候，会被重新加入到ISR中&lt;/p&gt;

&lt;h4&gt;2、Leader故障：&lt;/h4&gt;

&lt;p&gt;当leader故障之后，会从follower中选出新的leader，为保证多个副本之间的数据一致性，其余的follower会将各自HW之后的部分截掉（新leader如果没有那部分数据 follower就会截掉造成数据丢失），重新从leader开始同步数据，但是只能保证副本之间的数据一致性，并不能保证数据不重复或丢失。&lt;/p&gt;

&lt;h2&gt;24、Consumer分区分配策略：&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-46tJNocSIO10PCpGU6.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;自定义分区策略：&lt;/h4&gt;

&lt;p&gt;你需要显式地配置生产者端的参数partitioner.class。这个参数该怎么设定呢？方法很简单，在编写生产者程序时，你可以编写一个具体的类实现org.apache.kafka.clients.producer.Partitioner接口。这个接口也很简单，只定义了两个方法：partition()和close()，通常你只需要实现最重要的 partition 方法&lt;/p&gt;

&lt;p&gt;int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster){&lt;/p&gt;

&lt;p&gt;List&lt;partitioninfo&gt; partitions = cluster.partitionsForTopic(topic);&lt;/partitioninfo&gt;&lt;/p&gt;

&lt;p&gt;//随机&lt;/p&gt;

&lt;p&gt;//return ThreadLocalRandom.current().nextInt(partitions.size());&lt;/p&gt;

&lt;p&gt;//按消息键保序策略&lt;/p&gt;

&lt;p&gt;//return Math.abs(key.hashCode()) % partitions.size();&lt;/p&gt;

&lt;p&gt;//指定条件&lt;/p&gt;

&lt;p&gt;return partitions.stream().filter(Predicate(指定条件))).map(PartitionInfo::partition).findAny().get();&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;h2&gt;25、kafka中一个不为人知的topic：&lt;/h2&gt;

&lt;h4&gt;consumer_offsets：&lt;/h4&gt;

&lt;p&gt;老版本的Kafka会把位移信息保存在Zk中 ，但zk不适用于高频的写操作，这令zk集群性能严重下降，在新版本中将位移数据作为一条条普通的Kafka消息，提交至内部主题（_consumer_offsets）中保存，实现高持久性和高频写操作。&lt;/p&gt;

&lt;p&gt;位移主题每条消息内容格式：Group ID，主题名，分区号&lt;/p&gt;

&lt;p&gt;当Kafka集群中的第一个Consumer程序启动时，Kafka会自动创建位移主题。也可以手动创建 分区数依赖于Broker端的offsets.topic.num.partitions的取值，默认为50 副本数依赖于Broker端的offsets.topic.replication.factor的取值，默认为3&lt;/p&gt;

&lt;h4&gt;思考：&lt;/h4&gt;

&lt;p&gt;只要 Consumer 一直启动着，它就会无限期地向位移主题写入消息，就算没有新消息进来 也会通过定时任务重复写相同位移 最终撑爆磁盘？&lt;/p&gt;

&lt;p&gt;Kafka 提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据，这个后台线程叫 Log Cleaner，对相同的key只保留最新的一条消息。&lt;/p&gt;

&lt;h2&gt;26、Consumer Group Rebalance：&lt;/h2&gt;

&lt;h4&gt;术语简介：&lt;/h4&gt;

&lt;p&gt;Rebalance ：就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。&lt;/p&gt;

&lt;p&gt;Coordinator：它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。&lt;/p&gt;

&lt;p&gt;Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。&lt;/p&gt;

&lt;p&gt;如何确定Coordinator位置 ：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount) 比如（abs(627841412 % 50)=12 Coordinator就在 partitionId=12的Leader 副本所在的 Broker）。&lt;/p&gt;

&lt;h4&gt;Rebalance的危害：&lt;/h4&gt;

&lt;p&gt;Rebalance 影响 Consumer 端 TPS 这期间不会工作&lt;/p&gt;

&lt;p&gt;Rebalance 很慢 Consumer越多 Rebalance时间越长&lt;/p&gt;

&lt;p&gt;Rebalance 效率不高 需要所有成员参与&lt;/p&gt;

&lt;h4&gt;触发 Rebalance场景：&lt;/h4&gt;

&lt;p&gt;组成员数量发生变化&lt;/p&gt;

&lt;p&gt;订阅主题数量发生变化&lt;/p&gt;

&lt;p&gt;订阅主题的分区数发生变化&lt;/p&gt;

&lt;h4&gt;如何避免 Rebalance：&lt;/h4&gt;

&lt;p&gt;设置 session.timeout.ms = 15s （session连接时间 默认10）&lt;/p&gt;

&lt;p&gt;设置 heartbeat.interval.ms = 2s（心跳时间）&lt;/p&gt;

&lt;p&gt;max.poll.interval.ms （取决你一批消息处理时长 默认5分钟）&lt;/p&gt;

&lt;p&gt;要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms &amp;gt;= 3 * heartbeat.interval.ms。&lt;/p&gt;

&lt;h2&gt;27、Kafka 拦截器：&lt;/h2&gt;

&lt;p&gt;Kafka 拦截器分为生产者拦截器和消费者拦截器，可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。&lt;/p&gt;

&lt;p&gt;例：生产者Interceptor&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-06-10-47HQ1010RnGZGRYiXPx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;部分图文资料地址&lt;/p&gt;

&lt;p&gt;-- 极客时间 Kafka 核心技术与实战&lt;/p&gt;

&lt;p&gt;--google&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f9d20e6d53dabd706cd18c91aacf6609</guid>
<title>ChatGPT 真的可以让流浪地球的丫丫 “复活”</title>
<link>https://toutiao.io/k/29qnui2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;col-md-10 col-sm-12&quot;&gt;
            &lt;h1&gt; ChatGPT 真的可以让流浪地球的丫丫 “复活”&lt;/h1&gt;
            &lt;hr/&gt;
            &lt;p&gt;作者: 康凯森&lt;/p&gt;
            &lt;p&gt;日期: 2023-03-12&lt;/p&gt;
            &lt;p&gt;分类: &lt;a href=&quot;../tag/chatgpt.html&quot; target=&quot;_blank&quot;&gt;chatgpt&lt;/a&gt;&lt;/p&gt;
            &lt;hr/&gt;
            


&lt;h2 id=&quot;一-流浪地球2中的yy&quot;&gt;一 流浪地球2中的YY&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;media/16786259781472/yaya.png&quot; alt=&quot;yaya&quot;/&gt;&lt;/p&gt;
&lt;p&gt;流浪地球2中图恒宇利用超级计算机制造了数字生命丫丫，并最终拯救了整个人类，看这部影片时，还感觉数字生命可能离我们还比较遥远，可能需要很多年才能变成现实，但是最近随着对一些 ChatGPT 应用的粗浅思考，感觉数字生命已经离我们人类不是很遥远，至少初级版的丫丫现在就可以制造出原型。&lt;/p&gt;
&lt;h2 id=&quot;二-如何利用-chatgpt-和-ai-工具“复活”丫丫&quot;&gt;二 如何利用 ChatGPT 和 AI 工具“复活”丫丫&lt;/h2&gt;
&lt;h3 id=&quot;21-chatgpt-赋予丫丫思想，性格，说话风格，记忆&quot;&gt;2.1 ChatGPT 赋予丫丫思想，性格，说话风格，记忆&lt;/h3&gt;
&lt;p&gt;现在公开版的 ChatGPT 是基于大规模数据集预先训练好的模型，所以还不够个性化，但是 ChatGPT 是可以利用额外输入进行训练的，让其足够个性化。 原理可以参考：&lt;a href=&quot;https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb&quot;&gt;Question_answering_using_embeddings&lt;/a&gt;, 通俗版解释可以参考：&lt;a href=&quot;https://mp.weixin.qq.com/s/EYGnSBPmVNzY2_KTSlubZQ&quot;&gt;ChatGPT：未来，你会被淘汰吗？&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;大家只需要理解，你给 ChatGPT 一个 PDF 文件，一个网页链接，ChatGPT 就可以理解输入的内容，对输入的内容进行总结，解释你的疑问，和你进行对话。&lt;/p&gt;
&lt;p&gt;进一步，我们如果把一个人在社交媒体上所有的聊天记录，他创作过的所有文章，图片，视频输入给 ChatGPT，ChatGPT 基本就可以学习到这个人的性格，说话风格，思考问题的方式。&lt;/p&gt;
&lt;p&gt;如果这样还不够准确，我们还可以把这个人看过的书籍，电影，成长经历等也输入给 ChatGPT，也就是说，让 ChatGPT 经历一遍这个人的教育，成长过程，让 ChatGPT 更懂这个人。&lt;/p&gt;
&lt;p&gt;如果这样还不够准确呢？你还可以像教育孩子一样，在和 ChatGPT 不断交流互动的过程中，不断训练他，告诉它什么是对的，什么是错的。&lt;/p&gt;
&lt;h3 id=&quot;22-whisper-让丫丫理解语音&quot;&gt;2.2 Whisper 让丫丫理解语音&lt;/h3&gt;
&lt;p&gt;Whisper 将语音转换给文本， 输入给 ChatGPT，语音识别技术已经很成熟了，就不赘述了。&lt;/p&gt;
&lt;h3 id=&quot;23-elevenlabs-赋予丫丫语言能力&quot;&gt;2.3 ElevenLabs 赋予丫丫语言能力&lt;/h3&gt;
&lt;p&gt;ElevenLabs 可以生成语音，关键是可以定制化语音，也就是说你想要谁的语音，都可以定制，这个技术也比较成熟了，就不赘述了。&lt;/p&gt;
&lt;h3 id=&quot;24-midjourney-赋予丫丫形象&quot;&gt;2.4 Midjourney 赋予丫丫形象&lt;/h3&gt;
&lt;p&gt;Midjourney 等AI 绘画工具的绘画能力已经超过人类, 效果十分逆天, 大家可以自行体验。 &lt;/p&gt;
&lt;h2 id=&quot;三-丫丫-demo-show&quot;&gt;三 丫丫 Demo Show&lt;/h2&gt;
&lt;p&gt;目前我们只需要几百行代码，就可以构建出一个极简的 Demo 原型，接收人类的语音输入，ChatGPT 进行处理，并最终语音进行输出。我用网上的开源代码简单改了改，试了下。 这个应用的代码本身也是用 ChatGPT 写出来的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16786259781472/12-1.png&quot; alt=&quot;12-1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16786259781472/12-2.png&quot; alt=&quot;12-2&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;media/16786259781472/12-3.png&quot; alt=&quot;12-3&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;四-丫丫类应用畅想&quot;&gt;四 丫丫类应用畅想&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;寄托对逝者的思念：这也是丫丫在流浪地球电影中的本来作用&lt;/li&gt;
&lt;li&gt;私密倾诉：你可以制造一个你期望的人物和形象，然后和其进行私密聊天&lt;/li&gt;
&lt;li&gt;完美代替 Siri, 小冰，小度，小艺等语音助手&lt;/li&gt;
&lt;li&gt;在电影，电视剧，综艺节目等中引入一个有性格，有思想的虚拟人物&lt;/li&gt;
&lt;li&gt;游戏中的 NPC：玩家可以和 NPC 进行真实的互动，真正可以左右游戏的剧情&lt;/li&gt;
&lt;li&gt;成人应用和产业的全面升级&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;五-总结&quot;&gt;五 总结&lt;/h2&gt;
&lt;p&gt;目前这类个性化数字生命产品的大规模应用，我理解最大的障碍可能有两点：一个是成本，就是目前个性化训练的成本还是偏高；另一个就是数据隐私和安全，我们如何确保在网络世界里面我们的数据隐私不被泄露，甚至反过来伤害我们。&lt;/p&gt;

            &lt;hr/&gt;
            &lt;h3&gt;欢迎体验 免费 极速 无需翻墙的 ChatGPT&lt;/h3&gt;
            &lt;p&gt;&lt;a href=&quot;https://chat.bcmeng.com/&quot; target=&quot;_blank&quot;&gt;chat.bcmeng.com&lt;/a&gt;&lt;/p&gt;
            &lt;h3&gt;欢迎来知识星球和我交流&lt;/h3&gt;
            
        &lt;/div&gt;
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>111dff82948fad9553b49d2eac9008ef</guid>
<title>解析 Golang 网络 IO 模型之 EPOLL</title>
<link>https://toutiao.io/k/zoeot30</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-1g0fqss&quot; options=&quot;[object Object]&quot;&gt;&lt;h2 data-first-child=&quot;&quot;&gt;0 前言&lt;/h2&gt;&lt;p data-pid=&quot;JvTC15iY&quot;&gt;前一篇文章和大家聊了 Golang HTTP 标准库的底层实现，本篇尝试向下深挖，和大家一起聊聊 Golang 底层 IO 模型中使用到的 epoll 机制.&lt;/p&gt;&lt;p data-pid=&quot;zL3J22DA&quot;&gt;本文大抵分为两部分：第一部分聊 epoll 的实现原理（第一、二章）；第二部分串联 Golang 底层 IO 模型实现链路（第三章），观察其中对 epoll 技术的应用.&lt;/p&gt;&lt;p data-pid=&quot;EAF3yooZ&quot;&gt;本文走读的 Golang 源码版本为 1.19，全文目录树如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4aa89bc0443544bcbdeaa706086d0f37_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1705&quot; data-rawheight=&quot;6115&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-4aa89bc0443544bcbdeaa706086d0f37_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1705&quot; data-rawheight=&quot;6115&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-4aa89bc0443544bcbdeaa706086d0f37_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4aa89bc0443544bcbdeaa706086d0f37_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h2&gt;1 IO 多路复用&lt;/h2&gt;&lt;h2&gt;1.1 何为 IO 多路复用&lt;/h2&gt;&lt;p data-pid=&quot;mi0bWeBy&quot;&gt;首先拆解多路复用一词：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;u6sZfCBB&quot;&gt;多路：存在多个待服务的对象&lt;/li&gt;&lt;li data-pid=&quot;-EbV39mR&quot;&gt;复用：只由一个执行单元提供服务&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;gbZCJPkr&quot;&gt;串联上述要点，多路复用指的是，由一个执行单元，同时对多个对象提供服务，形成一对多的服务关系.&lt;/p&gt;&lt;p data-pid=&quot;JiNgqrxy&quot;&gt;打个比方：多名顾客在餐厅内用餐，考虑到经营成本，很难做到为每名顾客单独提供一名招待员作一对一服务，因此餐厅经理安排每名服务生固定负责几个餐桌，服务生在几个桌次间来回辗转提供服务，这个过程本质上就是一种多路复用.&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2aa62270af998273ec31ad446485b9b8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1623&quot; data-rawheight=&quot;1274&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-2aa62270af998273ec31ad446485b9b8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1623&quot; data-rawheight=&quot;1274&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-2aa62270af998273ec31ad446485b9b8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2aa62270af998273ec31ad446485b9b8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;9Kp0QJSu&quot;&gt;下面回到计算机领域，在 linux 操作系统中，对 IO 多路复用的概念有着更加明确的定义：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;9x0clKTm&quot;&gt;多路：存在多个需要处理 io event 的 fd（linux 中，一切皆文件，所有事务均可抽象为一个文件句柄 file descriptor，简称 fd）&lt;/li&gt;&lt;li data-pid=&quot;pp1TKGO0&quot;&gt;复用：复用一个 loop thread 同时为多个 fd 提供处理服务（线程 thread 是内核视角下的最小调度单位；多路复用通常为循环模型 loop model，因此称为 loop thread）&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;lCeGEH7G&quot;&gt;解释了概念，下面再对 IO 多路复用附加一些约定俗称的要求：&lt;/p&gt;&lt;p data-pid=&quot;cHd4UIkN&quot;&gt;IO 多路复用中，loop thread 是提供服务的乙方；待处理 io event 的 fd 们是甲方. 本着顾客是上帝的原则，乙方有义务为甲方提供更优质的服务，这里的服务质量就体现在一句话：”随叫随到，别让老板等久了”.&lt;/p&gt;&lt;p data-pid=&quot;euD6VOtX&quot;&gt;在餐厅顾客没有需求的时候，服务生趁着闲工夫摸个鱼打个盹也尚无不可. 当时一旦顾客招呼时，服务生需要第一时间赶到对需求作出响应.&lt;/p&gt;&lt;p data-pid=&quot;O5SHCLGW&quot;&gt;此外，由于服务生和顾客之间的服务关系是一对多，所以还要考虑到有多名顾客同时招呼时，服务生如何作兼容处理，让每名顾客都不至于产生被冷落的感觉. 这是一门学问，也同样是计算机领域 IO 多路复用场景下需要解决的问题.&lt;/p&gt;&lt;h2&gt;1.2 IO 多路复用的简单实现&lt;/h2&gt;&lt;h3&gt;（1）阻塞 IO&lt;/h3&gt;&lt;p data-pid=&quot;vBqJSrW7&quot;&gt;下面通过一段伪代码，来尝试让 IO 多路复用这个概念看起来更加具体一些：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// 多个待服务的 fd 
    fds = [fd1,fd2,fd3,...]
    // 遍历 fd 列表，末尾和首部相连，形成循环
    i = 0
    for {
       // 获取本轮待处理的 fd
       fd = fds[i]        
       // 从 fd 中读数据
       data = read(fd)  
       // 处理数据 
       handle(data)             
       // 推进遍历
       i++
       if i == len(fds){
         i = 0
       }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;OwSzT2XG&quot;&gt;上述搭了个架子，核心分为几步：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;MaQZ41Rl&quot;&gt;定义了待处理的 fds 列表（多路）&lt;/li&gt;&lt;li data-pid=&quot;9OgNYQ1u&quot;&gt;循环遍历 fds 列表，每轮负责读一个 fd（复用）&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;5MYLVCXa&quot;&gt;这是个乞丐版的 IO 多路复用模型看起来似乎有那么点意思了. 然而其本质上是一种阻塞 IO 模型（Blocking IO，简称 BIO）. 事实上，上述实现存在一个致命的问题，那就是句柄 fd 默认的 io 操作是阻塞型的，因此倘若在读 fd1 的时候，io event 没到达，那么 loop thread 就会陷入阻塞，后续 fd2、fd3 哪怕有 io event 到达，也无法得到执行.&lt;/p&gt;&lt;p data-pid=&quot;w-wsSSVt&quot;&gt;上述问题翻译成更形象的场景，大概就是：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;3TfU80kI&quot;&gt;A桌顾客对服务生说，你先搁这候着，我看会儿菜单，一会点菜&lt;/li&gt;&lt;li data-pid=&quot;iaKTofhq&quot;&gt;服务生于是站定A桌，打定主意在A桌点完菜之后再离开&lt;/li&gt;&lt;li data-pid=&quot;vFU4yC44&quot;&gt;在此期间，服务生辖区内的B桌、C桌招呼有事，服务生也充耳不闻，只等A桌事情完结才肯挪动步子&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;99cYQG3I&quot;&gt;这样的服务显然不够到位，倘若人人如此，餐厅必然面临倒闭.&lt;/p&gt;&lt;h3&gt;（2）非阻塞 IO&lt;/h3&gt;&lt;p data-pid=&quot;Ulahfnoi&quot;&gt;基于 BIO 存在的问题，我们进行一轮改进，核心是将 read 操作由同步阻塞操作改为带有尝试性的非阻塞操作. 在读一个 fd 的时候，倘若 io event 已就绪就正常读取，否则就即时返回并抛出一个特定类型的错误，让 loop thread 能够正常执行下去，为其他 fd 提供服务.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// 多个待服务的 fd 
    fds = [fd1,fd2,fd3,...]
    // 遍历 fd 列表，末尾和首部相连，形成循环
    i = 0
    for {
       // 获取本轮待处理的 fd
       fd = fds[i]        
       // 尝试从 fd 中读数据，失败时不阻塞，而是抛出错误
       data,err = tryRead(fd)  
       // 读取数据成功，处理数据
       if err == nil{
          handle(data) 
       } 
       // 小睡一秒后再推进流程
       sleep(1 second)
       // 推进遍历
       i++
       if i == len(fds){
         i = 0
       }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;4waH22ur&quot;&gt;上述伪代码核心步骤如下：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;545K-YrE&quot;&gt;定义了待处理的 fds 列表&lt;/li&gt;&lt;li data-pid=&quot;OBlYc_zv&quot;&gt;遍历 fds 列表，每轮尝试从一个 fd 中读数据&lt;/li&gt;&lt;li data-pid=&quot;nYjXFGCE&quot;&gt;倘若 io event 已就绪，则正常处理结果&lt;/li&gt;&lt;li data-pid=&quot;4mNV9k0l&quot;&gt;倘若 io event 未就绪，只抛出错误，同样不阻塞流程&lt;/li&gt;&lt;li data-pid=&quot;OpwSJnQb&quot;&gt;小睡一会儿，然后继续推进流程&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;dDMlDwIm&quot;&gt;这里确实解决阻塞 IO 中的问题，其本质上是一种非阻塞 IO 模型（Nonblocking IO，简称 NIO）. 但这里仍然存在问题，就是每轮处理之间的休眠时间. 倘若在休眠期间，fd 中有 io event 到达，就无法被正常处理，这同样是一种不好的体验.&lt;/p&gt;&lt;p data-pid=&quot;xiLGBJQ9&quot;&gt;这一问题翻译成餐厅的场景，指的就是服务生每次主动问询或者为一名客人提供服务后，就要大喘气休息几分钟，期间对客人不管不顾，这样的服务态度客人同样不会买账.&lt;/p&gt;&lt;p data-pid=&quot;mQI6Ukp0&quot;&gt;那大家可能会问了，倘若把此处的休眠操作去除了如何？&lt;/p&gt;&lt;p data-pid=&quot;XFfcGmgO&quot;&gt;答案是同样有问题. 倘若不限制轮询的执行频率，那么不轮 fd 中是否有 io event，程序都会一直高强度运行，这会导致 CPU 空转，造成很大程度的资源浪费.&lt;/p&gt;&lt;p data-pid=&quot;IXkYZiBh&quot;&gt;用餐厅的场景来聊，指的是餐厅招了个视听都不好的服务生，他感应不到客人的召唤，需要时时刻刻奔走在各个餐桌之间主动去询问客人们是否需要服务. 这种情况下，哪怕客人们性子好不嫌烦，服务生自己也被这种高强度的反复横跳动作给累坏了.&lt;/p&gt;&lt;p data-pid=&quot;sjpBC7dJ&quot;&gt;那大家可能又问了. 餐厅就不能招个正常的服务生吗，让他在听到客人的招呼时就去提供服务，否则就在一边老实歇着.&lt;/p&gt;&lt;p data-pid=&quot;SbMNd89U&quot;&gt;没错，这就是正解，设计程序的码农们也是这么想的. 然而实际情况很悲催，在用户态视角下的程序正是哪一个耳目昏聩的服务生，对于 io event 的到达并没有能力做到准确地把握.&lt;/p&gt;&lt;p data-pid=&quot;a-uJmyLZ&quot;&gt;于是，这就需要引入操作系统内核的帮助，通过几个内核对外暴露的接口，来进行 IO 多路复用的优雅实现，做到真正意义上的“随叫随到”.&lt;/p&gt;&lt;h2&gt;1.3 IO 多路复用的优雅实现&lt;/h2&gt;&lt;p data-pid=&quot;rjKh9q3D&quot;&gt;linux 内核提供了三种经典的多路复用技术：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9cdc3e0d1e5f30ae71bc154ecda17504_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1168&quot; data-rawheight=&quot;254&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-9cdc3e0d1e5f30ae71bc154ecda17504_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1168&quot; data-rawheight=&quot;254&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-9cdc3e0d1e5f30ae71bc154ecda17504_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9cdc3e0d1e5f30ae71bc154ecda17504_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;kLGT0bIU&quot;&gt;从上图中可以看到，各个技术之间通过单向箭头连接，因此是一个持续演化改进的过程，select 最通用，但是相对粗糙；而 epoll 则最精致，在性能上也有着最优越的表现.&lt;/p&gt;&lt;p data-pid=&quot;2T5oItr4&quot;&gt;poll 在 select 的基础之上做了改进，但治标不治本，优化得不够彻底. 我们核心还是来对比看看 select 和 epoll 之间的共性和差异：&lt;/p&gt;&lt;h3&gt;（1）select&lt;/h3&gt;&lt;ul&gt;&lt;li data-pid=&quot;-7_fKP4y&quot;&gt;一次可以处理多个 fd，体现多路. 但 fd 数量有限，最多 1024 个&lt;/li&gt;&lt;li data-pid=&quot;OHGmG1E5&quot;&gt;loop thread 通过 select 将一组 fd 提交到内核做监听&lt;/li&gt;&lt;li data-pid=&quot;2lruK3eo&quot;&gt;当 fd 中无 io event 就绪时，loop thread 会陷入阻塞&lt;/li&gt;&lt;li data-pid=&quot;FEDZnECF&quot;&gt;每当这组 fd 中有 io event 到达时，内核会唤醒 loop thread&lt;/li&gt;&lt;li data-pid=&quot;tI5k6MbO&quot;&gt;loop thread 无法精准感知到哪些 fd 就绪，需要遍历一轮 fd 列表，时间复杂度 O(N)&lt;/li&gt;&lt;li data-pid=&quot;_BJFWNlh&quot;&gt;托付给内核的 fd 列表只具有一轮交互的时效. 新的轮次中，loop thread 需要重新将监听的 fd 列表再传递给内核一次&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;（2）epoll&lt;/h3&gt;&lt;ul&gt;&lt;li data-pid=&quot;QYtccQ28&quot;&gt;每次处理的 fd 数量无上限&lt;/li&gt;&lt;li data-pid=&quot;Z8J_zOV0&quot;&gt;loop thread 通过 epoll_create 操作创建一个 epoll 池子&lt;/li&gt;&lt;li data-pid=&quot;Vn3-wx7Q&quot;&gt;loop thread 通过 epoll_ctl 每次将一个待监听的 fd 添加到 epoll 池中&lt;/li&gt;&lt;li data-pid=&quot;JTERQSUL&quot;&gt;每当 fd 列表中有 fd 就绪事件到达时，会唤醒 loop threa. 同时内核会将处于就绪态的 fd 直接告知 loop thread，无需额外遍历&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;3i-JoSCY&quot;&gt;综上所述，select 和 epoll 等多路复用操作利用了内核的能力，能在待监听 fd 中有 io event 到达时，将 loop thread 唤醒，避免无意义的主动轮询操作.&lt;/p&gt;&lt;p data-pid=&quot;s2GNldsr&quot;&gt;其中，epoll 相比于 select 的核心性能优势在于：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;ayVZAbhL&quot;&gt;loop thread 被唤醒时，能明确知道哪些 fd 需要处理，减少了一次额外遍历的操作，时间复杂度由 O(N) 优化到 O(1)&lt;/li&gt;&lt;li data-pid=&quot;d2mhN2ys&quot;&gt;epoll 通过将创建池子和添加 fd两个操作解耦，实现了池中 fd 数据的复用，减少了用户态与内核态间的数据拷贝成本&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;2 EventPoll 原理&lt;/h2&gt;&lt;h2&gt;2.1 核心指令&lt;/h2&gt;&lt;p data-pid=&quot;VoTtpnW0&quot;&gt;epoll 又称 EventPoll，使用很简单，包含三个指令“&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;m5ftYbDl&quot;&gt;epoll_create&lt;/li&gt;&lt;li data-pid=&quot;pnJMgD5T&quot;&gt;epoll_ctl&lt;/li&gt;&lt;li data-pid=&quot;HlZGMdRs&quot;&gt;epoll_wait&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;XNdtFv0i&quot;&gt;下面我们逐一展开聊聊：&lt;/p&gt;&lt;h3&gt;（1）epoll_create&lt;/h3&gt;&lt;p data-pid=&quot;OUYDc8G2&quot;&gt;在内核开辟空间，创建一个 epoll 池子用于批量存储管理 fd，后续可以通过 epoll_ctl 往池子中增删改 fd.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func epollcreate1(flags int32) int32&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（2）epoll_ctl&lt;/h3&gt;&lt;p data-pid=&quot;o1CPpXxO&quot;&gt;在某个 epoll 池子中进行一个 fd 的增删改操作.&lt;/p&gt;&lt;p data-pid=&quot;OAfAecrM&quot;&gt;正是由于 epoll 中将 epoll_ctl 与 epoll_create 操作进行了解耦，才实现了对 epoll_create 时传递的 fd 数据的复用，减少了用户态和内核台之间对 fd 数据的重复传递&lt;/p&gt;&lt;p data-pid=&quot;YRvBupTj&quot;&gt;此外，在 epoll_ctl 实现时，也需要通过 epollevent 设置好回调事件，当 fd 有指定事件到达时，会被添加到就绪队列中，最终将 loop thread 唤醒.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func epollctl(epfd, op, fd int32, ev *epollevent) int32


type epollevent struct {
    events uint32
    data   [8]byte // unaligned uintptr
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（3）epoll_wait&lt;/h3&gt;&lt;p data-pid=&quot;jdgrgC2K&quot;&gt;从对应 epoll 池子中获取就绪的 epollevent，从中可以关联到对应的 fd 和 loop thread 信息.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func epollwait(epfd int32, ev *epollevent, nev, timeout int32) int32&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;2.2 核心数据结构&lt;/h2&gt;&lt;h3&gt;（1）epoll 池红黑树&lt;/h3&gt;&lt;p data-pid=&quot;I43Qiwqp&quot;&gt;一个 epoll 池子中管理的 fd 数量理论上上不封顶. 同时后续可能存在对 fd 的增删改操作，因此需要使用合适的数据结构加以管理，从而降低后续操作的时间复杂度.&lt;/p&gt;&lt;p data-pid=&quot;q-TUu24N&quot;&gt;linux 内核中，实现 epoll 池的数据结构采用的是红黑树（Red-Black Tree，一种自平衡二叉查找树，这里不作展开，感兴趣自行了解）实现，保证了所有增、删、改操作的平均时间复杂度维持在 O(logN) 的对数级水平.&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ec0e8a3a83196a07c9b550a745c1984b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1087&quot; data-rawheight=&quot;895&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-ec0e8a3a83196a07c9b550a745c1984b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1087&quot; data-rawheight=&quot;895&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-ec0e8a3a83196a07c9b550a745c1984b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ec0e8a3a83196a07c9b550a745c1984b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h3&gt;（2）就绪事件队列&lt;/h3&gt;&lt;p data-pid=&quot;EkGdAlTh&quot;&gt;针对于 fd 的就绪 io event，由于通常数量有限，且每个事件都需要逐一处理，没有优先级之分，因此采用简单的双向链表实现即可.&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4398e12ae764308c5300c33b240f427f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2063&quot; data-rawheight=&quot;978&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-4398e12ae764308c5300c33b240f427f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2063&quot; data-rawheight=&quot;978&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-4398e12ae764308c5300c33b240f427f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4398e12ae764308c5300c33b240f427f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h2&gt;2.3 事件回调机制&lt;/h2&gt;&lt;p data-pid=&quot;mtP32qve&quot;&gt;epoll 高效的核心建立在精准的事件回调机制之上.&lt;/p&gt;&lt;p data-pid=&quot;oBz1vWXN&quot;&gt;首先，通过内核感知到 io event 事件的动态，令 loop thread 在合适的时机阻塞，避免浪费 CPU；在合适的时机执行，及时处理 io event.&lt;/p&gt;&lt;p data-pid=&quot;eLCDGuSS&quot;&gt;其次，在 io event 就绪时，会精准地将真正就绪的 fd 传递到 loop thread 手中，减少了一次无意义的遍历查询动作.&lt;/p&gt;&lt;p data-pid=&quot;f9P4EFWV&quot;&gt;事件回调的注册是在调用 epoll_ctl 添加 fd 时，此时会提前设置好对这个 fd 关心的事件类型，当对应的 io event 真的发生时，内核会将该 fd 和对应的 loop thread 封装到 epollevent 中，添加到就绪队列 ready list 当中.&lt;/p&gt;&lt;p data-pid=&quot;f7G6aGMA&quot;&gt;之后当用户调用 epoll_wait 时，能够准确地获取到这部分就绪的 epollevent，进而能够将对应的 loop thread 唤醒.&lt;/p&gt;&lt;h2&gt;3 Golang 网络 IO 源码走读&lt;/h2&gt;&lt;p data-pid=&quot;aNKJ4kpV&quot;&gt;聊完了理论，下面看看 epoll 技术在 Golang 中的应用.&lt;/p&gt;&lt;h2&gt;3.1 启动 TCP 服务器&lt;/h2&gt;&lt;p data-pid=&quot;HVhbQKCk&quot;&gt;首先给出一个启动 tcp 服务的代码框架，伪代码如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// 启动一个 tcp 服务端代码示例
func main(){
   // 创建一个 tcp 端口监听器
   l,_ := net.Listen(&quot;tcp&quot;,&quot;:8080&quot;)
   // 主动轮询模型
   for{
       // 等待 tcp 连接到达
       conn,_ := l.Accept()     
       // 开启一个 goroutine 负责一笔客户端请求的处理
       go serve(conn)
   }
}


// 处理一笔 tcp 连接
func serve(conn net.Conn){
    defer conn.Close()
    var buf []byte
    // 读取连接中的数据
    _,_ = conn.Read(buf)    
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;FG6pql2a&quot;&gt;方法核心步骤都展示于 main 函数中了：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;SVR1q4y2&quot;&gt;创建了一个 tcp 端口监听器 listener&lt;/li&gt;&lt;li data-pid=&quot;Do_4y99o&quot;&gt;通过 for 循环建立主动轮询模型&lt;/li&gt;&lt;li data-pid=&quot;2vQabxHy&quot;&gt;每轮尝试从 listener 中获取到达的 tcp 连接&lt;/li&gt;&lt;li data-pid=&quot;hnWYK-kw&quot;&gt;倘若成功取到连接，则 1:1启动一个 goroutine 异步处理连接的请求&lt;/li&gt;&lt;li data-pid=&quot;lLB_y-gI&quot;&gt;倘若无连接到达，则阻塞主流程&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;bLYzRYtv&quot;&gt;其中，有两个方法是核心入口：一个是创建 Listener 的 net.Listen；另一个是从 Listener 获取连接的 Listener.Accept 方法.&lt;/p&gt;&lt;h2&gt;3.2 创建 TCP 端口监听器&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5ef2ecf6e4da4ac3c0d47ab6505b4ecd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2195&quot; data-rawheight=&quot;2315&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-5ef2ecf6e4da4ac3c0d47ab6505b4ecd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2195&quot; data-rawheight=&quot;2315&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-5ef2ecf6e4da4ac3c0d47ab6505b4ecd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5ef2ecf6e4da4ac3c0d47ab6505b4ecd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;h3&gt;（1）创建 Listener 前处理&lt;/h3&gt;&lt;p data-pid=&quot;nXleMJDJ&quot;&gt;在创建 TCP 端口 Listener 时，首先历经 Listen -&amp;gt; ListenerConfig.Listen -&amp;gt; sysListener.listenTCP -&amp;gt; internetSocket -&amp;gt; socket 方法的辗转，最终来到位于 runtime/sock_posix.go 的 socket 方法中，开始执行套接字 socket 的创建和初始化.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func Listen(network, address string) (Listener, error) {
    var lc ListenConfig
    return lc.Listen(context.Background(), network, address)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (lc *ListenConfig) Listen(ctx context.Context, network, address string) (Listener, error) {
    // ...
    var l Listener
    la := addrs.first(isIPv4)
    switch la := la.(type) {
    case *TCPAddr:
        l, err = sl.listenTCP(ctx, la)
    // ...
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (sl *sysListener) listenTCP(ctx context.Context, laddr *TCPAddr) (*TCPListener, error) {
    fd, err := internetSocket(ctx, sl.network, laddr, nil, syscall.SOCK_STREAM, 0, &quot;listen&quot;, sl.ListenConfig.Control)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func internetSocket(ctx context.Context, net string, laddr, raddr sockaddr, sotype, proto int, mode string, ctrlFn func(string, string, syscall.RawConn) error) (fd *netFD, err error) {
    // ...
    return socket(ctx, net, family, sotype, proto, ipv6only, laddr, raddr, ctrlFn)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（2）创建 socket&lt;/h3&gt;&lt;p data-pid=&quot;dPV-XqhY&quot;&gt;在 socket 方法中首先，在 sysSocket 方法中，发起两次系统调用：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;IiYr_IMx&quot;&gt;syscall.Socket 创建套接字&lt;/li&gt;&lt;li data-pid=&quot;6daIA222&quot;&gt;syscall.SetNonblock 将 socket 设置为非阻塞模式&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;uDhhIGhF&quot;&gt;然后步入 netFD.listenStream 方法，将 socket fd 和端口进行绑定和监听，然后调用 epoll 指令设定 io 多路复用模式.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func socket(ctx context.Context, net string, family, sotype, proto int, ipv6only bool, laddr, raddr sockaddr, ctrlFn func(string, string, syscall.RawConn) error) (fd *netFD, err error) {
    // 创建一个 socket 套接字
    s, err := sysSocket(family, sotype, proto)   
    // ...
    // 绑定、监听端口，并对 socket fd 进行初始化. epoll_create 和 epoll_ctl 执行的执行正是在初始化的流程中.
    fd.listenStream(laddr, listenerBacklog(), ctrlFn)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// socketFunc 宏指令，关联执行系统调用 syscall.Socket 创建套接字
var socketFunc        func(int, int, int) (int, error)  = syscall.Socket


func sysSocket(family, sotype, proto int) (int, error) {
    // 通过系统调用创建一个 socket
    s, err = socketFunc(family, sotype, proto)
    // 通过系统调用将 socket 设置为非阻塞模式
    syscall.SetNonblock(s, true)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（3）绑定、监听端口&lt;/h3&gt;&lt;p data-pid=&quot;T3rSmUSn&quot;&gt;在 netFD.listenStream 方法中&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;GLYG21r8&quot;&gt;发起系统调用 syscall.Bind 实现 socket fd 和端口的绑定&lt;/li&gt;&lt;li data-pid=&quot;XdnnwwFF&quot;&gt;发起系统调用，实现对 fd 的监听&lt;/li&gt;&lt;li data-pid=&quot;ZUm4dvma&quot;&gt;调用 netFD.init 方法对 socket fd 进行初始化&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// listenFunc 宏指令，关联执行系统调用 syscall.Listen 监听端口
var listenFunc        func(int, int) error              = syscall.Listen


func (fd *netFD) listenStream(laddr sockaddr, backlog int, ctrlFn func(string, string, syscall.RawConn) error) error {
    // ...
    // 调用 bind 系统调用，将 socket fd 和端口进行绑定
    syscall.Bind(fd.pfd.Sysfd, lsa)
    // 通过宏指令调用 listen 系统调
    listenFunc(fd.pfd.Sysfd, backlog)
    // 初始化 socket fd，在其中执行了 epoll 操作
    fd.init()
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *netFD) init() error {
    return fd.pfd.Init(fd.net, true)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *FD) Init(net string, pollable bool) error {
    // ...
    fd.pd.init(fd)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（4）创建 epoll 池&lt;/h3&gt;&lt;p data-pid=&quot;TaOctLXt&quot;&gt;从 netFD.init 方法出发，历经 netFD.init -&amp;gt; FD.Init -&amp;gt; pollDesc.init 的链路，最终在 pollDesc.init 方法中，通过 sync.Once 保证全局只执行一次 runtime_pollServerInit 方法作 epoll 池的初始化.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var serverInit sync.Once


func (pd *pollDesc) init(fd *FD) error {
    serverInit.Do(runtime_pollServerInit)
    ctx, errno := runtime_pollOpen(uintptr(fd.Sysfd))
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;f92iaIRN&quot;&gt;runtime_pollServerInit 方法最终会编译关联到位于 runtime/netpoll_epoll.go 文件的 netpollinit 方法，可以看到在方法中，通过调用 epollcreate1 方法，执行了 epoll 指令完成了 epoll 池的创建.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpollinit() {
    // 执行 epoll_create 执行，开辟一块 epoll 池
    epfd = epollcreate1(_EPOLL_CLOEXEC)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（5）socket fd 入池&lt;/h3&gt;&lt;p data-pid=&quot;0PcmGuEc&quot;&gt;在 pollDesc.init 方法确保全局完成一次 epoll 池的创建后，会调用 runtime_pollOpen 方法将当前 fd 添加到 epoll 池中.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var serverInit sync.Once


func (pd *pollDesc) init(fd *FD) error {
    serverInit.Do(runtime_pollServerInit)
    ctx, errno := runtime_pollOpen(uintptr(fd.Sysfd))
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;F84aUedW&quot;&gt;runtime_pollOpen 方法最终会编译关联到位于 runtime/netpoll_epoll.go 文件的 netpollopen 方法，其中会调用 epollctl 指令，完成 socket fd 的入池操作.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpollopen(fd uintptr, pd *pollDesc) int32 {
    // 将待监听的 socket fd 添加到 epoll 池中，并注册好回调路径
    var ev epollevent
    ev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET
    *(**pollDesc)(unsafe.Pointer(&amp;amp;ev.data)) = pd    
    return -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), &amp;amp;ev)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;3.3 获取 TCP 连接&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bef94875f2c66183f634f57fa8e61b2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;921&quot; data-rawheight=&quot;2677&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-bef94875f2c66183f634f57fa8e61b2f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;921&quot; data-rawheight=&quot;2677&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-bef94875f2c66183f634f57fa8e61b2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bef94875f2c66183f634f57fa8e61b2f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;YEo9viZ8&quot;&gt;下面聊聊通过 Listener 获取 tcp 连接的方法链路.&lt;/p&gt;&lt;h3&gt;（1）获取 tcp 连接前处理&lt;/h3&gt;&lt;p data-pid=&quot;AoUGzYzb&quot;&gt;在创建好 Listener 后，接下来调用 Listener.Accept 方法，可以实现有 tcp 连接就绪时会取得连接；无 tcp 连接时令当前 goroutine 陷入阻塞的效果.&lt;/p&gt;&lt;p data-pid=&quot;eTbiERWI&quot;&gt;历经 TCPListener.Accept -&amp;gt; TCPListener.accept -&amp;gt; netFD.accept -&amp;gt; FD.Accept 的辗转，最终获取 tcp 连接及阻塞处理的核心逻辑实现于 internal/poll/fd_unix.go 的 FD.Accept 方法.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (l *TCPListener) Accept() (Conn, error) {
    // ...
    c, err := l.accept()
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (ln *TCPListener) accept() (*TCPConn, error) {
    fd, err := ln.fd.accept()
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *netFD) accept() (netfd *netFD, err error) {
    // 倘若有 tcp 连接到达，则成功取出并返回
    // 倘若没有 tcp 连接到达，会 gopark 进入被动阻塞，等待被唤醒
    d, rsa, errcall, err := fd.pfd.Accept()
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（2）尝试获取 tcp 连接&lt;/h3&gt;&lt;p data-pid=&quot;Y80G07fI&quot;&gt;在 FD.Accept 方法中：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;TTF6Luuu&quot;&gt;首先调用 accept 方法，会通过系统调用 syscall.Accept 以非阻塞模式尝试获取一次对应 socket fd 下到达的 tcp 连接&lt;/li&gt;&lt;li data-pid=&quot;7saO7tD-&quot;&gt;倘若没有就绪的 tcp 连接，会抛出 syscall.EAGAIN 错误，此时会走入 pollDesc.waitRead 分支，最终通过 gopark 操作令当前 goroutine 陷入被动阻塞状态&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *FD) Accept() (int, syscall.Sockaddr, string, error) {
    // ...
    for {
        // 通过 accept 系统调用，尝试接收一个连接
        s, rsa, errcall, err := accept(fd.Sysfd)
        // ...
        switch err {    
        case syscall.EAGAIN:
            if fd.pd.pollable() {
                if err = fd.pd.waitRead(fd.isFile); err == nil {
                    continue
                }
            }
        // ...
        }
        // ...
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var AcceptFunc func(int) (int, syscall.Sockaddr, error) = syscall.Accept


func accept(s int) (int, syscall.Sockaddr, string, error) {
    // ...
    ns, sa, err = AcceptFunc(s)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) waitRead(isFile bool) error {
    return pd.wait(&#x27;r&#x27;, isFile)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) wait(mode int, isFile bool) error {
    // ...
    res := runtime_pollWait(pd.runtimeCtx, mode)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（3）被动阻塞 goroutine&lt;/h3&gt;&lt;p data-pid=&quot;UIrv7xUo&quot;&gt;历经 pollDesc.waitRead -&amp;gt; pollDesc.wait -&amp;gt; poll_runtime_pollWait 的链路，最终会在 netpollblock 方法中，通过 gopark 操作，令求 tcp 连接而不得的 loop goroutine 陷入被动阻塞状态.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func poll_runtime_pollWait(pd *pollDesc, mode int) int {
    // ...
    for !netpollblock(pd, int32(mode), false) {
        // ...
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpollblock(pd *pollDesc, mode int32, waitio bool) bool {
    // ...
    if waitio || netpollcheckerr(pd, mode) == pollNoError {
        // 调用 gopark 被动阻塞挂起
        gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5)
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;3.4 TCP 连接读数据&lt;/h2&gt;&lt;p data-pid=&quot;1qknZLdM&quot;&gt;最后聊聊当 loop goroutine 获取到 tcp 连接时的代码分支.&lt;/p&gt;&lt;h3&gt;（1）conn fd 入池&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2571a096cc3058fff94f1477486a9746_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;2608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-2571a096cc3058fff94f1477486a9746_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;2608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-2571a096cc3058fff94f1477486a9746_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2571a096cc3058fff94f1477486a9746_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;s1wCJQv4&quot;&gt;在位于 internal/poll/sock_cloexec.go 的 netFD.accept 方法中，倘若通过系统调用 syscall.Accept 成功获取到了到达的 tcp 连接，则会将其封装为一个 netFD，并通过 epoll_ctl 指令将该 fd 添加到 epoll 池中，实现对 read 事件的监听.&lt;/p&gt;&lt;p data-pid=&quot;v_Gvwogl&quot;&gt;方法链路与 3.2 小节的第（5）部分类似，不再赘述.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *netFD) accept() (netfd *netFD, err error) {
    // 调用 accept 系统调用，接收 tcp 连接
    d, rsa, errcall, err := fd.pfd.Accept()
    // 将 connet fd 封装成 netfd
    netfd, err = newFD(d, fd.family, fd.sotype, fd.net)
    // 对 netfd 进行初始化，底层会调用 epoll_ctl 将其注册到 listener 对应的 epoll 池中 
    netfd.init()
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *netFD) init() error {
    return fd.pfd.Init(fd.net, true)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *FD) Init(net string, pollable bool) error {
   // ...
    err := fd.pd.init(fd)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) init(fd *FD) error {
    serverInit.Do(runtime_pollServerInit)
    ctx, errno := runtime_pollOpen(uintptr(fd.Sysfd))
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（2）读 tcp 连接数据&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;2566&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;2566&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;-6dCdgBw&quot;&gt;获取到 tcp 连接后，在缓存区数据未就绪时，用户执行 read 操作同样会陷入阻塞，对应的方法链路如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (c *conn) Read(b []byte) (int, error) {
    // ...
    n, err := c.fd.Read(b)
    // ...
    return n, err
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *netFD) Read(p []byte) (n int, err error) {
    n, err = fd.pfd.Read(p)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;VeI_A3zm&quot;&gt;在位于 internal/poll/fd_unix.go 的 FD.Read 方法中，会执行 syscall.Read 尝试从 conn fd 中读取数据，倘若数据未就绪，则会抛出 EAGAIN error，此时会调用 pollDesc.waitRead 方法将当前的 loop read goroutine 挂起，链路同 3.3 小节第（2）部分，不再赘述.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *FD) Read(p []byte) (int, error) {
    // ...
    for {
        n, err := ignoringEINTRIO(syscall.Read, fd.Sysfd, p)
        
        if err == syscall.EAGAIN &amp;amp;&amp;amp; fd.pd.pollable() {
            fd.pd.waitRead(fd.isFile)
            // ...
        }
        // ...
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) waitRead(isFile bool) error {
    return pd.wait(&#x27;r&#x27;, isFile)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) wait(mode int, isFile bool) error {
    // ...
    res := runtime_pollWait(pd.runtimeCtx, mode)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func poll_runtime_pollWait(pd *pollDesc, mode int) int {
    // ...
    for !netpollblock(pd, int32(mode), false) {
        // ...
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpollblock(pd *pollDesc, mode int32, waitio bool) bool {
    // ...
    if waitio || netpollcheckerr(pd, mode) == pollNoError {
        // 调用 gopark 被动阻塞挂起
        gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5)
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;3.5 TCP 连接写入数据&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;2566&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;2566&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1da5866dcf2291939267a22db20b8ab6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;yCs1qX6l&quot;&gt;向 tcp 连接中写入数据的流程基本和 3.4 小节第（2）部分从 tcp 连接读取数据的链路形成对仗.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (c *conn) Write(b []byte) (int, error) {
    // ...
    n, err := c.fd.Write(b)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *netFD) Write(p []byte) (nn int, err error) {
    nn, err = fd.pfd.Write(p)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;4Hv8NqhG&quot;&gt;在位于 internal/poll/fd_unix.go 的 FD.Write 方法，会执行系统调用 syscall.Write，尝试将数据写入 tcp 连接的缓冲区. 倘若当前缓冲区已经没有剩余的空间，则会抛出 EAGAIN 错误，然后执行 pollDesc.waitWrite，最终执行 gopark 操作将当前 loop write goroutine 挂起.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (fd *FD) Write(p []byte) (int, error) {
    // ...
    var nn int
    for {
        max := len(p)
        // ...
        n, err := ignoringEINTRIO(syscall.Write, fd.Sysfd, p[nn:max])
        // ...
        if err == syscall.EAGAIN &amp;amp;&amp;amp; fd.pd.pollable() {
            fd.pd.waitWrite(fd.isFile);
        }
        // ...
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) waitWrite(isFile bool) error {
    return pd.wait(&#x27;w&#x27;, isFile)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (pd *pollDesc) wait(mode int, isFile bool) error {
    // ...
    res := runtime_pollWait(pd.runtimeCtx, mode)
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpollblock(pd *pollDesc, mode int32, waitio bool) bool {
    // ...
    if waitio || netpollcheckerr(pd, mode) == pollNoError {
        // 调用 gopark 被动阻塞挂起
        gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5)
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;3.6 唤醒 IO 阻塞协程&lt;/h2&gt;&lt;p data-pid=&quot;5he18JcL&quot;&gt;3.3-3.5 小节中我们聊到，当 io event 未就绪时，会在位于 runtime/netpoll.go 的 poll_runtime_pollWait 方法中执行 gopark 操作，令当前的 loop goroutine 陷入被动阻塞状态.&lt;/p&gt;&lt;p data-pid=&quot;6HQ1_6ds&quot;&gt;本小节我们就来看看，这些 goroutine 将会在什么时机得到唤醒的机会.&lt;/p&gt;&lt;h3&gt;（1）全局监控任务 sysmon&lt;/h3&gt;&lt;p data-pid=&quot;pjuHG255&quot;&gt;在位于 runtime/proc.go 的 main 函数中，会单独启动一个 m（GMP中对线程的抽象 M），用于执行 sysmon 监控任务.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func main() {
    // ...
    systemstack(func() {
        newm(sysmon, nil, -1)
    })  
    // ... 
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;MF75uFKr&quot;&gt;在 sysmon 函数中，会每隔 10ms 调用 netpoll 函数，尝试取出 io event 已到达的 loop goroutine，进行唤醒操作.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func sysmon() {
    // ...
    for {        
        // 每 10 ms 周期性执行一次
        lastpoll := int64(atomic.Load64(&amp;amp;sched.lastpoll))
        if netpollinited() &amp;amp;&amp;amp; lastpoll != 0 &amp;amp;&amp;amp; lastpoll+10*1000*1000 &amp;lt; now {
            atomic.Cas64(&amp;amp;sched.lastpoll, uint64(lastpoll), uint64(now))
            // 取出就绪的 loop goroutine
            list := netpoll(0) 
            // ...
            // 唤醒 list 中的 goruotine
            injectglist(&amp;amp;list)
        }
        // ...
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;Ke924AIn&quot;&gt;netpoll 方法位于 runtime/net_epoll.go 文件，方法中会基于非阻塞模式调用 epollwait 方法，获取到就绪事件队列 events，然后遍历事件队列，调用 netpollready 方法将对应的 loop goroutine 添加到 gList 中返回给上层用于执行唤醒操作.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpoll(delay int64) gList {
    // ...
    var events [128]epollevent
retry:
    // 非阻塞调用 epoll_wait，接收到就绪的事件列表
    n := epollwait(epfd, &amp;amp;events[0], int32(len(events)), waitms)
    // ...
    var toRun gList
    for i := int32(0); i &amp;lt; n; i++ {
        ev := &amp;amp;events[i]
        // 添加关心的事件模式
        var mode int32
        if ev.events&amp;amp;(_EPOLLIN|_EPOLLRDHUP|_EPOLLHUP|_EPOLLERR) != 0 {
            mode += &#x27;r&#x27;
        }
        if ev.events&amp;amp;(_EPOLLOUT|_EPOLLHUP|_EPOLLERR) != 0 {
            mode += &#x27;w&#x27;
        }
        // 从 event 中获取已就绪的 fd，调用 netpollready 方法将 fd 添加到 gList 中用于返回，在上层进行唤醒和执行
        if mode != 0 {
            pd := *(**pollDesc)(unsafe.Pointer(&amp;amp;ev.data))
            pd.setEventErr(ev.events == _EPOLLERR)
            netpollready(&amp;amp;toRun, pd, mode)
        }
    }
    return toRun
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func netpollready(toRun *gList, pd *pollDesc, mode int32) {
    var rg, wg *g
    if mode == &#x27;r&#x27; || mode == &#x27;r&#x27;+&#x27;w&#x27; {
        rg = netpollunblock(pd, &#x27;r&#x27;, true)
    }
    if mode == &#x27;w&#x27; || mode == &#x27;r&#x27;+&#x27;w&#x27; {
        wg = netpollunblock(pd, &#x27;w&#x27;, true)
    }
    // 将 read、write 的就绪 fd 对应的 goroutine 中，添加到 toRun 链表中
    if rg != nil {
        toRun.push(rg)
    }
    if wg != nil {
        toRun.push(wg)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（2）GMP 调度主流程&lt;/h3&gt;&lt;p data-pid=&quot;-p80cdHZ&quot;&gt;在 GMP 主流程方法 schedule 中，在每轮调度中，g0 都会调用 findrunnable 为当前 P 寻找下一个可执行的 goroutine. 此时当 P 本地队列和全局队列都没有待执行的 goroutine 时，则会尝试获取就绪的 loop goroutine 用于执行.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func findrunnable() (gp *g, inheritTime bool) {
    // ...
    if netpollinited() &amp;amp;&amp;amp; atomic.Load(&amp;amp;netpollWaiters) &amp;gt; 0 &amp;amp;&amp;amp; atomic.Load64(&amp;amp;sched.lastpoll) != 0 {
        if list := netpoll(0); !list.empty() { // non-blocking
            gp := list.pop()
            injectglist(&amp;amp;list)
            casgstatus(gp, _Gwaiting, _Grunnable)
            //... 
            return gp, false
        }
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;（3）GC start the world&lt;/h3&gt;&lt;p data-pid=&quot;faSY31G-&quot;&gt;在 GC 过程中，每次调用完 stop the world 之后，都会对仗调用 start the world 重启世界，此时也会对就绪的 loop goroutine 执行唤醒操作.&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func startTheWorldWithSema(emitTraceEvent bool) int64 {
   // ...
    if netpollinited() {
        list := netpoll(0) // non-blocking
        // 唤醒 list 中的 goruotine
        injectglist(&amp;amp;list)
    }
    // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;4 总结&lt;/h2&gt;&lt;ul&gt;&lt;li data-pid=&quot;xHlwsZEE&quot;&gt;基于伪代码推演了 IO 多路复用的实现思路，核心是基于主动轮询+非阻塞 IO 模式实现，但真正的优雅实现需要依赖于内核，这是因为用户态始终无法准确感知到 io event 的情报&lt;/li&gt;&lt;li data-pid=&quot;sRpz9Nxj&quot;&gt;聊了 epoll 技术的实现原理：（1）拆解建池接口 epoll_create 和入池接口 epoll_ctl，实现 fd 一次拷贝多次复用；（2）通过红黑树维护池中的 fd 数据，增删改平均复杂度 O(logN)；（3）精准事件回调，准确告知 loop thread 具体哪些 fd 已就绪&lt;/li&gt;&lt;li data-pid=&quot;-f9ngRMs&quot;&gt;走读了 Golang 底层 IO 模型的代码链路，Golang 在创建 Listener、获取 conn、读 conn 和 写 conn 时都涉及到对 epoll 技术的应用.&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;NH9bM7Ak&quot;&gt;本文至此结束，未来两周，我们向上扩展，聊聊 Golang 开源 web 框架 gin 的实现原理.&lt;/p&gt;&lt;p data-pid=&quot;cnyAlLaM&quot;&gt;gin：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/gin-gonic/gin&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/gin-gonic/gi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p data-pid=&quot;KALiduPA&quot;&gt;文末小广告：&lt;/p&gt;&lt;p data-pid=&quot;XgpxgtyL&quot;&gt;欢迎老板们关注我的个人公众号：小徐先生的编程世界&lt;/p&gt;&lt;p data-pid=&quot;3O9KTEAd&quot;&gt;我会不定期更新个人纯原创的&lt;a href=&quot;https://www.zhihu.com/search?q=%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF&amp;amp;search_source=Entity&amp;amp;hybrid_search_source=Entity&amp;amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2846169717%7D&quot; class=&quot;internal&quot;&gt;编程技术&lt;/a&gt;博客，技术栈以 go 语言为主，让我们一起点亮更多的编程技能树吧！&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>73dca3c239def320ef424008a831a674</guid>
<title>Prometheus 云原生 kubernetes 服务发现原理图解</title>
<link>https://toutiao.io/k/3070hb8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;云原生kubernetes服务发现原理图解&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;概述&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上节分析了&lt;code&gt;Prometheus&lt;/code&gt;服务发现核心流程（如下图），&lt;code&gt;Discoverer&lt;/code&gt;基于不同协议发现采集点，通过&lt;code&gt;channel&lt;/code&gt;通知到&lt;code&gt;updater&lt;/code&gt;协程，然后更新到&lt;code&gt;discoveryManager&lt;/code&gt;结构体&lt;code&gt;trargets&lt;/code&gt;字段中，最终由&lt;code&gt;sender&lt;/code&gt;协程将&lt;code&gt;discoveryManager&lt;/code&gt;的&lt;code&gt;targets&lt;/code&gt;字段数据发送给&lt;code&gt;scrape&lt;/code&gt;采集模块。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycUdlxroG8YdnKcheVAFTyIx8X0x6DZz1BkYYOAhQ3UzIWoNcVYdonWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.537962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Discoverer&lt;/code&gt;定义的接口类型，不同的服务发现协议基于该接口进行实现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Discoverer &lt;span&gt;interface&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;// Run hands a channel to the discovery provider (Consul, DNS, etc.) through which&lt;/span&gt;&lt;br/&gt; &lt;span&gt;// it can send updated target groups. It must return when the context is canceled.&lt;/span&gt;&lt;br/&gt; &lt;span&gt;// It should not close the update channel on returning.&lt;/span&gt;&lt;br/&gt; Run(ctx context.Context, up &lt;span&gt;chan&lt;/span&gt;&amp;lt;- []*targetgroup.Group)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;k8s协议配置&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Prometheus&lt;/code&gt;本身就是作为云原生监控出现的，所以对云原生服务发现支持具有天然优势。&lt;code&gt;kubernetes_sd_configs&lt;/code&gt; 服务发现协议核心原理就是利用&lt;code&gt;API Server&lt;/code&gt;提供的&lt;code&gt;Rest接口&lt;/code&gt;获取到云原生集群中的&lt;code&gt;POD&lt;/code&gt;、&lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;Node&lt;/code&gt;、&lt;code&gt;Endpoints&lt;/code&gt;、&lt;code&gt;Endpointslice&lt;/code&gt;、&lt;code&gt;Ingress&lt;/code&gt;等对象的元数据，并基于这些信息生成&lt;code&gt;Prometheus&lt;/code&gt;采集点，并且可以随着云原生集群状态变更进行动态实时刷新。&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycj5acWzJCSCe5Ockgrkibrrlem6W3JADNicstpwIGNOLSP15hd8qt0Q0g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5011574074074074&quot; data-w=&quot;864&quot;/&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;&lt;code&gt;kubernetes&lt;/code&gt;云原生集群的&lt;code&gt;POD&lt;/code&gt;、&lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;Node&lt;/code&gt;、&lt;code&gt;Ingress&lt;/code&gt;等对象元数据信息都被存储到&lt;code&gt;etcd&lt;/code&gt;数据库中，并通过&lt;code&gt;API Server&lt;/code&gt;组件暴露的&lt;code&gt;Rest&lt;/code&gt;接口方式提供访问或操作这些对象数据信息。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「&lt;code&gt;kubernetes_sd_configs&lt;/code&gt;配置示例：」&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;job_name:&lt;/span&gt; &lt;span&gt;kubernetes-pod&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;kubernetes_sd_configs:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;-&lt;/span&gt; &lt;span&gt;role:&lt;/span&gt; &lt;span&gt;pod&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;namespaces:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;names:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;test01&#x27;&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;api_server:&lt;/span&gt; &lt;span&gt;https://apiserver.simon:6443&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;bearer_token_file:&lt;/span&gt; &lt;span&gt;/var/run/secrets/kubernetes.io/serviceaccount/token&lt;/span&gt; &lt;br/&gt;      &lt;span&gt;tls_config:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;ca_file:&lt;/span&gt; &lt;span&gt;/var/run/secrets/kubernetes.io/serviceaccount/ca.crt&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置说明：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;api_server&lt;/code&gt;指定&lt;code&gt;API Server&lt;/code&gt;地址，出于安全考虑，这些接口是带有安全认证的，&lt;code&gt;bearer_token_file&lt;/code&gt;和&lt;code&gt;ca_file&lt;/code&gt;则指定访问&lt;code&gt;API Server&lt;/code&gt;使用到的认证信息；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;role&lt;/code&gt;指定基于云原生集群中哪种对象类型做服务发现，支持&lt;code&gt;POD&lt;/code&gt;、&lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;Node&lt;/code&gt;、&lt;code&gt;Endpoints&lt;/code&gt;、&lt;code&gt;Endpointslice&lt;/code&gt;、&lt;code&gt;Ingress&lt;/code&gt;六种类型；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;namespaces&lt;/code&gt;指定作用于哪个云原生命名空间下的对象，不配置则对所有的云原生命名空间生效；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「为什么没有配置api server信息也可以正常进行服务发现？」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多时候我们并不需要配置&lt;code&gt;api server&lt;/code&gt;相关信息也可以进行服务发现，如我们将上面示例简化如下写法：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;job_name:&lt;/span&gt; &lt;span&gt;kubernetes-pod&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;kubernetes_sd_configs:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;-&lt;/span&gt; &lt;span&gt;role:&lt;/span&gt; &lt;span&gt;pod&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;namespaces:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;names:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;test01&#x27;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般&lt;code&gt;Prometheus&lt;/code&gt;部署在监控云原生集群上，从 &lt;code&gt;Pod&lt;/code&gt; 使用 &lt;code&gt;Kubernetes API&lt;/code&gt; 官方客户端库(&lt;code&gt;client-go&lt;/code&gt;)提供了更为简便的方法：&lt;code&gt;rest.InClusterConfig()&lt;/code&gt;。&lt;code&gt;API Server&lt;/code&gt;地址是从&lt;code&gt;POD&lt;/code&gt;的环境变量&lt;code&gt;KUBERNETES_SERVICE_HOST&lt;/code&gt;和&lt;code&gt;KUBERNETES_SERVICE_PORT&lt;/code&gt;构建出来， &lt;code&gt;token&lt;/code&gt; 以及 &lt;code&gt;ca&lt;/code&gt; 信息从&lt;code&gt;POD&lt;/code&gt;固定的文件中获取，因此这种场景下&lt;code&gt;kubernetes_sd_configs&lt;/code&gt;中&lt;code&gt;api_server&lt;/code&gt;和&lt;code&gt;ca_file&lt;/code&gt;是不需要配置的。&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycNKLEd4Gxh6SuicRW0WqT546icMTvSt0h4dvUfJchmXTmmC2xp0s7JGDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.7074074074074074&quot; data-w=&quot;1080&quot;/&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;&lt;code&gt;client-go&lt;/code&gt;是&lt;code&gt;kubernetes&lt;/code&gt;官方提供的&lt;code&gt;go&lt;/code&gt;语言的客户端库，&lt;code&gt;go&lt;/code&gt;应用使用该库可以访问&lt;code&gt;kubernetes&lt;/code&gt;的&lt;code&gt;API Server&lt;/code&gt;，这样我们就能通过编程来对&lt;code&gt;kubernetes&lt;/code&gt;资源进行增删改查操作。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Informer机制&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从之前分析的服务发现协议接口设计得知，了解&lt;code&gt;k8s&lt;/code&gt;服务发现协议入口在&lt;code&gt;discovery/kubernetes.go&lt;/code&gt;的&lt;code&gt;Run&lt;/code&gt;方法：&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycPmiccKZGKiamEGHmWgCWfeV3LZuqtryaqAIAVOBQQgpN8XogvLBKve2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.3962962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Run&lt;/code&gt;方法中&lt;code&gt;switch&lt;/code&gt;罗列出不同&lt;code&gt;role&lt;/code&gt;的处理逻辑，刚好和配置示例中&lt;code&gt;role&lt;/code&gt;支持的六种云原生对象类型对应，只是基于不同的对象进行服务发现，基本原理都是一致的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;云原生服务发现基本原理是访问&lt;code&gt;API Server&lt;/code&gt;获取到云原生集群资源对象，&lt;code&gt;Prometheus&lt;/code&gt;与&lt;code&gt;API Server&lt;/code&gt;进行交互这里使用到的是&lt;code&gt;client-go&lt;/code&gt;官方客户端里的&lt;code&gt;Informer&lt;/code&gt;核心工具包。&lt;code&gt;Informer&lt;/code&gt;底层使用&lt;code&gt;ListWatch&lt;/code&gt;机制，在&lt;code&gt;Informer&lt;/code&gt;首次启动时，会调用&lt;code&gt;List API&lt;/code&gt;获取所有最新版本的资源对象，缓存在内存中，然后再通过&lt;code&gt;Watch API&lt;/code&gt;来监听这些对象的变化，去维护这份缓存，降低&lt;code&gt;API Server&lt;/code&gt;的负载。除了&lt;code&gt;ListWatch&lt;/code&gt;，&lt;code&gt;Informer&lt;/code&gt;还可以注册自定义事件处理逻辑，之后如果监听到事件变化就会调用对应的用户自定义事件处理逻辑，这样就实现了用户业务逻辑扩展。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Informer&lt;/code&gt;机制工作流程如下图：&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycqwu7zfdcntPlS8x0VWXTpSH5uQFtPsR3qehwib4wefYicCibfBPoHDNZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.7870370370370371&quot; data-w=&quot;1080&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Informer&lt;/code&gt;机制本身比较复杂，这里先暂时不太具体说明，只需要理解&lt;code&gt;Prometheus&lt;/code&gt;使用&lt;code&gt;Informer&lt;/code&gt;机制获取和监听云原生资源对象，即上图中只有&lt;strong&gt;「绿色框部分是自定义业务逻辑」&lt;/strong&gt;，其它都是&lt;code&gt;client-go&lt;/code&gt;框架&lt;code&gt;informer&lt;/code&gt;工具包提供的功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这其中的关键就是注册自定义&lt;code&gt;AddFunc&lt;/code&gt;、&lt;code&gt;DeleteFunc&lt;/code&gt;和&lt;code&gt;UpdateFunc&lt;/code&gt;三种事件处理器，分别对应增、删、改操作，当触发对应操作后，事件处理器就会被回调感知到。比如云原生集群新增一个&lt;code&gt;POD&lt;/code&gt;资源对象，则会触发&lt;code&gt;AddFunc&lt;/code&gt;处理器，该处理器并不做复杂的业务处理，只是将该对象的&lt;code&gt;key&lt;/code&gt;放入到&lt;code&gt;Workqueue&lt;/code&gt;队列中，然后&lt;code&gt;Process Item&lt;/code&gt;组件作为消费端，不停从&lt;code&gt;Workqueue&lt;/code&gt;中提取数据获取到新增&lt;code&gt;POD&lt;/code&gt;的&lt;code&gt;key&lt;/code&gt;，然后交由&lt;code&gt;Handle Object&lt;/code&gt;组件，该组件通过&lt;code&gt;Indexer&lt;/code&gt;组件提供的&lt;code&gt;GetByKey()&lt;/code&gt;查询到该新增&lt;code&gt;POD&lt;/code&gt;的所有元数据信息，然后基于该&lt;code&gt;POD&lt;/code&gt;元数据就可以构建采集点信息，这样就实现&lt;code&gt;kubernetes&lt;/code&gt;服务发现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「为什么需要Workqueue队列？」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Resource Event Handlers&lt;/code&gt;组件注册自定义事件处理器，获取到事件时只是把对象&lt;code&gt;key&lt;/code&gt;放入到&lt;code&gt;Workerqueue&lt;/code&gt;中这种简单操作，而没有直接调用&lt;code&gt;Handle Object&lt;/code&gt;进行事件处理，这里主要是避免阻塞影响整个&lt;code&gt;informer&lt;/code&gt;框架运行。如果&lt;code&gt;Handle Object&lt;/code&gt;比较耗时放到&lt;code&gt;Resource Event Handlers&lt;/code&gt;组件中直接处理，可能就会影响到④⑤功能，所以这里引入&lt;code&gt;Workqueue&lt;/code&gt;类似于&lt;code&gt;MQ&lt;/code&gt;功能实现解耦。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;源码分析&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;熟悉了上面&lt;code&gt;Informer机制&lt;/code&gt;，下面以&lt;code&gt;role=POD&lt;/code&gt;为例结合&lt;code&gt;Prometheus&lt;/code&gt;源码梳理下上面流程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、创建和&lt;code&gt;API Server&lt;/code&gt;交互底层使用的&lt;code&gt;ListWatch&lt;/code&gt;工具；&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycLkmSTlOg7h6pMI4P1ZyYtzvFZWELBUEGRFUW8hsb0gcsiarwCyqspVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5420560747663551&quot; data-w=&quot;1070&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、基于&lt;code&gt;ListWatch&lt;/code&gt;创建&lt;code&gt;Informer&lt;/code&gt;；&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCyczfrE2Gj0woGlia5YoCKlZdMzuvYoZmlPTMYzIbOKMySEC9MNafqS0WA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.07420924574209246&quot; data-w=&quot;822&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、注册资源事件，分别对应资源创建、资源删除和资源更新事件处理；&lt;/p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCyc2ssFWGQIxJLiaVHuGiaDcS5QYY8UCWFbd3ZclV5Dn2vKIZv8fibEibG17w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6065022421524664&quot; data-w=&quot;892&quot;/&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;这里的 &lt;code&gt;podAddCount&lt;/code&gt;、&lt;code&gt;podDeleteCount&lt;/code&gt;和&lt;code&gt;podUpdateCount&lt;/code&gt;分别对应下面三个指标序列，指标含义也比较明显：&lt;/p&gt;&lt;p&gt;&lt;code&gt;prometheus_sd_kubernetes_events_total(role=&quot;pod&quot;, event=&quot;add&quot;)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;prometheus_sd_kubernetes_events_total(role=&quot;pod&quot;, event=&quot;delete&quot;)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;prometheus_sd_kubernetes_events_total(role=&quot;pod&quot;, event=&quot;update&quot;)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;role&lt;/code&gt;标识资源类型，包括：&lt;code&gt;&quot;endpointslice&quot;, &quot;endpoints&quot;, &quot;node&quot;, &quot;pod&quot;, &quot;service&quot;, &quot;ingress&quot;&lt;/code&gt;五种类型；&lt;/p&gt;&lt;p&gt;&lt;code&gt;event&lt;/code&gt;标识事件类型，包括：&lt;code&gt;&quot;add&quot;, &quot;delete&quot;, &quot;update&quot;&lt;/code&gt;三种类型。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、事件处理，&lt;code&gt;AddFunc&lt;/code&gt;、&lt;code&gt;DeleteFunc&lt;/code&gt;和&lt;code&gt;UpdateFunc&lt;/code&gt;注册的事件处理逻辑一样，处理逻辑也比较简单：就是获取资源对象&lt;code&gt;key&lt;/code&gt;，并将其写入到&lt;code&gt;Workqueue&lt;/code&gt;中；&lt;/p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3482642777155655&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCyczpDfMaw87EUcgibxuL7MD0uzhwOfibNblKYTMbmibdFOib8zRnFIicUCQ9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;893&quot;/&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;对于&lt;code&gt;POD&lt;/code&gt;资源，这里的&lt;code&gt;key&lt;/code&gt;就是：&lt;code&gt;namespace/pod_name&lt;/code&gt;格式，比如&lt;code&gt;key=test01/nginx-deployment-5ffc5bf56c-n2pl8&lt;/code&gt;。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5、给&lt;code&gt;Workqueue&lt;/code&gt;注册一个无限循环处理逻辑，就能持续从&lt;code&gt;Workqueue&lt;/code&gt;中取出&lt;code&gt;key&lt;/code&gt;进行处理；&lt;/p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7490740740740741&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycibeJZHZG6LrRPAqDmjwEdWWXdkJjsaZC9icCtaDbeEwJSslYiblvF6YNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;针对&lt;code&gt;Pod&lt;/code&gt;里的每个&lt;code&gt;Container&lt;/code&gt;上的每个&lt;code&gt;port&lt;/code&gt;，都会生成一个对应采集点&lt;code&gt;target&lt;/code&gt;，其中&lt;code&gt;__address__&lt;/code&gt;就是&lt;code&gt;PodIP&lt;/code&gt;+&lt;code&gt;port&lt;/code&gt;组合。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6、最后启动&lt;code&gt;Informer&lt;/code&gt;，让整个流程运转起来；&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.10860655737704918&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCyc935C3Mo2ozND1zRILR46icU1dWUicrfVzP0mBSTYNew9JtOP7Sht4XnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;488&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/O2TDJPu7cb34AsmIHZKBMxJibn7lTXCycpuRf1d0hFzm3AJNAKraMKLaiabvz2LtA8BXEpoyCcSOPrZD0EONFoyA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;600&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「更多云原生监控运维知识，请关注公众号：Reactor2020」&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>