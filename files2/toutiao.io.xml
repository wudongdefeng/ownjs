<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3cacd216c8bdcc39182f7e18e08caea8</guid>
<title>单体分层应用架构剖析</title>
<link>https://toutiao.io/k/rd927pj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;分层单体架构风格是分层思想在单体架构中的应用，其关注于技术视角的职责分层。同时，基于不同层变化速率的不同，在一定程度上控制变化在系统内的传播，有助于提升系统的稳定性。但这种技术视角而非业务视角的关注点隔离，导致了问题域与工程实现之间的Gap，这种割裂会导致系统认知复杂度的提升。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;作者：倪新明&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;1 经典单体分层架构&lt;/strong&gt;&lt;/h1&gt;

&lt;h2&gt;&lt;strong&gt;1.1 四层单体架构风格&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;经典的四层单体分层架构如下图所示，应用在逻辑上划分为展现层、业务层、持久层及数据存储层，每层的职责如下：&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;展现层&lt;/strong&gt;：负责给最终用户展现信息，并接受用户的输入触发系统的业务逻辑。用户可以是使用系统的人，也可以是其他软件系统。&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;业务层&lt;/strong&gt;：关注系统业务逻辑的实现&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;持久层&lt;/strong&gt;：负责数据的存取&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;数据存储层&lt;/strong&gt;：底层的数据存储设施&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-13cm6qc7o0hF8HcxR.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这种分层单体架构可能是大多数开发人员最早接触、最为熟悉的应用架构风格，其特点是：&lt;/p&gt;

&lt;p&gt;• 层间的依赖关系由上到下逐层向下直接依赖，每层都是关闭状态，请求的数据流向从上到下，必须严格通过每个分层进行流转，而不能进行穿透调用。&lt;/p&gt;

&lt;p&gt;• 关注点隔离：通过分层将系统的关注点进行垂直分配，每层只关注自身层边界内的职责，层间职责相互独立不存在交叉。比如业务层负责处理系统的核心业务逻辑，而持久层则关注于对数据的存取。&lt;/p&gt;

&lt;p&gt;除了关注点隔离这一维度，分层也在 “变化” 的维度进行隔离。每层的变化速率不同，由下级上逐层增加，展现层的变化速率最快，数据存储层变化速率最低。通过严格层依赖关系约束，尽量降低低层变化对上层的影响。这个特点的上下文是分层之间依赖于抽象，而非依赖于具体。当实现发生变化而接口契约不变时，变更范围框定在当前层。但，如果是接口契约的变更，则可能会直接影响到上游的依赖层。&lt;/p&gt;

&lt;p&gt;这种分层架构风格具有明显的优势：&lt;/p&gt;

&lt;p&gt;• 分层模型比较简单，&lt;strong&gt;理解和实现成本低&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 开放人员接受度和熟悉程度高，&lt;strong&gt;认知和学习成本低&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;1.2 五层单体架构风格&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;四层架构面临的问题是:&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;层间数据效率问题&lt;/strong&gt;: 由于层间调用关系的依赖约束，层间的数据流转需要付出额外成本&lt;/p&gt;

&lt;p&gt;• 业务层服务能力的&lt;strong&gt;复用性&lt;/strong&gt;：业务层中处于对等地位的组件或模块之间存在共享服务的诉求&lt;/p&gt;

&lt;p&gt;从复用性的角度考虑，如下所示的五层架构中，&lt;strong&gt;通过引入中间层解决复用问题&lt;/strong&gt;。将共享服务从业务层沉淀到通用服务层，以提高复用性。其特点是：&lt;/p&gt;

&lt;p&gt;• 引入通用服务层提供通用服务，提高复用性&lt;/p&gt;

&lt;p&gt;• 通用服务层是开放层，允许调用链路穿透，业务层可以按需直接访问更下层的持久层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14OjQ7aaKXCwanUr8.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;相比于四层架构，五层分层架构的主要优势是：通过中间层的引入一定程度解决系统的复用性问题。但从反向角度看，正是由于中间层的引入导致了如下问题：&lt;/p&gt;

&lt;p&gt;• 引入中间层&lt;strong&gt;降低了数据传输效率，提高了开发实现成本&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 有造成系统混乱度提升的风险：由于通用服务层的开放性导致业务层可以穿透调用。但这种是否需要进行穿透的场景无法形成统一的判定原则，往往依赖于实现人员的个人经验进行权衡，同一个业务场景由不同的开发人员实现可能会有不同的判定结果（在四层架构中如果放开层间调用约束也会存在该问题）。随着业务需求迭代，系统的依赖关系一定会日趋增加，最终形成复杂的调用关系，也导致系统复杂性上升，增加团队成员的认知成本。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14RSUjM1411pshyudg.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;2 单体分层架构的共性问题探讨&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;当然，正是由于其极高的接受度，也造成了大家对分层的认知误区，认为分层是必然的“默认选项” ，从而忽略了分层的本质。分层到底是为了解决什么问题？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分层本质上是处理复杂性的一种方式：将复杂性在不同级别进行抽象，通过分层进行职责隔离，以此降低认知成本。同时，通过分层形成的“屏障”，控制变化在系统间的传播，提升系统稳定性。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不论是四层架构还是五层架构都是分层思想在单体应用架构风格下的实践，这种分层模式存在的固有问题主要体现在以下几个方面：&lt;/p&gt;

&lt;p&gt;• 分层对系统复杂度和效率的影响&lt;/p&gt;

&lt;p&gt;• 变化真的能完全隔离吗？&lt;/p&gt;

&lt;p&gt;• 问题域与解决方案的隔离&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.1 分层对系统复杂度和效率的影响&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;如上文所述，分层架构中各层的变化速度不同。越往上变化越快，稳定性越低，越往下变化越慢，稳定性越高。比如，展现层的用户展示逻辑可能频繁变化，对应于不同的场景诉求展示数据及形式都可能不同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14DXPTxh6DJMBDIKe.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果划分层次越多，层间依赖关系越严格，则系统的调用链路和依赖关系会更加清晰。但，请求及响应的链路越长，层间数据转换有额外成本。即使引入各种数据转换工具，比如MapStruct，实现起来依然会感觉非常繁琐和重复。&lt;/p&gt;

&lt;p&gt;如果划分层次越多，层间依赖关系宽松，允许跨层调用（如下所示的从展现层调用持久层只是一个示意），则能在一定程度降低数据频繁转换的成本。但:&lt;/p&gt;

&lt;p&gt;• 其一：如何判定是否要跨层调用很难形成统一的严格判定标准，只能进行粗粒度划分。因此，在实现过程中会有不同的判定结果，系统的调用关系会随着代码规模增长而日趋复杂。当然，团队可以加强代码评审的粒度，每次评审基于是否穿透调用进行讨论、判断并达成一致。但实际经验是，由于人为因素，靠严格的代码评审并不能保证决策的一致性。&lt;/p&gt;

&lt;p&gt;• 其二：如果允许跨层调用，则意味着 “模型” 的穿透，低层的模型会直接暴露在更上层，这与我们追求的组件内聚性和模型的封装性存在冲突&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：层间的依赖约束是一种架构决策，可以考虑通过自动化单元测试机制进行保证，具体参考&lt;/p&gt;

&lt;p&gt;《 &lt;a href=&quot;http://xingyun.jd.com/shendeng/article/detail/5358?forumId=79&amp;amp;jdme_router=jdme%3A%2F%2Fweb%2F202206081297%3Furl%3Dhttps%3A%2F%2Fshendengh5.jd.com%2FarticleDetail%3Fid%3D5358&quot;&gt;基于ArchUnit守护系统架构&lt;/a&gt; 》&lt;/p&gt;

&lt;p&gt;《 &lt;a href=&quot;http://xingyun.jd.com/shendeng/article/detail/4226?forumId=79&amp;amp;jdme_router=jdme%3A%2F%2Fweb%2F202206081297%3Furl%3Dhttps%3A%2F%2Fshendengh5.jd.com%2FarticleDetail%3Fid%3D4226&quot;&gt;轻量级的架构决策记录机制&lt;/a&gt; - ADR》&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.2 变化的隔离&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;我们对分层有一个普遍的、“先入为主” 的认知，分层能够隔离变化。首先会想到的例子，比如，如果底层的数据库发生了变更，又或者ORM框架发生了变更，那么，我们只需要修改DAO层的实现，而不需要更改上层的业务层代码。&lt;/p&gt;

&lt;p&gt;• 你真的会替换数据库吗？你真的会替换ORM框架吗？有可能，但概率非常低，大部分系统并不会发生这种场景。&lt;/p&gt;

&lt;p&gt;• 发生替换就真的能隔离吗？如果你的层间不是依赖于抽象，而是依赖于具体，那么隔离也无从谈起。&lt;/p&gt;

&lt;p&gt;• 即使层间依赖于抽象，变化就真的隔离了吗？实现发生变化的直接结果就是依赖方需要引用新的实现，这种变化也同样会影响到上层。只不过是这种变化可能交由IOC容器了&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;但，这个是变化隔离的全部吗&lt;/strong&gt;？&lt;/p&gt;

&lt;p&gt;• 如果是展现层需要增加一个新的字段，而当前数据库模型中没有？&lt;/p&gt;

&lt;p&gt;• 如果是数据库中需要增加一个新的字段，而展现层和业务逻辑层不关心？&lt;/p&gt;

&lt;p&gt;• 如果是......&lt;/p&gt;

&lt;p&gt;所以，引起系统变化的原因很多，场景各异，业务诉求亦不相同，分层对变化隔离程度也不相同：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分层可以控制变化在系统内的传播，由于变化场景的多样化，分层不能完全的隔离变化。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14X8szEXek11zjwh4b.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.3 问题域与解决方案的割裂&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;重新思考下上文提到的分层单体架构的特点之一：关注点隔离，展现层、业务层、数据访问层、存储层等各层聚焦于自身的职责。这种关注点的本质是什么？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术视角的隔离！！！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每层都是从技术视角将技术关注点进行隔离，而非业务领域视角。技术视角是研发友好的，作为开发人员，天然的可以理解和接受这种技术维度的统一语言：DAO层只负责处理数据相关逻辑，Controller层之服务处理Restful API相关，RPC层只处理与外部系统的跨进程调用等等。&lt;/p&gt;

&lt;p&gt;而对于非常核心的业务概念，比如以订单为例，在单体分层架构下需要回答这样一个问题：&lt;strong&gt;“订单组件” 在哪里？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在经典的分层单体架构风格中，典型的实现如下图所示：&lt;/p&gt;

&lt;p&gt;• OrderConroller：Spring技术栈下的系统访问的Rest接口&lt;/p&gt;

&lt;p&gt;• OrderService/OrderServiceImpl：订单的核心业务逻辑实现服务，实现诸如下单、取消订单等逻辑&lt;/p&gt;

&lt;p&gt;• OrderDAO/OrdeDAOImpl：订单数据的存取&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-15rljiOOZWX8fPXou.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;订单组件&lt;strong&gt;并不是以一个单一的、内聚的事物存在&lt;/strong&gt;，其组成元素OrderService以及其依赖的OrderDAO分散于不同的层，因此，这种模式下订单组件只是&lt;strong&gt;逻辑性、概念性&lt;/strong&gt;的存在。作为业务域的核心抽象，订单组件没有真实的、直观的、内聚的反映在代码实现中。我们在工程代码库中寻找“订单组件”：&lt;/p&gt;

&lt;p&gt;• 首先，在工程顶层最先看到的是技术视角的Module(Maven Module)：web、service 、dao&lt;/p&gt;

&lt;p&gt;• 然后，需要在各层导航才能一窥其全貌&lt;/p&gt;

&lt;p&gt;在IDE的支持下，这种导航并不会很复杂。但问题的根本在于：&lt;strong&gt;认知成本的增加&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们去了解系统，&lt;strong&gt;天然的是从业务域而非技术域出发，单体分层恰恰是从技术域而非业务域出发，这种不同导致业务域与实现间的割裂，增加了对系统的认知成本&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现要反应抽象，组件化思维本质上一种模块化思维，通过内聚性和封装性，将问题空间进行拆分成子空间，分而治之。对外通过接口提供组件能力，屏蔽内部的复杂性。接口契约的大小粒度需要权衡，粒度越小，能力提供越约聚焦，理解和接入成本越低，但通用性越差。接口契约粒度越大，则通用性越强，但理解和接入复杂性越高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-157XexthS9xLghJLo.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;将组件化思维应用于单体分层架构，引申出模块化单体架构风格。&lt;strong&gt;应用架构按照问题域进行模块化组织，而非基于技术关注点进行拆分&lt;/strong&gt;。组件内部遵循内聚性原则，其内包含了实现组件能力所需要的各个元素及交互关系。组件之间通过统一的、合适粒度的接口契约进行交互，不直接依赖于组件的内部能力或模型。同时，组织良好的模块化单体应用架构也是进行微服务拆分的重要保证。如果你无法在单体架构中进行优雅的模块化组织，又何谈合理的微服务拆分呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-15swKLc4lHaASumTQ.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;3 结语&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;单体分层架构风格是分层思想在单体架构中的应用，其关注于技术视角的职责分层。同时，基于不同层变化速率的不同，在一定程度上控制变化在系统内的传播，有助于提升系统的稳定性。但这种技术视角而非业务视角的关注点隔离，导致了问题域与工程实现之间的Gap，这种割裂会导致系统认知复杂度的提升。将组件化思维应用于单体分层架构，模块化单体技术视角的分层拉回至业务域视角的模块化，一定程度上降低业务与工程实现间的隔离。良好的模块化是单体走向微服务的重要基石，如果模块化设计较差的系统，不仅会增加微服务拆分的成本，更为重要的是，会增加形成分布式单体的概率和风险。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>dbf7e8bdd8486948b257b2047c9d6ba2</guid>
<title>深入浅出学习透析 Nginx 服务器的基本原理和配置指南（Keepalive 性能优化实战篇）</title>
<link>https://toutiao.io/k/fzspi5p</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;content_views&quot; class=&quot;markdown_views prism-tomorrow-night&quot;&gt;
                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
                        &lt;path stroke-linecap=&quot;round&quot; d=&quot;M5,0 0,2.5 5,5z&quot; id=&quot;raphael-marker-block&quot;/&gt;
                    &lt;/svg&gt;
                    &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/a4bcbd66fab94f30938a34c53bce13e6.png&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;Linux系统：Centos 7 x64&lt;/li&gt;&lt;li&gt;Nginx版本：1.11.5&lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;Nginx 是一款面向性能设计的 HTTP 服务器，能反向代理 HTTP，HTTPS 和邮件相关(SMTP，POP3，IMAP)的协议链接。并且提供了负载均衡以及 HTTP 缓存。它的设计充分使用异步事件模型，削减上下文调度的开销，提高服务器并发能力。采用了模块化设计，提供了丰富模块的第三方模块。所以关于 Nginx，有这些标签：「异步」「事件」「模块化」「高性能」「高并发」「反向代理」「负载均衡」「长连接」。本章内容主要就是针对于长连接请求模块。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_8&quot;/&gt;为什么要单独讲解keepalive指令？&lt;/h3&gt; 
&lt;p&gt;upstream设置中，有个参数要特别的小心，就是这个keepalive。&lt;/p&gt; 
&lt;p&gt;大多数未仔细研读过nginx的同学通常都会误解这个参数，有些人理解为这里的keepalive是设置是否打开长连接，以为应该设置为on/off。有些人会被前面的keepalive_timeout误导，以为这里也是设置keepalive的timeout。&lt;/p&gt; 
&lt;p&gt;但是实际上这个keepalive参数的含义非常的奇特，请小心看nginx文档中的说明，因为Keepalive长连接非常重要而且容易理解错误，所以专门做连一期专门讲解keepalive的文章。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;本文介绍如何使用Nginx进行配置和实现长连接Keepalive，并介绍如何设置 nginx 以提供静态内容服务，如何配置 nginx 作为代理服务器。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_19&quot;/&gt;keepalive指令&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/ea9babb9b5f54550a425d15ee14ae989.webp#pic_center&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;支持keepalive长连接，当使用nginx作为反向代理时，为了支持长连接，需要做到两点：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;从client到nginx的连接是长连接&lt;/li&gt;&lt;li&gt;从nginx到server的连接是长连接&lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;从HTTP协议的角度看，Nginx在这个过程中，对于客户端它扮演着HTTP服务器端的角色。而对于真正的服务器端（在nginx的术语中称为upstream）Nginx又扮演着HTTP客户端的角色，keepalive指令出现在版本1.1.4。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_31&quot;/&gt;keepalive指令格式&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt;keepalive不是on/off之类的开关&lt;/li&gt;&lt;li&gt;keepalive不是timeout，不是用来设置超时值&lt;/li&gt;&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;Syntax:    keepalive connections;
Default:    —
Context:    upstream
Activates the cache for connections to upstream servers.
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;connections的取值代表着连接到upstream服务器的持续连接（即长连接）的数量。很多人都会有一个误解：认为这个参数是设置到upstream服务器的长连接的数量，分歧在于是最大连接数还是最小连接数&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;&lt;a id=&quot;_45&quot;/&gt;官方文档的介绍&lt;/h5&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;The connections parameter sets the maximum number of idle keepalive connections to upstream servers&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt;connections参数设置到upstream服务器的空闲keepalive连接的最大数量，这个”idle”的概念，何为idle。大多数人之所以误解为是到upstream服务器的最大长连接数，一般都是因为看到了文档中的这句话，而漏看了这个”idle”一词。&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;When this number is exceeded, the least recently used connections are closed.&lt;/p&gt; 
&lt;/blockquote&gt; 
 
&lt;p&gt;Nginx的官方文档给出了指示，否定了最大连接数的可能：&lt;strong&gt;keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量&lt;/strong&gt;。&lt;strong&gt;请注意空闲keepalive连接的最大数量中空闲这个关键字&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_55&quot;/&gt;keepalive实际场景分析&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;先假设一个场景： 有一个HTTP服务，作为upstream服务器接收请求，响应时间为100毫秒。如果要达到10000 QPS的性能，就需要在nginx和upstream服务器之间建立大约1000条HTTP连接。nginx为此建立连接池，然后请求过来时为每个请求分配一个连接，请求结束时回收连接放入连接池中，连接的状态也就更改为idle。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;之后假设这个upstream服务器的keepalive参数设置比较小，比如常见的10.&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;再次假设请求和响应是均匀而平稳的，那么这1000条连接应该都是一放回连接池就立即被后续请求申请使用，线程池中的idle线程会非常的少，趋进于零。我们以10毫秒为一个单位，来看连接的情况(注意场景是1000个线程+100毫秒响应时间，每秒有10000个请求完成)：&lt;/p&gt; 
  &lt;ul&gt;&lt;li&gt;每10毫秒有100个新请求，需要100个连接&lt;/li&gt;&lt;li&gt;每10毫秒有100个请求结束，可以释放100个连接&lt;/li&gt;&lt;li&gt;如果请求和应答都均匀，则10毫秒内释放的连接刚好够用，不需要新建连接，连接池空闲连接为零&lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;如果请求通常不是足够的均匀和平稳，为了简化问题，我们假设应答始终都是平稳的，只是请求不平稳，第一个10毫秒只有50,第二个10毫秒有150：&lt;/p&gt; 
   &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;strong&gt;再下一个10个毫秒，有150个请求进来，有100个请求结束任务释放连接。150 - 100 = 50,空缺了50个连接，减掉前面连接池保留的10个空闲连接，nginx不得不新建40个新连接来满足要求&lt;/strong&gt;。&lt;/p&gt; 
   &lt;/li&gt;&lt;li&gt; &lt;p&gt;前10毫秒，进来100个请求，结束50个请求，导致连接不够用，nginx为此新建50个连接&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;后10毫秒，进来100个请求，结束150个请求，导致空闲连接过多，ngixn为此关闭了150-100-10=40个空闲连接&lt;/p&gt; 
  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;第二个应答不均匀的场景实际上是对应第一个请求不均匀的场景：正是因为请求不均匀，所以导致100毫秒之后这些请求的应答必然不均匀&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;现实世界中的请求往往和理想状态有巨大差异，请求不均匀，服务器处理请求的时间也不平稳，这理论上的大概1000个连接在反复的回收和再分配的过程中，必然出现两种非常矛盾场景在短时间内反复：&lt;/p&gt; 
&lt;ol&gt;&lt;li&gt;连接不够用，造成新建连接&lt;/li&gt;&lt;li&gt;连接空闲，造成关闭连接。从而使得总连接数出现反复震荡，不断的创建新连接和关闭连接，使得长连接的效果被大大削弱。&lt;/li&gt;&lt;/ol&gt; 
&lt;h4&gt;&lt;a id=&quot;Keepalive_88&quot;/&gt;Keepalive参数建议&lt;/h4&gt; 
&lt;p&gt;造成连接数量反复震荡的一个推手，就是这个keepalive 这个最大空闲连接数。毕竟连接池中的1000个连接在频繁利用时，出现短时间内多余10个空闲连接的概率实在太高。因此为了避免出现上面的连接震荡，必须考虑加大这个参数，&lt;strong&gt;比如上面的场景如果将keepalive设置为100或者200,就可以非常有效的缓冲请求和应答不均匀&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_92&quot;/&gt;keepalive参数分析&lt;/h3&gt; 
&lt;ul&gt;&lt;li&gt;对应的参数设置为每个worker子进程在缓冲中保持的到upstream服务器的空闲keepalive连接的最大数量。当超过这个数量值的时候，会将最近最少使用（LRU）的连接进行关闭。需要考虑的是keepalive指令不会限制一个worker进程到upstream服务器连接的总数量。其参数应该设置为一个足够小的数字来让upstream服务器来处理新进来的连接。&lt;/li&gt;&lt;li&gt;如果想让upstream每次都处理新的进来的连接，就应该将这个值放的足够小。反过来理解，就是如果不想让upstream服务器处理新连接，就应该放大一些？&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;Keepalive_97&quot;/&gt;Keepalive的使用案例&lt;/h4&gt; 
&lt;h5&gt;&lt;a id=&quot;Keepalivememcached_99&quot;/&gt;Keepalive对接memcached服务&lt;/h5&gt; 
&lt;p&gt;使用keepalive连接的memcached upstream配置的例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream memcached_backend {
    server 127.0.0.1:11211;
    server 10.0.0.2:11211;
    keepalive 32;
}
server {
    ...
    location /memcached/ {
        set $memcached_key $uri;
        memcached_pass memcached_backend;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveHttp11Web_117&quot;/&gt;Keepalive对接Http1.1的Web服务&lt;/h5&gt; 
&lt;p&gt;对于HTTP，proxy_http_version指定应该设置为”1.1”，而”Connection” header应该被清理：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream http_backend {
    server 127.0.0.1:8080;
    keepalive 16;
}
server {
    ...
    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection &quot;&quot;;
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveHttp10Web_136&quot;/&gt;Keepalive对接Http1.0的Web服务&lt;/h5&gt; 
&lt;p&gt;HTTP/1.0 持久连接可以通过传递”&lt;strong&gt;Connection: Keep-Alive&lt;/strong&gt;” header 到upstream server， 但是不推荐使用这种方法。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveFastCGIWeb_140&quot;/&gt;Keepalive对接FastCGI的Web服务&lt;/h5&gt; 
&lt;p&gt;对于FastCGI服务器，要求设置fastcgi_keep_conn来让长连接工作：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream fastcgi_backend {
    server 127.0.0.1:9000;
    keepalive 8;
}
server {
    ...
    location /fastcgi/ {
        fastcgi_pass fastcgi_backend;
        fastcgi_keep_conn on;
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;当使用默认的round-robin之外的负载均衡算法时，必须在keepalive指令之前激活他们。SCGI 和 uwsgi 协议没有keepalive连接的概念。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;client_161&quot;/&gt;保持和client的长连接&lt;/h3&gt; 
&lt;p&gt;为了在client和nginx之间保持上连接，有两个要求：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;client发送的HTTP请求要求keep alive&lt;/li&gt;&lt;li&gt;nginx设置上支持keep alive&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;HTTP_167&quot;/&gt;HTTP配置&lt;/h4&gt; 
&lt;p&gt;默认情况下，Nginx已经自动开启了对client连接的keep alive支持。一般场景可以直接使用，但是对于一些比较特殊的场景，还是有必要调整个别参数。需要修改nginx的配置文件(在nginx安装目录下的conf/nginx.conf):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http {
    keepalive_timeout  120s 120s;
    keepalive_requests 10000;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_timeout_178&quot;/&gt;keepalive_timeout指令&lt;/h4&gt; 
&lt;p&gt;keepalive_timeout指令的语法：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Syntax:    keepalive_timeout timeout [header_timeout];
Default:    keepalive_timeout 75s;
Context:    http, server, location
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt;&lt;li&gt;第一个参数设置keep-alive客户端连接在服务器端保持开启的超时值。值为0会禁用keep-alive客户端连接。&lt;/li&gt;&lt;li&gt;可选的第二个参数在响应的header域中设置一个值“Keep-Alive: timeout=time”。这两个参数可以不一样。&lt;/li&gt;&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;注：默认75s一般情况下也够用，对于一些请求比较大的内部服务器通讯的场景，适当加大为120s或者300s。第二个参数通常可以不用设置&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_requests_193&quot;/&gt;keepalive_requests指令&lt;/h4&gt; 
&lt;p&gt;keepalive_requests指令用于设置一个keep-alive连接上可以服务的请求的最大数量。当最大请求数量达到时，连接被关闭。默认是100。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;keepalive_requests_197&quot;/&gt;keepalive_requests指令的实现原理&lt;/h5&gt; 
&lt;ul&gt;&lt;li&gt;指一个keepalive请求建立之后，Nginx就会为这个连接设置一个计数器，记录这个keep alive的长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则Nginx会强行关闭这个长连接，逼迫客户端不得不重新建立新的长连接。&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;这个参数往往被大多数人忽略，因为大多数情况下当QPS(每秒请求数)不是很高时，默认值100凑合够用。但是，对于一些QPS比较高（比如超过10000QPS，甚至达到30000,50000甚至更高) 的场景，默认的100就显得太低&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;&lt;strong&gt;简单计算一下，QPS=10000时，客户端每秒发送10000个请求(通常建立有多个长连接)，每个连接只能最多跑100次请求，意味着平均每秒钟就会有100个长连接因此被nginx关闭&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;为了保持QPS，客户端不得不每秒中重新新建100个连接。因此，如果用netstat命令看客户端机器，就会发现有大量的TIME_WAIT的socket连接(即使此时keep alive已经在client和nginx之间生效)。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;因此对于QPS较高的场景，非常有必要加大这个参数，以避免出现大量连接被生成再抛弃的情况，减少TIME_WAIT&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a id=&quot;server_209&quot;/&gt;保持和server的长连接&lt;/h3&gt; 
&lt;p&gt;为了让Nginx和server（Nginx称为upstream）之间保持长连接，典型设置如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http {
    upstream  BACKEND {
        server   192.168.0.1：8080  weight=1 max_fails=2 fail_timeout=30s;
        server   192.168.0.2：8080  weight=1 max_fails=2 fail_timeout=30s;
        keepalive 300;        // 这个很重要！
    }
    server {
        listen 8080 default_server;
        server_name &quot;&quot;;
        location /  {
            proxy_pass http://BACKEND;
            proxy_set_header Host  $Host;
            proxy_set_header x-forwarded-for $remote_addr;
            proxy_set_header X-Real-IP $remote_addr;
            add_header Cache-Control no-store;
            add_header Pragma  no-cache;
            proxy_http_version 1.1;                    // 这两个最好也设置
            proxy_set_header Connection &quot;&quot;;
            client_max_body_size  3072k;
            client_body_buffer_size 128k;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr/&gt; 
&lt;h4&gt;&lt;a id=&quot;_240&quot;/&gt;总结&lt;/h4&gt; 

                &lt;/div&gt;
                
                
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5accb485bed9ccdaecc0dd25743a4609</guid>
<title>大规模异构图召回在美团到店推荐广告的应用</title>
<link>https://toutiao.io/k/p05a6cy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;58&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBVHPgeBXgTUj0ib1Kwfosl82xO1Aw7x6gccLuuYs1dbxI7REI7OcjbGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总第530&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2022年 第047篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img border=&quot;0&quot; class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;103&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;103&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBic5ADGrKxgSd0tibyMiasOHXjb46qFBw7PTfuWAxXzWq32lDkL05icwkMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; data-width=&quot;100%&quot; opacity=&quot;&quot; title=&quot;undefined&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; data-style=&quot;text-align: left; font-size: 14px; color: inherit;&quot;&gt;&lt;section&gt;&lt;span&gt;美团到店推荐广告团队在图神经网络的长期落地实践中，思考分析了场景的特点与挑战，针对性地进行了模型设计，并通过大规模训练工具及线上部署优化多次成功落地，带来了线上收入提升。本文主要介绍了大规模图召回技术在美团到店广告场景下的实践经验，包括模型设计思路、模型迭代历程、大规模训练工具以及线上部署性能优化等，希望为从事相关工作的读者带来一些启发。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2. 图神经网络简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3. 业务场景及挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4. 图召回技术在推荐广告的演进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.1 基于全场景数据高阶关系的大规模异构图建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.2 强化时空信息感知的端到端异构图建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;5. 性能优化与应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6. 总结与展望&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;7. 作者简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;8. 参考资料&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;团队简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;美团到店推荐广告技术部服务于到店餐饮、休娱亲子、丽人医美等众多本地生活服务商家。其中，召回环节作为推荐广告系统的第一个环节，承担着从海量商品中寻找优质候选的角色，是算法优化的核心问题之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐系统中经典的召回范式有两类：基于标签构建倒排索引的显式召回和基于模型端到端建模用户兴趣的隐式召回。在隐式召回中，历史交互行为建模对于准确刻画用户兴趣非常关键。电商场景中，用户与商家、商品之间的交互关系适合通过图网络来表达。相较于传统模型，图神经网络可以构建用户与商品间的多种交互关系，然后借助高阶网络结构的传递性合理扩充用户行为的丰富度，将用户行为、用户基础属性和商品的内容属性等各种异质信息在统一的框架中进行融合，带来更大的效果空间。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;美团到店推荐广告算法团队和NLP中心知识计算团队围绕图技术在推荐广告的应用进行了密切的合作，获得了线上效果的显著提升。本文主要介绍探索过程以及相关的实践经验。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 图神经网络简介&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;图作为包含节点自身和节点间边关系的集合，广泛存在于真实世界的多种场景中，例如社交网络中人与人之间的社交关系图、推荐系统中用户与商品的交互图等。图神经网络能捕捉节点和边的特征及其之间的拓扑关系，对图结构数据有很好的建模效果。推荐系统中常用的图神经网络模型可以分为两大类：基于图游走的方法和基于图卷积的方法。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;基于图游走的方法&lt;/strong&gt;：传统神经网络模型擅长处理欧式空间的数据，但难以建模图结构中蕴含的复杂拓扑关系。因此，早期的研究者们提出了通过游走方法从图结构数据上采样序列，然后使用传统神经网络模型处理的间接方案，其中以DeepWalk&lt;sup&gt;[1]&lt;/sup&gt;，Node2vec&lt;sup&gt;[2]&lt;/sup&gt;等工作为典型代表。如下图1所示，这类方法侧重于在图中采用既定的游走策略生成节点序列，再使用NLP领域中的Skip-Gram模型训练得到每个节点的向量表征。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;170&quot; data-ratio=&quot;0.2837559972583962&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZBC7XrYnbSPOJwu9HIHgsYlKEZwXiadtSceD67iaJllRhgp86oA2eXiaVQ/640?wx_fmt=png&quot; data-w=&quot;2918&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图1 DeepWalk模型的游走与训练流程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基于图卷积的方法&lt;/strong&gt;：从图上采样序列进行建模的方式简单直接，但由于从原始图结构到序列的转换过程中存在信息损失，其效果存在较大的局限性，因而如何将图结构直接建模到神经网络中成为了图神经网络研究的关键问题。研究者们结合谱域图上信号的傅里叶变换，定义了图上的卷积操作，并通过一系列的简化将谱图卷积和神经网络联系起来。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;2017年Thomas等人提出的GCN&lt;sup&gt;[3]&lt;/sup&gt;是其中的代表作之一。图2为图结构至单层GCN公式的演化，其中&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -979 764 979&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mover&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;41&quot; d=&quot;M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(264, 561)&quot;&gt;&lt;path data-c=&quot;7E&quot; d=&quot;M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;和&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -946 828 946&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mover&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;44&quot; d=&quot;M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(219.6, 528)&quot;&gt;&lt;path data-c=&quot;7E&quot; d=&quot;M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;分别为加入自环的邻接矩阵及节点度矩阵，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 852 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;58&quot; d=&quot;M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为图节点特征矩阵，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 1048 705&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;57&quot; d=&quot;M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为GCN模型的可训练参数，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 571 442&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C3&quot; d=&quot;M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为激活函数（&lt;/span&gt;&lt;span&gt;例如ReLU&lt;/span&gt;&lt;span&gt;），&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 888 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;48&quot; d=&quot;M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为图节点特征经过单层GCN网络后的输出特征。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;208&quot; data-ratio=&quot;0.3296551724137931&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZk8qNHdmYD28sCfpprYgZUp0nTFwfjkvUQnvY5IAKOk6gFXiczHk4Rsw/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;2900&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2 单层GCN模型的公式演化&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;GCN从整图的角度出发，打通了原始图结构和神经网络之间的壁垒，但巨大的计算量使其难以应用到大规模场景中。相比之下，GraphSAGE&lt;sup&gt;[4]&lt;/sup&gt;从图上节点的角度，提出了基于采样的消息传递范式，使得图神经网络在大规模图上的高效计算变得可行。GraphSAGE中的SAGE指 SAmple and aggreGatE，即采样和聚合。下图3展示了GraphSAGE的采样聚合过程。图中左侧展示了对节点A使用两层采样器采样其一阶和二阶邻居，图中右侧展示了将采样得到的一阶二阶邻居的特征通过对应的聚合函数进行聚合，得到节点A的表征，进而可以使用A的表征计算包括节点分类、链接预测及图分类在内的多种图相关的任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;189&quot; data-ratio=&quot;0.425569176882662&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZCC8ibuy9zqfCY8tFVyHGgaxWKRBky8fSXczDdBUSGLeYAzHicrsRYyfQ/640?wx_fmt=png&quot; data-w=&quot;2284&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3 GraphSage模型的采样及聚合过程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;GraphSAGE等基于消息传递范式的图神经网络方法，其中心节点能聚合到的特征范围取决于其采样的邻居阶数。在使用这类图神经网络训练时，除了使用节点的固有特征作为模型输入外，我们还可以给每个节点加入独立可训练的向量参数，从而更好的学习到高阶邻居的相关性。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;除了上述提到的方法外，图神经网络领域作为研究热点之一，近年来不断涌现出GAT&lt;sup&gt;[5]&lt;/sup&gt;、FastGCN&lt;sup&gt;[6]&lt;/sup&gt;、GIN&lt;sup&gt;[7]&lt;/sup&gt;等优秀算法，并在Pinterest&lt;sup&gt;[8]&lt;/sup&gt;、阿里巴巴&lt;sup&gt;[9]&lt;/sup&gt;、腾讯&lt;sup&gt;[10]&lt;/sup&gt;等公司的大规模推荐场景落地取得良好效果。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 业务场景及挑战&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;到店推荐广告业务在流量侧主要覆盖美团/大众点评双侧的信息流广告、详情页广告等多种业务场景（&lt;/span&gt;&lt;span&gt;如下图4所示&lt;/span&gt;&lt;span&gt;），供给侧包括了餐饮、丽人医美、休闲娱乐、结婚、亲子等不同广告主品类，且每一个品类下包含商户、团单、泛商品等不同的推荐候选类型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;230&quot; data-ratio=&quot;0.9092356687898089&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZdiaD5RaibiaNdNKFJHKrl3cAkRict78foIy265IgVz6g8jRBNxiaLWstiaibA/640?wx_fmt=png&quot; data-w=&quot;1256&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图4 美团到店推荐广告的主要业务场景：信息流广告（左）、详情页广告（右）&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;业务中召回模型建模面临以下两大挑战：&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a. &lt;strong&gt;同场景反馈数据稀疏&lt;/strong&gt;：传统序列行为建模方案依赖用户在同场景的反馈数据构造正负样本进行模型训练，但用户在推荐广告场景的交互行为比较稀疏，据统计超过一半的活跃用户在近90天内无广告点击行为，超过40%的广告商品在近一个月没有被点击。如何解决反馈数据稀疏导致的用户兴趣刻画不准确、长尾商品学习不充分是我们面临的一大挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b. &lt;strong&gt;LBS业务中不同时空场景下的兴趣刻画&lt;/strong&gt;：到店业务中，用户在不同时间、空间下的浏览行为，往往有着完全不同的偏好。例如一个用户工作日在公司附近，可能感兴趣的就是一次方便的工作餐；在假期的家中，则会想找一个有趣的遛娃去处。但传统的图神经网络缺乏对用户请求时间和所处位置的实时感知能力。因此如何从图蕴含的丰富信息中挖掘出匹配当前时空场景的候选集合，同样是一大挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对以上业务特点和挑战，我们设计了基于全场景数据高阶关系的大规模异构图建模，借助全场景丰富的行为数据优化稀疏问题；并进一步强化时空信息感知，刻画用户在不同时空上下文中的兴趣。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4. 图召回技术在推荐广告的演进&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1 基于全场景数据高阶关系的大规模异构图建模&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;团队之前的召回模型仅通过用户在广告场景的行为构造正负样本进行训练，这种方式提高了训练数据与预测场景的一致性，但也不可避免地产生用户兴趣刻画不准确、长尾商品推荐效果较差等问题。特别是召回作为推荐系统最上游环节，决定了全链路效果优化上限，我们期望借助图神经网络蕴含的强大表达能力，基于用户在全场景的行为数据全面刻画用户兴趣和商品信息。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如图5所示，图网络分别产出用户（&lt;/span&gt;&lt;span&gt;User&lt;/span&gt;&lt;span&gt;）和商品（&lt;/span&gt;&lt;span&gt;Item&lt;/span&gt;&lt;span&gt;）的隐式表征（&lt;/span&gt;&lt;span&gt;Embedding&lt;/span&gt;&lt;span&gt;），通过距离相似度衡量用户对候选广告的潜在兴趣。在图神经网络的选型上，我们使用带Attention结构的GAT&lt;sup&gt;[5]&lt;/sup&gt;，使得邻居信息的贡献度可以根据其对源节点的重要性自适应调节，抑制误点击等带来的噪声；使用Jumping Knowledge Network&lt;sup&gt;[11]&lt;/sup&gt;，根据节点的连接性自助调整其聚合网络范围，避免热门节点由于其广泛的连接性聚合范围过大损失了个性化信息。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;245&quot; data-ratio=&quot;0.6835016835016835&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZeX1Fn7QAYbxuSG8Kzh17Zx1YmRibOFdK0dK5wPCXs4IOXs5AUMRzz2w/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1782&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图5 基于全场景数据多阶关系的图建模&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;全场景数据建模&lt;/strong&gt;：为了全面挖掘用户的兴趣偏好，我们通过全场景行为数据构建了超大规模异构图网络进行建模。此处的全场景涵盖全业务（&lt;/span&gt;&lt;span&gt;搜索、推荐、广告&lt;/span&gt;&lt;span&gt;），全位置（&lt;/span&gt;&lt;span&gt;首页、商品详情页、团单详情页&lt;/span&gt;&lt;span&gt;）和全商品类型（&lt;/span&gt;&lt;span&gt;商户、团单、泛商品等&lt;/span&gt;&lt;span&gt;）。异构图包含用户（&lt;/span&gt;&lt;span&gt;User&lt;/span&gt;&lt;span&gt;）和商品（&lt;/span&gt;&lt;span&gt;Item&lt;/span&gt;&lt;span&gt;）两种类型节点，并通过三种类型的边进行连接：User点击Item边、Item共同点击边以及Item同店铺边。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;为了增强全场景数据蕴含的丰富信息在各个场景间有效传递，同时区分出用户在广告场景独有的兴趣特点。我们在图构建过程中将广告场景和非广告场景的同个Item建模为不同节点，共享相同的非广告特征，但带有广告标识的节点会额外增加广告专属的特征。这样模型在训练过程中既能通过共享的特征迁移非广告场景的信息，也能学习到用户在广告场景独有的兴趣偏好。图构建完成后包含数亿节点、百亿边。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;165&quot; data-ratio=&quot;0.41150442477876104&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZXnKa4zL4Vnntp8aGOLdXkGIM6zK2pfowj7alY1wPXzzo10A5WLsd3w/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1808&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图6 全场景图构建流程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;图裁剪与噪声抑制&lt;/strong&gt;：上文提到的异构图由于涵盖了用户在全场景的行为数据，数据规模庞大，给实际落地带来了巨大的算力和性能挑战。我们发现在图的拓扑结构中，各个节点的度分布极不均匀，部分热门节点的邻居个数可达几十万，由于训练过程中每个节点只采样固定个数的邻居参与计算，过多的邻居引入了许多噪声数据，也带来了不必要的资源开销。根据图数据背后的业务理解，我们对原始拓扑结构进行合理裁剪。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;具体来说：对于“User点击Item边”，保留行为时间较近的topN条出边；对于“Item共同点击边”，保留边权重较高的topN条出边。图裁剪后，节点数量保持不变，边数量减少46%，训练内存开销降低30%，并带来了约0.68%的离线Hitrate效果提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;106&quot; data-ratio=&quot;0.3580060422960725&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZKicgLfrvMIjPzlcu4AFcibdjh7ISTa8H9V6eKOdXn4faFT4qNFXwVGQQ/640?wx_fmt=png&quot; data-w=&quot;1324&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图7 图裁剪示例（设图中 a &amp;gt; b &amp;gt; c）&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;动态负样本采样&lt;/strong&gt;：由于广告商户在全体商户中占比较小，全场景行为数据的引入导致训练样本空间增大了一个数量级，这进一步加剧了SSB（&lt;/span&gt;&lt;span&gt;Sample Selection Bias&lt;/span&gt;&lt;span&gt;）问题，负样本采样策略成为影响模型效果的关键因素。常见的随机负采样方式由于Hard Negative样本量不足，导致模型在实际预测时泛化性较差。而静态负样本采样策略，例如LBS场景下常见的基于距离、类目构建负样本，虽然可以取得一定效果提升，但通用性较差，策略配置繁琐，无法根据用户兴趣迁移自适应迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以不同等级的城市为例，用户对于距离、类目的偏好程度不同，需要设置不同的阈值。因此，我们提出一种基于半监督学习的迭代式训练范式，将前一轮模型输出的商户Embedding通过KMeans进行聚类，在正样本所在的聚类集合中采样得到Hard Negative，加入到下一轮的训练样本中，依此步骤循环，引导模型不断“自我提升”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验发现，随着迭代轮次的增加，离线指标的边际收益会收窄；考虑到训练速度与收益的平衡，线上我们采用2轮迭代的方式。该优化相比随机负采样带来了约4.66%的离线Hitrate效果提升；相比静态负样本策略（&lt;/span&gt;&lt;span&gt;如基于距离、类目的采样&lt;/span&gt;&lt;span&gt;）带来了约1.63%的离线Hitrate效果提升。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;252&quot; data-ratio=&quot;0.5993690851735016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZevlLCvA1svibKibrCedbFzEnnI15ZJa7dy0vLceicUWGrPhBH7Dv1uL0w/640?wx_fmt=png&quot; data-w=&quot;1902&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图8 动态负样本采样流程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;上述3个优化点的迭代在多个主广告位落地，并在&lt;/span&gt;&lt;strong&gt;&lt;span&gt;衡量广告营收的RPS（&lt;/span&gt;&lt;span&gt;Revenue Per Search&lt;/span&gt;&lt;span&gt;）指标提升约5%~10%&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.2 强化时空信息感知的端到端异构图建模&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;在LBS的业务中，时空信息是影响用户兴趣的重要因素。用户通常具有稳定的长期兴趣，但也会受到当前时空信息影响而呈现出多变的短期兴趣。因此，我们在4.1节介绍的全场景异构图建模的基础上进行升级。根据长期兴趣稳定、短期兴趣多变的特点，我们采用针对性措施分别建模时空信息对长短期兴趣的影响。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如下图9所示，我们通过时空子图刻画用户在不同时空场景下的长期兴趣偏好，通过多因子协同激活的序列建模刻画用户在短期时空场景下的兴趣演变。值得注意的是，区别于将异构图预训练Embedding作为静态特征引入的两阶段训练方式，我们将模型各部分在相同的优化目标下进行一阶段端到端训练，避免优化目标不一致带来的效果损失。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;217&quot; data-ratio=&quot;0.5672969966629589&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZ0NOghibHZLzmoMkbKpDxuOoUCIVCmt8NdVdlzHFGPpBXeMibzsqTx1AQ/640?wx_fmt=png&quot; data-w=&quot;1798&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图9 强化时空信息感知的端到端异构图建模&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;时空子图构建及多视角融合&lt;/strong&gt;：用户在不同的时空下表现出不同的兴趣，举例来说，一个用户可能在工作日的办公室订购咖啡，而在休息日的健身房参加运动。仅使用全局视角下的图模型提取用户全局兴趣，容易丢失用户在不同时空的兴趣差异。传统图模型方案通过全局信息获得用户统一的兴趣表征，无法准确刻画用户在不同时空场景下兴趣差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业界已经出现了一些结合时空信息的图表征学习方向的研究工作，如STGCN&lt;sup&gt;[12]&lt;/sup&gt;等。在相关工作的基础上，我们从推荐广告的业务场景出发，基于用户行为对应的时间和空间信息，从时间、空间、时间&amp;amp;空间、全局等4个视角构建子图，并通过多视角融合模块获得用户长期兴趣。值得注意的是，所有子图共享Item2Item边，因为Item与Item的关系（&lt;/span&gt;&lt;span&gt;如同店铺，共同点击等&lt;/span&gt;&lt;span&gt;）较为稳定，不容易受到时空变化的影响。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如下图10所示，当用户请求到达时，从空间子图中获得用户在当前位置的兴趣，从时间子图中获得用户在多个时间的兴趣，从时间&amp;amp;空间子图中获得用户在当前位置下多个时间的兴趣，并结合全局兴趣及当前时间，进行多视角融合。在实践中，我们将时间划分为早晨、下午、晚上、深夜等4个时间段，将位置使用Geohash进行划分为多个地理区域。据统计，每个用户的历史行为涉及到的时间段和地理区域均比较集中，并不会对存储空间造成过大的压力。时空子图的构建及融合带来了约3.65%的离线Hitrate提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;150&quot; data-ratio=&quot;0.4355909694555113&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZvuOa536Ud95OqYKBfoB8Mib6yOAJMDeUhtibRp6T10Bb3FVlc8koCCyw/640?wx_fmt=png&quot; data-w=&quot;1506&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图10 多视角融合&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;多因子协同激活的用户序列建模&lt;/strong&gt;：我们将时间信息（&lt;/span&gt;&lt;span&gt;当前时间与行为序列时间的差值&lt;/span&gt;&lt;span&gt;）、位置信息（&lt;/span&gt;&lt;span&gt;当前位置与行为序列位置的差值&lt;/span&gt;&lt;span&gt;）作为激活因子来激活短期行为序列，捕捉用户兴趣随时空的迁移趋势。此外，图神经网络输出的用户长期兴趣向量，体现了用户在时间、位置等维度较稳定的兴趣偏好，也有利于从短期序列中提取出匹配当前时空场景的实时兴趣。使用时空信息及用户长期兴趣对用户短期行为序列进行激活时，涉及到多个因子协同激活的问题，业界常见的方案如下图11所示：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;167&quot; data-ratio=&quot;0.2889447236180904&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZRIRpf0j56UxwyY6qiaVziaFeUPdYfeiatxPsMACnhXXRSHR9qgxMUIpicQ/640?wx_fmt=png&quot; data-w=&quot;2388&quot;/&gt;&lt;p&gt;&lt;span&gt;图11 多因子协同激活&lt;/span&gt;&lt;/p&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在美团LBS的业务场景中，各个激活因子之间可能会相互影响，例如时间和地理位置两种激活因子对行为序列激活的侧重点存在差异。为了让多因子激活发挥最佳效果，我们结合离线指标选择“多因子融合激活”模式。多因子协同激活的用户序列建模带来了约6.90%的离线Hitrate提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，图神经网络挖掘的多阶关系能够丰富用户序列的表达。这种多阶关系不仅体现在商品和商品、用户和商品等粗粒度节点之间，也体现在时间、位置、类目等细粒度特征之间。因此，我们对特征产出流程进行了升级改造，使图神经网络中的商品节点能够与用户行为序列在特征维度共享Embedding词典，并基于统一的优化目标端到端训练，帮助细粒度多阶信息更好地在图神经网络与用户序列间传递。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;上述2个优化点的迭代在多个主广告位落地，并在&lt;strong&gt;衡量广告营收的RPS（Revenue Per Search）指标提升约5%&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5. 性能优化与应用&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;为了能够在大规模场景上线并进行实时召回，我们针对模型的离线训练和在线部署进行了优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;204&quot; data-ratio=&quot;0.2903225806451613&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZG3ibY01T59Aic6r6ibgyvK1y1wciaAqT7icaRZGp3ibrV806bdiavjZnjQDfw/640?wx_fmt=png&quot; data-w=&quot;2914&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图12 性能优化与应用&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;适配LBS场景的大规模图神经网络训练框架&lt;/strong&gt;：随着图神经网络在工业界的推广，开源社区涌现出一大批优秀的图神经网络训练框架，如Euler、DGL等。我们在开源框架的基础上，匹配公司内部大数据与机器学习平台，研发出一套适配LBS场景的大规模图神经网络训练框架。该框架支持大规模图的构建、特征抽取等构图操作，并额外开发支持了包括“位置信息动态采样”在内的常见LBS图神经网络操作。通过该框架我们已在多个业务场景落地线上模型，其中最大规模为亿级别节点、百亿级别边、带Side-information的图神经网络模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;低延迟的在线计算流程&lt;/strong&gt;：召回环节是广告推荐系统的第一个漏斗，需要在有限时间内从全量候选广告中选出高质量子集传递给下游。鉴于子图搜索、图卷积等复杂操作对线上耗时的巨大挑战，我们提出了低延迟的在线计算流程优化方案：在4.2节介绍的模型中，图模型部分主要用来表征用户长期兴趣，不受实时行为和请求信息影响，因此，我们将图节点Embedding离线计算好存入KV表中，避免图模型的在线推导成为耗时瓶颈；同时，在线请求时并行处理图节点Embedding和其它特征的抽取过程。实践表明，经过以上优化召回环节线上耗时涨幅小于2%。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6. 总结与展望&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;图神经网络对图结构的数据有很好的建模能力，能充分利用图节点的高阶邻居信息，在大规模推荐系统的召回模块中展现出巨大潜力，业界头部公司均有结合各自业务特点的图模型落地实践&lt;sup&gt;[8][9][10]&lt;/sup&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文介绍了大规模图召回技术在美团到店推荐广告的应用。基于对到店推荐广告场景特点的分析，我们在落地图召回技术时进行了对应的优化。在模型方面，为了解决广告反馈数据稀疏的问题，我们将全场景的数据融入到图模型中丰富用户兴趣表达，并结合图裁剪和动态负样本采样技术，累计提升Hitrate约5.34%；为了加强对时空等LBS动态场景信息的感知，我们通过时空子图模块刻画用户在不同时空下的兴趣，并进行多视角融合及长短期序列融合，累计提升约10.55%。配合离线训练及在线计算的性能优化，我们成功在多个主广告位上落地，线上RPS累计提升10%~15%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来我们还将在以下技术方向继续进行探索：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 多场景知识迁移&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到店广告场景众多，不同广告位维护不同的图召回模型带来的维护成本较大。多场景的联合训练既能丰富图数据，提升用户兴趣的刻画，又能将单个图召回模型应用到不同广告位，降低维护成本。但是用户在不同广告位下的行为存在差异，数据融合不当可能导致引入噪声，影响模型训练结果。如何在模型设计中刻画用户在不同广告位下行为的共同点和差异点，是需要重点考虑的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 动态图技术&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户兴趣随着时间空间不断发生着改变。动态图模型可以将时空等动态信息构建到图结构中，相比人为划分长期兴趣与短期兴趣，动态图可以更灵活地感知用户兴趣的变化，更贴合LBS业务的特点。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;7. 作者简介&lt;/span&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;齐裕、李根、少华、张腾、程佳、雷军，来自美团到店事业群/广告平台技术部。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;祥洲、梦迪、武威，来自美团平台/搜索推荐算法部NLP中心。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;8. 参考资料&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;[1] Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. &quot;Deepwalk: Online learning of social representations.&quot; Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 2014.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2] Grover, Aditya, and Jure Leskovec. &quot;node2vec: Scalable feature learning for networks.&quot; Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 2016.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[3] Welling, Max, and Thomas N. Kipf. &quot;Semi-supervised classification with graph convolutional networks.&quot; J. International Conference on Learning Representations. ICLR, 2017.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[4] Hamilton, Will, Zhitao Ying, and Jure Leskovec. &quot;Inductive representation learning on large graphs.&quot; Advances in neural information processing systems 30 (2017).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[5] Velickovic, Petar, et al. &quot;Graph attention networks.&quot; International Conference on Learning Representations. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[6] Chen, Jie, Tengfei Ma, and Cao Xiao. &quot;FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling.&quot; International Conference on Learning Representations. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[7] Xu, Keyulu, et al. &quot;How powerful are graph neural networks.&quot; International Conference on Learning Representations. ICLR, 2019.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[8] Ying, Rex, et al. &quot;Graph convolutional neural networks for web-scale recommender systems.&quot; Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp;amp; data mining. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[9] Wang, Menghan, et al. &quot;M2GRL: A multi-task multi-view graph representation learning framework for web-scale recommender systems.&quot; Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp;amp; data mining. 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[10] Xie, Ruobing, et al. &quot;Improving accuracy and diversity in matching of recommendation with diversified preference network.&quot; IEEE Transactions on Big Data (2021).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[11] Xu, Keyulu, et al. &quot;Representation learning on graphs with jumping knowledge networks.&quot; International conference on machine learning. PMLR, 2018.&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;[12] Han, Haoyu, et al. &quot;STGCN: a spatial-temporal aware graph learning method for POI recommendation.&quot; 2020 IEEE International Conference on Data Mining (ICDM). IEEE, 2020.&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;----------  END  ----------&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;团队简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;美团到店广告算法团队负责到店相关业务的广告算法优化，在保证用户体验和广告商户ROI的前提下，持续提升商业流量的变现效率。主要技术方向包括触发策略、质量预估、机制设计、创意生成、创意优选、反作弊、商家策略等。团队技术氛围浓厚，通过对前沿技术不断突破，驱动业务持续发展；重视人才培养，具备完善成熟的培养机制，帮助成员快速成长。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;美团科研合作&lt;/span&gt;&lt;/strong&gt;&lt;strong/&gt;&lt;/section&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;美团科研合作致力于搭建美团技术团队与高校、科研机构、智库的合作桥梁和平台，依托美团丰富的业务场景、数据资源和真实的产业问题，开放创新，汇聚向上的力量，围绕机器人、人工智能、大数据、物联网、无人驾驶、运筹优化等领域，共同探索前沿科技和产业焦点宏观问题，促进产学研合作交流和成果转化，推动优秀人才培养。面向未来，我们期待能与更多高校和科研院所的老师和同学们进行合作。欢迎老师和同学们发送邮件至：&lt;/span&gt;&lt;span&gt;meituan.oi@meituan.com&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;也许你还想看&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651771320&amp;amp;idx=2&amp;amp;sn=75ba87f9347f279e694cda9fc8509fad&amp;amp;chksm=bd1208f58a6581e3ef5831687327ab4a2a5a9f9d8a121ba7d5ea9cb74bd77d0a3681fca8f24f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图技术在美团外卖下的场景化应用及探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651771320&amp;amp;idx=2&amp;amp;sn=75ba87f9347f279e694cda9fc8509fad&amp;amp;chksm=bd1208f58a6581e3ef5831687327ab4a2a5a9f9d8a121ba7d5ea9cb74bd77d0a3681fca8f24f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图技术在美团外卖下的场景化应用及探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;图技术在美团外卖下的场景化应用及探索&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt;&lt;/span&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651768703&amp;amp;idx=1&amp;amp;sn=07892efc82a88db2320588128ef7557a&amp;amp;chksm=bd121e328a6597244f0956d572b165c0f995930b5db40ec3b28e4fed1d51d05409cfacb3e157&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团图神经网络训练框架的实践和探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团图神经网络训练框架的实践和探索&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651753013&amp;amp;idx=1&amp;amp;sn=695f259b1235fcc9e878196377319532&amp;amp;chksm=bd1253788a65da6e3af981aa287a5f47178bfcef480d50b2d44fe5c20cea9842d08ed86581e4&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;KDD Cup 2020 自动图学习比赛冠军技术方案及在美团广告的实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;KDD Cup 2020 自动图学习比赛冠军技术方案及在美团广告的实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阅读更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765958&amp;amp;idx=1&amp;amp;sn=8201546812e5a95a2bee9dffc6d12f00&amp;amp;chksm=bd12658b8a65ec9de2f5be1e96796dfb3c8f1a374d4b7bd91266072f557caf8118d4ddb72b07&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;前‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;前端&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt; &lt;/strong&gt; &lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765981&amp;amp;idx=1&amp;amp;sn=c2dd86f15dee2cbbc89e27677d985060&amp;amp;chksm=bd1265908a65ec86d4d08f7600d1518b61c90f6453074f9b308c96861c045712280a73751c73&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;算‍法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;算法&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765982&amp;amp;idx=1&amp;amp;sn=231b41f653ac7959f3e3b8213dcec2b0&amp;amp;chksm=bd1265938a65ec85630c546169444d56377bc2f11401d251da7ca50e5d07e353aa01580c7216&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;后‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;后端&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765964&amp;amp;idx=1&amp;amp;sn=ab6d8db147234fe57f27dd46eec40fef&amp;amp;chksm=bd1265818a65ec9749246dd1a2eb3bf7798772cc4d5b4283b15eae2f80bc6db63a1471a9e61e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数‍据&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;数据&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765965&amp;amp;idx=1&amp;amp;sn=37e0c56c8b080146ce5249243bfd84d8&amp;amp;chksm=bd1265808a65ec96d3a2b2c87c6e27c910d49cb6b149970fb2db8bf88045a0a85fed2e6a0b84&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;安‍全&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;安全&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765972&amp;amp;idx=1&amp;amp;sn=afe02ec92762c1ce18740d03324c4ac3&amp;amp;chksm=bd1265998a65ec8f10d5f58d0f3681ddfc5325137218e568e1cda3a50e427749edb5c6a7dcf5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;And‍roid&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;Android&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765973&amp;amp;idx=1&amp;amp;sn=32a23bf1d278dda0398f993ab60a697e&amp;amp;chksm=bd1265988a65ec8e630ef4d24b4946ab6bd7e66702c1d712481cf3c471468a059c470a14c30d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;iO‍S&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;iOS&lt;/a&gt;&lt;span&gt; &lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765963&amp;amp;idx=1&amp;amp;sn=a3de9ef267d07d94118c1611776a4b28&amp;amp;chksm=bd1265868a65ec906592d25ad65f2a8516338d07ec3217059e6975fc131fc0107d66a8cd2612&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;运‍维&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;运维&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765974&amp;amp;idx=1&amp;amp;sn=763c1e37d04acffd0142a2852ecfb000&amp;amp;chksm=bd12659b8a65ec8dfcfeb2028ef287fae7c38f134a665375ba420556ce5d2e4cf398147bd12e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测‍试&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;测试&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5NjQ5MTI5OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVGibnsaEib3aNlqF0tOrA2RGEmNSbia2nnohE4Tpf95UyTiaSjDVbHRfY8WNBeTuLLTaVdSckkNyEx1Q/0?wx_fmt=png&quot; data-nickname=&quot;美团技术团队&quot; data-alias=&quot;meituantech&quot; data-signature=&quot;10000+工程师，如何支撑中国领先的生活服务电子商务平台？数亿消费者、数百万商户、2000多个行业、几千亿交易额背后是哪些技术在支撑？这里是美团、大众点评、美团外卖、美团配送、美团优选等技术团队的对外窗口。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e2b0d2f163e2a98db100c03aee26fbdd</guid>
<title>MySQL 数据库索引技术原理初探</title>
<link>https://toutiao.io/k/vwg43on</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;article fmt article-content &quot;&gt;&lt;h2&gt;概述&lt;/h2&gt;&lt;h3&gt;什么是索引&lt;/h3&gt;&lt;p&gt;一本书 500 页的书，如果没有目录，直接去找某个知识点，可能需要找一会儿，但是借助前面的目录，就可以快速找到对应知识点在书的哪一页。这里的目录就是索引。&lt;/p&gt;&lt;p&gt;所以，为什么会有索引？为了提高数据查询效率。&lt;/p&gt;&lt;h2&gt;常见索引算法&lt;/h2&gt;&lt;p&gt;最简单也最容易想到的索引算法就是有序数组了，我们创建一个数组，数组按照顺序排列，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912713&quot; alt=&quot;img&quot; title=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们要查找某一条记录，使用二分法就可以快速得到(log N)，从图中我们可以看出，有序数组作为索引时，处理等值查询和范围查询时性能会非常优秀。既然这么优秀，为什么我们不使用它呢？&lt;/p&gt;&lt;p&gt;因为它的插入性能很差，每次往中间插入一条记录，就必须挪动后面所有的记录，这个成本太高了。&lt;/p&gt;&lt;p&gt;第二种算法时哈希表，哈希表时一种 KV 形式存储的数据结构，比如我们平时用的 HashMap。哈希表的思路非常简单，用一个哈希函数把Key 换算成一个确定的位置，把 V 放到这个位置就可以了。&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912714&quot; alt=&quot;img&quot; title=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们可以看得出，哈希表这种数据结构在进行等值查询的时候，效率时非常高的，我们常用的 Redis 以及以前比较流行的 Memcached 都使用了哈希表。但是哈希表有个致命缺陷，就是对范围查询的支持性非常差，因为数据的存储时无序的，无论我们要查询的范围有多大，都必须把所有的数据全部便利一遍做个排序才行。&lt;/p&gt;&lt;p&gt;在讲第三种索引方式之前，我们简单了解下机械硬盘存取数据的原理&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912715&quot; alt=&quot;image-20210326092749979&quot; title=&quot;image-20210326092749979&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;要访问磁盘上的某个条数据，我们需要通过磁道，扇区来确定数据所在的 Block，然后通过 Offset  就可以定位到磁盘上的任意一个字节。从磁盘上读取数据时，都是以 Block 的形式读取的。这里我们可以看到，一个 Block 的大小是 512 Bytes，当然，这是针对磁盘设备的，对于 Linux 的文件系统来说，一个 Block 一般是 4KB。InnoDB 数据存取是以数据页为单位的，数据页相比磁盘 Block 要大一些，一般默认是 16KB。为了简化整个模型，我们这里抛开复杂的数据页或者文件系统 Block 概念，从磁盘的 Block 开始说起&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912716&quot; alt=&quot;image-20210326092835533&quot; title=&quot;image-20210326092835533&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;假设我们的数据库里面存储了 1000 条记录，每条记录占用 128 Bytes，前面我们说过，一个磁盘的 Block 能够存储 512 Bytes，也就是说，一个 Block 可以存储 4 条记录，存储这些记录，一共需要 250 个 Blocks。当我们需要查询一条数据时，最多需要从磁盘加载 250 个Blocks，想想读取 250 次磁盘会有多慢！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912717&quot; alt=&quot;image-20210326092923323&quot; title=&quot;image-20210326092923323&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;为了减少对磁盘的访问次数，我们可以把所有记录的 id 单独拿出来创建一个索引 L1，这个 id 和指向原始数据的地址组成了一个新的数据结构，它的长度这里是 16 Bytes，索引也是需要存储到磁盘的，一个 Block 可以存储 32 条索引记录，1000条索引记录需要 （1000/32=31.25） 32 个 Blocks。这时候我们需要查询一条数据时，就变成了先从索引表中查询出对应数据的指针（读取 32 个 Blocks），然后再去源数据表中根据地址直接读取记录所在的数据块（1个Block）。看，通过增加一个索引，我们成功的将磁盘读取次数从 250 次减少到了 33 次。我们可不可以让读取磁盘次数更少呢，当然可以！再增加一级索引呗！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912718&quot; alt=&quot;image-20210326093000953&quot; title=&quot;image-20210326093000953&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;新添加的这一级索引指向了前面我们添加的索引 L1 所在的数据块。在这一级索引上，每一条记录都对应了 L1 索引所在的数据块，也就是 32 条L1索引记录所在的位置。1000条数据在这里还剩多少呢，前面我们说过，1000条数据共需要 32 个 L1 索引 Block，对应在这里也就是需要 32 条 L2 索引，总空间占用才 32x16 = 512 Bytes，刚好一个磁盘 Block 大小。到这一级，我们需要访问磁盘的次数就变成了 1+1+1=3 了！&lt;/p&gt;&lt;p&gt;我们把上面这个图抽象一下，去掉其中的细节，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912719&quot; alt=&quot;image-20210326093031086&quot; title=&quot;image-20210326093031086&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;当我们把它旋转一下的时候，我们就得到了这样一种数据结构&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912720&quot; alt=&quot;image-20210326093055460&quot; title=&quot;image-20210326093055460&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;看！这不就是一棵树嘛&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912721&quot; alt=&quot;image-20210326104832514&quot; title=&quot;image-20210326104832514&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;说到树，我们知道最简单的就是二叉树了，二叉树的典型特点是有序，左子树小于父节点，右子树大于父节点。无论是搜索效率还是插入效率，二叉树的效率都是非常高的（log N），但是大多数数据库并不使用它，这是为什么呢？&lt;/p&gt;&lt;p&gt;因为我们的数据是存储在磁盘上的，程序运行过程中要使用数据，必须从磁盘把数据加载到内存才行。二叉树随着节点的增多，树的高度页越来越高，对应到磁盘访问上，我们就需要访问更多的数据块。当我们的数据存储在机械硬盘的时候，从磁盘随机读取一个数据块就需要 10ms 左右的寻址时间，也就是说，如果我们扫描一个 100 万行的表，单独访问一行就可能需要 20 个 10ms，可想可知这个查询会有多慢！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912722&quot; alt=&quot;_images/binary-tree.png&quot; title=&quot;_images/binary-tree.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;当然，我们这棵树可不是二叉树，因为每个分支都可能有很多条记录。我们把这种树称为 N 叉树，也就是多叉树，树的分叉越多，每个节点的子节点就越多，树的高度就越低。因此就有B-Tree 和 B+Tree。&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912723&quot; alt=&quot;Image 1&quot; title=&quot;Image 1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;h2&gt;B+Tree 索引&lt;/h2&gt;&lt;p&gt;讲到 B+ 树索引，我们就不得不一下 B 树索引，前面我们简单了解了下二叉树，我们知道，二叉树的树高太大，会严重影响查询效率，为了解决这个问题，就有了 B 树&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912724&quot; alt=&quot;索引&quot; title=&quot;索引&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;B树是为了更好的实现索引结构而被创造出来的，它大幅度减少了磁盘访问的次数。除此之外，它还充分利用了“局部性原理”（数据有序，相关性强）。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;局部性原理：在一段时间内，整个程序的执行仅限于程序的某一部分，相应的，执行所访问的存储空间也局限于某个内存区域。局部性原理分为时间局部性和空间局部性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;时间局部性：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）&lt;/li&gt;&lt;li&gt;空间局部性：如果一个存储器的位置被引用，那么将来它附近的位置也会被引用&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;利用局部性原理可以实现磁盘预读，前面提过，InnoDB一次是读取一页的数据（16K），也就是说，每次我们实际加载的数据比我们需要的可能会多一些，这些数据可以缓存在内存中，未来我们需要读取的时候，就可以避免磁盘 IO 了。&lt;/p&gt;&lt;p&gt;但是B树有着下面两个缺陷&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个节点都存储数据，因此索引会变得很大，每个 Block 能够容纳的索引数就会变少，我们也就需要访问更多次的磁盘&lt;/li&gt;&lt;li&gt;对范围查询支持不是很好，需要中序遍历&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这两个问题，B+ 树就诞生了，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912725&quot; alt=&quot;索引&quot; title=&quot;索引&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;B+树只有叶子节点才存储数据，其它节点不再存储数据，所有的叶子节点都在同一层上，叶子节点之间增加了一条链表，通过这条链表，我们就可以依次直接遍历所有数据。这些变化，让 B+ 树拥有了比 B 树更优秀的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;非叶子节点不存储数据，可以实现查询加速（一次磁盘访问可以读取更多的索引记录，减少磁盘访问）&lt;/li&gt;&lt;li&gt;范围查询更加优秀，可以顺着叶子节点的链表直接查询出某一个范围内的数据&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;B+数是一棵 N 叉树，N 的大小取决于索引字段的大小，以整数字段索引为例，N≈1200，当树高为 4 的时候，就是 1200 的 3 次方，17亿。一个 10 亿行的表上一个整数字段索引，查找一个值最多只需要访问 3 次磁盘（树根一般在内存中）。&lt;/p&gt;&lt;p&gt;MySQL 的 InnoDB 就是采用了 B+ 树作为默认的索引算法，前面我们说了，B+树只在叶子节点存储数据，但是这个叶子节点存储的是什么数据呢? 我们根据叶子存储数据类型的不同分为两种索引&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主键索引，也成为聚簇索引（Clustered index），在叶子节点存储的是整行数据&lt;/li&gt;&lt;li&gt;非主键索引，也成为二级索引（Secondary index），叶子节点存储的是主键的值&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912726&quot; alt=&quot;image-20210326115557786&quot; title=&quot;image-20210326115557786&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;正因为在 InnoDB 中，我们的数据也是存储在一个索引（主键索引）里的，因此，我们称 InnoDB 是索引组织表。二级索引存储的是数据的主键，当我们使用二级索引查询一条数据的时候，首先会从二级索引中查询到这条记录的 ID，然后拿这个 ID 去主键索引查询真正的数据，我们称这个过程为 回表。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;因为二级索引存储的是主键的 ID，因此通常我们会选择 integer 或者 bigint 等整型类型作为主键，这样做的目的是可以减少二级索引占用空间的大小。如果用字符串作为主键，可想可知二级索引会有多大！&lt;/p&gt;&lt;p&gt;除了上面这个外，通常要求主键一定是要自增的，这样做是为了保证主键的有序，每次插入数据都是追加到 B+ 树，避免页分裂（如果数据页满了，则需要申请新的数据页，然后挪动部分数据过去，这个过程叫做 页分裂）的产生，提高数据写入性能。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;从上面讲的这些，我们可以想到下面几个优化索引的技巧&lt;/p&gt;&lt;ul&gt;&lt;li&gt;索引应该尽可能小，这样一次磁盘读取可以返回尽可能多的索引数据，在查询数据时就可以减少磁盘 IO&lt;/li&gt;&lt;li&gt;大表查询尽可能的使用索引，不使用索引就会造成全表扫描，想想一个查询，需要遍历几百万数据，读取成千上百次磁盘会有多慢&lt;/li&gt;&lt;li&gt;如果可能，尽量使用主键索引进行查询，使用主键索引可以直接触达数据，不需要执行回表，减少磁盘 IO&lt;/li&gt;&lt;li&gt;如果索引中包含了我们要查询的所有字段，那就不需要在进行回表，可以减少磁盘 IO，显著提升查询性能，我们把这种查询数据都在索引里面的情况叫做覆盖索引&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;这次分享中，我们先简单介绍了下两种简单的索引结构，然后从数据在磁盘的存储说起，从没有索引到建立多级索引，解释了为什么会出现树索引以及B树索引和 B+树索引，最后我们介绍了下 InnoDB 中关于主键索引和二级索引的概念和几个优化索引的技巧。&lt;/p&gt;&lt;p&gt;本文将会持续修正和更新，最新内容请参考我的 &lt;a href=&quot;https://link.segmentfault.com/?enc=EEqu1wvH%2Bicw4Q6AlzddVA%3D%3D.J3iqbgU3haTK5wpWhmTxI7dqua4Pwc7s3oeqlTLvNDI%3D&quot; rel=&quot;nofollow&quot;&gt;GITHUB&lt;/a&gt; 上的 &lt;a href=&quot;https://link.segmentfault.com/?enc=5XUVTlPU%2BCMk3No7yYyR2w%3D%3D.5hT6Tiz1beWVXmGt0TPUR0Lfncq14kHMJdDcKSkYR%2BpNMbCKsCYCdky%2BhAZiHRmE&quot; rel=&quot;nofollow&quot;&gt;程序猿成长计划&lt;/a&gt; 项目，欢迎 Star，更多精彩内容请 &lt;a href=&quot;https://link.segmentfault.com/?enc=xgvnO08KYatQ5F%2BWWsgYLQ%3D%3D.ciNNSwwnGpG%2Bif6gFWbeO4g1mpz532Li4581ugY9jPY%3D&quot; rel=&quot;nofollow&quot;&gt;follow me&lt;/a&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fa3bad23df8894b5b20cedae6c83eb0d</guid>
<title>Go 凭什么搞特殊？不用 yyyy-mm-dd，非得要 2006-01-02 15:04:05</title>
<link>https://toutiao.io/k/nudjgh2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是煎鱼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前段时间我写了一篇《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUxMDI4MDc1NA==&amp;amp;mid=2247497592&amp;amp;idx=1&amp;amp;sn=bdfd41f5dfaa6a15dc3bec9ec0973a04&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Go1.20 中两个关于 Time 的更新，终于不用背 2006-01-02 15:04:05 了！&lt;/a&gt;》，文中有提到 Go 的参考时间格式是：2006-01-02 15:04:05，并解释这么设计的缘由。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有很多同学表示不解。如下图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8154362416107382&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4iaiaPbjOvmGIPiagtba1cbEYvXyibibYhVu6LhnrW9bJ8387TKYLO1WyspXh9qKuGC0OUe14UeUTRgiavQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;596&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;甚至我在点外卖时还特意看了，某团在个人信息页中的生日那一栏，是如此显示的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.21965317919075145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4iaiaPbjOvmGIPiagtba1cbEYvia2rn7dia5ibmGfLWF7ibbMSAEmVR2Pfib0V78Ye5kicaDUlQ7sDXKCQeHZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;692&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那熟悉的 yyyy-mm-dd。我甚至一度怀疑这是不是彩蛋，这可能只有程序员懂？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ISO 8601 规范&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尤其是有提到 ISO 8601，这是一个国际标准化组织提供的一个有关时间表示的规范，其中我们最为熟悉的是日期表示法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体介绍摘抄自网络，如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;YYYY-MM-DDThh:mm:ss[.mmm]TZD&lt;br/&gt;2022-11-18T10:05:45+08:00&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;YYYY：四位数年份，不全补齐。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MM：月份、两位，不全补齐。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;DD：两位数的天(day of the month)，01~31。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;T：指示时间元素的开始字符。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;hh：两位数的小时，00~23。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;mm：两位数的分钟，00~59。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ss：两位数的秒，00~59。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;mmm：三位数的毫秒，000~999。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;TZD：时区指示符：Z 或 +hh:mm 或 -hh:mm，+ 或 - 表示时区距离 UTC 时区多久。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么这么特别&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们之前的文章都在介绍 2006-01-02 15:04:05 这个时间点代表的含义是什么，代表什么意思：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Jan 2 15:04:05 2006 MST&lt;br/&gt;1   2  3  4  5    6  -7&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这有一个大大的问题，那就是 Go 为什么不遵守 ISO 8601 规范，非得用这个？这莫非是一种新的创新...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我猛翻后，找到了在对标准化辩解的背后。实际上 @Rob Pike 在 2014 年在《&lt;span&gt;What is the reason behind time.Parse using a reference time?&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;》进行了解释，说明为什么会选择这个时间点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.162&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4iaiaPbjOvmGIPiagtba1cbEYveXMjSJt6gsTNDvjhbFPK2bbxXJmCWmU1OGDzVqcHaJGMibgic5kK8mXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2000&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“&lt;strong&gt;这个选择是由我的 Unix 机器上的 date 命令的输出所决定的&lt;/strong&gt;。我应该意识到格式会随着地区的不同而变化。错了。但我仍然可以说它很容易记住，并且有据可查。”&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是原因。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么那么难受&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家一开始可能以为只有我们用的比较变扭？但其实不止，各地的人都拥到了社区里反馈过这个问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;归根到底还是世界各地用的时间格式不一样，而 Go 这里根据 Rob 的反馈，实际上它只是以某国为时间中心的 “随机” 格式，对应的就是 “1 2 3 4 5 6 7”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：“Jan 2 3:04 pm 06 -0700”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所代表的意义：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Jan：第一个月&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2：第二天&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3：下午 3 点&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4：第 4 分钟&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;5：第 5 秒&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;6：本世纪第 6 年&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;7：比格林威治标准时间晚 7 小时。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看起来很有规律，但...&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 的这一项时间规范选择，是比较特殊的。很多同学希望他 “改邪归正”，用回 &lt;span&gt;yyyy-mm-dd&lt;/span&gt;，别再用 2006-01-02 15:04:05 了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这显然不现实，首先是 Go1 兼容性不允许，其次一山不能容二虎，加估计都没法加。这件事已成定局。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;建议还是记好 Go1.20 要新增的 3 个常量，这个以后不用去背和查了。如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;DateTime   = &lt;span&gt;&quot;2006-01-02 15:04:05&quot;&lt;/span&gt;&lt;br/&gt;DateOnly   = &lt;span&gt;&quot;2006-01-02&quot;&lt;/span&gt;&lt;br/&gt;TimeOnly   = &lt;span&gt;&quot;15:04:05&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个比较现实。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个设计，我认为是技术债务了。将会持续陪伴 Go1 终身，你我皆为局中人。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go2 有戏更正吗？暂未看到。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;推荐阅读&lt;/h4&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;What is the reason behind time.Parse using a reference time?: &lt;em&gt;https://groups.google.com/g/golang-nuts/c/0nQbfyNzk9E/m/LWbMgpRQNOg&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关注和加煎鱼微信，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一手消息和知识，拉你进技术交流群&lt;span&gt;&lt;span&gt;👇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9988738738738738&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KVl0giak5ib4jVkzHVvaqjo3O0BIqDRJKkEyib7SJsryxHBFGsvek0FkdiczfJP6AdbWnK25DvlX3dY8wRObPbVJQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;888&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07106598984771574&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/486RHs1WbcgGib6o96dHbvGUGGwPicd8wusUGH1cXR29tM4bO0lNzialzkQhvU6m5ZUdaKibmcF2OQayjMe9Bia6iaXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;394&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是煎鱼，&lt;span&gt;出版过 Go 畅销书《Go 语言编程之旅》，再到获得 GOP（Go 领域最有观点专家）荣誉，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxMDI4MDc1NA==&amp;amp;mid=2247483854&amp;amp;idx=1&amp;amp;sn=ec422fbf4d846975f2930ddeb5e81373&amp;amp;chksm=f9041493ce739d85a4b987eece14da627206cdad798f645cc770868312e4a22b6df24804f186&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;点击蓝字查看我的出书之路&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;点击蓝字查看我的出书之路&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;日常分享高质量文章，输出 Go 面试、工作经验、架构设计，&lt;span&gt;加微信拉读者交流群，和大家交流！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>