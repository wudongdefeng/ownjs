<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>b92b914eb9627e712ba8345afd3e066a</guid>
<title>优质网站同好者周刊（第 111 期） | 倾城博客</title>
<link>https://toutiao.io/k/g1765df</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;content&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/?utm_source=weekly&quot;&gt;倾城之链&lt;/a&gt;作为一个开放平台，旨在云集全球&lt;strong&gt;优秀网站&lt;/strong&gt;，探索互联网中更广阔的世界。此周刊，将汇聚过去一周&lt;a href=&quot;https://nicelinks.site/?utm_source=weekly&quot;&gt;倾城&lt;/a&gt;所收录的内容，以飨同好；欢迎推荐或自荐（仅限有独立域名的网站，可以是二级域名）。您如果要了解收录要求，请参见&lt;a href=&quot;https://nicelinks.site/about?utm_source=weekly&quot;&gt;关于倾城&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;备注&lt;/strong&gt;：本周刊&lt;strong&gt;每周五&lt;/strong&gt;生成，首发于个人微信公众号&lt;a href=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI5MDIwMzM2Mg==&amp;amp;action=getalbum&amp;amp;album_id=1530765143352082433&amp;amp;scene=173&amp;amp;from_msgid=2650641087&amp;amp;from_itemidx=1&amp;amp;count=3#wechat_redirect&quot;&gt;晚晴幽草轩&lt;/a&gt;、博客&lt;a href=&quot;https://www.jeffjade.com&quot;&gt;晚晴幽草轩&lt;/a&gt;，以及&lt;a href=&quot;https://forum.lovejade.cn/&quot;&gt;悠然宜想亭&lt;/a&gt;社区；此一键生成脚本基于 &lt;a href=&quot;https://nicelinks.site/post/602d30aad099ff5688618591&quot;&gt;Deno&lt;/a&gt; 编写，并在 Github 开源：&lt;a href=&quot;https://github.com/nicejade/nicelinks-weekly&quot;&gt;nicejade/nicelinks-weekly&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E7%BB%84%E4%BB%B6&quot;&gt;&lt;code&gt;组件&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/Svelte&quot;&gt;&lt;code&gt;Svelte&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/Markdown&quot;&gt;&lt;code&gt;Markdown&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Combine svelte and markdown in the same file. Live your dreams!&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/mdsvex.com.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - mdsvex - markdown in svelte!&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://mdsvex.com/&quot;&gt;MDSvex&lt;/a&gt; 是一个基于 &lt;a href=&quot;https://nicelinks.site/tags/Markdown&quot;&gt;Markdown&lt;/a&gt; 和 &lt;a href=&quot;https://nicelinks.site/tags/Svelte&quot;&gt;Svelte&lt;/a&gt; 技术栈的工具，可以将 Markdown 文档转换为可交互的组件化 UI。该工具允许开发者以类似于编写 React 组件的方式编写 Markdown 文件，并支持在 Markdown 中嵌入 Svelte 组件。MDSvex 的主要特点如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;基于 Markdown&lt;/strong&gt;：MDSvex 使用 Markdown 作为文档格式，并支持 GitHub Flavored Markdown 标准。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;支持 Svelte 组件&lt;/strong&gt;：开发者可以在 Markdown 中嵌入 Svelte 组件，并通过 props 实现组件之间的数据传递和状态管理。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;可交互性&lt;/strong&gt;：由于 MDSvex 可以将 Markdown 转换为组件化 UI，因此可以实现更加丰富和动态的用户交互体验。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;灵活性&lt;/strong&gt;：MDSvex 支持自定义配置和插件，可以根据项目需求进行灵活扩展和定制化。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/redirect?url=https://mdsvex.com/&quot;&gt;MDSvex&lt;/a&gt; 基本上是 Svelte 的 &lt;a href=&quot;https://nicelinks.site/post/63e4e3eee63ccd089dee6686&quot;&gt;MDX&lt;/a&gt; ，允许您在 markdown 中使用 Svelte 组件，或在 Svelte 组件中使用 markdown。mdsvex 支持所有 Svelte 语法和_几乎_所有 markdown 语法。有关详细信息，请参阅 &lt;a href=&quot;https://mdsvex.com/docs/#limitations&quot;&gt;限制&lt;/a&gt; ，下面是使用示例：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot;&gt;&amp;lt;script&amp;gt;
    import { Chart } from &quot;../components/Chart.svelte&quot;;
&amp;lt;/script&amp;gt;

# Here’s a chart
The chart is rendered inside our MDsveX document.

&amp;lt;Chart /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;近期有基于 &lt;a href=&quot;https://nicelinks.site/post/62a9c2ad90509e23cea772c0&quot;&gt;Svelte&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/post/5fd20cb4c06d6302c1907ec7&quot;&gt;TailwindCSS&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/post/6010e1b10c71de1fb957b64e&quot;&gt;Vite&lt;/a&gt; 开发一款 &lt;a href=&quot;https://nicelinks.site/tags/ChatGPT&quot;&gt;ChatGPT&lt;/a&gt; 相关的 Web 应用： &lt;a href=&quot;https://chatgpt.nicelinks.site/&quot;&gt;素问智聊斋&lt;/a&gt; ；其中 &lt;a href=&quot;https://chatgpt.nicelinks.site/#/about&quot;&gt;关于&lt;/a&gt; 、 &lt;a href=&quot;https://chatgpt.nicelinks.site/#/sponsor&quot;&gt;赞助&lt;/a&gt; 等页面，基于 Markdown、 &lt;a href=&quot;https://nicelinks.site/post/5fd20cb4c06d6302c1907ec7&quot;&gt;TailwindCSS&lt;/a&gt; 、和 &lt;a href=&quot;https://nicelinks.site/redirect?url=https://mdsvex.com/&quot;&gt;MDSvex&lt;/a&gt; 来开发，配置简单，效率贼高，效果很棒，体验极好；颇为赞叹。下面是 Sponsor（赞助）页面的代码：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot;&gt;&amp;lt;script&amp;gt;
import Sponsor from &#x27;./../markdown/Sponsor.md&#x27;
&amp;lt;/script&amp;gt;

&amp;lt;div class=&quot;flex-col justify-between mx-auto my-4 prose page-warpper lg:prose-xl md:prose-sm&quot;&amp;gt;
  &amp;lt;Sponsor /&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用 MDSvex 可以帮助开发者快速构建可交互的文档和演示页面，同时&lt;strong&gt;提高开发效率&lt;/strong&gt;和&lt;strong&gt;代码复用性&lt;/strong&gt;，强烈推荐；该项目在 &lt;a href=&quot;https://github.com/pngwn/mdsvex&quot;&gt;Github 开源&lt;/a&gt; ，感兴趣的朋友可移步以了解更多。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/642598ca2d6c9c63445c8862&quot;&gt;倾城之链 - mdsvex - markdown in svelte!&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E7%BC%96%E8%BE%91%E5%99%A8&quot;&gt;&lt;code&gt;编辑器&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/AI&quot;&gt;&lt;code&gt;AI&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/ChatGPT&quot;&gt;&lt;code&gt;ChatGPT&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Refactor, understand, and write code effortlessly with Cursor.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/www.cursor.so.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - Cursor | Build Fast&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://www.cursor.so/&quot;&gt;Cursor&lt;/a&gt; 是一款专为 &lt;a href=&quot;https://nicelinks.site/tags/AI&quot;&gt;AI&lt;/a&gt; 编程而生的编辑器，配置非常简单，因为内置了 &lt;a href=&quot;https://nicelinks.site/tags/ChatGPT&quot;&gt;ChatGPT&lt;/a&gt; 的能力，所以下载即用，通过 &lt;code&gt;Ctrl+k&lt;/code&gt; 调出对话框进行会话，输入 prompts 即可得到结果。现在 cursor 还处于早期阶段，但现在它可以帮助您做一些事情，诸如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;编写&lt;/strong&gt;：使用比 Copilot 更智能的 AI 生成 10-100 行代码；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Diff&lt;/strong&gt;：要求 AI 编辑一段代码，只查看建议的更改；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;聊天&lt;/strong&gt;：了解您当前文件的 ChatGPT 风格界面；&lt;/li&gt;&lt;li&gt;&lt;strong&gt;还有更多&lt;/strong&gt;：要求修复 lint 错误，在悬停时生成测试/评论等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实际体验，当输入 prompts 进行会话时，它要求登录从而使用 AI 功能，理由是避免滥用它们后台；当然，Cursor 有其 AI 提供了另一种方式，即需要用户输入自己的 Open API key。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/post/5af55777979f626ea3d37917&quot;&gt;VSCode&lt;/a&gt; 有提供名为 CodeGPT 的扩展，也是需要用户输入 &lt;code&gt;OpenAI API&lt;/code&gt; 密钥，才能使用；有感兴趣的网友，对两者进行了测试，认为 Cursor 的体验要略胜一筹。毫不疑问，如今的 AI 已强大非常，可以帮各种用户做更多工作；推荐有条件的朋友，可以用起来，以提升效率、节省时间、启发灵感。如果您对 Cursor 感兴趣，可移步至 &lt;a href=&quot;https://github.com/getcursor/cursor&quot;&gt;Github 开源仓库&lt;/a&gt;从而了解更多。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/642573d62d6c9c63445c835c&quot;&gt;倾城之链 - Cursor | Build Fast&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93&quot;&gt;&lt;code&gt;数据库&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E6%90%9C%E7%B4%A2&quot;&gt;&lt;code&gt;搜索&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/AI&quot;&gt;&lt;code&gt;AI&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/weaviate.io.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - Welcome | Weaviate - vector database&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 是一个基于向量搜索 (vector search) 和自然语言处理 (NLP) 技术的开源向量数据库。它不仅可以存储、管理和查询向量，还可以自动学习向量之间的关系和上下文，从而支持更智能的搜索和推荐。Weaviate 具有如下功能特征：&lt;/p&gt;&lt;h3 id=&quot;矢量搜索&quot;&gt;&lt;a href=&quot;#%E7%9F%A2%E9%87%8F%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;矢量搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;矢量搜索&lt;/h3&gt;&lt;p&gt;无论您是自带向量还是使用其中一个向量化模块，您都可以为数十亿个数据对象建立索引以进行搜索。&lt;/p&gt;&lt;h3 id=&quot;混合搜索&quot;&gt;&lt;a href=&quot;#%E6%B7%B7%E5%90%88%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;混合搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;混合搜索&lt;/h3&gt;&lt;p&gt;结合多种搜索技术，例如基于关键字的搜索和矢量搜索，以提供最先进的搜索体验。&lt;/p&gt;&lt;h3 id=&quot;生成搜索&quot;&gt;&lt;a href=&quot;#%E7%94%9F%E6%88%90%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;生成搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;生成搜索&lt;/h3&gt;&lt;p&gt;通过 GPT-3 等 LLM 模型输送搜索结果来改进您的搜索结果，以创建下一代搜索体验。&lt;/p&gt;&lt;h3 id=&quot;超越搜索&quot;&gt;&lt;a href=&quot;#%E8%B6%85%E8%B6%8A%E6%90%9C%E7%B4%A2&quot; aria-label=&quot;超越搜索 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;超越搜索&lt;/h3&gt;&lt;p&gt;Weaviate 支持闪电般快速的矢量搜索，但它的功能远不止于此。它的其他一些超能力包括推荐、总结以及与神经搜索框架的集成。&lt;/p&gt;&lt;p&gt;官方网站 &lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 提供了丰富的文档资料、教程和示例代码，可以帮助开发者更好地理解和使用 Weaviate。同时，官网还提供了 Weaviate Playground 工具，可以在线试用和体验 Weaviate 的功能和接口。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 的应用场景非常广泛，可以用于各种不同的领域，如企业搜索、医疗健康、金融服务、新闻媒体等。它可以帮助企业和机构快速地找到所需的信息和数据，提高工作效率和准确率。同样地，在医疗和健康领域，它可以帮助医生和研究人员快速地查找和分析相关文献和数据，支持疾病预防和诊断。&lt;/p&gt;&lt;p&gt;总之， &lt;a href=&quot;https://nicelinks.site/redirect?url=https://weaviate.io/&quot;&gt;Weaviate&lt;/a&gt; 提供了丰富的文档和的资源，帮助用户更好地理解 Weaviate 数据库的功能和优势，从而支持开发者快速构建智能应用，提高数据查询和处理的准确率。同时，由于 Weaviate 是开源项目，用户可以在 &lt;a href=&quot;https://github.com/weaviate/weaviate&quot;&gt;GitHub 上获取其源代码&lt;/a&gt; ，并对其进行自定义和扩展。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/6422e0762d6c9c63445c73ed&quot;&gt;倾城之链 - Welcome | Weaviate - vector database&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/JavaScript&quot;&gt;&lt;code&gt;JavaScript&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%B7%A5%E5%85%B7&quot;&gt;&lt;code&gt;工具&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91&quot;&gt;&lt;code&gt;前端开发&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;JavaScript Obfuscator is a free online tool that obfuscates your source code, preventing it from being stolen and used without permission.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/obfuscator.io.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 - JavaScript Obfuscator Tool&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://obfuscator.io/&quot;&gt;JavaScript Obfuscator Tool&lt;/a&gt; ，是一个在线代码混淆工具，免费且高效；它可以将 &lt;a href=&quot;https://nicelinks.site/tags/JavaScript&quot;&gt;JavaScript&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/tags/CSS&quot;&gt;CSS&lt;/a&gt; 和 &lt;a href=&quot;https://nicelinks.site/tags/HTML&quot;&gt;HTML&lt;/a&gt; 代码进行混淆，从而防止源代码被恶意利用或破解。它提供了多种混淆选项，如随机变量名、删除空格、注释等等，以此增加被攻击者解密的难度，提高代码的安全性。同时，该工具还支持在线预览和多款编码风格的选择，可以方便地查看和选择混淆后的代码风格，以及调整混淆程度。&lt;/p&gt;&lt;p&gt;值得一提的是，该网站的服务是基于&lt;strong&gt;加密算法&lt;/strong&gt;实现的，因此不需要上传代码即可进行混淆，确保了用户的代码的隐私和安全（这也是跟类似产品如 UglifyJS、Closure Compiler 不同的地方）。另外，该网站还提供了 Chrome 插件，可以在开发过程中直接使用，非常方便。&lt;/p&gt;&lt;p&gt;需要注意的是，代码混淆只能增加被攻击者破解的难度，但并不能完全保证代码不被破解。高度复杂的代码混淆对代码的可读性和可维护性也会带来影响。因此，在实际开发中，需要根据实际情况选择适当的混淆方式。同时，还需要采取其他安全措施，如加密和防火墙等，以提高代码的安全性。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/6422da402d6c9c63445c7319&quot;&gt;倾城之链 - JavaScript Obfuscator Tool&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;标签&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/tags/%E5%B7%A5%E5%85%B7&quot;&gt;&lt;code&gt;工具&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%B9%B3%E5%8F%B0&quot;&gt;&lt;code&gt;平台&lt;/code&gt;&lt;/a&gt; · &lt;a href=&quot;https://nicelinks.site/tags/%E5%B7%A5%E5%85%B7%E7%AE%B1&quot;&gt;&lt;code&gt;工具箱&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt;：工具平台，帮小忙&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;帮小忙，腾讯 QQ 浏览器工具箱平台。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://oss.nicelinks.site/tool.browser.qq.com.png?x-oss-process=style/png2jpg&quot; alt=&quot;倾城之链 -  帮小忙，腾讯QQ浏览器在线工具箱平台 &quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐语&lt;/strong&gt;：&lt;a href=&quot;https://nicelinks.site/redirect?url=https://tool.browser.qq.com/&quot;&gt;帮小忙&lt;/a&gt; ，友腾讯 QQ 浏览器团队推出的在线工具箱平台，功能较为齐全，有图片加水印、数据换算、生活娱乐、教育、文本工具、证件生成、、文字提取、今天吃什么、亲戚关系计算、字帖生成、文档转换、开发工具、视频和 PDF 转换工具等等，分免费的和限时免费。类似工具聚合平台较多，诸如 &lt;a href=&quot;https://nicelinks.site/post/5a5cc0b60aee782ded3e7b6b&quot;&gt;在线工具 - 程序员的工具箱&lt;/a&gt; 、 &lt;a href=&quot;https://nicelinks.site/post/62727acd7d02b74eba0f09d9&quot;&gt;即时工具-致力打造即用即走型在线工具箱&lt;/a&gt; 等等，您可按需选择典藏、使用。&lt;/p&gt;&lt;p&gt;── 出自&lt;a href=&quot;https://nicelinks.site/post/641e8f67abfccb2329b4e383&quot;&gt;倾城之链 - 帮小忙，腾讯QQ浏览器在线工具箱平台&lt;/a&gt;&lt;/p&gt;&lt;p&gt;对倾城之链感兴趣的朋友，可通过 Web，小程序，快应用等渠道进行访问(后续将支持更多，如 VsCode 插件，Chrome 扩展等)。您有任何问题，欢迎随时向我们反馈（您可以通过官网反馈渠道，或添加如下客服微信），🤲 。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://image.nicelinks.site/%E5%80%BE%E5%9F%8E%E4%B9%8B%E9%93%BE-%E5%BE%AE%E4%BF%A1-mini.jpeg&quot; alt=&quot;倾城之链 - 客服微信&quot;/&gt;&lt;/p&gt;&lt;h2 id=&quot;本期文末寄语&quot;&gt;&lt;a href=&quot;#%E6%9C%AC%E6%9C%9F%E6%96%87%E6%9C%AB%E5%AF%84%E8%AF%AD&quot; aria-label=&quot;本期文末寄语 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;本期文末寄语&lt;/h2&gt;&lt;p&gt;风急天高猿啸哀，渚清沙白鸟飞回。&lt;br/&gt;无边落木萧萧下，不尽长江滚滚来。&lt;br/&gt;万里悲秋常作客，百年多病独登台。&lt;br/&gt;艰难苦恨繁霜鬓，潦倒新停浊酒杯。&lt;br/&gt;── 唐朝 · 杜甫 《登高》&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://nicelinks.site/?utm_source=weekly&quot;&gt;倾城之链&lt;/a&gt;作为一个开放平台，旨在云集全球&lt;strong&gt;优秀网站&lt;/strong&gt;，探索互联网中更广阔的世界；在这里，你可以轻松发现、学习、分享更多有用或有趣的事物。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://image.nicelinks.site/nicelinks-miniprogram-code.jpeg?imageView2/1/w/250/h/250/interlace/1/ignore-error/1&quot; alt=&quot;小程序码 - 倾城之链&quot;/&gt;&lt;/p&gt;&lt;h2 id=&quot;您可能感兴趣的文章&quot;&gt;&lt;a href=&quot;#%E6%82%A8%E5%8F%AF%E8%83%BD%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E6%96%87%E7%AB%A0&quot; aria-label=&quot;您可能感兴趣的文章 permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; version=&quot;1.1&quot; viewbox=&quot;0 0 16 16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;您可能感兴趣的文章&lt;/h2&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9be4accd37ece7c20b90aa7e0c0aae2d</guid>
<title>开箱即用，完整版 ChatGPT 克隆方案，开源了！</title>
<link>https://toutiao.io/k/mwebpmj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content              autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;公众号关注 “GitHubDaily”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设为 “&lt;/span&gt;&lt;span&gt;星标&lt;/span&gt;&lt;span&gt;”，每天带你逛 GitHub！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;316&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6453703703703704&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JKunUvtPFbY2bXnhpPc4yfhh6sOkjybYuVMv38g7QemW9wriaaGMZicqg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n2&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在过去的短短几个月，以 ChatGPT、GPT4 为代表的 AI 应用和大模型火爆全球，被视为开启了新的科技工业革命和 AGI （通用人工智能）的新起点。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n2&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;不仅科技巨头间你追我赶，争相推出新品，许多学术界、工业界的 AI 大佬也纷纷投入投身相关创业浪潮。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n94&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;生成式 AI 正以“天”为单位，快速迭代，持续狂飙！&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n3&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;然而，OpenAI 并未将其开源，它们背后的技术细节有哪些？如何快速跟进、追赶并参与到此轮技术浪潮中？如何降低 AI 大模型构建和应用的高昂成本？如何保护核心数据与知识产权不会因使用第三方大模型 API 外泄？&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n4&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;作为当下最受欢迎的开源 AI 大模型解决方案，GitHub 知名开源项目 Colossal-AI 率先建立了包含&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;监督数据集收集-&amp;gt;监督微调-&amp;gt;奖励模型训练-&amp;gt;强化学习微调的完整 RLHF 流程。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n4&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;以 LLaMA 为基础预训练模型，推出 ColossalChat，&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;是目前最接近 ChatGPT 原始技术方案的实用开源项目&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;!&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n5&quot; mdtype=&quot;paragraph&quot;&gt;开源地址：&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n6&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;包含以下内容&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n207&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n211&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Demo：可直接在线体验模型效果，无需注册或 waitinglist；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n213&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;训练代码：开源完整 RLHF 训练代码，已开源至含 7B 和 13B 两种模型；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n215&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;数据集：开源 104K 中、英双语数据集；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n217&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;推理部署：4bit 量化推理 70 亿参数模型仅需 4GB 显存；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n219&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;模型权重：仅需单台服务器少量算力即可快速复现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n221&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;更大规模模型、数据集、其他优化等将保持高速迭代添加。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 cid=&quot;n13&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;平价模型，强大能力&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n14&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 仅需不到百亿参数，在大语言模型的基础上进行 RLHF 微调，即可掌握中、英双语能力，达到与 ChatGPT 和 GPT-3.5 类似的效果。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;例如常识问答：&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;    &lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;542&quot; data-ratio=&quot;0.9805555555555555&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JIIHAD9oNWohZD73S3BenqFrb4R6UUibbuqY3f2ZbkEANeThFDiatPvnQ/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;中文应答：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n18&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J18szqASMnhIJakseaZYeypW3PMZZEfGrvWZF2jqbycn55oEgOqvsJw/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;225&quot; data-ratio=&quot;0.4064814814814815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8Jwibe6vMQ5JNw7RBicMdVs1x8UuHicGh349cYzP9TukVX3vyS8sPkP4sicA/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n19&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;写一封邮件：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n20&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JHThDAiaLS95O5WTyBDnnQFe826icGaKbeIFzpvgseaCI4tyctQJvQ0og/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;535&quot; data-ratio=&quot;0.9703703703703703&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JIqjXK2FylA8htLYEiak9OobJ6d2n5NVR17VPF4UIiasKgKhxaKuvVcyQ/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n21&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;写个算法：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n22&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J5hkib1561dwD0ia2x9iaje7OJmL6ldVbewLibJW7JFIia76ziaNPbo1Rb94A/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;345&quot; data-ratio=&quot;0.625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JSBc5CESMJrSscN34XQicia7XZ9B3tv49ELGdxbXT4gwNQPaDI1QmlnfA/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n23&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;完整 ChatGPT 克隆方案&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n24&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;尽管 ChatGPT 和 GPT-4 等 GPT 系列模型非常强大，但是它们不太可能被完全开源。幸运的是，开源社区一直在不断努力。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n25&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;例如 Meta 开源了 LLaMA 模型，该模型的参数量从 70 亿到 650 亿不等，130 亿参数即可胜过 1750 亿的 GPT-3 模型在大多数基准测试的表现。但是由于没有被指令微调（instruct tuning），因此实际生成效果不够理想。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n26&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;斯坦福的 Alpaca 通过调用OpenAI API，以 self-instruct 方式生成训练数据，使得仅有 70 亿参数的轻量级模型以极低成本微调后，即可获得媲美 GPT-3.5 这样千亿参数的超大规模语言模型的对话效果。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n27&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;但是&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;现有开源方案都可以被视为只得到了人类反馈强化学习（RLHF）中第一步的监督微调模型&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;，没有进行后续的对齐和微调工作。同时 Alpaca 的训练数据集过小，语料只有英文，也在一定程度上限制了模型的性能。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n28&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;而 &lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;ChatGPT 和 GPT-4 的惊艳效果，还在于将 RLHF 引入训练过程，使得生成内容更加符合人类价值观。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n29&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JnrZwqfDteVWoLqKzxniaYqqGnichIM47K5YgMNlOZLDAEXhmUeAPqZTQ/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;318&quot; data-ratio=&quot;0.5768518518518518&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J9Rk4EsLIRXBoJQNaSwnn2L9YO6Xod1T2AiaNVXlicLO25NBm6dw5Kicqg/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;span&gt;RLHF的三个阶段&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n31&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;基于 LLaMA 模型，Colossal-AI 首个开源包含完整 RLHF 流程的类Chat模型复现方案 ColossalChat，是目前&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;最接近 ChatGPT 原始技术路线&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;的实用开源项目!&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n32&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;训练数据集开源&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n33&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 开源了包含约 10 万条问答的中、英双语数据集。该数据集收集并清洗了社交平台上人们的真实提问场景作为种子数据集，利用 self-instruct 技术扩充数据，花费约 900 美元进行标注。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n33&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;对比其他 self-instruct 方法生成的数据集，该数据集的种子数据更加真实、丰富，生成的数据集涵盖的话题更多。该数据可以同时用于微调和 RLHF 训练。通过高质量的数据，ColossalChat 能进行更好地对话交互，同时支持中文。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n34&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JvvL8tOd8Zadr1FqAWBBicsNbKD3pnxHu4rCVGIhKr44LOm8vF11icO5g/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;245&quot; data-ratio=&quot;0.4425925925925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J82iamibvHrr6zQvqxlJ0sgib75DhdRQBhhPZYlnDSAoHibgb0Ojc3gsxMQ/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;span&gt;ColossalChat 数据集收集流程&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n36&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF算法复现&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n37&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF-Stage1 是 supervised-fintuning，即使用上文提到的数据集进行模型微调。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n38&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF-Stage2 训练了奖励模型，它通过对于同一个 prompt 的不同输出进行人工排序，得到对应分数，监督训练奖励模型。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n39&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;RLHF-Stage3 使用了强化学习算法，是训练流程中最复杂的一部分：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n40&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JbT9jGymUXtzGzcjYmpic6OJ7Ww3Iwz8Get0DGE8hiccMLiafPcxdiayOvg/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;240&quot; data-ratio=&quot;0.4361111111111111&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JQ6McNTvfpICsNFHcSbASII4ibAlEicrUtB2IsOwhEjBWGCHuZjXTpOJA/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;span&gt;RLHF-Stage3算法流程图&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n42&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 PPO 部分，ColossalChat 分为两个阶段进行：首先是 Make Experience 部分，利用 SFT 、Actor、RM、Critic 模型计算生成 Experience 存入 buffer 中；之后是参数更新部分，利用 Experience 计算策略损失和价值损失。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n43&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 PTX 部分，ColossalChat 计算 Actor 输出 response 和输入语料的回答部分的交叉熵损失函数，用来在 PPO 梯度中加入预训练梯度，以保持语言模型原有性能防止遗忘。最后将策略损失、价值损失和 PTX 损失加和进行反向传播和参数更新。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n44&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;快速上手&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n45&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 开源了基于 LLaMA 模型，复现训练 ChatGPT 三个阶段的完整代码。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n46&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;第一阶段，训练 SFT 模型：&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n47&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;# Training with a 4-GPU servers&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;colossalai run &lt;span&gt;--nproc_per_node&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; train_sft.py \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain&lt;/span&gt; &lt;span&gt;&quot;/path/to/LLaMa-7B/&quot;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--model&lt;/span&gt; &lt;span&gt;&#x27;llama&#x27;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--strategy&lt;/span&gt; colossalai_zero2 \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--log_interval&lt;/span&gt; &lt;span&gt;10&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--save_path&lt;/span&gt;  /path/to/Coati-7B \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--dataset&lt;/span&gt; /path/to/data.json \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--batch_size&lt;/span&gt; &lt;span&gt;4&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--accimulation_steps&lt;/span&gt; &lt;span&gt;8&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--lr&lt;/span&gt; 2e-5&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n50&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;第二阶段，训练奖励模型：&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n51&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;# Training with a 4-GPU servers&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;colossalai run &lt;span&gt;--nproc_per_node&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; train_reward_model.py \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain&lt;/span&gt; &lt;span&gt;&quot;/path/to/LLaMa-7B/&quot;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--model&lt;/span&gt; &lt;span&gt;&#x27;llama&#x27;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--strategy&lt;/span&gt; colossalai_zero2 \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--dataset&lt;/span&gt; /path/to/datasets&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n54&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;第三阶段，使用 RL 训练：&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n58&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;# Training with a 8-GPU servers&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;colossalai run &lt;span&gt;--nproc_per_node&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; train_prompts.py prompts.csv \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--strategy&lt;/span&gt; colossalai_zero2 \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain&lt;/span&gt; &lt;span&gt;&quot;/path/to/Coati-7B&quot;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--model&lt;/span&gt; &lt;span&gt;&#x27;llama&#x27;&lt;/span&gt; \&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;--pretrain_dataset&lt;/span&gt; /path/to/dataset&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n102&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在获得最终模型权重后，还可通过量化降低推理硬件成本，并启动在线推理服务，仅需单张约 4GB 显存的 GPU 即可完成 70 亿参数模型推理服务部署。&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;shell&quot; cid=&quot;n59&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;python server.py /path/to/pretrained &lt;span&gt;--quant&lt;/span&gt; 4bit &lt;span&gt;--gptq_checkpoint&lt;/span&gt; /path/to/coati-7b-4bit-128g.pt &lt;span&gt;--gptq_group_size&lt;/span&gt; &lt;span&gt;128&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;h3 cid=&quot;n62&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;系统性能优化与开发加速&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n63&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ColossalChat 能够快速跟进 ChatGPT 完整 RLHF 流程复现，离不开 AI 大模型基础设施 Colossal-AI 及相关优化技术的底座支持，相同条件下&lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;训练速度&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;相比 Alpaca 采用的 FSDP(Fully Sharded Data Parallel) &lt;/span&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;可提升两倍以上&lt;/strong&gt;&lt;/span&gt;&lt;span md-inline=&quot;plain&quot;&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n64&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;系统基础设施 Colossal-AI&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;AI 大模型开发系统 Colossal-AI 为该方案提供了基础支持，它可基于 PyTorch 高效快速部署 AI 大模型训练和推理，从而降低 AI 大模型应用的成本。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 由加州伯克利大学杰出教授 James Demmel 和新加坡国立大学校长青年教授尤洋领导开发。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;自开源以来，Colossal-AI 已经多次在 GitHub 热榜位列世界第一，获得 GitHub Star 约两万颗，并成功入选 SC、AAAI、PPoPP、CVPR、ISC 等国际 AI 与 HPC 顶级会议的官方教程。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n66&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;减少内存冗余的 ZeRO + Gemini&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n67&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 支持使用无冗余优化器 (ZeRO) 提高内存使用效率，低成本容纳更大模型，同时不影响计算粒度和通信效率。自动 Chunk 机制可以进一步提升 ZeRO 的性能，提高内存使用效率，减少通信次数并避免内存碎片。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n67&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;异构内存空间管理器 Gemini 支持将优化器状态从 GPU 显存卸载到 CPU 内存或硬盘空间，以突破 GPU 显存容量限制，扩展可训练模型的规模，降低 AI 大模型应用成本。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;使用 LoRA 低成本微调&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n69&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 支持使用低秩矩阵微调（LoRA）方法，对 AI 大模型进行低成本微调。LoRA 方法认为大语言模型是过参数化的，而在微调时，参数改变量是一个低秩矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n69&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;因此，可以将这个矩阵分解为两个更小的矩阵的乘积。在微调过程中，大模型的参数被固定，只有低秩矩阵参数被调整，从而显著减小了训练所需的参数量，并降低成本。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n70&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;低成本量化推理&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n71&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8Jib1fgkNuXmAqZGQhJPQKYEcibiaFMML9Rs1Q4a2P7Qdu4nstKjrQyiabyg/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;222&quot; data-ratio=&quot;0.4027777777777778&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J6wGqxOj6zvsT55ibn0OrlLtyuL5YU22op80TB9l2uQqqy1y6FxXiaF3Q/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;span&gt;GPTQ量化&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n73&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;为降低推理部署成本，Colossal-AI 使用 GPTQ 4bit 量化推理。在 GPT/OPT/BLOOM 类模型上，它比传统的RTN(rount-to-nearest) 量化技术能够获得更好的 Perplexity 效果。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n73&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;相比常见的 FP16 推理，它可将显存消耗降低75%，只损失极少量的吞吐速度与 Perplexity 性能。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n74&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;以 ColossalChat-7B 为例，在使用 4bit 量化推理时，70 亿参数模型仅需大约 4GB 显存即可完成短序列（生成长度为 128 ）推理，在普通消费级显卡上即可完成（例如 RTX 3060 Laptop），仅需一行代码即可使用。&lt;/span&gt;&lt;/p&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n75&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;args&lt;/span&gt;.&lt;span&gt;quant&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;&#x27;4bit&#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;    &lt;span&gt;model&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;load_quant&lt;/span&gt;(&lt;span&gt;args&lt;/span&gt;.&lt;span&gt;pretrained&lt;/span&gt;, &lt;span&gt;args&lt;/span&gt;.&lt;span&gt;gptq_checkpoint&lt;/span&gt;, &lt;span&gt;4&lt;/span&gt;, &lt;span&gt;args&lt;/span&gt;.&lt;span&gt;gptq_group_size&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;p cid=&quot;n78&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;如果采用高效的异步卸载技术(offload)，还可以进一步降低显存要求，使用更低成本的硬件推理更大的模型。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n79&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;开放协作&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n80&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;尽管已经进一步引入RLHF，但由于算力和数据集有限，在部分场景下的实际性能仍有提升空间。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n81&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8J9ib6IvdsLulXfz6W3EZ4Iic3E0icuFHM8NVgw0GsxTG7ajtldPIJjbgqQ/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;552&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;159&quot; data-ratio=&quot;0.287962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28jbw6ySFwFHBSUpfsgQ6O8JxgkCCU0DicxUVLy2znwLibvX4FSOGYibyMGDkVjhv6jQjPEov2EiacwqWw/640?wx_fmt=png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n82&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;幸运的是，不同以往 AI 大模型与前沿技术仅由少数科技巨头垄断，PyTorch、Hugging Face 和 OpenAI 等开源社区与初创企业在本轮浪潮中也起到了关键作用。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n82&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;借鉴开源社区的成功经验，Colossal-AI 欢迎各方参与共建，拥抱大模型时代！&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n83&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;可通过以下方式联系或参与：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; cid=&quot;n84&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n191&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 GitHub 发布 issue 或提交 pull request (PR)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;2&quot; cid=&quot;n85&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n193&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;加入 Colossal-AI 用户微信或 Slack 群交流&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n195&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;发送正式合作提案到邮箱 &lt;/span&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;youy@comp.nus.edu.sg&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;3&quot; cid=&quot;n86&quot; mdtype=&quot;list&quot;/&gt;&lt;p cid=&quot;n87&quot; mdtype=&quot;paragraph&quot;&gt;开源地址：&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzAxOTcxNTIwNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28ia8xsyOClt8NDDCTAZNaDsEic4EEpUG1FPduFr5TUMK1GbDiaFX0qNCJiaS2XPfHzWlFicK95v1a9ic7Vg/0?wx_fmt=png&quot; data-nickname=&quot;GitHubDaily&quot; data-alias=&quot;GitHubDaily&quot; data-signature=&quot;专注于分享 GitHub 上知名的 Python、Java、Web、AI、数据分析等多个领域的优质学习资源、开源项目及开发者工具，为 GitHub 开发者提供优质编程资讯。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1cd9f2f8f5fd05c09688de685fb2cca8</guid>
<title>各大互联网公司喜欢用的“智能推荐”，具体有什么区别？</title>
<link>https://toutiao.io/k/91g2fmw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;container app-preview post-body&quot;&gt;
  &lt;div class=&quot;preview&quot;&gt;&lt;p&gt;智能推荐是一种根据用户行为、兴趣爱好等信息，为用户推荐相关内容或产品服务的人工智能技术。现已广泛应用于电商、社交媒体、品牌零售等行业。当前市面上智能推荐相关产品有很多，大致可分为以下几种类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.基于内容的推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于用户历史行为和偏好，系统可以推荐与用户之前喜欢的内容相似的新内容。它通常基于文本、图像、音频和视频等内容元素的相似度计算。例如，淘宝根据用户浏览和购买记录、搜索关键词以及商品属性等信息，向用户推荐具有相似属性或者风格的商品。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.协同过滤推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;协同过滤推荐是根据用户之间的行为相似性来推荐产品。如果两个用户在过去喜欢了相似的产品，那么当其中一个用户喜欢新产品时，系统可以将该新产品推荐给另一个用户。例如，豆瓣根据用户对电影的评分，向用户推荐喜欢同样类型电影的其他用户也喜欢的电影。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.混合推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;混合推荐结合了不同类型的推荐算法来推荐产品，以获得更好的推荐效果。例如，可以将基于内容的推荐与协同过滤推荐结合起来，以利用它们各自的优点来提高内容推荐的准确性和多样性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.实时推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实时推荐是指根据当前上下文和用户行为实时推荐产品。例如，如果用户在搜索某个特定主题时，系统可以根据用户的搜索行为和搜索历史，推荐与该主题相关的最新内容。例如，知乎根据用户发布的问题、回答以及浏览历史等信息，综合运用基于内容推荐和基于协同过滤推荐，在推荐相似问题的同时，也会推荐用户可能感兴趣的话题和用户。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.基于知识的推荐&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于知识的推荐是一种利用领域知识来推荐产品的方法。例如，如果用户在搜索特定主题时，系统可以基于该主题的领域知识推荐相关的书籍、论文和其他学术资源。&lt;/p&gt;

&lt;p&gt;上述推荐算法各自具有不同的特点和应用场景。通常需要根据企业经营具体情况选择适当的智能推荐算法，以满足用户的需求和提高推荐的准确性和效果。&lt;/p&gt;

&lt;p&gt;神策智能推荐系统是一款基于用户行为分析的全流程智能推荐产品。它基于神策分析强大的数据采集能力，从用户行为数据的采集、数据建模、数据挖掘到效果分析，完成从“数据采集+推荐引擎+效果反馈”的推荐全流程。&lt;/p&gt;

&lt;p&gt;对比其他智能推荐系统，神策智能推荐系统拥有以下4大特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;完整性：实现采集、推荐、反馈的完整推荐闭环&lt;/li&gt;
&lt;li&gt;开放性：推荐算法的白盒，开放全平台的算法逻辑&lt;/li&gt;
&lt;li&gt;指标灵活性：可自定义多指标、漏斗转化评价能力&lt;/li&gt;
&lt;li&gt;算法迭代能力强：数据反馈与问题定位，实现算法精准迭代&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;神策智能推荐系统能够帮助企业实现对用户“千人千面”的个性化内容推荐，改善用户体验，持续提升核心业务指标。&lt;/p&gt;

&lt;p&gt;欢迎前往神策数据官网免费体验！&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a9b719e3334c467a6c80b971698593ad</guid>
<title>图解 Git 工作原理</title>
<link>https://toutiao.io/k/nvavx18</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文图解Git中的最常用命令。如果你稍微理解Git的工作原理，这篇文章能够让你理解的更透彻。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基本用法&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3626373626373626&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdVldJGOGXuibWZGhib6OyVXMic1ZznAwYtO2eFpicV29aUVpNpwCMDia6B4w/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;728&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的四条命令在工作目录、暂存目录（也叫做索引）和仓库之间复制文件。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;git add files把当前文件放入暂存区域。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git commit给暂存区域生成快照并提交。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git reset – files用来撤销最后一次git add files，你也可以用git reset撤销所有暂存区域文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git checkout – files把文件从暂存区域复制到工作目录，用来丢弃本地修改。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可以用git reset -p，git checkout -p，or git add -p进入交互模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也可以跳过暂存区域直接从仓库取出文件或者直接提交代码。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.30484988452655887&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdYReXDk7rS1rOicCQ7WtiagoMiaicu2xX2XmnNtiaiariayeskukH5fu1J3UibQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;866&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;git commit -a相当于运行git add把所有当前目录下的文件加入暂存区域再运行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git commit files进行一次包含最后一次提交加上工作目录中文件快照的提交。并且文件被添加到暂存区域。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;git checkout HEAD – files回滚到复制最后一次提交。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;约定&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后文中以下面的形式使用图片。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43441636582430804&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdbdwYDx6TQR4KD6FWsr2B8UI1QBYzIlp7LGzmSLG1DU0Z1gUESMqGDg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;绿色的5位字符表示提交的ID，分别指向父节点。分支用橘色显示，分别指向特定的提交。当前分支由附在其上的HEAD标识。这张图片里显示最后5次提交，ed489是最新提交。master分支指向此次提交，另一个maint分支指向祖父提交节点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;命令详解&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Diff&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有许多种方法查看两次提交之间的变动，下面是一些示例。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42839951865222625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdDpAGboibbjp15iaKlk0LyveH5aibicWiaibs0icmJgohye76ojHT8gBOVQA3w/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Commit&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提交时，Git用暂存区域的文件创建一个新的提交，并把此时的节点设为父节点。然后把当前分支指向新的提交节点。下图中，当前分支是master。在运行命令之前，master指向ed489，提交后，master指向新的节点f0cec并以ed489作为父节点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdVZvuXkGQXTnibv4hkRL3ALkCXGibtgPicPgmTjllf8dRg7sJ9PNozzOaQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即便当前分支是某次提交的祖父节点，Git会同样操作。下图中，在master分支的祖父节点maint分支进行一次提交，生成了1800b。这样，maint分支就不再是master分支的祖父节点。此时，合并[1]（或者衍合[2]）是必须的。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacduYic50KBcqN9pwAdTEJDI63zxQTx8aapgIkopvqXCDwK1UpQUf9icypg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果想更改一次提交，使用git commit –amend。Git会使用与当前提交相同的父节点进行一次新提交，旧的提交会被取消。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdrSBGHl2PZIfsTticrNYGQDgQqLC1Zn7rJVicpIJaJXDkiaVjrAnbfh0Bw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一个例子是分离HEAD提交[3]，后文讲。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Checkout&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Checkout命令用于从历史提交（或者暂存区域）中拷贝文件到工作目录，也可用于切换分支。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当给定某个文件名（或者打开-p选项，或者文件名和-p选项同时打开）时，Git会从指定的提交中拷贝文件到暂存区域和工作目录。比如，git checkout HEAD~ foo.c会将提交节点HEAD~（即当前提交节点的父节点）中的foo.c复制到工作目录并且加到暂存区域中。（如果命令中没有指定提交节点，则会从暂存区域中拷贝内容。）注意当前分支不会发生变化。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4368231046931408&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacd3nvKaac5eIaNEa0ibH7D3HGJRNHA57Vc8icte35clLq7sbOCo41Q9uKA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当不指定文件名，而是给出一个（本地）分支时，那么HEAD标识会移动到那个分支（也就是说，我们“切换”到那个分支了），然后暂存区域和工作目录中的内容会和HEAD对应的提交节点一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新提交节点（下图中的a47c3）中的所有文件都会被复制（到暂存区域和工作目录中）；只存在于老的提交节点（ed489）中的文件会被删除；不属于上述两者的文件会被忽略，不受影响。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacd4njffFGDBaiaiawib1jv6eS5umZXNwl0jdVibDlCdZrSN0aT6JGYgu2bYQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果既没有指定文件名，也没有指定分支名，而是一个标签、远程分支、SHA-1值或者是像master~3类似的东西，就得到一个匿名分支，称作detached HEAD（被分离的HEAD标识）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样可以很方便地在历史版本之间互相切换。比如说你想要编译1.6.6.1版本的Git，你可以运行git checkout v1.6.6.1（这是一个标签，而非分支名），编译，安装，然后切换回另一个分支，比如说git checkout master。然而，当提交操作涉及到“分离的HEAD”时，其行为会略有不同，详情见在下面。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdVxGHWej6PnlIiaoREvuQrnIicXPaltU9SAJ72TbePvOtA0icELZOlYcdg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;HEAD标识处于分离状态时的提交操作&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当HEAD处于分离状态（不依附于任一分支）时，提交操作可以正常进行，但是不会更新任何已命名的分支。（你可以认为这是在更新一个匿名分支。）&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdIknsiaJ60s2S1aYoPyn4qjkn9YepPUcpXosgNicGSKo2lEV7MmYL3bwQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦此后你切换到别的分支，比如说master，那么这个提交节点（可能）再也不会被引用到，然后就会被丢弃掉了。注意这个命令之后就不会有东西引用2eecb。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdtUMpFj1s3iaVAHc8OdO1nQNpE1OFqibZca2gGhDib6GOgAvC1HUdJeUFg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，如果你想保存这个状态，可以用命令git checkout -b name来创建一个新的分支。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdQ9sMJahbLwjLRUCcWBX9IX4TAPZDg4zYmCHmtKwdD1JO0K8IQ1678A/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Reset&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Reset命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不给选项，那么当前分支指向到那个提交。如果用–hard选项，那么工作目录也更新，如果用–soft选项，那么都不变。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4368231046931408&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdg7cp5MbL5g78655RSGxzh9xLFapI79n5WGbicWSMSwA3zickCZlnslicw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果没有给出提交点的版本号，那么默认用HEAD。这样，分支指向不变，但是索引会回滚到最后一次提交，如果用–hard选项，工作目录也同样。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdlpE3ic4w3pOznB3LDhric6FYMjPLiam2d9eytrmcKJ32f1wrYw41Q6YHw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果给了文件名（或者-p选项），那么工作效果和带文件名的checkout差不多，除了索引被更新。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdIkvt4DjfTJp02cNdxicsCPWLAxEVwWyicG0Vh0PG94prKJJMEjORdzZg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Merge&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Merge命令把不同分支合并起来。合并前，索引必须和当前提交相同。如果另一个分支是当前提交的祖父节点，那么合并命令将什么也不做。另一种情况是如果当前提交是另一个分支的祖父节点，就导致fast-forward合并。指向只是简单的移动，并生成一个新的提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdxsnHyTf9U6NVM6iasdyop8ZFMDtINC7qYhzfpp84ECg8ArLPiauXX2iag/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;否则就是一次真正的合并。默认把当前提交（ed489 如下所示）和另一个提交（33104）以及他们的共同祖父节点（b325c）进行一次三方合并[4]。结果是先保存当前目录和索引，然后和父节点33104一起做一次新提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46690734055354993&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdDFSlUbw008ODVcP0qlj9FF1kpMV1ZsQSzX5BspvfkiajVaE2q428oibQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Cherry Pick&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;cherry-pick命令“复制”一个提交节点并在当前分支做一次完全一样的新提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdlGk2GCEeqNdG4opRvmPcxglggpuYSJ2OibqKtrk6k3CHeia1Uc9ewOVw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Rebase&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;衍合是合并命令的另一种选择。合并把两个父分支合并进行一次提交，提交历史不是线性的。衍合在当前分支上重演另一个分支的历史，提交历史是线性的。本质上，这是线性化的自动的 cherry-pick。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-w=&quot;831&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdNpPX70icDA8vR1DKM7B0HATDmibTGZoLVvtKzH6RVwabwddKRfa3wefQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的命令都在topic分支中进行，而不是master分支，在master分支上重演，并且把分支指向新的节点。注意旧提交没有被引用，将被回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要限制回滚范围，使用–onto选项。下面的命令在master分支上重演当前分支从169a6以来的最近几个提交，即2c33a。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43561973525872444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A1HKVXsfHNnZfxjv4QgIc8lho4spoiacdEy3uLQL1VCFeOsGeC1uaVM6UPwiafbiaycrzpnWBujErcic7sH1SIYmcQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样有git rebase –interactive让你更方便的完成一些复杂操作，比如丢弃、重排、修改、合并提交。没有图片体现这些，细节看这里：git-rebase(1)[5]。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;技术说明&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;文件内容并没有真正存储在索引（.git/index）或者提交对象中，而是以blob的形式分别存储在数据库中（.git/objects），并用SHA-1值来校验。索引文件用识别码列出相关的blob文件以及别的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于提交来说，以树（tree）的形式存储，同样用对于的哈希值识别。树对应着工作目录中的文件夹，树中包含的 树或者blob对象对应着相应的子目录和文件。每次提交都存储下它的上一级树的识别码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果用detached HEAD提交，那么最后一次提交会被the reflog for HEAD引用。但是过一段时间就失效，最终被回收，与git commit –amend或者git rebase很像。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相关链接：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;http://marklodato.github.io/visual-git-guide/index-zh-cn.html#merge&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://marklodato.github.io/visual-git-guide/index-zh-cn.html#rebase&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://marklodato.github.io/visual-git-guide/index-zh-cn.html#detached&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://en.wikipedia.org/wiki/Three-way_merge&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://www.kernel.org/pub/software/scm/git/docs/git-rebase.html#_interactive_mode&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b0004eddefc951e1b36a6b5d6aa523fe</guid>
<title>kafka 中 producer 中的配置参数 linger.ms 的含义是什么，一直不太理解 ？</title>
<link>https://toutiao.io/k/jwjuo84</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;span class=&quot;RichText ztext CopyrightRichText-richText css-1g0fqss&quot; options=&quot;[object Object]&quot; itemprop=&quot;text&quot;&gt;&lt;blockquote data-first-child=&quot;&quot; data-pid=&quot;BqI7paeV&quot;&gt;   作者： 谢先生。 2014年入行的程序猿。多年开发和架构经验。专注于Java、云原生、大数据等技术。从CRUD入行，负责过亿级流量架构的设计和落地，解决了千万级数据治理问题。&lt;br/&gt;   微信公众号、B站：搜索「&lt;b&gt;谢先生说技术&lt;/b&gt;」不定时更新 ～&lt;br/&gt;   清单： &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gitee.com/mr_sanq/goku-framework&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;goku-framework&lt;/a&gt;&lt;/b&gt;、&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gitee.com/mr_sanq/enjoy-read-ii&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【定期开源】享阅读II&lt;/a&gt;&lt;/b&gt;&lt;br/&gt; &lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/h2&gt;&lt;blockquote data-pid=&quot;ExE7j5fu&quot;&gt;发句牢骚：&lt;br/&gt;最近真的累。年后第三天就去出差。3月回来马上又投入到新项目中~ ┓(;´_｀)┏&lt;br/&gt;最近老危险了。项目都是别的组的~~&lt;/blockquote&gt;&lt;p data-pid=&quot;xZHoxAFt&quot;&gt;前面我们花了较长的时间对生产者Producer理论、Producer分区做了一个比较细致的介绍。详细大家在认真阅读完前两节的内容之后会对Kafka的生产者有一个比较清晰的认知。&lt;/p&gt;&lt;p data-pid=&quot;RBD_0-XH&quot;&gt;其中我们需要重点掌握的内容是：Producer发送消息的过程，如果有不清楚的建议返回好好品味。&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;H87PTzbG&quot;&gt;《分布式流处理组件-理论篇：Producer入门理论》&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;b5QsNcxx&quot;&gt;我们需要注意的是：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;VrvINaDu&quot;&gt;在生产环境由于物理机器等资源配置的影响，也为了更大程度上保证资源的利用率，我们都会对各个组件进行适配。&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;sDDTAgUD&quot;&gt;而Kafka的Producer也是一样的。在生产环境中也有很多需要注意的点。本章我们就来好好的聊一聊~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;啰嗦两句Producer的消息发送原理&lt;/b&gt; &lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://picx.zhimg.com/50/v2-23e7b49fdd9aae414bf98ee7ce29114e_720w.jpg?source=1940ef5c&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2771&quot; data-rawheight=&quot;1381&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://picx.zhimg.com/v2-23e7b49fdd9aae414bf98ee7ce29114e_r.jpg?source=1940ef5c&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2771&quot; data-rawheight=&quot;1381&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://picx.zhimg.com/v2-23e7b49fdd9aae414bf98ee7ce29114e_r.jpg?source=1940ef5c&quot; data-actualsrc=&quot;https://picx.zhimg.com/50/v2-23e7b49fdd9aae414bf98ee7ce29114e_720w.jpg?source=1940ef5c&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-pid=&quot;UqeYwcdJ&quot;&gt; 为了让大家清晰的理解优化点，我们简单过一下Producer的发送原理 已经明白的请略过~&lt;br/&gt; &lt;/blockquote&gt;&lt;p data-pid=&quot;qW8MRocw&quot;&gt;如上图所示，消息数据通过主线程调用&lt;code&gt;producer.send()&lt;/code&gt;将其发送出去，其中经过拦截器、序列化器、分区器的层层加工之后，记录缓冲区&lt;code&gt;RecordAccumulator&lt;/code&gt;会将加工之后的消息记录添加到其中。而消息也不是单纯的存在于&lt;code&gt;RecordAccumulator&lt;/code&gt;中，为了降低网络IO，Producer将其按照batch的形式进行存放。&lt;/p&gt;&lt;blockquote data-pid=&quot;jJWlYQoF&quot;&gt;&lt;code&gt;RecordAccumulator&lt;/code&gt;当然不是无限大的，自然这里就是我们的第一个优化点&lt;br/&gt; 而合理的对batch容量进行配置，就是我们所说的第二个优化点&lt;br/&gt; 消息的大小也是我们需要考虑的重点，姑且算是一个优化点&lt;br/&gt; &lt;/blockquote&gt;&lt;p data-pid=&quot;2fSyKuIg&quot;&gt;而batch消息也会根据分区器计算得到的分区号存在于对应的&lt;code&gt;Deque&lt;/code&gt;双端队列中，所以他们的关系就是图中一层包一层的样子&lt;/p&gt;&lt;p data-pid=&quot;sPcaINbU&quot;&gt;当batch满足某个条件或者消息等待指定时间之后，sender线程被拉起，Sender程序将不断从缓冲区取出数据，进而进入到另外一个阶段&lt;/p&gt;&lt;blockquote data-pid=&quot;HhVP_SVu&quot;&gt; 新的优化点：指定等待时间&lt;br/&gt; &lt;/blockquote&gt;&lt;p data-pid=&quot;Qb0X13Le&quot;&gt;从缓冲区拉取出来的数据会被封装为&lt;code&gt;Request&lt;/code&gt;对象，并且与缓存区类似的是：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;8JTWTDRA&quot;&gt;&lt;code&gt;NetworkClient&lt;/code&gt;中同样会存在一个类似缓冲区的存在：&lt;code&gt;InFlightRequests&lt;/code&gt;。其中会按照分区对Request进行存储。所以他们的逻辑关系其实是这样的&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pica.zhimg.com/50/v2-b25d1b4917907e93374458110fb62f83_720w.jpg?source=1940ef5c&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2724&quot; data-rawheight=&quot;1724&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://picx.zhimg.com/v2-b25d1b4917907e93374458110fb62f83_r.jpg?source=1940ef5c&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2724&quot; data-rawheight=&quot;1724&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://picx.zhimg.com/v2-b25d1b4917907e93374458110fb62f83_r.jpg?source=1940ef5c&quot; data-actualsrc=&quot;https://pica.zhimg.com/50/v2-b25d1b4917907e93374458110fb62f83_720w.jpg?source=1940ef5c&quot;/&gt;&lt;figcaption&gt;2023-03-18-22-05-53&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-pid=&quot;ky4IM1PN&quot;&gt;随后进行发送，而在默认情况下，如果Broker端一直没有响应，每个分区下的Request只能存放5个请求。而超出的情况将会阻塞发送逻辑。&lt;/p&gt;&lt;p data-pid=&quot;ynO_nfcr&quot;&gt;消息发送成功后，将会清空原始数据。否则尝试重试等操作&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Producer高吞吐&lt;/b&gt;&lt;/h2&gt;&lt;blockquote data-pid=&quot;Pe6Mj9HP&quot;&gt; 注意： 本段属于测试阶段，多图模式&lt;br/&gt; &lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;前置条件&lt;/b&gt; &lt;/h2&gt;&lt;p data-pid=&quot;HzZ4j5NH&quot;&gt;来吧，啰嗦完Producer发送过程之后，就到了精彩的测试验证环节。有句话需要重点说明下：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;avDqLmm9&quot;&gt;以下验证结果不属银弹，实际生产中参数配置如何： 还是需要结合实际业务场景和资源配置给出最佳参数&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;humjbTcZ&quot;&gt;机器配置:&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;f-Z-YRzr&quot;&gt;3台 &lt;b&gt;2C4G&lt;/b&gt; 的虚拟机&lt;/li&gt;&lt;li data-pid=&quot;CLtkY65_&quot;&gt;Topic设置分区数为3，副本因子为2&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;测试脚本&lt;/b&gt; &lt;/h2&gt;&lt;p data-pid=&quot;dMS2pjRL&quot;&gt;本次Producer吞吐量测试脚本在Kafka中已经提供，我们在&lt;code&gt;${KAFKA_HOME}/kafka_2.13-3.3.1/bin&lt;/code&gt;中可以找到&lt;code&gt;kafka-producer-perf-test.sh&lt;/code&gt;。如下对执行参数进行简单说明：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;am-W9Sxh&quot;&gt;--throughput： 限制测试发送消息的最大吞吐量，-1表示不受限制&lt;/li&gt;&lt;li data-pid=&quot;O2nZT1az&quot;&gt;--num-records： 测试消息的数据量。&lt;/li&gt;&lt;li data-pid=&quot;ZVWB6Fjq&quot;&gt;--record-size： 每条消息的大小。&lt;/li&gt;&lt;li data-pid=&quot;YtiXmmyX&quot;&gt;--producer-props： Producer可配置参数信息，我们也可以通过properties文件的方式配置到&lt;code&gt;--producer.config&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;默认参数负载情况&lt;/b&gt;&lt;/h3&gt;&lt;blockquote data-pid=&quot;O0QbNaiQ&quot;&gt; kafka-producer-perf-test.sh内部也是默认参数，如果机器配置不错可以适当调整JVM参数&lt;br/&gt; &lt;/blockquote&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;kafka-producer-perf-test.sh --topic newTopic_test001 --producer-props bootstrap.servers=master:9092,node01:9092,node02:9092 --throughput -1 --num-records 100000  --record-size 1024
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;UFIEiQ7v&quot;&gt;发送10W条消息大小为1KB的消息到newTopic_test001上，不设置吞吐限制&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;30421 records sent, 6083.0 records/sec (5.94 MB/sec), 2125.8 ms avg latency, 3695.0 ms max latency.
55005 records sent, 11001.0 records/sec (10.74 MB/sec), 3129.7 ms avg latency, 4864.0 ms max latency.
100000 records sent, 9042.408898 records/sec (8.83 MB/sec), 2719.28 ms avg latency, 4864.00 ms max latency, 2598 ms 50th, 4250 ms 95th, 4734 ms 99th, 4832 ms 99.9th.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;HzMOVX-j&quot;&gt;输出表示：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;peN759X9&quot;&gt;成功消费100000记录，吞吐量：10101.010101条/s (9.86 MB/sec)&lt;/li&gt;&lt;li data-pid=&quot;3qPcS5gN&quot;&gt;平均延迟2451.60ms，最大延迟4025.00ms&lt;/li&gt;&lt;li data-pid=&quot;NojdAWx-&quot;&gt;50%消息延迟2455ms, 95%消息延迟3581ms, 99%消息延迟3875ms, 99.9%消息延迟4016ms。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;参数介绍&lt;/b&gt; &lt;/h2&gt;&lt;p data-pid=&quot;J6qI925n&quot;&gt;下面要介绍的这几个参数，在Producer端：任意一个都可以称为王牌的存在。接下来我们就一一来看看：&lt;/p&gt;&lt;blockquote data-pid=&quot;LFCfcD48&quot;&gt; 这些参数在&lt;code&gt;ProducerConfig&lt;/code&gt;中都有介绍，我们一一来看~&lt;br/&gt; &lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;batch.size&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;zOQrjhOl&quot;&gt;每当发送多个消息时，为了提高客户端和服务器的性能，生产者将尝试对多个消息进行打包成批，保证这一批可以在同一个分区内。默认为&lt;b&gt;16384【16KB】&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;w1vnlMO2&quot;&gt;为了尽可能的提高吞吐量，在实际生产中需要对发送的消息进行合理预估，根据实际情况选择一个合理的大小，避免出现如下情况：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;ovJO2JDP&quot;&gt;单条消息超过&lt;code&gt;batch.size&lt;/code&gt;，Producer有可能不会处理此消息&lt;/li&gt;&lt;li data-pid=&quot;CeZqVOBm&quot;&gt;&lt;code&gt;batch.size&lt;/code&gt;过大，有可能会造成Producer端内存空间的浪费&lt;/li&gt;&lt;li data-pid=&quot;jA3EMqX0&quot;&gt;&lt;code&gt;batch.size&lt;/code&gt;过小，频繁的网络IO会降低Producer的吞吐&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;linger.ms&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;8ex_nXV7&quot;&gt;如果消息迟迟没有达到&lt;code&gt;batch.size&lt;/code&gt;，那么将尝试等待&lt;code&gt;linger.ms&lt;/code&gt;时间发送。默认等待时间为0，也就是当消息到达之后立即发送&lt;/p&gt;&lt;blockquote data-pid=&quot;qTF9IQ0D&quot;&gt; 但实际上为了减少发送的请求数量，在没有负载的情况下也会延迟5ms的时间。所以这也不是绝对的立即发送~&lt;br/&gt; &lt;/blockquote&gt;&lt;p data-pid=&quot;UAfc9yfd&quot;&gt;这两个参数我们或多或少都介绍过，但是并没有测试调整它们对吞吐量的影响。接下来我们就先来测试一波吧！！！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;测试&lt;code&gt;batch.size&lt;/code&gt;和&lt;code&gt;linger.ms&lt;/code&gt;对吞吐量的影响&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;Z5CsX03W&quot;&gt;对照以上默认测试结果，然后我们开始进行参数调整。&lt;/p&gt;&lt;p data-pid=&quot;4h4KoBWJ&quot;&gt;跟着我的节奏，先对单个参数进行调整，对比差异&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;kafka-producer-perf-test.sh --topic newTopic_test001 --producer-props bootstrap.servers=master:9092,node01:9092,node02:9092 batch.size=32768 --throughput -1 --num-records 100000  --record-size 1024
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote data-pid=&quot;87cFNOBN&quot;&gt; 三次输出结果显示&lt;br/&gt; &lt;/blockquote&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;68697 records sent, 13733.9 records/sec (13.41 MB/sec), 900.0 ms avg latency, 1812.0 ms max latency.
100000 records sent, 14817.009927 records/sec (14.47 MB/sec), 1129.92 ms avg latency, 1957.00 ms max latency, 1167 ms 50th, 1884 ms 95th, 1932 ms 99th, 1951 ms 99.9th.

100000 records sent, 22311.468095 records/sec (21.79 MB/sec), 1036.42 ms avg latency, 1467.00 ms max latency, 1100 ms 50th, 1431 ms 95th, 1449 ms 99th, 1462 ms 99.9th.

100000 records sent, 21753.317381 records/sec (21.24 MB/sec), 1001.94 ms avg latency, 1646.00 ms max latency, 955 ms 50th, 1614 ms 95th, 1631 ms 99th, 1639 ms 99.9th.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;e0wc8dyl&quot;&gt;对比默认结果，我们可以看到在吞吐量上已经有了非常明显的提高&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;kafka-producer-perf-test.sh --topic newTopic_test001 --producer-props bootstrap.servers=master:9092,node01:9092,node02:9092 linger.ms=3000 --throughput -1 --num-records 100000  --record-size 1024
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote data-pid=&quot;s6_3er-w&quot;&gt; 三次输出结果显示&lt;br/&gt; &lt;/blockquote&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;60526 records sent, 12102.8 records/sec (11.82 MB/sec), 1632.5 ms avg latency, 2337.0 ms max latency.
100000 records sent, 12280.486307 records/sec (11.99 MB/sec), 1882.64 ms avg latency, 2591.00 ms max latency, 2050 ms 50th, 2553 ms 95th, 2571 ms 99th, 2584 ms 99.9th.

64966 records sent, 12990.6 records/sec (12.69 MB/sec), 1556.1 ms avg latency, 2757.0 ms max latency.
100000 records sent, 13540.961408 records/sec (13.22 MB/sec), 1719.67 ms avg latency, 2757.00 ms max latency, 1474 ms 50th, 2701 ms 95th, 2730 ms 99th, 2744 ms 99.9th.

71776 records sent, 14355.2 records/sec (14.02 MB/sec), 1506.2 ms avg latency, 2176.0 ms max latency.
100000 records sent, 14320.492625 records/sec (13.98 MB/sec), 1577.49 ms avg latency, 2176.00 ms max latency, 1668 ms 50th, 2134 ms 95th, 2154 ms 99th, 2170 ms 99.9th.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;NOtch6qB&quot;&gt;同样还是要和默认测试结果进行对比，虽然吞吐量没有配置&lt;code&gt;batch.size&lt;/code&gt;的效果差异，但也不能说本次调整不重要&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;kafka-producer-perf-test.sh --topic newTopic_test001 --producer-props bootstrap.servers=master:9092,node01:9092,node02:9092 linger.ms=3000 batch.size=32768 --throughput -1 --num-records 100000  --record-size 1024
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote data-pid=&quot;fWO-A2Vj&quot;&gt; 三次输出结果显示&lt;br/&gt; &lt;/blockquote&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;100000 records sent, 21739.130435 records/sec (21.23 MB/sec), 1007.46 ms avg latency, 1428.00 ms max latency, 995 ms 50th, 1400 ms 95th, 1411 ms 99th, 1424 ms 99.9th.
100000 records sent, 23041.474654 records/sec (22.50 MB/sec), 952.25 ms avg latency, 1334.00 ms max latency, 919 ms 50th, 1302 ms 95th, 1318 ms 99th, 1328 ms 99.9th.
100000 records sent, 24271.844660 records/sec (23.70 MB/sec), 916.17 ms avg latency, 1318.00 ms max latency, 912 ms 50th, 1278 ms 95th, 1309 ms 99th, 1314 ms 99.9th.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;IEHgSAGa&quot;&gt;已经可以看出对比了吧。 我们继续~~~&lt;/p&gt;&lt;h3&gt;&lt;b&gt;compression.type&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;oDD25_bf&quot;&gt;该参数对Producer生产的数据进行压缩，主要针对批数据压缩。默认是none【无压缩】，可以用来设置的值：&lt;/p&gt;&lt;p data-pid=&quot;vdHa6yBX&quot;&gt;接下来我们直接测试这几个压缩算法的性能吧，为了方便写个脚本&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#!/bin/bash

for i in gzip snappy lz4 zstd
do
 for ((j=0; j&amp;lt;3; j++))
 do
        echo &quot;----$i方式的第$j次测试----&quot;

  kafka-producer-perf-test.sh --topic newTopic_test002 --producer-props bootstrap.servers=master:9092,node01:9092,node02:9092 batch.size=65536 compression.type=$i --throughput -1 --num-records 100000  --record-size 1024

 done
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote data-pid=&quot;FZwbraPJ&quot;&gt; 查看每个级别的三次输出&lt;br/&gt; &lt;/blockquote&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;----gzip方式的第0次测试----
100000 records sent, 25425.883549 records/sec (24.83 MB/sec), 136.45 ms avg latency, 744.00 ms max latency, 97 ms 50th, 451 ms 95th, 677 ms 99th, 742 ms 99.9th.
----gzip方式的第1次测试----
100000 records sent, 27019.724399 records/sec (26.39 MB/sec), 54.22 ms avg latency, 291.00 ms max latency, 27 ms 50th, 174 ms 95th, 228 ms 99th, 288 ms 99.9th.
----gzip方式的第2次测试----
100000 records sent, 27940.765577 records/sec (27.29 MB/sec), 21.55 ms avg latency, 267.00 ms max latency, 11 ms 50th, 75 ms 95th, 97 ms 99th, 130 ms 99.9th.
===========分割线=============
----snappy方式的第0次测试----
100000 records sent, 34153.005464 records/sec (33.35 MB/sec), 518.28 ms avg latency, 1047.00 ms max latency, 479 ms 50th, 969 ms 95th, 1029 ms 99th, 1044 ms 99.9th.
----snappy方式的第1次测试----
100000 records sent, 32765.399738 records/sec (32.00 MB/sec), 474.20 ms avg latency, 985.00 ms max latency, 476 ms 50th, 921 ms 95th, 971 ms 99th, 984 ms 99.9th.
----snappy方式的第2次测试----
100000 records sent, 34578.146611 records/sec (33.77 MB/sec), 450.48 ms avg latency, 932.00 ms max latency, 442 ms 50th, 869 ms 95th, 911 ms 99th, 928 ms 99.9th.
===========分割线=============
----lz4方式的第0次测试----
100000 records sent, 34059.945504 records/sec (33.26 MB/sec), 474.75 ms avg latency, 871.00 ms max latency, 461 ms 50th, 818 ms 95th, 852 ms 99th, 867 ms 99.9th.
----lz4方式的第1次测试----
100000 records sent, 37174.721190 records/sec (36.30 MB/sec), 408.28 ms avg latency, 769.00 ms max latency, 418 ms 50th, 716 ms 95th, 753 ms 99th, 767 ms 99.9th.
----lz4方式的第2次测试----
100000 records sent, 32404.406999 records/sec (31.64 MB/sec), 483.38 ms avg latency, 1145.00 ms max latency, 372 ms 50th, 1077 ms 95th, 1122 ms 99th, 1142 ms 99.9th.
===========分割线=============
----zstd方式的第0次测试----
100000 records sent, 51975.051975 records/sec (50.76 MB/sec), 57.53 ms avg latency, 279.00 ms max latency, 54 ms 50th, 108 ms 95th, 141 ms 99th, 158 ms 99.9th.
----zstd方式的第1次测试----
100000 records sent, 47755.491882 records/sec (46.64 MB/sec), 66.12 ms avg latency, 333.00 ms max latency, 49 ms 50th, 208 ms 95th, 316 ms 99th, 332 ms 99.9th.
----zstd方式的第2次测试----
100000 records sent, 51203.277010 records/sec (50.00 MB/sec), 60.27 ms avg latency, 265.00 ms max latency, 49 ms 50th, 148 ms 95th, 172 ms 99th, 193 ms 99.9th.
===========分割线=============&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;0km5SbTZ&quot;&gt;根据本次测试，而且测试命令也运行了多次，确实是&lt;code&gt;zstd&lt;/code&gt;较好。 而我们再看看官网给出的说明： &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://picx.zhimg.com/50/v2-014c3d40a4a368c5907a1be5adb7c79b_720w.jpg?source=1940ef5c&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;986&quot; data-rawheight=&quot;932&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://picx.zhimg.com/v2-014c3d40a4a368c5907a1be5adb7c79b_r.jpg?source=1940ef5c&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;986&quot; data-rawheight=&quot;932&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://picx.zhimg.com/v2-014c3d40a4a368c5907a1be5adb7c79b_r.jpg?source=1940ef5c&quot; data-actualsrc=&quot;https://picx.zhimg.com/50/v2-014c3d40a4a368c5907a1be5adb7c79b_720w.jpg?source=1940ef5c&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;blockquote data-pid=&quot;aEAFA6uE&quot;&gt; 留个坑，下来我重新试试～～～&lt;br/&gt; &lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;acks&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;45gREeYK&quot;&gt;前面章节中其实我们介绍过&lt;code&gt;acks&lt;/code&gt;这个参数。&lt;/p&gt;&lt;blockquote data-pid=&quot;FFICKuTG&quot;&gt; 我们再啰嗦一下acks的可设置值&lt;br/&gt; &lt;/blockquote&gt;&lt;ul&gt;&lt;li data-pid=&quot;uDvX28dO&quot;&gt;&quot;0&quot;： 当消息调用&lt;code&gt;send()&lt;/code&gt;发送出去之后就表示消息已经发送成功，不管消息是否已经到达broker&lt;/li&gt;&lt;li data-pid=&quot;64lI4gpt&quot;&gt;&quot;1&quot;： 消息发送后，Leader接收到消息并记录到本地之后，不需要同步数据到副本就能进行ack返回&lt;/li&gt;&lt;li data-pid=&quot;V51zD3UP&quot;&gt;&quot;all&quot;： 当消息在Leader接收记录，并且等待副本数据同步完成之后，才会返回ack。 该级别也属于&lt;code&gt;Java#Producer&lt;/code&gt;的默认配置&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-pid=&quot;6pTd4SYs&quot;&gt; 接下来我们针对以上三种级别来做一个效果验证&lt;br/&gt; &lt;/blockquote&gt;&lt;p data-pid=&quot;yMt48vKA&quot;&gt;基本就是默认配置，只不过多了一个&lt;code&gt;acks&lt;/code&gt;的配置项&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#!/bin/bash
for i in 0 1 all
do
echo &quot;---------------acks=$i------------------&quot;
        for ((j=0; j&amp;lt;3; j++))
        do
        kafka-producer-perf-test.sh --topic newTopic_test001 --producer-props bootstrap.servers=master:9092,node01:9092,node02:9092 acks=$i --throughput -1 --num-records 100000  --record-size 1024
        done
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote data-pid=&quot;mquZkJpm&quot;&gt; 查看每个级别的三次输出&lt;br/&gt; 有数据有真相&lt;br/&gt; &lt;/blockquote&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;--------------acks=0------------------
100000 records sent, 43878.894252 records/sec (42.85 MB/sec), 60.90 ms avg latency, 367.00 ms max latency, 20 ms 50th, 218 ms 95th, 297 ms 99th, 363 ms 99.9th.
100000 records sent, 38699.690402 records/sec (37.79 MB/sec), 121.56 ms avg latency, 823.00 ms max latency, 60 ms 50th, 469 ms 95th, 736 ms 99th, 814 ms 99.9th.
100000 records sent, 37650.602410 records/sec (36.77 MB/sec), 127.71 ms avg latency, 441.00 ms max latency, 100 ms 50th, 351 ms 95th, 403 ms 99th, 440 ms 99.9th.
---------------acks=1------------------
100000 records sent, 30284.675954 records/sec (29.57 MB/sec), 387.87 ms avg latency, 897.00 ms max latency, 340 ms 50th, 799 ms 95th, 855 ms 99th, 893 ms 99.9th.
100000 records sent, 36995.930448 records/sec (36.13 MB/sec), 247.35 ms avg latency, 826.00 ms max latency, 199 ms 50th, 703 ms 95th, 789 ms 99th, 813 ms 99.9th.
100000 records sent, 37425.149701 records/sec (36.55 MB/sec), 394.01 ms avg latency, 850.00 ms max latency, 389 ms 50th, 784 ms 95th, 814 ms 99th, 841 ms 99.9th.
---------------acks=all------------------
76362 records sent, 15272.4 records/sec (14.91 MB/sec), 1422.4 ms avg latency, 1980.0 ms max latency.
100000 records sent, 16084.928422 records/sec (15.71 MB/sec), 1463.71 ms avg latency, 1980.00 ms max latency, 1628 ms 50th, 1903 ms 95th, 1960 ms 99th, 1974 ms 99.9th.

81151 records sent, 16223.7 records/sec (15.84 MB/sec), 1404.0 ms avg latency, 2201.0 ms max latency.
100000 records sent, 16906.170752 records/sec (16.51 MB/sec), 1397.82 ms avg latency, 2201.00 ms max latency, 1491 ms 50th, 2001 ms 95th, 2136 ms 99th, 2193 ms 99.9th.

88156 records sent, 17631.2 records/sec (17.22 MB/sec), 1245.0 ms avg latency, 1688.0 ms max latency.
100000 records sent, 17969.451932 records/sec (17.55 MB/sec), 1255.73 ms avg latency, 1688.00 ms max latency, 1403 ms 50th, 1598 ms 95th, 1635 ms 99th, 1668 ms 99.9th.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;SvNP8MU_&quot;&gt;所以：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;hwSXaMAh&quot;&gt;如果是类似日志、行为等不重要的消息，建议将&lt;code&gt;acks&lt;/code&gt;设置为0.&lt;/li&gt;&lt;li data-pid=&quot;r7SmPOuO&quot;&gt;其他的就根据消息的安全程度来进行合理的选择吧~&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;下期预告&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;-GsIZUli&quot;&gt;本期针对Producer调优参数的介绍和测试对比到这里就已经结束了。还是一句话：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;GwpUxOQl&quot;&gt;从数据看结果：实际生产中进行测试，选择合理的配置参数信息是必须得~&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;zLLyskFF&quot;&gt;下一期针对数据可靠性我们来做一个详细的介绍。 期待～&lt;/p&gt;&lt;p data-pid=&quot;wAl2Qh_G&quot;&gt;- END -&lt;/p&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>