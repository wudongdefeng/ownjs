<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ca13ba09e58a40cebde2cfc68bf98427</guid>
<title>TCP 拥塞控制详解 | 5. 回避算法</title>
<link>https://toutiao.io/k/hl9hinl</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;em&gt;网络传输问题本质上是对网络资源的共享和复用问题，因此拥塞控制是网络工程领域的核心问题之一，并且随着互联网和数据中心流量的爆炸式增长，相关算法和机制出现了很多创新，本系列是免费电子书《TCP Congestion Control: A Systems Approach》的中文版，完整介绍了拥塞控制的概念、原理、算法和实现方式。原文: &lt;span&gt;TCP Congestion Control: A Systems Approach&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.5908273381294964&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0WzfByFlh5E7Zp9lqR7HW0c875R2ibqINPUerQrYxPu5Gsc21os8hKOHKHmIC614ibiacouxFTH3nRUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1112&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;TCP拥塞控制详解:&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247485888&amp;amp;idx=1&amp;amp;sn=4819dcc1373f0e8ffa679847f7ab26e9&amp;amp;chksm=fc73b41bcb043d0dd0e5f2b6ea351b1183fd956ad21a259af84b30f7687d2e838a4122aaa5af&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;1. 概述&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;1. 概述&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247485889&amp;amp;idx=1&amp;amp;sn=8b1f3c0d0d6e75a4e5b9dfc3eee8649c&amp;amp;chksm=fc73b41acb043d0c43e88b49b65d7f735c20af8eef23a7671d2da3d22af1db5ee0350aaff04e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;2. 背景&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;2. 背景&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247485941&amp;amp;idx=1&amp;amp;sn=7740dc9e8b3a11d0f549c77b1139391b&amp;amp;chksm=fc73b42ecb043d38d8654fa457cde541a2053492022abb64c7bf2a88420add4214fa573fe94e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;3. 设计空间&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;3. 设计空间&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247485942&amp;amp;idx=1&amp;amp;sn=7fc91be8593085d4222c2af7b77cf3c7&amp;amp;chksm=fc73b42dcb043d3b1eb103830533c6cea1a561c5f25eabd3e1669caaa163feaf35e573a3c7ee&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;4. 控制算法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;4. 控制算法&lt;/a&gt;&lt;/p&gt;&lt;p&gt;5. 回避算法&lt;span&gt;（本&lt;/span&gt;&lt;span&gt;文）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;6. 主动队列管理&lt;/p&gt;&lt;p&gt;7. 超越TCP&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;第5章 回避算法(Avoidance-Based Algorithms)&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对TCP拥塞控制学术文献的回顾可以发现，最初在1988年和1990年分别引入的TCP Tahoe和Reno机制与1994年开始的研究活动之间存在着明显不同，主要标志是引入了一种被称为TCP Vegas的替代方案，从而引发了大量比较研究和替代设计，并持续了25年以上的时间。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;延伸阅读:&lt;br/&gt;L. Brakmo, S. O’Malley and L. Peterson &lt;span&gt;TCP Vegas: New Technique for Congestion Detection and Avoidance&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;. ACM SIGCOMM ‘94 Symposium. August 1994. (Reprinted in IEEE/ACM Transactions on Networking, October 1995).&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尽管截止目前所介绍的方法都将丢包视为拥塞信号，并试图在拥塞发生后对&lt;em&gt;控制&lt;/em&gt;拥塞做出反应，但TCP Vegas采取了一种&lt;em&gt;基于回避(avoidance-based)&lt;/em&gt; 的方法应对拥塞: 它试图检测吞吐率的变化来发现拥塞，并在拥塞严重到足以导致丢包之前调整发送速率。本章将介绍一般的&quot;Vegas策略&quot;，以及随着时间的推移引入的三个不同的例子。这类研究的高潮是谷歌如今所倡导的BBR算法。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1 TCP Vegas&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;TCP Vegas背后的基本思想是根据测量的吞吐率和预期吞吐率的比较来调整发送速率。可以从图29中给出的TCP Reno图示中直观看到，最上面的图显示了连接的拥塞窗口，给出的信息与前一章相同。中间和底部的图描述了新的信息: 中间的图显示了在发送端处测量的平均发送速率，而底部的图显示了在瓶颈路由器处测量的平均队列长度，三个图在时间上是同步的。在4.5秒到6.0秒之间(阴影区域)，拥塞窗口增加(上图)，我们预计观察到的吞吐量也会增加，但实际上却保持不变(中图)，这是因为吞吐量的增加不能超过可用带宽，超过可用带宽之后，任何窗口大小的增加只会导致占用更多的瓶颈路由器缓冲区空间(下图)。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8232224396607958&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0WzfByFlh5E7Zp9lqR7HW0cqkR3D8TtBgZggBfNW0PgEYnQ4p7dT9qN0vRrPhNlibbcwl1BzKUcSHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1533&quot;/&gt;&lt;figcaption&gt;图29. 拥塞窗口与观察到的吞吐量比率(三个图是同步的)。最上是拥塞窗口；中间是观察到的吞吐量；底部是路由器占用的缓冲区空间。彩色线=CongestionWindow；实心标记=超时；散列标记=每个数据包传输的时间；竖线=最终重传的数据包的第一次传输时间。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个有趣的比喻可以用来描述图29中所示现象，即冰上驾驶。速度计(拥堵窗口)可能会显示速度是每小时30英里，但通过看车窗外面，看到步行经过你的人们(测量的吞吐率)，你知道自己的速度不超过每小时5英里。在这种类比中，发动机无意义的空转就像发送的额外数据包一样，只是无用的停留在路由器缓冲区中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;TCP Vegas用这种思想来测量和控制连接传输中的额外数据量，这里的&quot;额外数据&quot;指的是如果发送端能够完全匹配网络可用带宽，就不会传输的数据。TCP Vegas的目标是在网络中维护&quot;正确的&quot;额外数据量。显然，如果一个发送端发送了太多额外数据，将导致长时间的延迟，并可能导致拥塞。不太明显的是，如果一个连接发送的额外数据太少，就无法对可用网络带宽的短暂增加做出足够快的响应。TCP Vegas基于估算网络中额外数据量的变化做出回避拥塞动作，而不仅仅基于丢包，接下来我们详细介绍这个算法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，将给定流的&lt;code&gt;BaseRTT&lt;/code&gt;定义为当流没有拥塞时数据包的RTT。在实践中，TCP Vegas将&lt;code&gt;BaseRTT&lt;/code&gt;设置为测量到的所有往返时间的最小值，通常是在路由器由于该流造成队列增加之前，连接发送的第一个包的RTT。如果假设没有溢出连接，那么预期吞吐量为&lt;/p&gt;&lt;span data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section role=&quot;presentation&quot; data-formula=&quot;\mathsf{ExpectedRate = CongestionWindow\ /\ BaseRTT}&amp;#10;&quot; data-formula-type=&quot;block-equation&quot;&gt;&lt;embed src=&quot;https://mmbiz.qlogo.cn/mmbiz_svg/WmwqjsSBsZLayX7sCuRAiaBx55eHbcJjYAmKcsBibmhAsHgJ50S3OgCb4Ct2Vts1ZBkrGfFCMKYYsiamuDtQWibapmoPsW8NuEYic/0?wx_fmt=svg&quot; data-type=&quot;svg+xml&quot;/&gt;&lt;/section&gt;&lt;/span&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中&lt;code&gt;CongestionWindow&lt;/code&gt;是TCP拥塞窗口，假设(为了这个讨论的目的)等于传输中的字节数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次，TCP Vegas计算当前发送速率&lt;code&gt;ActualRate&lt;/code&gt;。计算方法是记录一个区分数据包(distinguished packet)的发送时间，记录从数据包发送到接收到它的ACK之间传输了多少字节，并当ACK信息到达时计算区分数据包的样本RTT，最后传输字节数除以样本RTT，此计算在每次往返时间中执行一次。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三，TCP Vegas比较&lt;code&gt;ActualRate&lt;/code&gt;和&lt;code&gt;ExpectedRate&lt;/code&gt;并相应调整窗口。&lt;code&gt;Diff = ExpectedRate - ActualRate&lt;/code&gt;，注意，根据定义，&lt;code&gt;Diff&lt;/code&gt;为正或0。只有当测量样本RTT小于BaseRTT时，才会出现&lt;code&gt;ActualRate &amp;gt; ExpectedRate&lt;/code&gt;的情况，如果发生这种情况，将&lt;code&gt;BaseRTT&lt;/code&gt;改为最新采样的RTT。我们还定义了两个阈值，α &amp;lt; β，分别对应于网络中额外数据太少和太多的情况。当&lt;code&gt;Diff&lt;/code&gt; &amp;lt; α时，TCP Vegas在下一个RTT期间线性增加拥塞窗口；当&lt;code&gt;Diff&lt;/code&gt; &amp;gt; β时，TCP Vegas在下一个RTT期间线性减少拥塞窗口。当α &amp;lt; &lt;code&gt;Diff&lt;/code&gt; &amp;lt; β时，TCP Vegas保持拥塞窗口不变。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直观来看，实际吞吐量与预期吞吐量之间的差距越远，网络中的拥塞就越大，意味着发送速率应该降低，β阈值就会触发发送率下降。另一方面，当实际吞吐率太接近预期吞吐率时，连接就会面临无法利用可用带宽的境地，α阈值就会触发发送率的增加。总的目标是在网络中保留的额外字节数介于α和β之间。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5191292875989446&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0WzfByFlh5E7Zp9lqR7HW0co6VsfbJBAhXAXnnw02G0Az88EQVR0XmNudeGYokTbVWPUDuwcwaA5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1516&quot;/&gt;&lt;figcaption&gt;图30. TCP Vegas拥塞回避机制图示。上图是拥塞窗口；下图中彩色线是预期吞吐量和实际吞吐量(黑线)。阴影部分是α和β阈值的区间。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图30显示了TCP Vegas拥塞避免算法。上图显示了拥塞窗口，与本章给出的其他图示相同。下图显示了预期和实际的吞吐量，这决定了如何设置拥塞窗口。下图最能说明算法是如何工作的。彩色线显示了&lt;code&gt;ExpectedRate&lt;/code&gt;，而黑线显示了&lt;code&gt;ActualRate&lt;/code&gt;。阴影部分给出了α和β阈值区间，阴影带的顶部距离&lt;code&gt;ExpectedRate&lt;/code&gt;有α KBps的距离，底部距离&lt;code&gt;ExpectedRate&lt;/code&gt;有β KBps的距离，目标是将&lt;code&gt;ActualRate&lt;/code&gt;保持在阴影区域内的这两个阈值之间。每当&lt;code&gt;ActualRate&lt;/code&gt;低于阴影区域(即离&lt;code&gt;ExpectedRate&lt;/code&gt;太远)，TCP Vegas就会担心网络中有太多的包被缓冲，从而减少拥塞窗口。同样，每当&lt;code&gt;ActualRate&lt;/code&gt;超过阴影区域(即太接近&lt;code&gt;ExpectedRate&lt;/code&gt;)，TCP Vegas就会担心网络没有被充分利用，因此会增加拥塞窗口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于刚才介绍的算法比较实际和期望吞吐量率与α和β阈值之间的差异，所以这两个阈值是按照KBps定义的。但是，考虑连接在网络中占用了多少额外的包缓冲区可能更准确。例如，在&lt;code&gt;BaseRTT&lt;/code&gt;为100ms，数据包大小为1 KB的连接上，如果α = 30 KBps以及β = 60 KBps，那么可以认为α指定该连接需要在网络中占用至少3个额外的缓冲区，并且β指定该连接在网络中占用不超过6个额外的缓冲区。α和β的设置在Vegas第一次部署的实际环境中工作得很好，但正如下一节将会介绍的，这些参数将持续根据不断变化的环境进行调整。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，注意TCP Vegas以线性方式减少拥塞窗口，似乎与需要指数减少来确保稳定性的规则相冲突。这是因为TCP Vegas在超时发生时确实使用指数减少，刚才介绍的线性下降是拥塞窗口的早期下降，发生在拥塞发生以及数据包开始被丢弃之前。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2 不同的假设&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了响应不同网络的假设，TCP Vegas以及类似Vegas的拥塞回避方法已经随着时间的推移进行了调整。Vegas从未像Reno那样被广泛使用，所以这些修改通常更多的是由实验室研究而不是广泛的现实经验驱动的，但对算法的完善有助于我们对基于回避的算法的理解。我们在这里总结了其中一些见解，但在第7章中我们将继续介绍为特定用例定制拥塞控制算法的一般性主题。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.1 FAST TCP&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一种受到Vegas启发的机制是FAST TCP，它对Vegas进行了改进，使其在具有大带宽时延积的高速网络上更加高效。其主要想法是在算法试图找到可用的&quot;传输中&quot;带宽(数据包在网络中被缓冲之前)的阶段更积极的增加拥塞窗口，然后在算法开始与其他流在瓶颈路由器上争夺缓冲区时表现的保守。FAST还建议将α值调整为大约30个包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了在具有大带宽时延积的网络中管理拥塞之外，保持流水线满也是一个实质性的挑战，关于FAST还有两个值得注意的事项。首先，TCP Reno和TCP Vegas都是基于直觉和大量试错的结果，而FAST是基于优化理论(后来这被用来解释为什么Vegas行得通)。其次，与我们所知的所有其他拥塞控制算法不同，FAST的实现只能作为专有的解决方案。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;延伸阅读:&lt;br/&gt;S. Low, L. Peterson, and L. Wang. &lt;span&gt;Understanding TCP Vegas: A Duality Model&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;. Journal of the ACM, Volume 49, Issue 2, March 2002.&lt;/p&gt;&lt;/blockquote&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.2 TCP Westwood&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然Vegas的动机是在发生丢包之前检测并避免拥塞，但TCP Westwood (TCPW)的动机主要是意识到数据包丢失并不总是拥塞的可靠指标。这在无线连接方面尤其明显，在Vegas被提出时这还是新鲜事物，但在TCPW出现时已经变得很普遍了。无线链路经常会因为无线信道上未纠正的错误而丢包，而这与拥塞无关，因此，需要用另一种方法检测拥塞。有趣的是，其最终结果与Vegas有些相似，TCPW还试图通过查看ACK返回成功交付的数据包的速率来确定瓶颈带宽。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当发生丢包时，因为还不知道丢包是由于拥塞还是由于链路相关，TCPW不会立即将拥塞窗口缩短一半，取而代之的是会估计在丢包发生之前流量的流动速度，这是一种比TCP Reno更温和的退让形式。如果丢包与拥塞相关，则TCPW应该以丢包前可接受的速率发送。如果丢包是由无线错误造成的，则TCPW不会降低发送率，并且还会开始再次提高发送率，以充分利用网络。其结果是一个在固定链接上类似于Reno，但在有损链接上性能获得了实质性提升的协议。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;无线链路上拥塞控制算法的优化仍然是一个具有挑战性的问题，更复杂的是，WiFi和移动蜂窝网络具有不同的特性。我们将在第7章重新讨论这个问题。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.3 New Vegas&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后一个例子是New Vegas (NV)，它是对Vegas基于延迟的方法的一种适应，适用于链路带宽为10Gbps或更高的数据中心网络，其RTT通常在几十微秒内。这是我们在第7章将介绍的一个重要用例，当前的目标是建立一些直观感受。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了理解NV的基本思想，假设我们为每个收到ACK的包绘制&lt;code&gt;Rate&lt;/code&gt;与&lt;code&gt;CongestionWindow&lt;/code&gt;的关系图。出于简化目的，&lt;code&gt;Rate&lt;/code&gt;仅仅是&lt;code&gt;CongestionWindow&lt;/code&gt;(以字节为单位)与被ACK(以秒为单位)的数据包RTT的比率。注意，为了简单起见，讨论中使用了&lt;code&gt;CongestionWindow&lt;/code&gt;，而实际上NV使用的是传输中(未收到ACK)的字节。如图31所示，我们用竖条(而不是点)表示由于测量中的瞬时拥塞或噪声而导致的&lt;code&gt;CongestionWindow&lt;/code&gt;值。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.597027972027972&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0WzfByFlh5E7Zp9lqR7HW0c9WouOt22zQvxc533yuKZEV8TZnN0XVBaLHRTY2nRChbiakEwNcOkiaOQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1144&quot;/&gt;&lt;figcaption&gt;图31. 速率与拥塞窗口示意图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;条形图顶部的最大斜率表示过去所能达到的最佳水平。在一个经过良好调整的系统中，条形图的顶端由一条穿过原点的直线作为边界。这个想法是，只要网络没有拥塞，每RTT发送的数据量增加一倍，速率就会增加一倍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Rate&lt;/code&gt;和&lt;code&gt;CongestionWindow&lt;/code&gt;的新测量值可以落在边界线附近(图中的黑色菱形)或下面(图中的蓝色菱形)。在该直线上方的测量会导致NV通过增加其斜率来自动更新该直线，因此测量结果将落在新直线上。如果新的度量值接近这条线，那么NV会增加&lt;code&gt;CongestionWindow&lt;/code&gt;。如果测量值低于这条线，那就意味着和之前较低的拥塞窗口类似的性能。图31所示示例中，我们看到了与&lt;code&gt;CongestionWindow=12&lt;/code&gt;类似的性能，所以减少了&lt;code&gt;CongestionWindow&lt;/code&gt;。在新的测量有噪声的情况下，这种降低是指数级的，而不是瞬间的。为了过滤掉不好的度量值，NV收集了许多度量值，然后在做出拥塞判断之前使用最好的度量值。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.3 TCP BBR&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;BBR(Bottleneck Bandwidth and RTT)是谷歌研究人员开发的一种新的TCP拥塞控制算法。像Vegas一样，BBR是基于延迟的，意味着它试图检测缓冲区的增长，以避免拥塞和丢包。BBR和Vegas都使用最小RTT和观察到的瓶颈带宽(根据一段时间间隔计算)作为主要控制信号。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5086442220200182&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0WzfByFlh5E7Zp9lqR7HW0cBolnvb2sAWoDUNayZYV38aIqCzV0LgXhmR9OFO6MA9Roa797rCwGeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1099&quot;/&gt;&lt;figcaption&gt;图32. 根据观察到的吞吐量和RTT确定最佳发送速率。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图32显示了BBR的基本思想。假设某个网络的瓶颈链路还有一些可用带宽和队列容量，随着拥塞窗口打开，更多的数据被发送，最初由于瓶颈未满，延迟没有增加，吞吐量会增加(下图)。然后，一旦速率达到瓶颈带宽，就开始填充队列。此时，RTT上升，但没有观察到吞吐量上升，这是拥塞阶段的开始。这个图表实际上是我们在图29中4.5到6.0秒时间框架中看到的简化版本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像Vegas一样，BBR的目标是准确确定队列刚刚开始填充的那个点，而不是像Reno那样一直持续到填满缓冲区并导致丢包。BBR的很多工作都是围绕着提高定位最佳点的机制的灵敏度，其中有许多挑战: 测量带宽和延迟是有噪声的；网络条件是动态的；以及在与BBR和非BBR流竞争带宽时对公平的长期追求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与其他方法相比，BBR的一个显著特点是不完全依赖于&lt;code&gt;CongestionWindow&lt;/code&gt;来决定有多少数据被传输。值得注意的是，BBR还试图平滑发送者将数据送入网络的速率，以避免会导致过度排队的突发峰值流量。理想条件下，我们希望以完全符合瓶颈的速度发送数据，从而在不造成队列堆积的情况下实现尽可能高的吞吐量。虽然大多数TCP变体使用ACK到达来触发数据的发送，从而确保传输中未确认数据的数量保持不变，但BBR创建了瓶颈带宽的估算，并使用本地调度算法以该速率发送数据。ACK在更新有关网络的状态方面仍然发挥着重要作用，但并不直接用于调整传输速度，这意味着延迟的ACK不会导致传输量的突然爆发。当然，&lt;code&gt;CongestionWindow&lt;/code&gt;仍然用于确保可以发送足够的数据以保持流水线满，并确保传输中的数据量不会比带宽延迟积大太多，从而避免队列溢出。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了维护当前RTT和瓶颈带宽的最新视图，有必要在当前估计的瓶颈带宽上下持续探测。由于竞争流流量的减少、链路属性(如无线链路)的变化或路由的变化，也许可以获得更多带宽。如果路径变化了，RTT也有可能会变。为了检测RTT的变化，需要发送更少的流量，从而清空队列。为了检测可用带宽的变化，需要发送更多的流量。因此，BBR在其当前估计的瓶颈带宽的上下同时探测，如果有必要，会更新估算，并相应更新发送速率和&lt;code&gt;CongestionWindow&lt;/code&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.3642611683848798&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9utHkjMdE0WzfByFlh5E7Zp9lqR7HW0cic92ImEhjxHjPG6BLM5LHPFZ42icjAbxNrZafg3Wicg13uibFlJl8ml5icQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;291&quot;/&gt;&lt;figcaption&gt;图33. BBR状态机图。&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图33的状态图显示了顺序探测可用带宽和最小RTT的过程。在尝试建立路径上的可用带宽的激进启动阶段之后，降低发送速率以清空队列，然后算法进入图的内环，在内环中，定期检查在较低发送速率下是否有更低的延迟，或者在较高发送速率下是否有更高的吞吐量。在一个相对较长的时间范围内(几秒)，算法进入&lt;code&gt;ProbeRTT&lt;/code&gt;状态，将其发送速率降低两倍，以完全清空队列并测试是否有更低的RTT。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该方法有趣的地方在于，当一个大流在&lt;code&gt;ProbeRTT&lt;/code&gt;状态下显著降低发送速率时，该流对队列延迟的贡献将下降，这将导致其他流同时看到一个新的、更低的RTT，并更新它们的估算。因此，当队列实际上是空的或接近空的时候，流表现出同步RTT估算的趋势，从而提高了估算的准确性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;BBR正在积极开发并在快速发展中，撰写本文时最新版本是2。其主要焦点是公平，例如，一些早期实验表明，CUBIC流在与BBR流竞争时获得的带宽减少了100倍，而其他实验表明，BBR流之间可能存在不公平性。BBR版本1对丢包不敏感，特别是当路径上的缓冲量相对较低时，可能会导致较高的丢包率。由于BBR的几种实现现在正在不同环境中进行试验，包括在谷歌的内部主干网以及更广泛的互联网中，人们正在收集经验来进一步完善设计。IETF的拥塞控制工作组正在主持关于正在进行的设计和实验的讨论。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;延伸阅读:&lt;br/&gt;N. Cardwell, Y. Cheng, C. S. Gunn, S. Yeganeh, V. Jacobson. &lt;span&gt;BBR: Congestion-based Congestion Control&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt;. Communications of the ACM, Volume 60, Issue 2, February 2017.&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。&lt;br/&gt;微信公众号：DeepNoMind&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;TCP Congestion Control: A Systems Approach: &lt;em&gt;https://tcpcc.systemsapproach.org/index.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;TCP Vegas: New Technique for Congestion Detection and Avoidance: &lt;em&gt;https://sites.cs.ucsb.edu/~almeroth/classes/F05.276/papers/vegas.pdf&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;Understanding TCP Vegas: A Duality Model: &lt;em&gt;https://dl.acm.org/doi/10.1145/506147.506152&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;BBR: Congestion-based Congestion Control: &lt;em&gt;https://cacm.acm.org/magazines/2017/2/212428-bbr-congestion-based-congestion-control/fulltext&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;span&gt;- END -&lt;/span&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7d1ba59e41230c9029a0b938b16015e7</guid>
<title>JuiceFS 在 Elasticsearch/ClickHouse 温冷数据存储中的实践</title>
<link>https://toutiao.io/k/2ufg4sb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;&lt;blockquote data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;📖 &lt;span&gt;本文作者： &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高昌健，Juicedata 技术专家，参与建设 JuiceFS 开源社区的主力队员。十年互联网行业从业经历，曾在知乎、即刻、小红书多个团队担任架构师职位，专注于分布式系统、大数据、AI 领域的技术研究。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.52&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3EcuPIickyyEwbzUrMVnXJaXicEHYVRUz1Xar9X3Tic8ZUNJ3IfuVNP8wUpaKiafwYOY6lfXjlYbcJUJklKI7psbsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;p&gt;企业数据越存越多，存储容量与查询性能、以及存储成本之间的矛盾对于技术团队来说是个普遍难题。这个难题在 Elasticsearch 与 ClickHouse 这两个场景中尤为突出，为了应对不同热度数据对查询性能的要求，这两个组件在架构设计上就有一些将数据进行分层的策略。&lt;/p&gt;&lt;p&gt;同时，在存储介质方面，随着云计算的发展，对象存储以低廉的价格和弹性伸缩的空间获得了企业的青睐。越来越多的企业将温、冷数据迁移至对象存储。&lt;strong&gt;但如果将索引、分析组件直接对接至对象存储时会发生查询性能、兼容性等问题&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;这篇文章将为大家介绍这两个场景中冷热数据分层的基本原理，以及如何通过使用 JuiceFS 来应对在对象存储上存在的问题。&lt;/p&gt;&lt;h2&gt;01- Elasticsearch 数据分层结构详解&lt;/h2&gt;&lt;p&gt;在介绍 ES 如何实现冷热数据分层策略之前先来了解三个相关的概念：Data Stream，Index Lifecycle Management 和 Node Role。&lt;/p&gt;&lt;h3&gt;Data Stream&lt;/h3&gt;&lt;p&gt;Data Stream（数据流）是 ES 中一个重要概念，它有如下特征：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;• 流式写入：它是一个流式写入的数据集，而不是一个固定大小的集合；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 仅追加写：它是用追加写的方式将数据更新进去，且不需要修改历史数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 时间戳：每一条新增的数据都会有一个时间戳记录是什么时候产生的；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 多个索引：在 ES 里有一个索引的概念，每一条数据最终会落到它对应的一个索引中，但是数据流是一个更上层、更大的概念，一个数据流背后可能会有很多索引，这些索引是根据不同的规则来生成的。一个数据流虽然由很多的索引来构成，但是只有最新的索引才是可写的，历史索引是只读的，一旦固化好之后就不能再修改。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;日志数据就是符合数据流特征的一类数据，它是只追加写，同时也得有时间戳，用户会根据不同的维度，比如按天或者按其他的维度来生成新的索引。&lt;/p&gt;&lt;p&gt;下图是一个数据流建立索引的简单示例，在用数据流的过程中，ES 会直接写到最新的索引，而不是历史索引，历史索引不会被修改。随着后续更多新的数据生成，这个索引也会沉淀成为一个老的索引。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6554455445544555&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FcGg9Zw5iaoPQsia2xMLN2edNW9Xxz5EteN66eqKZMNYJsOfAKictcuO7g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;505&quot; title=&quot;null&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下图，当用户往 ES 里面去写数据时，大致分为两个阶段：&lt;/p&gt;&lt;p&gt;这个过程中可能会有一些时间差，在持久化的过程中，如果去触发查询， 新创建的Segment 不能被搜索到。一旦这个 Segment 持久化完成之后，就可以立即被上层的查询引擎搜索。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8092783505154639&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9Fq1E6qC4c50DX9ffKFbrEW0547vrXela1ANAqYicqVlicy6OqCQibVRuhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;776&quot; title=&quot;null&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Index Lifecycle Management&lt;/h3&gt;&lt;p&gt;Index Lifecycle Management，简称 ILM，就是索引的生命周期管理。ILM 将索引的生命周期定义为 5 个阶段：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;• 热数据（Hot）：需要频繁更新或者查询的数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 温数据（Warm）：不再更新，但仍会被频繁查询的数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 冷数据（Cold）：不再更新，且查询频率较低的数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 极冷数据（Frozen）：不再更新，且几乎不会被查询的数据。可以比较放心地把这类数据放在一个相对最低速最便宜的存储介质中；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 删除数据（Delete) : 不再需要用到，可以放心删除的数据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一个索引里的数据，不管是 index 还是 segment，都会经历这些阶段，这个分类的规则很好地帮助用户去管理 ES 里的数据，用户可以自己定义不同阶段的规则。&lt;/p&gt;&lt;h3&gt;Node Role&lt;/h3&gt;&lt;p&gt;在 ES 中，每一个部署节点都会有一个 Node Role，也就是节点角色。每一个 ES 节点会分配不同的角色，比如 master、data、ingest 等。用户可以结合节点角色，以及上文提到的不同生命周期的阶段来组合进行数据管理。&lt;/p&gt;&lt;p&gt;数据节点会有不同的阶段，可能是一个存储热数据的节点，也可能是一个存储温数据、冷数据，甚至极冷数据的节点。需要根据节点的功能去给他分配不同的角色，同时会给不同的角色的节点配置不同的硬件。&lt;/p&gt;&lt;p&gt;比如，对于热数据节点需要配置高性能的 CPU 或者磁盘，对于温冷数据的节点，基本上认为这些数据被查询的频率较低，这个时候其实对于某些计算资源的硬件要求就没有那么高了。&lt;/p&gt;&lt;p&gt;节点角色是根据生命周期的不同阶段来定义的，需要注意的一点是，每一个 ES 节点，可以有多种角色，这些角色并不是一一对应的关系。下面有个示例，在 ES 的 YAML 文件里面配置的时候，node.roles 就是节点角色的配置，可以针对这个节点应该有的角色给它配置多种角色。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;node.roles: [&lt;span&gt;&quot;data_hot&quot;&lt;/span&gt;, &lt;span&gt;&quot;data_content&quot;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;h3&gt;生命周期策略&lt;/h3&gt;&lt;p&gt;在了解完 Data Stream 、Index Lifecycle Management、Node Role 这些概念以后，就可以为数据创建一些不同的生命周期策略（Lifecycle Policy）。&lt;/p&gt;&lt;p&gt;根据生命周期策略中定义的不同维度的索引特征，如索引的大小、索引里的文档的数量、索引创建的时间，ES 可以自动地帮用户把某个生命周期阶段的数据滚动到另一个阶段，在 ES 中的术语是 rollover。&lt;/p&gt;&lt;p&gt;比如，用户可以制定基于索引大小维度的特征，把热数据滚动到温数据，或者根据一些其它规则，再把温数据滚动到冷数据。这样，索引在不同生命周期的阶段之间去滚动的时候，相应的它索引的数据也会去做迁移和滚动。ES 可以自动完成这些工作，但是生命周期策略则需要用户自己来定义。&lt;/p&gt;&lt;p&gt;下面的截图，是 Kibana 的管理界面，用户可以通过图形化的方式去配置生命周期策略。可以看到有三个阶段，从上到下分别是热数据、温数据以及冷数据。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.98125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FnHD8wJ4xcoibicmxZjRMiaZPW7JkiaWgTMicCm956icyIqJpKuATIbP4TXTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;展开其中热数据阶段的高级设置，可以看到更详细，上文提到的基于不同维度特征的策略配置，如在下图右边看到的这三个选项。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FO37qALE2hGLYUyQnTWcrc0VbzDTXVo8TIuOwe8GU7DWSNORhh3ic7aw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 索引的大小，示意图上的例子是 50GB，当索引的大小超过 50GB 的时候，就会把它从热数据阶段滚动到温数据阶段。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 最大的文档数，ES 里索引的单元是文档，用户数据是以文档的形式写入 ES 中的，所以文档数也是一个可以衡量的指标。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3. 最大索引创建时间，这里的示例是 30 天，假设某个索引已经创建了 30 天了，这个时候就会触发刚刚提到的从热数据阶段到温数据的滚动。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;02- ClickHouse 数据分层架构详解&lt;/h2&gt;&lt;p&gt;下图是一组从大到小的俄罗斯套娃，它非常形象地展现了 ClickHouse 的数据管理模式， MergeTree 引擎。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;• Table: 在图片的最右边是一个最大的概念，用户最开始要创建或者能够直接接触到的就是 Table；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• Partition：是一个更小的维度或者更小的粒度。在 ClickHouse 里，数据分成 Partition 来存储，每个 Partition 会有一个标识；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• Part：在每个 Partition 中，又会再进一步地细分为多个 Part。如果查看 ClickHouse 磁盘上存储的数据格式，可以认为每一个子目录就是一个 Part；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• Column：在 Part 里会看到一些更小粒度的数据，即 Column。ClickHouse 的引擎使用的是列式存储，所有的数据都是按照列存的方式来组织。在 Part 目录里会看到很多列，比如 Table 可能有100 列，就会有 100 个 Column 文件；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• Block：每个 Column 文件里是按照 Block 的粒度来组织。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5366430260047281&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FQhlCicDoDpZlmUaMDkiaSYibicGNa9JxrGlJQbMlJD1cOHNBNeaUvzQ7rA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;846&quot; title=&quot;null&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下面这个示例中，在 table 目录下可以看到有 4 个子目录，每个子目录就是上文提到的 Part。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ ls -l /var/lib/clickhouse/data/&amp;lt;database&amp;gt;/&amp;lt;table&amp;gt;&lt;br/&gt;drwxr-xr-x  2 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt; 64B Aug  8 13:46 202208_1_3_0&lt;br/&gt;drwxr-xr-x  2 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt; 64B Aug  8 13:46 202208_4_6_1&lt;br/&gt;drwxr-xr-x  2 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt; 64B Sep  8 13:46 202209_1_1_0&lt;br/&gt;drwxr-xr-x  2 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt; 64B Sep  8 13:46 202209_4_4_&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;图示的最右边这一列，每个子目录的名字前面可能是一个时间，比如 202208 类似这样的前缀，202208 其实就是 Partition 名。Partition 名字是用户自己来定义的，但是按照约定俗成或者一些实践习惯，通常会使用时间来命名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;比如， 202208 这个 Partition，它会有两个子目录，子目录就是 Part，一个 Partition 通常会由多个 Part 来构成。用户在往 ClickHoue 写入数据时，会先写到内存里，再根据内存里的数据结构，持久化到磁盘上。同一个Partition 里面的数据如果比较大的话，在磁盘上就会变成很多 part。ClickHouse 官方建议不要在一个 Table 下创建太多 Part，它会定期或者不定期地对 Part 进行合并，减少总的 Part 数量。Merge 的概念就是合并 Part，这也是 MergeTree 这个引擎的名字来源之一。&lt;/p&gt;&lt;p&gt;再通过一个例子来了解 Part。Part 里会有很多小文件，有一些是元信息，比如索引信息，帮助用户快速查找数据。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ ls -l /var/lib/clickhouse/data/&amp;lt;database&amp;gt;/&amp;lt;table&amp;gt;/202208_1_3_0&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 ColumnA.bin&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 ColumnA.mrk&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 ColumnB.bin&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 ColumnB.mrk&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 checksums.txt&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 columns.txt&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 count.txt&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 minmax_ColumnC.idx&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 partition.dat&lt;br/&gt;-rw-r--r--  1 &lt;span&gt;test&lt;/span&gt;  &lt;span&gt;test&lt;/span&gt;  ?? Aug  8 14:06 primary.id&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;在示例的右侧，以 Column 作为前缀的这些文件是实际的数据文件，相比元信息通常会比较大。这个示例中只有 A、B 两列，实际的表里可能有很多列。所有这些文件，包括元信息、索引信息，都会共同帮助用户快速地在不同文件之间去做跳转或者查找。&lt;/p&gt;&lt;h3&gt;ClickHouse 存储策略&lt;/h3&gt;&lt;p&gt;如果要在 ClickHouse 里做冷热数据分层，会用到类似于 ES 中提到的生命周期策略，在 ClickHouse 里称为存储策略（Storage Policy）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;与 ES 稍有不同，ClickHouse 官方并没有将数据划分不同的阶段，比如热数据、温数据、冷数据这些不同的阶段，ClickHouse 提供了一些规则和配置方法，需要用户自己来制定分层策略&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;每个 ClickHouse 节点支持同时配置多块磁盘，存储介质可以是多种多样的。比如，一般用户为了性能会给 ClickHouse 节点配置 SSD 盘；对于一些温冷数据，用户可以把数据存储在成本更低的介质，如机械盘。ClickHouse 的用户对底层存储介质是无感知的。&lt;/p&gt;&lt;p&gt;与 ES 相似，ClickHouse 用户需要根据数据不同的维度特征去制定存储策略，比如每个 part 子目录的大小、整个磁盘的剩余空间比例等，当满足某个维度特征设定的条件时就会触发存储策略的执行。这个策略会将某一个 part 从一块盘迁移到另外一块盘。在 ClickHouse 中，一个节点配置的多块盘是有优先级的，默认情况下数据会优先落在最高优先级的盘上。这样实现了 Part 从一个存储介质转移到另外一个存储介质上。&lt;/p&gt;&lt;p&gt;通过 ClickHouse 的一些 SQL 命令，如 MOVE PARTITION/PART 命令可以手动触发数据迁移，用户也可以通过这些命令做一些功能性的验证。其次有某些情况下，可能也希望能够通过手动的方式，而不是自动转移的方式来显式把 part 从当前的存储介质上转移到另外一个存储介质上。&lt;/p&gt;&lt;p&gt;ClickHouse 还支持基于时间的迁移策略，这是一个独立于存储策略的概念。数据写入后，ClickHouse 会按照每个表的 TTL 属性设置的时间来触发磁盘上数据的迁移。比如设置 TTL 为 7 天，ClickHouse 就会把表中超过 7 天的数据从当前的磁盘（如默认的 SSD）再写到另外一个更低优先级的磁盘上（如 JuiceFS）。&lt;/p&gt;&lt;h2&gt;03- 温冷数据存储：为什么使用对象存储+ JuiceFS ？&lt;/h2&gt;&lt;p&gt;企业把温、冷数据存放到云上后，存储成本相较于传统的 SSD 架构大为下降。&lt;strong&gt;企业还享受到了云上的弹性伸缩空间；不用为数据存储去做任何运维操作，比如扩缩容，或者一些数据清理类的工作&lt;/strong&gt;。温冷数据所需的存储容量比热数据大很多，尤其是随着时间推移，会产生大量需要长期保存的数据，如果这些数据都存储在本地，相应的运维工作将不堪重负。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;但如果在对象存储上使用 Elasticsearch、ClickHouse 这类数据应用组件，会存在写入性能差、兼容性等问题。希望兼顾查询性能的企业，开始在云上寻找解决方案。在这样的背景之下，JuiceFS 被越来越多地应用于数据分层的架构之中。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;通过下面 ClickHouse 写入性能测试可以直观了解到写入SSD、JuiceFS 以及对象存储的性能差异。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5146666666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FDMYsgm6kvic7c7eUxUUnibZSzGbYXI5KULTibiaqIV7edoNtJ4OQtiaH9LA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;JuiceFS 的写入吞吐量远大于直接对接对象存储，接近 SSD&lt;/strong&gt;。当用户把热数据转移到温暖数据这一层时，对于写入性能也有一定要求。在迁移的过程中，如果底层存储介质的写入性能差，整个迁移的流程也会拖得很长，对于整个 pipeline 或数据管理也会带来一些挑战。&lt;/p&gt;&lt;p&gt;下图的 ClickHouse 查询性能测试使用真实业务中的数据，并选取几个典型的查询场景进行测试。其中 q1-q4 是扫描全表的查询，q5-q7 是命中主键索引的查询。测试结果如下图：&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.616875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FibENmDgfWKkDJudQDpEybPFnRXf00FttEddDxzX8qXBlrg09lUClVwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1600&quot; title=&quot;null&quot;/&gt;&lt;/figure&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9FicCN8fJsJOBDsYysa8j6k2nOjD6Q0rpL23lT0dbdLSWFicZdUIzAjH8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;JuiceFS 与 SSD 盘的查询性能基本相当，平均差异在 6% 左右，但是对象存储相比 SSD 盘有 1.4 至 30 倍的性能下降&lt;/strong&gt;。得益于 JuiceFS 高性能的元数据操作以及本地缓存特性，可以自动将查询请求需要的热数据缓存在 ClickHouse 节点本地，大幅提升了 ClickHouse 的查询性能。需要注意的是以上测试中对象存储是通过 ClickHouse 的 S3 磁盘类型进行访问，这种方式只有数据是存储在对象存储上，元数据还是在本地磁盘。如果通过类似 S3FS 的方式把对象存储挂载到本地，性能会有进一步的下降。&lt;/p&gt;&lt;p&gt;另外值得一提的是 JuiceFS 是一个完全兼容 POSIX 的文件系统，它能够与上层应用（如 Elasticsearch、ClickHouse）有很好的兼容。用户对底层存储是分布式文件系统或者是本地磁盘是没有感知的。如果直接使用对象存储，不能很好地实现与上层应用的兼容。&lt;/p&gt;&lt;h2&gt;04- 实操：ES + JuiceFS&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Step 1：准备多种类型节点，分配不同角色。&lt;/strong&gt;每一个 ES 节点可以分配不同的角色，比如存热数据、温数据、冷数据等，用户需要准备不同机型的节点来匹配不同角色的需求。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 2：挂载 JuiceFS 文件系统。&lt;/strong&gt;一般用户将 JuiceFS 用于温、冷数据的存储，用户需要在 ES 温数据节点或冷数据的节点上把 JuiceFS 文件系统挂载到本地。用户可以通过符号链接或其它方式把挂载点配置到 ES 中去，让 ES 认为它的数据存储在本地目录里，但这个目录背后其实是一个 JuiceFS 文件系统。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 3：创建生命周期策略。&lt;/strong&gt;这个需要每个用户自己去定制，用户既可以通过 ES API 去创建，也可以通过 Kibana 去创建，Kibana 提供了一些相对便捷的方式去创建和管理生命周期策略。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 4：为索引设置生命周期策略。&lt;/strong&gt;创建完生命周期策略之后，用户需要把这个策略应用到索引上，也就是要为索引去设置刚刚创建好的策略。用户可以通过索引模板的方式，可以在 Kibana 里创建索引模板，也可以通过 index.lifycycle.name，显式通过 API 配置。&lt;/p&gt;&lt;p&gt;这里有几个小提示：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tip 1：&lt;/strong&gt;&lt;strong&gt;Warm 或 Cold 节点的副本数（replica）可以设置为 1。&lt;/strong&gt;所有数据本质上都是放在 JuiceFS 上，它的底层是对象存储，因而数据的可靠性已经足够高了，所以在 ES 这边可以适当降低副本数，节省存储空间。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.98984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZlxUL7e9sy6EbbHNqMDSY9F80IiadNCLGnnfLtmNUMxzaKgXLn8P7ZeG0JtXYWjwt63a7wpzQGvFtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Tip 2：&lt;/strong&gt;&lt;strong&gt;开启 Force merge 可能会导致节点 CPU 持续占用，酌情关闭&lt;/strong&gt;。从热数据转移到温数据这个阶段时，ES 会将所有热数据索引对应的底层 segment 做合并。如果开启 Force merge 这个功能，ES 会先合并完这些 segment 以后，再把它存储到温数据的底层系统。然而合并 segment 是一个非常消耗 CPU 的过程，如果温数据的数据节点同时也需要承载一些查询请求，可以酌情关闭这个功能能，也就是原封不动地把数据保留下来，直接写到底层存储中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tip 3：&lt;/strong&gt;&lt;strong&gt;Warm 或 Cold 阶段的索引可以设置为只读&lt;/strong&gt;。在给温数据和冷数据阶段建立索引时，我们基本上可以认为这些数据是只读的，这些阶段的索引不会被修改。设置为只读可以适当降低温冷数据节点上的资源，比如内存可以释放一些，从而节省一些在温节点或者冷节点上的硬件资源。&lt;/p&gt;&lt;h2&gt;05- 实操：ClickHouse + JuiceFS&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Step 1：在所有 ClickHouse 节点上挂载 JuiceFS 文件系统。&lt;/strong&gt;这个路径可以是任意路径，因为 ClickHouse 会有一个配置文件去指向挂载点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 2：修改 ClickHouse 配置，新增 JuiceFS 盘。&lt;/strong&gt;在 ClickHouse 中把刚刚挂载好的 JuiceFS 文件系统挂载点添加进来，让 ClickHouse 可以识别这个新磁盘。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 3：新增存储策略，设定下沉数据规则。&lt;/strong&gt;这个存储策略会根据用户的规则去不定期的、自动地将数据从默认磁盘上下沉到指定的，比如 JuiceFS 中。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 4：为特定表设置存储策略及 TTL。&lt;/strong&gt;存储策略制定好之后，需要把这个策略应用到某一个表上。前期测试阶段和验证阶段，可以把用相对大一点的表去做测试和验证，如果用户希望基于时间维度来实现数据下沉，就同时也需要在表上设置 TTL。整个下沉过程是一个自动的机制，可以通过 ClickHouse 的 system 表查看当前正在进行数据迁移的 part 以及迁移进度。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 5：手动移动 part 进行验证。&lt;/strong&gt;可以通过手动执行&lt;span&gt; &lt;/span&gt;&lt;code&gt;MOVE PARTITION&lt;/code&gt;&lt;span&gt; &lt;/span&gt;命令的方式去验证当前的配置或存储策略是否生效。&lt;/p&gt;&lt;p&gt;下图是一个具体示例，在 ClickHouse 中有一个叫做&lt;span&gt; &lt;/span&gt;&lt;code&gt;storage_configuration&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的配置项，其中包含 disks 配置，这里会把 JuiceFS 作为一个盘加进来，我们将它命名为“jfs”，但其实可以用任意名字，挂载点是&lt;span&gt; &lt;/span&gt;&lt;code&gt;/jfs&lt;/code&gt;目录。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&amp;lt;storage_configuration&amp;gt;&lt;br/&gt; &amp;lt;disks&amp;gt;&lt;br/&gt;     &amp;lt;jfs&amp;gt;&lt;br/&gt;         &amp;lt;path&amp;gt;/jfs&amp;lt;/path&amp;gt;&lt;br/&gt;     &amp;lt;/jfs&amp;gt;&lt;br/&gt; &amp;lt;/disks&amp;gt;&lt;br/&gt; &amp;lt;policies&amp;gt;&lt;br/&gt;     &amp;lt;hot_and_cold&amp;gt;&lt;br/&gt;         &amp;lt;volumes&amp;gt;&lt;br/&gt;             &amp;lt;hot&amp;gt;&lt;br/&gt;                 &amp;lt;disk&amp;gt;default&amp;lt;/disk&amp;gt;&lt;br/&gt;                 &amp;lt;max_data_part_size_bytes&amp;gt;1073741824&amp;lt;/max_data_part_size_bytes&amp;gt;&lt;br/&gt;             &amp;lt;/hot&amp;gt;&lt;br/&gt;             &amp;lt;cold&amp;gt;&lt;br/&gt;                 &amp;lt;disk&amp;gt;jfs&amp;lt;/disk&amp;gt;&lt;br/&gt;             &amp;lt;/cold&amp;gt;&lt;br/&gt;         &amp;lt;/volumes&amp;gt;&lt;br/&gt;         &amp;lt;move_factor&amp;gt;0.1&amp;lt;/move_factor&amp;gt;&lt;br/&gt;     &amp;lt;/hot_and_cold&amp;gt;&lt;br/&gt; &amp;lt;/policies&amp;gt;&lt;br/&gt;&amp;lt;/storage_configuration&amp;gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;再往下是 policies 配置项，这里定义了一个叫做 &lt;span&gt;hot_and_cold&lt;/span&gt; 的存储策略，用户需要定义一些具体的规则，如 volumes 中按照先热后冷的优先级排列，数据首先会落到 volumes 里的第一个 hot 盘上，及默认的 ClickHouse 磁盘，一般是本地的 SSD。&lt;/p&gt;&lt;p&gt;volumes 中的 &lt;span&gt;max_data_part_size_bytes&lt;/span&gt; 配置表示当某一个 part 的大小超过设定的大小之后，就会触发存储策略的执行，对应的 part 会下沉到下一个 volume，也就是 cold volume。在上面的示例中，cold volume 就是 JuiceFS。&lt;/p&gt;&lt;p&gt;最下面的 &lt;span&gt;move_factor &lt;/span&gt; 配置代表 ClickHouse 会根据当前磁盘的剩余空间比例来触发存储策略的执行。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;CREATE TABLE &lt;span&gt;test&lt;/span&gt; (&lt;br/&gt;  d DateTime,&lt;br/&gt;  ...&lt;br/&gt;) ENGINE = MergeTree&lt;br/&gt;...&lt;br/&gt;TTL d + INTERVAL 1 DAY TO DISK &lt;span&gt;&#x27;jfs&#x27;&lt;/span&gt;&lt;br/&gt;SETTINGS storage_policy = &lt;span&gt;&#x27;hot_and_cold&#x27;；&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;如上面的代码所示，有了存储策略之后，在创建表或者修改这个表的 schema 时，可以在 SETTINGS 中设置 &lt;span&gt;storage_policy &lt;/span&gt; 为前面定义的 &lt;span&gt;hot_and_cold&lt;/span&gt; 存储策略。上述代码中倒数第二行的 TTL 即为上文提过的基于时间的分层规则。在这个示例中，我们指定的表中某一个叫做 d 的列，它的类型是 &lt;span&gt;DateTime&lt;/span&gt;，结合 &lt;span&gt;INTERVAL 1 DAY&lt;/span&gt; 就表示当新的数据写进来超过一天之后，这些数据就会转移到 JuiceFS 上。&lt;/p&gt;&lt;h2&gt;06- 展望&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;第一，副本共享。&lt;/strong&gt;无论是 ES 还是 ClickHouse，他们都是由多副本来保证数据的可用性和可靠性。JuiceFS 本质上是一个共享文件系统，任何一份数据写入到 JuiceFS 之后，不再需要维护多个副本。比如，用户有两个 ClickHouse 节点，都有某一个表的或者某一个 part 的副本，这两个节点都下沉到了 JuiceFS，它可能会写两次一样的数据。&lt;span&gt;&lt;strong&gt;未来，我们是否可以做到让上层引擎能够感知到下层使用的是一个共享存储，当数据下沉的时候去降低副本数，这样在不同节点之间是可以做副本共享的。&lt;/strong&gt;&lt;/span&gt;从应用层来说，用户查看这个表， part 数还是多副本，但实际在底层的存储上只保了一个副本，因为本质上数据是可以共享的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二点，故障恢复。&lt;/strong&gt;当数据已经下沉到一个远端的共享存储之后，如果 ES 或 ClickHousle 节点宕机故障之后，怎么快速地做故障恢复？除了热数据以外的大部分数据其实都已经转移到了一个远端的共享存储上，这个时候如果要去恢复或创建一个新的节点时，成本会比传统的基于本地盘的故障恢复方式轻量很多，这在 ES 或者 ClickHouse 场景上是值得探索的。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三点，存算分离。&lt;/strong&gt;不管 ES 也好，还是 ClickHouse，整个社区也都在尝试或者探索在云原生的大环境下，怎么去让传统的这些基于本地盘的存储系统变成一个真正的存算分离系统。但存算分离不是仅仅简单地把数据和计算分离就好了，同时要满足上层各种复杂的需求，比如对于查询性能的需求、对于写入性能的需求、对各种维度调优的需求，在存量分离整个大的方向上还是有许多值得探索的技术难点。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第四点，其他上层应用组件数据分层探索。&lt;/strong&gt;除了ES 和 ClickHouse 这两个场景，我们最近也有在做一些尝试，把 Apache Pulsar 中的温冷数据下沉到 JuiceFS 中，用到的一些策略和方案与本文中提到的是类似的，只不过在 Apache Pulsar 中，它需要下沉的数据类型或者数据格式不太一样。有了进一步成功实践后，会分享出来。&lt;/p&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c33ada77de4389595c609ba2afe2951e</guid>
<title>如何实现数据库读一致性</title>
<link>https://toutiao.io/k/xpscpsa</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;（给&lt;/span&gt;&lt;span&gt;ImportNew&lt;/span&gt;&lt;span&gt;加星标，提高Java技能）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1 导读&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;数据的一致性是数据准确的重要指标，那如何实现数据的一致性呢？本文从事务特性和事务级别的角度和大家一起学习如何实现数据的读写一致性。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2 一致性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;1. 数据的一致性：通常指关联数据之间的逻辑关系是否正确和完整。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;举个例子：某系统实现读写分离，读数据库是写数据库的备份库，小李在系统中之前录入的学历信息是高中，经过小李努力学习，成功获得了本科学位。小李及时把信息变成成了本科，可是由于今天系统备份时间较长，小李变更信息时，数据已经开始备份。公司的 HR 通过系统查询小李信息时，发现还是本科，小李的申请被驳回。这就是数据不一致问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2. 数据库的一致性：是指数据库从一个一致性状态变到另一个一致性状态。这是事务的一致性的定义。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;举个例子：仓库中商品 A 有 100 件，门店中商品 A 有 10 件。上午 10 点，仓库发送商品 A50 件到门店，最后仓库中有商品 A50 件，门店有商品 A60 件，这样商品的总是是不变的。不能门店收到货后，仓库的商品 A 还是 100 件，这样就出现数据库不一致问题。仓库和门店商品 A 的总数是 110 才是正确的，这就是数据库的一致性。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3 数据库事务&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;数据库事务 (transaction) 是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行，要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;事务的性质：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;原子性 (Atomicity)：事务中的全部操作在数据库中是不可分割的，要么全部完成，要么全部不执行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一致性 (Consistency)：几个并行执行的事务，其执行结果必须与按某一顺序 串行执行的结果相一致。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;隔离性 (Isolation)：事务的执行不受其他事务的干扰，事务执行的中间结果对其他事务必须是透明的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;持久性 (Durability): 对于任意已提交事务，系统必须保证该事务对数据库的改变不被丢失，即使数据库出现故障&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4 并发问题&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;数据库在并发环境下会出现脏读、重复读和幻读问题。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;1. 脏读&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;事务 A 读取了事务 B 未提交的数据，如果事务 B 回滚了，事务 A 读取的数据就是脏的。&lt;br/&gt;举例：订单 A 需要商品 A20 件，订单 B 需要商品 A10 件。仓库中有商品 A 库存是 20 件。订单 B 先查询，发现库存够，进行扣减。在扣减的过程中，订单 A 进行查询，发现库存只有 10 个不够订单数量，抛出异常。这时候订单 B 提交失败了。库存数量又变成 20 了。这时候，仓库人员去查库存，发现数量是 20，可是订单 A 却说库存不足，这就让人很奇怪。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3546875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/dkwuWwLoRKibkzvr8M8nH8bQ2g39B9T6zvniajMRicUHtm3G5KaY35omzLnHRwvHet1VKhvsyBJILOHY0qzSBgCeA/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;2. 不可重复读&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据出现不一致的情况。&lt;br/&gt;举例：库房管理员查询商品 A 的数量，读取结果是 20 件。这是订单 A 出库，扣减了商品 10 件。这时管理员再去查商品 A 时，发现商品 A 的数量时 10 件和第一此查询的结果不同了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4859375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/dkwuWwLoRKibkzvr8M8nH8bQ2g39B9T6zCpvl8us3xItiaJryia3Am1GIH2buVDUWdHoIqq8kuUrcX8f3WneOycUw/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;3. 幻读&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;事务 A 在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务 B 执行了新增数据的操作并提交后，这个时候事务 A 读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。&lt;br/&gt;举例：操作员查询可生产单量 10 个，调用接口下发 10 个订单，事务 A 增加 10 个订单。操作员获取 10 个订单落库，查询 发现变成 30 个订单。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3015625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/dkwuWwLoRKibkzvr8M8nH8bQ2g39B9T6zeTAgSicwUtUicib5k9CkriaibdlqhA8TeNB8DsRd7cLk4oaxpCnYsMy5JLQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5 事务隔离级别&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;Read Uncommitted（未提交读）&lt;/span&gt;&lt;br/&gt;&lt;span&gt;一个事务可以读取到其他事务未提交的数据，会出现脏读，所以叫做 RU，它没有解决任何的问题。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;Read Committed（已提交读）&lt;/span&gt;&lt;br/&gt;&lt;span&gt;一个事务只能读取到其他事务已提交的数据，不能读取到其他事务未提交的数据，它解决了脏读的问题，但是会出现不可重复读的问题。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;Repeatable Read（可重复读）&lt;/span&gt;&lt;br/&gt;&lt;span&gt;它解决了不可重复读的问题，也就是在同一个事务里面多次读取同样的数据结果是一样的，但是在这个级别下，没有定义解决幻读的问题。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;Serializable（串行化）&lt;/span&gt;&lt;br/&gt;&lt;span&gt;在这个隔离级别里面，所有的事务都是串行执行的，也就是对数据的操作需要排队，已经不存在事务的并发操作了，所以它解决了所有的问题。&lt;/span&gt;&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6 解决数据读一致性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;有两个方案可以解决读一致性问题：基于锁的并发操作（LBCC）和基于多版本的并发操作（MVCC）&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;6.1 LBCC&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;既然要保证前后两次读取数据一致，那么读取数据的时候，锁定我要操作的数据，不允许其他的事务修改就行了。这种方案叫做基于锁的并发控制 Lock Based Concurrency Control（LBCC）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;LBCC 是通过悲观锁来实现并发控制的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果事务 A 对数据进行加锁，在锁释放前，其他事务就不能对数据进行读写操作。这样并发调用，改成了顺序调用。对目前的大多数系统来说，性能完全不能满足要求。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;6.2 MVCC&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;要让一个事务前后两次读取的数据保持一致，那么我们可以在修改数据的时候给它建立一个备份或者叫快照，后面再来读取这个快照就行了。不管事务执行多长时间，事务内部看到的数据是不受其它事务影响的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。这种方案我们叫做多版本的并发控制 Multi Version Concurrency Control (MVCC)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;MVCC 是基于乐观锁的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 InnoDB 中，MVCC 是通过 Undo log 中的版本链和 Read-View 一致性视图来实现的。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;6.2.1 Undo log&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;undo log 是 innodb 引擎的一种日志，在事务的修改记录之前，会把该记录的原值先保存起来再做修改，以便修改过程中出错能够恢复原值或者其他的事务读取。undo log 是一种用于撤销回退的日志，在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时或者数据库崩溃时，可以利用 undo log 来进行回退。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对数据变更的操作不同，undo log 记录的内容也不同:&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新增一条记录的时候，在创建对应 undo 日志时，只需要把这条记录的主键值记录下来，如果要回滚插入操作，只需要根据对应的主键值对记录进行删除操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;删除一条记录的时候，在创建对应 undo 日志时，需要把这条数据的所有内容都记录下来，如果要回滚删除语句，需要把记录的数据内容生产相应的 insert 语句，并插入到数据库中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更新一条记录的时候，如果没有更新主键，在创建对应 undo 日志时，如果要回滚更新语句，需要把变更前的内容记录下来，如果要回滚更新语句，需要根据主键，把记录的数据更新回去。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更新一条记录的时候，如果有更新主键，在创建对应 undo 日志时，需要把数据的所有内容都记录下来，如果要回滚更新语句，先把变更后的数据删掉，再执行插入语句，把备份的数据插入到数据库中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;undo log 版本链&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每条数据有两个隐藏字段，trx_id 和 roll_pointer，trx_id 表示最近一次事务的 id，roll_pointer 表示指向你更新这个事务之前生成的 undo log。&lt;br/&gt;事务 ID：MySQL 维护一个全局变量，当需要为某个事务分配事务 ID 时，将该变量的值作为事务 id 分配给事务，然后将变量自增 1。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;举例：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事务 A id 是 1 插入一条数据 X，这条数据的 trx_id =1 ,roll_pointer 是空（第一次插入）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事务 B id 是 2 对这条数据进行了更新，这条数据的 trx_id =2 ,roll_pointer 指向 事务 A 的 undo log.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事务 C id 是 3 又对数据进行了更新操作，这条数据的 trx_id =3,roll_pointer 指向 事务 B 的 undo log.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;所以当多个事务串行执行的时候，每个事务修改了一行数据，都会更新隐藏字段 trx_id 和 roll_pointer，同时多个事务的 undo log 会通过 roll_pointer 指针串联起来，形成 undo log 版本链。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;6.2.2 Read-View 一致性视图&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;InnoDB 为每个事务维护了一个数组，这个数组用来保存这个事务启动的瞬间，当前活跃的事务 ID。这个数组里有两个水位值： 低水位 (事务 ID 最小值) 和 高水位 (事务 ID 最大值 + 1); 这两个水位值就构成了当前事务的一致性视图（Read-View）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ReadView 中主要包含 4 个比较重要的内容：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;m_ids：表示在生成 ReadView 时当前系统中活跃的读写事务的事务 id 列表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;min_trx_id：表示在生成 ReadView 时当前系统中活跃的读写事务中最小的事务 id，也就是 m_ids 中的最小值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;max_trx_id：表示生成 ReadView 时系统中应该分配给下一个事务的 id 值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;creator_trx_id：表示生成该 ReadView 的事务的事务 id。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;有了这些信息，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果被访问版本的 trx_id 属性值小于 ReadView 中的 min_trx_id 值，表明生成该版本的事务在当前事务生成 ReadView 前已经提交，所以该版本可以被当前事务访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果被访问版本的 trx_id 属性值大于 ReadView 中的 max_trx_id 值，表明生成该版本的事务在当前事务生成 ReadView 后才开启，所以该版本不可以被当前事务访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;&lt;span&gt;6.2.3 数据的查找方式&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;span&gt;1. 快照读&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;快照读又叫一致性读，读取的是历史版本的数据。不加锁的简单的 SELECT 都属于快照读，即不加锁的非阻塞读，只能查找创建时间小于等于当前事务 ID 的数据或者删除时间大于当前事务 ID 的行（或未删除）。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;2. 当前读&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;当前读查找的是记录的最新数据。加锁的 SELECT、对数据进行增删改都会进行当前读。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;6.2.4 数据举例&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dkwuWwLoRKibkzvr8M8nH8bQ2g39B9T6zSIgt5VUDicIUKufCdegRxJDMibtyk1QibWK9qEOZnqzib1vgQUTPAadoNA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;事务 A id =1 初始化了数据&lt;/span&gt;&lt;br/&gt;&lt;span&gt;事务 B id=2 进行了查询操作&lt;/span&gt;&lt;span&gt;（MVCC 只读取创建时间小于当前事务 ID 的数据或者删除时间大于当前事务 ID 的行）&lt;br/&gt;事务 B 的结果是 (商品 A：10, 商品 B：5）&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;事务 C id =3 插入了商品 C&lt;/span&gt;&lt;br/&gt;&lt;span&gt;事务 B id=2 进行了查询操作（MVCC 只读取创建时间小于当前事务 ID 的数据或者删除时间大于当前事务 ID 的行）&lt;br/&gt;事务 B 的结果是 (商品 A：10, 商品 B：5）&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;事务 D id =4 删除商品 B&lt;/span&gt;&lt;br/&gt;&lt;span&gt;事务 B id=2 进行了查询操作（MVCC 只读取创建时间小于当前事务 ID 的数据或者删除时间大于当前事务 ID 的行）&lt;br/&gt;事务 B 的结果是 (商品 A：10, 商品 B：5）&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;事务 E id =4 修改商品 A 的数量&lt;/span&gt;&lt;br/&gt;&lt;span&gt;事务 B id=2 进行了查询操作（MVCC 只读取创建时间小于当前事务 ID 的数据或者删除时间大于当前事务 ID 的行）&lt;br/&gt;事务 B 的结果是 (商品 A：10, 商品 B：5）&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以当事务 E 提交后，当前读获取的数据和事务 B 读取的快照数据明显不同。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;6.2.5 可解决问题&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;MVCC 可以很好的解决读一致问题，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。而且降低了死锁的概率和解决读写之间堵塞问题。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7 小结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section&gt;&lt;span&gt;LBCC 和 MVCC 都可以解决读一致问题，具体使用哪种方式，要结合业务场景选择最合适的方式，MVCC 和锁也可以结合使用，没有最好只有更好。&lt;/span&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;转自：OSCHINA&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接&lt;span&gt;：&lt;span&gt;https://my.oschina.net/u/4090830/blog/5580720&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;- EOF -&lt;/span&gt;&lt;/p&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_030&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section&gt;&lt;span&gt;推荐阅读&lt;/span&gt;  &lt;span&gt;点击标题可跳转&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651519607&amp;amp;idx=1&amp;amp;sn=9a6e498c86b2d966f1f80fbd364f6c4d&amp;amp;chksm=bd2596088a521f1e3a6b70915917ad333f1e505dabcc8e8688475e3c50ada0bec573bee95752&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;掘地三尺搞定 Redis 与 MySQL 数据一致性问题&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;掘地三尺搞定 Redis 与 MySQL 数据一致性问题&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651509714&amp;amp;idx=1&amp;amp;sn=8d2338d1868103aa7de6cce2aec91a8c&amp;amp;chksm=bd25bfad8a5236bba84735740e968846dd5d51295aca3ee06a61d04ca9d7c1831a3ae1ce9ac6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;缓存和数据库一致性问题，看这篇就够了&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;缓存和数据库一致性问题，看这篇就够了&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看完本文有收获？请转发分享给更多人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关注「ImportNew」，提升Java技能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9166666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2A8tXicCG8ylbWIGfdoDED35IRRySQZTXUkJ1eop9MHApzFibKnOo0diboXpl0rmS5mH78YJhsWQv0dhv718A6kUA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;点赞和在看就是最大的支持&lt;/span&gt;&lt;span&gt;❤️&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>29a8b600b7a530d9b0c6fbc762d6ef30</guid>
<title>cgo 机制 - 从 c 调用 go</title>
<link>https://toutiao.io/k/oq6plpn</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;一、前言&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;去年刚学 go 语言的时候，写了这篇 &lt;span&gt;cgo 实现机制&lt;/span&gt;&lt;span&gt;&lt;sup&gt;[1] &lt;/sup&gt;&lt;/span&gt;，介绍了 cgo 的基本情况。主要介绍的是 &lt;code&gt;go=&amp;gt;c&lt;/code&gt;&lt;span&gt; &lt;/span&gt;这个调用方式，属于比较浅的层次。随着了解的深入，发现&lt;span&gt; &lt;/span&gt;&lt;code&gt;c=&amp;gt;go&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的复杂度又高了一级，所以有了这篇文章。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;二、两个方向&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;首先，cgo 包含&lt;/span&gt;&lt;/span&gt;&lt;span&gt;了两个&lt;/span&gt;&lt;span&gt;&lt;span&gt;方向， &lt;/span&gt;&lt;/span&gt;&lt;code&gt;c=&amp;gt;go&lt;/code&gt;&lt;span&gt; ，&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;code&gt;go=&amp;gt;c&lt;/code&gt;&lt;span&gt; &lt;/span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;相对来说，&lt;span/&gt;&lt;code&gt;go=&amp;gt;c&lt;/code&gt;&lt;span&gt; &lt;/span&gt;是更简单的，是在 go runtime 创建的线程中，调用执行 c 函数。对 go 调度器而言，调用 c 函数，就相当于系统调用。执行环境还是在本线程，只是调用栈有切换，还多了一个函数调用的 ABI 对齐，对于 go runtime 依赖的 GMP 环境，都是现有的，并没有太大的区别。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而&lt;span&gt; &lt;/span&gt;&lt;code&gt;c=&amp;gt;go&lt;/code&gt;&lt;span&gt; &lt;/span&gt;则复杂很多，是在一个 c 宿主创建的线程上，调用执行 go 函数。这意味着，需要在 c 线程中，准备好 go runtime 所需要的 GMP 环境，才能运行 go 函数。以及，go 和 c 对于线程掌控的不同，主要是信号这块。所以，复杂度又高了一级。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;三、GMP 从哪里来&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;首先简单解释一下，为什么需要&lt;span&gt; &lt;/span&gt;&lt;code&gt;GMP&lt;/code&gt; ，因为在 go 函数运行的时候，总是假设是运行在一个 goroutine 环境中，以及绑定有对应的&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;和&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;。比如，要申请内存的时候，则会先从 &lt;span&gt;P&lt;/span&gt; 这一层 cache 的 span 中的获取，如果这些没有的话，go runtime 就没法运行了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;虽然&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;是线程，但是具体实现上，其实就是一个&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的数据结构来表示，对于 c 创建的协程，获取的是&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt; ，也就是单独的表示线程的&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;数据结构。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;简单来说，c 线程需要获取的&lt;span&gt; &lt;/span&gt;&lt;code&gt;GMP&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;，就是三个数据对象。在具体的实现过程中，是分为两步来的：&lt;br/&gt;&lt;/p&gt;&lt;p&gt;1. &lt;code&gt;needm&lt;/code&gt;&lt;span&gt; &lt;/span&gt;获取一个 &lt;span&gt;extra M&lt;/span&gt;&lt;/p&gt;&lt;p&gt;开启了 cgo 的情况下，go runtime 会预先创建好额外的&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;，同时还会创建一个 goroutine，跟这个&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;绑定。所以，获取到 M，也就同时得到了 G。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而且，go runtime 对于 M 并没有限制，可以认为是无限的，也就不存在获取不到 M 的情况。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.&lt;code&gt;exitsyscall&lt;/code&gt;&lt;span&gt; &lt;/span&gt;获取&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;是的，这个就是&lt;span&gt; &lt;/span&gt;&lt;code&gt;go=&amp;gt;c&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的反向过程。只是&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt; 资源是有限的，可能会出现抢不到 &lt;span&gt;P &lt;/span&gt;的情况，此时就得看调度机制了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;四、调度机制&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;简单情况下，&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;和&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;资源都顺利拿到了，这个 c 线程，就可以在 &lt;span&gt;M&lt;/span&gt; 绑定的 goroutine 中运行指定的 go 函数了。更进一步，如果 go 函数很简单，只是简单的做点纯 CPU 计算就结束了，那么这期间则不依赖 go 的调度了。&lt;/p&gt;&lt;p&gt;有两种情况，会发生调度：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;1. exitsyscall 获取不到 P&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;此时没法继续执行了，只能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.将当前&lt;/span&gt;&lt;span&gt; extra M &lt;/span&gt;&lt;span&gt;上绑定的 &lt;/span&gt;&lt;span&gt;g &lt;/span&gt;&lt;span&gt;，放入全局 &lt;/span&gt;&lt;span&gt;g&lt;/span&gt;&lt;span&gt; 等待队列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.将当前 c 线程挂起，等待 &lt;/span&gt;&lt;span&gt;g&lt;/span&gt;&lt;span&gt; 被唤起执行&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 &lt;/span&gt;&lt;span&gt;g&lt;/span&gt;&lt;span&gt; 被唤起执行的时候，因为 &lt;/span&gt;&lt;span&gt;g&lt;/span&gt;&lt;span&gt; 和 &lt;/span&gt;&lt;span&gt;M&lt;/span&gt;&lt;span&gt; 是绑定关系：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.执行 &lt;/span&gt;&lt;span&gt;g&lt;/span&gt;&lt;span&gt; 的那个线程，会挂起，让出 &lt;/span&gt;&lt;span&gt;P&lt;/span&gt;&lt;span&gt; ，唤起等待的 c 线程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.c 线程被唤起之后，拿到 P 继续执行&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;2. go 函数执行过程中发生了协程挂起&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;比如，go 函数中发起了网络调用，需要等待网络响应，按照之前介绍的文章，&lt;/span&gt;&lt;span&gt;Goroutine 调度 - 网络调&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;sup&gt;[2] &lt;/sup&gt;&lt;/span&gt;&lt;span&gt;。当前 &lt;/span&gt;&lt;span&gt;g&lt;/span&gt;&lt;span&gt; 会挂起，唤醒下一个 &lt;/span&gt;&lt;span&gt;g &lt;/span&gt;&lt;span&gt;，继续执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但是，因为 &lt;span&gt;M&lt;/span&gt; 和 &lt;span&gt;g&lt;/span&gt; 是绑定关系，此时会：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1. &lt;span&gt;g&lt;/span&gt; 放入等待队列&lt;/p&gt;&lt;p&gt;2.当前 c 线程被挂起，等待 &lt;span&gt;g&lt;/span&gt; 被唤醒&lt;/p&gt;&lt;p&gt;3. &lt;span&gt;P&lt;/span&gt; 被释放&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 &lt;span&gt;g&lt;/span&gt; 被唤醒的时候，此时肯定不是在原来的 c 线程上了&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.当前线程挂起，让出 &lt;span&gt;P&lt;/span&gt;，唤醒等待的 c 线程&lt;/p&gt;&lt;p&gt;2.c 线程被唤醒后，拿到 &lt;span&gt;P&lt;/span&gt;，继续执行&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;直观来说，也就是在 c 线程上执行的 goroutine，并不像普通的 go 线程一样，参与 go runtime 的调度。对于 go runtime 而言，协程中的网络任务，还是以非阻塞的方式在执行，只是对于 c 线程而言，则完全是以阻塞的方式来执行了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么需要这样，还是因为线程的调用栈，只有一个，没有办法并发，需要把线程挂起，保护好调用栈。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PS：这里的执行流程，其实跟上面抢不到 P 的流程，很类似，底层也是同一套函数在跑（核心还是&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;schedule&lt;/code&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;五、信号处理&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;另外一大差异是，信号处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. c 语言世界里，把信号处理的权利/责任，完全交给用户了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. go 语言，则在 runtime 做了一层处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，一个具体的问题，当程序运行过程中，发生了 segfault 信号，此时是应该由 go 来处理，还是 c 来响应信号呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案是，看发生 segfault 时的上下文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.如果正在运行 go 代码，则交给 go runtime 来处理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.如果正在运行 c 代码，则还是 c 来响应&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那具体是怎么实现的呢？信号处理还是比较复杂的，有比较多的细节，这里我们只介绍几个核心点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;1. sighandler 注册&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;首先，对于操作系统而言，同一个信号，只能有一个 handler 。再看 go 和 c 发生 sighandler 注册的时机：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1. go 编译产生的 so 文件，被加载的时候，会注册 sighandler（仅针对 go 需要用的信号），并且会把原始的 sighandler 保存下来。&lt;/p&gt;&lt;p&gt;2. c 可以在任意的时间，注册 sighandler，可以是任意的信号。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，推荐的做法是，在加载 go so 之前，c 先完成信号注册，在 go so 加载之后，不要再注册 sighandler 了，避免覆盖 go 注册 sighandler。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;2.信号处理&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;对于最简单的情况，如果一个信号，只有 c 注册了 sighandler，那么还是按照常规 c 信号处理的方式来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对于 sigfault 这种，go 也注册了 sighandler 的信号，按照这个流程来：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.操作系统触发信号时，会调用 go 注册的 sighandler（最佳实践中，go 的信号注册在后面）；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.go sighandler 先判断是否在 c 上下文中（简单的理解，也就是没有 g，实际上还是挺复杂的）；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;3.如果，在 c 上下文中，会调用之前保存的原始 sighandler（没有原始的 sighandler，则会临时恢复 signal 配置，重新触发信号）；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;4.如果，在 go 上下文中，则会执行普通的信号处理流程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其中，2 和 3 是最复杂的，因为 cgo 包含了两个方向，以及信号还有 sigmask 等等额外的因素，所以这里细节是非常多的，不过思路方向还是比较清晰的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;六、优化&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;上篇&lt;span&gt; &lt;/span&gt;&lt;span&gt;cgo 实现机制&lt;/span&gt;&lt;span&gt;&lt;sup&gt;[1] &lt;/sup&gt;&lt;/span&gt;，提过优化一些思路，不过主要针对&lt;span&gt; &lt;/span&gt;&lt;code&gt;go =&amp;gt; c&lt;/code&gt;&lt;span&gt; &lt;/span&gt;这个方向。因为&lt;span&gt; &lt;/span&gt;&lt;code&gt;c =&amp;gt; go&lt;/code&gt; 的场景中，还有其他更重要的优化点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;1.复用 extra M&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;通常情况下，最大的性能消耗点在获取/释放&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.上面提到，从 c 进入 go，需要通过&lt;span&gt; &lt;/span&gt;&lt;code&gt;needm&lt;/code&gt;&lt;span&gt; &lt;/span&gt;来获取&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt; 。这期间有 5 个信号相关的系统调用。比如：避免死锁用的，临时屏蔽所有信号，以及开启 go 所需要的信号。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2.从 go 返回 c 的时候，通过&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;dropm&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&lt;span&gt;来释放&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这期间有 3 个信号相关的系统调用。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;目的是恢复到&lt;/span&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;needm&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&lt;span&gt;之前的信号状态（因 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;span&gt;needm &lt;/span&gt;&lt;span&gt;&lt;span&gt;强制开启了 go 必须的信号）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这两个操作，在 MOSN 新的 MOE 架构的测试中，可以看到约占整体 2~5% 的 CPU 占用，还是比较可观的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;了解了瓶颈之后，也就成功了一半。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;优化思路也很直观，第一次从 go 返回 c 的时候，不释放&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;，继续留着使用，下一次从 c 进入 go 也就不需要再获取&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;了。因为&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;资源是无限的，c 线程一直占用一个&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;也无所谓。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过，在 c 线程退出的时候，还是需要释放&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;，避免泄漏。所以，这个优化，在 windows 就不能启用了，因为 windows 的 pthread API 没有线程退出的 callback 机制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前实现了一版在 &lt;span&gt;CL 392854&lt;/span&gt;&lt;span&gt;&lt;sup&gt;[3] &lt;/sup&gt;&lt;/span&gt;。虽然通过了一个大佬的初步 review，以及跑通了全部测试，不过，估计要合并还要很久...因为这个 PR 已经比较大了，被标记 L size 了，这种 CL 估计大佬们 review 起来也头大...&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在简单场景的测试中，单次&lt;span&gt; c =&amp;gt; go &lt;/span&gt;的调用，从&lt;span&gt; &lt;/span&gt;&lt;code&gt;~1600ns&lt;/code&gt;&lt;span&gt; &lt;/span&gt;优化到了&lt;span&gt; &lt;/span&gt;&lt;code&gt;~140ns&lt;/code&gt;&lt;span/&gt;，提升 10 倍，达到了接近 go =&amp;gt; c 的水平（&lt;/span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;code&gt;~80ns&lt;/code&gt;&lt;span&gt;&lt;span&gt; ）效果还是挺明显的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;实现上主要有两个较复杂的点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.接收到信号时，判断在哪个上下文里，以及是否应该转发给 c。因为 cgo 有两个方向，而且这两个方向又是可以在一个调用栈中同时发生的，以及信号还有&lt;span&gt; &lt;/span&gt;&lt;code&gt;mask&lt;/code&gt;&lt;span/&gt; ，系统默认 handler 之分。这里面已经不是简单的状态机可以描述的，go runtime 在这块有约 100 + 行的核心判断代码，以应对各式各样的用法。估计没几个人可以全部记住，只有碰到具体场景临时去分析。或者在跑测试用例失败的时候，才具体去分析。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.在 c 线程退出，callback 到 go 的时候，涉及到 c 和 go function call ABI 对齐。这里主要的复杂度在于，需要处理好不同的 CPU 体系结构，以及操作系统上的差异。所以工作量还是比较大的。比如 arm ，arm64 ， 期间有一个有意思的坑，Aarch64 的 stack pointer 必须是 16 byte 对齐的，否则会触发 bus error 信号。（也因此 arm64 的压栈/出栈指令，都是两个两个操作的）&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;2.获取不到 P&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;从 c 进入 go，获取 GMP 的过程中，只有&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;资源是受限的，在负载较高时，获取不到&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;也是比较容易碰到的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当获取不到&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;时，c 线程会挂起，等待进入全局队列的&lt;span&gt; &lt;/span&gt;&lt;code&gt;g&lt;/code&gt;&lt;span&gt; &lt;/span&gt;被唤醒。这个过程对于 go runtime 而言是比较合理的，但是对于 c 线程则比较危险，尤其当 c 线程中跑的是多路复用的逻辑，则影响更大了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此时有两个优化思路：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.类似&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra M&lt;/code&gt; ，再给 c 线程绑一个&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;，或者预先绑定一个&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt; &lt;span&gt;。&lt;/span&gt;这样 c 线程就不需要被挂起了。这个思路，最大的挑战在于&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;，是不受常规&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;数量的限制，对于 go 中&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的定义，是一个不小的挑战。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.将&lt;span&gt; &lt;/span&gt;&lt;code&gt;g&lt;/code&gt;&lt;span&gt; &lt;/span&gt;不放入全局队列，改为放到优先级更高的 &lt;code&gt;P.runnext&lt;/code&gt;&lt;span&gt; &lt;/span&gt;，这样 &lt;span&gt;g&lt;/span&gt; 可以被快速的调度到，c 线程可以等待的时间更短了。这个思路，最大的挑战则在于，对这个&lt;span&gt; &lt;/span&gt;&lt;code&gt;g&lt;/code&gt;&lt;span&gt; &lt;/span&gt;加了优先级的判断，或许有一点有悖于 &lt;span&gt;g&lt;/span&gt; 应该是平等的原则。不过应该也还好，&lt;span&gt; &lt;/span&gt;&lt;code&gt;P.runnext&lt;/code&gt;&lt;span&gt; &lt;/span&gt;本来也是为了应对某些需要优先的场景的，这里只是多了一个场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个优化方向，还没有 CL，不过我们有同学在搞了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;3.尽快释放 P&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;当从 go 返回 c 的时候，会调用&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;entersyscall&lt;/code&gt;&lt;span/&gt;&lt;span&gt; ，具体是，&lt;code&gt;M&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;并没有完全解除绑定，而是让&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;进入&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;code&gt;syscall&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;的状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来，会有两种情况：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.很快又有了下一个 &lt;span&gt;c=&amp;gt;go&lt;/span&gt; 调用，则直接用这个 &lt;span&gt;P&lt;/span&gt; ；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.sysmon 会强制解除绑定。对于进入&lt;span&gt; &lt;/span&gt;&lt;code&gt;syscall&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的 &lt;span&gt;P&lt;/span&gt; ，sysmon 会等 20 us =&amp;gt; 10 ms，然后将 P 抢走释放掉。等待时间跨度还是挺大的，具体多久就看命了，主要看&lt;span&gt; &lt;/span&gt;&lt;code&gt;sysmon&lt;/code&gt;&lt;span&gt; &lt;/span&gt;是否之前已经长时间空闲了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对于 go =&amp;gt; c 这方向，一个 syscall 的等待时间，通常是比较小的，所以这套机制是合适的。但是对于 c =&amp;gt; go 这个方向，这种伪 syscall 的等待时间，取决于两个 c =&amp;gt; go 调用的间隔时间，其实不太有规律的。所以，可能会造成&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;资源被浪费 20us =&amp;gt; 10ms。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，又有一个优化方向，两个思路：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.从 go 返回 c 的时候，立即释放&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;，这样不会浪费&lt;span&gt; &lt;/span&gt;&lt;code&gt;P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.调整下 sysmon，针对这种场景，有一种机制，能尽量在 20 us 就把 P 抢走。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其中，思路 1 ，这个 CL 411034 里顺便实现了。这个本来是为了修复 go trace 在 cgo 场景下不能用的 bug ，改到这个点，是因为跟 Michael 大佬讨论，引发的一个改动（一开始还没有意识到是一个优化）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;七、总结&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;不知道看到这里，你是否一样觉得，&lt;span&gt;c =&amp;gt; go&lt;/span&gt; 比 &lt;span&gt;go =&amp;gt; c&lt;/span&gt; 的复杂度又高了一级。反正我是有的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先，c 线程得拿到 &lt;span&gt;GMP&lt;/span&gt; 才能运行 go 函数，然后，c 线程上的 g 发生了协程调度事件的时候，&lt;span&gt;调度策略又跟普通的 go 线程不一样。&lt;/span&gt;另外一个大坑则是信号处理，在 go runtime 接管了 sighandler 之后，我们还需要让 c 线程之前注册的 sighandler 一样有效，使 c 线程感觉不到被 go runtime 接管了一道。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;优化这块，相对来说，比较好理解一些，主要是涉及到 go 目前的实现方式，并没有太多底层原理上的改进。复用 extra M 属于降低 CPU 开销；P 相关的获取和释放，则更多涉及到延时类的优化（如果搞了 extra P，则也会有 CPU 的优化效果）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;八、最后&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;最后吐个槽，其实目前的实现方案中，从 c 调用 go 的场景，go runtime 的调度策略，更多是考虑 go 这一侧，比如 goroutine 和 P 不能被阻塞。但是，对 c 线程其实是很不友好的，只要涉及到等待，就会把 c 线程挂起...&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因为 go 的并发模型中，线程挂起通常是可以接受的，但是对于宿主 c 线程而言，有时候被阻塞挂起则是很敏感的。比如，在 MOSN 的 MOE 架构中，对于这类可能导致 c 线程被挂起的行为，需要很小心的处理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那有没有办法改变，也是有的，只是改动相对要大一点，大体思路是，将 c 调用 go 的 API 异步化：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;g = GoFunc(a, b)&lt;br/&gt;&lt;span&gt;printf&lt;/span&gt;(&lt;span&gt;&quot;g.status: %d, g.result: %d\n&quot;&lt;/span&gt;, g.status, g.result)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;意思是，调用 Go 函数，不再同步返回函数返回值，而是返回一个带状态&lt;span&gt; &lt;/span&gt;&lt;code&gt;g&lt;/code&gt;，这样的好处是，因为 API 异步了，所以执行的时候，也不必同步等待 g 返回了。如果碰到 g 被挂起了，直接返回&lt;span&gt; &lt;/span&gt;&lt;code&gt;status = yield&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的 g 即可，goroutine 协程继续走 go runtime 的调度，c 线程也不必挂起等待了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这样的设计，对于 c 线程是最友好的，当然也还得有一些配套的改动，比如缺少 P 的时候，得有个&lt;span&gt; &lt;/span&gt;&lt;code&gt;extra P&lt;/code&gt;&lt;span&gt; &lt;/span&gt;更好一些，等其他的细节。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过，这样子的改动还是比较大的，让 go 官方接受这种设计，应该还是比较难的，以后没准可以试试，万一接受了呢~&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;九、相关链接&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span&gt;[1] cgo 实现机制：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;em&gt;&lt;span&gt;https://uncledou.site/2021/go-cgo/&lt;/span&gt;&lt;/em&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2] &lt;span&gt;Goroutine 调度 - 网络调用：&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;em&gt;&lt;span&gt;https://uncledou.site/2021/goroutine-schedule-network/&lt;/span&gt;&lt;/em&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[3] &lt;span&gt;CL 392854 :&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;em&gt;&lt;span&gt;https://go-review.googlesource.com/c/go/+/392854&lt;/span&gt;&lt;/em&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; 本周推荐阅读 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzMzU5Mjc1Nw==&amp;amp;mid=2247513902&amp;amp;idx=1&amp;amp;sn=be00c5af2e9775a4039430bf187e16f4&amp;amp;chksm=faa358f4cdd4d1e23d7e9c93b4a94d6e6c377f51eb5e96b6dd5f74b840e48ebd3f518c4bf80a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;538&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;229&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/nibOZpaQKw0icVic2YozAVFT3Glnb0kGOm9Itgia880Ug1iaAMicZVsrccXmGLmDPkIYRezMRcICZo7h84W0wVoVabvA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;span&gt;MOSN 反向通道详解&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzMzU5Mjc1Nw==&amp;amp;mid=2247512138&amp;amp;idx=1&amp;amp;sn=851abb8d07d47f703e33978c9c125c59&amp;amp;chksm=faa35f90cdd4d6869c6cd4934c042484dbe1063c3fb85462d2f33e936b96240ae33d02d18c3a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;538&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;229&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nibOZpaQKw0ib6ocxPJUcdDfHVIL3niax97WtwdyHsicym5kbOAGaZlXEesshLic6uK6SMkh2X3xRHFAGWkKibITVdKg/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;span&gt;&lt;span&gt;Go 原生插件使用问题全解析&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzMzU5Mjc1Nw==&amp;amp;mid=2247516046&amp;amp;idx=1&amp;amp;sn=c8ed0fbbc18b4377778c2ed06c7332ba&amp;amp;chksm=faa35054cdd4d9425b6780ae5ed1a6b83ab16afd9d870affba350c8002a2c4e2efdb85abc603&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot; hasload=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;246&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nibOZpaQKw08VNbtYZicic5Nog5MV3VxrPUKQaiakOMvYf25J0xpOzIRCoicGHWor1G3liaOn4ibVEuOKHVAc3HuoibbCw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;span&gt;Go 内存泄漏，pprof 够用了么？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzMzU5Mjc1Nw==&amp;amp;mid=2247516354&amp;amp;idx=1&amp;amp;sn=804c45c191a9e319d4a47135e301f91a&amp;amp;chksm=faa36f18cdd4e60e445dd9b4acfe51e40e2060349199e6160811ca069c2c54270d42ec0ca2b7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;538&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;229&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nibOZpaQKw0icJDEQVeM5ibuaTdsYLgTOfSBhic5Ule6GK401ibJX7XuBGz4RV02AicSTHkg8Jw5BicCKNEsck478h8oA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;span&gt;从规模化平台工程实践，我们学到了什么？&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8148148148148148&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/nibOZpaQKw084tjDIkMOl22S8SFeCHHuZwaf4pQdLma9LNCwTSjtUcZBa4H6GoxvmvctKW4KcCFtuHYsm2tic4ZQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5ee89c09de1dccdefdedf6b5eafa7a34</guid>
<title>OpenJDK 的 Amber 项目对 Java 入口类的修改方向</title>
<link>https://toutiao.io/k/8rfhzod</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;v_desc&quot; class=&quot;video-desc-v1&quot; data-v-220c9cc3=&quot;&quot;&gt;&lt;p class=&quot;desc-info desc-v2&quot;&gt;&lt;span class=&quot;desc-info-text&quot;&gt;Oracle 的 Java 语言架构师 Brian Goetz 发布了 OpenJDK 的 Amber 项目的新的设计笔记，标题是 Paving the on-ramp。该笔记阐述了 Amber 项目会对 Java 程序中的执行入口类所做的修改。&lt;/span&gt;&lt;/p&gt;&lt;p report-id=&quot;abstract_unspread&quot; class=&quot;toggle-btn&quot;&gt;&lt;span&gt;收起&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>