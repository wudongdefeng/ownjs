<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>58951e9aa1dbca3d56bcfaa665fd465c</guid>
<title>Golang 整洁架构实践</title>
<link>https://toutiao.io/k/g4os0y6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content              autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-backh=&quot;246&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4250681198910082&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VY8SELNGe979Bb4KNoEWxibDp8V9LPhyj4ibVSiajGqurEek0gn3LrTibpnibSFXrz1kdNZRhibia7ppg4ZjxsfNuaJTw/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;734&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-backh=&quot;56&quot; data-backw=&quot;558&quot; data-ratio=&quot;0.1008174386920981&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VY8SELNGe979Bb4KNoEWxibDp8V9LPhyjpibq1WkazIado7OjDfRPLKTaL97YG2bPBF2uWsD8bNkq954KZJtoUUA/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;734&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template-rows=&quot;1&quot; data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;👉 腾小云导读&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;为了降低系统组件之间的耦合、提升系统的可维护性，一个好的代码框架显得尤为重要。本文将为大家介绍众所周知的三种代码框架，并从三种框架引申出COLA 架构以及作者基于 COLA 架构设计的 Go 语言项目脚手架实践方案。希望能给广大开发爱好者带来帮助和启发！&lt;/span&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;👉 看目录，点收藏&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.为什么要有代码架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.好的代码架构是如何构建的&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    2.1 整洁架构&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    2.2 洋葱架构&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    2.3 六边形架构&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    2.4 COLA架构&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.推荐一种 Go 代码架构实践&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.总结&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;*本文提及的架构主要指项目组织的“代码架构”，注意与微服务架构等名词中的服务架构进行区分。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;p&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h1 data-mid=&quot;&quot;&gt;&lt;span&gt;01&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;为什么要有代码架构&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;历史悠久的项目大都会有很多开发人员参与“贡献”，在没有好的指导规则约束的情况下，大抵会变成一团乱麻。剪不断，理还乱，也没有开发勇士愿意去剪去理。被迫接手的开发勇士如果想要增加一个小需求，可能需要花10倍的时间去理顺业务逻辑，再花 10 倍的时间去补充测试代码，实在是低效又痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;这是一个普遍的痛点问题，有无数开发者尝试过去解决它。这么多年发展下来，业界自然也诞生了很多软件架构。大家耳熟能详的就有六边形架构&lt;/span&gt;&lt;span&gt;（Hexagonal Architecture）&lt;/span&gt;&lt;span&gt;，洋葱架构&lt;/span&gt;&lt;span&gt;（Onion Architecture）&lt;/span&gt;&lt;span&gt;，整洁架构&lt;/span&gt;&lt;span&gt;（Clean Architecture）&lt;/span&gt;&lt;span&gt;等。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;这些架构在细节上有所差异，但是核心目标是一致的：致力于实现软件系统的&lt;/span&gt;&lt;strong&gt;&lt;span&gt;关注点分离&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;（separation of concerns）&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关注点分离之后的软件系统都具备如下特征：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;不依赖特定 UI。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;UI 可以任意替换，不会影响系统中其他组件。从 Web UI 变成桌面 UI，甚至变成控制台 UI 都无所谓，业务逻辑不会被影响。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;不依赖特定框架。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;以 JavaScript 生态举例，不管是使用 web 框架 koa、express，还是使用桌面应用框架 electron，还是控制台框架 commander，业务逻辑都不会被影响，被影响的只会是框架接入的那一层。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;不依赖特定外部组件。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;系统可以任意使用 MySQL、MongoDB或 Neo4j 作为数据库，任意使用 Redis、Memcached或 etcd 作为键值存储等。业务逻辑不会因为这些外部组件的替换而变化。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;容易测试。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;核心业务逻辑可以在不需要 UI、不需要数据库、不需要 Web 服务器等一切外界组件的情况下被测试。这种纯粹的代码逻辑意味着清晰容易的测试。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;软件系统有了这些特征后，易于测试，更易于维护、更新，大大减轻了软件开发人员的心理负担。所以，好的代码架构值得推崇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;p&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h1 data-mid=&quot;&quot;&gt;&lt;span&gt;02&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;好的代码架构是如何构建的&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前文所述的三个架构在理念上是近似的，从下文图 1 到图 3 三幅架构图中也能看出相似的圈层结构。图中可以看到，越往外层越具体，越往内层越抽象。这也意味着，越往外越有可能发生变化，包括但不限于框架升级、中间件变更、适配新终端等等。&lt;/span&gt;&lt;/p&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.1&lt;/span&gt;&lt;/strong&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;整洁架构&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7344559585492227&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9SHTQicTvXQibUeOvNgfE3Xvz5VrtI8T1L2bdLw1xAn38BskQp1XVSmUWA/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;772&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 1 The Clean Architecture, Robert C. Martin&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;图 1&lt;strong&gt; 整洁架构&lt;/strong&gt;的同心圆结构中可以看见三条由外向内的黑色箭头，它表示依赖规则&lt;/span&gt;&lt;span&gt;（The Dependency Rule）&lt;/span&gt;&lt;span&gt;。依赖规则规定外层的代码可以依赖内层，但是内层的代码不可以依赖外层。也就是说内层逻辑不可以依赖任何外层定义的变量、函数、结构体、类、模块等等代码实体。假如最外层蓝色层“Frameworks &amp;amp; Drivers” DB 处使用了 go 语言的 gorm 三方库，并定义了 gorm 相关的数据库结构体及其 tag 等。那么内层的 Gateways、Use Cases、Entities 等处不可以引用任何外层中 gorm 相关的结构体或方法，甚至不应该感知到 gorm 的存在。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;核心层的 Entities 定义表示核心业务规则的核心业务实体。这些实体既可以是带方法的类，也可以是带有一堆函数的结构体。但它们必须是高度抽象的，只可以随着核心业务规则而变化，不可以随着外层组件的变化而变化。以简单博客系统举例的话，此层可以定义 Blog、Comment 等核心业务实体。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;type&lt;/span&gt; Blog &lt;span&gt;struct&lt;/span&gt; {...}&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;type&lt;/span&gt; Comment &lt;span&gt;struct&lt;/span&gt; {...}&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;应用业务层的 Use Cases 应该包含软件系统的所有业务逻辑。该层控制所有流向和流出核心层的数据流，并使用核心层的实体及其业务规则来完成业务需求。此层的变更不会影响核心层、更外层的变更，例如开发框架、数据库、UI 等变化，也不会影响此层。接着博客系统的例子，此层可以定义 BlogManager 接口，并定义其中的 CreateBlog, LeaveComment 等业务逻辑方法。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;type&lt;/span&gt; BlogManager &lt;span&gt;interface&lt;/span&gt; {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    CreateBlog(...) ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    LeaveComment(...) ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接口适配层的 Controllers 将外层输入的数据格式转换成内层 Use Cases 和 Entities 方便使用的格式，然后 Presenters，Gateways 再将内层处理结果转换成外层方便使用的格式，然后再由更外层呈现到 Web、UI 或者写入到数据库。假如系统选择关系型数据库做为其持久化方案的话，那么所有关于 SQL 的处理都应该在此层完成，更内层不需要感知到任何数据库的存在。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;同理，假如系统与外界服务通信，那么所有有关外界服务数据的转化都在此层完成，更内层也不需要感知到外界服务的存在。外层通过此层传递数据一般通过DTO&lt;/span&gt;&lt;span&gt;（Data Transfer Object）&lt;/span&gt;&lt;span&gt;或者DO&lt;/span&gt;&lt;span&gt;（Data Object）&lt;/span&gt;&lt;span&gt;完成。接上文博客系统例子，示例代码如下：&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;&lt;span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;type&lt;/span&gt; BlogDTO &lt;span&gt;struct&lt;/span&gt; { &lt;span&gt;// Data Transfer Object&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    Content &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`json:&quot;...&quot;`&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;// DTO 与 model.Blog 的转化在此层完成&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;CreateBlog&lt;/span&gt;&lt;span&gt;(b *model.Blog)&lt;/span&gt;&lt;/span&gt; { &lt;br mpa-from-tpl=&quot;t&quot;/&gt; dbClient.Create(&amp;amp;blog{...})&lt;br mpa-from-tpl=&quot;t&quot;/&gt; ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;该层包含具体的框架和依赖工具的细节，例如系统使用的数据库、Web 框架、消息队列等等。此层主要帮助外部的框架、工具，和内层进行数据衔接。接博客系统例子，框架和驱动层如果使用 gorm 来操作数据库，则相关的示例代码如下：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;&lt;span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;&quot;gorm.io/driver/mysql&quot;&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;&quot;gorm.io/gorm&quot;&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;type&lt;/span&gt; blog &lt;span&gt;struct&lt;/span&gt; { &lt;span&gt;// Data Object&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    Content &lt;span&gt;string&lt;/span&gt; &lt;span&gt;`gorm:&quot;...&quot;`&lt;/span&gt; &lt;span&gt;// 本层的数据库 ORM 如果替换，此处的 tag 也需要随之改变&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;} &lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;type&lt;/span&gt; MySQLClient &lt;span&gt;struct&lt;/span&gt; { DB *gorm.DB }&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;New&lt;/span&gt;&lt;span&gt;(...)&lt;/span&gt;&lt;/span&gt; { gorm.Open(...) ... }&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;Create&lt;/span&gt;&lt;span&gt;(...)&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;...&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;至此，整洁架构图中的四层已介绍完成。但此图中的四层结构仅作示意，整洁架构并不要求软件系统必须按照此四层结构设计。只要软件系统能保证“由外向内”的依赖规则，系统的层数多少可自由决定。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;整体结构&lt;/span&gt;与&lt;span&gt;洋葱架构二者齐名且结构图&lt;/span&gt;相似，都是四层同心圆。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.2&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;洋葱架构&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7076502732240437&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9S757zcZ1JlDIwibGWUrNnTUsyjvFBujNMNJ8E1bQcYGZrkPjdezOILVw/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;366&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 2 Onion Architecture, Jeffrey Palermo&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 2 中&lt;strong&gt;洋葱架构&lt;/strong&gt;最核心的 Domain Model 为组织中核心业务的状态及其行为模型，与整洁架构中的 Entities 高度一致。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其外层的 Domain Services 与整洁架构中的 Use Cases 职责相近。更外层的 Application Services 桥接 UI 和 Infrastructue 中的数据库、文件、外部服务等，与整洁架构中的  Interface Adaptors 功能相同。最边缘层的 User Interface 与整洁架构中的最外层 UI 部分一致，Infrastructure 则与整洁架构中的 DB， Devices， External Interfaces 作用一致，只有 Tests 部分稍有差异。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同前两者齐名的六边形架构，虽然外形不是同心圆，但是结构上还是有很多对应的地方。&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.3&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;六边形架构&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9SofMoMc8sEAFzEgXEA2DDibgFuiclZ66lg9KBNB2TzqEO7oNX7Vl83Rrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 3 Hexagon Architecture, Andrew Gordon&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;图 3 &lt;strong&gt;六边形架构&lt;/strong&gt;中灰色箭头表示依赖注入&lt;/span&gt;&lt;span&gt;（Dependency Injection）&lt;/span&gt;&lt;span&gt;，其与整洁架构中的依赖规则&lt;/span&gt;&lt;span&gt;（The Dependency Rule）&lt;/span&gt;&lt;span&gt;有异曲同工之妙，也限制了整个架构各组件的依赖方向必须是“由外向内”。图中的各种 Port 和 Adapter 是六边形架构的重中之重，故该架构别称 Ports and Adapters。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.562962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9Suu0Z6MuU3ndxk1hVE2OajkpO8YZ4ujPHCicYea8Vl7F0Omn01kfuI6w/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 4 Hexagon Architecture Phase 1, Pablo Martinez&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;如图 4 所示，在六边形架构中，来自驱动边&lt;/span&gt;&lt;span&gt;（Driving Side）&lt;/span&gt;&lt;span&gt;的用户或外部系统输入指令通过左边的 Port &amp;amp; Adapter 到达应用系统，处理后，再通过右边的 Adapter &amp;amp; Port 输出到被驱动边&lt;/span&gt;&lt;span&gt;（Driven Side）&lt;/span&gt;&lt;span&gt;的数据库和文件等。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;Port 是系统的一个与具体实现无关的入口，该入口定义了外界与系统通信的接口&lt;/span&gt;&lt;span&gt;（interface）&lt;/span&gt;&lt;span&gt;。Port 不关心接口的具体实现，就像 USB 端口允许多种设备通过其与电脑通信，但它不关心设备与电脑之间的照片、视频等等具体数据是如何编解码传输的。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.562962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9S3eF9jkKGQkibBlRwAgIicA47jAgVWTu5CEibhnVcelFgCBLBw8eb3icrjQ/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 5 Hexagon Architecture Phase 2, Pablo Martinez&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图 5 所示，Adapter 负责 Port 定义的接口的技术实现，并通过 Port 发起与应用系统的交互。例如，图左 Driving Side 的 Adapter 可以是一个 REST 控制器，客户端通过它与应用系统通信。图右 Driven Side 的 Adapter 可以是一个数据库驱动，应用系统的数据通过它写入数据库。此图中可以看到，虽然六边形架构看上去与整洁架构不那么相似，但其应用系统核心层的 Domain 、边缘层的User Interface 和 Infrastructure 与整洁架构中的 Entities 和 Frameworks &amp;amp; Drivers 完全是一一对应的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;再次回到图 3 的六边形架构整体图：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以 Java 生态为例，Driving Side 的 HTTP Server In Port 可以承接来自 Jetty 或 Servlet 等 Adapter 的请求，其中 Jetty 的请求可以是来自其他服务的调用。既处在 Driving Side 又处在 Driven Sides 中的 Messaging In/Out Port 可以承接来自 RabbitMQ 的事件请求，也可以将 Application Adapters 中生成的数据写入到 RabbitMQ。Driven Side 的 Store Out Port 可以将 Application Adapters 产生的数据写入到 MongoDB；HTTP Client Out Port 则可以将 Application Adapters 产生的数据通过 JettyHTTP 发送到外部服务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其实，不仅国外有优秀的代码架构，国内也有。&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.4&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;COLA架构&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;国内开发者在学习了六边形架构、洋葱架构和整洁架构之后，提出了&lt;strong&gt; COLA&lt;/strong&gt; &lt;/span&gt;&lt;span&gt;（Clean Object-oriented and Layered Architecture）&lt;/span&gt;&lt;strong&gt;&lt;span&gt;架构&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，其名称含义为「整洁的基于面向对象和分层的架构」。它的核心理念与国外三种架构相同，都是提倡以业务为核心，解耦外部依赖，分离业务复杂度和技术复杂度[4]。整体架构形式如图 6 所示。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7975460122699386&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9SUHou7Wg6wzH1cTTf8EibUtKo4Cy1GGa3rWCwGWdFLXibj5ZpkFFQmRtQ/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;815&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 6 COLA 架构, 张建飞&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;虽然 COLA 架构不再是同心圆或者六边形的形式，但是还是能明显看到前文三种架构的影子。Domain 层中 model 对应整洁架构的 Entities、六边形架构和洋葱架构中的 Domain Model。Domain 层中 gateway 和 ability 对应整洁架构的 Use Cases、六边形架构中的 Application Logic以及洋葱架构中的 Domain Services。App 层则对应整洁架构 Interface Adapters 层中的 Controllers、Gateways和 Presenters。最上方的 Adapter 层和最下方的 Infrastructure 层合起来与整洁架构的边缘层 Frameworks &amp;amp; Drivers 相对应。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Adapter 层上方的 Driving adater 与 Infrastructure 层下方的 Driven adapter 更是与六边形架构中的 Driving Side 和 Driven Side 高度相似。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;COLA 架构在 Java 生态中落地已久，也为开发者们提供了 Java 语言的 archetype，可方便地用于 Java 项目脚手架代码的生成。笔者受其启发，推出了一种符合 COLA 架构规则的 Go 语言项目脚手架实践方案。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;p&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h1 data-mid=&quot;&quot;&gt;&lt;span&gt;03&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;推荐一种 Go 代码架构实践&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;项目目录结构如下：&lt;/span&gt;&lt;/section&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;span&gt;├── adapter // Adapter层，适配各种框架及协议的接入，比如：Gin，tRPC，Echo，Fiber 等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;├── application // App层，处理Adapter层适配过后与框架、协议等无关的业务逻辑&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── consumer //（可选）处理外部消息，比如来自消息队列的事件消费&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── dto // App层的数据传输对象，外层到达App层的数据，从App层出发到外层的数据都通过DTO传播&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── executor // 处理请求，包括command和query&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   └── scheduler //（可选）处理定时任务，比如Cron格式的定时Job&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;├── domain // Domain层，最核心最纯粹的业务实体及其规则的抽象定义&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── gateway // 领域网关，model的核心逻辑以Interface形式在此定义，交由Infra层去实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   └── model // 领域模型实体&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;├── infrastructure // Infra层，各种外部依赖，组件的衔接，以及domain/gateway的具体实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── cache //（可选）内层所需缓存的实现，可以是Redis，Memcached等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── client //（可选）各种中间件client的初始化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── config // 配置实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── database //（可选）内层所需持久化的实现，可以是MySQL，MongoDB，Neo4j等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── distlock //（可选）内层所需分布式锁的实现，可以基于Redis，ZooKeeper，etcd等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── log // 日志实现，在此接入第三方日志库，避免对内层的污染&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── mq //（可选）内层所需消息队列的实现，可以是Kafka，RabbitMQ，Pulsar等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── node //（可选）服务节点一致性协调控制实现，可以基于ZooKeeper，etcd等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   └── rpc //（可选）广义上第三方服务的访问实现，可以通过HTTP，gRPC，tRPC等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;└── pkg // 各层可共享的公共组件代&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由此目录结构可以看出通过 Adapter 层屏蔽外界框架、协议的差异，Infrastructure 层囊括各种中间件和外部依赖的具体实现，App 层负责组织输入、输出， Domain 层可以完全聚焦在最纯粹也最不容易变化的核心业务规则上。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;按照前文 infrastructure 中目录结构，各子目录中文件样例参考如下：&lt;/span&gt;&lt;/section&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;span&gt;├── infrastructure&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── cache&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── redis.go // Redis 实现的缓存&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── client&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   ├── kafka.go // 构建 Kafka client&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   ├── mysql.go // 构建 MySQL client&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   ├── redis.go // 构建 Redis client（cache和distlock中都会用到 Redis，统一在此构建）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── zookeeper.go // 构建 ZooKeeper client&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── config&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── config.go // 配置定义及其解析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── database&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   ├── dataobject.go // 数据库操作依赖的数据对象&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── mysql.go // MySQL 实现的数据持久化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── distlock&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   ├── distributed_lock.go // 分布式锁接口，在此是因为domain/gateway中没有直接需要此接口&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── redis.go // Redis 实现的分布式锁&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── log&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── log.go // 日志封装&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── mq&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   ├── dataobject.go // 消息队列操作依赖的数据对象&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── kafka.go // Kafka 实现的消息队列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   ├── node&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   │   └── zookeeper_client.go // ZooKeeper 实现的一致性协调节点客户端&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│   └── rpc&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│       ├── dataapi.go // 第三方服务访问功能封装&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;│       └── dataobject.go // 第三方服务访问操作依赖的数据对象&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;再接前文提到的博客系统例子，假设用 Gin 框架搭建博客系统 API 服务的话，架构各层相关目录内容大致如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;// Adapter 层 router.go，路由入口&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    &lt;span&gt;&quot;mybusiness.com/blog-api/application/executor&quot;&lt;/span&gt; &lt;span&gt;// 向内依赖 App 层&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    &lt;span&gt;&quot;github.com/gin-gonic/gin&quot;&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewRouter&lt;/span&gt;&lt;span&gt;(...)&lt;/span&gt; &lt;span&gt;(*gin.Engine, error)&lt;/span&gt;&lt;/span&gt; {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  r := gin.Default()&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  r.GET(&lt;span&gt;&quot;/blog/:blog_id&quot;&lt;/span&gt;, getBlog)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;getBlog&lt;/span&gt;&lt;span&gt;(...)&lt;/span&gt; ...&lt;/span&gt; {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  &lt;span&gt;// b&#x27;s type: *executor.BlogOperator&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  result := b.GetBlog(blogID)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  &lt;span&gt;// c&#x27;s type: *gin.Context&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  c.JSON(..., result)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;如代码所体现，Gin 框架的内容会被全部限制在 Adapter 层，其他层不会感知到该框架的存在。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;// App 层 executor/blog_operator.go&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;&quot;mybusiness.com/blog-api/domain/gateway&quot;&lt;/span&gt; &lt;span&gt;// 向内依赖 Domain 层&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;type&lt;/span&gt; BlogOperator &lt;span&gt;struct&lt;/span&gt; {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  blogManager gateway.BlogManager &lt;span&gt;// 字段 type 是接口类型，通过 Infra 层具体实现进行依赖注入&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(b *BlogOperator)&lt;/span&gt; &lt;span&gt;GetBlog&lt;/span&gt;&lt;span&gt;(...)&lt;/span&gt; ...&lt;/span&gt; {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    blog, err := b.blogManager.Load(ctx, blogID)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    &lt;span&gt;return&lt;/span&gt; dto.BlogFromModel(...) &lt;span&gt;// 通过 DTO 传递数据到外层&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;App 层会依赖 Domain 层定义的领域网关，而领域网关接口会由 Infra 层的具体实现注入。外层调用 App 层方法，通过 DTO 传递数据，App 层组织好输入交给 Domain 层处理，再将得到的结果通过 DTO 传递到外层。&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;// Domain 层 gateway/blog_manager.go&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;&quot;mybusiness.com/blog-api/domain/model&quot;&lt;/span&gt; &lt;span&gt;// 依赖同层的 model&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;type&lt;/span&gt; BlogManager &lt;span&gt;interface&lt;/span&gt; { &lt;span&gt;//定义核心业务逻辑的接口方法&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  Load(...) ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  Save(...) ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  ...&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;br mpa-from-tpl=&quot;t&quot;/&gt; Domain 层是核心层，不会依赖任何外层组件，只能层内依赖。这也保障了 Domain 层的纯粹，保障了整个软件系统的可维护性。&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;// Infrastructure 层 database/mysql.go&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    &lt;span&gt;&quot;mybusiness.com/blog-api/domain/model&quot;&lt;/span&gt; &lt;span&gt;// 依赖内层的 model&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    &lt;span&gt;&quot;mybusiness.com/blog-api/infrastructure/client&quot;&lt;/span&gt; &lt;span&gt;// 依赖同层的 client&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;type&lt;/span&gt; MySQLPersistence &lt;span&gt;struct&lt;/span&gt; {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  client client.SQLClient &lt;span&gt;// client 中已构建好了所需客户端，此处不用引入 MySQL, gorm 相关依赖&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(p ...)&lt;/span&gt; &lt;span&gt;Load&lt;/span&gt;&lt;span&gt;(...)&lt;/span&gt; ...&lt;/span&gt; { &lt;span&gt;// Domain 层 gateway 中接口方法的实现&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  record := p.client.FindOne(...)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  &lt;span&gt;return&lt;/span&gt; record.ToModel() &lt;span&gt;// 将 DO（数据对象）转成 Domain 层 model&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/pre&gt;&lt;pre&gt;&lt;p&gt;&lt;/p&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;Infrastructure 层中接口方法的实现都需要将结果的数据对象转化成 Domain 层 model 返回，因为领域网关 gateway 中定义的接口方法的入参、出参只能包含同层的 model，不可以有外层的数据类型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;前文提及的完整调用流程如图 7 所示。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6481481481481481&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Vww7O7ibEbCbQRBxibuhR9SF6rUeFqRtiboq3dFEMK6HK3682odddgHe1ibxMTNnrBt5uDdAuDAg6xA/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 7 Blog 读取过程时序示意图&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图，外部请求首先抵达 Adapter 层。如果是读请求，则携带简单参数来调用 App 层；如果是写请求，则携带 DTO 调用 App 层。App 层将收到的DTO转化成对应的 Model 调用 Domain 层 gateway 相关业务逻辑接口方法。由于系统初始化阶段已经完成依赖注入，接口对应的来自 Infra 层的具体实现会处理完成并返回 Model 到 Domain 层，再由 Domain 层返回到 App 层，最终经由 Adapter 层将响应内容呈现给外部。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;至此可知，参照 COLA 设计的系统分层架构可以一层一层地将业务请求剥离干净，分别处理后再一层一层地组装好返回到请求方。各层之间互不干扰，职责分明，有效地降低了系统组件之间的耦合，提升了系统的可维护性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h1 data-mid=&quot;&quot;&gt;&lt;span&gt;04&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;无论哪种架构都不会是项目开发的银弹，也不会有百试百灵的开发方法论。毕竟引入一种架构是有一定复杂度和较高维护成本的，所以开发者需要根据自身项目类型判断是否需要引入架构：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;不建议引入架构的&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;项目类型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;* 软件生命周期大概率会小于三个月的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;* 项目维护人员在现在以及可见的将来只有自己的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;可以考虑引入架构的项目类型：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;* 软件生命周期大概率会大于三个月的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;* 项目维护人员多于1人的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;强烈建议引入架构的项目类型：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;* 软件生命周期大概率会大于三年的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;* 项目维护人员多于5人的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;h2&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;参考文献:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] Robert C. Martin, The Clean Architecture, https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html (2012)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] Andrew Gordon, Clean Architecture,  https://www.andrewgordon.me/posts/Clean-Architecture/ (2021)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] Pablo Martinez, Hexagonal Architecture, there are always two sides to every story,  &lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://medium.com/ssense-tech/hexagonal-architecture-there-are-always-two-sides-to-every-story-bc0780ed7d9c&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt; (2021)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] 张建飞, COLA 4.0：应用架构的最佳实践,  https://blog.csdn.net/significantfrank/article/details/110934799 (2022)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] Jeffrey Palermo, The Onion Architecture,  https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/ (2008)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以上是本次分享全部内容，欢迎大家在评论区分享交流。如果觉得内容有用，欢迎转发～&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;-End-&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;原创作者｜donghui&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;技术责编｜donghui&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.39490445859872614&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe979Bb4KNoEWxibDp8V9LPhyjmg15G7AJUBPjic4zgPw1IDPaOHDQqDNbBsWOSBqtgpeC2dvoO9EdZBQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;628&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247602046&amp;amp;idx=1&amp;amp;sn=6dd93f00ba716d31c7228cec6be6c5de&amp;amp;chksm=eaa9552edddedc38a97af0390533baeb57cf3c2e6500b93da925d2374da5c39256c5081f554e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.16296296296296298&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe959lyFQjvEpMIBqfBibXVE2whDZso5AuJEhV7BYU9AMpDJTqo7IWMfnEkiaDhhr4ydIia9YaAkCeib79Q/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247601092&amp;amp;idx=1&amp;amp;sn=f1e21f90a61e5f31ed5eab57e938ea46&amp;amp;chksm=eaa95194ddded8822dfa6531b0fe2ff3079e6ed44b56a878b9dd95f4d355debc6118429ca0dd&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.16348773841961853&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96k8c8Byl1asIeIOjQEnUlXdPxETBl6wlTCGQw8ibicAAs3GwtmNUKibzs0kUenXOBvdg587BhwKptDw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;734&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247599007&amp;amp;idx=1&amp;amp;sn=02a51b3a485d4af41c8030ad2b5205ac&amp;amp;chksm=eaa959cfddded0d9a22fdeb47607f15926877fa617cd83de03937f510deb05328ae5c5634722&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.16296296296296298&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe95UUT6yYse0lzSrTc2CFKGGicpNd2OwmWpddSyaibbZqicW5oLq4suqxsQc2Z1tN6ZuXIgV6cWewzalw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247593033&amp;amp;idx=1&amp;amp;sn=5dbaeabb575b4f2c374d7f1b25b42d27&amp;amp;chksm=eaa97619dddeff0fc3f72f635427da4349e969c6277bacc8c9a5e86799d8fefdae934749b6b0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.39490445859872614&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96k8c8Byl1asIeIOjQEnUlXQ0mXWOWtd4jg0G63avGBCw8ib78JbpicburDEicA0oiaTC990NCpk2VQ8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;628&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;“如何更好的降低系统组件之间的耦合、提升系统的可维护性”是让开发者们亘古不变的头疼问题，除了设计好的代码架构，容器化技术等也是重要的解耦技术。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;大家还能想到哪些可以降低系统耦合度，提高系统可维护性的方法呢？&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;欢迎在评论区聊一聊你的看法。在4月4日前将你的评论记录截图，发送给腾讯云开发者公众号后台，可领取腾讯云&lt;/span&gt;&lt;span&gt;「开发者春季限定红包封面」&lt;/span&gt;&lt;span&gt;一个，数量有限先到先得😄。我们还将选取&lt;/span&gt;&lt;span&gt;点赞量&lt;/span&gt;&lt;span&gt;最高的1位朋友，送出&lt;/span&gt;&lt;span&gt;腾讯QQ公仔&lt;/span&gt;&lt;span&gt;1个。4月4日中午12点开奖。快邀请你的开发者朋友们一起来参与吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近微信改版啦&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多开发者朋友反馈收不到我们更新的文章&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家可以&lt;/span&gt;&lt;span&gt;&lt;strong&gt;关注并点亮星标&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;🥹不再错过小云的知识速递🥹&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-ratio=&quot;0.6267029972752044&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VY8SELNGe95sINOI2rjxOTmQzicLicmcnEyqWGx2ibs6ibGQslRkKl5PJibrPmbsYicLYZHRh3uSGGg5YYrQ1RAwkVXw/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;734&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable js_wx_tap_highlight&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzI2NDU4OTExOQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97ibOIthe2pvwt1H0HqX0HVJVFK9WPNQKNsibXynR5yT5S7b45uIpzN7xeZdeJIfOibPjOflZ35rKZyw/0?wx_fmt=png&quot; data-nickname=&quot;腾讯云开发者&quot; data-alias=&quot;QcloudCommunity&quot; data-signature=&quot;腾讯云官方社区公众号，汇聚技术开发者群体，分享技术干货，打造技术影响力交流社区。&quot; data-from=&quot;2&quot; data-is_biz_ban=&quot;0&quot; data-index=&quot;0&quot; data-origin_num=&quot;678&quot; data-isban=&quot;0&quot; data-biz_account_status=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-ratio=&quot;0.1008174386920981&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VY8SELNGe95sINOI2rjxOTmQzicLicmcnES7iaAAJVrAictePXDMc5vDBkhwdyzr0vGZkksm34icNiaQX3acwMyrsPLg/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gifwxfrom=5wx_lazy=1&quot; data-w=&quot;734&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fd3bd46ba7592eddf2b740d489131106</guid>
<title>【云原生 • Docker】Docker 核心 UTS Namespace 原理实践</title>
<link>https://toutiao.io/k/2gwwzi7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;【云原生 • Docker】Docker核心UTS Namespace原理实践&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Docker&lt;/code&gt;三大支柱核心技术：&lt;code&gt;Namespace&lt;/code&gt;、&lt;code&gt;Cgroups&lt;/code&gt;和&lt;code&gt;UnionFS&lt;/code&gt;，这节通过一个&lt;code&gt;UTS Namespace&lt;/code&gt;简单实践小案例，更加直观理解&lt;code&gt;Namespace&lt;/code&gt;资源隔离技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;UTS Namespace&lt;/code&gt; 主要是用来隔离主机名和域名的隔离，它允许每个 &lt;code&gt;UTS Namespace&lt;/code&gt; 拥有一个独立的主机名。例如我们的主机名称为 &lt;code&gt;VM-4-14-centos&lt;/code&gt;，使用 &lt;code&gt;UTS Namespace&lt;/code&gt; 可以实现在容器内的主机名称为 &lt;code&gt;container-docker&lt;/code&gt; 或者其他任意自定义主机名。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;UTS Namespace案例实践&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在进行&lt;code&gt;UTS Namespace&lt;/code&gt;案例实践之前，我们先来了解个关键指令：&lt;strong&gt;「unshare，运行一些与父级不共享某些名称空间的程序。」&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;root@node3:~&lt;span&gt;# unshare --help&lt;/span&gt;&lt;br/&gt;Usage:&lt;br/&gt; unshare [options] &amp;lt;program&amp;gt; [&amp;lt;argument&amp;gt;...]&lt;br/&gt;&lt;br/&gt;Run a program with some namespaces unshared from the parent.&lt;br/&gt;&lt;br/&gt;Options:&lt;br/&gt;-h，--&lt;span&gt;help&lt;/span&gt;&lt;br/&gt;显示帮助文本并退出。&lt;br/&gt;-i，-- ipc 取消共享IPC名称空间。&lt;br/&gt;-m，-- mount 取消共享安装名称空间。&lt;br/&gt;-n，-- net 取消共享网络名称空间。&lt;br/&gt;-p，-- pid 取消共享pid名称空间。另请参见--fork和--mount-proc选项。&lt;br/&gt;-u，-- uts 取消共享UTS名称空间。&lt;br/&gt;-U，--user 取消共享用户名称空间。&lt;br/&gt;-f，-将指定程序fork为取消共享的子进程，而不是直接运行它。这在创建新的pid命名空间时很有用。&lt;br/&gt;--mount-proc [=mountpoint]在运行程序之前，将proc文件系统挂载到mountpoint （默认为/ proc）。这在创建新的pid名称空间时很有用。这也意味着创建一个新的挂载名称空间，因为/ proc挂载否则会破坏系统上的现有程序。新的proc文件系统显式安装为私有文件（由MS_PRIVATE | MS_REC）。&lt;br/&gt;-r，-- map-root-user 仅在当前有效的用户和组ID已映射到新创建的用户名称空间中的超级用户UID和GID之后，才运行该程序。这样即使在没有特权的情况下运行，也可以方便地获得管理新创建的名称空间各个方面所需的功能（例如，在网络名称空间中配置接口或在安装名称空间中安装文件系统）。仅作为一项便利功能，它不支持更复杂的用例，例如映射多个范围的UID和GID。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们通过一个实例来验证下 &lt;code&gt;UTS Namespace&lt;/code&gt; 的作用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、首先我们使用 &lt;code&gt;unshare&lt;/code&gt; 命令来创建一个 &lt;code&gt;UTS Namespace&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# unshare --uts --fork /bin/bash&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建好 &lt;code&gt;UTS Namespace&lt;/code&gt; 后，宿主机&lt;code&gt;shell&lt;/code&gt;下&lt;code&gt;lsns&lt;/code&gt;列出&lt;code&gt;namespace&lt;/code&gt;信息，会发现最后一条就是我们使用&lt;code&gt;unshare&lt;/code&gt;创建了一个&lt;code&gt;uts&lt;/code&gt;类型的&lt;code&gt;namespace&lt;/code&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.19814814814814816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb0hib0az5PRibUuS8dobHA0LPx79ib0iblo1Zqe4JUwmxcic3WFYeadc5KX2PUArjM2TmgR38z7ibk494RA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、回到上步&lt;code&gt;uts&lt;/code&gt;命名空间&lt;code&gt;shell&lt;/code&gt;下，使用 &lt;code&gt;hostname&lt;/code&gt; 命令设置一下主机名：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;VM-4-14-centos&lt;br/&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname -b container-docker&lt;/span&gt;&lt;br/&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;container-docker&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过上面命令的输出，我们可以看到当前 &lt;code&gt;UTS Namespace&lt;/code&gt; 内的主机名已经被修改为 &lt;code&gt;container-docker&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、回到宿主机&lt;code&gt;shell&lt;/code&gt;下，查看一下主机的 &lt;code&gt;hostname&lt;/code&gt;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;VM-4-14-centos&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到主机的名称仍然为 &lt;code&gt;VM-4-14-centos&lt;/code&gt;，并没有被修改，这就是使用&lt;code&gt;UTS Namespace&lt;/code&gt;技术实现主机名隔离功能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;Docker原理验证&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、使用&lt;code&gt;docker run&lt;/code&gt;创建并运行一个&lt;code&gt;Docker&lt;/code&gt;容器：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# docker run -d --name test-nginx --hostname docker-nginx nginx&lt;/span&gt;&lt;br/&gt;0fd5ec42923553ec2600c51ef4f119e4025ebf5adf13561b0e847cd816f332b7&lt;br/&gt;[root@VM-4-14-centos ~]&lt;span&gt;# docker exec -it 0fd sh&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;docker-nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;--hostname指定docker容器的hostname，上面指定--hostname docker-nginx，通过docker exec指令进入到docker容器中，使用hostname查看Docker容器的hostname已被正确修改。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、查看刚创建的Docker容器对应的宿主机&lt;code&gt;PID&lt;/code&gt;信息：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# docker inspect -f {{.State.Pid}} test-nginx&lt;/span&gt;&lt;br/&gt;29424&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或者通过&lt;code&gt;lsns&lt;/code&gt;指令也可以查看到我们刚才创建的Docker容器Namespace信息：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.22314814814814815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb0hib0az5PRibUuS8dobHA0LPfMk4ycWJFviclaFYpIP6TMjm8obibV3RyRUdQARviaWgmQ7AqoNWfGwfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、在宿主机&lt;code&gt;shell&lt;/code&gt;下使用&lt;code&gt;nsenter&lt;/code&gt;指令可以进入到Docker容器相同的Namespace下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# nsenter -t 29424 -u -n&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说明：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;-t：指定被进入命名空间的目标进程的pid，即指定Docker容器在宿主机上对应pid；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-u：进入uts命令空间；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-n：进入net命令空间。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;&lt;strong&gt;「nsenter：一个可以在指定进程的命令空间下运行指定程序的命令。」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;有很多image内部是没有bash的，所以我们docker exec是无法进入容器的，此时如果还想看一下容器内的情况，其实只需要想办法加入到容器对应的namespace就可以了。我们使用nsenter工具即可实现，该工具启动后会将自己加入到指定的namespace中，然后exec执行我们指定的程序（通常就是bash）。&lt;/p&gt;&lt;p&gt;这个命令大家在容器网络调试下可能常用，比如在一些没有网络调试工具(&lt;code&gt;ip address&lt;/code&gt;，&lt;code&gt;ping&lt;/code&gt;，&lt;code&gt;telnet&lt;/code&gt;，&lt;code&gt;ss&lt;/code&gt;，&lt;code&gt;tcpdump&lt;/code&gt;)的容器内利用宿主机上的命令进行容器内网络连通性的调试等等。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、使用&lt;code&gt;hostname&lt;/code&gt;和&lt;code&gt;ip addr&lt;/code&gt;验证，和Docker容器在相同的&lt;code&gt;UTS Namespace&lt;/code&gt;和&lt;code&gt;Network Namespace&lt;/code&gt;下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@docker-nginx ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;docker-nginx&lt;br/&gt;[root@docker-nginx ~]&lt;span&gt;# ip addr&lt;/span&gt;&lt;br/&gt;1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000&lt;br/&gt;    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00&lt;br/&gt;    inet 127.0.0.1/8 scope host lo&lt;br/&gt;       valid_lft forever preferred_lft forever&lt;br/&gt;40: eth0@if41: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default &lt;br/&gt;    link/ether 02:42:ac:11:00:07 brd ff:ff:ff:ff:ff:ff link-netnsid 0&lt;br/&gt;    inet 172.17.0.7/16 brd 172.17.255.255 scope global eth0&lt;br/&gt;       valid_lft forever preferred_lft forever&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>09706903af39c8c6eb8e1ae9236235cc</guid>
<title>ChatGPT 应用思考</title>
<link>https://toutiao.io/k/8ivw4x1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content              autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;p&gt;OpenAI在2022年11月30日发布了ChatGPT，它是一个基于大模型技术实现的通用聊天机器人，它可以用来写作、翻译、润色句子、做事实性问答、执行文本分类/实体抽取/阅读理解/文本摘要等各类NLP任务，甚至可以写SQL、写代码，几乎无所不能。&lt;/p&gt;&lt;section&gt;ChatGPT自发布之后一直大火至今，引起行业震动，我们也持续在跟进ChatGPT，体验其功能，了解其技术原理，并基于爬虫技术封装了ChatGPT API，在实际NLP应用场景下对比了ChatGPT和自研技术的效果。本文从应用角度出发，给出一些对ChatGPT的思考。&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong/&gt;&lt;span&gt;一、GPT 到 ChatGPT 的演进&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong/&gt;&lt;strong/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Google于2017年在《Attention Is All You Need》一文中发布了Transformer，此后对NLP、语音、CV等AI领域产生了深远影响。&lt;/span&gt;&lt;span&gt;2018年6月，OpenAI发布了GPT（Generative Pre-Training）[1]——基于Transformer Decoder结构和无监督预训练方法实现的生成式预训练语言模型，也即GPT-1。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2018年10月，Google发布了BERT（Bidirectional Encoder Representation from Transformers）[2]，BERT是基于Transformer Encoder结构的预训练语言模型，在多项NLP任务上取得SOTA效果，开启了自然语言处理&lt;span&gt;「&lt;/span&gt;预训练+微调&lt;span&gt;」&lt;/span&gt;的新范式，是自然语言处理发展史上的里程碑。BERT自发布之后在学术界和工业界均产生了重大影响，大量论文和应用基于BERT实现，谷歌学术上BERT的论文引用数也远超GPT，近几年大模型技术火热，国内外发布的大部分大模型也是基于BERT技术路线来实现。&lt;/span&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;237&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;237&quot; data-ratio=&quot;0.22158273381294963&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeov2RabEqOlJxfmFDNJy87ncibgribzKS4rwM8aHBXUHIcDU5jTPl2RIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;695&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI持续升级优化GPT，于2019年2月发布了GPT-2[3]，于2020年6月发布了拥有1750亿参数的超大模型GPT-3[4]，轰动一时，GPT-3不需要像BERT那样针对特定任务做微调&lt;span&gt;（Fine-tune）&lt;/span&gt;，一个大模型即可在一系列自然语言处理任务上取得优秀的效果，结合Few-Shot少样本学习能力，在部分任务上甚至接近或者达到当时的SOTA效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用BERT执行某个具体场景下的NLP任务如文本分类时，需要人工标注该场景下的一定量数据，然后微调得到一个文本分类模型应用于分类，即重新更新了模型，对于不同的任务均要这样做。而使用GPT-3执行NLP任务时，不需要重新更新模型，只需要向其发送一句提示（Prompt）例如&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;请给这段文字分类，类别标签有A、B、C&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;即可完成分类，或者可以使用少量标注数据作为例子告诉模型，能够取得更优的效果，在这一点上GPT-3要比BERT更加易用。值得说明的是，自GPT-3开始，OpenAI没有像GPT-1、GPT-2那样发布开源代码，而是以API的形式提供商业化服务，具体见 &lt;/span&gt;&lt;span&gt;https://openai.com/api&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;247&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4267161410018553&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSewjOuL2mPFgX1e7TKQegP67iaFDP1mmP0cGsHTc4ticIYMISPES9hOGcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;BERT和ChatGPT执行任务的区别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT是从GPT-3发展而来的，&lt;/span&gt;&lt;span&gt;符尧等人在《&lt;/span&gt;&lt;span&gt;拆解追溯 GPT-3.5 各项能力的起源》一文[10]中总结了GPT-3到GPT-3.5的进化树，GPT-3在OpenAI API中的模型名称为Davinci（达芬奇），之后经历在代码上训练、指令微调、RLHF（Reinforcement Learning from Human Feedback，基于人类反馈的强化学习）等过程，进化成ChatGPT，详细内容可参见文章[10]，这里不再赘述。&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2022年11月，OpenAI除了发布ChatGPT之外，还发布了text-davinci-003模型，两者都是在text-davinci-002模型的基础上使用RLHF方法训练得到的&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;，ChatGPT实际上不仅是一个单独的模型，而是一个完整的Web聊天机器人产品，其内部调用的模型假设也称作ChatGPT。&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5776942355889725&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSevYUTRm2GRJO3BlzqDfBRuqYJr8pVBcsqlPia6QfAwsIy2uI7Lt7VauA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;798&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;GPT-3到&lt;span/&gt;&lt;span&gt;GPT-3.5的进&lt;/span&gt;&lt;/span&gt;&lt;span&gt;化树. 符尧等. 2022.12.11&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI当前并未公布ChatGPT论文，只在官网发布了一篇BLOG[9]，BLOG中讲到&lt;span&gt;「&lt;/span&gt;We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as &lt;/span&gt;&lt;span&gt;InstructGPT&lt;/span&gt;&lt;span&gt;, but with slight differences in the data collection setup&lt;span&gt;」&lt;/span&gt;，ChatGPT模型训练采用了RLHF方法，和2022年3月发布的InstrutGPT[8]一致，仅是数据采集上有一些差异，当前介绍ChatGPT技术原理的文章均是介绍InstrutGPT。RLHF并非是一个全新的方法，InstrutGPT论文里有讲到该方法参考了2020年9月发布的文章《Learning to summarize from human feedback》[7]和2017年6月发布的文章《Deep reinforcement learning from human preferences》[12]，文章[7]又参考了2019年9月发布的文章《Fine-Tuning Language Models from Human Preferences》[6]，由此可见，&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;OpenAI在RLHF方法上有持续的沉淀积累，ChatGPT的诞生也并非一蹴而就&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;334&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5888208269525268&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSewNvBGpFcqIAl4y9RtUJdI0gQXBrVKwl5QhnvTzyQoUcvTAqEibqXNpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1306&quot;/&gt;&lt;span&gt;ChatGPT训练过程. 2022.11.30&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;334&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5957613814756672&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSePYDSbgiaCgXhIibxkGtjs4zAG2DrZZGq9icauicgjQEAYdPJoShgdQJOJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1274&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;InstructGPT训&lt;/span&gt;&lt;span&gt;练过程. 2022.3&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;334&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5313971742543171&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeDgKx40ibLYpwsQBiaW027ia9KxtMDh2L1dF1fh12Av7IRZKTg8zCsCXLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1274&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning to summarize from human feedback. 2020.9&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;334&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5548717948717948&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeyicUrr1jPibWjiaUbIOdV1PKkzalFLe5hM59GD3m3N9XXiaDvsRn3iaNYLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;975&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;Fine-Tuning Language Models from Human Preferences&lt;span&gt;. 2019&lt;/span&gt;&lt;span&gt;.9&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong/&gt;&lt;span&gt;二、GPT API 说明&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong/&gt;&lt;strong/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前，&lt;/span&gt;&lt;span&gt;在OpenAI发布的&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;GPT API中可以调用上文GPT-3到GPT-3.5的进化树中除ChatGPT模型之外的所有模型&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;，用户可以在API Playgroud里选择模型版本进行体验，也可以编写程序调用API来进行批量实验，如下图所示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8050761421319796&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeGdS7rzpicWP45ficV5mFwD0602C5Mc6QAIp9sA0Alb0ndWZNL1teZujQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;985&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;GPT API Playground&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;2.1530944625407167&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeMUS02KSfXwRcfdVrFW3GzxbxHwp9gkmpg2hvemaJ99LkqdCEeFic0Ug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;307&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPT&lt;/span&gt;&lt;span&gt; A&lt;/span&gt;&lt;span&gt;PI 当前支持的模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT是以一个Web聊天机器人的形态发布的，用户需要登录网站进行体验，OpenAI目前还未发布ChatGPT API，但OpenAI API官网显示不久后将发布&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;ChatGPT is coming to our API soon, sign up to stay updated&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;。目前业界有一些声称基于ChatGPT的聊天机器人工具，均是以非官方API来实现的，例如&lt;/span&gt;&lt;span&gt;可以基于爬虫技术来访问ChatGPT官网，封装成ChatGPT API&lt;/span&gt;&lt;span&gt;，并注册大量ChatGPT账号，以保证支持一定的访问量。ChatGPT官网对访问频率有限制，且官网时不时会因为用户请求过多无法访问，这样的API不是很稳定，只能在一些离线场景应用。值得一提的是，目前ChatGPT提供了付费账号，价格为20美元/月，经测试，付费账号和免费账号在访问频率上并没有多大差别，只是付费账号的服务响应会相对稳定一些，若是个人使用，直接使用免费账号即可。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8501118568232662&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSekplmVkyXW8dHSGOXBQ1tDnn6wEQ6NEPM8uysE0YJ1gHPDLV9fZia1sA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;894&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;ChatGPT官网&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPT API按照输入输出的token数量收费，价格为0.02美元/1000tokens，一个token大概是0.75个英文单词，一个中文汉字为两个token，这里包括请求API的token（Prompt）和API返回的token（Completion），一个GPT账号会免费赠送18美元的额度，有效期为3个月。未来ChatGPT API 收费方式很可能也和此相同。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45740498034076016&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeZumJEGMHe8hxkSgpibibcicZNGjZVQdW7mfnpiapSWvbibKjibspic0mSO75A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;GPT API 收费说明&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1024691358024692&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSetF10hicQfGWCpfJj5iaV6985P7KzyOy2BwNUCRYKozrScPibHm6HUXXpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;810&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台针对每次请求输入和输出token计数&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从GPT-3到GPT-3.5的进化树中可以看到text-davinci-003模型和ChatGPT模型均是在text-davinci-002模型的基础上使用RLHF方法训练得到，都在2022年11月发布，两者的差别可能是针对不同类型人工反馈数据调优上的差异，ChatGPT模型是应用于对话聊天，会基于线上对话数据调优，在上下文多轮对话、拟人化等能力上可能更强，text-davinci-003基于GPT API上用户反馈数据（如上述Playground）调优，在相关任务上的效果和ChatGPT相比可能差异不大，如后文有实验在评论情感分类任务上二者效果相当。因此，&lt;/span&gt;&lt;span&gt;用户可以直接在GPT API中使用&lt;strong&gt;text-davinci-003&lt;/strong&gt;模型来搭建相关应用&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong/&gt;&lt;span&gt;三、GPT-3 训练成本&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong/&gt;&lt;strong/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;GPT-3拥有1750亿参数，模型训练需要消耗大量资源，OpenAI并未公开过GPT系列大模型训练和推理消耗的具体费用，我们可以从其他材料中获得一些信息。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;2020年5月，文章[12]中讲到微软在Azure上为OpenAI搭建了独立的超级计算机系统，包含28.5万个CPU核和1万张GPU卡（当时为V100）：The supercomputer developed for OpenAI is a single system with more than 285,000 CPU cores, 10,000 GPUs and 400 gigabits per second of network connectivity for each GPU server。2020年6月发布的GPT-3模型应该是在该系统上训练得到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达在2021年4月发表的《Efficient Large Scale Language Model Training on GPU Clusters》[13] 文章中有预估不同参数规模的大模型训练需要消耗的资源和时间：使用1024张80G显存的A100卡训练1750亿参数的GPT-3模型，需要训练34天。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是2-3年前之前的费用说明，根据相关材料介绍，当前训练GPT-3的费用更低 ，文章《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU5ODY2MTk3Nw==&amp;amp;mid=2247490676&amp;amp;idx=1&amp;amp;sn=f3f98a7b3b0670e4274dd681dcb44430&amp;amp;chksm=fe419242c9361b5425dd7205f30ceba365dbb05ee0a6f6d8a676357b1295fc341c7371a33860&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;ChatGPT背后的经济账&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;ChatGPT背后的经济账&lt;/a&gt;》讲到&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;对于大公司而言，训练LLM（即使是从头开始）的成本并不高，如今，在公有云中训练GPT-3仅需花费约140万美元&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong/&gt;&lt;span&gt;四、ChatGPT的应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong/&gt;&lt;strong/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ChatGPT可以用来写作、翻译、润色句子、做事实性问答、写SQL、写代码、执行文本分类/实体抽取/阅读理解/文本摘要等各类NLP任务，相关案例不一一赘述，这里仅讨论在智能写稿、智能客服、智能外呼实际产品场景下我们对ChatGPT的应用尝试，&lt;/span&gt;&lt;span&gt;相关实验对比结果基于我们自主封装的ChatGPT API完成。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;智能写稿：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们从2018年开始就有落地智能写稿，利用机器自动生成一些稿件应用于各类场景，如自动生成二手车车源介绍文章，可参见《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;amp;mid=2456197989&amp;amp;idx=1&amp;amp;sn=e1c68a4129e236249f08bb488d695083&amp;amp;chksm=87101079b067996f64f63242a6b30c1eb97a720afb23a5b8cca2a7600707ab4169b89a20fef6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;58智能写稿机器人实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;58智能写稿机器人实践&lt;/a&gt;》。原始生成方法是基于优质车源帖子数据，利用模板填充和文本生成技术自动生成文章，生成的文章较短且生硬，我们使用ChatGPT来润色这些文章，向ChatGPT发送prompt提示&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;请润色下面这段文字，字数在400字以内&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;即可完成该任务，通过ChatGPT润色的文章可读性极佳。此外，我们也尝试直接拿车源属性字段来让ChatGPT写作，例如向ChatGPT发送提示&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;请以下面这些关键词写一篇400字的文章&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，最终ChatGPT也能生成可读性较好的结果。我们都知道ChatGPT在一些常识性问题上会犯错误，可能会生成一些错误内容，而我们是基于优质车源帖子数据来生成文章，车源帖子首先是真的，最终生成的内容也是真实可用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本地服务（黄页）业务下，客户（商家）需要定期下线旧帖子，重新发布新贴子，由于商家平时工作繁忙，往往没有时间发帖，因此平台提供了代客发帖服务，人工来帮助其发帖。2022年我们上线了AI自动发帖功能，节省了30+人力。AI自动发帖的大概逻辑是基于旧帖子正文内容和帖子用户评价，自动生成新帖标题和更新正文内容。在更新帖子正文内容这里，需要筛选出用户优质评价，并将评价提炼成一小段文字，再插入到帖子正文头部，以&quot;口碑亮点&quot;模块来展示。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.0046403712296983&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSen8iaick8hDSIBcGdPWG9yffFCicNEzf505Yo0Bf35WKuZXDhZnwj5hHUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;431&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;帖子正文口碑亮点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的原始方案是使用微调的BERT模型来识别评论正负向情感，先挑出正向评论，然后基于抽取式方法生成最终的评论短语。我们将ChatGPT应用于该场景，首先使用ChatGPT来识别评论正负向情感，然后继续用ChatGPT将正向评论润色成最终的&quot;口碑亮点&quot;，取得了很好的效果。评论正负向情感识别是一个常见的NLP任务，我们直接向ChatGPT发送Prompt提示&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;对下面的评论进行分类，类别有正向、其他，[商家很专业，很有耐心]属于什么类别？&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，这里没有给其提供任何先验知识和例子，即Zero-Shot，它也能获得不错的效果，比BERT微调模型略低，我们继续实验Few-Shot，告诉其分类标准并给予了一些样例，如下图所示，识别效果明显提升，超过BERT微调模型，可见ChatGPT十分强大。在前文GPT API章节我们有讲到2022年11月同期发布的&lt;/span&gt;&lt;span&gt;text-davinci-003模型和ChatGPT模型在部分NLP任务上可能差异不大，这里我们也进行了验证，在评论情感识别任务上二者差异不大&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;86&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1484771573604061&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSe190FcunyRIwGsVwIkyZF1BicCr1CskSiboZk1zBxw7ESaXrgY5l0rib9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;788&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ChatGPT在评论正负向情感识别任务上的效果&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;432&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;86&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7469512195121951&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSet4dzuET3xyiawzfASC9TfIRlLuvNv4AMZjsiaVaibMoWPQkqvnz2icKkzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;656&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ChatGPT Few-Shot&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外，在SEO场景我们也进行了探索，使用ChatGPT生成一些SEO场景需要的内容，尽管ChatGPT会生成一些事实性错误的内容，但通过优化Prompt可以使得生成的结果基本可用，并结合人工审核、人工改写，最终能够得到符合SEO需求的内容。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;智能客服：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前网上很多人都说ChatGPT可以直接拿来做智能客服，能够让一些客服或者销售人员下岗，很多人都信以为真，实际并非如此&lt;/span&gt;&lt;span&gt;。智能客服是当下发展非常成熟的产品，各大企业都有应用，能够提高客服人效，&lt;a target=&quot;_blank&quot; href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&amp;amp;mid=2247485955&amp;amp;idx=1&amp;amp;sn=b35805cfc98f50f3c9b7dc629a90c2ed&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;58同城是2017年开始打造的智能客服&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;58同城是2017年开始打造的智能客服&lt;/a&gt;。&lt;/span&gt;&lt;span&gt;这是智能客服的基本原理：企业维护了一套业务问答知识库，即一些业务问题和答案的集合，若用户在使用APP时遇到相关问题，他会在智能客服聊天窗口里输入问题进行咨询，机器会自动理解用户输入的问题，从问答知识库中找到那条和用户输入语义相同的问题，即文本匹配或文本分类，然后把该问题的答案返回给用户。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;160&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.27712854757929883&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSe1jTfT78acqTLWhGL7cvI1xbljG19FdMRv4iarW8qjbAft5uP4pKF3sQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1797&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;智能客服基本原理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能客服的核心是构建问答知识库和文本匹配，问答知识库里的问题是线上用户遇到的真实业务问题，答案是客服运营人员人工整理的答案，而文本匹配是一项传统的NLP技术。很明显，&lt;/span&gt;&lt;span&gt;客服场景的问答知识库是企业独有的，ChatGPT没有学习过这些数据，对于用户咨询它不可能给出正确答案&lt;/span&gt;&lt;span&gt;。部分业务方也给我们提过使用ChatGPT代替现有智能客服系统的想法，我们抽取了一定量线上真实用户的输入，并交给ChatGPT回答，最终证实了在业务问题上它会一本正经的&quot;胡说八道&quot;。当然，如果我们将问答知识库数据全部提交给ChatGPT做微调（Fine-tune），它也能回答得较好，但目前ChatGPT还不提供微调功能，GPT-3 API提供了微调功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;尽管ChatGPT不能直接拿来做智能客服，但是我们可以用它来做智能客服中的文本匹配任务，我们在近期接入的一个新业务场景下实验了ChatGPT，可以类似下图这样向ChatGPT发送Prompt，Zero-Shot的效果较差，若在Prompt里给每个标准问题增加少量扩展问法就能有较好的效果提升，但要超过自研模型还需在Prompt上做更多优化工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;96&quot; data-backw=&quot;405&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.23703703703703705&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSep1aNtD0icSdRYHRn3RlNb3KlUzv7y03Z7YST0KdretuA7PBJNlGmbsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;405&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;ChatGPT文本匹配效果&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;179&quot; data-backw=&quot;405&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;405&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;96&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.44178628389154706&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSepSqTBykzCkRsuSlbVeOicBfXPBQpovk8COCRXDNd5eTkfuFRy55AeRQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;627&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;用ChatGPT做文本匹配Prompt示例&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;智能客服的问答知识库是持续更新的，因为随着产品功能的持续更新升级，线上用户会遇到新的操作问题，这些新问题会被挖掘出来加入到问答知识库中，并通过持续的数据标注来积累这些新问题的扩展问法。往往新问题上线初期扩展问法较少，模型对新问题识别效果较差，这里也可以在新问题产生时&lt;/span&gt;&lt;span&gt;直接使用ChatGPT来为每个新问题生成若干扩展问法（数据增强），再加入模型训练，使得模型对新问题有较好的识别效果。我们在一个新接入的场景下也进行了实验对比，针对新增的六条新问题，使用ChatGPT为每条新问题生成数十条扩展问法，然后训练模型，这相比不做数据增强的模型效果有明显提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;96&quot; data-backw=&quot;405&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;137&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.17829457364341086&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSew1icaaPZKwFVkrfoEUJgo7SUYlZsEFJFlJ3PLkukDMtLNNua7tAibqQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;387&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;自研模型 + ChatGPT数据增强后效果&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在招聘业务赶集直招「微聊反向邀约」场景，在C端用户和B端企业微聊沟通时，我们应用了智能客服留资机器人，具体介绍可参见《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;amp;mid=2456205375&amp;amp;idx=1&amp;amp;sn=705e8f440489e5b175fae84f9935daf9&amp;amp;chksm=87103323b067ba3599d904d4174f7c29dcd4cb32ecda95c7e81a668f18600e0dae6c59cda401&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;58同城 AI Lab 2022 年度回顾&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;一份AI中台产品应用手册&lt;/a&gt;》，当C端用户向B端企业发起微聊沟通时，若B端企业不在线，则由机器人和C端用户对话，在对话结束后若识别到用户有高求职意向，则调用智能双呼能力（可参见《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;amp;mid=2456205272&amp;amp;idx=1&amp;amp;sn=59a583ce733baa3667b51813b9f297d6&amp;amp;chksm=87103cc4b067b5d23faad453350aa328f3ad1b239e15070fdb7f85f67c072bc1d23a860b90b1&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;语音机器人人机协同能力介绍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;智能语音机器人四种人机协同能力介绍&lt;/a&gt;》）&lt;span&gt;提醒B端企业&lt;/span&gt;，B端企业接听后可以一键直连C端用户，从而双方可以直接电话沟通。这里机器人需要基于微聊对话记录识别用户求职意向，我们也实验了ChatGPT，通过优化Prompt，ChatGPT在F1-Score上超过了自研模型。但是这是一个重准确率的业务场景，因为需要保证B端企业连接的用户尽量是实际求职者，但&lt;/span&gt;&lt;span&gt;如何通过调整Prompt来控制ChatGPT的准确率和召回率，目前还没找到行之有效的方法&lt;/span&gt;&lt;span&gt;，而自研模型要做到这一点很简单。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;165&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.28523489932885904&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeoh83qUpTE2iasiaKNrIwF3xEPbMv3IeRgm0FluvjBc8IrgibSx0P8vnqA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;894&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;用ChatGPT做对话意图识别&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;智能外呼：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;智能外呼是人机实时语音对话场景，电话沟通语音会被语音识别引擎实时转写成文本，然后交给NLP模型进行语义理解，本质上和微聊文本对话没有差别，也会执行上述文本分类、文本匹配、对话意图识别任务，ChatGPT应用类似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;人机语音对话相对微聊文本对话来讲延时更敏感&lt;/span&gt;&lt;span&gt;，即需要NLP模型快速返回识别结果，耗时一般要求在数十到上百毫秒之间，因为人和机器在实时对话过程中若机器反应慢，例如数秒才响应，人会明显感觉到停顿，用户体验差，可能会直接挂断电话，影响转化效果，而在一些微聊智能客服场景下，为了让用户感觉到背后不是机器人，会故意让机器人回答慢一点，在程序中做一些延时回复操作。当前ChatGPT和GPT API的推理延时并不低，平均耗时在数秒级别，&lt;/span&gt;&lt;span&gt;直接应用ChatGPT来做人机语音对话中的NLP模块不可取&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用ChatGPT离线实验了近期上线的一个语音对话场景下的槽位提取（实体抽取），识别对话内容中的地点和服务类别槽位，这里直接使用Zero-Shot，向ChatGPT发送提示&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;请抽取这段话中的省、城市、区县和服务类别&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，从实验结果看ChatGPT表现不错。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.33455882352941174&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeS6pKza3zgZ1mBtOhhrJ6xuJ4pibibbVK9KgI1s32pN7J6iboYbRIJNCVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;544&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;ChatGPT槽位提取效果&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong/&gt;&lt;span&gt;五、个人思考&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong/&gt;&lt;strong/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ChatGPT在一个大模型里可以完成众多任务，而且效果都很不错，前所未见，令人惊叹&lt;/span&gt;&lt;span&gt;。毫无疑问，ChatGPT能够在各类岗位上辅助人工，提升人效，但能否完全替代某类岗位，还需时间验证，以NLP工程师岗位为例，企业若想使用ChatGPT代替NLP工程师，至少需要考虑以下几点：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;识别效果是否可控。NLP场景一般都会有准确率、召回率的侧重，需要通过调整模型来控制这两项指标，自研模型很容易做到，若使用ChatGPT，则只能通过调整Prompt来控制，如何编写Prompt来控制准确率、召回率，目前还没看到行之有效的方法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推理性能是否符合应用需求。大模型的推理性能与硬件资源、模型加速手段相关，性能和投入成正比，当前ChatGPT推理较慢，无法满足一些延时要求高的应用场景，例如智能外呼，未来这里可能需要和企业定制化。值得一提的是，当前&lt;span&gt;NewBing体验版的搜索也非常缓慢，用户体验不佳，这也是微软和OpenAI需要解决的痛点。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ROI的精确衡量。企业需要评估某个应用场景下使用ChatGPT API的花费是否比人力成本低，即将发布的ChatGPT API可能也和GPT-3 API一样按照token收费，它包括了输入和输出的token，真正接入使用时需要对Prompt和生成结果做精细化控制，编写Prompt也是一项挑战。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;当前，ChatGPT在国内还不能直接访问，未来就算对国内开放，但各大企业与其合作会很敏感，国内企业的大量数据若流入ChatGPT会有很大风险。中国很有必要做出自己的ChatGPT，当下国内大厂和一些创业公司正在努力，也许在不久的将来，国内ChatGPT解决上述问题后，真的不再需要那么多NLP算法工程师。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[1] GPT1：Improving Language Understanding by Generative Pre-Training. &lt;/span&gt;&lt;span&gt;https://openai.com/blog/language-unsupervised/&lt;/span&gt;&lt;span&gt; 2018.6&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2] BERT：Pre-training of Deep Bidirectional Transformers for Language Understanding. 2018.10&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[3] GPT2：Language Models are Unsupervised Multitask Learners.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;https://openai.com/blog/better-language-models/&lt;/span&gt;&lt;span&gt; 2019.2&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[4] GPT3：Language Models are Few-Shot Learners. &lt;/span&gt;&lt;span&gt;https://arxiv.org/abs/2005.14165&lt;/span&gt;&lt;span&gt; 2020.5&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[5] GPT3 API：&lt;/span&gt;&lt;span&gt;https://openai.com/blog/openai-api/&lt;/span&gt;&lt;span&gt; 2020.6&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[6] Fine-Tuning Language Models from Human Preferences. &lt;/span&gt;&lt;span&gt;https://arxiv.org/abs/1909.08593&lt;/span&gt;&lt;span&gt; 2019.9&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[7] Learning to summarize from human feedback.  &lt;/span&gt;&lt;span&gt;https://openai.com/blog/learning-to-summarize-with-human-feedback/&lt;/span&gt;&lt;span&gt; 2020.9&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[8] InstructGPT：Training language models to follow instructions with human feedback. &lt;/span&gt;&lt;span&gt;https://arxiv.org/abs/2203.02155&lt;/span&gt;&lt;span&gt; 2022.3&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[9] ChatGPT: Optimizing Language Models for Dialogue. &lt;/span&gt;&lt;span&gt;https://openai.com/blog/chatgpt/&lt;/span&gt;&lt;span&gt; 2022.11.30&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[10] How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources. &lt;/span&gt;&lt;span&gt;https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1&lt;/span&gt;&lt;span&gt; 符尧等. 2022.12.11. 中文版：拆解追溯 GPT-3.5 各项能力的起源. 2022.12.18. &lt;/span&gt;&lt;span&gt;https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;span&gt;[11] Deep reinforcement learning from human preferences. &lt;/span&gt;&lt;span&gt;https://arxiv.org/abs/1706.03741&lt;/span&gt;&lt;span&gt; 2017.6&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[12] Microsoft announces new supercomputer, lays out vision for future AI work. &lt;/span&gt;&lt;span&gt;https://news.microsoft.com/source/features/ai/openai-azure-supercomputer/&lt;/span&gt;&lt;span&gt; 2020.5.19&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[13] Efficient Large Scale Language Model Training on GPU Clusters. &lt;/span&gt;&lt;span&gt;https://arxiv.org/abs/2104.04473&lt;/span&gt;&lt;span&gt; 2021.4&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;[14] OpenAI API. &lt;/span&gt;&lt;span&gt;https://openai.com/api&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;詹坤林 &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2023.2.21&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本&lt;/span&gt;&lt;span&gt;文内容&lt;/span&gt;&lt;span&gt;为2023年2月14在58技术委员会AI分会AI技术沙龙《ChatGPT科普和应用初探》上的分享总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.5648148148148149&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/K01T9Yo4EoZzribaxPiah8ucicY9WZm0ZSeXdibLJiaK1P5J3wjgIjicFSODckKD4nI3F7kCxWKJe31iaVIH6Nia9ToKhw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;推荐阅读：&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI Lab部门简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;58同城AI Lab隶属TEG技术工程平台群，旨在推动AI技术在58同城的落地，打造AI中台能力，以提高前台业务人效、收入和用户体验。&lt;/span&gt;&lt;span&gt;部门介绍具体见：&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;amp;mid=2456203141&amp;amp;idx=1&amp;amp;sn=ddc71e22dd1f8c5f9e58eaa28ad4ebc3&amp;amp;chksm=87102499b067ad8fb2bdc2635f38cf15d68130ebfc57057f1100cef9b2402bb1a45ce60481e7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;58同城AI Lab部门介绍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;58同城AI Lab部门介绍&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;欢迎关注部门微信公众号：58AILab。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzA5OTQ1MDQ4Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/sz_mmbiz_png/K01T9Yo4EoaA721Tqju4H69OouAMW2O0XoFWO5NLKlvibolx2UBTg9ONlkEN53ib7JlEwnBD4Mk6KkHkP8w3GV9w/0?wx_fmt=png&quot; data-nickname=&quot;58AILab&quot; data-alias=&quot;AItech_58&quot; data-signature=&quot;58同城AI Lab公众号，关注AI技术和实践经验。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/K01T9Yo4EoYkhrY6O8bYGd76fJ4XKyw4vhicTAlQb9yUNTpBYAicAS1QrBTcibjKG1ibjg5726hgllFG3YER1ucdibQ/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;860&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d533b06d2a3aeb6393d9ff4b9ce791d8</guid>
<title>一文详解扩散模型：DDPM</title>
<link>https://toutiao.io/k/pulcqkj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h4&gt;&lt;strong&gt;作者：京东零售 刘岩&lt;/strong&gt;&lt;/h4&gt;

&lt;h1&gt;扩散模型讲解&lt;/h1&gt;

&lt;h2&gt;前沿&lt;/h2&gt;

&lt;p&gt;人工智能生成内容（AI Generated Content，AIGC）近年来成为了非常前沿的一个研究方向，生成模型目前有四个流派，分别是生成对抗网络（Generative Adversarial Models，GAN），变分自编码器（Variance Auto-Encoder，VAE），标准化流模型（Normalization Flow， NF）以及这里要介绍的扩散模型（Diffusion Models，DM）。扩散模型是受到热力学中的一个分支，它的思想来源是非平衡热力学（Non-equilibrium thermodynamics）。扩散模型的算法理论基础是通过变分推断（Variational Inference）训练参数化的马尔可夫链（Markov Chain），它在许多任务上展现了超过GAN等其它生成模型的效果，例如最近非常火热的OpenAI的DALL-E 2，Stability.ai的Stable Diffusion等。这些效果惊艳的模型扩散模型的理论基础便是我们这里要介绍的提出扩散模型的文章[1]和非常重要的DDPM[2]，扩散模型的实现并不复杂，但其背后的数学原理却非常丰富。在这里我会介绍这些重要的数学原理，但省去了这些公式的推导计算，如果你对这些推导感兴趣，可以学习参考文献[4,5,11]的相关内容。我在这里主要以一个相对简单的角度来讲解扩散模型，帮助你快速入门这个非常重要的生成算法。&lt;/p&gt;

&lt;h2&gt;1. 背景知识: 生成模型&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b35372caf579b4088aa6d7c466f12dfeed9.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;目前生成模型主要有图1所示的四类。其中GAN的原理是通过判别器和生成器的互相博弈来让生成器生成足以以假乱真的图像。VAE的原理是通过一个编码器将输入图像编码成特征向量，它用来学习高斯分布的均值和方差，而解码器则可以将特征向量转化为生成图像，它侧重于学习生成能力。流模型是从一个简单的分布开始，通过一系列可逆的转换函数将分布转化成目标分布。扩散模型先通过正向过程将噪声逐渐加入到数据中，然后通过反向过程预测每一步加入的噪声，通过将噪声去掉的方式逐渐还原得到无噪声的图像，扩散模型本质上是一个马尔可夫架构，只是其中训练过程用到了深度学习的BP，但它更属于数学层面的创新。这也就是为什么很多计算机的同学看扩散模型相关的论文会如此费力。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e5ee1ec9f3394e07bd29a6f8b08f49ac%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_1.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图1：生成模型的四种类型 [4]&lt;/p&gt;

&lt;p&gt;扩散模型中最重要的思想根基是马尔可夫链，它的一个关键性质是平稳性。即如果一个概率随时间变化，那么再马尔可夫链的作用下，它会趋向于某种平稳分布，时间越长，分布越平稳。如图2所示，当你向一滴水中滴入一滴颜料时，无论你滴在什么位置，只要时间足够长，最终颜料都会均匀的分布在水溶液中。这也就是扩散模型的前向过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8686ee33155e4057988a594858ac1b7a%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_2.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图2：颜料分子在水溶液中的扩散过程&lt;/p&gt;

&lt;p&gt;如果我们能够在扩散的过程颜料分子的位置、移动速度、方向等移动属性。那么也可以根据正向过程的保存的移动属性从一杯被溶解了颜料的水中反推颜料的滴入位置。这边是扩散模型的反向过程。记录移动属性的快照便是我们要训练的模型。&lt;/p&gt;

&lt;h3&gt;2. 扩散模型&lt;/h3&gt;

&lt;p&gt;在这一部分我们将集中介绍扩散模型的数学原理以及推导的几个重要性质，因为推导过程涉及大量的数学知识但是对理解扩散模型本身思想并无太大帮助，所以这里我会省去推导的过程而直接给出结论。但是我也会给出推导过程的出处，对其中的推导过程比较感兴趣的请自行查看。&lt;/p&gt;

&lt;h4&gt;2.1 计算原理&lt;/h4&gt;

&lt;p&gt;扩散模型简单的讲就是通过神经网络学习从纯噪声数据逐渐对数据进行去噪的过程，它包含两个步骤，如图3：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-53d22dbd9ac0e75ed50fd292909a6079957.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/df9ff9ba24a146658ed124607bf495c1%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_3.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图3：DDPM的前向加噪和后向去噪过程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4461c951853c3e8234f9df3cc159e71d869.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.1 前向过程&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-61c9bd6062262503faa96fa4cf31ba7e38a.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a642b6099d5eb4b0c08752adb46205fb532.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.2 后向过程&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-93dbc0d9867a95b4ae21476c068827e63b0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.3 目标函数&lt;/h4&gt;

&lt;p&gt;那么问题来了，我们究竟使用什么样的优化目标才能比较好的预测高斯噪声的分布呢？一个比较复杂的方式是使用变分自编码器的最大化证据下界（Evidence Lower Bound, ELBO）的思想来推导，如式(6)，推导详细过程见论文[11]的式(47)到式(58)，这里主要用到了贝叶斯定理和琴生不等式。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-48ea665f2dafa4ee17686d0e29bffc910a4.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;式(6)的推导细节并不重要，我们需要重点关注的是它的最终等式的三个组成部分，下面我们分别介绍它们：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c5d9c7467bc0258b4fc0cbffcc14e27ba52.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e23fcc641f454a6b846d97fbe8010dda%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_4.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图4：扩散模型的去噪匹配项在每一步都要拟合噪音的真实后验分布和估计分布&lt;/p&gt;

&lt;p&gt;真实后验分布可以使用贝叶斯定理进行推导，最终结果如式(8)，推导过程见论文[11]的式(71)到式(84)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b0def3f1985ebf2a6011cd37ef3d710aa39.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1b1640b37c37b8a0439ebf9046c7e990418.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;\(p{\boldsymbol{\theta}}\left(\boldsymbol{x}{t-1} \mid \boldsymbol{x}t\right) = \mathcal N(\boldsymbol x{t-1}; \mu\theta(\boldsymbol x_t, t), \Sigma_q(t)) \tag9\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b30476658b394d0b2a107e243965a2577d5.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4203a42c77277969e683d070453f222e497.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8ceb423af6ecd50cb25139eb9130d76c3f0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8ec4359ea3ccc0150c6cf59fd053998f1e3.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.4 模型训练&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-73ef2dbc80d583bc5a25bf5972c9a423680.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;虽然上面我们介绍了很多内容，并给出了大量公式，但得益于推导出的几个重要性质，扩散模型的训练并不复杂，它的训练伪代码见算法1。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0f071ea6ca0146878914cb9a33e041ca%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_ag1.png&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.5 样本生成&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0be5c14e1d629154e6ad509bba2d6fc0d92.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c198a3c52e4486d96d6c414fd57c630%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_ag2.png&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;2.2 算法实现&lt;/h3&gt;

&lt;h4&gt;2.2.1模型结构&lt;/h4&gt;

&lt;p&gt;DDPM在预测施加的噪声时，它的输入是施加噪声之后的图像，预测内容是和输入图像相同尺寸的噪声，所以它可以看做一个Img2Img的任务。DDPM选择了U-Net[9]作为噪声预测的模型结构。U-Net是一个U形的网络结构，它由编码器，解码器以及编码器和解码器之间的跨层连接（残差连接）组成。其中编码器将图像降采样成一个特征，解码器将这个特征上采样为目标噪声，跨层连接用于拼接编码器和解码器之间的特征。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c150054c5fe242f191439c05398856ea%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_5.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图5：U-Net的网络结构&lt;/p&gt;

&lt;p&gt;下面我们介绍DDPM的模型结构的重要组件。首先在U-Net的卷积部分，DDPM使用了宽残差网络（Wide Residual Network，WRN）[12]作为核心结构，WRN是一个比标准残差网络层数更少，但是通道数更多的网络结构。也有作者复现发现ConvNeXT作为基础结构会取得非常显著的效果提升[13,14]。这里我们可以根据训练资源灵活的调整卷积结构以及具体的层数等超参。因为我们在扩散过程的整个流程中都共享同一套参数，为了区分不同的时间片，作者借鉴了Transformer [15]的位置编码的思想，采用了正弦位置嵌入对时间$t$进行了编码，这使得模型在预测噪声时知道它预测的是批次中分别是哪个时间片添加的噪声。在卷积层之间，DDPM添加了一个注意力层。这里我们可以使用Transformer中提出的自注意力机制或是多头自注意力机制。[13]则提出了一个线性注意力机制的模块，它的特点是消耗的时间以及占用的内存和序列长度是线性相关的，对比传统注意力机制的平方相关要高效很多。在进行归一化时，DDPM选择了组归一化（Group Normalization，GN）[16]。最后，对于U-Net中的降采样和上采样操作，DDPM分别选择了步长为2的卷积以及反卷积。&lt;/p&gt;

&lt;p&gt;确定了这些组件，我们便可以搭建用于DDPM的U-Net的模型了。从第2.1节的介绍我们知道，模型的输入为形状为(batch_size, num_channels, height, width)的噪声图像和形状为(batch_size,1)的噪声水平，返回的是形状为(batch_size, num_channels, height, width)的预测噪声，我们搭建的用于噪声预测的模型结构如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 首先在噪声图像\( \boldsymbol x_0\)上应用卷积层，并为噪声水平$t$计算时间嵌入；&lt;/li&gt;
&lt;li&gt; 接下来是降采样阶段。采用的模型结构依次是两个卷积（WRNS或是ConvNeXT）+GN+Attention+降采样层；&lt;/li&gt;
&lt;li&gt; 在网络的最中间，依次是卷积层+Attention+卷积层；&lt;/li&gt;
&lt;li&gt; 接下来是上采样阶段。它首先会使用Short-cut拼接来自降采样中同样尺寸的卷积，再之后是两个卷积+GN+Attention+上采样层。&lt;/li&gt;
&lt;li&gt; 最后是使用WRNS或是ConvNeXT作为输出层的卷积。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;U-Net类的forword函数如下面代码片段所示，完整的实现代码参照[3]。&lt;/p&gt;

&lt;pre lang=&quot;python&quot;&gt;&lt;code&gt;def forward(self, x, time):
    x = self.init_conv(x)
    t = self.time_mlp(time) if exists(self.time_mlp) else None
    h = []
    # downsample
    for block1, block2, attn, downsample in self.downs:
        x = block1(x, t)
        x = block2(x, t)
        x = attn(x)
        h.append(x)
        x = downsample(x)
    # bottleneck
    x = self.mid_block1(x, t)
    x = self.mid_attn(x)
    x = self.mid_block2(x, t)
    # upsample
    for block1, block2, attn, upsample in self.ups:
        x = torch.cat((x, h.pop()), dim=1)
        x = block1(x, t)
        x = block2(x, t)
        x = attn(x)
        x = upsample(x)
    return self.final_conv(x)




&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2.2.2 前向加噪&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-30ecf8ea1e3f8e121c12c1860b7b12c4ac9.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/963eee81349d406d95c18fa29805fb98%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_6.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图6：一张图依次经过0次，50次，100次，150次以及199次加噪后的效果图&lt;/p&gt;

&lt;p&gt;根据式(14)我们知道，扩散模型的损失函数计算的是两张图像的相似性，因此我们可以选择使用回归算法的所有损失函数，以MSE为例，前向过程的核心代码如下面代码片段。&lt;/p&gt;

&lt;pre lang=&quot;python&quot;&gt;&lt;code&gt;def p_losses(denoise_model, x_start, t, noise=None, loss_type=&quot;l1&quot;):
    # 1. 根据时刻t计算随机噪声分布，并对图像x_start进行加噪
    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)
    # 2. 根据噪声图像以及时刻t，预测添加的噪声
    predicted_noise = denoise_model(x_noisy, t)
    # 3. 对比添加的噪声和预测的噪声的相似性
    loss = F.mse_loss(noise, predicted_noise)
    return loss




&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2.2.3 样本生成&lt;/h4&gt;

&lt;p&gt;根据2.1.5节介绍的样本生成流程，它的核心代码片段所示，关于这段代码的讲解我通过注释添加到了代码片段中。&lt;/p&gt;

&lt;pre lang=&quot;python&quot;&gt;&lt;code&gt;@torch.no_grad()
def p_sample(model, x, t, t_index):
    betas_t = extract(betas, t, x.shape)
    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape)
    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)
    # 使用式(13)计算模型的均值
    model_mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t)
    if t_index == 0:
        return model_mean
    else:
        # 获取保存的方差
        posterior_variance_t = extract(posterior_variance, t, x.shape)
        noise = torch.randn_like(x)
        # 算法2的第4行
        return model_mean + torch.sqrt(posterior_variance_t) * noise 

# 算法2的流程，但是我们保存了所有中间样本
@torch.no_grad()
def p_sample_loop(model, shape):
    device = next(model.parameters()).device
    b = shape[0]
    # start from pure noise (for each example in the batch)
    img = torch.randn(shape, device=device)
    imgs = []
    for i in tqdm(reversed(range(0, timesteps)), desc=&#x27;sampling loop time step&#x27;, total=timesteps):
        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)
        imgs.append(img.cpu().numpy())
    return imgs




&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后我们看下在人脸图像数据集下训练的模型，一批随机噪声经过逐渐去噪变成人脸图像的示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f7df428bb1c34532836ffda5aac66c31%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_7.gif&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图7：扩散模型由随机噪声通过去噪逐渐生成人脸图像&lt;/p&gt;

&lt;h2&gt;3. 总结&lt;/h2&gt;

&lt;p&gt;这里我们以DDPM为例介绍了另一个派系的生成算法：扩散模型。扩散模型是一个基于马尔可夫链的数学模型，它通过预测每个时间片添加的噪声来进行模型的训练。作为近日来引发热烈讨论的ControlNet， Stable Diffusion等模型的底层算法，我们十分有必要对其有所了解。DDPM的实现并不复杂，这得益于大量数学界大佬通过大量的数学推导将整个扩散过程和反向去噪过程进行了精彩的化简，这才有了DDPM的大道至简的实现。DDPM作为一个扩散模型的基石算法，它有着很多早期算法的共同问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 采样速度慢：DDPM的去噪是从时刻$T$到时刻$1$的一个完整的马尔可夫链的计算，尤其是DDPM还需要一个比较大的$T$才能保证比较好的效果，这就导致了DDPM的采样过程注定是非常慢的；&lt;/li&gt;
&lt;li&gt; 生成效果差：DDPM的效果并不能说是非常好，尤其是对于高分辨率图像的生成。这一方面是因为它的计算速度限制了它扩展到更大的模型；另一方面它的设计还有一些问题，例如逐像素的计算损失并使用相同权值而忽略图像中的主体并不是非常好的策略。&lt;/li&gt;
&lt;li&gt; 内容不可控：我们可以看出，DDPM生成的内容完全还是取决于它的训练集。它并没有引入一些先验条件，因此并不能通过控制图像中的细节来生成我们制定的内容。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们现在已经知道，DDPM的这些问题已大幅得到改善，现在基于扩散模型生成的图像已经达到甚至超过人类多数的画师的效果，我也会在之后逐渐给出这些优化方案的讲解。&lt;/p&gt;

&lt;h2&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] Sohl-Dickstein, Jascha, et al. &quot;Deep unsupervised learning using nonequilibrium thermodynamics.&quot; &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;. PMLR, 2015.&lt;/p&gt;

&lt;p&gt;[2] Ho, Jonathan, Ajay Jain, and Pieter Abbeel. &quot;Denoising diffusion probabilistic models.&quot; &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 33 (2020): 6840-6851.&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://huggingface.co/blog/annotated-diffusion&quot;&gt;https://huggingface.co/blog/annotated-diffusion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#simplification&quot;&gt;https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#simplification&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://openai.com/blog/generative-models/&quot;&gt;https://openai.com/blog/generative-models/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] Nichol, Alexander Quinn, and Prafulla Dhariwal. &quot;Improved denoising diffusion probabilistic models.&quot; &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;. PMLR, 2021.&lt;/p&gt;

&lt;p&gt;[7] Kingma, Diederik P., and Max Welling. &quot;Auto-encoding variational bayes.&quot; &lt;em&gt;arXiv preprint arXiv:1312.6114&lt;/em&gt; (2013).&lt;/p&gt;

&lt;p&gt;[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. &quot;Reducing the dimensionality of data with neural networks.&quot; &lt;em&gt;science&lt;/em&gt; 313.5786 (2006): 504-507.&lt;/p&gt;

&lt;p&gt;[9] Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.&lt;/p&gt;

&lt;p&gt;[10] Long, Jonathan, Evan Shelhamer, and Trevor Darrell. &quot;Fully convolutional networks for semantic segmentation.&quot; &lt;em&gt;Proceedings of the IEEE conference on computer vision and pattern recognition&lt;/em&gt;. 2015.&lt;/p&gt;

&lt;p&gt;[11] Luo, Calvin. &quot;Understanding diffusion models: A unified perspective.&quot; &lt;em&gt;arXiv preprint arXiv:2208.11970&lt;/em&gt; (2022).&lt;/p&gt;

&lt;p&gt;[12] Zagoruyko, Sergey, and Nikos Komodakis. &quot;Wide residual networks.&quot; &lt;em&gt;arXiv preprint arXiv:1605.07146&lt;/em&gt; (2016).&lt;/p&gt;

&lt;p&gt;[13] &lt;a href=&quot;https://github.com/lucidrains/denoising-diffusion-pytorch&quot;&gt;https://github.com/lucidrains/denoising-diffusion-pytorch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[14] Liu, Zhuang, et al. &quot;A convnet for the 2020s.&quot; &lt;em&gt;Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition&lt;/em&gt;. 2022.&lt;/p&gt;

&lt;p&gt;[15] Vaswani, Ashish, et al. &quot;Attention is all you need.&quot; &lt;em&gt;Advances in neural information processing systems&lt;/em&gt; 30 (2017).&lt;/p&gt;

&lt;p&gt;[16] Wu, Yuxin, and Kaiming He. &quot;Group normalization.&quot; &lt;em&gt;Proceedings of the European conference on computer vision (ECCV)&lt;/em&gt;. 2018.&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7516b1aa46398c0bf027d3ba990a4806</guid>
<title>研发提效利器：聊聊 mock 服务化</title>
<link>https://toutiao.io/k/uw0f4l3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;老张的求知思考世界&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;For-Think&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;专注互联网领域相关技术实践和思考，也分享职场成长、读书杂谈等内容。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>