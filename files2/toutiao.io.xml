<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>25d5e8e74fde99c1251687d1857227c7</guid>
<title>什么是顶级的思维？</title>
<link>https://toutiao.io/k/ulqvlcd</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;&lt;p data-first-child=&quot;&quot; data-pid=&quot;m8v6gniB&quot;&gt;分享几个非常适合职场人的顶级思维&lt;/p&gt;&lt;p data-pid=&quot;Hqu0GVua&quot;&gt;&lt;strong&gt;1、麦肯锡七步成诗：解决问题的7个步骤&lt;/strong&gt;&lt;/p&gt;&lt;p data-pid=&quot;9ZCkEKV3&quot;&gt;ProcessOn模板社区-麦肯锡解决问题的七个步骤&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.836111111111111&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ysfza24cADtY5Wf2P8EkX4IPzpwPqD7V0ibDlsnwgqRISTeSCAADOl652AhbIyd93GvZRnowCTC1juiaPUcZ8rdA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、SWOT分析法：基于竞争环境和竞争条件的态势分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8694444444444445&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ysfza24cADtY5Wf2P8EkX4IPzpwPqD7VTcfkwvwXe4Qb7UesmFfjzCtVZDBCDfO1qNFSh2Fz73hOCOBrskiaDbw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3、TWOS分析法：基于SWOT的战略制定&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.49027777777777776&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ysfza24cADtY5Wf2P8EkX4IPzpwPqD7VBC7DcPiaEKQCjkSic1Xc8fXJOKfdFDNVfPV2e1GyickzQ6yYBzibribNjfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;4、PEST分析模型：宏观环境分析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6430555555555556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ysfza24cADtY5Wf2P8EkX4IPzpwPqD7V4C5u3FEUgHN9W4ZsSic1vecVNsBg8wHz3zlfbNk3Uo3Q2X6K4ibWDTCg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;

          

          
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>68826b7f808c1c38b524882fcf0d51d4</guid>
<title>Kafka 面试连环炮, 看你能撑到哪一步?</title>
<link>https://toutiao.io/k/kd4d4fd</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;本系列总共4万多字，本篇是中篇，阅读本文大约需要 40 分钟。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大家好，我是华仔, 又跟大家见面了。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;之前有粉丝留言说能否总结和分享一些 Kafka 相关的面试题&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;今天我们就来安排一期关于 Kafka 的核心面试题连环炮,  从&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;基础知识&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;、&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;进阶提升&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;、&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;架构调优&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 三个方向梳理面试题，希望在金三银四的关键节点可以帮助到大家。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;由于内容很多，打算拆分成&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;上中下&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;三篇，本文是面试系列的中篇。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;这篇文章干货很多，希望你可以耐心读完。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.39609375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyopRDggwq0mKciccdJ3E37uediaQcK4AgJE2khpnGMfylLA9kOvqf4dM6so3JHUD9Yc7QvEMiatehmqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;02 kafka 进阶提升10问&lt;/span&gt;&lt;/h1&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈你对 kafka 的集群架构是如何理解的？&lt;/span&gt;&lt;/h1&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Kafka 整体架构图&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4150763358778626&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoeMialZBQdWF9GO2CuBRwpehybWcSN3SsX5n86c7j65TqWZWPg3rb7HQXicmh9Ib6V0FgMUBE9CibxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1048&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个典型的 Kafka 集群中包含若干 Producer，若干 Broker「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;Kafka支持水平扩展，一般 Broker 数量越多，集群吞吐率越高&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，若干 Consumer Group，以及一个 Zookeeper集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka 通过 Zookeeper 管理集群配置，选举 Leader，以及在 Consumer Group 发生变化时进行 Rebalance。Producer 使用 push 模式将消息发布到 Broker，Consumer使用 pull 模式从 Broker 订阅并消费消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Kafka 存储机制&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6949860724233984&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoeMialZBQdWF9GO2CuBRwpeHoYLmew91UsqibD0NrspkD48DqJ3j8At7yRhP8Go2EM54arn8UFfgLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;718&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Producer 端生产的消息会不断追加到 log 文件末尾，这样文件就会越来越大, 为了防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它将每个 Partition 分为多个 Segment每个 Segment 对应3个文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）.index 索引文件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）.log 数据文件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）.timeindex 时间索引文件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些文件都位于同一文件夹下面，该文件夹的命名规则为：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;topic 名称-分区号&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Kafka 副本机制&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46574074074074073&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpqp2KIDPBicGrHV0oWKfZJpNp1BbJOhsk42zMibfF9PT5ZG1L95viaQNpPNKPvI8SQW9u2oHc1axAUPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka中的 Partition 为了保证数据安全，每个 Partition 可以设置多个副本。&lt;/span&gt;&lt;span&gt;此时我们对分区0,1,2分别设置3个副本&lt;span&gt;。而且每个副本都是有&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;角色&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;之分的，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;它们会选取一个副本作为 Leader 副本，而其他的作为 Follower 副本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，我们的 Producer 端在发送数据的时候，只能发送到Leader Partition 里面 ，然后 Follower Partition 会去 Leader Partition 自行同步数据, Consumer 消费数据的时候，也只能从 Leader 副本那去消费数据的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;04&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Kafka 网络模型&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48703703703703705&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazppHLcRRSkQ2jzGhlo2kdR00Le1CQlzNgQv66XxwssQ3cFwXvHSgWPa0H8POg996gTWXud39hBOdIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Kafka 采用多路复用方案，Reactor 设计模式，并引用 Java NIO 的方式更好的解决网络超高并发请求问题。&lt;/span&gt;&lt;/h1&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈Kafka客户端如何巧妙解决JVM GC问题？&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Kafka 客户端缓冲机制&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，大家知道的就是在客户端发送消息给 Kafka 服务端的时候，存在一个「&lt;strong&gt;&lt;span&gt;内存缓冲池机制&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; &lt;/span&gt;的。即消息会先写入一个内存缓冲池中，然后直到多条消息组成了一个 Batch，达到一定条件才会一次网络通信把 Batch 发送过去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个发送过程图如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7032871972318339&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyrBl44FYHlUic91zUPmsur4XOiaRVtCL8giciafhHGBs9VLbmXL7kDibIZoUU5fcc5HsgjiamkUZj9icicG7A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1156&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Kafka Producer 发送消息流程如下:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）进行 Producer 初始化，加载配置参数，开启网络线程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）执行拦截器逻辑，预处理消息, 封装 Producer Record。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）调用 Serializer.serialize() 方法进行消息的 key/value 序列化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）调用 partition() 选择合适的分区策略，给消息体 Producer Record 分配要发送的 Topic 分区号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）从 Kafka Broker 集群获取集群元数据 metadata。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6）将消息缓存到 RecordAccumulator 收集器中, 最后判断是否要发送。这个加入消息收集器，首先得从 Deque&amp;lt;RecordBatch&amp;gt; 里找到自己的目标分区，如果没有就新建一个 Batch 消息 Deque 加进入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7）当达到发送阈值，唤醒 Sender 线程，实例化 NetWorkClient 将 batch record 转换成 request client 的发送消息体, 并将待发送的数据按 【Broker Id &amp;lt;=&amp;gt; List】的数据进行归类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8）与服务端不同的 Broker 建立网络连接，将对应 Broker 待发送的消息 List 发送出去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;9）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;批次发送的条件为: 缓冲区数据大小达到 batch.size 或者 linger.ms 达到上限，哪个先达到就算哪个。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;内存缓冲造成的频繁GC问题&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内存缓冲机制说白了，其实就是&lt;/span&gt;&lt;span&gt;&lt;strong&gt;把多条消息组成一个Batch，一次网络请求就是一个Batch 或者多个 Batch&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。这样避免了一条消息一次网络请求，从而提升了吞吐量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么问题来了，试想一下一个 Batch 中的数据取出来封装到网络包里，通过网络发送到达 Kafka 服务端。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;此时&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这个 Batch 里的数据都发送过去了，里面的数据该怎么处理？&lt;/span&gt;&lt;span&gt;这些 Batch 里的数据还存在客户端的 JVM 的内存里！那么一定要避免任何变量去引用 Batch 对应的数据，然后尝试触发 JVM 自动回收掉这些内存垃圾。这样不断的让 JVM 进行垃圾回收，就可以不断的腾出来新的内存空间让后面新的数据来使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想法是挺好，但&lt;/span&gt;&lt;strong&gt;&lt;span&gt;实际生产运行的时候最大的问题，就是 JVM Full GC 问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。JVM GC 在回收内存垃圾的时候，会有一个「&lt;strong&gt;&lt;span&gt;Stop the World&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的过程，即垃圾回收线程运行的时候，会导致其他工作线程短暂的停顿，这样可以踏踏实实的回收内存垃圾。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;试想一下，在回收内存垃圾的时候，工作线程还在不断的往内存里写数据，那如何让JVM 回收垃圾呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;我们看看下面这张图就更加清楚了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6107711138310894&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyrBl44FYHlUic91zUPmsur4XicAwTpWCulBEMQbhqcOr05uKo3eAdxTYhlvibVD8X3uI9D79gM5ltiaeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;817&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然现在 JVM GC 演进越来越先进，从 CMS 垃圾回收器到 G1 垃圾回收器，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;核心的目标之一就是不断的缩减垃圾回收的时候，导致其他工作线程停顿的时间&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;但是再先进的垃圾回收器这个停顿的时间还是存在的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，如何尽可能在设计上避免 JVM 频繁的 Full GC 就是一个非常考验其设计水平了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Kafka 实现的缓冲机制&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;在 Kafka 客户端内部，针对这个问题实现了一个非常优秀的机制，就是「&lt;strong&gt;&lt;span&gt;缓冲池机制&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;。即&lt;/span&gt;&lt;span&gt;每个 Batch 底层都对应一块内存空间，这个内存空间就是专门用来存放写进去的消息。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当一个 Batch 数据被发送到了 kafka 服务端，这个 Batch 的内存空间不再使用了。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;此时这个 Batch 底层的内存空间先不交给 JVM 去垃圾回收，而是把&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;这块内存空间给放入一个缓冲池里&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个缓冲池里存放了很多块内存空间，下次如果有一个新的 Batch 数据了，那么直接从缓冲池获取一块内存空间是不是就可以了？然后如果一个 Batch 数据发送出去了之后，再把内存空间还回来是不是就可以了？以此类推，循环往复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看看下面这张图就更加清楚了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7509293680297398&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazppn1MKTI37kEBia3ib6zYGoXEmG0clQsW211cHS33aFMHBC2eNw1YRFwiaf8NugZamu6JhsT1StyVEBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1076&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3094384707287933&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpqHxJ6FBics1DexDVTLbmDe5x8YzjFQ1xrT2bfFdbH1neZbOU2PTgg3p7khOqdarQ1MCibnp1KFPjvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;837&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦使用了这个缓冲池机制之后，就不涉及到频繁的大量内存的 GC 问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;初始化分配固定的内存，即32MB。然后把 32MB 划分为 N 多个内存块，一个内存块默认是16KB，这样缓冲池里就会有很多的内存块&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。然后如果需要创建一个新的 Batch，&lt;/span&gt;&lt;span&gt;就从缓冲池里取一个 16KB 的内存块就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着如果 Batch 数据被发送到 Kafka 服务端了，此时 Batch 底层的内存块就直接还回缓冲池就可以了。这样循环往复就可以利用有限的内存，那么就不涉及到垃圾回收了。没有频繁的垃圾回收，自然就避免了频繁导致的工作线程的停顿了，JVM Full GC 问题是不是就得到了大幅度的优化？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;没错，正是这个设计思想让 Kafka 客户端的性能和吞吐量都非常的高，这里蕴含了大量的优秀的机制&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈你对 Kafka 消息语义是如何理解的？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;对于 Kafka 来说，当消息从 Producer 到 Consumer，有许多因素来影响消息的消费，因此「&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;就是 Kafka 提供的 Producer 和 Consumer 之间的消息传递过程中消息传递的保证性。主要分为三种， 如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.30462962962962964&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ojWoacgRbyrBl44FYHlUic91zUPmsur4XdBOTqoD9qhhUxD6tQ42pAyTSXdlAjDhbMmSaCV9Lcib1Pbb50wbwvgA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这三种语义，我们来看一下可能出现的场景：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.47343957503320055&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyovon6XYrCeoliaRqfhrfbSJReG7ricPdYIBB5CSOPLkGoib5U508QHFwekKQWBKtoHSu6xYLlkO5Kag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1506&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Producer端&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;生产者发送语义：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;首先当 Producer 向 Broker 发送数据后，会进行消息提交，如果成功消息不会丢失。因此发送一条消息后，可能会有几种情况发生&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1）遇到网络问题造成通信中断， 导致 Producer 端无法收到 ack，Producer 无法准确判断该消息是否已经被提交， 又重新发送消息，这就可能造成 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at least once&lt;span&gt;‍‍‍‍‍‍‍‍‍‍‍‍‍&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;语义。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2）在 Kafka 0.11之前的版本，会导致消息在 Broker 上重复写入（保证至少一次语义），但在0.11版本开始，通过引入「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;PID及Sequence Number&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」支持幂等性，保证精确一次&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;exactly once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;语义&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;其中启用幂等传递的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：enable.idempotence = true。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;启用事务支持的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：设置属性 transcational.id = &quot;指定值&quot;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;3）可以&lt;/span&gt;&lt;span&gt;根据 Producer 端 request.required.acks 的配置来取值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;acks = 0：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;由于发送后就自认为发送成功，这时如果发生网络抖动， Producer 端并不会校验 ACK 自然也就丢了，且无法重试。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;acks = 1：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;消息发送 Leader Parition 接收成功就表示发送成功，这时只要 Leader Partition 不 Crash 掉，就可以保证 Leader Partition 不丢数据，保证&lt;span&gt; &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at least once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;语义。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;acks = -1 或者 all：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 消息发送需要等待 ISR 中 Leader Partition 和 所有的 Follower Partition 都确认收到消息才算发送成功, 可靠性最高, 但也不能保证不丢数据,比如当 ISR 中只剩下 Leader Partition 了, 这样就变成 acks = 1 的情况了&lt;span&gt;，保证 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at least once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;语义&lt;/span&gt;。 &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5020325203252033&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyovon6XYrCeoliaRqfhrfbSJiatwQ74kiaEtKBAOrosqxnic5gTdAwT4ibFlGQBEmLG1zDRtI4n3LQPp0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;984&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.49214659685863876&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyovon6XYrCeoliaRqfhrfbSJOzjudoQLF6licvWS9NVqz5GGtcZsckUbRkthHkia8qyalbC2xYb2dibyg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;Consumer端&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;消费者接收语义：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;从 Consumer 角度来剖析，我们知道 Offset 是由 Consumer 自己来维护的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Consumer 消费消息时，有以下2种选择:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;读取消息 -&amp;gt; 提交offset -&amp;gt; 处理消息:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;如果此时保存 offset 成功，但处理消息失败，Consumer 又挂了，会发生 Reblance，新接管的 Consumer 将从上次保存的 offset 的下一条继续消费，导致消息丢失，保证&lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at most once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;语义&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;strong&gt;&lt;span&gt;读取消息 -&amp;gt; 处理消息 -&amp;gt; 提交offset：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;如果此时消息处理成功，但保存 offset 失败，Consumer 又挂了，导致刚才消费的 offset 没有被成功提交，会发生 Reblance，新接管的 Consumer 将从上次保存的 offset 的下一条继续消费，导致消息重复消费，保证&lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at least once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;语义&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;默认 Kafka 提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;at least once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;语义的消息传递&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;允许用户通过在处理消息之前保存 Offset 的方式提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at most once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 语义。如果我们可以自己实现消费幂等，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;理想情况下这个系统的消息传递就是严格的&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;exactly once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」, &lt;/span&gt;&lt;span&gt;也就是保证不丢失、且只会被精确的处理一次，但是这样是很难做到的。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈你对 Kafka 副本机制是如何理解的？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在上篇中，我们简单的分析了 Kafka 副本机制，这里我们再详细分析下 Kafka 的副本机制，说白了就是一个&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;数据备份机制&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;保证集群中的某个节点发生故障时，该节点上的 Partition 数据不丢失，且 Kafka 仍然能够继续工作，提高了系统可用性和数据持久性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;同一个分区下的所有副本保存相同的消息数据，这些副本分散保存在不同的 Broker 上，保证了 Broker 的整体可用性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示：一个由 3 台 Broker 组成的 Kafka 集群上的副本分布情况。从这张图中，我们可以看到，主题 1 分区 1 的 3 个副本分散在 3 台 Broker 上，其他主题分区的副本也都散落在不同的 Broker 上，从而实现数据冗余。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.44970414201183434&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyp2IZTg1NWIjZ8C1zrhkkAZW26wVwE3sqiaV5nMoNLQv4xvrKfeaJddgQxTSzSNEpu9HO9OC80zCuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1014&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;副本同步机制&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然所有副本的消息内容相同，&lt;/span&gt;&lt;span&gt;&lt;span&gt;我们该如何保证副本中所有的数据都是一致的呢？当 Producer 发送消息到某个 Topic 后，消息是如何同步到对应的所有副本 Replica 中的呢？Kafka 中 只有 Leader 副本才能对外进行读写服务，所以解决同步问题，Kafka 是采用基于 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Leader&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;的副本机制来完成的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;在 Kafka 中，一个 Topic 的每个 Partition 都有若干个副本&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;副本分成两类：领导者副本「Leader Replica」和追随者副本「Follower Replica」&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;。每个分区在创建时都要选举一个副本作为领导者副本，其余的副本作为追随者副本&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;在 Kafka 中，Follower 副本是不对外提供服务的。也就是说，任何一个&lt;span&gt;Follower 副本&lt;/span&gt;都不能响应客户端的读写请求。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;所有的读写请求都必须先发往 Leader 副本所在的 Broker，由该 Broker 负责处理。&lt;span&gt;Follower 副本&lt;/span&gt;不处理客户端请求，它唯一的任务就是从 &lt;span&gt;Leader 副本&lt;/span&gt;异步拉取消息，并写入到自己的提交日志中，从而实现与 &lt;span&gt;Leader 副本&lt;/span&gt;的同步&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;3）在 Kafka 2.X 版本中，&lt;/span&gt;&lt;span&gt;当 &lt;span&gt;Leader 副本 &lt;/span&gt;所在的 Broker 宕机时，ZooKeeper 提供的监控功能能够实时感知到，并立即开启新一轮的 Leader 选举，从 ISR 副本集合中 &lt;span&gt;Follower 副本&lt;/span&gt;中选一个作为新的 Leader ，当旧的 Leader 副本重启回来后，只能作为&lt;span&gt; Follower 副本&lt;/span&gt;加入到集群中&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。3.x 的选举后续会有单篇去介绍。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;副本管理&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.668918918918919&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyqFuCYnZkWFk99vXIBFS6qdnUkd8Tia7rc7YYWqU1OJAbMIPuNtyULcLOEzSsIckz23iaFQkrQZ4CKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;592&quot;/&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;strong&gt;&lt;span&gt;AR 副本集合:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 分区 Partition 中的所有 Replica 组成 AR 副本集合。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;ISR 副本集合:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 所有与 Leader 副本能保持一定程度同步的 Replica 组成 ISR&lt;span&gt; 副本集合， 其中也包括 Leader 副本。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）&lt;/span&gt;&lt;strong&gt;&lt;span&gt;OSR 副本集合: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;与 Leader 副本同步滞后过多的 Replica 组成 OSR 副本集合&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;这里我们重点来分析下 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;ISR 副本集合。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;04&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;ISR 副本集合&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面强调过，Follower 副本不提供服务，只是定期地异步拉取 Leader 副本中的数据。既然是异步的，就一定会存在不能与 Leader 实时同步的情况出现&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka 为了解决这个问题， 引入了&lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt; In-sync Replicas&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;机制&lt;/span&gt;，即 ISR 副本集合。要求 ISR 副本集合中的 Follower 副本都是与 Leader 同步的副本&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;那么，到底什么样的副本能够进入到 ISR 副本集合中呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先要明确的，Leader 副本天然就在 ISR 副本集合中。也就是说，ISR 不只是有 Follower 副本集合，它必然包括 Leader 副本。另外，能够进入到 ISR 副本集合的 Follower 副本要满足一定的条件&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5907534246575342&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyp2IZTg1NWIjZ8C1zrhkkAZUgl44pMh0P4gK1pf7JSBicjSibT6FMS4G3Kz6JlScfB4t5fuo8exJMvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;584&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中有 3 个副本：1 个 Leader 副本和 2 个 Follower 副本。Leader 副本当前写入了 6 条消息，Follower1 副本同步了其中的 4 条消息，而 Follower2 副本只同步了其中的 3 条消息。那么，对于这 2 个 Follower 副本，你觉得哪个 Follower 副本与 Leader 不同步？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，这2个 Follower 副本都有可能与 Leader 副本同步，但也可能不与 Leader 副本同步，这个完全依赖于&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Broker 端参数 replica.lag.time.max.ms 参数值。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个参数是指&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒，从 2.5 版本开始，&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;默认值从 10 秒增加到 30 秒&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;即只要一个 Follower 副本落后Leader 副本的时间不连续超过 30 秒，Kafka 就认为该 Follower 副本与 Leader 是同步的，即使 Follower 副本中保存的消息明显少于 Leader 副本中的消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此时如果这个副本同步过程的速度持续慢于 Leader 副本的消息写入速度的时候，那么在 replica.lag.time.max.ms 时间后，该 Follower 副本就会被认为与 Leader 副本是不同步的，因此 &lt;span&gt;Kafka 会自动收缩，将其&lt;/span&gt;踢出 ISR 副本集合中。后续如果该副本追上了 Leader 副本的进度的话，那么它是能够重新被加回 ISR副本集合的&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在默认情况下，当 Leader 副本发生故障时，只有在 ISR 副本集合中的 Follower 副本才有资格被选举为新Leader，而 OSR 中副本集合的副本是没有机会的（可以通过&lt;/span&gt;&lt;strong&gt;&lt;span&gt;unclean.leader.election.enable&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;进行配置执行脏选举）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结：ISR 副本集合是一个动态调整的集合。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈你对Kafka Leader选举机制是如何理解？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;这里所说的 Leader 选举是指分区 Leader 副本的选举，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;它是由 Kafka Controller 负责具体执行的，当创建分区或分区副本上线的时候都需要执行 Leader 的选举动作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有以下场景可能会触发选举：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）当 Controller 感知到分区 Leader 下线需要执行 Leader 选举。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此时的选举策略是：Controller 会从 AR 副本集合（同时也在ISR 副本集合）中按照副本的顺序取出第一个存活的副本作为 Leader。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;⼀个分区的 AR 副本集合在分配的时候就被指定，并且只要不发⽣重分配集合内部副本的顺序是保持不变的，而分区的 ISR 副本集合中副本的顺序可能会改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意这里是根据 AR 副本集合的顺序而不是 ISR 副本结合的顺序进行选举的。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此时如果 ISR 副本集合中没有可用的副本，还需要再检查⼀下所配置的 unclean.leader.election.enable 参数&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;默认值为false&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;如果这个参数配置为true，那么表示允许从非 ISR 副本集合中选举 Leader，从 AR 副本集合列表中找到第⼀个存活的副本即为 Leader&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）当分区进行重分配的时候也需要进行 Leader 选举。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;此时的选举策略是&lt;/span&gt;：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;从重分配的 AR 副本集合中找到第⼀个存活的副本，且这个副本在当前的 ISR 副本集合中。当发生优先副本的选举时，直接将优先副本设置为 Leader 即可，AR 副本集合中的第⼀个副本即为优先副本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）当某节点&lt;span&gt;执⾏ ControlledShutdown &lt;/span&gt;被优雅地关闭时，位于这个节点上的 Leader 副本都会下线，所以与此对应的分区需要执行 Leader 的选举。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;此时的选举策略是&lt;/span&gt;：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;从 AR 副本集合中找到第⼀个存活的副本，且这个副本在当前的 ISR 副本集合中，同时还要确保这个副本不处于正在被关闭的节点上&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈你对Kafka控制器及选举机制是如何理解？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;所谓的控制器&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;Controller&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;就是通过 ZooKeeper 来管理和协调整个 Kafka 集群的组件。集群中任意一台 Broker 都可以充当控制器的角色，但是在正常运行过程中，只能有一个 Broker 成为控制器&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;控制器的职责主要包括：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）集群元信息管理及更新同步 (Topic路由信息等)&lt;/span&gt;&lt;span&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;主题管理（创建、删除、增加分区等）&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）分区重新分配&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）副本故障转移、 Leader 选举、ISR 变更。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）集群成员管理（通过 watch 机制自动检测新增 Broker、Broker 主动关闭、Broker 宕机等）。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;控制器机制&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;我们知道 &lt;/span&gt;&lt;span&gt;Kafka 2.X 版本是依赖 Zookeeper 来维护集群成员的信息：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;Kafka 使用 Zookeeper 的临时节点来选举 Controller。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;Zookeeper 在 Broker 加入集群或退出集群时通知 Controller&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;Controller 负责在 Broker 加入或离开集群时进行分区 Leader 选举&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;控制器数据分布&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;table align=&quot;center&quot; interlaced=&quot;enabled&quot;&gt;&lt;tbody&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;strong&gt;&lt;span&gt;分类&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;strong&gt;&lt;span&gt;数据描述&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;middle&quot; rowspan=&quot;4&quot; colspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;Broker&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;当前存活的 broker 列表&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;正在关闭中的 broker 列表&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;获取某个 broker 上的所有分区&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;某组 broker 上的所有副本&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;middle&quot; rowspan=&quot;4&quot; colspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;Topic&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;topic 列表&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;某个 topic 的所有分区和&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有副本&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;移除某个 topic 的所有信息&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;span&gt;每个分区的 Leader 和 ISR 信息&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td colspan=&quot;1&quot; valign=&quot;middle&quot; align=&quot;center&quot; rowspan=&quot;5&quot;&gt;&lt;p&gt;&lt;span&gt;运维任务&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;副本相关&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;正在进行的&lt;/span&gt;&lt;/p&gt;&lt;span&gt;Leader 选举的分区&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;span&gt;当前存活的所有副本&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;span&gt;分配给每个分区的副本列表&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;span&gt;正在进行重分配的分区列表&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;span&gt;某组分区下的所有副本&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上面表格可以看出,存储的大概有3大类:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;所有topic信息：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;包括具体的分区信息，比如 Leader 副本是谁，ISR 集合中有哪些副本等&lt;/span&gt;&lt;span&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;所有 Broker 信息：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;包括当前都有哪些运行中的 Broker，哪些正在关闭中的 Broker 等&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;涉及运维任务的副本分区：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;包括当前正在进行 Leader 选举以及分区重分配的分区列表等&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;控制器故障转移&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Kafka 集群运行过程中，只能有一台 Broker 充当控制器的角色，存在「&lt;strong&gt;&lt;span&gt;单点故障&lt;/span&gt;&lt;/strong&gt;」的风险，Kafka 如何应对单点故障呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实 Kafka 为控制器提供故障转移功能「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;Failover&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;指当运行中的控制器突然宕机时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败控制器的过程&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面通过一张图来展示控制器故障转移的过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4748663101604278&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpocMOmcxSFibYCGCYagQuUiafiaMN2va2lLtMpFcpGAcKmPKGf3lMDwHZRmQ9tBlkcXc99ia4pjSKMzzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;935&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;04&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;控制器触发选举场景&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至此你一定想知道控制器是如何被选出来的？前面说过，每台 Broker 都能充当控制器，当集群启动后，Kafka 是如何确认控制器在哪台 Broker 呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上这个问题很简单，即 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Broker 启动时，&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;会尝试去 ZooKeeper 中创建 /controller 节点，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第一个成功创建 /controller 节点的 Broker 会被选为控制器&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来我们看下&lt;/span&gt;&lt;strong&gt;&lt;span&gt;触发 Controller 选举的场景&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;有哪些？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;场景一、集群首次启动时：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群首次启动时，Controller 还未被选举出来，因此 Broker 启动后，会干4件事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;先注册 Zookeeper 状态变更监听器，用来监听 Broker 与 Zookeeper 之间的会话是否过期。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;然后将 Startup 这个控制器事件写入到事件队列中&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;然后开始启动对应的控制器事件处理线程即「&lt;strong&gt;&lt;span&gt;ControllerEventThread&lt;/span&gt;&lt;/strong&gt;」、以及 「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;ControllerChangeHandler&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」 Zookeeper 监听器，开始处理事件队列中Startup 事件。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）最后依赖事件处理线程来选举 Controller&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;场景二、Broker 监听 /controller 节点消失时&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群运行过程中，当 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;Broker 监听到 /controller 节点消失时，就表示此时当前整个集群中已经没有 Controller 了&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。所有监听到 /controller 节点消失的 Broker，此时都会开始执行竞选操作。 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么 Broker 是如何监听到 ZooKeeper 上的变化呢？主要依赖 ZooKeeper 监听器提供的功能，所以 Kafka 是依赖 ZooKeeper 来完成 Controller 的选举。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Kafka 3.X 版本中，内部实现一个类似于 Raft 的共识算法来选举 Controller。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;场景三、Broker 监听 /controller 节点数据变化时&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群运行过程中，当&lt;/span&gt;&lt;span&gt;&lt;strong&gt; Broker 检测到 /controller 节点数据发生变化，此时 Controller 可能已经被「易主」了&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，这时有以下两种情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）假如 Broker 是 Controller，那么该 Broker 需要首先执「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;退位&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」操作，然后再尝试进行竞选 Controller。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）假如 Broker 不是 Controller，那么，该 Broker 直接去竞选新 Controller。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;05&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;控制器选举机制&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实选举最终都是通过调用底层的 elect 方法进行选举，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoeMialZBQdWF9GO2CuBRwpeMxyVPsxJ1xuXyRYDB33eiadQf2dg5KicclolcBGrNAQFxg9lQ190Ovqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈 kafka 的数据可靠性是怎么保证的？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;开始数据可靠性之前先看几个重要的概念：AR、OSR、ISR、HW、LEO，前面已经讲了 AR、OSR、ISR。这里我们重点讲下 HW、LEO。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;HW：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;全称「&lt;strong&gt;&lt;span&gt;Hign WaterMark&lt;/span&gt;&lt;/strong&gt;」 ，即&lt;span&gt;高水位，它标识了一个特定的消息偏移量 offset ，消费者只能拉取到这个水位 offset 之前的消息。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LEO：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;全称「&lt;strong&gt;&lt;span&gt;Log End Offset&lt;/span&gt;&lt;/strong&gt;」，它&lt;span&gt;标识当前日志文件中下一条待写入的消息的 offset，在 ISR 副本集合中的每个副本都会维护自身的LEO。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5879629629629629&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr2PPUPywVebvOZDNpMFoJ1bevkv1wR1So1iaAIyZP5kg919B8rwKJmibEF9hSib2CwX3k8TRxic81Wmg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上图可以看出 HW 和 LEO 的作用：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;HW 作用：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;用来标识分区下的哪些消息是可以被消费者消费的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;协助 Kafka 完成副本数据同步&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LEO 作用：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;&lt;span&gt;如果 Follower 和 Leader 的 LEO 数据&lt;/span&gt;&lt;span&gt;同步了, 那么 HW 就可以更新了&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;&lt;span&gt;HW 之前的消息数据对消费者是可见的，&lt;/span&gt;&lt;span&gt;属于 commited 状态,  HW 之后的消息数据对消费者是不可见的&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24934383202099739&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazprektvj6gaAYp8JobQzcf7Mv65pVWmZz6kyKv2DKeM8pLSEavcv99FUzgaJhiauZibzzLvKiachUI2dg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;762&quot;/&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;HW 更新是需要一轮额外的拉取请求才能实现，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;Follower 副本要拉取 Leader 副本的数据，&lt;/span&gt;&lt;span&gt;也就是说，Leader 副本 HW 更新和 Follower 副本 HW 更新在时间上是存在错配的&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;这种错配是很多“数据丢失”或“数据不一致”问题的根源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;因此社区在 0.11 版本正式引入了&lt;/span&gt;&lt;span&gt; 「&lt;strong&gt;&lt;span&gt;&lt;strong&gt;Leader Epoch&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;」 &lt;/span&gt;&lt;span&gt;概念，来规避因 HW 更新错配导致的各种不一致问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 所谓 Leader Epoch，我们大致可以认为是 Leader 版本。它由两部分数据组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;strong&gt;&lt;span&gt;Epoch: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一个单调递增的版本号。每当副本 Leader 权力发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;起始位移（Start Offset）:&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; Leader 副本在该 Epoch 值上写入的首条消息的位移。&lt;/span&gt;&lt;strong/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;Kafka Broker 会在&lt;/span&gt;&lt;strong&gt;&lt;span&gt;内存中为每个分区都缓存 Leader Epoch 数据&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，同时它还会定期地将这些信息&lt;/span&gt;&lt;strong&gt;&lt;span&gt;持久化到一个 checkpoint 文件&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;中。当 Leader Partition 写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目，否则就不做更新。这样，每次有 Leader 变更时，新的 Leader 副本会查询这部分缓存，取出对应的 Leader Epoch 的起始位移，以避免数据丢失和不一致的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;严格来说，这个场景发生的前提是 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Broker 端参数 min.insync.replicas 设置为 1&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。此时一旦消息被写入到 Leader 副本的磁盘，就会被认为是 commited 状态，但因存在时间错配问题导致 Follower 的 HW 更新是有滞后的。如果在这个短暂的滞后时间内，接连发生 Broker 宕机，那么这类数据的丢失就是无法避免的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来, 我们来看下如何利用 Leader Epoch 机制来规避这种数据丢失。如下图所示:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6563467492260062&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoeMialZBQdWF9GO2CuBRwpeoQtVdGUtKtJ6jGichmhIAahYak56UVKAIKmk9YudKw5OHZjlwXENMww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;969&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;因此 Kafka 只对 &lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息做&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;由于篇幅&lt;/span&gt;&lt;span&gt;详细请看：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247490489&amp;amp;idx=1&amp;amp;sn=17817f6d9837ad6a8823362d5ed38687&amp;amp;chksm=cefb3288f98cbb9edeb568e51127c25caa90da6dd064936560a851a9c9e5b865bb49ca04312d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;刨根问底: Kafka 到底会不会丢数据？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;刨根问底: Kafka 到底会不会丢数据&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈 Kafka 消息分配策略都有哪些？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.36926360725720386&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoeMialZBQdWF9GO2CuBRwpeu9ibrwaKALeribNCiaIicHY6iaiaAic9xVqcDA2yGg9vLfsMdqkibjANm9OydA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;937&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里主要说的是&lt;/span&gt;&lt;span&gt;&lt;strong&gt;消费的分区分配策略&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，我们知道一个 Consumer Group 中有多个 Consumer，一个 Topic 也有多个 Partition，所以必然会有 Partition 分配问题「&lt;strong&gt;&lt;span&gt; &lt;strong&gt;确定哪个 Partition 由哪个 Consumer 来消费的问题&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka 客户端提供了3 种分区分配策略：RangeAssignor、RoundRobinAssignor 和 StickyAssignor，前两种分配方案相对简单一些StickyAssignor 分配方案相对复杂一些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;RangeAssignor &lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;RangeAssignor 是 Kafka 默认的分区分配算法，它是按照 Topic 的维度进行分配的&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，首先对 每个Topic 的 Partition 按照分区ID进行排序，然后对订阅该 Topic 的 Consumer Group 的 Consumer 按名称字典进行排序，之后&lt;/span&gt;&lt;strong&gt;&lt;span&gt;尽量均衡的按照范围区段将分区分配给 Consumer&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。此时也可能会造成先分配分区的 Consumer 任务过重（分区数无法被消费者数量整除）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;分区分配场景分析如下图所示（同一个消费者组下的多个 consumer）：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5107655502392344&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr5zt2hOlk3F9pic5Gyfm4caiap42wPFL44pEMsmslaxK7icTlsM6Fmvkz6flXhcwOiaTKDvibU7QsWviag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6710239651416122&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr5zt2hOlk3F9pic5Gyfm4ca6JTibXWSibdFaMloloY0ZHpKLvOtk0ub9EgJVas7oS7Vl3sQg0UibORKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;918&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;总结：该分配方式明显的问题就是随着消费者订阅的Topic的数量的增加，不均衡的问题会越来越严重。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;RoundRobinAssignor&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;该分区分配策略是将 Consumer Group 订阅的所有 Topic 的 Partition 及所有 Consumer 按照字典进行排序后尽量均衡的挨个进行分配。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;如果 Consumer Group 内，每个 Consumer 订阅都订阅了相同的Topic，那么分配结果是均衡的。如果订阅 Topic 是不同的，那么分配结果是不保证「&lt;strong&gt;&lt;span&gt; &lt;strong&gt;&lt;span&gt;尽量均衡&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;」的，因为某些 Consumer 可能不参与一些 Topic 的分配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;分区&lt;/strong&gt;分配场景分析如下图所示：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1) 当组内每个 Consumer 订阅的相同 Topic ：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4880095923261391&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr5zt2hOlk3F9pic5Gyfm4ca3a3YJ1tp2MS7K7veFmFI1oYSHuPAUAzEzk9yM9ibU6frXN8tV9Pw18Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2) 当组内每个订阅的不同的 Topic ，这样就可能会造成分区订阅的倾斜:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4856262833675565&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcrD0BkNTVpwY19tibdlyE6NtWub5jicygoZ4oZTUicUhU8yciaOG3vXQsibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;974&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;StickyAssignor&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该分区分配算法是最复杂的一种，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;可以通过 partition.assignment.strategy 参数去设置&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，从 0.11 版本开始引入，目的就是在执行新分配时，尽量在上一次分配结果上少做调整，其主要实现了以下2个目标：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、Topic Partition 的分配要尽量均衡。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、当 Rebalance 发生时，尽量与上一次分配结果保持一致。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;当两个目标发生冲突的时候，优先保证第一个目标，这样可以使分配更加均匀&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，其中第一个目标是3种分配策略都尽量去尝试完成的， 而第二个目标才是该算法的精髓所在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们看看该策略与RoundRobinAssignor策略的不同：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;分区&lt;/strong&gt;分配场景分析如下图所示：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）组内每个 Consumer 订阅的相同的 Topic ，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;RoundRobinAssignor 跟&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;StickyAssignor &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;分配一致：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.53125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr5zt2hOlk3F9pic5Gyfm4caRx42Oicbu0qXvP9iaqCAoTwvQicicYRfyvFRxNlPzMz35QB0khdB6Odovw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;832&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;当发生 Rebalance 情况后，可能分配会不太一样，假如这时候C1发生故障下线：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;RoundRobinAssignor：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5300353356890459&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr5zt2hOlk3F9pic5Gyfm4caHVGQReyaxQVEovicB68yDFQOib7WPZlvRzobux3ZqMiaSB5pUhmBNLhSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;849&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;StickyAssignor：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5080459770114942&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr5zt2hOlk3F9pic5Gyfm4car7wBTCLicTTsiaMZwhjfpnoQibF8exWSkZ6JuClPS9j7jsoQk3iaE314Ww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;870&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;结论: 从上面 Rebalance 发生后的结果可以看出，虽然两种分配策略最后都是均匀分配的，但是 RoundRoubin&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Assignor 分区分配策略&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt; 完全是重新分配了一遍，而 Sticky&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;Assignor&lt;/strong&gt; &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;则是在原先的基础上达到了均匀的状态。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2) 当组内每个 Consumer 订阅的 Topic 是不同情况:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;RoundRobinAssignor：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48897795591182364&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcNLW6KeAbB7pK0qExqp1pf2smxaoyFDGfrcfnDabWNicX1ZVECxGtI9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;998&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;StickyAssignor：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4845360824742268&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcIIwp95461y08NWIaJVmdicM4tbmibnexbwbVMpZ4BTwhL4h8SsG9JuOA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;970&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;当发生 Rebalance 情况后，可能分配会不太一样，假如这时候C1发生故障下线：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;RoundRobinAssignor：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45359749739311783&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcpFDBDIJXBPcn8fUQdHGXnNuJPIiaF3fRZNtAZVKOSktaGMia6JZIAPDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;959&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;StickyAssignor：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45390070921985815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcJ6s5oiaM1ib8B0TIda3DvlIkq2pdMMeyHiaystu2ce36bZdjQozy1cwSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;987&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上面结果可以看出，RoundRoubin 的分配策略在 Rebalance 之后造成了严重的分配倾斜。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;因此在生产环境上如果想要减少重分配带来的开销，可以选用 StickyAssignor 的分区分配策略。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;    &lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈 Kafka 消费者重平衡机制是怎样的？&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;所谓的消费者组的重平衡目的就是让组内所有的消费者实例对消费哪些主题分区达成一致&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Consumer Group 来说，可能随时都会有 Consumer 加入或退出，那么 Consumer 列表的变化必定会引起 Partition 的重新分配。我们将这个分配过程叫做 Consumer Rebalance，但是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;这个分配过程需要借助 Broker 端的 Coordinator 协调者组件，在 Coordinator 的帮助下完成整个消费者组的分区重分配，也是通过监听ZooKeeper 的 /admin/reassign_partitions 节点触发的&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;Rebalance 触发与通知&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rebalance 的触发条件有三种:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;当 Consumer Group 组成员数量发生变化(主动加入或者主动离组，故障下线等)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;当订阅主题数量发生变化&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;当订阅主题的分区数发生变化&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;Rebalance 触发后如何通知其他 Consumer 进程？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;Rebalance 的通知机制就是&lt;/span&gt;&lt;span&gt;&lt;strong&gt;靠 Consumer 端的心跳线程&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，它会定期发送心跳请求到 Broker 端的 Coordinator 协调者组件,当协调者决定开启 Rebalance 后，它会将&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;REBALANCE_IN_PROGRESS&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;封装&lt;/span&gt;&lt;span&gt;进心跳请求的响应中发送给 Consumer ,当 Consumer 发现心跳响应中包含了&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;REBALANCE_IN_PROGRESS&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;，就知道是 Rebalance 开始了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;Rebalance 协议说明&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实 Rebalance 本质上也是一组协议，Consumer Group 与 Coordinator 共同使用它来完成 Consumer Group 的 Rebalance。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我看看这5种协议完成了什么功能：&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Heartbeat 请求：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;Consumer 需要定期给 Coordinator 发送心跳来证明自己还活着。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;strong&gt;&lt;span&gt;LeaveGroup 请求：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主动告诉 Coordinator 要离开 Consumer Group。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;SyncGroup 请求：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;Group Leader Consumer 把分配方案告诉组内所有成员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;JoinGroup 请求：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;成员请求加入组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;DescribeGroup 请求：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Coordinator 在 Rebalance 的时候主要用到了前面4种请求。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;Consumer Group 状态机&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果 Rebalance 一旦发生，就会涉及到 Consumer Group 的状态流转，此时 Kafka 为我们设计了一套完整的状态机机制，来帮助 Broker Coordinator 完成整个重平衡流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解整个状态流转过程可以帮助我们深入理解 Consumer Group 的设计原理。5种状态，定义分别如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Empty 状态&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;表示当前组内无成员， 但是可能存在 Consumer Group 已提交的位移数据，且未过期，这种状态只能响应 JoinGroup 请求。。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Dead 状态&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;表示组内已经没有任何成员的状态，组内的元数据已经被 Broker Coordinator 移除，这种状态响应各种请求都是一个Response：UNKNOWN_MEMBER_ID。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;PreparingRebalance 状态&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;表示准备开始新的 Rebalance, 等待组内所有成员重新加入组内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;CompletingRebalance 状态&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;表示组内成员都已经加入成功，正在等待分配方案，旧版本中叫&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;AwaitingSync&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Stable 状态&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;表示 Rebalance 已经完成， 组内 Consumer 可以开始消费了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;5种状态流转图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5453703703703704&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcWO39W7Vpv8ianvNkUrlcS7xJG8TKz3onNiajQEszGgsSvQvlqvoSKuwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;04&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;Rebalance 流程分析&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上面5种状态可以看出，Rebalance 主要分为两个步骤：加入组&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;JoinGroup请求&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;和等待 Leader Consumer 分配方案&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;SyncGroup 请求&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section title=&quot;660，更新于2016-05-06 09:57&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section title=&quot;315，更新于2015-09-25 09:46&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;JoinGroup请求&lt;/section&gt;&lt;img data-fileid=&quot;100004025&quot; data-ratio=&quot;0.8333333333333334&quot; data-type=&quot;png&quot; data-w=&quot;24&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iabWEnNLIJBhGH7rvZ322E9kia1FsphdbhmP25BFRiaeumU5dNszPgzh1pXWbFq9zn1NEw0wFo1aWlkQ/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span&gt;组内所有成员向 Coordinator 发送 JoinGroup 请求，请求加入组，顺带会上报自己订阅的 Topic，这样 Coordinator 就能收集到所有成员的 JoinGroup 请求和订阅 Topic 信息，Coordinator 就会从这些成员中选择一个担任这个Consumer Group 的 Leader「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;一般情况下，第一个发送请求的 Consumer 会成为 Leader&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;这里说的 Leader 是指具体的某一个 Consumer，它的任务就是收集所有成员的订阅 Topic 信息，然后制定具体的消费分区分配方案。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;待选出 Leader 后，Coordinator 会把 Consumer Group 的订阅 Topic 信息封装进 JoinGroup 请求的 Response 中，然后发给 Leader ，然后由 Leader 统一做出分配方案后，进入到下一步&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5496828752642706&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlcTWo0oVONiaqIic8B5lqUpr8iaYnSxrxv3kGAcrQXff08ck2kT3BOicSXiag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;946&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section title=&quot;660，更新于2016-05-06 09:57&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section title=&quot;315，更新于2015-09-25 09:46&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;SyncGroup 请求&lt;/section&gt;&lt;img data-fileid=&quot;100004025&quot; data-ratio=&quot;0.8333333333333334&quot; data-type=&quot;png&quot; data-w=&quot;24&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iabWEnNLIJBhGH7rvZ322E9kia1FsphdbhmP25BFRiaeumU5dNszPgzh1pXWbFq9zn1NEw0wFo1aWlkQ/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;Leader 开始分配消费方案，&lt;strong&gt;&lt;span&gt;即哪个 Consumer 负责消费哪些 Topic 的哪些 Partition&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一旦完成分配，Leader 会将这个分配方案封装进 SyncGroup 请求中发给 Coordinator ，其他成员也会发 SyncGroup 请求，只是内容为空，待 Coordinator 接收到分配方案之后会把方案封装进 SyncGroup 的 Response 中发给组内各成员, 这样各自就知道应该消费哪些 Partition 了。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6267529665587918&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpoxy9PicA1zF2ufQsqdhsC5ibmHjEXib1vaSibicPUkrlAMxcwyYwvHE9uZA5oam8cSTKnTNySbFiccSic6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;927&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;05&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;Rebalance 场景分析&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚刚详细的分析了关于 Rebalance 的状态流转，接下来我们通过时序图来重点分析几个场景来加深对 Rebalance 的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;场景一：新成员(c1)加入组&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里新成员加入组是指组处于 Stable 稳定状态后，有新成员加入的情况。当协调者收到新的 JoinGroup 请求后，它会通过心跳机制通知组内现有的所有成员，强制开启新一轮的重平衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5305555555555556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpr9UWArJVFtscdkibLuyfxlc19bPylecR2q7ZAoVGpBEfPqaTfA0Uh8hFQ2DcRicdoSiazCf9LVTiaApQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;场景二：成员(c2)主动离组&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里主动离组是指消费者所在线程或进程调用 close() 方法主动通知协调者它要退出。当协调者收到 LeaveGroup 请求后，依然会以心跳机制通知其他成员，强制开启新一轮的重平衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5388888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazppXOMsQggia4DuSGgAMHrjN2wySLbEH4ibp41rT24AoBTrFHS2VTzpaksVrhSkdlDz8gAOEJiapKu1Dw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;场景三：成员(c2)超时被踢出组&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里超时被踢出组是指消费者实例出现故障或者处理逻辑耗时过长导致的离组。此时离组是被动的，协调者需要等待一段时间才能感知到，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;一般是由消费者端参数 session.timeout.ms 控制的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5203703703703704&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpoxy9PicA1zF2ufQsqdhsC5ibcr2QoTmW98eXJeUS6iaOgVC319FaaicPQml4bBMZehWFSmLUJOERMaLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景四：成员(c2)提交位移数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当重平衡开启时，协调者会要求组内成员必须在这段缓冲时间内快速地提交自己的位移信息，然后再开启正常的 JoinGroup/SyncGroup 请求发送。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5157407407407407&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpoxy9PicA1zF2ufQsqdhsC5ib2x627FLBHVoaP4Yjjsibvt0BBXtwNmb16AygRic7R3xsBg2t3ic7dwMlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;谈谈Kafka线上大量消息积压你是如何处理的？&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;消息大量积压这个问题，直接原因&lt;span&gt;一定是某个环节出现了性能问题，来不及消费消息，才会导致消息积压&lt;/span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;接着就比较坑爹了，此时假如 Kafka 集群的磁盘都快写满了，都没有被消费，这个时候怎么办？或者消息积压了⼏个⼩时，这个时候怎么办？生产环境挺常⻅的问题，⼀般不出问题，而⼀出就是⼤事故。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们先来分析下，在使用 Kafka 时如何来优化代码的性能，避免出现消息积压。如果你的线上 Kafka 系统出现了消息积压，该如何进行紧急处理，最大程度地避免消息积压对业务的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;优化性能来避免消息积压&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Kafka 性能的优化，主要体现在生产者和消费者这两部分业务逻辑中。而 Kafka 本身不需要多关注的主要原因是，对于绝大多数使用Kafka 的业务来说，Kafka 本身的处理能力要远大于业务系统的处理能力。Kafka 单个节点，消息收发的性能可以达到每秒钟处理几十万条消息的水平，还可以通过水平扩展 Broker 的实例数成倍地提升处理能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于业务系统处理的业务逻辑要复杂一些，单个节点每秒钟处理几百到几千次请求，已经非常不错了，所以我们应该更关注的是消息的收发两端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 发送端性能优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发送端即生产者业务代码都是先执行自己的业务逻辑，最后再发送消息。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;如果说性能上不去，需要你优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能。我们知道 Producer 发消息给 Broker 且收到消息并返回 ack 响应，&lt;/span&gt;&lt;span&gt;假设这一次过程的平均时延是 1ms，它包括了下面这些步骤的耗时：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）&lt;/span&gt;&lt;span&gt;发送端在发送网络请求之前的耗时&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）&lt;/span&gt;&lt;span&gt;发送消息和返回响应在网络传输中的耗时&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）&lt;/span&gt;&lt;span&gt;Broker 端处理消息的时延&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;假设此时你的发送端是单线程，每次只能发送 1 条消息，那么每秒只能发送 1000 条消息，这种情况下并不能发挥出 Kafka 的真实性能。此时无论是增加每次发送消息的批量大小，还是增加并发，都可以成倍地提升发送性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果当前发送端是在线服务的话，比较在意请求响应时延，此时可以采用并发方式来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果当前发送端是离线服务的话，更关注系统的吞吐量，发送数据一般都来自数据库，此时更适合批量读取，批量发送来提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-spm-anchor-id=&quot;a2c6h.12873639.0.i5.3ee93c41d5v2te&quot;&gt;&lt;strong&gt;&lt;span&gt;另外还需要关注下消息体是否过大&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，如果消息体过大，势必会增加 IO 的耗时，影响 Kafka 生产和消费的速度，也可能会造成消息积压。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 消费端性能优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在使用 Kafka 时，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要是消费速度一直比生产速度慢，时间长了系统就会出现问题，比如Kafka 的磁盘存储被写满无法提供服务，或者消息丢失，对于整个系统来说都是严重故障。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们在设计的时候，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消费端的性能优化除了优化业务逻辑外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。&lt;/span&gt;&lt;span&gt;需要注意的是，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区数量，确保 Consumer 的实例数和分区数量是相等的&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;消息积压后如何处理&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日常系统正常时候，没有积压或者只有少量积压很快就消费掉了，但某时刻，突然开始积压消息且持续上涨。这种情况下需要你在短时间内找到消息积压的原因，迅速解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导致消息积压突然增加，只有两种：发送变快了或者消费变慢了。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如&lt;span&gt;赶上大促或者抢购时，&lt;/span&gt;短时间内不太可能优化消费端的代码来提升消费性能，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;此时唯一的办法是通过扩容消费端的实例数来提升总体的消费能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;如果短时间内没有足够的服务器资源进行扩容，只能降级一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，保证重要业务服务正常。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如通过内部监控到消费变慢了，需要你检查消费实例，分析一下是什么原因导致消费变慢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、优先查看日志是否有大量的消费错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、此时如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在哪里&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;触发死锁或者卡在某些等待资源&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果我的文章对你有所帮助，还请帮忙&lt;/span&gt;&lt;strong&gt;点赞、在看、转发&lt;/strong&gt;&lt;span&gt;一下，非常感谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;坚持总结, 持续输出高质量文章&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;  关注我: 华仔聊技&lt;span data-raw-text=&quot;术&quot; data-textnode-index=&quot;537&quot; data-index=&quot;7642&quot;&gt;术&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3648148148148148&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83ZHamO5l2JTJzkDxSZLsmtzXSkYBxG2uK2pN7s3q3pyxlRBDLFwEwkA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;  &lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-id=&quot;Mzg3MTcxMDgxNA==&quot; data-pluginname=&quot;mpprofile&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyp4CYMexUiagvdYANIhY2ibiaibtqichibk92kiaMvHTJmavuepu4yZWC2OqwCVz834X916B5txFNYY7KgXw/0?wx_fmt=png&quot; data-nickname=&quot;华仔聊技术&quot; data-alias=&quot;&quot; data-signature=&quot;聊聊后端技术架构以及中间件源码&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;                        点个“赞”和“在看”鼓励一下嘛~&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpoxy9PicA1zF2ufQsqdhsC5ibcr2QoTmW98eXJeUS6iaOgVC319FaaicPQml4bBMZehWFSmLUJOERMaLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5203703703703704&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          

          
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ca93057701c077490ae66f61a3768ed6</guid>
<title>能ping通，TCP就一定能连通吗？</title>
<link>https://toutiao.io/k/qqiid6c</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;strong&gt;&lt;span&gt;点击关注公众号，一周多次&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;包邮送书&lt;/span&gt;&lt;/strong&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100064273&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iaajvl7fD4ZCicMcjhXMp1v6UibM134tIsO1j5yqHyNhh9arj090oAL7zGhRJRq6cFqFOlDZMleLl4pw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;64&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100064273&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iaajvl7fD4ZCicMcjhXMp1v6UibM134tIsO1j5yqHyNhh9arj090oAL7zGhRJRq6cFqFOlDZMleLl4pw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;64&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100064273&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iaajvl7fD4ZCicMcjhXMp1v6UibM134tIsO1j5yqHyNhh9arj090oAL7zGhRJRq6cFqFOlDZMleLl4pw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;64&quot;/&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card&quot; data-id=&quot;MzIzMjg5MTU1MA==&quot; data-pluginname=&quot;mpprofile&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/I0nV5DiabQiajWb0TDrpqbicibnkpDSDicWFe1TK805sQwu802AgvyQI879jE4dtaRebnKsDYXg3UUcKibWOCEcEHxMQ/0?wx_fmt=png&quot; data-nickname=&quot;程序员架构&quot; data-alias=&quot;chengxuyuanjg&quot; data-signature=&quot;一个有趣的专注用人话说技术、帮助程序员成长的架构公众号&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;来源：小白debug（ID：xiaobaidebug）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：小白&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;平时，我们想要知道，自己的机器到目的机器之间，&lt;/span&gt;&lt;strong&gt;网络通不通&lt;/strong&gt;&lt;span&gt;，一般会执行&lt;/span&gt;&lt;strong&gt;ping命令&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一般对于状况良好的网络来说，你能看到它对应的&lt;/span&gt;&lt;code&gt;&lt;span&gt;loss&lt;/span&gt;&lt;/code&gt;&lt;span&gt;丢包率为&lt;/span&gt;&lt;code&gt;&lt;span&gt;0%&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，也就是所谓的&lt;strong&gt;能ping通&lt;/strong&gt;。如果看到丢包率&lt;/span&gt;&lt;code&gt;&lt;span&gt;100%&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，也就是&lt;strong&gt;ping不通&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.37910447761194027&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkJr6IQsWrPGXeraUKESaDTic8HnyGJxcXXkQxwBMKkQhVXvZJYa24EDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1340&quot; title=&quot;ping正常&quot;/&gt;&lt;figcaption&gt;ping正常&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2837370242214533&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkLsGe5OeLd8Wsurd9E2Pntgr096iawkUIN7NhjqnPUOueic5yA6umA6ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1156&quot; title=&quot;ping不通&quot;/&gt;&lt;figcaption&gt;ping不通&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;那么问题来了，假设我能&lt;strong&gt;ping&lt;/strong&gt;通某台机器，那这时候如果我改用&lt;strong&gt;TCP协议&lt;/strong&gt;去发数据到目的机器，&lt;strong&gt;也一定能通吗？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者换个问法，&lt;strong&gt;ping和tcp协议走的网络路径是一样的吗？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时候第一反应就是&lt;strong&gt;不一定&lt;/strong&gt;，因为ping完之后中间链路里的&lt;strong&gt;某个路由器可能会挂了（断电了）&lt;/strong&gt;，再用TCP去连就会走别的路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也没错。但假设，&lt;strong&gt;中间链路没发生任何变化呢？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我先直接说答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;不一定，走的网络路径还是有可能是不同的。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天就来聊聊为什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我之前写过一篇&lt;/span&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg5NDY2MDk4Mw==&amp;amp;mid=2247486417&amp;amp;idx=1&amp;amp;sn=c648ca9f2d33f77d69ae3c615c62b77e&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;《断网了，还能ping通 127.0.0.1 吗？》&lt;/span&gt;&lt;/a&gt;&lt;span&gt;,里面提到过&lt;strong&gt;ping数据包和tcp数据包的区别&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0588235294117647&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkW7bTQtOcha2PLxibQYSPZRoGwh74DKXVPaBh8sguZTGYT0LgvA9iammg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2550&quot; title=&quot;ping和TCP发消息的区别&quot;/&gt;&lt;figcaption&gt;ping和TCP发消息的区别&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;我们知道网络是分层的，每一层都有对应协议。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6666666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkNr8Wibiafl5PBLX27VhkJiaHZvZCZAtOjQs5IqBia32AvX7CKS539w6L4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;4200&quot; title=&quot;五层网络协议对应的消息体变化分析&quot;/&gt;&lt;figcaption&gt;五层网络协议对应的消息体变化分析&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;而这网络层就像搭积木一样，上层协议都是基于下层协议搭出来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;不管是ping（用了ICMP协议）还是tcp本质上都是基于网络层IP协议的数据包，而到了物理层，都是二进制01串，都走网卡发出去了。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果网络环境没发生变化，目的地又一样，那按道理说他们走的网络路径应该是一样的，什么情况下会不同呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们就从&lt;strong&gt;路由&lt;/strong&gt;这个话题聊起吧。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;网络路径&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;在我们的想象中，当我们想在两台机器之间传输数据。本机和目的机器之间会建立一条连接，像&lt;strong&gt;一条管道&lt;/strong&gt;一样，数据从这头到那头。这条管道其实是我们为了方便理解而抽象出来的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，我们将数据包从本地网卡发出之后，会经过各种&lt;strong&gt;路由器（或者交换机）&lt;/strong&gt;，才能到达目的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些路由器数量众多，相互之间可以互连，连起来之后就像是一张大网，所以叫&lt;strong&gt;&quot;网络&quot;&lt;/strong&gt;可以说是非常的形象。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFk2zMjLK9h1mYtmfyeibIqvWic9oNiaUUfKTYzaWia2sSianlLugBIeQHM1nw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;4500&quot; title=&quot;路由器构成的网络&quot;/&gt;&lt;figcaption&gt;路由器构成的网络&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt;考虑到交换机有的功能，路由器基本上都支持，所以我们这边只讨论路由器。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;那么现在问题来了，&lt;strong&gt;路由器收到数据后，怎么知道应该走哪条路径，传给哪个路由器？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;路径由什么决定？&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;在上面的那么大一张网络中，随便一个路由器都有可能走任何一个路径，将数据发到另外一个路由器上，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但路由和路由之间距离，带宽啥的可能都不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;于是就很需要知道，&lt;strong&gt;两点之间走哪条路才是最优路径&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;于是问题就变成了这样一个&lt;strong&gt;图状结构&lt;/strong&gt;。每条边都带有&lt;strong&gt;成本或权重&lt;/strong&gt;，算这上面&lt;strong&gt;任意两点的最短距离&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFk9uu9EvGGvFaVVetf2xxaSfpOmAWr4B82ibp8aW23iclYTyAsiaWQTWKicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3000&quot; title=&quot;路由器和Dijkstra&quot;/&gt;&lt;figcaption&gt;路由器和Dijkstra&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;这时候想必大家回忆压不住要上来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这题我熟，这就是大学时候刷的&lt;strong&gt;Dijkstra算法&lt;/strong&gt;。菊花厂的OJ笔试题集里也经常出现，现在终于明白为什么他们家的笔试题里图类题目比别的大厂貌似要多一些了吧，因为菊花厂就是搞通信的，做路由器的老玩家了。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;路由表的生成&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;基于&lt;strong&gt;Dijkstra算法&lt;/strong&gt;，封装出了一个新的协议，&lt;strong&gt;OSPF协议&lt;/strong&gt;（&lt;strong&gt;O&lt;/strong&gt;pen &lt;strong&gt;S&lt;/strong&gt;hortest &lt;strong&gt;P&lt;/strong&gt;ath &lt;strong&gt;F&lt;/strong&gt;irst, 开放最短路径优先）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了OSPF，路由器就得到了网络图里自己到其他点之间的&lt;strong&gt;最短距离&lt;/strong&gt;，于是就知道了&lt;strong&gt;数据包要到某个点，该走哪条最优路径&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将这些信息汇成一张表，也就是我们常说的&lt;strong&gt;路由表&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;路由表里记录了到什么IP需要走什么端口，以及走这条路径的成本（&lt;/span&gt;&lt;code&gt;&lt;span&gt;metric&lt;/span&gt;&lt;/code&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以通过 &lt;/span&gt;&lt;code&gt;&lt;span&gt;route&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 命令查看到。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.264919941775837&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkXSCRGpiaRMtPEt45VFybiaA3K8icuBuQBXdYxygXq6WzGIyaLJdzJsu0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1374&quot; title=&quot;route表&quot;/&gt;&lt;figcaption&gt;route表&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;&lt;span&gt;路由表决定数据包路径&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;数据包在发送的过程中，会在&lt;strong&gt;网络层&lt;/strong&gt;加入&lt;strong&gt;目标地址IP&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;路由器会根据这个&lt;strong&gt;IP&lt;/strong&gt;跟&lt;strong&gt;路由表&lt;/strong&gt;去做匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后路由表，会告诉路由器，什么样的消息该转发到什么端口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6176470588235294&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkQP6WPyyWrCIsHNGDPl3ENibFXC8JTVTps3RB6ibrs9GQRCMfrVo390zA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;5100&quot; title=&quot;通过路由表转发数据&quot;/&gt;&lt;figcaption&gt;通过路由表转发数据&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;假设A要发消息到D。也就是&lt;/span&gt;&lt;code&gt;&lt;span&gt;192.168.0.105/24&lt;/span&gt;&lt;/code&gt;&lt;span&gt;要发消息到&lt;/span&gt;&lt;code&gt;&lt;span&gt;192.168.1.11/24&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么A会把消息经发到路由器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;路由器已知目的地IP&lt;/span&gt;&lt;code&gt;&lt;span&gt;192.168.1.11/24&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ，去跟&lt;strong&gt;路由表&lt;/strong&gt;做匹配，发现&lt;/span&gt;&lt;code&gt;&lt;span&gt;192.168.1.0/24&lt;/span&gt;&lt;/code&gt;&lt;span&gt;, 就在e2端口，那么就会把消息从e2端口发出，（可能还会经过交换机）最后把消息打到目的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，如果路由表里找不到，那就打到&lt;strong&gt;默认网关&lt;/strong&gt;吧，也就是从e1口发出，发到IP&lt;/span&gt;&lt;code&gt;&lt;span&gt;192.0.2.1&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;strong&gt;这个路由器的路由表不知道该去哪，说不定其他路由器知道&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;路由表的匹配规则&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;上面的例子里，是只匹配上了路由表里的&lt;strong&gt;一项&lt;/strong&gt;，所以只能是它了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，条条大路通罗马。实际上能到目的地的路径肯定有很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如果路由表里有很多项都被匹配上了，会怎么选？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果多个路由项都能到目的地，那就优先选&lt;strong&gt;匹配长度更长&lt;/strong&gt;的那个。比如，还是目的地&lt;/span&gt;&lt;code&gt;&lt;span&gt;192.168.1.11&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，发现路由表里的&lt;strong&gt;192.168.1&lt;/strong&gt;.0/&lt;strong&gt;24&lt;/strong&gt; 和 &lt;strong&gt;192.168&lt;/strong&gt;.0.0/&lt;strong&gt;16&lt;/strong&gt;都能匹配上，但明显&lt;strong&gt;前者匹配长度更长&lt;/strong&gt;，所以最后会走 &lt;strong&gt;192.168.1&lt;/strong&gt;.0/&lt;strong&gt;24&lt;/strong&gt;对应的转发端口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;但如果两个表项的匹配长度都一样呢？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那就会看生成这个路由表项的&lt;strong&gt;协议&lt;/strong&gt;是啥，选优先级高的，优先级越高也就是所谓的&lt;strong&gt;管理距离&lt;/strong&gt;（&lt;strong&gt;AD&lt;/strong&gt;，&lt;strong&gt;A&lt;/strong&gt;dministrative&lt;strong&gt;D&lt;/strong&gt;istance）越小。比如说优先选&lt;strong&gt;手动配&lt;/strong&gt;的静态（&lt;strong&gt;static&lt;/strong&gt;）路由，次优选&lt;strong&gt;OSPF&lt;/strong&gt;动态学习过来的表项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果还是相同，就看&lt;strong&gt;度量值metrics&lt;/strong&gt;，其实也就是&lt;strong&gt;路径成本cost&lt;/strong&gt;，成本越小，越容易被选中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;路由器能选的路线有很多，但按道理，最优的只有&quot;一条&quot;，所以到这里为止，我们都可以认为，对于同一个目的地，ping和TCP走的路径是相同的。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如果连路径成本都一样呢？&lt;/strong&gt;也就是说有多条最优路径呢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;那就都用&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也就是所谓的&lt;strong&gt;等价多路径，ECMP&lt;/strong&gt;（&lt;strong&gt;E&lt;/strong&gt;qual &lt;strong&gt;C&lt;/strong&gt;ost &lt;strong&gt;M&lt;/strong&gt;ulti&lt;strong&gt;P&lt;/strong&gt;ath）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以通过&lt;/span&gt;&lt;code&gt;&lt;span&gt;traceroute&lt;/span&gt;&lt;/code&gt;&lt;span&gt;看下链路是否存在等价多路径的情况。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.30818181818181817&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFk6PzyshMT7Iiajcfib0y5HZBmpyCFhehGwrgw1Xgfevr8BD2vuNj3kelg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2200&quot; title=&quot;image-20220805122619206&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;可以看到，中间某几行，有&lt;strong&gt;好几个IP&lt;/strong&gt;，也就是说这一跳里同时可以选好几个目的机器，说明这段路径&lt;strong&gt;支持ECMP&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;ECMP有什么用&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;利用等价多路径，我们&lt;strong&gt;可以增加链路带宽&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkHZicWf61IoTIyFOibVDBiaPysIY6O8Av2ibzL5LTDJcxKn2bFQ6icZibdDGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;4500&quot; title=&quot;没有ECMP时只能选择某一条路径&quot;/&gt;&lt;figcaption&gt;没有ECMP时只能选择某一条路径&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;从A点到B点，如果这两条路径成本不同，带宽都是&lt;/span&gt;&lt;code&gt;&lt;span&gt;1千兆&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。那数据包肯定就选成本低的那条路了，如果这条路出故障了，就走下面那条路。但不管怎么样，&lt;strong&gt;同一时间，只用到了一条路径&lt;/strong&gt;。另外一条闲置就有些浪费了，有没有办法可以利用起来呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有，将它们两条路径的成本设置成一样，那它们就成了等价路由，然后中间的路由器开启&lt;strong&gt;ECMP&lt;/strong&gt;特性，就可以同时利用这两条链路了。带宽就从原来的&lt;/span&gt;&lt;code&gt;&lt;span&gt;1千兆&lt;/span&gt;&lt;/code&gt;&lt;span&gt;变成了&lt;/span&gt;&lt;code&gt;&lt;span&gt;2千兆&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。数据就可以在两条路径中随意选择了。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkVDgU7TUuVlcdrbrLQ1icbMOBEJmf7xItOX9MzSORV3HJu3X3oFwdj8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;4500&quot; title=&quot;利用ECMP可以同时使用两条链路&quot;/&gt;&lt;figcaption&gt;利用ECMP可以同时使用两条链路&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;但这也带来了另外一个问题。&lt;strong&gt;加剧了数据包乱序&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原来我只使用一条网络路径，数据依次发出，如无意外，也是依次到达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在两个数据包走两条路径，先发的数据包可能后到。这就乱序了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么问题又又来了。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;乱序会有什么问题？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;对于我们最最最常使用的TCP协议来说，它是个可靠性网络的协议，这里提到的&lt;strong&gt;可靠&lt;/strong&gt;，不仅是保证数据要能送到目的地，还要保证&lt;strong&gt;数据顺序&lt;/strong&gt;要跟原来发送端的一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现也很简单，&lt;strong&gt;TCP为每个数据包（segment）做上编号&lt;/strong&gt;。数据到了接收端后，根据&lt;strong&gt;数据包编号&lt;/strong&gt;发现是&lt;strong&gt;乱序数据包&lt;/strong&gt;，就会扔到&lt;strong&gt;乱序队列&lt;/strong&gt;中对数据包进行排序。如果前面的数据包还没到，哪怕后面的数据包先到了，也得在乱序队列中一直等，到齐后才能被上层拿到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，发送端发出三个数据包，&lt;/span&gt;&lt;code&gt;&lt;span&gt;编号1,2,3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，假设在&lt;strong&gt;传输层&lt;/strong&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;2和3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;先到了，&lt;/span&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;&lt;/code&gt;&lt;span&gt;还没到。那此时&lt;strong&gt;应用层&lt;/strong&gt;是没办法拿到&lt;/span&gt;&lt;code&gt;&lt;span&gt;2和3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的数据包的，必须得等&lt;/span&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;&lt;/code&gt;&lt;span&gt;来了之后，&lt;strong&gt;应用层才能一次性拿到这三个包&lt;/strong&gt;。因为这三个包原来可能表示的是一个完整的消息，少了1, 那么&lt;strong&gt;消息就不完整&lt;/strong&gt;，应用层拿到了也毫无意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像这种，由于&lt;strong&gt;前面的数据丢失&lt;/strong&gt;导致&lt;strong&gt;后面的数据没办法及时给到应用层&lt;/strong&gt;的现象，就是我们常说的&lt;strong&gt;TCP队头阻塞&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkPQjq4kZGqasu6YDn4gXdvaonteo06DS9pavednyW9prSxax1bKib6qw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;4500&quot; title=&quot;乱序队列等待数据包的到来&quot;/&gt;&lt;figcaption&gt;乱序队列等待数据包的到来&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;乱序发生时&lt;/span&gt;&lt;code&gt;&lt;span&gt;2和3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;需要待在乱序队列中，而&lt;strong&gt;乱序队列其实用的也是接收缓冲区的内存&lt;/strong&gt;，而&lt;strong&gt;接收缓冲区是有大小限制的&lt;/strong&gt;。通过下面的命令可以看到接收缓冲区的大小。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 查看接收缓冲区&lt;/span&gt;&lt;br/&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; sysctl net.ipv4.tcp_rmem&lt;/span&gt;&lt;br/&gt;net.ipv4.tcp_rmem = 4096(min)    87380(default)  6291456(max)&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 缓冲区会在min和max之间动态调整&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;乱序的情况越多，接收缓冲区的内存就被占用的越多，对应的&lt;strong&gt;接收窗口&lt;/strong&gt;就会变小，那正常能收的数据就变少了，&lt;strong&gt;网络吞吐就变差&lt;/strong&gt;了，也就是性能变差了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们需要尽量保证所有&lt;strong&gt;同一个TCP连接下的所有TCP包都走相同路径，这样才能最大程度避免丢包&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;ECMP的路径选择策略&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;当初开启ECMP就是为了提升性能，现在反而加重了乱序，降低了TCP传输性能。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这怎么能忍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这个问题，我们需要有一个合理的路径选择策略。为了避免同一个连接里的数据包乱序，我们需要保证同一个连接里的数据包，都走同样的路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这好办。我们可以通过连接的&lt;strong&gt;五元组&lt;/strong&gt;（发送方的&lt;strong&gt;IP&lt;/strong&gt;和&lt;strong&gt;端口&lt;/strong&gt;，接收方的&lt;strong&gt;IP&lt;/strong&gt;和&lt;strong&gt;端口&lt;/strong&gt;，以及通信&lt;strong&gt;协议&lt;/strong&gt;）信息定位到唯一一条连接。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4166666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFk212iaXYEXhHRc7k9UKZibue6WbkWEb5wCEGWU5dxH1EKicicxYHLuHibBKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1800&quot; title=&quot;五元组&quot;/&gt;&lt;figcaption&gt;五元组&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;然后对五元组信息生成哈希键，让同一个哈希键的数据走同一条路径，问题就完美解决了。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3142857142857143&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkGD4BibKHGhSaEU13IYhw6rs9D2PpqNoHcfWWdSE4DndmEmJJHzpwxMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2100&quot; title=&quot;五元组映射成hash键&quot;/&gt;&lt;figcaption&gt;五元组映射成hash键&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.34782608695652173&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkWPpSXI1jg7mTMVKVk73oSZhKbV7D46F9zhh7yL25KOIA6OlxHlY6ag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3450&quot; title=&quot;根据五元组选择ECMP路径&quot;/&gt;&lt;figcaption&gt;根据五元组选择ECMP路径&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;TCP和Ping走的网络路径一样吗&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;现在我们回到文章开头的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于同样的发送端和接收端，&lt;strong&gt;TCP和Ping走的网络路径一样吗？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不一定一样，因为&lt;strong&gt;五元组&lt;/strong&gt;里的信息里有一项是&lt;strong&gt;通信协议&lt;/strong&gt;。ping用的是&lt;strong&gt;ICMP协议&lt;/strong&gt;，跟&lt;strong&gt;TCP协议&lt;/strong&gt;不同，并且ping不需要用到端口，所以五元组不同，生成的&lt;strong&gt;哈希键不同&lt;/strong&gt;，通过ECMP选择到的路径也可能不同。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFklSAwDam5HZZoBeemhHwNqicg0ugEUZFVna477vujTf1dtuQX3EH0p3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2400&quot; title=&quot;TCP和ping的五元组差异&quot;/&gt;&lt;figcaption&gt;TCP和ping的五元组差异&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;同样都用TCP协议，数据包走的网络路径一样吗&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;还是同样的发送端和接收端，同样是TCP协议，不同TCP连接走的网络路径是一样的吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟上面的问题一样，其实&lt;strong&gt;还是五元组的问题&lt;/strong&gt;，同样都是TCP协议，对于同样的发送端和接收端，他们的IP和接收端的端口肯定是一样的，但&lt;strong&gt;发送方的端口是可以随时变化&lt;/strong&gt;的，因此通过ECMP走的路径也可能不同。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkAH1I0qt3rajhofv5fcH3fCa9AbSmMM9fYqQTdgu4dwAybfj5UdqiaKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2400&quot; title=&quot;不同TCP连接的五元组差异&quot;/&gt;&lt;figcaption&gt;不同TCP连接的五元组差异&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;但问题又来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;我知道这个有什么用呢？我做业务开发，又没有设置网络路由的权限。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;利用这个知识点排查问题&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;对于业务开发，这绝对不是个没用的知识点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果某天，你发现，你能ping通目的机器，但用TCP去连，却&lt;strong&gt;偶尔连不上&lt;/strong&gt;目的机器。而且两端机器都挺空闲，没什么性能上的瓶颈。实在&lt;strong&gt;走投无路&lt;/strong&gt;了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你就可以想想，会不会是网络中用到了&lt;/span&gt;&lt;code&gt;&lt;span&gt;ECMP&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，其中一条链路有问题导致的。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.391304347826087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkcPmDGiaZseVYK59icYy05WdjZJnFhl6xYj1jGXBNALzdAJ4W6wUTSCLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3450&quot; title=&quot;ping能成功但部分TCP连接失败&quot;/&gt;&lt;figcaption&gt;ping能成功但部分TCP连接失败&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;排查方法也很简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你是知道本机的IP以及目的机器的IP和端口号的，也知道自己用的是TCP连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只要你在&lt;strong&gt;报错的时候打印下错误信息，你就知道了发送端的端口号了。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样&lt;strong&gt;五元组&lt;/strong&gt;是啥你就知道了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步就是&lt;strong&gt;指定发送端的端口号重新发起TCP请求，同样的五元组，走同样的路径，按理说如果链路有问题，就肯定会复现。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果不想改自己的代码，你可以用&lt;strong&gt;nc命令指定客户端端口&lt;/strong&gt;看下能不能正常建立TCP连接。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;nc -p 6666 baidu.com 80&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;-p 6666&lt;/span&gt;&lt;/code&gt;&lt;span&gt;是指定发出请求的客户端端口是&lt;/span&gt;&lt;code&gt;&lt;span&gt;6666&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，后面跟着的是&lt;strong&gt;连接的域名&lt;/strong&gt;和&lt;strong&gt;80端口&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.13706954760297096&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AnAgeMhDIianA4RVS9XdKXZT5fmcogTFkDSvVCZe4OoUEsiausLeTnIciamJib7c0iaYd2AXjP0WQzokb6CrqttsCNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2962&quot; title=&quot;通过nc成功建立tcp连接&quot;/&gt;&lt;figcaption&gt;通过nc成功建立tcp连接&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;假设用了&lt;/span&gt;&lt;code&gt;&lt;span&gt;6666端口&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的五元组去连接&lt;strong&gt;总是失败&lt;/strong&gt;，改用&lt;/span&gt;&lt;code&gt;&lt;span&gt;6667或其他端口&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;strong&gt;却能成功&lt;/strong&gt;，你可以带着这个信息去找找负责网络的同事。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h3&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;路由器可以通过OSPF协议生成路由表，利用数据包里的IP地址去跟路由表做匹配，选择最优路径后进行转发。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当路由表一个都匹配不上时会走默认网关。当匹配上多个的时候，会先看&lt;strong&gt;匹配长度&lt;/strong&gt;，如果一样就看&lt;strong&gt;管理距离&lt;/strong&gt;，还一样就看&lt;strong&gt;路径成本&lt;/strong&gt;。如果连路径成本都一样，那&lt;strong&gt;等价路径&lt;/strong&gt;。如果路由开启了ECMP，那就可以同时利用这几条路径做传输。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ECMP可以提高链路带宽，同时利用五元组做哈希键进行路径选择，保证了同一条连接的数据包走同一条路径，减少了乱序的情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以通过traceroute命令查看到链路上是否有用到ECMP的情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;开启了ECMP的网络链路中，TCP和ping命令可能走的路径不同，甚至同样是TCP，不同连接之间，走的路径也不同，因此出现了连接时好时坏的问题，实在是走投无路了，可以考虑下是不是跟ECMP有关。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当然，&lt;strong&gt;遇到问题多怀疑自己，要相信绝大部分时候真的跟ECMP无关&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;《网络排查案例课》 ——极客时间&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;·················END·················&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;section data-class=&quot;_mbEditor&quot; data-id=&quot;107518&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;pre/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/div&gt;

          

          
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c3629956bea124354e6f03bcb39519b0</guid>
<title>接口流量突增，如何做好性能优化？</title>
<link>https://toutiao.io/k/5x6jtd4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5520504731861199&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/AVWicyZuuClGXNu0B6dUfEBDOqhrZHBZgCb7ic4D8kRic77Qiaz2rOABiaAxiahFvA0Nf1ywGcp3nC3GvV0TjVyHaGmA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;951&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;对于提供接口服务的应用来说，很多都是用 SpringBoot 默认的 Servlet 容器 Tomcat。&lt;/span&gt;&lt;span&gt;在一开始上线的时候，由于大多数流量较小，我们也并不会为 Tomcat 做专门的参数调整。&lt;/span&gt;&lt;span&gt;但随着流量越来越大，应用的各项性能指标越来越差，此时我们大多数都会选择扩容。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了扩容之外，我们还可以选择对 Tomcat 进行性能调优，从而在不增加成本的情况下提升性能。如果面试官问你，流量突增你们一般怎么做，你只会答扩容可就太差劲了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天树哥就跟大家简单分享下，如何对 Tomcat 进行简单地性能调优，从而提升应用的性能！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9526362823949955&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AVWicyZuuClGXNu0B6dUfEBDOqhrZHBZgSZVMSN0ibdmOrW95eJHSm5aic88cMaz8ibpGSvG1lIReyic8bOsto1s7zA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2238&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;组件架构&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要对 Tomcat 进行性能调优，我们需要先了解其组件架构。Tomcat 的组件架构如下图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7048808172531215&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AVWicyZuuClGXNu0B6dUfEBDOqhrZHBZgVZqdxCIviaLodPQHw1VM5fCzGvH9giafMusrK8oSDpfUUO9kDS2oTiatA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;881&quot;/&gt;&lt;figcaption&gt;Tomcat 组件结构示意图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从上图可以看到，Tomcat 将其业务抽象成了 Server、Service、Connector、Container 等等组件，每个组件都有不同的作用。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Server 组件。&lt;/strong&gt; Server 组件是 Tomcat 最外层的组件，该组件是 Tomcat 实例本身的抽象，代表着 Tomcat 自身。一个 Server 组件可以有一个或多个 Service 组件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Service 组件。&lt;/strong&gt; Service 组件是 Tomcat 中一组提供服务、处理请求的组件，一个 Service 组件可以有多个 Connector 连接器和一个 Container，有多个 Connector 表示其可以同时使用多种协议接收用户请求。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Connector 组件。&lt;/strong&gt; Connector 负责处理客户端的连接，它提供各种服务协议支持，包括：BIO、NIO、AIO 等等。其存在的价值在于，为 Container 容器屏蔽了多协议的复杂性，统一了 Container 容器的处理标准。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Container 组件。&lt;/strong&gt; Container 组件是负责具体业务逻辑处理的容器，当 Connector 组件与客户端建立连接后，便会将请求转发给 Container 组件的 Engine 组件处理。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，Tomcat 的核心组件基本上讲完了。实际上 Container 组件里还细分了很多组件，其实对业务的抽象，感兴趣的可以继续看看。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Engine 组件。&lt;/strong&gt; Engine 组件表示可运行的 Servlet 实例，包含了 Servlet 容器的核心功能，其可以有一个或多个虚拟主机（Host）。其主要功能是将请求委托给合适的虚拟主机处理，即根据 URL 路径的配置匹配到合适的虚拟主机处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Host 组件。&lt;/strong&gt; Host 组件负责运行多个应用，其负责安装这些应用，其主要作用是解析 web.xml 文件，并将其匹配到对应的 Context 组件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Context 组件。&lt;/strong&gt; Context 组件代表具体的 Web 应用程序本身，其最重要的功能就是管理里面的 Servlet 实例。一个 Context 可以有一个或者多个 Servlet 实例。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Wrapper 组件。&lt;/strong&gt; 一个 Wrapper 组件代表一个 Servlet，它负责管理一个 Servlet，包括 Servlet 的装载、初始化、执行以及资源回收。Wrapper 是最底层的容器。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，Host 是虚拟主机的抽象，Context 是应用程序的抽象，Wrapper 是 Servlet 的抽象，而 Engine 则是处理层的抽象。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;核心参数&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在了解核心参数之前，我们我们需要大致了解一下 Tomcat 对于请求的处理流程。Tomcat 对请求的处理流程如下所示：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;首先，客户端向 Tomcat 服务器发起请求，Connector 组件监听到请求，于是与客户端建立起连接。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;接着，Connector 将请求封装后转发给 Engine 组件处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;最后，Engine 组件处理完之后将结果返回给 Connector，Connector 组件再将结果返回给客户端。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上述过程可以用如下示意图来表示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6785304247990815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AVWicyZuuClGXNu0B6dUfEBDOqhrZHBZgZ2ia1IjiaaO7g7UayibvWvySVumwCSAq6atsqoYkeDzAYcmXRVFjKxlicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;871&quot;/&gt;&lt;figcaption&gt;Tomcat 核心参数示意图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上面的示意图中有三个非常关键的核心参数，这几个关键的参数也是性能调优的关键，它们分别是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;acceptCount&lt;/strong&gt;：当 Container 线程池达到最大数量且没有空闲线程，同时 Connector 队列达到最大数量时，操作系统最多能接受的连接数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;maxConnections&lt;/strong&gt;：当 Container 线程池达到最大数量且没有空闲线程时，Connector 的队列能接收的最大线程数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;maxThreads&lt;/strong&gt;：Container 线程池的处理线程的最大数量。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从上面三个参数的含义我们可以知道如下几点结论：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;客户端并不是直接与 Tomcat 的 Connector 组件建立联系的，而是先与操作系统建立，然后再移交给 Connector 的。这点很重要，不然你就无法理解 acceptCount 这个参数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不仅仅 Connector 组件中有队列，操作系统中也有队列来临时存储与客户端的连接，这也是很关键的点。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我们所说的线程池，指的是 Container 这个容器里的线程池。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;明白这三个核心参数的含义是非常重要的，不然没有办法进行后续的性能调优工作。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;maxThreads&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们知道 maxThreads 指的是请求处理线程的最大数量，在 Tomcat7 和 Tomcat8 中都是默认 200 个。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于这个参数的设置，需要根据任务的执行内容去调整，一般来说计算公式为：最大线程数 = &lt;code&gt;((IO时间 + CPU时间)/CPU时间) * CPU 核数&lt;/code&gt;。这个公式的思路其实很简单，就是最大化利用 CPU 的资源。一个任务的耗时分为 IO 耗时和 CPU 耗时，基本上 IO 耗时是最多的，这时候 CPU 是没事干的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此如果可以让 CPU 在任务等待 IO 的时候处理其他任务，那么 CPU 利用率不就上来了么。&lt;strong&gt;一般来说，由于 IO 耗时远大于 CPU 耗时，因此根据公式计算出来的 maxThreads 数都会远大于 CPU 核数，这是很正常的。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要注意的是，这个数值也不是越高越好。因为一旦线程数太多了，CPU 需要进行上下文切换，这就消耗了一部分 CPU 资源。因此最好的办法是用上述公式去计算一个基准值，随后再进行压力测试，去调整到一个合理的值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说，如果调高了 maxThreads 的值，但是吞吐量没有提升或者下降的话，那么表明可能到达了了瓶颈了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;maxConnections&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;maxConnections 指的是当线程池的线程达到最大值，并且都在忙的时候，Connector 中的队列最多能容纳多少个连接。一般来说，我们都要设置一个合理的数值，不能让其无限制堆积。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为 Tomcat 的处理能力肯定是有限的，到达一定程度肯定就处理不过来了，因此你堆积太多了也没啥用，反而会造成内存堆积，最终导致内存溢出 OOM 的发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;一般来说，一个经验值是可以设置成为 maxThreads 同样的大小。&lt;/strong&gt; 我想这样也是比较合理的，因为在队列中的连接最多只需要等待线程处理一个任务的时间即可，不会等待太久，响应时间也不会太长。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你想缩短响应时间，那么可以将 maxConnections 调低于 maxThreads 一些，这样可以降低一些响应时间。但要注意的是，如果降得太低的话，可能就会严重降低性能，降低吞吐量。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;acceptCount&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;acceptCount 指的是当 Container 线程池达到最大数量且没有空闲线程，同时 Connector 队列达到最大数量时，操作系统最多能接受的连接数。&lt;/strong&gt; 当&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;队列中的个数达到最大值后，进来的请求一律被拒绝，默认值是 100。这可以理解成是操作系统的一种自我保护机制吧，堆积太多无法处理，那就直接拒绝掉，保护自身资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;这个参数的调优资料比较少，但根据其含义，这个值不建议比 maxConnections 大。&lt;/strong&gt; 因为在这个队列中的连接，是需要等待的。如果数值太大，就说明会有很多连接没有被处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;连接越多，那么其等待的时间就越长，其响应时间就越慢。如果你想响应时间短一些，或许应该调低一下这个值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有同学会疑惑，为啥有了 maxConnections 了还要有 acceptCount 呢？这不是重复了么？其实在 BIO 的时代，这两个数值基本都是相同的。我猜是因为后面出现了 NIO、AIO 等技术，操作系统可以接受更多的客户端连接了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是就可以先让操作系统先建立连接缓存着，随后 Connnector 直接从操作系统处获取连接即可，这样就不需要等待操作系统进行耗时的 TCP 连接了，从而提高了效率。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了上面这三个参数之外，还有几个非核心参数，但我觉得还是有些作用的。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;connectionTimeout 参数，&lt;/strong&gt; 表示建立连接后的等待超时时间，如果超过这个时间，那么就会直接返回超时。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;minSpareThreads 参数，&lt;/strong&gt; 表示最小存活线程数，也就是如果没有请求了，那么最低要保持几个线程存活。这个参数与是否有突发流程相关联，在有突发流量的情况下，如果这个数值太低，那么就会导致瞬时的响应时间比较长。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天我们分享了 Tomcat 的核心组件，接着讲解了 Tomcat 处理请求过程时的 3 个核心参数及其调优经验。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于 maxThreads 参数而言，如果按照公式计算的话，我们需要获取 IO 时间和 CPU 时间，但实际上这两个值并不是很好获取。所以一般情况下，我们可以通过压测的方式来获得一个比较合适的 maxThreads。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于 maxConnections 参数而言，可以设置一个与 maxThreads 相同的值，再根据具体情况进行调整。如果想降低响应时间，那么可以稍微调低一些，否则可以调高一些。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于 acceptCount 参数而言，其调优逻辑与 maxConnections 类似，可以设置与 maxConnections 相似，再根据对相应时间的要求，做一个微调。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;好了，这就是今天的分享了。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;如果你喜欢这篇文章，请帮忙点赞转发支持我，感谢～&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;喜欢读书的你，如果觉得没人一起讨论，可以进！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;喜欢思考的你，如果觉得没人一起碰撞，可以进！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;喜欢分享的你，如果觉得没人一起欣赏，可以进！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一起读书、一起分享、一起进步、一起坚持&lt;/span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Zg93iapYic55Eg0NfaaEknPvwEtXxUB3TSUZDcWnygXd2HoibIuWZdlPk8ScdZsHuqDxtBHjCz1HIqgfyr6LGYscg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9d48858acb4d32c8241e75ebfd269437</guid>
<title>Springboot 是这样提高创建 docker 容器的效率的</title>
<link>https://toutiao.io/k/2pqfntz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;前言&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;小伙伴们好呀，今天来和大家聊聊这个  &lt;strong&gt;Springboot 在为创建高效容器方面中做的一个改动&lt;/strong&gt; 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，写这篇文章也不是因为实际项目真的需要我去研究这东西，而是我在上篇文章&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg2MjUzODc5Mw==&amp;amp;mid=2247490829&amp;amp;idx=1&amp;amp;sn=61646edeec04bd7ac7302d3ade9a80ee&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;《为什么SpringBoot可以直接运行 jar 包？》&lt;/a&gt; 中留了坑🕳 ，还有错误得纠正🐖 (原文也稍微改了下，但是只能改20字🙃)&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里应该改为&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;用 &lt;strong&gt;jarmode&lt;/strong&gt; 的 &lt;strong&gt;extract&lt;/strong&gt; 参数会自动将 &lt;strong&gt;jar&lt;/strong&gt; 包中的文件按 &lt;strong&gt;layers.idx&lt;/strong&gt; 中的分层提取出来。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6509298998569385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJN7uTQvNn4oz7p1p4nVG04Yq3DYVE8qAroJ4SPjRUBB7TuZTL1Z9XSAQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;699&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;改进原因&lt;span/&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;There’s always a certain amount of overhead when running a fat jar without unpacking it, and in a containerized environment this can be noticeable.&lt;/p&gt;&lt;p&gt;The other issue is that putting your application’s code and all its dependencies in one layer in the Docker image is sub-optimal.&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面这两句摘自 Springboot2.4.13 官方文档，但是这个改动是 2.3 就有了的（看了下 2.3 的，也还是这几句话🐷）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://docs.spring.io/spring-boot/docs/2.4.13/reference/html/spring-boot-features.html#boot-features-container-images&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大意就是说，&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在容器中，如果没有解压就直接运行一个 jar 包，它带来的开销是明显的&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;将 应用代码和包依赖都混在同一层，也是可以被优化的地方。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;w(ﾟДﾟ)w ，感觉说的很有道理 哈哈哈&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4836223506743738&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNwxy7UXurXcSkCoR3wlWEBgbC0OJvx6DYeibJPbS6KSGf5C8eib4Pia8aQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;519&quot;/&gt;&lt;figcaption&gt;默默三连认同&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是这里有个疑问，那之前 2.3 之前是怎么解决这个问题的呢？还是说现在才解决的呢？🤔&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;求证&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;怀着严谨求证的态度，我打开了 &lt;strong&gt;Springboot2.2.9&lt;/strong&gt; 的版本 👇&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://docs.spring.io/spring-boot/docs/2.2.9.RELEASE/reference/htmlsingle/#containers-deployment&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到这里列举了不高效的写法，以及推荐写法&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5614934114202049&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNXe3bAO502A3n3Ng9c8lPLu4M1gfCjkUZJd1tNUgc7aU2hhKBGykU6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1366&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我将 &lt;strong&gt;Springboot2.2.9&lt;/strong&gt; 版本中 &lt;strong&gt;创建高效容器&lt;/strong&gt; 的 Dockerfile 抄下来&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; openjdk:&lt;span&gt;8&lt;/span&gt;-jdk-alpine AS builder&lt;br/&gt;&lt;span&gt;WORKDIR&lt;/span&gt;&lt;span&gt; target/dependency&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARG&lt;/span&gt; APPJAR=target/*.jar&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; &lt;span&gt;${APPJAR}&lt;/span&gt; app.jar&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; jar -xf ./app.jar&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; openjdk:&lt;span&gt;8&lt;/span&gt;-jre-alpine&lt;br/&gt;&lt;span&gt;VOLUME&lt;/span&gt;&lt;span&gt; /tmp&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARG&lt;/span&gt; DEPENDENCY=target/dependency&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder &lt;span&gt;${DEPENDENCY}&lt;/span&gt;/BOOT-INF/lib /app/lib&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder &lt;span&gt;${DEPENDENCY}&lt;/span&gt;/META-INF /app/META-INF&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder &lt;span&gt;${DEPENDENCY}&lt;/span&gt;/BOOT-INF/classes /app&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ENTRYPOINT&lt;/span&gt;&lt;span&gt; [&lt;span&gt;&quot;java&quot;&lt;/span&gt;,&lt;span&gt;&quot;-cp&quot;&lt;/span&gt;,&lt;span&gt;&quot;app:app/lib/*&quot;&lt;/span&gt;,&lt;span&gt;&quot;com.example.MyApplication&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;发现在 &lt;strong&gt;Springboot2.2.9&lt;/strong&gt; ，是通过解压 jar 包，并 copy  &lt;strong&gt;/BOOT-INF/classes&lt;/strong&gt; ， &lt;strong&gt;/BOOT-INF/lib&lt;/strong&gt; 以及 &lt;strong&gt;/META-INF&lt;/strong&gt; 这三个文件夹来创建高效容器的 🐖 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再次回忆下这几个文件夹 👇&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5430932703659976&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNr1saozFEwEVcRUFEEHhSiaebjmwEKQfY4SEhoSic4QGmcWeGJicYRLenQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;847&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47613636363636364&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJN4HLX0Ty7Q0hFD2nGShGXe2Fox4OUQ9J3HTJ3MaOebsJ2ibSbOOGaJ8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5060773480662983&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNDjFK8jfXsMDxzT7aatCk2tcYPD1Erwh03LkIm9Svia7RSl2qQ4x5x3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;905&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，根据我们上文的结论，可以知道这里拷贝这个 &lt;strong&gt;META-INF&lt;/strong&gt; 文件夹也没啥意义。毕竟最后已经指定 Main Class 去运行了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我也去掉并做了个简单验证，依然部署成功，并且可以正常访问（当然，官方那样做可能也有其他我没考虑到的因素，就不多赘述啦🐖）&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45297805642633227&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNWFrdwWZ3FSzSM98q34tbqG65bYRAg0VYt0jdhiaSVMm1Bk8FickNUnQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1276&quot;/&gt;&lt;figcaption&gt;验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接着，我们来看看 &lt;strong&gt;Springboot2.4.13&lt;/strong&gt; 版本 的 👇&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://docs.spring.io/spring-boot/docs/2.4.13/reference/html/spring-boot-features.html#boot-features-container-images&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; adoptopenjdk:&lt;span&gt;11&lt;/span&gt;-jre-hotspot as builder&lt;br/&gt;&lt;span&gt;WORKDIR&lt;/span&gt;&lt;span&gt; application&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARG&lt;/span&gt; JAR_FILE=target/*.jar&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; &lt;span&gt;${JAR_FILE}&lt;/span&gt; application.jar&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; java -Djarmode=layertools -jar application.jar extract&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; adoptopenjdk:&lt;span&gt;11&lt;/span&gt;-jre-hotspot&lt;br/&gt;&lt;span&gt;WORKDIR&lt;/span&gt;&lt;span&gt; application&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder application/dependencies/ ./&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder application/spring-boot-loader/ ./&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder application/snapshot-dependencies/ ./&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder application/application/ ./&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ENTRYPOINT&lt;/span&gt;&lt;span&gt; [&lt;span&gt;&quot;java&quot;&lt;/span&gt;, &lt;span&gt;&quot;org.springframework.boot.loader.JarLauncher&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里就是我们上文中截取的代码了，当时也有强调说这个东西的作用 👇&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.947945205479452&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNkDL2aicMRicKFaXlPkmeh1rcx0eLu1qrtMVRdD1fHaVvkSMb00ZTic60A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;730&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以再次回顾下这个官方的这段话，再次细品这段代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;COPY --from=builder application/dependencies/ ./&lt;br/&gt;COPY --from=builder application/spring-boot-loader/ ./&lt;br/&gt;COPY --from=builder application/snapshot-dependencies/ ./&lt;br/&gt;COPY --from=builder application/application/ ./&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以发现，为了优化容器的创建，这里的 copy 顺序也是极为用心的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;先后顺序是&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;依赖包&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Springboot  loader 源码&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;依赖包中的快照&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;应用代码，配置文件等&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为按照 docker 容器的创建原理，底层没改变的话，是可以直接使用缓存的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就意味着，我们创建容器时，很多都可以用到缓存，直到到达 &lt;strong&gt;应用代码和配置文件这一层&lt;/strong&gt; ，这就极大的提高了容器的创建速度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;细心的小伙伴可以从上面 &lt;strong&gt;“验证”&lt;/strong&gt; 这张图中发现有 &lt;strong&gt;Using cache&lt;/strong&gt; 的字眼😝&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;小结&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么，到了这里，你有没有感受到前面提到的改进原因呢？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在容器中，如果没有解压就直接运行一个 jar 包，它带来的开销是明显的&lt;br/&gt;感受：Springboot 2.2.9 和 Springboot 2.4.13 都提供 高效的 dockerfile 方式&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;将 应用代码和包依赖都混在同一层，也是可以被优化的地方。&lt;br/&gt;感受：Springboot 2.2.9 和 Springboot 2.4.13 都有改动，但是 2.4 中分的更细，而且基本上，2.4 的 dockerfile 在任何地方都可以直接用，不用做过多修改，很方便。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以结论就是在 2.2.9 中就有了优化了，但是 2.3 之后又弄了个 &lt;strong&gt;layers.idx&lt;/strong&gt; 来进一步优化，规范这个分层，提供了一个更简便的方式！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以最后就变得更好使了😂&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8159509202453987&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNyQcjRnSaF1iah0CnImg2seddw9iabVXXBnAMl5GPB1nfHxoBkhx5ZYyg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;163&quot;/&gt;&lt;/figure&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面进入项目的搭建教学~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个小项目主要是用来获取各种 &lt;strong&gt;验证码&lt;/strong&gt; 的（中英文动态都有），是好久以前发现的，而且这个小 demo，还有隐藏的 API 等着小伙伴去发现。&lt;span&gt;😄&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;感兴趣的小伙伴可以简单了解下这个 captcha 的生成，还是很有意思的😝&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5989847715736041&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJN874YYxf7iaHGaVjDJuk6fDWuvibTFMKIQyjnGY1CkwFEUj7JmbBzd82w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;197&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;IDEA 部署 docker 容器&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# 修改Docker服务文件，需要先切换到root用户 &lt;/span&gt;&lt;br/&gt;vim /lib/systemd/system/docker.service&lt;br/&gt;&lt;br/&gt;ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -H tcp://0.0.0.0:2375&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 然后重启 docker&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4289719626168224&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNzqTAdqNsEy566E46fasWoRULNWNubqNMH9mZZIRIOcFqRFe88VaTVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1070&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;IDEA 中建一个 docker&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6375838926174496&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNv2FdVt7FR5yI3zyv1P5XHxE79xiad83R91dvwZBFDb8Mx5UhIibodD3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1192&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建 Dockerfile 容器。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.507213363705391&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJN3gBbr0HcNiashicuhCjibpfotoTrkcLG8SiaXMCSdgpTDMRicURVyUTbRZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1317&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后运行即可~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以在这里看到容器运行的 log。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3946969696969697&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zIjiaGEEKdYFkfCJmP1C7eKx4hyVSGaJNepakzJ48O9X7nf7zWQYficTzOawmtHbQhgNiaOjBUoWuLic8YgNa3KF8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1320&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>