<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f8028b4fcba6fdffdceecadd411cf538</guid>
<title>欢迎加入读者圈子，一起交流！</title>
<link>https://toutiao.io/k/mtrqmru</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;欢迎加入读者圈子，一起交流！&lt;br/&gt;↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;307&quot; data-ratio=&quot;0.5493333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/AjN1jquNavich3VaNkKeiaAwUhz7TQbQmic4fFsr58X9PAYleYzxqc1K1vZjeBoZDMUsmia0xH67EQYINGRvNOtLmA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;圈子剧透&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、600+圈子成员，以中高级程序员为主，更有架构师、CTO坐镇交流；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、1000+优质主题，数十G独家资料，每日分享，精挑细选；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、全年52期专属邮件周报，让你轻松掌握业界资讯、技术干货，提升认知水平；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、全年52本好书共读，让你花最少的时间，获取更好的知识；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;心动不如行动，赶快加入吧！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>53661c97f5d6a21c2940b7f2593b8061</guid>
<title>美团高性能终端实时日志系统建设实践</title>
<link>https://toutiao.io/k/sewret8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;58&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBVHPgeBXgTUj0ib1Kwfosl82xO1Aw7x6gccLuuYs1dbxI7REI7OcjbGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总第541&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2022年 第058篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img border=&quot;0&quot; class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;103&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;103&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBic5ADGrKxgSd0tibyMiasOHXjb46qFBw7PTfuWAxXzWq32lDkL05icwkMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; data-width=&quot;100%&quot; opacity=&quot;&quot; title=&quot;undefined&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; data-style=&quot;text-align: left; font-size: 14px; color: inherit;&quot;&gt;&lt;section&gt;&lt;span&gt;你是否经常遇到线上需要日志排查问题但迟迟联系不上用户上报日志的情况？或者是否经常陷入由于存储空间不足而导致日志写不进去的囧境？本文介绍了美团是如何从0到1搭建高性能终端实时日志系统，从此彻底解决日志丢失和写满问题的。希望能为大家带来一些帮助和启发。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1 背景&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.1 Logan 简介&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Logan 是美团面向终端的统一日志服务，已支持移动端App、Web、小程序、IoT 等多端环境，具备日志采集、存储、上传、查询与分析等能力，帮助用户定位研发问题，提升故障排查效率。同时，Logan 也是业内&lt;/span&gt;&lt;a href=&quot;https://github.com/Meituan-Dianping/Logan&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;开源&lt;/span&gt;&lt;/a&gt;&lt;span&gt;较早的大前端日志系统，具有写入性能高、安全性高、日志防丢失等优点。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.2 Logan 工作流程&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;为了方便读者更好地理解 Logan 系统是如何工作的，下图是简化后的 Logan 系统工作流程图。主要分为以下几个部分：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;主动上报日志&lt;/strong&gt;：终端设备在需要上报日志时，可以通过 HTTPS 接口主动上传日志到 Logan 接收服务，接收服务再把原始日志文件转存到对象存储平台。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;日志解密与解析&lt;/strong&gt;：当研发人员想要查看主动上报的日志时会触发日志下载与解析流程，原始加密日志从对象存储平台下载成功后进行解密、解析等操作，然后再投递到日志存储系统。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;日志查询与检索&lt;/strong&gt;：日志平台支持对单设备所有日志进行日志类型、标签、进程、关键字、时间等维度的筛选，同时也支持对一些特定类型的日志进行可视化展示。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;557&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;343&quot; data-ratio=&quot;0.6138888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGCDDD3BgyEpw8Eqldyd5cicHo2iceIVGImW9SCMXrNJ6gy9WNRKQQXBEw/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图1 Logan 系统工作流程图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.3 为什么需要实时日志？&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;如前文所述，这套“本地存储+主动上报”的模式虽然解决了大前端场景下基础的日志使用需求，但是随着业务复杂度的不断增加，用户对日志的要求也越来越高，当前 Logan 架构存在的问题也变得越来越突出，主要体现在以下几个方面：&lt;/span&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;部分场景上报日志受限&lt;/strong&gt;：由于在 Web 与小程序上用户一般的使用场景是用完即走，当线上出现问题时再联系用户主动上报日志，整个处理周期较长，有可能会错过最佳排查时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;缺少实时分析和告警能力&lt;/strong&gt;：当前缺少实时分析和告警的能力，用户曾多次提到过想要对线上异常日志进行监控，当有符合规则的异常日志出现时能收到告警信息。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;缺少全链路追踪能力&lt;/strong&gt;：当前多端的日志散落在各个系统中，研发人员在定位问题时需要手动去关联日志，操作起来很不方便，美团内部缺乏一个通用的全链路追踪方案。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;针对以上痛点问题，我们提出了建设 Logan 实时日志，旨在提供统一的、高性能的实时日志服务，以解决美团现阶段不同业务系统想要日志上云的需求。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.4 Logan 实时日志是什么？&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Logan 实时日志是服务于移动端 App、Web、小程序、IoT 等终端场景下的实时日志解决方案，旨在提供高扩展性、高性能、高可靠性的实时日志服务，包括日志采集、上传、加工、消费、投递、查询与分析等能力。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;557&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;212&quot; data-ratio=&quot;0.38055555555555554&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGPn67H1LV8VmoCptIEAZ6hAnh3yYDgfUXJNRrzDUMsn7iazSUnUg7u5A/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2 Logan 实时日志产品功能图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2 设计实现&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.1 整体架构&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;557&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;136&quot; data-ratio=&quot;0.24351851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGJj2CRdv8sQ3lwUqmAqFwoSea5GtV7ETEq6CbqY2KHFH84jMibkhQUVw/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3 Logan 实时日志整体架构图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;如上图所示，整体架构主要分为五个部分，它们分别是：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;采集端&lt;/strong&gt;：负责端上日志数据的采集、加密、压缩、聚合和上报等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;接入层&lt;/strong&gt;：负责提供日志上报接口，接收日志上报数据，并将数据转发到数据处理层。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据处理层&lt;/strong&gt;：负责日志数据的解密、拆分、加工和清洗等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据消费层&lt;/strong&gt;：负责日志数据的过滤、格式化、投递等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;日志平台&lt;/strong&gt;：负责日志数据查询与分析、业务系统接入配置、统计与告警等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.2 采集端&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;通用采集端架构，解决跨平台复用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采集端SDK用于端侧日志收集，需要在多种终端环境落地，但是由于端和平台较多、技术栈和运行环境也不一致，多端开发和维护成本会比较高。因此，我们设计了一套核心逻辑复用的通用采集端架构，具体的平台依赖代码则单独进行适配。我们目前上线了微信、MMP、Web、MRN 端侧，逻辑层代码做到了完全复用。采集端架构设计图如下：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;577&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;374&quot; data-ratio=&quot;0.64765625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGqzh90Vdiao7eiaLuoT5txyo6k7TsOhEPAyDBPmiaFvfc7SibtHFfj3EPWQ/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图4 采集端SDK架构图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;重点模块介绍：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;配置管理&lt;/strong&gt;：采集端初始化完成后，首先启动配置管理模块，拉取和刷新配置信息，包括上报限流配置、指标采样率、功能开关等，支持对关键配置进行灰度发布。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;加密&lt;/strong&gt;：所有记录的日志都使用 ECDH + AES 方案加密，确保日志信息不泄漏。Web 版加密模块使用浏览器原生加密 API 进行适配，可实现高性能异步加密，其他平台则使用纯 JS 实现。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;存储管理&lt;/strong&gt;：线上数据表明，由于页面关闭导致的日志丢失占比高达 1%，因此我们设计了日志落盘功能，当日志上传失败后会先缓存在本地磁盘，等到页面下一次启动时再重新恢复上传。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;队列管理&lt;/strong&gt;：需要发送的日志首先进行分组聚合，如果等待分组过多则需要丢弃一部分请求，防止在弱网环境或者日志堆积太多时造成内存持续上涨而影响用户。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;落盘缓存 + 上报恢复，防止日志丢失&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;为了方便读者更好地理解端上日志采集过程，下面将具体介绍下采集端流程设计。当采集端初始化 API 开始调用时，先创建 Logger、Encryptor、Storage 等实例对象，并异步拉取环境配置文件。初始化完成之后，先检查是否有成功落盘，但是上报失败的日志，如果有的话立即开始恢复上传流程。当正常调用写日志 API 时，原始日志被加密后加入当前上报组，等到有上报事件（&lt;/span&gt;&lt;span&gt;时间、条数、导航等&lt;/span&gt;&lt;span&gt;）触发时，当前上报组内的所有日志被加入上报队列并开始上传。采集端详细流程图如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;577&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;412&quot; data-ratio=&quot;0.7125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGtmibLBfTribGRDFia77MV6jhzUQjQ3g4m0wZkDRJzVWm2Ys1Dp54iceDjQ/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图5 采集端SDK流程图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.3 数据接入层&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;对于实时日志系统来讲，接入层需要满足以下几点要求：（1）支持公网上报域名；（2）支持高并发处理；（3）具备高实时性，延迟是分钟级；（4）支持投递数据到 Kafka 消息队列。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;经过对比，美团内的统一日志收集通道均满足以上需求，因此我们选用了统一日志收集通道作为接入层。采集端 SDK 通过独立的公网域名上报日志后，收集通道将日志数据汇总好并投递到指定的 Kafka 消息队列。如果读者公司没有类似的日志收集通道，那么可以参考以下流程搭建实时日志系统接入层。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;577&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;56&quot; data-ratio=&quot;0.0962962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGeNsKF0qnyFEzFRSz3fB5IficPc1qaN5wtBc3uNOQmGolTMNC33j4icHw/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图6 接入层流程图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.4 数据处理层&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;在数据处理框架的技术选型上，我们先后考虑了三种方案，分别是传统架构（&lt;/span&gt;&lt;span&gt;Java 应用&lt;/span&gt;&lt;span&gt;）、Storm 架构、Flink 架构，这三种方案在不同维度的对比数据如下：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.20317460317460317&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGqcfjE673M2P7g2soItlGeWtyOrkWAfmH1YalXPPKLZFMqU8EWz9QNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1260&quot;/&gt;&lt;span&gt;表1 技术选型对比表&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;综合来看，虽然传统架构有比较好的成熟度与灵活性，但是在扩展性、容错性以及性能上均不能满足系统要求，而 Flink 架构与 Storm 架构都有比较优秀的扩展性与容错性，但是 Flink 架构在延迟与吞吐量上表现要更好，因此我们最终选择了使用 Flink 架构作为数据处理框架。&lt;/span&gt;&lt;/section&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;Flink：业内领先的流式计算引擎，具有高吞吐、低延迟、高可靠和精确计算等优点，对事件窗口有很好的支持，被业内很多公司作为首选的流式计算引擎。&lt;/span&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;span&gt;在日志处理流程设计上，日志数据通过接入层处理后被投递到汇总 topic 里面，然后再通过 Flink 作业的逻辑处理后分发到下游。处理流程如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;577&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;253&quot; data-ratio=&quot;0.43796296296296294&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGSDiao1oXVgv9hRqguLOcYmmuqpdGDHx8HMpl4gSopHUaaCD3mdFWic0A/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图7 日志处理层流程图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;汇总后的日志数据处理和分发依赖于实时计算平台的实时作业能力，底层使用 Flink 数据处理引擎，主要负责日志数据的解析、日志内容的解密以及拆分到下游等。&lt;/span&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;元数据解析&lt;/strong&gt;：通过实时作业能力完成原始日志数据解析为 JSON 对象数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;内容解密&lt;/strong&gt;：对加密内容进行解密，此处使用非对称协商计算出对称加密密钥，然后再进行解密。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;服务维度拆分&lt;/strong&gt;：通过 topic 字段把日志分发到各业务系统所属的 topic 里面，从而实现业务日志相互隔离。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据自定义加工&lt;/strong&gt;：根据用户自定义的加工语法模版，从服务 topic 实时消费并加工数据到自定义 topic 中。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.5 数据消费层&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;对大部分用户来说 Logan 实时日志提供的日志采集、加工、检索能力已经能满足大部分需求。但是在与用户沟通过程中我们发现还有一些更高阶的需求，比如指标监控、前后端链路串联、离线数据计算等。于是我们将 Logan 标准化后的日志统一投递到 Kafka 流处理平台，并提供一些通用的数据转换能力，方便用户按需接入到不同的第三方系统。数据消费层设计如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;577&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;456&quot; data-ratio=&quot;0.7890625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEG2MqeDWBFprnuPOvBibgqfcpW1Qty1HtcLR6x4lxGKrJGnVaibjADEJ6w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图8 数据消费层设计图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;数据消费层的一些典型的应用场景：&lt;/span&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;网络全链路追踪&lt;/strong&gt;：现阶段前后端的日志可能分布在不同的系统中，前端日志系统记录的主要是代码级日志、端到端日志等，后端日志系统记录的是链路关系、服务耗时等信息。通过 Logan 实时日志开放的数据消费能力，用户可以根据自己的需求来串联多端日志，从而实现网络全链路追踪。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;指标聚合统计&amp;amp;告警&lt;/strong&gt;：实时日志也是一种实时的数据流，可以作为指标数据上报的载体，如果把日志数据对接到数据统计平台就能实现指标监控和告警了。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;离线数据分析&lt;/strong&gt;：如果在一些需求场景下需要对数据进行长期化保存或者离线分析，就可以将数据导入到 Hive 中来实现。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.6 日志平台&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;日志平台的核心功能是为用户提供日志检索支持，日志平台提供了用户标识、自定义标签、关键字等多种检索过滤方式。在日志底层存储架构的选择上，目前业界广泛使用的是 Elasticsearch，考虑到计费与运维成本的关系，美团内部已经有一套统一的框架可以使用，所以我们也选用了 Elasticsearch 架构。同时，我们也支持通过单独的接口层适配其他存储引擎，日志查询流程如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;560&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;347&quot; data-ratio=&quot;0.6194444444444445&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGibH8ichgAY6w8UCMG4hfZlBQVuUwkSveta3lw2ItnibDEwhX8ZO0VjZbg/640?wx_fmt=jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图9 日志查询流程设计图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;Elasticsearch：是一个分布式的开源搜索和分析引擎，具有接入成本低、扩展性高和近实时性等优点，比较适合用来做大数据量的全文检索服务，例如日志查询等。&lt;/span&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3 稳定性保障&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1 核心监控&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;为了衡量终端实时日志系统的可用性，我们制定了以下核心 SLA 指标：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2721238938053097&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGUR3Dvptk1jPsexicHJV913YyMjHCkzLjlh4aicicEHic8SV0U2NmIGqFnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;904&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;表2 核心 SLA 指标表格&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;除了核心指标监控之外，我们还建设了全流程监控大盘，覆盖了分端上报成功率、域名可用性、域名 QPS、作业吞吐量、平均聚合条数等重要观测指标，并且针对上报成功率、域名 QPS、作业吞吐量等配置了兜底告警，当线上有异常时可以第一时间发现并进行处理。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.2 蓝绿发布&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;实时日志依赖于实时作业的处理计算能力，但是目前实时作业的发布和部署不能无缝衔接，中间可能存在真空的情况。当重启作业时，需要先停止原作业，再启动新的作业。如果遇到代码故障或系统资源不足等情况时则会导致作业启动失败，从而直接面临消息积压严重和数据延时升高的问题，这对于实时日志系统来说是不能忍受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蓝绿发布（&lt;/span&gt;&lt;span&gt;Blue Green Deployment&lt;/span&gt;&lt;span&gt;）是一种平滑过渡的发布模式。在蓝绿发布模式中，首先要将应用划分为对等的蓝绿两个分组，蓝组发布新产品代码并引入少许线上流量，绿组继续运行老产品代码。当新产品代码经线上运行观察没有问题后，开始逐步引入更多线上流量，直至所有流量都访问蓝组新产品。因此，蓝绿发布可以保证整体系统的稳定，在产品发布前期就可以发现并解决问题，以保证其影响面可控。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;目前美团已有的实时作业蓝绿部署方案各不相同，由于 Logan 实时日志接入业务系统较多，且数据量较大，经过综合考量后，我们决定自己实现一套适合当前系统的蓝绿部署方案。为了保证系统的稳定性，在作业运行过程中，启动另外一个相同的作业，当新作业运行没有问题后，再完成新老作业切换。蓝绿发布流程图如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;577&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;605&quot; data-ratio=&quot;1.04765625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsWbSCiauMibUjp0l4pOibUicXEGMge8ry2iakXPjianWZC7J3U3h9qU3WvkXDtendicstdmf06Qich5rNFoPQ/640?wx_fmt=jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图10 蓝绿发布流程图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;使用蓝绿部署后，彻底解决了由于资源不足或参数不对导致的上线失败问题，平均部署切换耗时也保持在1分钟以内，基本避免了因发布带来的日志消费延迟问题。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4 落地成果&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;Logan 实时日志在建设初期就受到了各个业务的广泛关注，截止到 2022 年第 3 季度，Logan 实时日志接入并上线的业务系统数量已多达二十余个，其中包括美团小程序、优选商家、餐饮 SaaS 等大体量业务。下面是一些业务系统接入的典型使用场景，供大家参考：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;核心链路还原&lt;/strong&gt;：到家某 C 端小程序使用 Logan 实时日志记录程序核心链路中的关键日志与异常日志，当线上有客诉问题发生时，可以第一时间查看实时日志并定位问题。项目上线后，平均客诉定位时间从之前的 10 分钟减少到 3 分钟以内，排障效率有明显提升。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;内测阶段排障&lt;/strong&gt;：企业平台某前端项目由于 2.0 改版改动较大，于是使用 Logan 实时日志在内测阶段添加更多的调试日志，方便定位线上问题。项目上线后，每次排查问题除了节省用户上报日志时间 10-15 分钟，还杜绝了因为存储空间不足而拿不到用户日志的情况。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;日志数据分析&lt;/strong&gt;：美团到店某团队使用 Logan 实时日志分析前后端交互过程中的请求头、请求参数、响应体等数据是否符合标准化规范。经过一个多月时间的试运行，一期版本上线后共覆盖 300+ 前端页面和 500+ 前端接口，共计发现 1000+ 规范问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5 未来规划&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Logan 实时日志经过半年的建设与推广，已经完成了系统基础能力的建设，能满足用户对于实时日志的基本诉求。但是对于日志数据深加工与清洗、日志统计与告警等高阶需求还不支持，因此为了更好地发挥日志价值，提升终端故障排查效率，Logan 实时日志有以下几个方面的规划：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;完善功能&lt;/strong&gt;：支持更多终端类型，建设日志加工与清洗、日志统计与告警、全链路追踪等功能。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;提升性能&lt;/strong&gt;：支持百万并发 QPS、日志上报成功率提升至 99.9% 等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;提升稳定性&lt;/strong&gt;：建设限流熔断机制、应急响应与故障处理预案等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6 本文作者&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;洪坤、徐博、陈成、少星等，均来自美团-基础技术部-前端技术中心。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;----------  END  ----------&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;招聘信息&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;美团基础技术部-前端技术中心，诚招高级、资深技术专家，Base上海、北京。我们致力于为美团海量业务建设高性能、高可用、高体验的前端基础技术服务，涵盖终端通信、终端安全、资源托管、可观测性、研发协同、设计工具、低代码、Node基建等技术领域，欢迎有兴趣的同学投送简历至：&lt;/span&gt;&lt;span&gt;edp.itu.zhaopin@meituan.com&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;也许你还想看&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651770156&amp;amp;idx=1&amp;amp;sn=2aa8349931dbbeddc66284dd82ab80e3&amp;amp;chksm=bd1214618a659d7760ff8e750e5d84cc0d427fdae3d1d4be191a6c12691be912300e0cb23a58&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;日志导致线程Block的这些坑，你不得不防&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651770156&amp;amp;idx=1&amp;amp;sn=2aa8349931dbbeddc66284dd82ab80e3&amp;amp;chksm=bd1214618a659d7760ff8e750e5d84cc0d427fdae3d1d4be191a6c12691be912300e0cb23a58&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;日志导致线程Block的这些坑，你不得不防&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;日志导致线程Block的这些坑，你不得不防&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651770155&amp;amp;idx=1&amp;amp;sn=03437e5e67bb971f96cd698139c71fcf&amp;amp;chksm=bd1214668a659d7079bdcaabef696bcfd0f17add2f71303e7a7fce76997631eba2629e9a669c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;可视化全链路日志追踪&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651770155&amp;amp;idx=1&amp;amp;sn=03437e5e67bb971f96cd698139c71fcf&amp;amp;chksm=bd1214668a659d7079bdcaabef696bcfd0f17add2f71303e7a7fce76997631eba2629e9a669c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;可视化全链路日志追踪&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;可视化全链路日志追踪&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651764878&amp;amp;idx=1&amp;amp;sn=47d0a950bacdbd062e544251e4d2c4d5&amp;amp;chksm=bd1261c38a65e8d59395c62f565067c8c1dad2e71e9a864dd782b111a43234c24154799a9db5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;如何优雅地记录操作日志？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;如何优雅地记录操作日志？&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阅读更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765958&amp;amp;idx=1&amp;amp;sn=8201546812e5a95a2bee9dffc6d12f00&amp;amp;chksm=bd12658b8a65ec9de2f5be1e96796dfb3c8f1a374d4b7bd91266072f557caf8118d4ddb72b07&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;前‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;前端&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt; &lt;/strong&gt; &lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765981&amp;amp;idx=1&amp;amp;sn=c2dd86f15dee2cbbc89e27677d985060&amp;amp;chksm=bd1265908a65ec86d4d08f7600d1518b61c90f6453074f9b308c96861c045712280a73751c73&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;算‍法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;算法&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765982&amp;amp;idx=1&amp;amp;sn=231b41f653ac7959f3e3b8213dcec2b0&amp;amp;chksm=bd1265938a65ec85630c546169444d56377bc2f11401d251da7ca50e5d07e353aa01580c7216&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;后‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;后端&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765964&amp;amp;idx=1&amp;amp;sn=ab6d8db147234fe57f27dd46eec40fef&amp;amp;chksm=bd1265818a65ec9749246dd1a2eb3bf7798772cc4d5b4283b15eae2f80bc6db63a1471a9e61e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数‍据&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;数据&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765965&amp;amp;idx=1&amp;amp;sn=37e0c56c8b080146ce5249243bfd84d8&amp;amp;chksm=bd1265808a65ec96d3a2b2c87c6e27c910d49cb6b149970fb2db8bf88045a0a85fed2e6a0b84&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;安‍全&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;安全&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765972&amp;amp;idx=1&amp;amp;sn=afe02ec92762c1ce18740d03324c4ac3&amp;amp;chksm=bd1265998a65ec8f10d5f58d0f3681ddfc5325137218e568e1cda3a50e427749edb5c6a7dcf5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;And‍roid&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;Android&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765973&amp;amp;idx=1&amp;amp;sn=32a23bf1d278dda0398f993ab60a697e&amp;amp;chksm=bd1265988a65ec8e630ef4d24b4946ab6bd7e66702c1d712481cf3c471468a059c470a14c30d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;iO‍S&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;iOS&lt;/a&gt;&lt;span&gt; &lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765963&amp;amp;idx=1&amp;amp;sn=a3de9ef267d07d94118c1611776a4b28&amp;amp;chksm=bd1265868a65ec906592d25ad65f2a8516338d07ec3217059e6975fc131fc0107d66a8cd2612&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;运‍维&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;运维&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765974&amp;amp;idx=1&amp;amp;sn=763c1e37d04acffd0142a2852ecfb000&amp;amp;chksm=bd12659b8a65ec8dfcfeb2028ef287fae7c38f134a665375ba420556ce5d2e4cf398147bd12e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测‍试&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;测试&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5NjQ5MTI5OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVGibnsaEib3aNlqF0tOrA2RGEmNSbia2nnohE4Tpf95UyTiaSjDVbHRfY8WNBeTuLLTaVdSckkNyEx1Q/0?wx_fmt=png&quot; data-nickname=&quot;美团技术团队&quot; data-alias=&quot;meituantech&quot; data-signature=&quot;10000+工程师，如何支撑中国领先的生活服务电子商务平台？数亿消费者、数百万商户、2000多个行业、几千亿交易额背后是哪些技术在支撑？这里是美团、大众点评、美团外卖、美团配送、美团优选等技术团队的对外窗口。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>36939f10b3a274541955451ef87a938a</guid>
<title>如何将进程、线程与 CPU 核进行绑定</title>
<link>https://toutiao.io/k/q0ifce4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;markdown编辑器&quot; data-website=&quot;https://markdown.com.cn/editor&quot;&gt;&lt;h1 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;/h1&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkwNjE2ODMyMQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/dr6jv46VAWdDbl0jFicIibMS96BDOdxJnXg3wEIgS3xdkgd1gEF2BPDJkFWRu8DQBYtkzbMQs3icZmHBrEbZ7F6Tw/0?wx_fmt=png&quot; data-nickname=&quot;小渔儿学视觉&quot; data-alias=&quot;&quot; data-signature=&quot;分享计算机视觉、机器学习、深度学习、无人驾驶等领域的文章&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;h1 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;概念&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;CPU&lt;/code&gt;绑定指的是在多核&lt;code&gt;CPU&lt;/code&gt;的系统中将进程或线程绑定到指定的&lt;code&gt;CPU&lt;/code&gt;核上去执行。在&lt;code&gt;Linux&lt;/code&gt;中，我们可以利用&lt;code&gt;CPU affinity&lt;/code&gt;属性把进程绑定到一个或多个&lt;code&gt;CPU&lt;/code&gt;核上。&lt;/p&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;CPU Affinity&lt;/code&gt;是进程的一个属性，这个属性指明了进程调度器能够把这个进程调度到哪些&lt;code&gt;CPU&lt;/code&gt;上。该属性要求进程在某个指定的&lt;code&gt;CPU&lt;/code&gt;上尽量长时间地运行而不被迁移到其他处理器。&lt;/p&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;CPU Affinity&lt;/code&gt;分为2种：&lt;code&gt;soft affinity&lt;/code&gt;和&lt;code&gt;hard affinity&lt;/code&gt;。&lt;code&gt;soft affinity&lt;/code&gt;只是一个建议，如果不可避免，调度器还是会把进程调度到其它的&lt;code&gt;CPU&lt;/code&gt;上去执行；&lt;code&gt;hard affinity&lt;/code&gt;则是调度器必须遵守的规则， &lt;code&gt;2.6&lt;/code&gt;以上版本的&lt;code&gt;Linux&lt;/code&gt;内核可以让开发人员可以编程实现&lt;code&gt;hard affinity&lt;/code&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用hard affinity的意义&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;CPU&lt;/code&gt;各核之间是不共享缓存的，如果进程频繁地在多个&lt;code&gt;CPU&lt;/code&gt;核之间切换，则会使旧&lt;code&gt;CPU&lt;/code&gt;核的&lt;code&gt;cache&lt;/code&gt;失效，失去了利用&lt;code&gt;CPU&lt;/code&gt;缓存的优势。如果进程只在某个&lt;code&gt;CPU&lt;/code&gt;上执行，可以避免进程在一个&lt;code&gt;CPU&lt;/code&gt;上停止执行，然后在不同的&lt;code&gt;CPU&lt;/code&gt;上重新执行时发生的缓存无效而引起的性能成本。&lt;/p&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;在实时性要求高应用中，我们可以把重要的系统进程绑定到指定的&lt;code&gt;CPU&lt;/code&gt;上，把应用进程绑定到其余的&lt;code&gt;CPU&lt;/code&gt;上。这种做法确保对时间敏感的应用程序可以得到运行，同时可以允许其他应用程序使用其余的计算资源。&lt;/p&gt;&lt;h2 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;如何将进程与CPU核进行绑定&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;在&lt;code&gt;Linux&lt;/code&gt;中，用结构体&lt;code&gt;cpu_set_t&lt;/code&gt;来表示&lt;code&gt;CPU Affinity&lt;/code&gt;掩码，同时定义了一系列的宏来用于操作进程的可调度&lt;code&gt;CPU&lt;/code&gt;集合：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;#define _GNU_SOURCE &lt;br/&gt;#include &amp;lt;sched.h&amp;gt;&lt;br/&gt;void CPU_ZERO(cpu_set_t *set);&lt;br/&gt;void CPU_SET(int cpu, cpu_set_t *set);&lt;br/&gt;void CPU_CLR(int cpu, cpu_set_t *set);&lt;br/&gt;int CPU_ISSET(int cpu, cpu_set_t *set);&lt;br/&gt;int CPU_COUNT(cpu_set_t *set);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;具体的作用如下：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;CPU_ZERO()：清除集合的内容，让其不包含任何CPU。&lt;br/&gt;CPU_SET()：添加cpu到集合中。&lt;br/&gt;CPU_CLR()：从集合中移除cpu&lt;br/&gt;CPU_ISSET() ：测试cpu是否在集合中。&lt;br/&gt;CPU_COUNT()：返回集合中包含的CPU数量。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;在&lt;code&gt;Linux&lt;/code&gt;中，可以使用以下两个函数设置和获取进程的&lt;code&gt;CPU Affinity&lt;/code&gt;属性：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;#define _GNU_SOURCE &lt;br/&gt;#include &amp;lt;sched.h&amp;gt;&lt;br/&gt;int sched_setaffinity(pid_t pid, size_t cpusetsize,const cpu_set_t *mask);&lt;br/&gt;int sched_getaffinity(pid_t pid, size_t cpusetsize,cpu_set_t *mask);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;另外可以通过下面的函数获知当前进程运行在哪个&lt;code&gt;CPU&lt;/code&gt;上：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;int sched_getcpu(void);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;如果调用成功，该函数返回一个非负的&lt;code&gt;CPU&lt;/code&gt;编号值。&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;#define _GNU_SOURCE&lt;br/&gt;#include &amp;lt;sched.h&amp;gt;&lt;br/&gt;#include &amp;lt;unistd.h&amp;gt;&lt;br/&gt;#include &amp;lt;sys/types.h&amp;gt;&lt;br/&gt;#include &amp;lt;sys/wait.h&amp;gt;&lt;br/&gt;#include &amp;lt;stdio.h&amp;gt;&lt;br/&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;br/&gt; &lt;br/&gt;int main(int argc, char *argv[])&lt;br/&gt;{&lt;br/&gt;    cpu_set_t set;&lt;br/&gt;    int parentCPU, childCPU;&lt;br/&gt;    int j;&lt;br/&gt;    int cpu_num = -1;&lt;br/&gt;    if (argc != 3) {&lt;br/&gt;        fprintf(stderr, &quot;Usage: %s parent-cpu child-cpu\n&quot;, argv[0]);&lt;br/&gt;        exit(EXIT_FAILURE);&lt;br/&gt;    }&lt;br/&gt;    parentCPU = atoi(argv[1]);&lt;br/&gt;    childCPU = atoi(argv[2]);&lt;br/&gt;    CPU_ZERO(&amp;amp;set);&lt;br/&gt;    &lt;br/&gt;    switch (fork()) {&lt;br/&gt;        case -1: { /* Error */&lt;br/&gt;            fprintf(stderr, &quot;fork error\n&quot;);&lt;br/&gt;            exit(EXIT_FAILURE);&lt;br/&gt;        }&lt;br/&gt;        case 0: { /* Child */&lt;br/&gt;            CPU_SET(childCPU, &amp;amp;set);&lt;br/&gt;            if (sched_setaffinity(getpid(), sizeof(set), &amp;amp;set) == -1) {&lt;br/&gt;                fprintf(stderr, &quot;child sched_setaffinity error\n&quot;);&lt;br/&gt;                exit(EXIT_FAILURE);&lt;br/&gt;            }&lt;br/&gt;            sleep(1);&lt;br/&gt;            if (-1 != (cpu_num = sched_getcpu())) {&lt;br/&gt;                fprintf(stdout, &quot;The child process is running on cpu %d\n&quot;, cpu_num);&lt;br/&gt;            }&lt;br/&gt;            exit(EXIT_SUCCESS);&lt;br/&gt;        }&lt;br/&gt;        default: { /* Parent */&lt;br/&gt;            CPU_SET(parentCPU, &amp;amp;set);&lt;br/&gt;            if (sched_setaffinity(getpid(), sizeof(set), &amp;amp;set) == -1) {&lt;br/&gt;                fprintf(stderr, &quot;parent sched_setaffinity error\n&quot;);&lt;br/&gt;                exit(EXIT_FAILURE);&lt;br/&gt;            }&lt;br/&gt;            if (-1 != (cpu_num = sched_getcpu())) {&lt;br/&gt;                fprintf(stdout, &quot;The parent process is running on cpu %d\n&quot;, cpu_num);&lt;br/&gt;            }&lt;br/&gt;            wait(NULL); /* Wait for child to terminate */&lt;br/&gt;            exit(EXIT_SUCCESS);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;程序首先用&lt;code&gt;CPU_ZERO&lt;/code&gt;清空&lt;code&gt;CPU&lt;/code&gt;集合，然后调用&lt;code&gt;fork()&lt;/code&gt;函数创建一个子进程，并调用&lt;code&gt;sched_setaffinity()&lt;/code&gt;函数给父进程和子进程分别设置&lt;code&gt;CPU Affinity&lt;/code&gt;，输入参数&lt;code&gt;parentCPU&lt;/code&gt;和&lt;code&gt;childCPU&lt;/code&gt;分别指定父进程和子进程运行的&lt;code&gt;CPU&lt;/code&gt;号。指定父进程和子进程运行的&lt;code&gt;CPU&lt;/code&gt;为1和0，程序输出如下：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;# ./affinity_test 1 0&lt;br/&gt;The parent process is running on cpu 1&lt;br/&gt;The child process is running on cpu 0&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;如何将线程与CPU核进行绑定&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;前面介绍了进程与&lt;code&gt;CPU&lt;/code&gt;的绑定，那么线程可不可以与&lt;code&gt;CPU&lt;/code&gt;绑定呢？当然是可以的。在&lt;code&gt;Linux&lt;/code&gt;中，可以使用以下两个函数设置和获取线程的&lt;code&gt;CPU Affinity&lt;/code&gt;属性：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;#define _GNU_SOURCE &lt;br/&gt;#include &amp;lt;pthread.h&amp;gt;&lt;br/&gt;int pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset);&lt;br/&gt;int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;#define _GNU_SOURCE&lt;br/&gt;#include &amp;lt;pthread.h&amp;gt;&lt;br/&gt;#include &amp;lt;stdio.h&amp;gt;&lt;br/&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;br/&gt;#include &amp;lt;errno.h&amp;gt;&lt;br/&gt; &lt;br/&gt;static void *thread_start(void *arg) {&lt;br/&gt;    ......&lt;br/&gt;    struct thread_info *tinfo = arg;&lt;br/&gt;    thread = tinfo-&amp;gt;thread_id;&lt;br/&gt;    CPU_ZERO(&amp;amp;cpuset);&lt;br/&gt;    CPU_SET(tinfo-&amp;gt;thread_num, &amp;amp;cpuset);&lt;br/&gt;    s = pthread_setaffinity_np(thread, sizeof(cpu_set_t), &amp;amp;cpuset);&lt;br/&gt;    if (s != 0) {&lt;br/&gt;        handle_error_en(s, &quot;pthread_setaffinity_np&quot;);&lt;br/&gt;    } &lt;br/&gt;    CPU_ZERO(&amp;amp;cpuset);&lt;br/&gt;    s = pthread_getaffinity_np(thread, sizeof(cpu_set_t), &amp;amp;cpuset);&lt;br/&gt;    if (s != 0) {&lt;br/&gt;        handle_error_en(s, &quot;pthread_getaffinity_np&quot;);&lt;br/&gt;    }&lt;br/&gt;    &lt;br/&gt;    for (j = 0; j &amp;lt; cpu_num; j++) {&lt;br/&gt;        if (CPU_ISSET(j, &amp;amp;cpuset)) { //如果当前线程运行在CPU j上，则输出信息&lt;br/&gt;            printf(&quot; thread %d is running on cpu %d\n&quot;, tinfo-&amp;gt;thread_num, j);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    pthread_exit(NULL);&lt;br/&gt;}&lt;br/&gt; &lt;br/&gt;int main(int argc, char *argv[])&lt;br/&gt;{&lt;br/&gt;    ......&lt;br/&gt;    cpu_num = sysconf(_SC_NPROCESSORS_CONF); //获取系统的CPU数量&lt;br/&gt;    tinfo = calloc(cpu_num, sizeof(struct thread_info));&lt;br/&gt;    &lt;br/&gt;    if (tinfo == NULL) {&lt;br/&gt;        handle_error_en(0, &quot;calloc&quot;);&lt;br/&gt;    }&lt;br/&gt;    &lt;br/&gt;    for (j = 0; j &amp;lt; cpu_num; j++) { //有多少个CPU就创建多少个线程&lt;br/&gt;        tinfo[j].thread_num = j;&lt;br/&gt;        s = pthread_create(&amp;amp;tinfo[j].thread_id, NULL, thread_start, &amp;amp;tinfo[j]);&lt;br/&gt;        if (s != 0) {&lt;br/&gt;            handle_error_en(s, &quot;pthread_create&quot;);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    &lt;br/&gt;    for (j = 0; j &amp;lt; cpu_num; j++) {&lt;br/&gt;        s = pthread_join(tinfo[j].thread_id, NULL);&lt;br/&gt;        if (s != 0) {&lt;br/&gt;            handle_error_en(s, &quot;pthread_join&quot;);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    ......&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;程序首先获取当前系统的&lt;code&gt;CPU&lt;/code&gt;数量&lt;code&gt;cpu_num&lt;/code&gt;，然后根据&lt;code&gt;CPU&lt;/code&gt;数量的数量创建线程，有多少个&lt;code&gt;CPU&lt;/code&gt;就创建多少个线程，每个线程都运行在不同的&lt;code&gt;CPU&lt;/code&gt;上。在4核的机器中运行结果如下：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;$ ./thread_affinity&lt;br/&gt; thread 1 is running on cpu 1&lt;br/&gt; thread 0 is running on cpu 0&lt;br/&gt; thread 3 is running on cpu 3&lt;br/&gt; thread 2 is running on cpu 2&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;用taskset命令实现进程与CPU核的绑定&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;Linux&lt;/code&gt; 的&lt;code&gt;taskset&lt;/code&gt;命令用于设置或检索由&lt;code&gt;pid&lt;/code&gt;指定的运行进程的&lt;code&gt;CPU Affinity&lt;/code&gt;，或者以给定的&lt;code&gt;CPU Affinity&lt;/code&gt;属性启动新的进程。&lt;code&gt;CPU Affinity&lt;/code&gt;属性用位掩码来表示，其中最低位对应第一逻辑&lt;code&gt;CPU&lt;/code&gt;，最后一位与最后一个逻辑&lt;code&gt;CPU&lt;/code&gt;对应。检索到的掩码仅反映与物理系统上的&lt;code&gt;CPU&lt;/code&gt;相对应的位。如果给出无效的掩码（即当前系统上没有对应的有效的&lt;code&gt;CPU&lt;/code&gt;掩码），则返回错误。掩码通常以十六进制形式给出。例如：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;0x00000001 表示CPU #0,&lt;br/&gt;0x00000003 表示CPU #0 和 #1,&lt;br/&gt;0x0000000f 表示CPU #0 ~ #3&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;taskset&lt;/code&gt;命令的选项如下：&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;-a, --all-tasks&lt;br/&gt;设置或检索所有由pid指定的进程的CPU Affinity属性。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;-c, --cpu-list numbers&lt;br/&gt;指定处理器的数值列表，而不是位掩码。数字用逗号分隔，可以包括范围。比如：0,5,8-11。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;-p, --pid&lt;br/&gt;操作由pid指定的进程，不启动新的进程。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;strong&gt;下面以&lt;code&gt;Ubuntu16.04&lt;/code&gt;中的&lt;code&gt;taskset&lt;/code&gt;命令说明该命令的使用方法：&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;命令：taskset -p 1&lt;br/&gt;结果：pid 1‘s current affinity mask: f&lt;br/&gt;说明：f表示进程1运行在CPU#0~CPU#3上&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;命令：taskset -cp 1,2 7737&lt;br/&gt;结果：pid 7737&#x27;s current affinity list: 0-3&lt;br/&gt;     pid 7737&#x27;s new affinity list: 1,2&lt;br/&gt;说明：该操作把进程7737限定在CPU#1~CPU#2上运行。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;code&gt;命令：taskset -c 1-2 ./get_affinity&lt;br/&gt;结果：This process is running on cpu 1&lt;br/&gt;     This process is running on cpu 2&lt;br/&gt;说明：get_affinity程序通过sched_getaffinity()函数获取当前进程的CPU Affinity属性并输出提示信息。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;markdown.com.cn编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;markdown.com.cn编辑器&quot;&gt;本文通过几个简单的例子介绍了&lt;code&gt;Linux&lt;/code&gt;环境下进程、线程与&lt;code&gt;CPU&lt;/code&gt;的绑定方法，希望对大家有参考意义。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b290303ceaffe315a9965ed99cfcab1c</guid>
<title>一文搞懂 XaaS</title>
<link>https://toutiao.io/k/b59020l</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;em&gt;云服务是指通过互联网按需提供给企业和客户的各种服务，大致可以分为IaaS、PaaS、SaaS三类，每一类又衍生出不同细分的云服务模式。本文介绍了当前已经提出的19种云服务模式，原文: &lt;span&gt;The Comprehensive Concept of IaaS, PaaS, SaaS, AaaS, BaaS, FaaS, DaaS, STaaS, CaaS, NaaS, DBaaS, AaaS, aPaaS, iPaaS, apimPaaS, IoT PaaS, mPaaS, dbPaaS, and UIPaaS&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你想建立、托管网站，但不想使用云服务(即本地部署模式, on-premises)，那么就需要以更高的前期成本购买服务器硬件，好处是可以更好的控制这些服务并与业务集成。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;The Comprehensive Concept of IaaS, PaaS, SaaS, AaaS, BaaS, FaaS, DaaS, STaaS, CaaS, NaaS, DBaaS, AaaS, aPaaS, iPaaS, apimPaaS, IoT PaaS, mPaaS, dbPaaS, and UIPaaS: &lt;em&gt;https://medium.com/geekculture/the-comprehensive-concept-of-iaas-paas-saas-aaas-baas-faas-daas-staas-caas-naas-dbaas-14145d4f93c4&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;DigitalOcean: &lt;em&gt;https://www.digitalocean.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;Linode: &lt;em&gt;https://www.linode.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;Rackspace: &lt;em&gt;https://www.rackspace.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[5]&lt;/span&gt;&lt;p&gt;Amazon Web Service (AWS): &lt;em&gt;https://aws.amazon.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[6]&lt;/span&gt;&lt;p&gt;Cisco Metacloud: &lt;em&gt;https://www.cisco.com/c/en/us/solutions/cloud/index.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[7]&lt;/span&gt;&lt;p&gt;Microsoft Azure: &lt;em&gt;https://azure.microsoft.com/en-us&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[8]&lt;/span&gt;&lt;p&gt;Google Compute Engine (GCE): &lt;em&gt;https://cloud.google.com/compute&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[9]&lt;/span&gt;&lt;p&gt;AWS Elastic Beanstalk: &lt;em&gt;https://aws.amazon.com/elasticbeanstalk&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[10]&lt;/span&gt;&lt;p&gt;Windows Azure: &lt;em&gt;https://azure.microsoft.com/en-us/free/windows-server-on-azure&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[11]&lt;/span&gt;&lt;p&gt;Heroku: &lt;em&gt;https://www.heroku.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[12]&lt;/span&gt;&lt;p&gt;Salesforce.com: &lt;em&gt;https://www.salesforce.com/products/platform/overview&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[13]&lt;/span&gt;&lt;p&gt;Google App Engine: &lt;em&gt;https://cloud.google.com/appengine&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[14]&lt;/span&gt;&lt;p&gt;OpenShift: &lt;em&gt;https://www.redhat.com/en/technologies/cloud-computing/openshift&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[15]&lt;/span&gt;&lt;p&gt;Google workspace: &lt;em&gt;https://workspace.google.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[16]&lt;/span&gt;&lt;p&gt;Dropbox: &lt;em&gt;https://www.dropbox.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[17]&lt;/span&gt;&lt;p&gt;Salesforce: &lt;em&gt;https://www.salesforce.com/ap/?ir=1&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[18]&lt;/span&gt;&lt;p&gt;Cisco WebEx: &lt;em&gt;https://www.webex.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[19]&lt;/span&gt;&lt;p&gt;SAP Concur: &lt;em&gt;https://www.concur.com.sg&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[20]&lt;/span&gt;&lt;p&gt;GoToMeeting: &lt;em&gt;https://www.goto.com/meeting&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[21]&lt;/span&gt;&lt;p&gt;Outlier: &lt;em&gt;https://outlier.ai&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[22]&lt;/span&gt;&lt;p&gt;Supabase: &lt;em&gt;https://supabase.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[23]&lt;/span&gt;&lt;p&gt;Google Cloud Functions: &lt;em&gt;https://cloud.google.com/functions&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[24]&lt;/span&gt;&lt;p&gt;AWS Lambda: &lt;em&gt;https://cloud.google.com/functions&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[25]&lt;/span&gt;&lt;p&gt;Snowflake: &lt;em&gt;https://www.snowflake.com/en&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[26]&lt;/span&gt;&lt;p&gt;Oracle: &lt;em&gt;https://docs.oracle.com/en/cloud/saas/social-data-insight-cloud/csdsr/getting-started-daas.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[27]&lt;/span&gt;&lt;p&gt;HPE GreenLake for storage: &lt;em&gt;https://www.hpe.com/us/en/greenlake/storage.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[28]&lt;/span&gt;&lt;p&gt;Portainer: &lt;em&gt;https://www.portainer.io&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[29]&lt;/span&gt;&lt;p&gt;Perimeter81: &lt;em&gt;https://www.perimeter81.com&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[30]&lt;/span&gt;&lt;p&gt;Nutanix Era: &lt;em&gt;https://www.nutanix.com/blog/nutanix-era-databases-made-simple&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[31]&lt;/span&gt;&lt;p&gt;Oracle Autonomous Database: &lt;em&gt;https://www.oracle.com/my/autonomous-database&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[32]&lt;/span&gt;&lt;p&gt;IBM Cloudant: &lt;em&gt;https://www.ibm.com/cloud/cloudant&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[33]&lt;/span&gt;&lt;p&gt;Thales: &lt;em&gt;https://cpl.thalesgroup.com/access-management/authentication-as-a-service&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[34]&lt;/span&gt;&lt;p&gt;SaaS vs PaaS vs IaaS: What&#x27;s The Difference &amp;amp; How To Choose: &lt;em&gt;https://www.bmc.com/blogs/saas-vs-paas-vs-iaas-whats-the-difference-and-how-to-choose&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[35]&lt;/span&gt;&lt;p&gt;What is Data as a Service (DaaS)?: &lt;em&gt;https://blog.hubspot.com/marketing/data-as-a-service&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[36]&lt;/span&gt;&lt;p&gt;Top 7 NaaS Providers in 2022 for Better Network Infrastructure: &lt;em&gt;https://krispcall.com/blog/top-naas-providers/&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[37]&lt;/span&gt;&lt;p&gt;Authentication As a Service: Architecture, Technologies, and Solutions: &lt;em&gt;https://www.apriorit.com/dev-blog/549-authentication-as-a-service&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[38]&lt;/span&gt;&lt;p&gt;What is iPaas? Guide to Integration Platform as a Service: &lt;em&gt;https://www.techtarget.com/searchcloudcomputing/definition/iPaaS-integration-platform-as-a-service&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[39]&lt;/span&gt;&lt;p&gt;What is API Management?: &lt;em&gt;https://www.ais.com/what-is-api-management&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>aeda1807f93252c80334786917f903a4</guid>
<title>Arctic 基于 Hive 的流批一体实践</title>
<link>https://toutiao.io/k/byhxi7m</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.16796875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/IAyPdLlewxrKIEiaJqaBRicTj5rkdfIGCiaV2qWEiclShjlDVbmgvJibYh6rxKia7tH5GDfYBTCcDMPDYMEbMEiaDmZ2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;12G5-1666334652225&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;heading&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;level&amp;quot;:&amp;quot;h1&amp;quot;,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;hFVI-1666334652224&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;背景&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;},{&amp;quot;type&amp;quot;:&amp;quot;fontSize&amp;quot;,&amp;quot;value&amp;quot;:26}]}]}]}]&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span&gt;随着大数&lt;/span&gt;&lt;span&gt;据业务的发展，基于 Hive 的数仓体系逐渐难以满足日益增长的业务需求，一方面已有很大体量的用户，但是在实时性，功能性上严重缺失；&lt;/span&gt;&lt;span&gt;另一方面 Hudi，Iceberg 这类系统在事务性，快照管理上带来巨大提升，但是对已经存在的 Hive 用户有较大的迁移成本，并且难以满足流式计算毫秒级延迟的需求。&lt;/span&gt;&lt;span&gt;为了满足网易内外部客户对于流批一体业务的需求，网易数帆基于 Apache Iceberg 研发了新一代流式湖仓，相较于 Hudi，Iceberg 等传统湖仓，它提供了流式更新，维表 Join，partial upsert 等功能，并且将 Hive，Iceberg，消息队列整合为一套流式湖仓服务，实现了开箱即用的流批一体，能帮助业务平滑地从 Hive 过渡到 Streaming Lakehouse。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;什么是 Arctic&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Arctic 是搭建在 Apache Iceberg 之上的流式湖仓服务 （ Streaming LakeHouse Service )。相比 Iceberg、Hudi、Delta 等数据湖，Arctic 提供了更加优化的 CDC，流式更新，OLAP 等功能，并且结合了 Iceberg 高效的离线处理能力，Arctic 能服务于更多的流批混用场景。Arctic 还提供了包括结构自优化、并发冲突解决、标准化的湖仓管理功能等，可以有效减少数据湖在管理和优化上负担。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;60uP-1666235110383&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;r644-1666235110384&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic 是搭建在 Apache Iceberg 之上的流式湖仓服务 （ Streaming LakeHouse Service )。相比Iceberg，Hudi、Delta 等数据湖，Arctic 提供了更加优化的CDC，流式更新，OLAP等功能，并且结合了Iceberg高效的离线处理能力，Arctic能服务与更多的流批混用场景。通过Arctic 还提供了包括结构自优化、并发冲突解决、标准化的湖仓管理功能等，可以有效减少数据湖在管理和优化上负担。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.38255698711595637&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/IAyPdLlewxrKIEiaJqaBRicTj5rkdfIGCiarNicicnOpiap6Fk2WLO4DcW6FU6xNqiaAMmzHCZF3B20NDeCl3pichmjlFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1009&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Arctic Table 依赖 Iceberg 作为基础表格式，但是 Arctic 没有倾入 Iceberg 的实现，而是将 Iceberg 做为 lib 使用，同时 Arctic  作为专门为流批一体计算设计的流式湖仓，Arctic Table 还封装了消息队列作为表的一部分，在流式计算场景下可以提供更低的消息延迟，并且提供了流式更新，主键唯一性保证等功能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;流体一批的解决方案&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在实时计算中，由于低延迟的要求，业务通常采用 Kafka 这类消息队列作为流表方案，但是在离线计算中，通常采用 Hive 作为离线表，并且由于消息队列不支持 AP 查询，通常还需要额外的 OLAP 系统如 Kudu 以支持实时计算链接的最终数据输出。这就是典型的 Lambda 架构：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4266409266409266&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUV7XRnWsF3vIvZricfib006YPfKibxmlDW9oH569C91NWJFEvMeicPhw1qQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1554&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;9MwA-1666321128068&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;eyO8-1666321128069&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;这套架构最明显的问题就是多套系统带来的运维成本和重复开发带来的低效率，其次就是两套系统同时建模带来的语义二义性问题，并且真实生产场景中，还会出现实时和离线视图合并的需求，或者引入KV的实时维表关联的需求。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6bny-1666321268615&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;BJXs-1666321268613&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic 的核心目标之一，就是为业务提供基于数据湖的去 Lambda 化，业务系统使用 Arctic 替代 Kafka 和Hive，实现存储底座的流批一体。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;这套架构最明显的问题就是多套系统带来的运维成本和重复开发带来的低效率，其次就是两套系统同时建模带来的语义二义性问题，并且真实生产场景中，还会出现实时和离线视图合并的需求，或者引入 KV 的实时维表关联的需求。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Arctic 的核心目标之一，就是为业务提供基于数据湖的去 Lambda 化，业务系统使用 Arctic 替代 Kafka 和Hive，实现存储底座的流批一体。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43418467583497056&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BULB2sRLUsjXll8dUReDLuCicwyNqAzMdCuVddRT3lVA5eVGmlcNO0Mlw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1527&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;wWjT-1666321377490&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ppC7-1666321377491&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;为此 Arctic 提供了以下功能：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;vhOI-1666322117540&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;M9TM-1666322118648&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;jTRo-1666322117539&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Message Queue 的封装：Arctic 通过将 MessageQueue 和数据湖封装成一张表，实现了 Spark、Flink、Trino 等不同计算引擎访问时不需要区分流表和批表，实现了计算指标上的统一。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;xXEk-1666322200412&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;M9TM-1666322118648&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;eEg7-1666322200411&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;毫秒级流计算延迟：Message Queue 提供了毫秒级的读延迟，并且提供了数据写入和读取的一致性保障。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;wiop-1666322272550&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;M9TM-1666322118648&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6b9e-1666322272549&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;分钟级的OLAP延迟：Arctic 支持流式写入以及流式更新，在查询时通过 Merge On Read 实现分钟级的 OLAP查询&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;为此 Arctic 提供了以下功能：&lt;/span&gt;&lt;/section&gt;&lt;ul yne-block-type=&quot;list&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Message Queue 的封装：Arctic 通过将 MessageQueue 和数据湖封装成一张表，实现了 Spark、Flink、Trino 等不同计算引擎访问时不需要区分流表和批表，实现了计算指标上的统一。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;毫秒级流计算延迟：Message Queue 提供了毫秒级的读延迟，并且提供了数据写入和读取的一致性保障。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;分钟级的 OLAP 延迟：Arctic 支持流式写入以及流式更新，在查询时通过 Merge on Read 实现分钟级的 OLAP 查询。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Table Store&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Arctic Table 由不同的 Table Store 组成，TableStore 是 Arctic 在存储系统中定义的表格式实体，Tablestore 类似于数据库中的 cluster index，代表独立的存储结构，目前分为三种 TableStore。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.51015625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUKzuHbjuf4MhS0xUhe2nWian54Lnjd4onnrsA0wOdgquPawNQrE8gLjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6YMs-1666321114342&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ooAt-1666321114341&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;ChangeStore&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;rrd6-1666322518667&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;lDBN-1666322518666&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;ChangeStroe 是一张 Iceberg 表，它代表了表上的增量数据，或者说最新的数据变更，通常由 Apache Flink 任务实时写入，并用于下游任务近实时的消费。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;TbTO-1666322699712&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;SPLN-1666322699711&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;BaseStore&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;DFi5-1666322706590&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;X6E8-1666322706588&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;BaseStore 也是张 Iceberg 表，它代表了表上的存量数据。通常来自批计算的全量初始化，或者通过Optimizer 定时将来自 ChangeStore 的数据合并入 BaseStore。在对Arctic 表执行查询时， BaseStore 的数据会联合 ChangeStore 的数据一起通过 Merge-On-Read 返回&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;kbXn-1666321114526&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;yWEu-1666321114525&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;LogStore&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;riwW-1666322882880&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;h8aY-1666322882879&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;尽管 Changestore 已经能够为表提供近实时的 CDC 能力，但在对延迟有更高要求的场景仍然需要诸如 Apache Kafka 这样的消息队列提供毫秒级的 CDC 数据分发能力。 而消息队列在 Arctic 表中被封装为 Logstore。它由 Flink 任务实时写入，并用于下游 Flink 任务进行实时消费。&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;color&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;#000000&amp;quot;},{&amp;quot;type&amp;quot;:&amp;quot;backgroundColor&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;rgb(255, 255, 255)&amp;quot;},{&amp;quot;type&amp;quot;:&amp;quot;fontSize&amp;quot;,&amp;quot;value&amp;quot;:16},{&amp;quot;type&amp;quot;:&amp;quot;fontFamily&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;Arial&amp;quot;}]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;ChangeStore&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ChangeStroe 是一张 Iceberg 表，它代表了表上的增量数据，或者说最新的数据变更，通常由 Apache Flink 任务实时写入，并用于下游任务近实时的消费。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;BaseStore&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;BaseStore 也是张 Iceberg 表，它代表了表上的存量数据。通常来自批计算的全量初始化，或者通过Optimizer 定时将来自 ChangeStore 的数据合并入 BaseStore。在对Arctic 表执行查询时， BaseStore 的数据会联合 ChangeStore 的数据一起通过Merge-On-Read 返回。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;LogStore&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;尽管 Changestore 已经能够为表提供近实时的 CDC 能力，但在对延迟有更高要求的场景仍然需要诸如 Apache Kafka 这样的消息队列提供毫秒级的 CDC 数据分发能力。而消息队列在 Arctic 表中被封装为 Logstore。它由 Flink 任务实时写入，并用于下游 Flink 任务进行实时消费。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Arctic 对 Hive 的兼容&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在真实业务实践中，Hive 有着非常庞大的存量用户以及围绕其构建的中台体系，要想一步直接完成从 Hive 到湖仓系统的转换难度非常大，因此如何利用已有的 Hive 生态是 Arctic 实现流批一体首先需要解决的问题。为此 Arctic 提供了 Hive 兼容的能力，以帮助 Hive 用户可以平滑的迁移到流式数仓中。具体到细节，Arctic 提供了以下 Hive 兼容能力：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;T4Gp-1666323712176&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;3xGZ-1666323712177&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;在真实业务实践中，Hive有着非常庞大的存量用户以及围绕Hive构建的中台体系，要想一步直接完成从 Hive 到湖仓系统的转换难度非常大，因此如何利用已有的Hive生态是Arctic实现流批一体首先需要解决的问题。为此Arctic 提供了Hive兼容的能力，以帮助Hive用户可以平滑的迁移到流式数仓中。具体到细节，Arctic 提供了以下Hive 兼容能力：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;44kx-1666324544734&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;0Jq5-1666324546206&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;HbOn-1666324544733&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;数据访问层面的兼容：Arctic 与 Hive原生的读写方式保持兼容，即通过 Arctic 写入的数据，Hive可以读；Hive写入的数据，Arctic可以读。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;pZeU-1666324562726&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;odm2-1666324562709&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;63s5-1666324562727&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;元数据层面的兼容：Arctic 表可以在 HMS 上注册并管理，用户直接对Hive表执行DDL可以被Arctic感知到&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;pwg6-1666324562728&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;odm2-1666324562709&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;wnnv-1666324562729&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive生态的兼容： Arctic 表可以复用目前围绕Hive 的生态，比如可以直接通过 ranger 对 Hive 进行权限管理的方式对 Arctic 表进行授权&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;q8Sf-1666324562730&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;odm2-1666324562709&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;oOOu-1666324562731&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;存量Hive表的兼容： 海量的存量Hive表，如果有实时化的需求，可以以很低的代价将Hive表升级为Arctic表。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;ul yne-block-type=&quot;list&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据访问层面的兼容：Arctic 与 Hive原生的读写方式保持兼容，即通过 Arctic 写入的数据，Hive 可以读；Hive 写入的数据，Arctic 可以读。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;元数据层面的兼容：Arctic 表可以在 HMS 上注册并管理，用户直接对 Hive 表执行 DDL 可以被 Arctic 感知到。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Hive 生态的兼容：Arctic 表可以复用目前围绕 Hive 的生态，比如可以直接通过 ranger 对 Hive 进行权限管理的方式对 Arctic 表进行授权。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;存量 Hive 表的兼容：海量的存量 Hive 表，如果有实时化的需求，可以以很低的代价将 Hive 表升级为 Arctic 表。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Hive 兼容的 Table Store&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;hfi4-1666148867760&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;kLSd-1666148867761&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic Table 依赖 Iceberg 作为基础表格式，但是Arctic没有倾入Iceberg的实现，而是将 Iceberg 做为 lib 使用，同时 Arctic  作为专门为流批一体计算设计的流式湖仓，Arctic Table 还封装了消息队列作为表的一部分，在流式计算场景下可以提供更低的消息延迟，并且提供了流式更新，主键唯一性保证等功能。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;解决 Hive 兼容的首要问题是需要解决 Hive 和 Arctic 文件分布上的不同，在 Arctic 表中被分为 ChangeStore、BaseStore、LogStore 三个不同的 Table Store，从定义上，BaseStore 代表着表的存量数据，这与 Hive 的离线数仓定位是一致的，但是在实现上，Arctic 并未直接将 BaseStore 替换为 Hive Table ， 而是仍然保留 Iceberg Table 作为 BaseStore 的实现以提供 ACID 等特性，并通过目录划分的方式，划分出对 Hive 兼容的目录空间，具体结构如下图所示：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5831622176591376&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUMPDYMwAddUPr5YYPslFKrSzGsBvkw62HstwNvGRlqPrSE1t5ia8wWtw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;974&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;vAwD-1666271607842&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;WWHu-1666271607843&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;重点我们关注 Basestore 下的结构，其中区分了两个目录空间：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;DflP-1666324920467&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;meXL-1666324920472&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ULdf-1666324920466&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;hive location: Hive 表（或分区）的目录空间，会记录在 Hive Meta Store 中，用原生的 Hive reader 会读到这部分数据。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;g0YR-1666324920469&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;meXL-1666324920472&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;MC85-1666324920468&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;iceberg location: 存储近实时写入数据的目录空间，用 Iceberg 管理，包含 insert file 与 delete file，原生的 Hive reader 无法读取到其中的数据， Arctic reader 能读取到。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;KiBk-1666324920471&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;0MYr-1666324920470&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;两个目录空间的设计保障了支持 Arctic 完整特性的基础之上仍然兼容 Hive 原生读取。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;重点我们关注 Basestore 下的结构，其中区分了两个目录空间：&lt;/span&gt;&lt;/section&gt;&lt;ul yne-block-type=&quot;list&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;hive location: Hive 表（或分区）的目录空间，会记录在 Hive Meta Store 中，用原生的 Hive reader 会读到这部分数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;iceberg location: 存储近实时写入数据的目录空间，用 Iceberg 管理，包含 insert file 与 delete file，原生的 Hive reader 无法读取到其中的数据， Arctic reader 能读取到。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;两个目录空间的设计保障了支持 Arctic 完整特性的基础之上仍然兼容 Hive 原生读取。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Hive 数据同步&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Hive location 的划分实现了 Arctic 写入数据对 Hive 查询引擎读的兼容，但是通过 Hive 查询引擎写入的数据或者 schema 变更却无法让 Arctic 立即识别，为此 Arctic 引入了 Hive Syncer 用于识别通过 Hive 查询引擎对表结构和数据的变更。Hive Syncer 包括 2 个目标：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;7yjY-1666324952164&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ILcA-1666324952165&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive location 的划分实现了 Arctic 写入数据对 hive 查询引擎读的兼容，但是通过hive查询引擎写入的数据或者schema 变更却无法让 Arctic 立即识别，为此 Arctic 引入了 Hive Syncer 用于识别通过 hive 查询引擎对表结构和数据的变更。Hive Syncer 包括2个目标：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;3bgi-1666324960891&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;DYAT-1666324960884&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;TZg3-1666324960892&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive 表结构变更同步到 Arctic &amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;jIsi-1666324960894&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;DYAT-1666324960884&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;unordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{},&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;SAf2-1666324960895&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive 表数据变更同步到 Arctic &amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;gebf-1666324952383&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;IgTM-1666324952382&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Table Metadata Sync&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;N7SR-1666324972221&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;iWjf-1666324972222&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive 表结构信息的同步是通过对比 Arctic Table Schema 和 Hive Table Schema 的差异实现的，由于对比代价较小，Arctic 采取的方式是在所有的读取/写入/schema查询/变更 执行前都会执行 Metadata Sync 操作。通过对 Schema 的对比，Arctic 可以自动识别在 Hive 表上的DDL变更。Hive Schema 的同步能力使得 Arctic 的数据开发可以继续复用Hive生态下的数据建模工具，数据开发只需要如同对Hive表建模一样即可完成对 Arctic 表的建模。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;E9vJ-1666324972213&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;twPY-1666324972223&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Table Data Sync&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;}]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ToTg-1666324972224&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;KdxF-1666324972225&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive 表数据的变更的检查是通过分区下的 &amp;quot;,&amp;quot;marks&amp;quot;:[]},{&amp;quot;text&amp;quot;:&amp;quot;transient_lastDdlTime&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;color&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;#000000&amp;quot;},{&amp;quot;type&amp;quot;:&amp;quot;backgroundColor&amp;quot;,&amp;quot;value&amp;quot;:&amp;quot;rgb(255, 255, 255)&amp;quot;}]},{&amp;quot;text&amp;quot;:&amp;quot; 字段识别的，读取Hive分区下数据时会对比分区的修改时间是否和Arctic的metadata中记载是否一致，如果不一致就通过 HDFS 的 listDir 接口获取分区下的全部文件，并对比 Arctic 表最新snapshot 对应的文件，如果文件列表有差异，说明有通过非 Arctic 的途径对Hive表的数据进行了修改，此时Arctic 会生成一个新的快照，对Arctic表的文件信息进行修正。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;4JmA-1666324972226&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;1j6W-1666324972227&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;由于HDFS 的 listDir 操作是一个比较重的操作，默认情况下是通过AMS定时触发 DataSync 检查，如果对数据一致性要求更高，可以通过参数 &amp;quot;,&amp;quot;marks&amp;quot;:[]},{&amp;quot;text&amp;quot;:&amp;quot;base.hive.auto-sync-data-write &amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;inlineCode&amp;quot;}]},{&amp;quot;text&amp;quot;:&amp;quot;配置为每次查询前进行 Data Sync 检查。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Pjmt-1666327400328&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Xadu-1666327400327&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive 数据同步的能力使得用户从离线开发链路迁移到实时开发链接的过程中保留离线数据开发的逻辑，通过离线完成对实时的数据修正，并且保证了实时和离线建模的统一以及指标的统一。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;ul yne-block-type=&quot;list&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Hive 表结构变更同步到 Arctic&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Hive 表数据变更同步到 Arctic&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Table Metadata Sync&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Hive 表结构信息的同步是通过对比 Arctic Table Schema 和 Hive Table Schema 的差异实现的，由于对比代价较小，Arctic 采取的方式是在所有的读取/写入/schema 查询/变更 执行前都会执行 Metadata Sync 操作。通过对 Schema 的对比，Arctic 可以自动识别在 Hive 表上的 DDL 变更。Hive Schema 的同步能力使得 Arctic 的数据开发可以继续复用Hive生态下的数据建模工具，数据开发只需要如同对 Hive 表建模一样即可完成对 Arctic 表的建模。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Table Data Sync&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Hive 表数据的变更的检查是通过分区下的 transient_lastDdlTime 字段识别的，读取 Hive 分区下数据时会对比分区的修改时间是否和 Arctic 的 metadata 中记载是否一致，如果不一致就通过 HDFS 的 listDir 接口获取分区下的全部文件，并对比  Arctic 表最新 snapshot 对应的文件，如果文件列表有差异，说明有通过非 Arctic 的途径对 Hive 表的数据进行了修改，此时 Arctic 会生成一个新的快照，对 Arctic 表的文件信息进行修正。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于 HDFS 的 listDir 操作是一个比较重的操作，默认情况下是通过 AMS 定时触发 DataSync 检查，如果对数据一致性要求更高，可以通过参数 base.hive.auto-sync-data-write 配置为每次查询前进行 Data Sync 检查。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Hive 数据同步的能力使得用户从离线开发链路迁移到实时开发链接的过程中保留离线数据开发的逻辑，通过离线完成对实时的数据修正，并且保证了实时和离线建模的统一以及指标的统一。&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;存量 Hive 表原地升级&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;GQYv-1666320892268&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;heading&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;level&amp;quot;:&amp;quot;h2&amp;quot;,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;WSlO-1666320892266&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;流批一体的解决方案&amp;quot;,&amp;quot;marks&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;bold&amp;quot;},{&amp;quot;type&amp;quot;:&amp;quot;fontSize&amp;quot;,&amp;quot;value&amp;quot;:22}]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;Arctic 不仅支持创建 Hive 兼容表，还支持直接将已经存在的 Hive 表升级为一张 Arctic 下的 Hive 兼容表。在 AMS 上导入 HMS 对应的 hive-site.xml 即可看到 HMS 上对应的表，在对应的 Hive 表上点击 Upgrade 按钮即可对 Hive 表进行原地升级。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5353283458021613&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUcGG9RWJWvTZhicOZSvicpcKggI0WgibHX114XZwtWCAMsiaLic6rc2sSsicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1203&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6i6j-1666326712723&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ToAp-1666326712724&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic 还支持在进行原地升级时指定主键，这样可以将Hive表升级为有主键的Arctic表&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;Arctic 还支持在进行原地升级时指定主键，这样可以将 Hive 表升级为有主键的 Arctic 表。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5193415637860083&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUEtstU4eaFB1K4FFKRPJ0AxDjkP3ib0KttJZ6ukgyHFltpHqBSpicJ7jg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1215&quot;/&gt;&lt;/section&gt;&lt;/article&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Rfc6-1666326712727&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;R1ms-1666326712728&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Hive 的原地升级操作是非常轻量级的，在执行 Upgrade 操作的背后，AMS 仅仅是新建一个空的 Arctic Table，然后扫描Hive目录，并创建一个包括所有Hive 下的 Parquet 文件的 Snapshot 即可，整个过程并不涉及到数据文件的复制和重写。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Hive 的原地升级操作是非常轻量级的，在执行 Upgrade 操作的背后，AMS 仅仅是新建一个空的 Arctic Table，然后扫描 Hive 目录，并创建一个包括所有 Hive 下的 Parquet 文件的 Snapshot 即可，整个过程并不涉及到数据文件的复制和重写。&lt;/span&gt;&lt;/p&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;兼容 Hive 表的权限管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;围绕着 Hive 已经有了一套完整的大数据生态，其中对于表的权限管理和数据脱敏极为重要，当前 Arctic的 Hive 兼容表已经适配了 incubator-kyuubi 项目下的 spark-auth 插件 &lt;/span&gt;&lt;em&gt;&lt;span&gt;https://github.com/apache/incubator-kyuubi  &lt;/span&gt;&lt;/em&gt;&lt;span&gt;通过该插件 Arctic 完成了对 Ranger 的适配，在实际应用中，通过 Ranger 对 Arctic 对应的 Hive 进行授权，在 SparkJob 中即可完成对 Arctic 表的鉴权。&lt;/span&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;CxsA-1666326712730&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;mXC0-1666326712731&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;围绕着Hive已经有了一套完整的大数据生态，其中对于表的权限管理和数据脱敏极为重要，当前Arctic的 Hive兼容表已经适配了 incubator-kyuubi 项目下的 spark-auth 插件 &amp;quot;,&amp;quot;marks&amp;quot;:[]}]},{&amp;quot;type&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;JeQ1-1666326712732&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;link&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;href&amp;quot;:&amp;quot;https://github.com/apache/incubator-kyuubi&amp;quot;},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;8ZCw-1666326712733&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;https://github.com/apache/incubator-kyuubi&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;IoW8-1666326712734&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;  通过该插件 Arctic 完成了对 Ranger 的适配，在实际应用中，通过Ranger对 Arctic对应的Hive进行授权，在SparkJob中即可完成对 Arctic 表的鉴权。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基于Hive 的流批一体实践&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Arctic 的 Hive 兼容模式是为了帮助适应了 Hive 的用户快速上手 Arctic，对于 Hive 用户来说，如果满足以下其中一点：&lt;/span&gt;&lt;/p&gt;&lt;/article&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;tvyP-1664454721630&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;YzPo-1664454721631&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic 的 Hive 兼容模式是为了帮助适应了 Hive 的用户快速上手Arctic，对于Hive用户来说，如果满足以下其中一点：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Giif-1664455570416&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;Y2l5-1664455570991&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;ordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;m3Y0-1664455570415&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;有大量的存量Hive表，并且其中部分Hive表有流式写入、订阅的需求&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;VQOt-1664455641181&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;Y2l5-1664455570991&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;ordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;FwW2-1664455641179&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;在离线场景下有成熟的产品构建，并且希望为离线赋予部分实时的能力，但是又不想对离线平台做过多的改造&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ivyo-1664455690998&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Aiyv-1664455690996&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;即可尝试通过 Arctic Hive 兼容表解决你的痛点。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. 有大量的存量 Hive 表，并且其中部分 Hive 表有流式写入、订阅的需求&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. 在离线场景下有成熟的产品构建，并且希望为离线赋予部分实时的能力，但是又不想对离线平台做过多的改造&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;即可尝试通过 Arctic Hive 兼容表解决你的痛点。&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;实践案例：网易云音乐特征生产工程实时化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;网易云音乐的推荐业务围绕着 Spark+Hive 已经构建了一套成熟的大数据+AI 开发体系，随着业务的增长，业务对整套系统的实时性要求在不断增强，但是直接通过 Flink + Kafka 构建的实时链路并不够完善。在离线链路中围绕着 Hive 有着完善的基础设施和方法论，数据开发和算法工程师通过模型设计中心完成表的设计，数据开发负责数据的摄取，清洗，打宽，聚合等基础处理，算法工程师负责在 DWS 层的数据上实现特征生产算法，分析师通过对 ODS 层、DWD 层以及 DWS 层的表执行Ad Hoc 式的查询并构建分析报表以评估特征数据质量。整套链路层次分明、分工清晰，即最大限度的复用了计算结果，又比较好的统一了指标口径，是典型的 T+1 的数仓建设。但是在实时链路中，数据开发仅仅协助完成原始数据到 Kafka 的摄取，算法工程师需要从 ODS 层数据进行加工，整个链路缺乏数据分层，既不能复用离线计算结果，也无法保证指标的一致性。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Vxwq-1665405187149&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;E6BQ-1665405187148&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;网易云音乐的推荐业务围绕着 Spark+Hive 已经构建了一套成熟的大数据+AI开发体系，随着业务的增长，业务对整套系统的实时性要求在不断增强，但是直接通过Flink + Kafka 构建的实时链路并不够完善。在离线链路中围绕着Hive有着完善的基础设施和方法论，数据开发和算法工程师通过模型设计中心完成表的设计，数据开发负责数据的摄取，清洗，打宽，聚合等基础处理，算法工程师负责在DWS层的数据上实现特征生产算法，分析师通过对ODS层、DWD层以及 DWS层的表执行ADHOC式的查询并构建分析报表以评估特征数据质量。整套链路层次分明、分工清晰，即最大限度的复用了计算结果，又比较好的统一了指标口径，是典型的T+1的数仓建设。但是在实时链路中，数据开发仅仅协助完成原始数据到Kafka 的摄取，算法工程师需要从ODS层数据进行加工，整个链路缺乏数据分层，既不能复用离线计算结果，也无法保证指标的一致性。 &amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;v7lS-1665405752560&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;ZWxZ-1665405752559&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;整个特征工程的生产路线的现状如下图所示：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;整个特征工程的生产路线的现状如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.48359375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BU8WwYCsnuZ9YSA3AjoaYBueZc317hQ1NM9JRpFERZPzWCYxvp3NFU6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;e6ZU-1665405795920&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;nbc8-1665405795919&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;由于存在大量的存量Hive表，并且还有来自 presto 和 impala 的查询链路需要复用ODS和DWD层的Hive表，整个特征工程想直接使用 iceberg 或 hudi 这样的系统其切换代价还是很大的，系统切换期间对系统整体SLA要求较高，新系统磨合过程中如果造成数据产出延迟，对于业务来说是不可接受的。 最终&amp;quot;,&amp;quot;marks&amp;quot;:[]},{&amp;quot;text&amp;quot;:&amp;quot;我们&amp;quot;,&amp;quot;marks&amp;quot;:[]},{&amp;quot;text&amp;quot;:&amp;quot;采用了 Arctic Hive 兼容表的模式， 分阶段的将Hive表升级为 Arctic 下的Hive兼容表，升级后的数据生产链路如下图所示：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;由于存在大量的存量 Hive 表，并且还有来自 Presto 和 Impala 的查询链路需要复用 ODS 和 DWD 层的 Hive 表，整个特征工程想直接使用 Iceberg 或 Hudi 这样的系统其切换代价还是很大的，系统切换期间对系统整体 SLA 要求较高，新系统磨合过程中如果造成数据产出延迟，对于业务来说是不可接受的。最终我们采用了 Arctic Hive 兼容表的模式， 分阶段的将 Hive 表升级为 Arctic 下的 Hive 兼容表，升级后的数据生产链路如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4578125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUdWzdcpuHwQETQPrHKbicxxXZ1b78hkB1OAJJhHrdb5iakcEnhNiaVfg7g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;article data-content=&quot;[{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;XmqC-1664454722169&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;paragraph&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;version&amp;quot;:1},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;bO1t-1664454722168&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;升级后Arctic 为整个特征工程带来了以下好处&amp;quot;,&amp;quot;marks&amp;quot;:[]},{&amp;quot;text&amp;quot;:&amp;quot;：&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;UcLd-1665406426243&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;2OjQ-1665406426976&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;ordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;pOeO-1665406426242&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic 以无感知的方式完成了约2PB级别的Hive表实时化，由于做到Hive的读写兼容，本身T+1的全量数据回补以及分析师的报表查询SQL不用做任何修改，升级过程中保证了不影响离线链路开发。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Arab-1665539323826&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;2OjQ-1665406426976&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;ordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;Oxc0-1665539323824&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;实时特征的生产复用了数仓DWS层数据，不需要从ODS层直接构建特征算法，而数仓的清洗、聚合均由数据开发完成，提升了算法工程师的人效，使得算法工程师可以更好的专注于特征算法本身。平均下来每个算法节省人效约1天。&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;zI8g-1665406554745&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;2OjQ-1665406426976&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;ordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;FVBU-1665406554744&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;完成了实时链路和离线链路的统一，在数据血缘，数据指标，模型设计上可以做到更好的数据治理&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]},{&amp;quot;type&amp;quot;:&amp;quot;block&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;jbYa-1665406696354&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;list-item&amp;quot;,&amp;quot;data&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;2OjQ-1665406426976&amp;quot;,&amp;quot;listType&amp;quot;:&amp;quot;ordered&amp;quot;,&amp;quot;listLevel&amp;quot;:1,&amp;quot;style&amp;quot;:{}},&amp;quot;nodes&amp;quot;:[{&amp;quot;type&amp;quot;:&amp;quot;text&amp;quot;,&amp;quot;id&amp;quot;:&amp;quot;6IGE-1665406696353&amp;quot;,&amp;quot;leaves&amp;quot;:[{&amp;quot;text&amp;quot;:&amp;quot;Arctic 本身可以为 ODS 和 DWD 层的表配置更激进的Optimize 策略，以10分钟的频率对Hive Table的数据进行Overwrite, 分析师可以享受到更加实时的分析报表&amp;quot;,&amp;quot;marks&amp;quot;:[]}]}]}]&quot;&gt;&lt;section&gt;&lt;span&gt;升级后Arctic 为整个特征工程带来了以下好处：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1. Arctic 以无感知的方式完成了约 2PB 级别的 Hive 表实时化，由于做到 Hive 的读写兼容，本身 T+1 的全量数据回补以及分析师的报表查询 SQL 不用做任何修改，升级过程中保证了不影响离线链路开发。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2. 实时特征的生产复用了数仓 DWS 层数据，不需要从 ODS 层直接构建特征算法，而数仓的清洗、聚合均由数据开发完成，提升了算法工程师的人效，使得算法工程师可以更好的专注于特征算法本身。平均下来每个算法节省人效约 1 天。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3. 完成了实时链路和离线链路的统一，在数据血缘，数据指标，模型设计上可以做到更好的数据治理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4. Arctic 本身可以为 ODS 和 DWD 层的表配置更激进的 Optimize 策略，以 10 分钟的频率对 Hive Table 的数据进行 Overwrite, 分析师可以享受到更加实时的分析报表。&lt;/span&gt;&lt;/section&gt;&lt;/article&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;本文介绍了网易数帆开源的新一代流式湖仓 Arctic 以及其基于 Hive 的流批一体实践。希望读者可以经此文章了解 Arctic 并对业务构建流批一体的数据湖有帮助。感谢一直一来对 Arctic 社区的支持，如果您对 Arctic 、湖仓一体、流批一体感兴趣，并想一起推动它的发展，请在 Github 上关注 Arctic 项目&lt;/span&gt;&lt;em&gt;&lt;span&gt;https://github.com/NetEase/arctic&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt; 。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;作者简介：&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;em&gt;张永翔，网易数帆资深平台开发工程师&lt;em&gt;&lt;span&gt;，Arctic Committer&lt;/span&gt;&lt;/em&gt;，6 年从业经验，先后从事网易 RDS、数据中台、实时计算平台等开发，目前主要负责 Arctic 流式湖仓服务开发&lt;/em&gt;&lt;em&gt;。&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;em&gt;胡溢胜，网易云音乐数据专家，10 年数仓经验，涉及通信、互联网、环保、医疗等行业。2020 年加入网易云音乐，目前负责网易云音乐社交直播业务线的数据建设。&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;em/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/article&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/iaOz7l1bIBYAhWm26iaVwfJRez3fZiaq2BUI52C8UsibUCap0VZqv7Hd379IdqmTNwv3BJRAEFq6XWmOIkam2n3VIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>