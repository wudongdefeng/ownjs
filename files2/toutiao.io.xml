<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>e651ea9ec44d445584ecab3bcf68ce02</guid>
<title>一文搞懂 Redis</title>
<link>https://toutiao.io/k/kn8zedh</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;作者： 京东物流 刘丽侠 姚再毅 康睿 刘斌 李振&lt;/p&gt;

&lt;h1&gt;一、Redis的特性&lt;/h1&gt;

&lt;h2&gt;1.1 Redis为什么快？&lt;/h2&gt;





&lt;ul&gt;
&lt;li&gt;  命令执行是单线程，因为是基于内存操作，单次执行的时间快于线程切换时间，同时通信采用多路复用&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
&lt;li&gt;  Redis本身就是一个k-v结构，类似于hashMap，所以查询性能接近于O(1)&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
&lt;li&gt;  同时redis自己底层数据结构支持，比如跳表、SDS&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
&lt;li&gt;  lO多路复用，单个线程中通过记录跟踪每一个sock（I/O流）的状态来管理多个I/O流&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;1.2 Redis其他特性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;  更丰富的数据类型，虽然都是k、v结构，value可以存储很多的数据类型&lt;/li&gt;
&lt;/ul&gt;



&lt;ul&gt;
&lt;li&gt;  完善的内存管理机制、保证数据一致性：持久化机制、过期策略&lt;/li&gt;
&lt;/ul&gt;









&lt;h2&gt;1.3 Redis高可用&lt;/h2&gt;







&lt;h1&gt;二、Redis数据类型以及使用场景&lt;/h1&gt;

&lt;p&gt;Redis的数据类型有String、Hash、Set、List、Zset、bitMap（基于String类型）、 Hyperloglog（基于String类型）、Geo（地理位置）、Streams流。&lt;/p&gt;

&lt;h2&gt;2.1 String&lt;/h2&gt;

&lt;h3&gt;2.1.1 基本指令&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;// 批量设置
&amp;gt; mset key1 value1 key2 value2
// 批量获取
&amp;gt; mget key1 key2
// 获取长度
&amp;gt; strlen key  
//  字符串追加内容
&amp;gt; append key xxx
// 获取指定区间的字符
&amp;gt; getrange key 0 5
// 整数值递增 (递增指定的值)
&amp;gt; incr intkey (incrby intkey 10)
// 当key 存在时将覆盖
&amp;gt; SETEX key seconds value
// 将 key 的值设为 value ，当且仅当 key 不存在。
&amp;gt; SETNX key value
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.1.2 应用场景&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 缓存相关场景 缓存、 token（跟过期属性完美契合）&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 线程安全的计数场景 （软限流、分布式ID等）&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;2.2 Hash&lt;/h2&gt;

&lt;h3&gt;2.2.1 基本指令&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;// 将哈希表 key 中的域 field 的值设为 value 。
&amp;gt; HSET key field value
// 返回哈希表 key 中给定域 field 的值。
&amp;gt;  HGET key field
// 返回哈希表 key 中的所有域。
&amp;gt; HKEYS key
// 返回哈希表 key 中所有域的值。
&amp;gt;  HVALS key
// 为哈希表 key 中的域 field 的值加上增量 increment 。
&amp;gt; HINCRBY key field increment
// 查看哈希表 key 中，给定域 field 是否存在。
&amp;gt; HEXISTS key field
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.2.2 应用场景&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 存储对象类的数据(官网说的）比如一个对象下有多个字段&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 统计类的数据，可以对单个统计数据进行单独操作&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;2.3 List&lt;/h2&gt;

&lt;p&gt;存储有序的字符串列表，元素可以重复。列表的最大长度为 2^32 - 1 个元素（4294967295，每个列表超过 40 亿个元素）。&lt;/p&gt;

&lt;h3&gt;2.3.1 基本指令&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;// 将一个或多个值 value 插入到列表 key 的表头
&amp;gt; LPUSH key value [value ...]
// 将一个或多个值 value 插入到列表 key 的表尾(最右边)。
&amp;gt; RPUSH key value [value ...]
// 移除并返回列表 key 的头元素。
&amp;gt; LPOP key
// 移除并返回列表 key 的尾元素。
&amp;gt; RPOP key
// BLPOP 是列表的阻塞式(blocking)弹出原语。
&amp;gt; BLPOP key [key ...] timeout
// BRPOP 是列表的阻塞式(blocking)弹出原语。
&amp;gt; BRPOP key [key ...] timeout
// 获取指点位置元素
&amp;gt; LINDEX key index
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.3.2 应用场景&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 用户消息时间线&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为list是有序的，所以我们可以先进先出，先进后出的列表都可以做&lt;/p&gt;

&lt;h2&gt;2.4 Set&lt;/h2&gt;

&lt;h3&gt;2.4.1 基本指令&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;// 将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略。
&amp;gt; SADD key member [member ...]
// 返回集合 key 中的所有成员。
&amp;gt; SMEMBERS key
// 返回集合 key 的基数(集合中元素的数量)。
&amp;gt; SCARD key
// 如果命令执行时，只提供了 key 参数，那么返回集合中的一个随机元素。
&amp;gt; SRANDMEMBER key [count]
// 移除并返回集合中的一个随机元素。
&amp;gt; SPOP key
// 移除集合 key 中的一个或多个 member 元素，不存在的 member 元素会被忽略。
&amp;gt; SREM key member [member ...]
// 判断 member 元素是否集合 key 的成员。
&amp;gt; SISMEMBER key member
// 获取前一个集合有而后面1个集合没有的
&amp;gt; sdiff huihuiset huihuiset1
// 获取交集
&amp;gt; sinter huihuiset huihuiset1
// 获取并集
&amp;gt; sunion huihuiset huihuiset1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.4.2 应用场景&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 抽奖 spop跟srandmember随机弹出或者获取元素&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 点赞、签到等，sadd集合存储&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 交集并集 关注等场景&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;2.5 ZSet(SortedSet)&lt;/h2&gt;

&lt;p&gt;sorted set，有序的set，每个元素有个score。&lt;/p&gt;

&lt;p&gt;score相同时，按照key的ASCII码排序。&lt;/p&gt;

&lt;h3&gt;2.5.1 基本指令&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;//将一个或多个 member 元素及其 score 值加入到有序集 key 当中。
&amp;gt; ZADD key score member [[score member] [score member] ...]
// 返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递增(从小到大)来排序
&amp;gt; ZRANGE key start stop [WITHSCORES]
// 返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递减(从大到小)来排列。
&amp;gt; ZREVRANGE key start stop [WITHSCORES]
// 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。
&amp;gt;  ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]
// 移除有序集 key 中的一个或多个成员，不存在的成员将被忽略。
&amp;gt; ZREM key member [member ...]
// 返回有序集 key 的基数。
&amp;gt; ZCARD key
// 为有序集 key 的成员 member 的 score 值加上增量 increment 。
&amp;gt; ZINCRBY key increment member
// 返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量。
&amp;gt; ZCOUNT key min max
// 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。
&amp;gt; ZRANK key member
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.5.2 应用场景&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 排行榜&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;三、Redis的事务&lt;/h1&gt;

&lt;h2&gt;3.1 事务基本操作&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// 1. multi命令开启事务，exec命令提交事务
127.0.0.1:6379&amp;gt; multi
OK
127.0.0.1:6379(TX)&amp;gt; set k1 v1
QUEUED
127.0.0.1:6379(TX)&amp;gt; set k2 v2
QUEUED
127.0.0.1:6379(TX)&amp;gt; exec
1) OK
2) OK
// 2. 组队的过程中可以通过discard来放弃组队。
 127.0.0.1:6379&amp;gt; multi
OK
 127.0.0.1:6379(TX)&amp;gt; set k3 v3
QUEUED
 127.0.0.1:6379(TX)&amp;gt; set k4 v4
QUEUED
 127.0.0.1:6379(TX)&amp;gt; discard
OK
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;3.2 Redis事务特性&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt; 单独的隔离操作&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;事务中的所有命令都会序列化、按顺序地执行。&lt;/p&gt;

&lt;p&gt;事务在执行过程中，不会被其他客户端发送来的命令请求所打断。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 没有隔离级别的概念&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;队列中的命令没有提交之前，都不会被实际地执行，因为事务提交之前任何指令都不会被实际执行，也就不存在“事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头疼的问题。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 不保证原子性&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。&lt;/p&gt;

&lt;h1&gt;四、Redis 分布式锁&lt;/h1&gt;

&lt;h2&gt;4.1 Lua 实现分布式锁&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;local lockSet = redis.call(&#x27;exists&#x27;, KEYS[1])
if lockSet == 0 
    then
        redis.call(&#x27;set&#x27;, KEYS[1], ARG[1])
        redis.call(&#x27;expire&#x27;, KEYS[1], ARG[2])
    end
return lockSet
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;五、Redis总体数据结构&lt;/h1&gt;

&lt;h2&gt;5.1 Redis dict字典&lt;/h2&gt;

&lt;h3&gt;5.1.1 RedisDb数据接口（server.h文件）&lt;/h3&gt;

&lt;p&gt;数据最外层的结构为RedisDb&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct redisDb {
    dict *dict; /* The keyspace for this DB */ //数据库的键
    dict *expires; /* Timeout of keys with a timeout set */ //设置了超时时间的键
    dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ //客户端等待的keys
    dict *ready_keys; /* Blocked keys that received a PUSH */
    dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */
    int id; /* Database ID */ //所在数 据库ID
    long long avg_ttl; /* Average TTL, just for tats */ //平均TTL，仅用于统计
    unsigned long expires_cursor; /* Cursor of the active expire cycle. */
    list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */
} redisDb;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.1.2 dict数据结构（dict.h文件）&lt;/h3&gt;

&lt;p&gt;我们发现数据存储在dict中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct dict {
    dictType *type; //理解为面向对象思想，为支持不同的数据类型对应dictType抽象方法，不同的数据类型可以不同实现
    void *privdata; //也可不同的数据类型相关，不同类型特定函数的可选参数。
    dictht ht[2]; //2个hash表，用来数据存储 2个dictht
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */ // rehash标记 -1代表不再rehash
    unsigned long iterators; /* number of iterators currently running */
} dict;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.1.3 dictht结构（dict.h文件）&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;typedef struct dictht {
    dictEntry **table; //dictEntry 数组
    unsigned long size; //数组大小 默认为4 #define DICT_HT_INITIAL_SIZE 4
    unsigned long sizemask; //size-1 用来取模得到数据的下标值
    unsigned long used; //改hash表中已有的节点数据
} dictht;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.1.4 dictEntry节点结构（dict.h文件）&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;typedef struct dictEntry {
    void *key; //key
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v; //value
    struct dictEntry *next; //指向下一个节点
} dictEntry;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.1.5 RedisObject（service.h文件）&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;/* Objects encoding. Some kind of objects like Strings and
Hashes can be
* internally represented in multiple ways. The &#x27;encoding&#x27;
field of the object
* is set to one of this fields for this object. */
#define OBJ_ENCODING_RAW 0 /* Raw representation */
#define OBJ_ENCODING_INT 1 /* Encoded as integer */
#define OBJ_ENCODING_HT 2 /* Encoded as hash table */
#define OBJ_ENCODING_ZIPMAP 3 /* Encoded as zipmap */
#define OBJ_ENCODING_LINKEDLIST 4 /* No longer used: old
list encoding. */
#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */
#define OBJ_ENCODING_INTSET 6 /* Encoded as intset */
#define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */
#define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string
encoding */
#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list
of ziplists */
#define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree
of listpacks */
#define LRU_BITS 24
#define LRU_CLOCK_MAX ((1&amp;lt;&amp;lt;LRU_BITS)-1) /* Max value of
obj-&amp;gt;lru */
#define LRU_CLOCK_RESOLUTION 1000 /* LRU clock resolution
in ms */
#define OBJ_SHARED_REFCOUNT INT_MAX /* Global object
never destroyed. */
#define OBJ_STATIC_REFCOUNT (INT_MAX-1) /* Object
allocated in the stack. */
#define OBJ_FIRST_SPECIAL_REFCOUNT OBJ_STATIC_REFCOUNT
typedef struct redisObject {
unsigned type:4; //数据类型 string hash list
unsigned encoding:4; //底层的数据结构 跳表
unsigned lru:LRU_BITS; /* LRU time (relative to global
lru_clock) or
* LFU data (least significant
8 bits frequency
* and most significant 16 bits
access time). */
int refcount; //用于回收，引用计数法
void *ptr; //指向具体的数据结构的内存地址 比如 跳表、压缩列表
} robj;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;5.2 Redis数据结构图&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f19ecd561f94d7099b38881b122cc92%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;2.jpg&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;5.3 Redis扩容机制&lt;/h2&gt;

&lt;p&gt;因为我们的dictEntry数组默认大小是4，如果不进行扩容，那么我们所有的数据都会以链表的形式添加至数组下标 随着数据量越来越大，之前只需要hash取模就能得到下标位置，现在得去循环我下标的链表，所以性能会越来越慢，当我们的数据量达到一定程度后，我们就得去触发扩容操作。&lt;/p&gt;

&lt;h3&gt;5.3.1 什么时候扩容&lt;/h3&gt;

&lt;h4&gt;5.3.1.1 扩容机制&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt; 当没有fork子进程在进行RDB或AOF持久化时，ht[0]的used大于size时，触发扩容&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 如果有子进程在进行RDB或者AOF时，ht[0]的used大于等于size的5倍的时候，会触发扩容&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;5.3.1.2 源码验证&lt;/h4&gt;

&lt;p&gt;扩容，肯定是在添加数据的时候才会扩容，所以我们找一个添加数据的入口。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 入口，添加或替换dictReplace (dict.c文件)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int dictReplace(dict *d, void *key, void *val) {
    dictEntry *entry, *existing, auxentry;
    /* Try to add the element. If the key
    * does not exists dictAdd will succeed. */
    entry = dictAddRaw(d,key,&amp;amp;existing);
    if (entry) {
        dictSetVal(d, entry, val);
        return 1;
    }
    /* Set the new value and free the old one. Note that
    it is important
    * to do that in this order, as the value may just be
    exactly the same
    * as the previous one. In this context, think to
    reference counting,
    * you want to increment (set), and then decrement
    (free), and not the
    * reverse. */
    auxentry = *existing;
    dictSetVal(d, existing, val);
    dictFreeVal(d, &amp;amp;auxentry);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; 进入dictAddRaw方法 （dict.c文件）&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing){
    long index;
    dictEntry *entry;
    dictht *ht;

    if (dictIsRehashing(d)) _dictRehashStep(d); //如果正在Rehash 进行渐进式hash 按步rehash

    /* Get the index of the new element, or -1 if
    * the element already exists. */
    if ((index = _dictKeyIndex(d, key, dictHashKey(d,key),existing)) == -1)
        return NULL;

    /* Allocate the memory and store the new entry.
    * Insert the element in top, with the assumption that
    in a database
    * system it is more likely that recently added
    entries are accessed
    * more frequently. */
    //如果在hash 放在ht[1] 否则放在ht[0]
    ht = dictIsRehashing(d) ? &amp;amp;d-&amp;gt;ht[1] : &amp;amp;d-&amp;gt;ht[0];
    entry = zmalloc(sizeof(*entry));
    //采用头插法插入hash桶
    entry-&amp;gt;next = ht-&amp;gt;table[index];
    ht-&amp;gt;table[index] = entry;
    //已使用++
    ht-&amp;gt;used++;

    /* Set the hash entry fields. */
    dictSetKey(d, entry, key);
    return entry;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; 得到数据下标的方法 _dictKeyIndex (dict.c文件)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;static long _dictKeyIndex(dict *d, const void *key,uint64_t hash, dictEntry **existing){
    unsigned long idx, table;
    dictEntry *he;
    if (existing) *existing = NULL;

    /* Expand the hash table if needed */
    //扩容如果需要
    if (_dictExpandIfNeeded(d) == DICT_ERR)
        return -1;
    //比较是否存在这个值
    for (table = 0; table &amp;lt;= 1; table++) {
        idx = hash &amp;amp; d-&amp;gt;ht[table].sizemask;
        /* Search if this slot does not already contain
        the given key */
        he = d-&amp;gt;ht[table].table[idx];
        while(he) {
            if (key==he-&amp;gt;key || dictCompareKeys(d, key,he-&amp;gt;key)) {
                if (existing) *existing = he;
                    return -1;
                }
            he = he-&amp;gt;next;
        }
        if (!dictIsRehashing(d)) break;
    }
    return idx;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; _dictExpandIfNeeded 验证是否需要扩容 （dict.c文件）&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;/* Expand the hash table if needed */
static int _dictExpandIfNeeded(dict *d){
    /* Incremental rehashing already in progress. Return.*/
    if (dictIsRehashing(d)) return DICT_OK; //正在rehash，返回

    /* If the hash table is empty expand it to the initialsize. */
    //如果ht[0]的长度为0，设置默认长度4 dictExpand为扩容的关键方法
    if (d-&amp;gt;ht[0].size == 0) 
            return dictExpand(d,DICT_HT_INITIAL_SIZE);

    //扩容条件 hash表中已使用的数量大于等于 hash表的大小
    //并且dict_can_resize为1 或者 已使用的大小大于hash表大小的 5倍，大于等于1倍的时候，下面2个满足一个条件即可
    if (d-&amp;gt;ht[0].used &amp;gt;= d-&amp;gt;ht[0].size &amp;amp;&amp;amp;
        (dict_can_resize || d-&amp;gt;ht[0].used/d-&amp;gt;ht[0].size &amp;gt;dict_force_resize_ratio)){
        //扩容成原来的2倍
        return dictExpand(d, d-&amp;gt;ht[0].used*2);
    }
    return DICT_OK;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.3.2 怎么扩容&lt;/h3&gt;

&lt;h4&gt;5.3.2.1 扩容步骤&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt; 当满足我扩容条件，触发扩容时，判断是否在扩容，如果在扩容，或者 扩容的大小跟我现在的ht[0].size一样，这次扩容不做&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; new一个新的dictht，大小为ht[0].used * 2（但是必须向上2的幂，比 如6 ，那么大小为8） ，并且ht[1]=新创建的dictht&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 我们有个更大的table了，但是需要把数据迁移到ht[1].table ，所以将 dict的rehashidx（数据迁移的偏移量）赋值为0 ，代表可以进行数据迁 移了，也就是可以rehash了&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 等待数据迁移完成，数据不会马上迁移，而是采用渐进式rehash，慢慢的把数据迁移到ht[1]&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 当数据迁移完成，ht[0].table=ht[1] ，ht[1] .table = NULL、ht[1] .size = 0、ht[1] .sizemask = 0、 ht[1] .used = 0&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 把dict的rehashidex=-1&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;5.3.2.2 源码验证&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt; dictExpand方法在_dictExpandIfNeeded 方法中调用 (dict.c文件)，为扩容的关键方法&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int dictExpand(dict *d, unsigned long size){
    /* the size is invalid if it is smaller than the
    number of
    * elements already inside the hash table */
    //正在扩容，不允许第二次扩容，或者ht[0]的数据量大于扩容后的数量，没有意义，这次不扩容
    if (dictIsRehashing(d) || d-&amp;gt;ht[0].used &amp;gt; size)
        return DICT_ERR;

    dictht n; /* the new hash table */
    //得到最接近2的幂 跟hashMap思想一样
    unsigned long realsize = _dictNextPower(size);

    /* Rehashing to the same table size is not useful. */
    //如果跟ht[0]的大小一致 直接返回错误
    if (realsize == d-&amp;gt;ht[0].size) return DICT_ERR;

    /* Allocate the new hash table and initialize all
    pointers to NULL */
    //为新的dictht赋值
    n.size = realsize;
    n.sizemask = realsize-1;
    n.table = zcalloc(realsize*sizeof(dictEntry*));
    n.used = 0;

    /* Is this the first initialization? If so it&#x27;s not
    really a rehashing
    * we just set the first hash table so that it can
    accept keys. */
    //ht[0].table为空，代表是初始化
    if (d-&amp;gt;ht[0].table == NULL) {
        d-&amp;gt;ht[0] = n;
        return DICT_OK;
    }

    /* Prepare a second hash table for incremental rehashing */
    //将扩容后的dictht赋值给ht[1]
    d-&amp;gt;ht[1] = n;
    //标记为0，代表可以开始rehash
    d-&amp;gt;rehashidx = 0;
    return DICT_OK;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.3.3 数据怎么迁移（渐进式hash）&lt;/h3&gt;

&lt;h4&gt;5.3.3.1 迁移方式&lt;/h4&gt;

&lt;p&gt;假如一次性把数据全部迁移会很耗时间，会让单条指令等待很久，会形成阻塞。&lt;/p&gt;

&lt;p&gt;所以，redis采用渐进式Rehash，所谓渐进式，就是慢慢的，不会一次性把所有数据迁移。&lt;/p&gt;

&lt;p&gt;那什么时候会进行渐进式数据迁移？&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 每次进行key的crud操作都会进行一个hash桶的数据迁移&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 定时任务，进行部分数据迁移&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;5.3.3.2 源码验证&lt;/h4&gt;

&lt;h5&gt;&lt;strong&gt;CRUD触发都会触发_dictRehashStep（渐进式hash）&lt;/strong&gt;&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt; 每次增删改的时候都会调用_dictRehashStep方法&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;if (dictIsRehashing(d)) _dictRehashStep(d); //这个代码在增删改查的方法中都会调用
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; _dictRehashStep方法&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;static void _dictRehashStep(dict *d) {
    if (d-&amp;gt;iterators == 0) dictRehash(d,1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; dictRehash方法&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int dictRehash(dict *d, int n) {
    int empty_visits = n*10; /* Max number of empty
    buckets to visit. */ //要访问的最大的空桶数 防止此次耗时过长

    if (!dictIsRehashing(d)) return 0; //如果没有在rehash返回0

    //循环，最多1次，并且ht[0]的数据没有迁移完 进入循环
    while(n-- &amp;amp;&amp;amp; d-&amp;gt;ht[0].used != 0) {
        dictEntry *de, *nextde;
        /* Note that rehashidx can&#x27;t overflow as we are
        sure there are more
        * elements because ht[0].used != 0 */
        assert(d-&amp;gt;ht[0].size &amp;gt; (unsigned long)d-&amp;gt;rehashidx);
        //rehashidx rehash的索引，默认0 如果hash桶为空 进入自旋 并且判断是否到了最大的访问空桶数
        while(d-&amp;gt;ht[0].table[d-&amp;gt;rehashidx] == NULL) {
            d-&amp;gt;rehashidx++;
            if (--empty_visits == 0) return 1;
        }
        de = d-&amp;gt;ht[0].table[d-&amp;gt;rehashidx]; //得到ht[0]的下标为rehashidx桶
        /* Move all the keys in this bucket from the old
        to the new hash HT */
        while(de) { //循环hash桶的链表 并且转移到ht[1]
            uint64_t h;
            nextde = de-&amp;gt;next;
            /* Get the index in the new hash table */
            h = dictHashKey(d, de-&amp;gt;key) &amp;amp; d-
            &amp;gt;ht[1].sizemask;
            de-&amp;gt;next = d-&amp;gt;ht[1].table[h]; //头插
            d-&amp;gt;ht[1].table[h] = de;
            d-&amp;gt;ht[0].used--;
            d-&amp;gt;ht[1].used++;
            de = nextde;
        }
        //转移完后 将ht[0]相对的hash桶设置为null
        d-&amp;gt;ht[0].table[d-&amp;gt;rehashidx] = NULL;
        d-&amp;gt;rehashidx++;
    }
    /* Check if we already rehashed the whole table... */
    //ht[0].used=0 代表rehash全部完成
    if (d-&amp;gt;ht[0].used == 0) {
        //清空ht[0]table
        zfree(d-&amp;gt;ht[0].table);
        //将ht[0] 重新指向已经完成rehash的ht[1]
        d-&amp;gt;ht[0] = d-&amp;gt;ht[1];
        //将ht[1]所有数据重新设置
        _dictReset(&amp;amp;d-&amp;gt;ht[1]);
        //设置-1,代表rehash完成
        d-&amp;gt;rehashidx = -1;
        return 0;
    }
    /* More to rehash... */
    return 1;
}

//将ht[1]的属性复位
static void _dictReset(dictht *ht)
{
    ht-&amp;gt;table = NULL;
    ht-&amp;gt;size = 0;
    ht-&amp;gt;sizemask = 0;
    ht-&amp;gt;used = 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h6&gt;&lt;strong&gt;定时任务触发&lt;/strong&gt;&lt;/h6&gt;

&lt;p&gt;再讲定时任务之前，我们要知道Redis中有个时间事件驱动,在 server.c文件下有个serverCron 方法。&lt;/p&gt;

&lt;p&gt;serverCron 每隔多久会执行一次，执行频率根据redis.conf中的hz配置，serverCorn中有个方法databasesCron()&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 定时方法serverCron&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    //.......
    /* We need to do a few operations on clients
    asynchronously. */
    clientsCron();
    /* Handle background operations on Redis databases. */
    databasesCron(); //处理Redis数据库上的后台操作。
    //.......
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; databasesCron方法&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;void databasesCron(void) {
    /* Expire keys by random sampling. Not required for
    slaves
    * as master will synthesize DELs for us. */
    if (server.active_expire_enabled) {
        if (iAmMaster()) {
            activeExpireCycle(ACTIVE_EXPIRE_CYCLE_SLOW);
        } else {
            expireSlaveKeys();
        }
    }
    /* Defrag keys gradually. */
    activeDefragCycle();
    /* Perform hash tables rehashing if needed, but only
    if there are no
    * other processes saving the DB on disk. Otherwise
    rehashing is bad
    * as will cause a lot of copy-on-write of memory
    pages. */
    if (!hasActiveChildProcess()) {
        /* We use global counters so if we stop the
        computation at a given
        * DB we&#x27;ll be able to start from the successive
        in the next
        * cron loop iteration. */
        static unsigned int resize_db = 0;
        static unsigned int rehash_db = 0;
        int dbs_per_call = CRON_DBS_PER_CALL;
        int j;
        /* Don&#x27;t test more DBs than we have. */
        if (dbs_per_call &amp;gt; server.dbnum) 
            dbs_per_call = server.dbnum;
        /* Resize */
        for (j = 0; j &amp;lt; dbs_per_call; j++) {
            tryResizeHashTables(resize_db % server.dbnum);
            resize_db++;
        }
        /* Rehash */ //Rehash逻辑
        if (server.activerehashing) {
            for (j = 0; j &amp;lt; dbs_per_call; j++) {
                //进入incrementallyRehash
                int work_done = incrementallyRehash(rehash_db);
                if (work_done) {
                    /* If the function did some work, stop
                        here, we&#x27;ll do
                        * more at the next cron loop. */
                    break;
                } else {
                    /* If this db didn&#x27;t need rehash,
                        we&#x27;ll try the next one. */
                    rehash_db++;
                    rehash_db %= server.dbnum;
                }
            }
        }
    }
} 
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; 进入incrementallyRehash方法（server.c)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int incrementallyRehash(int dbid) {
    /* Keys dictionary */
    if (dictIsRehashing(server.db[dbid].dict)) {
        dictRehashMilliseconds(server.db[dbid].dict,1);
        return 1; 
        /* already used our millisecond for this
        loop... */
    }
    /* Expires */
    if (dictIsRehashing(server.db[dbid].expires)) {
        dictRehashMilliseconds(server.db[dbid].expires,1);
        return 1; /* already used our millisecond for this
        loop... */
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; 进入dictRehashMilliseconds（dict.c）&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int dictRehashMilliseconds(dict *d, int ms) {
    long long start = timeInMilliseconds();
    int rehashes = 0;
    //进入rehash方法 dictRehash 去完成渐进时HASH
    while(dictRehash(d,100)) {
        rehashes += 100;
        //判断是否超时
        if (timeInMilliseconds()-start &amp;gt; ms) break;
    }
    return rehashes;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;5.4 String类型数据结构&lt;/h2&gt;

&lt;p&gt;Redis中String的底层没有用c的char来实现，而是采用了SDS（simple Dynamic String）的数据结构来实现。并且提供了5种不同的类型&lt;/p&gt;

&lt;h3&gt;5.4.1 SDS数据结构定义（sds.h文件）&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;typedef char *sds;
/* Note: sdshdr5 is never used, we just access the flags
    byte directly.
    * However is here to document the layout of type 5 SDS
strings. */
struct __attribute__ ((__packed__)) sdshdr5 {
    unsigned char flags; /* 3 lsb of type, and 5 msb of
        string length */
    char buf[];
}

struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len;  /* used */ //已使用的长度
    uint8_t alloc; /* excluding the header and null terminator */ //分配的总容量 不包含头和空终止符
    unsigned char flags; /* 3 lsb of type, 5 unused bits */ //低三位类型 高5bit未使用
    char buf[]; //数据buf 存储字符串数组
};

struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null
    terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits
    */
    char buf[];
};

struct __attribute__ ((__packed__)) sdshdr32 {
    uint32_t len; /* used */
    uint32_t alloc; /* excluding the header and null
    terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits
    */
    char buf[];
};

struct __attribute__ ((__packed__)) sdshdr64 {
    uint64_t len; /* used */
    uint64_t alloc; /* excluding the header and null
    terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits
    */
    char buf[];
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.4.2 SDS数据结构的优势&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; char字符串不记录自身长度，所以获取一个字符串长度的复杂度是O(n)，但是SDS记录分配的长度alloc，已使用的长度len，获取长度为 O(1)&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 减少修改字符串带来的内存重分配次数&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 空间预分配，SDS长度如果小于1MB，预分配跟长度一样的，大于1M，每次跟len的大小多1M&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 惰性空间释放，截取的时候不马上释放空间，供下次使用！同时提供相应的释放SDS未使用空间的API&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 二进制安全&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;5.5 Hash类型数据结构&lt;/h2&gt;

&lt;p&gt;Redis的字典相当于Java语言中的HashMap，他是无序字典。内部结构上同样是数组 + 链表二维结构。第一维hash的数组位置碰撞时，就会将碰撞的元素使用链表串起来。&lt;/p&gt;

&lt;h3&gt;5.5.1 Hash数据结构图&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/295ec2e9e069445bbf513226fd6c7e51%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;3.png&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;5.5.2 Hash的压缩列表&lt;/h3&gt;

&lt;p&gt;压缩列表会根据存入的数据的不同类型以及不同大小，分配不同大小的空间。所以是为了节省内存而采用的。&lt;/p&gt;

&lt;p&gt;因为是一块完整的内存空间，当里面的元素发生变更时，会产生连锁更新，严重影响我们的访问性能。所以，只适用于数据量比较小的场景。&lt;/p&gt;

&lt;p&gt;所以，Redis会有相关配置，Hashes只有小数据量的时候才会用到ziplist，当hash对象同时满足以下两个条件的时候，使用ziplist编码：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 哈希对象保存的键值对数量＜512个&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 所有的键值对的键和值的字符串长度都＜64byte（一个英文字母一个字节）&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;hash-max-ziplist-value 64 // ziplist中最大能存放的值长度
hash-max-ziplist-entries 512 // ziplist中最多能存放的entry节点数量
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;5.6 List类型数据结构&lt;/h2&gt;

&lt;h3&gt;5.6.1 quickList快速列表&lt;/h3&gt;

&lt;p&gt;兼顾了ziplist的节省内存，并且一定程度上解决了连锁更新的问题，我们的 quicklistNode节点里面是个ziplist，每个节点是分开的。那么就算发生了连锁更新，也只会发生在一个quicklistNode节点。&lt;/p&gt;

&lt;p&gt;quicklist.h文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct{
    struct quicklistNode *prev; //前指针
    struct quicklistNode *next; //后指针
    unsigned char *zl; //数据指针 指向ziplist结果
    unsigned int sz; //ziplist大小 /* ziplist
    size in bytes */
    unsigned int count : 16; /* count of items in ziplist */ //ziplist的元素
    unsigned int encoding : 2; /* RAW==1 or LZF==2 */ //
    是否压缩， 1没有压缩 2 lzf压缩
    unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ //预留容器字段
    unsigned int recompress : 1; /* was this node previous compressed? */
    unsigned int attempted_compress : 1; /* node can&#x27;t compress; too small */
    unsigned int extra : 10; /* more bits to steal for  future usage */ //预留字段
} quicklistNode;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;5.6.2 list数据结构图&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9c82f046cc3a4ebeb28ed79557a9939e%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;4.png&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;5.7 Set类型数据结构&lt;/h2&gt;

&lt;p&gt;Redis用intset或hashtable存储set。满足下面条件，就用inset存储。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 如果不是整数类型，就用dictht hash表（数组+链表）&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 如果元素个数超过512个，也会用hashtable存储。跟一个配置有关：&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;set-max-intset-entries 512
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不满足上述条件的，都使用hash表存储，value存null。&lt;/p&gt;

&lt;h2&gt;5.8 ZSet数据结构&lt;/h2&gt;

&lt;h3&gt;5.8.1 ZipList&lt;/h3&gt;

&lt;p&gt;默认使用ziplist编码。&lt;/p&gt;

&lt;p&gt;在ziplist的内部，按照score排序递增来存储。插入的时候要移动之后的数据。&lt;/p&gt;

&lt;p&gt;如果元素数量大于等于128个，或者任一member长度大于等于64字节使用 skiplist+dict存储。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zset-max-ziplist-entries 128
zset-max-ziplist-value 64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果不满足条件，采用跳表。&lt;/p&gt;

&lt;h3&gt;5.8.2 跳表（skiplist）&lt;/h3&gt;

&lt;p&gt;结构定义（servier.h）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/* ZSETs use a specialized version of Skiplists */
typedef struct zskiplistNode {
 sds ele; //sds数据
 double score; //score
 struct zskiplistNode *backward; //后退指针
 //层级数组
 struct zskiplistLevel {
     struct zskiplistNode *forward; //前进指针
     unsigned long span; //跨度
 } level[];
} zskiplistNode;

//跳表列表
typedef struct zskiplist {
 struct zskiplistNode *header, *tail; //头尾节点
 unsigned long length; //节点数量
 int level; //最大的节点层级
} zskiplist;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;zslInsert 添加节点方法 （t_zset.c）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zskiplistNode *zslInsert(zskiplist *zsl, double score, sds
ele) {
 zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
 unsigned int rank[ZSKIPLIST_MAXLEVEL];
 int i, level;
 serverAssert(!isnan(score));
 x = zsl-&amp;gt;header;
 for (i = zsl-&amp;gt;level-1; i &amp;gt;= 0; i--) {
     /* store rank that is crossed to reach the insert
     position */
     rank[i] = i == (zsl-&amp;gt;level-1) ? 0 : rank[i+1];
     while (x-&amp;gt;level[i].forward &amp;amp;&amp;amp;
         (x-&amp;gt;level[i].forward-&amp;gt;score &amp;lt; score ||
         咕泡出品 必属精品精品属精品 咕泡出品 必属精品 咕泡出品 必属精品 咕泡咕泡
         (x-&amp;gt;level[i].forward-&amp;gt;score == score
         &amp;amp;&amp;amp;
         sdscmp(x-&amp;gt;level[i].forward-&amp;gt;ele,ele) &amp;lt;
         0)))
         {
         rank[i] += x-&amp;gt;level[i].span;
         x = x-&amp;gt;level[i].forward;
     }
     update[i] = x;
 }
 /* we assume the element is not already inside, since
 we allow duplicated
    * scores, reinserting the same element should never
    happen since the
    * caller of zslInsert() should test in the hash table
    if the element is
    * already inside or not. */
    level = zslRandomLevel();
    if (level &amp;gt; zsl-&amp;gt;level) {
        for (i = zsl-&amp;gt;level; i &amp;lt; level; i++) {
            rank[i] = 0;
            update[i] = zsl-&amp;gt;header;
            update[i]-&amp;gt;level[i].span = zsl-&amp;gt;length;
        }
        zsl-&amp;gt;level = level;
    }
    x = zslCreateNode(level,score,ele);
    //不同层级建立链表联系
    for (i = 0; i &amp;lt; level; i++) {
        x-&amp;gt;level[i].forward = update[i]-&amp;gt;level[i].forward;
        update[i]-&amp;gt;level[i].forward = x;
        /* update span covered by update[i] as x is
        inserted here */
        x-&amp;gt;level[i].span = update[i]-&amp;gt;level[i].span -
        (rank[0] - rank[i]);
        update[i]-&amp;gt;level[i].span = (rank[0] - rank[i]) +
        1;
    }
    /* increment span for untouched levels */
    for (i = level; i &amp;lt; zsl-&amp;gt;level; i++) {
        update[i]-&amp;gt;level[i].span++;
    }
    x-&amp;gt;backward = (update[0] == zsl-&amp;gt;header) ? NULL :
    update[0];
    if (x-&amp;gt;level[0].forward)
        x-&amp;gt;level[0].forward-&amp;gt;backward = x;
    else
        zsl-&amp;gt;tail = x;
        zsl-&amp;gt;length++;
    return x;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ZSKIPLIST_MAXLEVEL默认32 定义在server.h&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^64
elements */
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;六、Redis过期策略&lt;/h1&gt;

&lt;h2&gt;6.1 惰性过期&lt;/h2&gt;

&lt;p&gt;所谓惰性过期，就是在每次访问操作key的时候，判断这个key是不是过期了，过期了就删除。&lt;/p&gt;

&lt;h3&gt;6.1.1 源码验证&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; expireIfNeeded方法（db.c文件）&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;int expireIfNeeded(redisDb *db, robj *key) {
    if (!keyIsExpired(db,key)) return 0;
    /* If we are running in the context of a slave,
    instead of
    * evicting the expired key from the database, we
    return ASAP:
    * the slave key expiration is controlled by the
    master that will
    * send us synthesized DEL operations for expired
    keys.
    *
    * Still we try to return the right information to the
    caller,
    * that is, 0 if we think the key should be still
    valid, 1 if
    * we think the key is expired at this time. */
    // 如果配置有masterhost，说明是从节点，那么不操作删除
    if (server.masterhost != NULL) return 1;
    /* Delete the key */
    server.stat_expiredkeys++;
    propagateExpire(db,key,server.lazyfree_lazy_expire);
    notifyKeyspaceEvent(NOTIFY_EXPIRED,
    &quot;expired&quot;,key,db-&amp;gt;id);
    //是否是异步删除 防止单个Key的数据量很大 阻塞主线程 是4.0之后添加的新功能，默认关闭
    int retval = server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) : dbSyncDelete(db,key);
    if (retval) signalModifiedKey(NULL,db,key);
    return retval;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每次调用到相关指令时，才会执行expireIfNeeded判断是否过期，平时不会去判断是否过期。&lt;/p&gt;

&lt;p&gt;该策略可以最大化的节省CPU资源。&lt;/p&gt;

&lt;p&gt;但是却对内存非常不友好。因为如果没有再次访问，就可能一直堆积再内存中。占用内存&lt;/p&gt;

&lt;p&gt;所以就需要另一种策略来配合使用，就是定期过期&lt;/p&gt;

&lt;h2&gt;6.2 定期过期&lt;/h2&gt;

&lt;p&gt;那么多久去清除一次，我们在讲Rehash的时候，有个方法是serverCron，执行频率根据redis.conf中的hz配置。&lt;/p&gt;

&lt;p&gt;这方法除了做Rehash以外，还会做很多其他的事情，比如：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 清理数据库中的过期键值对&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 关闭和清理连接失效的客户端&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 尝试进行持久化操作&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;6.2.1 实现流程&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 定时serverCron方法去执行清理，执行频率根据redis.cong中的hz配置的值（默认是10，也就是1s执行10次，100ms执行一次）&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 执行清理的时候，不是去扫描所有的key，而是去扫描所有设置了过期时间的key redisDB.expires&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 如果每次去把所有的key都拿出来，那么假如过期的key很多，就会很慢，所以也不是一次性拿出所有的key&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 根据hash桶的维度去扫描key，扫到20(可配置)个key为止。假如第一个桶是15个key没有满足20，继续扫描第二个桶，第二个桶20个key，由于是以hash桶的维度扫描的，所以第二个扫到了就会全扫，总共扫描35个key&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 找到扫描的key里面过期的key，并进行删除&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 如果取了400个空桶（最多拿400个桶），或者扫描的删除比例跟扫描的总数超过10%，继续执行4、5步&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 也不能无限的循环，循环16次后回去检测时间，超过指定时间会跳出&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;6.2.2 源码验证&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt; 入口serverCrom&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;// serverCron方法调用databasesCron方法（server.c）
/* Handle background operations on Redis databases. */
databasesCron();

void databasesCron(void) {
    /* Expire keys by random sampling. Not required for
    slaves
    * as master will synthesize DELs for us. */
    if (server.active_expire_enabled) {
        if (iAmMaster()) {
            activeExpireCycle(ACTIVE_EXPIRE_CYCLE_SLOW);
        //过期删除方法
        } else {
            expireSlaveKeys();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;七、Redis淘汰策略&lt;/h1&gt;

&lt;p&gt;由于Redis内存是有大小的，并且我可能里面的数据都没有过期，当快满的时候，我又没有过期的数据进行淘汰，那么这个时候内存也会满。内存满了，Redis也会不能放入新的数据。所以，我们不得已需要一些策略来解决这个问题来保证可用性。&lt;/p&gt;

&lt;h2&gt;7.1 淘汰策略&lt;/h2&gt;

&lt;h3&gt;7.1.1 noeviction&lt;/h3&gt;

&lt;p&gt;New values aren’t saved when memory limit is reached. When a database uses replication, this applies to the primary database.&lt;/p&gt;

&lt;p&gt;默认，不淘汰 能读不能写&lt;/p&gt;

&lt;h3&gt;7.1.2 allkeys-lru&lt;/h3&gt;

&lt;p&gt;Keeps most recently used keys; removes least recently used (LRU) keys&lt;/p&gt;

&lt;p&gt;基于伪LRU算法，在所有的key中去淘汰&lt;/p&gt;

&lt;h3&gt;7.1.3 allkeys-lfu&lt;/h3&gt;

&lt;p&gt;Keeps frequently used keys; removes least frequently used (LFU) keys.&lt;/p&gt;

&lt;p&gt;基于伪LFU算法，在所有的key中去淘汰&lt;/p&gt;

&lt;h3&gt;7.1.4 volatile-lru&lt;/h3&gt;

&lt;p&gt;Removes least recently used keys with the expire field set to true.&lt;/p&gt;

&lt;p&gt;基于伪LRU算法，在设置了过期时间的key中去淘汰&lt;/p&gt;

&lt;h3&gt;7.1.5 volatile-lfu&lt;/h3&gt;

&lt;p&gt;Removes least frequently used keys with the expire field set to true.&lt;/p&gt;

&lt;p&gt;基于伪LFU算法 在设置了过期时间的key中去淘汰&lt;/p&gt;

&lt;h3&gt;7.1.6 allkeys-random&lt;/h3&gt;

&lt;p&gt;Randomly removes keys to make space for the new data added.&lt;/p&gt;

&lt;p&gt;基于随机算法，在所有的key中去淘汰&lt;/p&gt;

&lt;h3&gt;7.1.7 volatile-random&lt;/h3&gt;

&lt;p&gt;Randomly removes keys with expire field set to true.&lt;/p&gt;

&lt;p&gt;基于随机算法 在设置了过期时间的key中去淘汰&lt;/p&gt;

&lt;h3&gt;7.1.8 volatile-ttl&lt;/h3&gt;

&lt;p&gt;Removes least frequently used keys with expire field set to true and the shortest remaining time-to-live (TTL) value.&lt;/p&gt;

&lt;p&gt;根据过期时间来，淘汰即将过期的&lt;/p&gt;

&lt;h2&gt;7.2 淘汰流程&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt; 首先，我们会有个淘汰池，默认大小是16，并且里面的数据是末尾淘汰制&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 每次指令操作的时候，自旋会判断当前内存是否满足指令所需要的内存&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 如果当前不满足，会从淘汰池的尾部拿一个最适合淘汰的数据&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 会取样（配置 maxmemory-samples），从Redis中获取随机获取到取样的数据，解决一次性读取所有的数据慢的问题&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 在取样的数据中，根据淘汰算法找到最适合淘汰的数据&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 将最合适的那个数据跟淘汰池中的数据进行比较，是否比淘汰池的数据更适合淘汰，如果更适合，放入淘汰池&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 按照适合的程度进行排序，最适合淘汰的放入尾部&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 将需要淘汰的数据从Redis删除，并且从淘汰池移除&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;7.3 LRU算法&lt;/h2&gt;

&lt;p&gt;Lru，Least Recently Used 翻译过来是最久未使用，根据时间轴来走，仍很久没用的数据。只要最近有用过，我就默认是有效的。&lt;/p&gt;

&lt;p&gt;那么它的一个衡量标准是啥？时间！根据使用时间，从近到远，越远的越容易淘汰。&lt;/p&gt;

&lt;h3&gt;7.3.1 实现原理&lt;/h3&gt;

&lt;p&gt;需求：得到对象隔多久没访问，隔的时间越久，越容易被淘汰&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 首先，LRU是根据这个对象的访问操作时间来进行淘汰的，那么我们需要知道这个对象最后操作的访问时间&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 知道了对象的最后操作访问时间后，我们只需要跟当前系统时间来进行对比，就能算出对象多久没访问了&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;7.3.2 源码验证&lt;/h3&gt;

&lt;p&gt;redis中，对象都会被redisObject对象包装，其中有个字段叫lru。&lt;/p&gt;

&lt;p&gt;redisObject对象 （server.h文件）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct redisObject {
 unsigned type:4;
 unsigned encoding:4;
 unsigned lru:LRU_BITS; /* LRU time (relative to global
 lru_clock) or
 * LFU data (least significant 8 bits frequency
 * and most significant 16 bits access time). */
 int refcount;
 void *ptr;
} robj;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看LRU的字段的说明，那么我们大概能猜出来，redis去实现lru淘汰算法肯定跟我们这个对象的lru相关&lt;/p&gt;

&lt;p&gt;并且这个字段的大小为24bit，那么这个字段记录的是对象操作访问时候的秒单位时间的后24bit&lt;/p&gt;

&lt;p&gt;相当于：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;long timeMillis=System.currentTimeMillis();
System.out.println(timeMillis/1000); //获取当前秒
System.out.println(timeMillis/1000 &amp;amp; ((1&amp;lt;&amp;lt;24)-1)); //获取秒的后24位
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们知道了这个对象的最后操作访问的时间。如果我们要得到这个对象多久没访问了，我们是不是就很简单，用我当前的时间-这个对象的访问时间就可以了！但是这个访问时间是秒单位时间的后24bit 所以，也是用当前的时间的秒单位的后24bit去减。&lt;/p&gt;

&lt;p&gt;estimateObjectIdleTime方法(evict.c)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsigned long long estimateObjectIdleTime(robj *o) {
 //获取秒单位时间的最后24位
 unsigned long long lruclock = LRU_CLOCK();
 //因为只有24位，所有最大的值为2的24次方-1
 //超过最大值从0开始，所以需要判断lruclock（当前系统时间）跟缓存对象的lru字段的大小
 if (lruclock &amp;gt;= o-&amp;gt;lru) {
     //如果lruclock&amp;gt;=robj.lru，返回lruclock-o-&amp;gt;lru，再转换单位
     return (lruclock - o-&amp;gt;lru) * LRU_CLOCK_RESOLUTION;
 } else {
     //否则采用lruclock + (LRU_CLOCK_MAX - o-&amp;gt;lru)，得到对
     象的值越小，返回的值越大，越大越容易被淘汰
     return (lruclock + (LRU_CLOCK_MAX - o-&amp;gt;lru)) *
     LRU_CLOCK_RESOLUTION;
 }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;7.3.3 LRU总结&lt;/h3&gt;

&lt;p&gt;用lruclock与 redisObject.lru进行比较，因为lruclock只获取了当前秒单位时间的后24位，所以肯定有个轮询。&lt;/p&gt;

&lt;p&gt;所以，我们会用lruclock跟 redisObject.lru进行比较，如果lruclock&amp;gt;redisObject.lru，那么我们用lruclock- redisObject.lru，否则lruclock+(24bit的最大值-redisObject.lru)，得到lru越小，那么返回的数据越大，相差越大的越优先会被淘汰！&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.processon.com/view/link/5fbe0541e401fd2d6ed8fc38&quot;&gt;https://www.processon.com/view/link/5fbe0541e401fd2d6ed8fc38&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;7.4 LFU算法&lt;/h2&gt;

&lt;p&gt;LFU，英文 Least Frequently Used，翻译成中文就是最不常用的优先淘汰。&lt;/p&gt;

&lt;p&gt;不常用，它的衡量标准就是次数，次数越少的越容易被淘汰。&lt;/p&gt;

&lt;p&gt;这个实现起来应该也很简单，对象被操作访问的时候，去记录次数，每次操作访问一次，就+1；淘汰的时候，直接去比较这个次数，次数越少的越容易淘汰！&lt;/p&gt;

&lt;h3&gt;7.4.1 LFU的时效性问题&lt;/h3&gt;

&lt;p&gt;何为时效性问题？就是只会去考虑数量，但是不会去考虑时间。&lt;/p&gt;

&lt;p&gt;ps：去年的某个新闻很火，点击量3000W，今年有个新闻刚出来点击量100次，本来我们是想保留今年的新的新闻的，但是如果根据LFU来做的话，我们发现淘汰的是今年的新闻，明显是不合理的&lt;/p&gt;

&lt;p&gt;导致的问题：新的数据进不去，旧的数据出不来。&lt;/p&gt;

&lt;p&gt;那么如何解决呢，且往下看&lt;/p&gt;

&lt;h3&gt;7.4.2 源码分析&lt;/h3&gt;

&lt;p&gt;我们还是来看redisObject(server.h)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS; /* LRU time (relative to global
    lru_clock) or
    * LFU data (least significant 8 bits frequency
    * and most significant 16 bits access time). */
    int refcount;
    void *ptr;
} robj;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看它的lru，它如果在LFU算法的时候！它前面16位代表的是时间，后8位代表的是一个数值，frequency是频率，应该就是代表这个对象的访问次数，我们先给它叫做counter。&lt;/p&gt;

&lt;p&gt;前16bits时间有啥用?&lt;/p&gt;

&lt;p&gt;跟时间相关，我猜想应该是跟解决时效性相关的，那么怎么解决的？从生活中找例子&lt;/p&gt;

&lt;p&gt;大家应该充过一些会员，比如我这个年纪的，小时候喜欢充腾讯的黄钻、绿钻、蓝钻等等。但是有一个点，假如哪天我没充钱了的话，或者没有续VIP的时候，我这个钻石等级会随着时间的流失而降低。比如我本来是黄钻V6，但是一年不充钱的话，可能就变成了V4。&lt;/p&gt;

&lt;p&gt;那么回到Redis，大胆的去猜测，那么这个时间是不是去记录这个对象有多久没访问了，如果多久没访问，我就去减少对应的次数。&lt;/p&gt;

&lt;p&gt;LFUDecrAndReturn方法（evict.c）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsigned long LFUDecrAndReturn(robj *o) {
    //lru字段右移8位，得到前面16位的时间
    unsigned long ldt = o-&amp;gt;lru &amp;gt;&amp;gt; 8;
    //lru字段与255进行&amp;amp;运算（255代表8位的最大值），
    //得到8位counter值
    unsigned long counter = o-&amp;gt;lru &amp;amp; 255;
    //如果配置了lfu_decay_time，用LFUTimeElapsed(ldt) 除以配置的值
    //LFUTimeElapsed(ldt)源码见下
    //总的没访问的分钟时间/配置值，得到每分钟没访问衰减多少
    unsigned long num_periods = server.lfu_decay_time ?LFUTimeElapsed(ldt) / server.lfu_decay_time : 0;
    if (num_periods)
    //不能减少为负数，非负数用couter值减去衰减值
    counter = (num_periods &amp;gt; counter) ? 0 : counter - num_periods;
    return counter;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;衰减因子由配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lfu-decay-time 1 //多少分钟没操作访问就去衰减一次
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后8bits的次数，最大值是255，够不够?&lt;/p&gt;

&lt;p&gt;肯定不够，一个对象的访问操作次数肯定不止255次。&lt;/p&gt;

&lt;p&gt;但是我们可以让数据达到255的很难。那么怎么做的？这个比较简单，我们先看源码，然后再总结&lt;/p&gt;

&lt;p&gt;LFULogIncr方法 （evict.c 文件）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uint8_t LFULogIncr(uint8_t counter) {
    //如果已经到最大值255，返回255 ，8位的最大值
    if (counter == 255) return 255;
    //得到随机数（0-1）
    double r = (double)rand()/RAND_MAX;
    //LFU_INIT_VAL表示基数值（在server.h配置）
    double baseval = counter - LFU_INIT_VAL;
    //如果达不到基数值，表示快不行了，baseval =0
    if (baseval &amp;lt; 0) baseval = 0;
    //如果快不行了，肯定给他加counter
    //不然，按照几率是否加counter，同时跟baseval与lfu_log_factor相关
    //都是在分子，所以2个值越大，加counter几率越小
    double p = 1.0/(baseval*server.lfu_log_factor+1);
    if (r &amp;lt; p) counter++;
    return counter;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;八、Redis 持久化&lt;/h1&gt;

&lt;h2&gt;8.1 RBD&lt;/h2&gt;

&lt;h3&gt;8.1.1 何时触发RBD&lt;/h3&gt;

&lt;p&gt;自动触发&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 配置触发&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;save 900 1 900s检查一次，至少有1个key被修改就触发
save 300 10 300s检查一次，至少有10个key被修改就触发
save 60 10000 60s检查一次，至少有10000个key被修改
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt; shutdown正常关闭&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;任何组件在正常关闭的时候，都会去完成应该完成的事。比如Mysql 中的Redolog持久化，正常关闭的时候也会去持久化。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; flushall指令触发&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;数据清空指令会触发RDB操作，并且是触发一个空的RDB文件，所以， 如果在没有开启其他的持久化的时候，flushall是可以删库跑路的，在生产环境慎用。&lt;/p&gt;

&lt;h3&gt;8.1.2 RDB的优劣&lt;/h3&gt;

&lt;p&gt;优势&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 是个非常紧凑型的文件，非常适合备份与灾难恢复&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 最大限度的提升了性能，会fork一个子进程，父进程永远不会产于磁盘 IO或者类似操作&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 更快的重启&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;不足&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 数据安全性不是很高，因为是根据配置的时间来备份，假如每5分钟备份 一次，也会有5分钟数据的丢失&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 经常fork子进程，所以比较耗CPU，对CPU不是很友好&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;8.2 AOF&lt;/h2&gt;

&lt;p&gt;由于RDB的数据可靠性非常低，所以Redis又提供了另外一种持久化方案： Append Only File 简称：AOF&lt;/p&gt;

&lt;p&gt;AOF默认是关闭的，你可以在配置文件中进行开启：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;appendonly no //默认关闭，可以进行开启
# The name of the append only file (default:&quot;appendonly.aof&quot;)
appendfilename &quot;appendonly.aof&quot; //AOF文件名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;追加文件，即每次更改的命令都会附加到我的AOF文件中。&lt;/p&gt;

&lt;h3&gt;8.2.1 同步机制&lt;/h3&gt;

&lt;p&gt;AOF会记录每个写操作，那么问题来了。我难道每次操作命令都要和磁盘交互？&lt;/p&gt;

&lt;p&gt;当然不行，所以redis支持几种策略，由用户来决定要不要每次都和磁盘交互&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# appendfsync always 表示每次写入都执行fsync(刷新)函数 性能会非常非常慢 但是非常安全
appendfsync everysec 每秒执行一次fsync函数 可能丢失1s的数据
# appendfsync no 由操作系统保证数据同步到磁盘，速度最快 你的数据只需要交给操作系统就行
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;默认1s一次，最多有1s丢失&lt;/p&gt;

&lt;h3&gt;8.2.2 重写机制&lt;/h3&gt;

&lt;p&gt;由于AOF是追加的形式，所以文件会越来越大，越大的话，数据加载越慢。 所以我们需要对AOF文件进行重写。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;何为重写&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;比如 我们的incr指令，假如我们incr了100次，现在数据是100，但是我们的aof文件中会有100条incr指令，但是我们发现这个100条指令用处不大， 假如我们能把最新的内存里的数据保存下来的话。所以，重写就是做了这么一件事情，把当前内存的数据重写下来，然后把之前的追加的文件删除。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;重写流程&lt;/strong&gt;&lt;/p&gt;



&lt;ol&gt;
&lt;li&gt; Redis fork一个子进程，在一个临时文件中写入新的AOF（当前内存的数据生成的新的AOF）&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 那么在写入新的AOF的时候，主进程还会有指令进入，那么主进程会在内存缓存区中累计新的指令 （但是同时也会写在旧的AOF文件中，就算 重写失败，也不会导致AOF损坏或者数据丢失）&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 如果子进程重写完成，父进程会收到完成信号，并且把内存缓存中的指令追加到新的AOF文件中&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt;&lt;p&gt;替换旧的AOF文件 ，并且将新的指令附加到重写好的AOF文件中&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 子进程开始在一个临时文件中写入新的基础AOF&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 父级打开一个新的增量 AOF 文件以继续写入更新。如果重写失败，旧的基础和增量文件（如果有的话）加上这个新打开的增量文件就代表了完整的更新数据集，所以我们是安全的&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 当子进程完成基础文件的重写后，父进程收到一个信号，并使用新打开 的增量文件和子进程生成的基础文件来构建临时清单，并将其持久化&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 现在 Redis 对清单文件进行原子交换，以便此 AOF 重写的结果生效。 Redis 还会清理旧的基础文件和任何未使用的增量文件&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是重写是把当前内存的数据，写入一个新的AOF文件，如果当前数据比较大，然后以指令的形式写入的话，会很慢很慢&lt;/p&gt;

&lt;p&gt;所以在4.0之后，在重写的时候是采用RDB的方式去生成新的AOF文件，然 后后续追加的指令，还是以指令追加的形式追加的文件末尾&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;aof-use-rdb-preamble yes //是否开启RDB与AOF混合模式
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;什么时候重写&lt;/p&gt;

&lt;p&gt;配置文件redis.conf&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 重写触发机制
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb 就算达到了第一个百分比的大小，也必须大于 64M

在 aof 文件小于64mb的时候不进行重写，当到达64mb的时候，就重写一
次。重写后的 aof 文件可能是40mb。上面配置了auto-aof-rewritepercentag为100，即 aof 文件到了80mb的时候，进行重写。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;8.2.3 AOF的优势与不足&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 安全性高，就算是默认的持久化同步机制，也最多只会丢失1s数据&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; AOF由于某些原因，比如磁盘满了等导致追加失败，也能通过redischeck-aof 工具来修复&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 格式都是追加的日志，所以可读性更高&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;不足&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 数据集一般比RDB大&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 持久化跟数据加载比RDB更慢&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 在7.0之前，重写的时候，因为重写的时候，新的指令会缓存在内存区，所以会导致大量的内存使用&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 并且重写期间，会跟磁盘进行2次IO，一个是写入老的AOF文件，一个是写入新的AOF文件&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;九、Redis常见问题总结&lt;/h1&gt;

&lt;h2&gt;9.1 Redis数据丢失场景&lt;/h2&gt;

&lt;h3&gt;9.1.1 持久化丢失&lt;/h3&gt;

&lt;p&gt;采用RDB或者不持久化， 会有数据丢失，因为是手动或者配置以快照的形式来进行备份。&lt;/p&gt;

&lt;p&gt;解决：启用AOF，以命令追加的形式进行备份，但是默认也会有1s丢失， 这是在性能与数据安全性中寻求的一个最适合的方案，如果为了保证数据 一致性，可以将配置更改为always，但是性能很慢，一般不用。&lt;/p&gt;

&lt;h3&gt;9.1.2 主从切换&lt;/h3&gt;

&lt;p&gt;因为Redis的数据是主异步同步给从的，提升了性能，但是由于是异步同步到从。所以存在数据丢失的可能&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; master写入数据k1 ,由于是异步同步到slave，当master没有同步给slave的时候，master挂了&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; slave会成为新的master，并且没有同步k1&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; master重启，会成为新master的slave，同步数据会清空自己的数据，从新的master加载&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; k1丢失&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;9.2 Redis缓存雪崩、穿透、击穿问题分析&lt;/h2&gt;

&lt;h3&gt;9.2.1 缓存雪崩&lt;/h3&gt;

&lt;p&gt;缓存雪崩就是Redis的大量热点数据同时过期（失效)，因为设置了相同的过期时间，刚好这个时候Redis请求的并发量又很大，就会导致所有的请求落到数据库。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 保证Redis的高可用，防止由于Redis不可用导致全部打到DB&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 加互斥锁或者使用队列，针对同一个key只允许一个线程到数据库查询&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 缓存定时预先更新，避免同时失效&lt;/li&gt;
&lt;/ol&gt;



&lt;ol&gt;
&lt;li&gt; 通过加随机数，使key在不同的时间过期&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;9.2.2 缓存穿透&lt;/h3&gt;

&lt;p&gt;缓存穿透是指缓存和数据库中都没有的数据，但是用户一直请求不存在的数据！这时的用户很可能就是攻击者，恶意搞你们公司的，攻击会导致数据库压力过大。&lt;/p&gt;

&lt;p&gt;解决方案：布隆过滤器&lt;/p&gt;

&lt;p&gt;布隆过滤器的思想：既然是因为你Redis跟DB都没有，然后用户恶意一直访问不存在的key，然后全部打到Redis跟DB。那么我们能不能单独把DB的数据单独存到另外一个地方，但是这个地方只存一个简单的标记，标记这个key存不存在，如果存在，就去访问Redis跟DB，否则直接返回。并且这个内存最好很小。&lt;/p&gt;

&lt;h3&gt;9.2.3 缓存击穿&lt;/h3&gt;

&lt;p&gt;单个key过期的时候有大量并发，使用互斥锁，回写redis，并且采用双重检查锁来提升性能！减少对DB的访问。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>88d94db86916e6c2bbffabb534abf66b</guid>
<title>30 岁被裁，我想明白的几件事</title>
<link>https://toutiao.io/k/c5vo8n4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             &quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;qqmusic class=&quot;js_editor_qqmusic qqmusic_iframe js_uneditable custom_select_card&quot; musicid=&quot;323942200&quot; mid=&quot;004e0zXJ1VPi3o&quot; albumurl=&quot;https://y.gtimg.cn/music/photo_new/T002R68x68M000.jpg&quot; audiourl=&quot;http://isure6.stream.qqmusic.qq.com/C200004e0zXJ1VPi3o.m4a?guid=2000000052&amp;amp;vkey=1F74733FDD05C2803F211D90132C117289DB551B096F14063B430D8F072332CD99FE304FC4C68C84945AFC05E3629B7698A14163E685AD90&amp;amp;uin=&amp;amp;fromtag=20052&quot; music_name=&quot;春天里&quot; singer=&quot;旭日阳刚&quot; play_length=&quot;268&quot; src=&quot;/mp/readtemplate?t=app_editor/music&amp;amp;singer=%E6%97%AD%E6%97%A5%E9%98%B3%E5%88%9A&amp;amp;music_name=%E6%98%A5%E5%A4%A9%E9%87%8C&amp;amp;albumurl=https%3A%2F%2Fy.gtimg.cn%2Fmusic%2Fphoto_new%2FT002R68x68M000.jpg&amp;amp;musictype=1&quot; musictype=&quot;1&quot; otherid=&quot;004e0zXJ1VPi3o&quot; albumid=&quot;&quot; jumpurlkey=&quot;&quot; data-pluginname=&quot;insertaudio&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.549074074074074&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/ftksfIbzTWj1Vzoc5T4OeDsux380qjHLQJNlvdSib91YqR6HrUfpl9fUzM6WzP8ibHVWZbGhHGm4b17ulKDh96kQ/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我今年30岁，上个月底我被裁员了，也就是业内所谓的毕业，喜提大礼包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从HRBP约会到开始面谈再到工作的lark账号被停用，总计耗时1小时2分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后就是走离职流程，和部分有工作往来的同事做友好告别，职场嘛，人来人往，好聚好散。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从裁员到今天，休息了半个月。一方面在处理生活上的一些杂事，比如考驾照之类的；另一方面就是看看书，同时在思考这次裁员对我的影响，其实细细想来对我好像没太多负面影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;昨晚和几个前同事一起吃饭，喝了点酒，席间不免谈到这次裁员的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我聊了些自己的感受，对职场生涯的回顾或者说感触，也分享了我后续的一些打算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;都是些碎碎念，索性写篇文章，以我为例，分享下这次裁员的一些感受，以及让我明白的一些事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;行业周期论&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;关注我公众号大多是互联网相关的技术同学，大家对互联网和传统企业的区别，或多或少有些感触。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年的互联网大裁员，我的理解其实就是行业周期的变化进入了第一曲线末尾和第二曲线的交接区间。&lt;/span&gt;&lt;span&gt;第一曲线和第二曲线现在大多被认为是经济学上的术语，大意是：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;130&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;世界上任何事物的产生与发展，都有一个生命周期，并形成一条曲线。在这条曲线上，有起始期、成长期、成就期、高成就期、下滑期、衰败期，整个过程犹如登山活动。为了保持成就期的生命力，就要在高成就到来或消失之前，开始另外一条新的曲线，即第二曲线。&lt;/span&gt;&lt;span&gt;                                                                                                                        ——英国：查尔斯·汉迪&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;国内的互联网发展，经历了2000年前后的萌芽，08年左右的web1.0时代，12年至18年的移动互联网爆发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然web3.0提出好几年了，但目前依然看不到新的增长点和爆发点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从增长阶段到留存阶段，之前的跑马圈地和烧钱砸市场占用率的时代一去不复返。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;粗暴运营了很多年的互联网企业，也到了精细化运营和追求利润的时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有句话我觉得说的挺对的：“高速发展可以掩盖一切问题”！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为高速发展，蛋糕在不断做大，大家都相信自己能随着分更多的蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是当蛋糕不再变大，加入市场分蛋糕的人更多时，越是底层越是会陷入内卷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再叠加上目前全球的各种黑天鹅以及灰犀牛事件的不断发酵，风险会迫使人们更关注自己能分多少，而不是做大蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我个人对于互联网未来依然很看好，互联网以及基于信息技术的未来依然是很好的行业，能创造更多更有创造力的岗位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但当下，是时候慢下来进行调整，以便于更好的去往未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们参与并分享了互联网行业第一曲线爆发时候的蛋糕，不能说自己不承受下滑调整期的动荡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不要和市场对抗，要跟随市场积极调整，这是我今年理财亏损以及被裁所明白的第一件事&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;在哪里很重要&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;其实今年很多被裁的同学，并不是自己技术或者业务能力不过关，有个很大的因素，是所在的岗位不那么幸运而已。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以我为例，我最初入职以及今年第一季度时候，在团队内负责的项目，都是内部A和S级的项目。&lt;/span&gt;&lt;span&gt;优先级高，上级重视，投入的资源多，当你能做到预期的结果时，自然能得到对应的蛋糕，重要性也会凸显。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但第二季度开始项目盘点时候，我负责的项目优先级被调整为A和B级项目，预期和重要性下调。&lt;/span&gt;&lt;span&gt;碰到行业发展和爆冷，自然是开源节流缩减成本的第一批被切掉的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我觉得，裁员其实并不是一件完全的坏事，最起码能让我明确自我定位和不足之处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选择核心的业务和团队，有自己的核心竞争力和不可替代性，这是我关于职场明白的第二件事&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;和领导是否合拍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;这点是个隐性因素，很多同学忽略了，但其实蛮重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还是拿我举例子，我的直属上级和团队总监，工作上是比较会push和卷的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不能说他们不对，在不同的位置，所要承担的压力和面临的问题不同，这只是选择而已。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我入职时候和领导就谈过关于工作风格和加班的事，从最开始我和领导的风格就不是一个路子。&lt;/span&gt;&lt;span&gt;起初公司业务发展较好的时候，只要我完成领导预期的结果，即使风格不同，那也是可以接受的。&lt;/span&gt;&lt;span&gt;但当公司业务发展爆冷甚至行业倒退时候，我这种不受领导完全掌控的人，自然就成为了第一个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无关对错和能力，只是个人的选择，仅此而已。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如果想追求安稳长期的职场发展，钱并不是唯一重要因素，选择合拍或相处舒服的领导，是我明白的第三件事&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;职场生涯的新选择&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;和前同事吃饭时候聊到了职场生涯感触及后续的一些打算，这里给大家分享下我的一些想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“35岁努力达到职业自由”，这句话之前就和一些圈子里的朋友谈起过，我在前面的文章也有提到过这个想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;老实说，我认为大部分人是没有做技术的天赋的，同时对于技术也并没有太多的热爱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选择程序员或者技术相关岗位，无非是大学专业如此或这份工作薪资高，仅此而已。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果仅是这样，那今年网上甚嚣尘上的“35岁职场危机”，是一个再正常不过的现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试想，你对你的工作并没有太热爱，也没有投入太多精力和时间深入钻研，凭什么就认为自己能干一辈子呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么问题来了，为什么这么多人担心35岁失业呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“35岁失业”&lt;/span&gt;&lt;strong&gt;&lt;span&gt;不是担心‘不知道如何成长找不到前进方向’的问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，而是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;对‘失业后生活水平后退’又无能为力的恐慌和没有安全感的焦虑&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;互联网行业相比于医生、教师、律师及部分靠经验吃饭的行业来说，是“大前期行业”，即初始起步所获得的薪资水平是比较高的。再加上行业本身的轻资产以及前面十几年的快速发展，整体从业人员的物质收入相对来说是所有行业TOP1。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;不能只享受行业快速发展阶段的红利，而不想背负发展放缓甚至内卷时的代价&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十年前下岗潮那批人，和现在担心“35岁失业”的人群，实际上本质是相同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们为什么会对“35岁失业”恐慌和焦虑，最本质的原因就是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;对当下的行业整体情况以及自身没有清晰的认识，总觉得自己十来年的工作经验是可以重复不断变现的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拿我自己来说，我自认是没有技术天赋的，现在的一些成就，不过是长期持续练习实践再加上一些运气使然的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术饭吃不了一辈子，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;早点找到自己的第二曲线并持续投入，是我今年明白的第四件事&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面分享一些我在前面的文章《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484785&amp;amp;idx=1&amp;amp;sn=71e6034737aadf141c65f04bd899e894&amp;amp;chksm=ce714d2df906c43bd950b7d05c52535509ee19087635828e65f57f5d9ac55898989ad0f6731d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;职场焦虑之我对35岁危机的看法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;职场焦虑之我对35岁危机的看法&lt;/a&gt;》中谈到应对“35岁失业”的建议，仅供参考。&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;持续学习，保持成长；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;开源节流，寻找新的可能性；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;打造个人品牌，树立业内影响力；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选择具有发展潜力的行业，甚至冒着风险；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;降低欲望，找到工作和生活之间的平衡点；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;自我认知的一些变化&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;自我评价，我其实算半个理想主义者，每份工作我都会赋予它一些特别的使命或意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种特殊的使命会促使我持续投入时间和精力去努力做一些事，在朋友看来可能就是努力就有收获。&lt;/span&gt;&lt;span&gt;当我完成预期目标或获得预期甚至超过预期的收获后，就会对当前工作兴致乏乏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后开始动摇，看市场上其他新的机会，跳槽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么我说自己是半个理想主义者？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一方面是每次选择跳槽，内心都会认为我是在做新的尝试，寻找新的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，是不想被束缚在原地，想趁着年轻去不一样的地方看看，本质上我还是有一些勇敢和冒险精神的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样做的好处是经历的故事（也可能是事故）比较丰富，不足则是风险系数会更高，在长辈看来不够稳重吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理想主义者总是这样，我有理想，但缺乏一些持之以恒的耐心和坚韧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后分享一段我很喜欢的话，与大家共勉：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“&lt;/span&gt;&lt;strong&gt;&lt;span&gt;保持头脑极度开放，和聪明人一起审视问题。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;找到问题的所有答案很重要，但提出正确的问题并向其他聪明人请教也很重要。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;与任何人知道的任何东西相比，“不知道”区域里的东西要重要得多，令人兴奋得多”&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-id=&quot;67311&quot; data-type=&quot;lspecial02&quot; data-tools=&quot;速排小蚂蚁编辑器&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg2NDAwMjM1NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWhnnG3FnMGxk4tujZAJv8cPZibDbChbEzPK3FJD5aM9XFQQicu4Lu3L3eo5ldtz5Q63ctdpxhAD25rw/0?wx_fmt=png&quot; data-nickname=&quot;老张的求知思考世界&quot; data-alias=&quot;Engineer_Way&quot; data-signature=&quot;专注互联网技术及相关领域，也分享职场成长、读书思考的内容。这是一个求知探索之人，在寻找更多可能性的旅途中的记录。&quot; data-from=&quot;2&quot; has-insert-preloading=&quot;1&quot; wah-hotarea=&quot;click&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如果喜欢我文章，点赞、关注、在看三连走起。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如果想阅读更多的文章，可以关注我的公众号。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247485280&amp;amp;idx=1&amp;amp;sn=383bb63229b1af6553ea6732ae7da3d9&amp;amp;chksm=ce714f3cf906c62add30416a78acb3441238018b337ed1f3e6c4d8349d828fda2a6cc8baa703&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测试的核心竞争力是什么？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;测试的核心竞争力是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484430&amp;amp;idx=1&amp;amp;sn=4ad300bf0f9ea9fb59f23f68a2b51ba9&amp;amp;chksm=ce714c52f906c54427d907cb1a635fc11d49f239d4f7ff96519399f28a8df4adde9699c54f02&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;一个测试工程师的成长复盘&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;一个测试工程师的成长复盘&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484742&amp;amp;idx=1&amp;amp;sn=71f45e31e45ee6ef2619b1dc4dee144f&amp;amp;chksm=ce714d1af906c40c0eae4cff7014ff34bef40508535188b4fb943e8fbf261bbc3840acf74e94&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测试工程师的职场发展二三谈&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;测试工程师的职场发展二三谈&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247485178&amp;amp;idx=1&amp;amp;sn=feb5e7657f099b6ede9ef40e4ebe6851&amp;amp;chksm=ce714ea6f906c7b089c268f7fc68e105c2cdc42b476a4709ce90e8d28be85d2a936faa414973&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;技术之外的测试工程师成长指南&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;技术之外的测试工程师成长指南&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484785&amp;amp;idx=1&amp;amp;sn=71e6034737aadf141c65f04bd899e894&amp;amp;chksm=ce714d2df906c43bd950b7d05c52535509ee19087635828e65f57f5d9ac55898989ad0f6731d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;职场焦虑之我对35岁危机的看法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;职场焦虑之我对35岁危机的看法&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247485197&amp;amp;idx=1&amp;amp;sn=5d8a112bea7502c045f0ab3494ca8a86&amp;amp;chksm=ce714f51f906c647667edc47d7c5d7ae932b9088bceb4d52723a625b20717b6b3a5e565e71c6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊我对测试领域两级分化的看法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;聊聊我对测试领域两级分化的看法&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484898&amp;amp;idx=1&amp;amp;sn=42ac75c57e4fd792b66ecb99c3b32285&amp;amp;chksm=ce714dbef906c4a850b6a702c6f8bbccd7a7380b96b60cb269af838b1752912c990e7abf45f4&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;优秀的测试开发应该具备的六大能力&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;优秀的测试开发应该具备的六大能力&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484174&amp;amp;idx=1&amp;amp;sn=6cdf3e3a4f9931e021bb779b4b6e17d5&amp;amp;chksm=ce714b52f906c2442f722676f81473d27508e970a897c2082f71c6a6b71a5ee962d7eb17c3bf&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;从技术专家到技术管理，我对管理的思考&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;从技术专家到技术管理，我对管理的思考&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484746&amp;amp;idx=1&amp;amp;sn=fd4bde4a1140a033d68a333f947bc50f&amp;amp;chksm=ce714d16f906c40006c541c781dc166b4e4527fe862825949b5e3aeb22e63017ef3eaca2c4de&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;再谈：我对测试行业发展和自我价值诉求的思考&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;&lt;span&gt;再谈：我对测试行业发展和自我价值诉求的思考&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>352d7edc357b3595b61d3e6ac72873fc</guid>
<title>Java Decompiler Online</title>
<link>https://toutiao.io/k/lqgqlbu</link>
<content:encoded>&lt;div&gt;&lt;body id=&quot;readabilityBody&quot;&gt;&lt;noscript&gt;You need to enable JavaScript to run this app.&lt;/noscript&gt;&lt;p id=&quot;root&quot;/&gt;&lt;/body&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>881f12dfcace7ca6f5ae04c2ff966bba</guid>
<title>手把手教你基于 Kubernetes 实现 CI/CD 配置</title>
<link>https://toutiao.io/k/g58tzli</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于 Kubernetes 实现 CI/CD 配置，其实和往常那些 CI/CD 配置并没有太大区别。都是通过 提交代码，拉取代码，构建代码，发布代码来实现的。 只不过要是通过 K8s 来实现的话，则是需要将构建好的代码打包成镜像，通过镜像的方式来运行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CI/CD 流程图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45693563009972804&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZc7PxnxG2vo1Cfub4SoLiagnvkKWJF00EsUNT5rmZhMvrTFkd6hclIfZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1103&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开发将代码提交代码仓库后，我们便可以通过在 Jenkins 上配置脚本或是 Pipline 的方式来实现代码发布，其中发布有两种方式，一种是通过手动发布，另外一种可以通过 WebHook 插件来实现提交代码便自动发布（生产环境不建议自动发布)&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;脚本内容一般分为：克隆代码、编译代码、将编译好的代码打包成镜像、运行镜像几个步骤。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;基于 Spring Boot + MyBatis Plus + Vue &amp;amp; Element 实现的后台管理系统 + 用户小程序，支持 RBAC 动态权限、多租户、数据权限、工作流、三方登录、支付、短信、商城等功能&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;项目地址：https://github.com/YunaiV/ruoyi-vue-pro&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;视频教程：https://doc.iocoder.cn/video/&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们是通过容器的方式安装配置，物理安装参考：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;https://blog.csdn.net/weixin_46902396/article/details/118337250&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）安装 Docker-Compose&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 ~]&lt;span&gt;# wget &quot;https://github.com/docker/compose/releases/download/v2.3.2/docker-compose-$(uname -s)-$(uname -m)&quot; -O /usr/local/bin/docker-compose &lt;/span&gt;&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# chmod +x /usr/local/bin/docker-compose&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# docker-compose --version&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）安装 GitLab&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;vim&lt;/span&gt; &lt;span&gt;docker-compose.yml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;version:&lt;/span&gt; &lt;span&gt;&#x27;3&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;services:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;web:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;image:&lt;/span&gt; &lt;span&gt;&#x27;gitlab/gitlab-ce:14.8.5-ce.0&#x27;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;restart:&lt;/span&gt; &lt;span&gt;always&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;hostname:&lt;/span&gt; &lt;span&gt;192.168&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;environment:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;GITLAB_OMNIBUS_CONFIG:&lt;/span&gt; &lt;span&gt;|&lt;br/&gt;        external_url &#x27;http://192.168.1.1&#x27;&lt;br/&gt;&lt;/span&gt;    &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;1080:80&#x27;&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;1443:443&#x27;&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;1022:22&#x27;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;volumes:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;/app/gitlab/config:/etc/gitlab&#x27;&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;/app/gitlab/logs:/var/log/gitlab&#x27;&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;&#x27;/app/gitlab/data:/var/opt/gitlab&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;docker-compose&lt;/span&gt; &lt;span&gt;up&lt;/span&gt; &lt;span&gt;-d&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为博主的电脑配置不是很高，所以就不使用上面的方式安装 GitLab，而是直接使用 GitHub 上面的仓库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）安装 NFS 存储，并配置共享目录&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 ~]&lt;span&gt;# yum -y install nfs-utils rpcbind&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# echo &quot;/app/jenkins *(rw,sync,no_root_squash)&quot; &amp;gt; /etc/exports&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# mkdir /app/jenkins&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# systemctl start rpcbind nfs&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）创建 PV 和 PVC&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;vim&lt;/span&gt; &lt;span&gt;jenkins-pv.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;PersistentVolume&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-pv&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;capacity:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;storage:&lt;/span&gt; &lt;span&gt;10Gi&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;accessModes:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;-&lt;/span&gt; &lt;span&gt;ReadWriteMany&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;nfs:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;server:&lt;/span&gt; &lt;span&gt;192.168&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;path:&lt;/span&gt; &lt;span&gt;/app/jenkins&lt;/span&gt;&lt;br/&gt;&lt;span&gt;---&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;PersistentVolumeClaim&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-pvc&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;resources:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;requests:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;storage:&lt;/span&gt; &lt;span&gt;10Gi&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;accessModes:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;-&lt;/span&gt; &lt;span&gt;ReadWriteMany&lt;/span&gt;   &lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;kubectl&lt;/span&gt; &lt;span&gt;create&lt;/span&gt; &lt;span&gt;-f&lt;/span&gt; &lt;span&gt;jenkins-pv.yaml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3）创建 RBAC 授权&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;vim&lt;/span&gt; &lt;span&gt;jenkins-sa.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;ServiceAccount&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-sa&lt;/span&gt;&lt;br/&gt;&lt;span&gt;---&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;rbac.authorization.k8s.io/v1beta1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;ClusterRole&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-cr&lt;/span&gt;&lt;br/&gt;&lt;span&gt;rules:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;apiGroups:&lt;/span&gt; &lt;span&gt;[&quot;extensions&quot;,&quot;apps&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;resources:&lt;/span&gt; &lt;span&gt;[&quot;deployments&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;verbs:&lt;/span&gt; &lt;span&gt;[&quot;create&quot;,&quot;delete&quot;,&quot;get&quot;,&quot;list&quot;,&quot;watch&quot;,&quot;patch&quot;,&quot;update&quot;]&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;apiGroups:&lt;/span&gt; &lt;span&gt;[&quot;&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;resources:&lt;/span&gt; &lt;span&gt;[&quot;services&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;verbs:&lt;/span&gt; &lt;span&gt;[&quot;create&quot;,&quot;delete&quot;,&quot;get&quot;,&quot;list&quot;,&quot;watch&quot;,&quot;patch&quot;,&quot;update&quot;]&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;apiGroups:&lt;/span&gt; &lt;span&gt;[&quot;&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;resources:&lt;/span&gt; &lt;span&gt;[&quot;pods&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;verbs:&lt;/span&gt; &lt;span&gt;[&quot;create&quot;,&quot;delete&quot;,&quot;get&quot;,&quot;list&quot;,&quot;patch&quot;,&quot;update&quot;]&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;apiGroups:&lt;/span&gt; &lt;span&gt;[&quot;&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;resources:&lt;/span&gt; &lt;span&gt;[&quot;pods/exec&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;verbs:&lt;/span&gt; &lt;span&gt;[&quot;create&quot;,&quot;delete&quot;,&quot;get&quot;,&quot;list&quot;,&quot;patch&quot;,&quot;update&quot;]&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;apiGroups:&lt;/span&gt; &lt;span&gt;[&quot;&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;resources:&lt;/span&gt; &lt;span&gt;[&quot;pods/log&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;verbs:&lt;/span&gt; &lt;span&gt;[&quot;get&quot;,&quot;list&quot;,&quot;update&quot;]&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;apiGroups:&lt;/span&gt; &lt;span&gt;[&quot;&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;resources:&lt;/span&gt; &lt;span&gt;[&quot;secrets&quot;]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;verbs:&lt;/span&gt; &lt;span&gt;[&quot;get&quot;]&lt;/span&gt;&lt;br/&gt;&lt;span&gt;---&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;rbac.authorization.k8s.io/v1beta1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;ClusterRoleBinding&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-crb&lt;/span&gt;&lt;br/&gt;&lt;span&gt;roleRef:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;ClusterRole&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-cr&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;apiGroup:&lt;/span&gt; &lt;span&gt;rbac.authorization.k8s.io&lt;/span&gt;&lt;br/&gt;&lt;span&gt;subjects:&lt;/span&gt;&lt;br/&gt;&lt;span&gt;-&lt;/span&gt; &lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;ServiceAccount&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins-sa&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;namespace:&lt;/span&gt; &lt;span&gt;default&lt;/span&gt;&lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;kubectl&lt;/span&gt; &lt;span&gt;create&lt;/span&gt; &lt;span&gt;-f&lt;/span&gt; &lt;span&gt;jenkins-sa.yaml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4）创建 StatefulSet&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;vim&lt;/span&gt; &lt;span&gt;jenkins-statefulset.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;apps/v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;StatefulSet&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;serviceName:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;replicas:&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;selector:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;matchLabels:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;template:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;&quot;jenkins&quot;&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;labels:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;serviceAccountName:&lt;/span&gt; &lt;span&gt;jenkins-sa&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;containers:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;image:&lt;/span&gt; &lt;span&gt;jenkins/jenkins:lts&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;imagePullPolicy:&lt;/span&gt; &lt;span&gt;IfNotPresent&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;containerPort:&lt;/span&gt; &lt;span&gt;8080&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;containerPort:&lt;/span&gt; &lt;span&gt;50000&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;volumeMounts:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;mountPath:&lt;/span&gt; &lt;span&gt;/var/jenkins_home&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;volumes:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;persistentVolumeClaim:&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;claimName:&lt;/span&gt; &lt;span&gt;jenkins-pvc&lt;/span&gt;          &lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;chown&lt;/span&gt; &lt;span&gt;-R&lt;/span&gt; &lt;span&gt;1000&lt;/span&gt; &lt;span&gt;/app/jenkins&lt;/span&gt;&lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;kubectl&lt;/span&gt; &lt;span&gt;create&lt;/span&gt; &lt;span&gt;-f&lt;/span&gt; &lt;span&gt;jenkins-statefulset.yaml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5）创建 Service&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;vim&lt;/span&gt; &lt;span&gt;jenkins-svc.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;type:&lt;/span&gt; &lt;span&gt;NodePort&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;http&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;port:&lt;/span&gt; &lt;span&gt;8080&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;targetPort:&lt;/span&gt; &lt;span&gt;8080&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;nodePort:&lt;/span&gt; &lt;span&gt;30080&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;agent&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;port:&lt;/span&gt; &lt;span&gt;50000&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;targetPort:&lt;/span&gt; &lt;span&gt;50000&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;nodePort:&lt;/span&gt; &lt;span&gt;30090&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;selector:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;jenkins&lt;/span&gt;&lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;kubectl&lt;/span&gt; &lt;span&gt;create&lt;/span&gt; &lt;span&gt;-f&lt;/span&gt; &lt;span&gt;jenkins-svc.yaml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6）配置 Jenkins&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root&lt;span&gt;@k&lt;/span&gt;8s-master01 ~]# cat /app/jenkins/secrets/initialAdminPassword &lt;br/&gt;a303d66e915e4ee5b26648a64fdff4be&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;http://192.168.1.1:30080/&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4521354933726068&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZc7avE3icGBjTO5r33w0hU7gKnEwTPffMIrKliazlQKGicDiau4vVq3wf90A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1358&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们这里安装推荐的插件即可，后面有需求可以再进行安装&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4521354933726068&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcu0oBicnjW8Kw6kSg8XzkMStW6IpibI2uGbbRiax2B0RdA27ricic2xXw0vQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1358&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4684615384615385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcxalG7kichVnMicic5FPQibLUGhXgLDCzma9MtzOpbcH6tw0do3e5ZquXlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1300&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）在 Jenkins 宿主机上创建 SSH 密钥&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 ~]&lt;span&gt;# ssh-keygen -t rsa        # 三连回车&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# cat ~/.ssh/id_rsa.pub       # 查看公钥&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）将公钥上传到 GitLab 上&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4721189591078067&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcnXPQJcK4J15kyPR7ePUeMMa8L9qeKibnGKs48JvD1bWlHQia8q9SfO1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1345&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3)将仓库克隆到本地&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 ~]&lt;span&gt;# git clone git@github.com:ChenZhuang1217/test.git&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4）编写 Go 代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 ~]# cd test&lt;br/&gt;[root@k8s-master01 test]# vim main.&lt;span&gt;go&lt;/span&gt;&lt;br/&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt; &lt;span&gt;&quot;fmt&quot;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&quot;net/http&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;HelloHandler&lt;/span&gt;&lt;span&gt;(w http.ResponseWriter, r *http.Request)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; fmt.Fprintf(w, &lt;span&gt;&quot;Hello World&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; http.HandleFunc(&lt;span&gt;&quot;/&quot;&lt;/span&gt;, HelloHandler)&lt;br/&gt; http.ListenAndServe(&lt;span&gt;&quot;:8080&quot;&lt;/span&gt;, &lt;span&gt;nil&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5）编写 Dockerfile&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 &lt;span&gt;test&lt;/span&gt;]&lt;span&gt;# vim Dockerfile&lt;/span&gt;&lt;br/&gt;FROM golang:1.16 as builder&lt;br/&gt;ENV GO111MODULE=on \&lt;br/&gt;    GOPROXY=https://goproxy.cn,direct&lt;br/&gt;WORKDIR /app&lt;br/&gt;COPY . .&lt;br/&gt;RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags=&lt;span&gt;&quot;-w -s&quot;&lt;/span&gt; -o main main.go&lt;br/&gt;&lt;br/&gt;FROM busybox:1.28.4&lt;br/&gt;WORKDIR /app&lt;br/&gt;COPY --from=builder /app/ .&lt;br/&gt;EXPOSE 8080&lt;br/&gt;CMD [&lt;span&gt;&quot;./main&quot;&lt;/span&gt;]&lt;br/&gt;[root@k8s-master01 &lt;span&gt;test&lt;/span&gt;]&lt;span&gt;# docker build -t test-web-server:devops-$(date +%Y-%m-%d-%H-%M-%S) .&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6）提交代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 &lt;span&gt;test&lt;/span&gt;]&lt;span&gt;# git add .              # 提交到暂存区&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 &lt;span&gt;test&lt;/span&gt;]&lt;span&gt;# git config --global user.email &quot;Zhuang_zz1217@163.com&quot;  # 配置用户邮箱&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 &lt;span&gt;test&lt;/span&gt;]&lt;span&gt;# git commit -m &quot;This is test CI/CD&quot;       # 提交到本地仓库&lt;/span&gt;&lt;br/&gt;[root@k8s-master01 &lt;span&gt;test&lt;/span&gt;]&lt;span&gt;# git push              # 推送到远程仓库&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;7）创建 Deployment 和 Service&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;vim&lt;/span&gt; &lt;span&gt;test-web-server.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;apps/v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;Deployment&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;replicas:&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;selector:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;matchLabels:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;template:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;labels:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;containers:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;image:&lt;/span&gt; &lt;span&gt;test-web-server:devops-2022-04-25-17-16-54&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;imagePullPolicy:&lt;/span&gt; &lt;span&gt;IfNotPresent&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;containerPort:&lt;/span&gt; &lt;span&gt;8080&lt;/span&gt;&lt;br/&gt;&lt;span&gt;---&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;type:&lt;/span&gt; &lt;span&gt;NodePort&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;port:&lt;/span&gt; &lt;span&gt;8080&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;targetPort:&lt;/span&gt; &lt;span&gt;8080&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;nodePort:&lt;/span&gt; &lt;span&gt;30188&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;selector:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;test-web-server&lt;/span&gt;&lt;br/&gt;&lt;span&gt;[root@k8s-master01&lt;/span&gt; &lt;span&gt;~]#&lt;/span&gt; &lt;span&gt;kubectl&lt;/span&gt; &lt;span&gt;create&lt;/span&gt; &lt;span&gt;-f&lt;/span&gt; &lt;span&gt;test-web-server.yaml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3261058109280139&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcdVm5ra392sxrcxAa604csHTfdTTXIU9YUa1k5micQZc5xAujx2uia8fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1153&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;8)编写 Jenkins 发版脚本&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@k8s-master01 ~]&lt;span&gt;# vim test.sh&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#!/bin/bash&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&amp;gt; 基于 Spring Cloud Alibaba + Gateway + Nacos + RocketMQ + Vue &amp;amp; Element 实现的后台管理系统 + 用户小程序，支持 RBAC 动态权限、多租户、数据权限、工作流、三方登录、支付、短信、商城等功能&lt;br/&gt;&amp;gt;&lt;br/&gt;&amp;gt; * 项目地址：&amp;lt;https://github.com/YunaiV/yudao-cloud&amp;gt;&lt;br/&gt;&amp;gt; * 视频教程：&amp;lt;https://doc.iocoder.cn/video/&amp;gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 固定时间格式&lt;/span&gt;&lt;br/&gt;Second=$(date +%Y-%m-%d-%H-%M-%S)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 备份旧的镜像&lt;/span&gt;&lt;br/&gt;Image=$(kubectl -s https://192.168.1.1:6443 describe pod | grep Image: | awk &lt;span&gt;&#x27;{print $2}&#x27;&lt;/span&gt; | grep &lt;span&gt;test&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; &lt;span&gt;$Image&lt;/span&gt; &amp;gt; /opt/&lt;span&gt;test&lt;/span&gt;-image-&lt;span&gt;$Second&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 克隆代码&lt;/span&gt;&lt;br/&gt;&lt;span&gt;cd&lt;/span&gt; /root&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; [ -d &lt;span&gt;test&lt;/span&gt; ];&lt;br/&gt;&lt;span&gt;then&lt;/span&gt;&lt;br/&gt;  mv &lt;span&gt;test&lt;/span&gt; /opt/&lt;span&gt;test&lt;/span&gt;-devops-&lt;span&gt;$Second&lt;/span&gt;&lt;br/&gt;  git &lt;span&gt;clone&lt;/span&gt; git@github.com:ChenZhuang1217/test.git&lt;br/&gt;&lt;span&gt;else&lt;/span&gt;&lt;br/&gt;  git &lt;span&gt;clone&lt;/span&gt; git@github.com:ChenZhuang1217/test.git&lt;br/&gt;&lt;span&gt;fi&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 发布新的镜像&lt;/span&gt;&lt;br/&gt;&lt;span&gt;cd&lt;/span&gt; /root/&lt;span&gt;test&lt;/span&gt; &amp;amp;&amp;amp; docker build -t &lt;span&gt;test&lt;/span&gt;-web-server:devops-&lt;span&gt;$Second&lt;/span&gt; .&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 上传到镜像仓库&lt;/span&gt;&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; [ $? -eq 0 ];&lt;br/&gt;&lt;span&gt;then&lt;/span&gt;&lt;br/&gt;  docker tag &lt;span&gt;test&lt;/span&gt;-web-server:devops-&lt;span&gt;$Second&lt;/span&gt; harbor.tianya.com:5000/&lt;span&gt;test&lt;/span&gt;-web-server:devops-&lt;span&gt;$Second&lt;/span&gt;&lt;br/&gt;  docker push harbor.tianya.com:5000/&lt;span&gt;test&lt;/span&gt;-web-server:devops-&lt;span&gt;$Second&lt;/span&gt;&lt;br/&gt;&lt;span&gt;else&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;exit&lt;/span&gt; 1   &lt;span&gt;# 退出 (防止运行下面命令)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;fi&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 替换镜像&lt;/span&gt;&lt;br/&gt;sed -i &lt;span&gt;&#x27;s/image:.*/image: harbor.tianya.com:5000\/test-web-server:devops-&#x27;&lt;/span&gt;&lt;span&gt;$Second&lt;/span&gt;&lt;span&gt;&#x27;/g&#x27;&lt;/span&gt; /root/&lt;span&gt;test&lt;/span&gt;-web-server.yaml&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 重启应用&lt;/span&gt;&lt;br/&gt;kubectl delete -f /root/&lt;span&gt;test&lt;/span&gt;-web-server.yaml&lt;br/&gt;kubectl create -f /root/&lt;span&gt;test&lt;/span&gt;-web-server.yaml&lt;br/&gt;[root@k8s-master01 ~]&lt;span&gt;# chmod +x test.sh&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面这个脚本有两步需要注意：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;「上传到镜像仓库：」&lt;/strong&gt; 如果你们没有自己的镜像仓库，可以选择调整脚本或看博主前面写的文章来安装 Harbor 仓库。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;「替换镜像：」&lt;/strong&gt; 我们上面配置的脚本是针对单个模块的，多个模块可以根据 for 循环来实现。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）在 Jenkins 上安装 SSH 插件&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装 SSH 插件的原因是因为，我们这个 Jenkins 是容器安装的，而脚本是在宿主机写的，所以通过远程到宿主机来运行脚本。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.43615494978479197&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcp46PEoR3YWp6wJu819Sb6Efp9Ck3sOJxJdFEvpz4PAia8YV1Swnibm9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1394&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）配置远程主机的用户名和密码&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.44636429085673146&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZceeElufeY26Gqz3BIbZhRrPQDnksSjibUc8gEc8tEpcCJGoGTmmQjxibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1389&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4348452123830094&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcDJV3XQX10iaV7lded2edZcqolbWIGwiblR4libfNl1Np7jJAPYibiccnoBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1389&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3）创建 Jenkins 私钥凭证（类型选择：&lt;code&gt;SSH Username with private key&lt;/code&gt;）&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4589337175792507&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcia52CqaNrW6LHgX3aMaosGJpXXGiaJBJCFXRDZHc4XKlIWm3xXCaReDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1388&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4）配置 Jenkins 流水线&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46708961141950833&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcBAzN5O6icq5pjkmjkPKuibD2gAuymabJ6GxbfcN4w2cuhNKtnn5Iicelw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1261&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46946867565424266&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcQOVD6mJiaHVFH9dZnMQ2pj0Wa8cYyRUUyn7QsQia0CicFia62xOQQe5oYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1261&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4425059476605868&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcmOl8IxBqkyO4yh6S8GK5LdGwBJAmcgbm7zAzRN9WFmTpNnqibxmyl1A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1261&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4425925925925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZctLbxCbnamHtR0CLA7XmhbggicdJxICJbTic1fZBmTsgdeCoIfxwCMBWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5）修改代码&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4750593824228028&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcINiaeIUZOic5PT3DxqbRJJ14pkmeNK718sicfzMTic5dTtGDA1V68lu8wA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1263&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6）在 Jenkins 上发布&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.38142857142857145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcIrN77ic3qAVmyed7oawUQKxOCtXr2zMIsemno87bxovf8CG3epGeH6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.32556131260794474&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe2UZcFz9cMaXCnWbWD5BZcJ2tafb5hhh5IqQibjFHN4r6ADq5Z92ia6Ctl53zSGpEMkoGwRqz6bWiaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1158&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a4c6b493b3e5b2b8243dc2c30e04de72</guid>
<title>作为研发 Leader，如何做迭代管理</title>
<link>https://toutiao.io/k/13892qp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;h1&gt;写在前面&lt;/h1&gt;&lt;p&gt;「迭代流程管理」在每个公司的情况都不一样，随着产品发展阶段、团队规模、资源情况等变化，会进行各种实践和优化。我的团队一般会以半年为单位，进行迭代管理流程的Review，进行相关的流程调整和优化。&lt;/p&gt;&lt;p&gt;以下是我的团队在2023年初，刚刚优化过的迭代流程。&lt;/p&gt;&lt;h1&gt;迭代管理在解决什么问题&lt;/h1&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.705945945945946&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Jq6sJhMhoXVLgicEBw3VRKPT5VX4wo8N3IOMk5GxaMFoOzyiaalCjSQVq8Ix3Rs5y73y2vL1sxYYIe1wtODDRH1A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;925&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;strong&gt;上图中，共分为3个阶段，其中「产品开发」这个阶段，是下文中描述的「迭代流程」部分。&lt;/strong&gt;&lt;/figure&gt;&lt;h1&gt;开发过程方法论&lt;/h1&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.40809443507588533&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Jq6sJhMhoXVLgicEBw3VRKPT5VX4wo8N3RTWL3bekRZE5GDg5k6icCEM2ztcAhBiczTwuzLvAITHLtwc5BNyC1G9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;593&quot;/&gt;&lt;/p&gt;&lt;h1&gt;原则和框架&lt;/h1&gt;&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;说明：&lt;/strong&gt;&lt;strong&gt;在整体迭代阶段上，我们采用类似「瀑布」方式进行了大阶段的拆分；&lt;/strong&gt;&lt;strong&gt;在需求的理解、交付上，我们采用「敏捷」方式，以故事的粒度进行交付和验收。&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;遵循的原则&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;以「人的主观能动性」为核心，高效、高质量交付更有价值的产品，让团队成员成为更好的自己&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;使用的框架&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Scrum + Kanban&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;敏捷（Agile）的目标是为了：帮助我们尽早了解我们到底有多糟糕，尽早管理这种局面。&lt;/strong&gt;&lt;/p&gt;&lt;h1&gt;流程概览&lt;/h1&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.51171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Jq6sJhMhoXVLgicEBw3VRKPT5VX4wo8N3CfI0S2pX13XtKLkHQicJ96VMzH69tibxDibzFxq9Oql3hEgljUxBxSzkg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h1&gt;角色说明&lt;/h1&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6294736842105263&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Jq6sJhMhoXVLgicEBw3VRKPT5VX4wo8N3tfUvnzvrX2ASmPUkKTwicmj6zmIlZJVOLGJZfnbict64VB0jzkQy0FJw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;950&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;角色&lt;/td&gt;&lt;td&gt;职责&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Scrum Master&lt;/td&gt;&lt;td&gt;敏捷教练，推动迭代的进行，目前QA兼任&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;PM&lt;/td&gt;&lt;td&gt;产品经理，进行PRD的输出和讲解&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;RD&lt;/td&gt;&lt;td&gt;服务端工程师，负责后端代码实现&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;FE&lt;/td&gt;&lt;td&gt;前端工程师，负责前端代码实现&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;QA&lt;/td&gt;&lt;td&gt;测试工程师，负责迭代质量&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UI&lt;/td&gt;&lt;td&gt;UI设计师，负责交互和界面设计&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;h1&gt;详细说明&lt;/h1&gt;&lt;h2&gt;需求阶段&lt;/h2&gt;&lt;h3&gt;启动会 Kick Off Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;顾名思义，开球。主要是传达产品价值，以及为什么要做，和本次迭代的目标，不会深入产品细节和原型细节等。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;全体&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;「PM」→ 输出PRD中的产品价值&lt;/section&gt;&lt;section&gt;&lt;span&gt;「Master」→ 在 &lt;/span&gt;&lt;strong&gt;项目管理平台&lt;/strong&gt;&lt;span&gt; 创建迭代版本&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「Master」→ 在 &lt;/span&gt;&lt;strong&gt;沟通工具&lt;/strong&gt;&lt;span&gt; 创建沟通群&lt;/span&gt;&lt;/section&gt;&lt;h3&gt;需求影响分析会 Impact Analysis Meeting&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;熟悉系统现有功能，分析本次迭代变动的影响&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;RD、FE、QA&lt;/p&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「RD 或 FE」→ 讲解系统现有功能，分析影响&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;需求评审会 PRD Review Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;讨论需求、实现逻辑和规则细节，达成整体团队对于本次需求理解的共识（会议次数原则上不应不超过2次）。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;全体&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「PM」→ 输出 Final PRD&lt;/span&gt;&lt;/section&gt;&lt;h3&gt;UI评审会 UI Review Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;讨论页面和交互的实现，达成团队对于本次页面和交互设计的理解共识（会议次数原则上不应不超过2次）。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;全体&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「UI」→ 输出页面和交互设计&lt;/span&gt;&lt;/section&gt;&lt;h2&gt;设计及评估阶段&lt;/h2&gt;&lt;h3&gt;计划会 Plan Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;进行本次迭代内容的确认，可能包含：业务部分、技术部分、遗留问题或Bug等。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;全体&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;「Master」→ 组织计划会，确定本次迭代的范围（Review 项目管理平台 内的遗留问题和Bug）&lt;/p&gt;&lt;h3&gt;设计评审会 Design Review Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;讨论设计、规范、实现、数据迁移、历史技术债务、上线发布等多方面。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;RD 或 FE、QA&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「RD」→ 输出设计文档，并评审（按需）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「FE」 → 输出设计文档，并评审&lt;span&gt;（按需）&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;h3&gt;工作量评估会 Estimate Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;根据计划会的确认的开发范围，进行工作量估算，并分配任务优先级和具体开发人员。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;RD、FE、QA&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;「Master」→ 组织工作量评估会，确定本次迭代的工作量（评估方式：计划扑克）&lt;/p&gt;&lt;h3&gt;「研发周期」计划发布 Plan Deploy&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「QA」→ 发布本次迭代的「研发周期」计划&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;「Master」→ 把各类迭代信息，更新到 &lt;/span&gt;&lt;strong&gt;项目管理平台&lt;/strong&gt;&lt;span&gt;，正式进入编码&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4170008019246191&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Jq6sJhMhoXVLgicEBw3VRKPT5VX4wo8N3xuqP7SkrVJmublBC8kklzCM5xiaQ3MwVEXn9flAzg2soVrdicuiamYuFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1247&quot;/&gt;&lt;/p&gt;&lt;h3&gt;测试用例评审会 Test Case Review Meeting&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;评审测试用例的完整性和合理性。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;RD、FE、QA&lt;/section&gt;&lt;section&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;「QA」→ 组织评审（测试用例维护在 &lt;span&gt;&lt;strong&gt;测试用例管理平台&lt;/strong&gt;&lt;/span&gt;）&lt;/section&gt;&lt;h2&gt;开发阶段&lt;/h2&gt;&lt;h3&gt;每日站会 Stand Up Meeting&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;顺畅、高质量地交付产品价值。聚焦于价值（需求/故事）的流动，而非个人工作。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;全体&lt;/p&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Master」→ 组织会议，主要沟通依赖、Block、风险等&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;故事验收 &amp;amp; 测试 Desk Check &amp;amp; Story Testing&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「RD &amp;amp; FE」→ 发起故事验收（Desk Check）通过后，部署FAT环境进行测试，「QA」记录结果&lt;/span&gt;&lt;span&gt;「QA」→ 针对故事进行测试，当故事没有功能相关问题时，结束此故事测试&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;中期检查 Mid-term Check&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;沟通问题，预知风险&lt;/p&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Master」→ 在迭代进行到中段，组织研发人员进行工作进度的Review，预知Delay风险&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;测试 &amp;amp; 验收阶段&lt;/h2&gt;&lt;h3&gt;系统测试 System Testing&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「RD &amp;amp; FE」→ 整理部署文档，提交部署工单&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「QA」→ 在FAT：&lt;/span&gt;&lt;span&gt;验证部署文档、&lt;/span&gt;&lt;span&gt;冒烟测试、&lt;/span&gt;&lt;span&gt;用例测试（黑盒、白盒）、&lt;/span&gt;&lt;span&gt;回归测试（黑盒、白盒）&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;验收 Acceptance&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「QA」→ 在UAT，&lt;span&gt;验证部署文档&lt;/span&gt;&lt;/span&gt;&lt;span&gt;「PM」→ 进行产品验收&lt;/span&gt;&lt;span&gt;「UI」→ 进行UI验收&lt;/span&gt;&lt;span&gt;「QA」→ 在UAT，&lt;span&gt;回归测试（黑盒、白盒）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;发布阶段&lt;/h2&gt;&lt;h3&gt;发布 Release&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「QA」→ 提交部署工单进行审核，通过后进行发布动作，&lt;/span&gt;&lt;span&gt;填写本次发布说明（对内）&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;迭代回顾阶段&lt;/h2&gt;&lt;h3&gt;迭代回顾会 Review Meeting&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;会议目标：&lt;/strong&gt;总结迭代流程和质量问题，进行复盘，优化迭代流程、代码质量、协作方式等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参加人员：&lt;/strong&gt;全体&lt;/p&gt;&lt;p&gt;&lt;strong&gt;相关动作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Master」→ 汇总迭代数据，进行报告和总结的编写&lt;/span&gt;&lt;span&gt;「Master」→ 组织迭代全部人员进行迭代数据的Review和问题的讨论&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;使用的相关工具或平台&lt;/h1&gt;&lt;section&gt;&lt;span&gt;‍&lt;/span&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;td&gt;工具或平台&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;项目管理平台&lt;/td&gt;&lt;td&gt;https://www.teambition.com/&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;沟通工具&lt;/td&gt;&lt;td&gt;钉钉&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;测试用例管理平台&lt;/td&gt;&lt;td&gt;https://metersphere.io&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>