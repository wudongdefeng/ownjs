<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3cacd216c8bdcc39182f7e18e08caea8</guid>
<title>单体分层应用架构剖析</title>
<link>https://toutiao.io/k/rd927pj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;分层单体架构风格是分层思想在单体架构中的应用，其关注于技术视角的职责分层。同时，基于不同层变化速率的不同，在一定程度上控制变化在系统内的传播，有助于提升系统的稳定性。但这种技术视角而非业务视角的关注点隔离，导致了问题域与工程实现之间的Gap，这种割裂会导致系统认知复杂度的提升。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;作者：倪新明&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;1 经典单体分层架构&lt;/strong&gt;&lt;/h1&gt;

&lt;h2&gt;&lt;strong&gt;1.1 四层单体架构风格&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;经典的四层单体分层架构如下图所示，应用在逻辑上划分为展现层、业务层、持久层及数据存储层，每层的职责如下：&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;展现层&lt;/strong&gt;：负责给最终用户展现信息，并接受用户的输入触发系统的业务逻辑。用户可以是使用系统的人，也可以是其他软件系统。&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;业务层&lt;/strong&gt;：关注系统业务逻辑的实现&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;持久层&lt;/strong&gt;：负责数据的存取&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;数据存储层&lt;/strong&gt;：底层的数据存储设施&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-13cm6qc7o0hF8HcxR.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这种分层单体架构可能是大多数开发人员最早接触、最为熟悉的应用架构风格，其特点是：&lt;/p&gt;

&lt;p&gt;• 层间的依赖关系由上到下逐层向下直接依赖，每层都是关闭状态，请求的数据流向从上到下，必须严格通过每个分层进行流转，而不能进行穿透调用。&lt;/p&gt;

&lt;p&gt;• 关注点隔离：通过分层将系统的关注点进行垂直分配，每层只关注自身层边界内的职责，层间职责相互独立不存在交叉。比如业务层负责处理系统的核心业务逻辑，而持久层则关注于对数据的存取。&lt;/p&gt;

&lt;p&gt;除了关注点隔离这一维度，分层也在 “变化” 的维度进行隔离。每层的变化速率不同，由下级上逐层增加，展现层的变化速率最快，数据存储层变化速率最低。通过严格层依赖关系约束，尽量降低低层变化对上层的影响。这个特点的上下文是分层之间依赖于抽象，而非依赖于具体。当实现发生变化而接口契约不变时，变更范围框定在当前层。但，如果是接口契约的变更，则可能会直接影响到上游的依赖层。&lt;/p&gt;

&lt;p&gt;这种分层架构风格具有明显的优势：&lt;/p&gt;

&lt;p&gt;• 分层模型比较简单，&lt;strong&gt;理解和实现成本低&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 开放人员接受度和熟悉程度高，&lt;strong&gt;认知和学习成本低&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;1.2 五层单体架构风格&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;四层架构面临的问题是:&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;层间数据效率问题&lt;/strong&gt;: 由于层间调用关系的依赖约束，层间的数据流转需要付出额外成本&lt;/p&gt;

&lt;p&gt;• 业务层服务能力的&lt;strong&gt;复用性&lt;/strong&gt;：业务层中处于对等地位的组件或模块之间存在共享服务的诉求&lt;/p&gt;

&lt;p&gt;从复用性的角度考虑，如下所示的五层架构中，&lt;strong&gt;通过引入中间层解决复用问题&lt;/strong&gt;。将共享服务从业务层沉淀到通用服务层，以提高复用性。其特点是：&lt;/p&gt;

&lt;p&gt;• 引入通用服务层提供通用服务，提高复用性&lt;/p&gt;

&lt;p&gt;• 通用服务层是开放层，允许调用链路穿透，业务层可以按需直接访问更下层的持久层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14OjQ7aaKXCwanUr8.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;相比于四层架构，五层分层架构的主要优势是：通过中间层的引入一定程度解决系统的复用性问题。但从反向角度看，正是由于中间层的引入导致了如下问题：&lt;/p&gt;

&lt;p&gt;• 引入中间层&lt;strong&gt;降低了数据传输效率，提高了开发实现成本&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 有造成系统混乱度提升的风险：由于通用服务层的开放性导致业务层可以穿透调用。但这种是否需要进行穿透的场景无法形成统一的判定原则，往往依赖于实现人员的个人经验进行权衡，同一个业务场景由不同的开发人员实现可能会有不同的判定结果（在四层架构中如果放开层间调用约束也会存在该问题）。随着业务需求迭代，系统的依赖关系一定会日趋增加，最终形成复杂的调用关系，也导致系统复杂性上升，增加团队成员的认知成本。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14RSUjM1411pshyudg.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;2 单体分层架构的共性问题探讨&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;当然，正是由于其极高的接受度，也造成了大家对分层的认知误区，认为分层是必然的“默认选项” ，从而忽略了分层的本质。分层到底是为了解决什么问题？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分层本质上是处理复杂性的一种方式：将复杂性在不同级别进行抽象，通过分层进行职责隔离，以此降低认知成本。同时，通过分层形成的“屏障”，控制变化在系统间的传播，提升系统稳定性。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不论是四层架构还是五层架构都是分层思想在单体应用架构风格下的实践，这种分层模式存在的固有问题主要体现在以下几个方面：&lt;/p&gt;

&lt;p&gt;• 分层对系统复杂度和效率的影响&lt;/p&gt;

&lt;p&gt;• 变化真的能完全隔离吗？&lt;/p&gt;

&lt;p&gt;• 问题域与解决方案的隔离&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.1 分层对系统复杂度和效率的影响&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;如上文所述，分层架构中各层的变化速度不同。越往上变化越快，稳定性越低，越往下变化越慢，稳定性越高。比如，展现层的用户展示逻辑可能频繁变化，对应于不同的场景诉求展示数据及形式都可能不同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14DXPTxh6DJMBDIKe.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果划分层次越多，层间依赖关系越严格，则系统的调用链路和依赖关系会更加清晰。但，请求及响应的链路越长，层间数据转换有额外成本。即使引入各种数据转换工具，比如MapStruct，实现起来依然会感觉非常繁琐和重复。&lt;/p&gt;

&lt;p&gt;如果划分层次越多，层间依赖关系宽松，允许跨层调用（如下所示的从展现层调用持久层只是一个示意），则能在一定程度降低数据频繁转换的成本。但:&lt;/p&gt;

&lt;p&gt;• 其一：如何判定是否要跨层调用很难形成统一的严格判定标准，只能进行粗粒度划分。因此，在实现过程中会有不同的判定结果，系统的调用关系会随着代码规模增长而日趋复杂。当然，团队可以加强代码评审的粒度，每次评审基于是否穿透调用进行讨论、判断并达成一致。但实际经验是，由于人为因素，靠严格的代码评审并不能保证决策的一致性。&lt;/p&gt;

&lt;p&gt;• 其二：如果允许跨层调用，则意味着 “模型” 的穿透，低层的模型会直接暴露在更上层，这与我们追求的组件内聚性和模型的封装性存在冲突&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：层间的依赖约束是一种架构决策，可以考虑通过自动化单元测试机制进行保证，具体参考&lt;/p&gt;

&lt;p&gt;《 &lt;a href=&quot;http://xingyun.jd.com/shendeng/article/detail/5358?forumId=79&amp;amp;jdme_router=jdme%3A%2F%2Fweb%2F202206081297%3Furl%3Dhttps%3A%2F%2Fshendengh5.jd.com%2FarticleDetail%3Fid%3D5358&quot;&gt;基于ArchUnit守护系统架构&lt;/a&gt; 》&lt;/p&gt;

&lt;p&gt;《 &lt;a href=&quot;http://xingyun.jd.com/shendeng/article/detail/4226?forumId=79&amp;amp;jdme_router=jdme%3A%2F%2Fweb%2F202206081297%3Furl%3Dhttps%3A%2F%2Fshendengh5.jd.com%2FarticleDetail%3Fid%3D4226&quot;&gt;轻量级的架构决策记录机制&lt;/a&gt; - ADR》&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.2 变化的隔离&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;我们对分层有一个普遍的、“先入为主” 的认知，分层能够隔离变化。首先会想到的例子，比如，如果底层的数据库发生了变更，又或者ORM框架发生了变更，那么，我们只需要修改DAO层的实现，而不需要更改上层的业务层代码。&lt;/p&gt;

&lt;p&gt;• 你真的会替换数据库吗？你真的会替换ORM框架吗？有可能，但概率非常低，大部分系统并不会发生这种场景。&lt;/p&gt;

&lt;p&gt;• 发生替换就真的能隔离吗？如果你的层间不是依赖于抽象，而是依赖于具体，那么隔离也无从谈起。&lt;/p&gt;

&lt;p&gt;• 即使层间依赖于抽象，变化就真的隔离了吗？实现发生变化的直接结果就是依赖方需要引用新的实现，这种变化也同样会影响到上层。只不过是这种变化可能交由IOC容器了&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;但，这个是变化隔离的全部吗&lt;/strong&gt;？&lt;/p&gt;

&lt;p&gt;• 如果是展现层需要增加一个新的字段，而当前数据库模型中没有？&lt;/p&gt;

&lt;p&gt;• 如果是数据库中需要增加一个新的字段，而展现层和业务逻辑层不关心？&lt;/p&gt;

&lt;p&gt;• 如果是......&lt;/p&gt;

&lt;p&gt;所以，引起系统变化的原因很多，场景各异，业务诉求亦不相同，分层对变化隔离程度也不相同：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分层可以控制变化在系统内的传播，由于变化场景的多样化，分层不能完全的隔离变化。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14X8szEXek11zjwh4b.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.3 问题域与解决方案的割裂&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;重新思考下上文提到的分层单体架构的特点之一：关注点隔离，展现层、业务层、数据访问层、存储层等各层聚焦于自身的职责。这种关注点的本质是什么？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术视角的隔离！！！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每层都是从技术视角将技术关注点进行隔离，而非业务领域视角。技术视角是研发友好的，作为开发人员，天然的可以理解和接受这种技术维度的统一语言：DAO层只负责处理数据相关逻辑，Controller层之服务处理Restful API相关，RPC层只处理与外部系统的跨进程调用等等。&lt;/p&gt;

&lt;p&gt;而对于非常核心的业务概念，比如以订单为例，在单体分层架构下需要回答这样一个问题：&lt;strong&gt;“订单组件” 在哪里？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在经典的分层单体架构风格中，典型的实现如下图所示：&lt;/p&gt;

&lt;p&gt;• OrderConroller：Spring技术栈下的系统访问的Rest接口&lt;/p&gt;

&lt;p&gt;• OrderService/OrderServiceImpl：订单的核心业务逻辑实现服务，实现诸如下单、取消订单等逻辑&lt;/p&gt;

&lt;p&gt;• OrderDAO/OrdeDAOImpl：订单数据的存取&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-15rljiOOZWX8fPXou.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;订单组件&lt;strong&gt;并不是以一个单一的、内聚的事物存在&lt;/strong&gt;，其组成元素OrderService以及其依赖的OrderDAO分散于不同的层，因此，这种模式下订单组件只是&lt;strong&gt;逻辑性、概念性&lt;/strong&gt;的存在。作为业务域的核心抽象，订单组件没有真实的、直观的、内聚的反映在代码实现中。我们在工程代码库中寻找“订单组件”：&lt;/p&gt;

&lt;p&gt;• 首先，在工程顶层最先看到的是技术视角的Module(Maven Module)：web、service 、dao&lt;/p&gt;

&lt;p&gt;• 然后，需要在各层导航才能一窥其全貌&lt;/p&gt;

&lt;p&gt;在IDE的支持下，这种导航并不会很复杂。但问题的根本在于：&lt;strong&gt;认知成本的增加&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们去了解系统，&lt;strong&gt;天然的是从业务域而非技术域出发，单体分层恰恰是从技术域而非业务域出发，这种不同导致业务域与实现间的割裂，增加了对系统的认知成本&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现要反应抽象，组件化思维本质上一种模块化思维，通过内聚性和封装性，将问题空间进行拆分成子空间，分而治之。对外通过接口提供组件能力，屏蔽内部的复杂性。接口契约的大小粒度需要权衡，粒度越小，能力提供越约聚焦，理解和接入成本越低，但通用性越差。接口契约粒度越大，则通用性越强，但理解和接入复杂性越高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-157XexthS9xLghJLo.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;将组件化思维应用于单体分层架构，引申出模块化单体架构风格。&lt;strong&gt;应用架构按照问题域进行模块化组织，而非基于技术关注点进行拆分&lt;/strong&gt;。组件内部遵循内聚性原则，其内包含了实现组件能力所需要的各个元素及交互关系。组件之间通过统一的、合适粒度的接口契约进行交互，不直接依赖于组件的内部能力或模型。同时，组织良好的模块化单体应用架构也是进行微服务拆分的重要保证。如果你无法在单体架构中进行优雅的模块化组织，又何谈合理的微服务拆分呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-15swKLc4lHaASumTQ.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;3 结语&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;单体分层架构风格是分层思想在单体架构中的应用，其关注于技术视角的职责分层。同时，基于不同层变化速率的不同，在一定程度上控制变化在系统内的传播，有助于提升系统的稳定性。但这种技术视角而非业务视角的关注点隔离，导致了问题域与工程实现之间的Gap，这种割裂会导致系统认知复杂度的提升。将组件化思维应用于单体分层架构，模块化单体技术视角的分层拉回至业务域视角的模块化，一定程度上降低业务与工程实现间的隔离。良好的模块化是单体走向微服务的重要基石，如果模块化设计较差的系统，不仅会增加微服务拆分的成本，更为重要的是，会增加形成分布式单体的概率和风险。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>05a6b9ae0f8e0cc552cc1ab0ba79afd7</guid>
<title>这几种神级性能优化手段，你用过几个？</title>
<link>https://toutiao.io/k/qgdj6f4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;引言：取与舍&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;软件设计开发某种意义上是“取”与“舍”的艺术。关于性能方面，就像建筑设计成抗震9度需要额外的成本一样，高性能软件系统也意味着更高的实现成本，有时候与其他质量属性甚至会冲突，比如安全性、可扩展性、可观测性等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大部分时候我们需要的是：在业务遇到瓶颈之前，利用常见的技术手段将系统优化到预期水平。那么，&lt;strong&gt;性能优化有哪些技术方向和手段呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;性能优化通常是“时间”与“空间”的互换与取舍&lt;/strong&gt;。本篇讲解六种通用的“时间”与“空间”互换取舍的手段：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每种性能优化的技术手段，我都找了一张&lt;strong&gt;应景&lt;/strong&gt;的《火影忍者》中人物或忍术的配图，评论区答出任意人物或忍术送一颗小星星。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（注：所有配图来自动漫《火影忍者》，部分图片添加了文字方便理解，仅作技术交流用途）&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;索引术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7157001414427157&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6a9VECuBLuibg6uu4GuP8rMjYc6aCXvyMOlAicchgJWiaA5wWULvafVzz9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;707&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;10ms之后。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7241379310344828&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6adPxiagQf98PtgyHdDpf4vS92TD7EiaLbhYeiboHAuOhpJtnU0VT9Q8lzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;580&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;索引&lt;/strong&gt;的原理是&lt;strong&gt;拿额外的存储空间换取查询时间&lt;/strong&gt;，增加了&lt;strong&gt;写入数据&lt;/strong&gt;的开销，但使&lt;strong&gt;读取数据&lt;/strong&gt;的时间复杂度一般从O(n)降低到O(logn)甚至O(1)。索引不仅在数据库中广泛使用，前后端的开发中也在不知不觉运用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据集比较大时，不用索引就像从一本&lt;strong&gt;没有目录而且内容乱序&lt;/strong&gt;的新华字典查一个字，得一页一页全翻一遍才能找到；用索引之后，就像用拼音先在目录中先&lt;strong&gt;找到要查到字在哪一页&lt;/strong&gt;，直接翻过去就行了。书籍的目录是典型的树状结构，那么软件世界常见的索引有哪些数据结构，分别在什么场景使用呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;哈希表（Hash Table）&lt;/strong&gt;：哈希表的原理可以类比银行办业务取号，给每个人一个号（计算出的Hash值），叫某个号直接对应了某个人，索引效率是最高的O(1)，消耗的存储空间也相对更大。K-V存储组件以及各种编程语言提供的Map/Dict等数据结构，多数底层实现是用的哈希表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;二叉搜索树（Binary Search Tree）&lt;/strong&gt;：有序存储的二叉树结构，在编程语言中广泛使用的&lt;span&gt;&lt;strong&gt;红黑树&lt;/strong&gt;&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;属于二叉搜索树，确切的说是“不完全平衡的”二叉搜索树。从C++、Java的TreeSet、TreeMap，到&lt;span&gt;Linux的CPU调度&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;，都能看到红黑树的影子。Java的HashMap在发现某个Hash槽的链表长度大于8时也会将链表升级为红黑树，而相比于红黑树“更加平衡”的AVL树反而实际用的更少。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;平衡多路搜索树（B-Tree）&lt;/strong&gt;：这里的B指的是Balance而不是Binary，二叉树在大量数据场景会导致查找深度很深，解决办法就是变成多叉树，MongoDB的索引用的就是B-Tree。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;叶节点相连的平衡多路搜索树（B+ Tree）&lt;/strong&gt;：B+ Tree是B-Tree的变体，只有叶子节点存数据，叶子与相邻叶子相连，MySQL的索引用的就是B+树，Linux的一些文件系统也使用的B+树索引inode。其实B+树还有一种在枝桠上再加链表的变体：B*树，暂时没想到实际应用。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;日志结构合并树（LSM Tree）&lt;/strong&gt;：Log Structured Merge Tree，简单理解就是像日志一样顺序写下去，多层多块的结构，上层写满压缩合并到下层。LSM Tree其实本身是为了优化写性能牺牲读性能的数据结构，并不能算是索引，但在大数据存储和一些NoSQL数据库中用的很广泛，因此这里也列进去了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;字典树（Trie Tree）&lt;/strong&gt;：又叫前缀树，从树根串到树叶就是数据本身，因此树根到枝桠就是前缀，枝桠下面的所有数据都是匹配该前缀的。这种结构能非常方便的做前缀查找或词频统计，典型的应用有：自动补全、URL路由。其变体基数树（Radix Tree）在Nginx的Geo模块处理子网掩码前缀用了；Redis的Stream、Cluster等功能的实现也用到了基数树（Redis中叫Rax）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;跳表（Skip List）&lt;/strong&gt;：是一种多层结构的有序链表，插入一个值时有一定概率“晋升”到上层形成间接的索引。跳表更适合大量并发写的场景，不存在红黑树的再平衡问题，Redis强大的ZSet底层数据结构就是哈希加跳表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;倒排索引（Inverted index）&lt;/strong&gt;：这样翻译不太直观，可以叫“关键词索引”，比如书籍末页列出的术语表就是倒排索引，标识出了每个术语出现在哪些页，这样我们要查某个术语在哪用的，从术语表一查，翻到所在的页数即可。倒排索引在全文索引存储中经常用到，比如ElasticSearch非常核心的机制就是倒排索引；Prometheus的时序数据库按标签查询也是在用倒排索引。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据库主键之争&lt;/strong&gt;：自增长 vs UUID。主键是很多数据库非常重要的索引，尤其是MySQL这样的RDBMS会经常面临这个难题：是用自增长的ID还是随机的UUID做主键？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自增长ID的性能最高，但不好做分库分表后的全局唯一ID，自增长的规律可能泄露业务信息；而UUID不具有可读性且太占存储空间。争执的结果就是找一个兼具二者的优点的&lt;strong&gt;折衷方案&lt;/strong&gt;：用&lt;strong&gt;雪花算法&lt;/strong&gt;生成分布式环境全局唯一的ID作为业务表主键，性能尚可、不那么占存储、又能保证全局单调递增，但引入了额外的复杂性，再次体现了取舍之道。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再回到&lt;strong&gt;数据库&lt;/strong&gt;中的索引，建索引要注意哪些点呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;定义好主键并尽量使用主键，多数数据库中，主键是效率最高的&lt;strong&gt;聚簇索引&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在&lt;strong&gt;Where&lt;/strong&gt;或&lt;strong&gt;Group By、Order By、Join On&lt;/strong&gt;条件中用到的字段也要&lt;strong&gt;按需&lt;/strong&gt;建索引或联合索引，MySQL中搭配explain命令可以查询DML是否利用了索引；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;类似枚举值这样重复度太高的字段&lt;strong&gt;不适合&lt;/strong&gt;建索引（如果有位图索引可以建），频繁更新的列不太适合建索引；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;单列索引可以根据&lt;strong&gt;实际查询的字段&lt;/strong&gt;升级为&lt;strong&gt;联合索引&lt;/strong&gt;，通过部分冗余达到&lt;strong&gt;索引覆盖&lt;/strong&gt;，以&lt;strong&gt;避免回表&lt;/strong&gt;的开销；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量减少索引冗余，比如建A、B、C三个字段的联合索引，Where条件查询A、A and B、A and B and C 都可以利用该联合索引，就无需再给A单独建索引了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;根据数据库特有的索引特性选择适合的方案，比如像MongoDB，还可以建自动删除数据的&lt;strong&gt;TTL索引&lt;/strong&gt;、不索引空值的&lt;strong&gt;稀疏索引&lt;/strong&gt;、地理位置信息的&lt;strong&gt;Geo索引&lt;/strong&gt;等等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据库之外&lt;/strong&gt;，在代码中也能应用索引的思维，比如对于集合中大量数据的查找，使用&lt;strong&gt;Set、Map、Tree&lt;/strong&gt;这样的数据结构，其实也是在用哈希索引或树状索引，比&lt;strong&gt;直接遍历&lt;/strong&gt;列表或数组查找的性能高很多。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;缓存术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5381165919282511&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6aJTaeRCRARibHgUiaNicNy4UkBlmMpvqNOPWmfZFdyCsu2j8brhiaibEf7Pw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;缓存&lt;/strong&gt;优化性能的原理和索引一样，是拿额外的&lt;strong&gt;存储空间换取查询时间&lt;/strong&gt;。缓存无处不在，设想一下我们在浏览器打开这篇文章，会有多少层缓存呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;首先解析DNS时，浏览器一层DNS缓存、操作系统一层DNS缓存、DNS服务器链上层层缓存；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;发送一个GET请求这篇文章，服务端很可能早已将其缓存在KV存储组件中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使没有击中缓存，数据库服务器内存中也缓存了最近查询的数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使没有击中数据库服务器的缓存，数据库从索引文件中读取，操作系统已经把热点文件的内容放置在Page Cache中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使没有击中操作系统的文件缓存，直接读取文件，大部分固态硬盘或者磁盘本身也自带缓存；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据取到之后服务器用模板引擎渲染出HTML，模板引擎早已解析好缓存在服务端内存中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;历经数十毫秒之后，终于服务器返回了一个渲染后的HTML，浏览器端解析DOM树，发送请求来加载静态资源；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;需要加载的静态资源可能因Cache-Control在浏览器本地磁盘和内存中已经缓存了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使本地缓存到期，也可能因Etag没变服务器告诉浏览器304 Not Modified继续缓存；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使Etag变了，静态资源服务器也因其他用户访问过早已将文件缓存在内存中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;加载的JS文件会丢到JS引擎执行，其中可能涉及的种种缓存就不再展开了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;整个过程中链条上涉及的&lt;strong&gt;所有的计算机和网络设备&lt;/strong&gt;，执行的热点代码和数据很可能会载入CPU的多级高速缓存。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里列举的&lt;strong&gt;仅仅是一部分&lt;/strong&gt;常见的缓存，就有多种多样的形式：从廉价的磁盘到昂贵的CPU高速缓存，最终目的都是用来换取宝贵的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;缓存是“银弹”吗？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不，Phil Karlton 曾说过：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;计算机科学中只有两件困难的事情：缓存失效和命名规范。There are only two hard things in Computer Science: cache invalidation and naming things.&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缓存的使用除了带来额外的复杂度以外，还面临如何处理&lt;strong&gt;缓存失效&lt;/strong&gt;的问题。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;多线程并发编程需要用各种手段（比如Java中的synchronized volatile）防止并发更新数据，一部分原因就是防止线程&lt;strong&gt;本地缓存的不一致&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缓存失效衍生的问题还有：&lt;strong&gt;缓存穿透、缓存击穿、缓存雪崩&lt;/strong&gt;。解决用不存在的Key来穿透攻击，需要用空值缓存或布隆过滤器；解决单个缓存过期后，瞬间被大量恶意查询击穿的问题需要做查询互斥；解决某个时间点大量缓存同时过期的雪崩问题需要添加随机TTL；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;热点数据如果是&lt;strong&gt;多级缓存&lt;/strong&gt;，在发生修改时需要清除或修改&lt;strong&gt;各级缓存&lt;/strong&gt;，这些操作往往不是原子操作，又会涉及各种不一致问题。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了通常意义上的缓存外，&lt;strong&gt;对象重用的池化技术&lt;/strong&gt;，也可以看作是一种&lt;strong&gt;缓存的变体&lt;/strong&gt;。常见的诸如JVM，V8这类运行时的&lt;strong&gt;常量池、数据库连接池、HTTP连接池、线程池、Golang的sync.Pool对象池&lt;/strong&gt;等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在需要某个资源时从现有的池子里直接拿一个，稍作修改或直接用于另外的用途，池化重用也是性能优化常见手段。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;压缩术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5297418630751964&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6aMWhBpZThh7Lb3oDmvSQ2JLIyqClBqhaDtGqVd4iaZxteWdOMUSq68ibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;891&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说完了两个“空间换时间”的，我们再看一个“&lt;strong&gt;时间换空间&lt;/strong&gt;”的办法——&lt;strong&gt;压缩&lt;/strong&gt;。压缩的原理&lt;strong&gt;消耗计算的时间，换一种更紧凑的编码方式来表示数据&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么要拿时间换空间？时间不是最宝贵的资源吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举一个视频网站的例子，如果不对视频做任何压缩编码，因为带宽有限，巨大的数据量在网络传输的耗时会比编码压缩的耗时多得多。&lt;strong&gt;对数据的压缩虽然消耗了时间来换取更小的空间存储，但更小的存储空间会在另一个维度带来更大的时间收益&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个例子本质上是：“&lt;strong&gt;操作系统内核与网络设备处理负担 vs 压缩解压的CPU/GPU负担&lt;/strong&gt;”的权衡和取舍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在代码中通常用的是&lt;strong&gt;无损压缩&lt;/strong&gt;，比如下面这些场景:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;HTTP协议中Accept-Encoding添加Gzip/deflate，服务端对接受压缩的文本（JS/CSS/HTML）请求做压缩，大部分图片格式本身已经是压缩的无需压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HTTP2协议的头部HPACK压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;JS/CSS文件的混淆和压缩（Uglify/Minify）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些RPC协议和消息队列传输的消息中，采用二进制编码和压缩（Gzip、Snappy、LZ4等等）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缓存服务存过大的数据，通常也会事先压缩一下再存，取的时候解压；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些大文件的存储，或者不常用的历史数据存储，采用更高压缩比的算法存储；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;JVM的对象指针压缩，JVM在32G以下的堆内存情况下默认开启“UseCompressedOops”，用4个byte就可以表示一个对象的指针，这也是JVM尽量不要把堆内存设置到32G以上的原因；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MongoDB的二进制存储的BSON相对于纯文本的JSON也是一种压缩，或者说更紧凑的编码。但更紧凑的编码也意味着更差的可读性，这一点也是需要取舍的。纯文本的JSON比二进制编码要更占存储空间但却是REST API的主流，因为数据交换的场景下的可读性是非常重要的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;信息论&lt;/strong&gt;告诉我们，无损压缩的极限是&lt;strong&gt;&lt;span&gt;信息熵&lt;/span&gt;&lt;/strong&gt;&lt;sup&gt;[3]&lt;/sup&gt;。进一步减小体积只能以损失部分信息为代价，也就是&lt;strong&gt;有损压缩&lt;/strong&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.23484848484848486&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6abuGViacAhE9tgbkBDynOh1CiblSpsrNO5eKJc8Aj4mwzib9d4PGa8Hxog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;264&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么，有损压缩有哪些应用呢？&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;预览和缩略图，低速网络下视频降帧、降清晰度，都是对信息的有损压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;音视频等多媒体数据的&lt;strong&gt;采样和编码&lt;/strong&gt;大多是有损的，比如MP3是利用傅里叶变换，有损地存储音频文件；jpeg等图片编码也是有损的。虽然有像WAV/PCM这类无损的音频编码方式，但多媒体数据的&lt;strong&gt;采样本身就是有损的&lt;/strong&gt;，相当于只截取了真实世界的极小一部分数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;散列化&lt;/strong&gt;，比如K-V存储时Key过长，先对Key执行一次“傻”系列（SHA-1、SHA-256）哈希算法变成固定长度的短Key。另外，散列化在文件和数据验证（MD5、CRC、HMAC）场景用的也非常多，无需耗费大量算力对比完整的数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了有损/无损压缩，但还有一个办法，就是&lt;strong&gt;压缩的极端&lt;/strong&gt;——从根本上&lt;strong&gt;减少数据或彻底删除&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;能减少的就减少&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;JS打包过程“摇树”，去掉没有使用的文件、函数、变量；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;开启HTTP/2和高版本的TLS，减少了Round Trip，节省了TCP连接，自带大量性能优化；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;减少不必要的信息，比如Cookie的数量，去掉不必要的HTTP请求头；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;更新采用增量更新，比如HTTP的PATCH，只传输变化的属性而不是整条数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缩短单行日志的长度、缩短URL、在具有可读性情况下用短的属性名等等；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用位图和位操作，用风骚的&lt;strong&gt;位操作最小化存取的数据&lt;/strong&gt;。典型的例子有：用Redis的位图来记录统计海量用户登录状态；布隆过滤器用位图排除不可能存在的数据；大量开关型的设置的存储等等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;能删除的就删除&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;删掉不用的数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删掉不用的索引；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删掉不该打的日志；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删掉不必要的通信代码，不去发不必要的HTTP、RPC请求或调用，轮询改发布订阅；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;终极方案：砍掉整个功能&lt;/strong&gt;。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;No code is the best way to write secure and reliable applications. Write nothing; deploy nowhere. —— Kelsey Hightower&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;预取术&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;预取&lt;/strong&gt;通常搭配缓存一起用，其原理是&lt;strong&gt;在缓存空间换时间基础上&lt;/strong&gt;更进一步，再加上一次“&lt;strong&gt;时间换时间&lt;/strong&gt;”，也就是：&lt;strong&gt;用事先预取的耗时，换取第一次加载的时间&lt;/strong&gt;。当可以猜测出以后的某个时间很有可能会用到某种数据时，把数据预先取到需要用的地方，能大幅度提升用户体验或服务端响应速度。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6365461847389559&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6acXwyaLDXHxm0zTNzdrxkgwFNnDCLnaNtZAXSghEDshuYf8IicNUc5ZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;996&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;是否用预取模式就像自助餐餐厅与厨师现做的区别，在自助餐餐厅可以直接拿做好的菜品，一般餐厅需要坐下来等菜品现做。那么，预取在哪些实际场景会用呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;视频或直播类网站，在播放前先缓冲一小段时间，就是预取数据。有的在播放时不仅预取这一条数据，甚至还会预测下一个要看的其他内容，提前把数据取到本地；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;HTTP/2 Server Push&lt;/strong&gt;，在浏览器请求某个资源时，服务器顺带把其他相关的资源一起推回去，HTML/JS/CSS几乎同时到达浏览器端，相当于浏览器被动预取了资源；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些客户端软件会用常驻进程的形式，提前预取数据或执行一些代码，这样可以极大提高第一次使用的打开速度；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务端同样也会用一些预热机制，一方面&lt;strong&gt;热点数据预取到内存提前形成多级缓存&lt;/strong&gt;；另一方面也是&lt;strong&gt;对运行环境的预热&lt;/strong&gt;，载入CPU高速缓存、热点函数JIT编译成机器码等等；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;热点资源提前预分配&lt;/strong&gt;到各个实例，比如：秒杀、售票的&lt;strong&gt;库存性质的数据&lt;/strong&gt;；分布式&lt;strong&gt;唯一ID&lt;/strong&gt;等等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;天上不会掉馅饼，&lt;strong&gt;预取也是有副作用的&lt;/strong&gt;。正如烤箱预热需要消耗时间和额外的电费，在软件代码中做预取/预热的副作用通常是启动慢一些、占用一些闲时的计算资源、可能取到的&lt;strong&gt;不一定是后面需要的&lt;/strong&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;削峰填谷术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6816143497757847&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6aMevojEweGOON8OqB7btIyMlKhmyR4KDwRvpsFkxUKWK4UchQPibWgbw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;削峰填谷&lt;/strong&gt;的原理也是“&lt;strong&gt;时间换时间&lt;/strong&gt;”，&lt;strong&gt;谷时换峰时&lt;/strong&gt;。削峰填谷与&lt;strong&gt;预取&lt;/strong&gt;是反过来的：预取是事先花时间做，削峰填谷是事后花时间做。就像三峡大坝可以抗住短期巨量洪水，事后雨停再慢慢开闸防水。软件世界的“削峰填谷”是类似的，只是不是用三峡大坝实现，而是用消息队列、异步化等方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的有这几类问题，我们分别来看每种对应的解决方案：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;针对前端、客户端的&lt;strong&gt;启动优化或首屏优化&lt;/strong&gt;：代码和数据等资源的&lt;strong&gt;延时加载、分批加载、后台异步加载、或按需懒加载&lt;/strong&gt;等等。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;背压控制&lt;/strong&gt; - &lt;strong&gt;限流、节流、去抖&lt;/strong&gt;等等。一夫当关，万夫莫开，从&lt;strong&gt;入口处削峰&lt;/strong&gt;，防止一些恶意重复请求以及请求过于频繁的爬虫，甚至是一些DDoS攻击。简单做法有网关层根据单个IP或用户用漏桶控制请求速率和上限；前端做按钮的节流去抖防止重复点击；网络层开启TCP SYN Cookie防止恶意的SYN洪水攻击等等。彻底杜绝爬虫、黑客手段的恶意洪水攻击是很难的，DDoS这类属于网络安全范畴了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;针对正常的业务请求洪峰，&lt;strong&gt;用消息队列暂存再异步化处理&lt;/strong&gt;：常见的后端消息队列&lt;strong&gt;Kafka、RocketMQ&lt;/strong&gt;甚至Redis等等都可以做缓冲层，第一层业务处理直接校验后丢到消息队列中，在洪峰过去后慢慢消费消息队列中的消息，执行具体的业务。另外执行过程中的耗时和耗计算资源的操作，也可以丢到消息队列或数据库中，等到谷时处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;捋平毛刺&lt;/strong&gt;：有时候洪峰不一定来自外界，如果系统内部大量&lt;strong&gt;定时任务&lt;/strong&gt;在同一时间执行，或与业务高峰期重合，很容易在监控中看到“毛刺”——短时间负载极高。一般解决方案就是错峰执行定时任务，或者分配到其他非核心业务系统中，把“毛刺”摊平。比如很多数据分析型任务都放在业务低谷期去执行，大量定时任务在创建时尽量加一些随机性来分散执行时间。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;避免错误风暴带来的次生洪峰&lt;/strong&gt;：有时候网络抖动或短暂宕机，业务会出现各种异常或错误。这时处理不好很容易带来&lt;strong&gt;次生灾害&lt;/strong&gt;，比如：很多代码都会做错误重试，不加控制的大量重试甚至会导致网络抖动恢复后的瞬间，积压的大量请求再次冲垮整个系统；还有一些代码没有做超时、降级等处理，可能导致大量的等待耗尽TCP连接，进而导致整个系统被冲垮。解决之道就是做限定次数、间隔指数级增长的Back-Off重试，设定超时、降级策略。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;批量处理术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6982055464926591&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6a7sjebwZJ9tjNg1Es0huCVUBEf1ibAicXyfHwwmN7M52reX3IicPVbK1UA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;613&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;批量处理&lt;/strong&gt;同样可以看成“&lt;strong&gt;时间换时间&lt;/strong&gt;”，其原理是&lt;strong&gt;减少了重复的事情，是一种对执行流程的压缩&lt;/strong&gt;。以&lt;strong&gt;个别批量操作更长的耗时为代价，在整体上换取了更多的时间&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量处理的应用也非常广泛，我们还是从前端开始讲：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;打包合并的JS文件、雪碧图等等，将&lt;strong&gt;一批资源&lt;/strong&gt;集中到一起，&lt;strong&gt;一次性传输&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;前端动画使用requestAnimationFrame在UI渲染时&lt;strong&gt;批量处理积压的变化&lt;/strong&gt;，而不是有变化立刻更新，在游戏开发中也有类似的应用；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;前后端中使用&lt;strong&gt;队列暂存临时产生的数据&lt;/strong&gt;，积压到一定数量再批量处理；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在不影响可扩展性情况下，&lt;strong&gt;一个接口传输多种需要的数据&lt;/strong&gt;，减少大量ajax调用（&lt;strong&gt;GraphQL&lt;/strong&gt;在这一点就做到了极致）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;系统间通信尽量发送整批数据&lt;/strong&gt;，比如&lt;strong&gt;消息队列的发布订阅、存取缓存服务的数据、RPC调用、插入或更新数据库&lt;/strong&gt;等等，能批量做尽可能批量做，因为这些系统间通信的I/O时间开销已经很昂贵了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;数据积压到一定程度再落盘&lt;/strong&gt;，操作系统本身的写文件就是这么做的，Linux的fwrite只是写入缓冲区暂存，积压到一定程度再fsync刷盘。在应用层，很多高性能的数据库和K-V存储的实现都体现了这一点：一些NoSQL的LSM Tree的第一层就是在内存中先积压到一定大小再往下层合并；Redis的RDB结合AOF的落盘机制；Linux系统调用也提供了批量读写多个缓冲区文件的系统调用：readv/writev；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;延迟地批量回收资源&lt;/strong&gt;，比如JVM的Survivor Space的S0和S1区互换、Redis的Key过期的清除策略。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量处理如此好用，那么问题来了，&lt;strong&gt;每一批放多大最合适呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个问题其实没有定论，有一些个人经验可以分享。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;前端把所有文件打包成单个JS，大部分时候并不是最优解。Webpack提供了很多分块的机制，CSS和JS分开、JS按业务分更小的Chunk结合懒加载、一些体积大又不用在首屏用的第三方库设置external或单独分块，可能整体性能更高。不一定要一批搞定所有事情，分几个小批次反而用户体验的性能更好。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Redis的&lt;strong&gt;MGET、MSET&lt;/strong&gt;来批量存取数据时，每批大小&lt;strong&gt;不宜过大&lt;/strong&gt;，因为Redis主线程只有一个，如果一批太大执行期间会让其他命令无法响应。经验上一批50-100个Key性能是不错的，但最好在真实环境下用真实大小的数据量化度量一下，做Benchmark测试才能确定一批大小的最优值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MySQL、Oracle这类RDBMS，最优的批量Insert的大小也视数据行的特性而定。我之前在2U8G的Oracle上用一些普遍的业务数据做过测试，批量插入时每批5000-10000条数据性能是最高的，每批过大会导致DML的解析耗时过长，甚至单个SQL语句体积超限，单批太多反而得不偿失。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消息队列的发布订阅，每批的消息长度尽量控制在1MB以内，有些云服务商提供的消息队列限制了最大长度，那这个长度可能就是&lt;strong&gt;性能拐点&lt;/strong&gt;，比如AWS的SQS服务对单条消息的限制是256KB。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之，多大一批可以确保单批响应时间不太长的同时让整体性能最高，是需要在实际情况下做基准测试的，不能一概而论。而批量处理的&lt;strong&gt;副作用&lt;/strong&gt;在于：处理逻辑会更加复杂，尤其是一些涉及事务、并发的问题；需要用数组或队列用来存放缓冲一批数据，消耗了额外的存储空间。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;小结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先聊到这里，大都是“时间”与“空间”的取舍之术，这些思路在很多地方甚至是非软件领域都是&lt;strong&gt;普适&lt;/strong&gt;的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;&lt;strong&gt;红黑树&lt;/strong&gt;: &lt;em&gt;https://www.jianshu.com/p/e136ec79235c&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;Linux的CPU调度: &lt;em&gt;https://en.wikipedia.org/wiki/Completely_Fair_Scheduler&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;&lt;strong&gt;信息熵&lt;/strong&gt;: &lt;em&gt;https://www.ruanyifeng.com/blog/2014/09/information-entropy.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>dbf7e8bdd8486948b257b2047c9d6ba2</guid>
<title>深入浅出学习透析 Nginx 服务器的基本原理和配置指南（Keepalive 性能优化实战篇）</title>
<link>https://toutiao.io/k/fzspi5p</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;content_views&quot; class=&quot;markdown_views prism-tomorrow-night&quot;&gt;
                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
                        &lt;path stroke-linecap=&quot;round&quot; d=&quot;M5,0 0,2.5 5,5z&quot; id=&quot;raphael-marker-block&quot;/&gt;
                    &lt;/svg&gt;
                    &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/a4bcbd66fab94f30938a34c53bce13e6.png&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;Linux系统：Centos 7 x64&lt;/li&gt;&lt;li&gt;Nginx版本：1.11.5&lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;Nginx 是一款面向性能设计的 HTTP 服务器，能反向代理 HTTP，HTTPS 和邮件相关(SMTP，POP3，IMAP)的协议链接。并且提供了负载均衡以及 HTTP 缓存。它的设计充分使用异步事件模型，削减上下文调度的开销，提高服务器并发能力。采用了模块化设计，提供了丰富模块的第三方模块。所以关于 Nginx，有这些标签：「异步」「事件」「模块化」「高性能」「高并发」「反向代理」「负载均衡」「长连接」。本章内容主要就是针对于长连接请求模块。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_8&quot;/&gt;为什么要单独讲解keepalive指令？&lt;/h3&gt; 
&lt;p&gt;upstream设置中，有个参数要特别的小心，就是这个keepalive。&lt;/p&gt; 
&lt;p&gt;大多数未仔细研读过nginx的同学通常都会误解这个参数，有些人理解为这里的keepalive是设置是否打开长连接，以为应该设置为on/off。有些人会被前面的keepalive_timeout误导，以为这里也是设置keepalive的timeout。&lt;/p&gt; 
&lt;p&gt;但是实际上这个keepalive参数的含义非常的奇特，请小心看nginx文档中的说明，因为Keepalive长连接非常重要而且容易理解错误，所以专门做连一期专门讲解keepalive的文章。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;本文介绍如何使用Nginx进行配置和实现长连接Keepalive，并介绍如何设置 nginx 以提供静态内容服务，如何配置 nginx 作为代理服务器。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_19&quot;/&gt;keepalive指令&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/ea9babb9b5f54550a425d15ee14ae989.webp#pic_center&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;支持keepalive长连接，当使用nginx作为反向代理时，为了支持长连接，需要做到两点：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;从client到nginx的连接是长连接&lt;/li&gt;&lt;li&gt;从nginx到server的连接是长连接&lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;从HTTP协议的角度看，Nginx在这个过程中，对于客户端它扮演着HTTP服务器端的角色。而对于真正的服务器端（在nginx的术语中称为upstream）Nginx又扮演着HTTP客户端的角色，keepalive指令出现在版本1.1.4。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_31&quot;/&gt;keepalive指令格式&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt;keepalive不是on/off之类的开关&lt;/li&gt;&lt;li&gt;keepalive不是timeout，不是用来设置超时值&lt;/li&gt;&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;Syntax:    keepalive connections;
Default:    —
Context:    upstream
Activates the cache for connections to upstream servers.
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;connections的取值代表着连接到upstream服务器的持续连接（即长连接）的数量。很多人都会有一个误解：认为这个参数是设置到upstream服务器的长连接的数量，分歧在于是最大连接数还是最小连接数&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;&lt;a id=&quot;_45&quot;/&gt;官方文档的介绍&lt;/h5&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;The connections parameter sets the maximum number of idle keepalive connections to upstream servers&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt;connections参数设置到upstream服务器的空闲keepalive连接的最大数量，这个”idle”的概念，何为idle。大多数人之所以误解为是到upstream服务器的最大长连接数，一般都是因为看到了文档中的这句话，而漏看了这个”idle”一词。&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;When this number is exceeded, the least recently used connections are closed.&lt;/p&gt; 
&lt;/blockquote&gt; 
 
&lt;p&gt;Nginx的官方文档给出了指示，否定了最大连接数的可能：&lt;strong&gt;keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量&lt;/strong&gt;。&lt;strong&gt;请注意空闲keepalive连接的最大数量中空闲这个关键字&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_55&quot;/&gt;keepalive实际场景分析&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;先假设一个场景： 有一个HTTP服务，作为upstream服务器接收请求，响应时间为100毫秒。如果要达到10000 QPS的性能，就需要在nginx和upstream服务器之间建立大约1000条HTTP连接。nginx为此建立连接池，然后请求过来时为每个请求分配一个连接，请求结束时回收连接放入连接池中，连接的状态也就更改为idle。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;之后假设这个upstream服务器的keepalive参数设置比较小，比如常见的10.&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;再次假设请求和响应是均匀而平稳的，那么这1000条连接应该都是一放回连接池就立即被后续请求申请使用，线程池中的idle线程会非常的少，趋进于零。我们以10毫秒为一个单位，来看连接的情况(注意场景是1000个线程+100毫秒响应时间，每秒有10000个请求完成)：&lt;/p&gt; 
  &lt;ul&gt;&lt;li&gt;每10毫秒有100个新请求，需要100个连接&lt;/li&gt;&lt;li&gt;每10毫秒有100个请求结束，可以释放100个连接&lt;/li&gt;&lt;li&gt;如果请求和应答都均匀，则10毫秒内释放的连接刚好够用，不需要新建连接，连接池空闲连接为零&lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;如果请求通常不是足够的均匀和平稳，为了简化问题，我们假设应答始终都是平稳的，只是请求不平稳，第一个10毫秒只有50,第二个10毫秒有150：&lt;/p&gt; 
   &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;strong&gt;再下一个10个毫秒，有150个请求进来，有100个请求结束任务释放连接。150 - 100 = 50,空缺了50个连接，减掉前面连接池保留的10个空闲连接，nginx不得不新建40个新连接来满足要求&lt;/strong&gt;。&lt;/p&gt; 
   &lt;/li&gt;&lt;li&gt; &lt;p&gt;前10毫秒，进来100个请求，结束50个请求，导致连接不够用，nginx为此新建50个连接&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;后10毫秒，进来100个请求，结束150个请求，导致空闲连接过多，ngixn为此关闭了150-100-10=40个空闲连接&lt;/p&gt; 
  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;第二个应答不均匀的场景实际上是对应第一个请求不均匀的场景：正是因为请求不均匀，所以导致100毫秒之后这些请求的应答必然不均匀&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;现实世界中的请求往往和理想状态有巨大差异，请求不均匀，服务器处理请求的时间也不平稳，这理论上的大概1000个连接在反复的回收和再分配的过程中，必然出现两种非常矛盾场景在短时间内反复：&lt;/p&gt; 
&lt;ol&gt;&lt;li&gt;连接不够用，造成新建连接&lt;/li&gt;&lt;li&gt;连接空闲，造成关闭连接。从而使得总连接数出现反复震荡，不断的创建新连接和关闭连接，使得长连接的效果被大大削弱。&lt;/li&gt;&lt;/ol&gt; 
&lt;h4&gt;&lt;a id=&quot;Keepalive_88&quot;/&gt;Keepalive参数建议&lt;/h4&gt; 
&lt;p&gt;造成连接数量反复震荡的一个推手，就是这个keepalive 这个最大空闲连接数。毕竟连接池中的1000个连接在频繁利用时，出现短时间内多余10个空闲连接的概率实在太高。因此为了避免出现上面的连接震荡，必须考虑加大这个参数，&lt;strong&gt;比如上面的场景如果将keepalive设置为100或者200,就可以非常有效的缓冲请求和应答不均匀&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_92&quot;/&gt;keepalive参数分析&lt;/h3&gt; 
&lt;ul&gt;&lt;li&gt;对应的参数设置为每个worker子进程在缓冲中保持的到upstream服务器的空闲keepalive连接的最大数量。当超过这个数量值的时候，会将最近最少使用（LRU）的连接进行关闭。需要考虑的是keepalive指令不会限制一个worker进程到upstream服务器连接的总数量。其参数应该设置为一个足够小的数字来让upstream服务器来处理新进来的连接。&lt;/li&gt;&lt;li&gt;如果想让upstream每次都处理新的进来的连接，就应该将这个值放的足够小。反过来理解，就是如果不想让upstream服务器处理新连接，就应该放大一些？&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;Keepalive_97&quot;/&gt;Keepalive的使用案例&lt;/h4&gt; 
&lt;h5&gt;&lt;a id=&quot;Keepalivememcached_99&quot;/&gt;Keepalive对接memcached服务&lt;/h5&gt; 
&lt;p&gt;使用keepalive连接的memcached upstream配置的例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream memcached_backend {
    server 127.0.0.1:11211;
    server 10.0.0.2:11211;
    keepalive 32;
}
server {
    ...
    location /memcached/ {
        set $memcached_key $uri;
        memcached_pass memcached_backend;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveHttp11Web_117&quot;/&gt;Keepalive对接Http1.1的Web服务&lt;/h5&gt; 
&lt;p&gt;对于HTTP，proxy_http_version指定应该设置为”1.1”，而”Connection” header应该被清理：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream http_backend {
    server 127.0.0.1:8080;
    keepalive 16;
}
server {
    ...
    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection &quot;&quot;;
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveHttp10Web_136&quot;/&gt;Keepalive对接Http1.0的Web服务&lt;/h5&gt; 
&lt;p&gt;HTTP/1.0 持久连接可以通过传递”&lt;strong&gt;Connection: Keep-Alive&lt;/strong&gt;” header 到upstream server， 但是不推荐使用这种方法。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveFastCGIWeb_140&quot;/&gt;Keepalive对接FastCGI的Web服务&lt;/h5&gt; 
&lt;p&gt;对于FastCGI服务器，要求设置fastcgi_keep_conn来让长连接工作：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream fastcgi_backend {
    server 127.0.0.1:9000;
    keepalive 8;
}
server {
    ...
    location /fastcgi/ {
        fastcgi_pass fastcgi_backend;
        fastcgi_keep_conn on;
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;当使用默认的round-robin之外的负载均衡算法时，必须在keepalive指令之前激活他们。SCGI 和 uwsgi 协议没有keepalive连接的概念。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;client_161&quot;/&gt;保持和client的长连接&lt;/h3&gt; 
&lt;p&gt;为了在client和nginx之间保持上连接，有两个要求：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;client发送的HTTP请求要求keep alive&lt;/li&gt;&lt;li&gt;nginx设置上支持keep alive&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;HTTP_167&quot;/&gt;HTTP配置&lt;/h4&gt; 
&lt;p&gt;默认情况下，Nginx已经自动开启了对client连接的keep alive支持。一般场景可以直接使用，但是对于一些比较特殊的场景，还是有必要调整个别参数。需要修改nginx的配置文件(在nginx安装目录下的conf/nginx.conf):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http {
    keepalive_timeout  120s 120s;
    keepalive_requests 10000;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_timeout_178&quot;/&gt;keepalive_timeout指令&lt;/h4&gt; 
&lt;p&gt;keepalive_timeout指令的语法：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Syntax:    keepalive_timeout timeout [header_timeout];
Default:    keepalive_timeout 75s;
Context:    http, server, location
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt;&lt;li&gt;第一个参数设置keep-alive客户端连接在服务器端保持开启的超时值。值为0会禁用keep-alive客户端连接。&lt;/li&gt;&lt;li&gt;可选的第二个参数在响应的header域中设置一个值“Keep-Alive: timeout=time”。这两个参数可以不一样。&lt;/li&gt;&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;注：默认75s一般情况下也够用，对于一些请求比较大的内部服务器通讯的场景，适当加大为120s或者300s。第二个参数通常可以不用设置&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_requests_193&quot;/&gt;keepalive_requests指令&lt;/h4&gt; 
&lt;p&gt;keepalive_requests指令用于设置一个keep-alive连接上可以服务的请求的最大数量。当最大请求数量达到时，连接被关闭。默认是100。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;keepalive_requests_197&quot;/&gt;keepalive_requests指令的实现原理&lt;/h5&gt; 
&lt;ul&gt;&lt;li&gt;指一个keepalive请求建立之后，Nginx就会为这个连接设置一个计数器，记录这个keep alive的长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则Nginx会强行关闭这个长连接，逼迫客户端不得不重新建立新的长连接。&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;这个参数往往被大多数人忽略，因为大多数情况下当QPS(每秒请求数)不是很高时，默认值100凑合够用。但是，对于一些QPS比较高（比如超过10000QPS，甚至达到30000,50000甚至更高) 的场景，默认的100就显得太低&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;&lt;strong&gt;简单计算一下，QPS=10000时，客户端每秒发送10000个请求(通常建立有多个长连接)，每个连接只能最多跑100次请求，意味着平均每秒钟就会有100个长连接因此被nginx关闭&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;为了保持QPS，客户端不得不每秒中重新新建100个连接。因此，如果用netstat命令看客户端机器，就会发现有大量的TIME_WAIT的socket连接(即使此时keep alive已经在client和nginx之间生效)。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;因此对于QPS较高的场景，非常有必要加大这个参数，以避免出现大量连接被生成再抛弃的情况，减少TIME_WAIT&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a id=&quot;server_209&quot;/&gt;保持和server的长连接&lt;/h3&gt; 
&lt;p&gt;为了让Nginx和server（Nginx称为upstream）之间保持长连接，典型设置如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http {
    upstream  BACKEND {
        server   192.168.0.1：8080  weight=1 max_fails=2 fail_timeout=30s;
        server   192.168.0.2：8080  weight=1 max_fails=2 fail_timeout=30s;
        keepalive 300;        // 这个很重要！
    }
    server {
        listen 8080 default_server;
        server_name &quot;&quot;;
        location /  {
            proxy_pass http://BACKEND;
            proxy_set_header Host  $Host;
            proxy_set_header x-forwarded-for $remote_addr;
            proxy_set_header X-Real-IP $remote_addr;
            add_header Cache-Control no-store;
            add_header Pragma  no-cache;
            proxy_http_version 1.1;                    // 这两个最好也设置
            proxy_set_header Connection &quot;&quot;;
            client_max_body_size  3072k;
            client_body_buffer_size 128k;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr/&gt; 
&lt;h4&gt;&lt;a id=&quot;_240&quot;/&gt;总结&lt;/h4&gt; 

                &lt;/div&gt;
                
                
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e2b0d2f163e2a98db100c03aee26fbdd</guid>
<title>MySQL 数据库索引技术原理初探</title>
<link>https://toutiao.io/k/vwg43on</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;article fmt article-content &quot;&gt;&lt;h2&gt;概述&lt;/h2&gt;&lt;h3&gt;什么是索引&lt;/h3&gt;&lt;p&gt;一本书 500 页的书，如果没有目录，直接去找某个知识点，可能需要找一会儿，但是借助前面的目录，就可以快速找到对应知识点在书的哪一页。这里的目录就是索引。&lt;/p&gt;&lt;p&gt;所以，为什么会有索引？为了提高数据查询效率。&lt;/p&gt;&lt;h2&gt;常见索引算法&lt;/h2&gt;&lt;p&gt;最简单也最容易想到的索引算法就是有序数组了，我们创建一个数组，数组按照顺序排列，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912713&quot; alt=&quot;img&quot; title=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们要查找某一条记录，使用二分法就可以快速得到(log N)，从图中我们可以看出，有序数组作为索引时，处理等值查询和范围查询时性能会非常优秀。既然这么优秀，为什么我们不使用它呢？&lt;/p&gt;&lt;p&gt;因为它的插入性能很差，每次往中间插入一条记录，就必须挪动后面所有的记录，这个成本太高了。&lt;/p&gt;&lt;p&gt;第二种算法时哈希表，哈希表时一种 KV 形式存储的数据结构，比如我们平时用的 HashMap。哈希表的思路非常简单，用一个哈希函数把Key 换算成一个确定的位置，把 V 放到这个位置就可以了。&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912714&quot; alt=&quot;img&quot; title=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们可以看得出，哈希表这种数据结构在进行等值查询的时候，效率时非常高的，我们常用的 Redis 以及以前比较流行的 Memcached 都使用了哈希表。但是哈希表有个致命缺陷，就是对范围查询的支持性非常差，因为数据的存储时无序的，无论我们要查询的范围有多大，都必须把所有的数据全部便利一遍做个排序才行。&lt;/p&gt;&lt;p&gt;在讲第三种索引方式之前，我们简单了解下机械硬盘存取数据的原理&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912715&quot; alt=&quot;image-20210326092749979&quot; title=&quot;image-20210326092749979&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;要访问磁盘上的某个条数据，我们需要通过磁道，扇区来确定数据所在的 Block，然后通过 Offset  就可以定位到磁盘上的任意一个字节。从磁盘上读取数据时，都是以 Block 的形式读取的。这里我们可以看到，一个 Block 的大小是 512 Bytes，当然，这是针对磁盘设备的，对于 Linux 的文件系统来说，一个 Block 一般是 4KB。InnoDB 数据存取是以数据页为单位的，数据页相比磁盘 Block 要大一些，一般默认是 16KB。为了简化整个模型，我们这里抛开复杂的数据页或者文件系统 Block 概念，从磁盘的 Block 开始说起&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912716&quot; alt=&quot;image-20210326092835533&quot; title=&quot;image-20210326092835533&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;假设我们的数据库里面存储了 1000 条记录，每条记录占用 128 Bytes，前面我们说过，一个磁盘的 Block 能够存储 512 Bytes，也就是说，一个 Block 可以存储 4 条记录，存储这些记录，一共需要 250 个 Blocks。当我们需要查询一条数据时，最多需要从磁盘加载 250 个Blocks，想想读取 250 次磁盘会有多慢！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912717&quot; alt=&quot;image-20210326092923323&quot; title=&quot;image-20210326092923323&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;为了减少对磁盘的访问次数，我们可以把所有记录的 id 单独拿出来创建一个索引 L1，这个 id 和指向原始数据的地址组成了一个新的数据结构，它的长度这里是 16 Bytes，索引也是需要存储到磁盘的，一个 Block 可以存储 32 条索引记录，1000条索引记录需要 （1000/32=31.25） 32 个 Blocks。这时候我们需要查询一条数据时，就变成了先从索引表中查询出对应数据的指针（读取 32 个 Blocks），然后再去源数据表中根据地址直接读取记录所在的数据块（1个Block）。看，通过增加一个索引，我们成功的将磁盘读取次数从 250 次减少到了 33 次。我们可不可以让读取磁盘次数更少呢，当然可以！再增加一级索引呗！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912718&quot; alt=&quot;image-20210326093000953&quot; title=&quot;image-20210326093000953&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;新添加的这一级索引指向了前面我们添加的索引 L1 所在的数据块。在这一级索引上，每一条记录都对应了 L1 索引所在的数据块，也就是 32 条L1索引记录所在的位置。1000条数据在这里还剩多少呢，前面我们说过，1000条数据共需要 32 个 L1 索引 Block，对应在这里也就是需要 32 条 L2 索引，总空间占用才 32x16 = 512 Bytes，刚好一个磁盘 Block 大小。到这一级，我们需要访问磁盘的次数就变成了 1+1+1=3 了！&lt;/p&gt;&lt;p&gt;我们把上面这个图抽象一下，去掉其中的细节，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912719&quot; alt=&quot;image-20210326093031086&quot; title=&quot;image-20210326093031086&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;当我们把它旋转一下的时候，我们就得到了这样一种数据结构&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912720&quot; alt=&quot;image-20210326093055460&quot; title=&quot;image-20210326093055460&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;看！这不就是一棵树嘛&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912721&quot; alt=&quot;image-20210326104832514&quot; title=&quot;image-20210326104832514&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;说到树，我们知道最简单的就是二叉树了，二叉树的典型特点是有序，左子树小于父节点，右子树大于父节点。无论是搜索效率还是插入效率，二叉树的效率都是非常高的（log N），但是大多数数据库并不使用它，这是为什么呢？&lt;/p&gt;&lt;p&gt;因为我们的数据是存储在磁盘上的，程序运行过程中要使用数据，必须从磁盘把数据加载到内存才行。二叉树随着节点的增多，树的高度页越来越高，对应到磁盘访问上，我们就需要访问更多的数据块。当我们的数据存储在机械硬盘的时候，从磁盘随机读取一个数据块就需要 10ms 左右的寻址时间，也就是说，如果我们扫描一个 100 万行的表，单独访问一行就可能需要 20 个 10ms，可想可知这个查询会有多慢！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912722&quot; alt=&quot;_images/binary-tree.png&quot; title=&quot;_images/binary-tree.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;当然，我们这棵树可不是二叉树，因为每个分支都可能有很多条记录。我们把这种树称为 N 叉树，也就是多叉树，树的分叉越多，每个节点的子节点就越多，树的高度就越低。因此就有B-Tree 和 B+Tree。&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912723&quot; alt=&quot;Image 1&quot; title=&quot;Image 1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;h2&gt;B+Tree 索引&lt;/h2&gt;&lt;p&gt;讲到 B+ 树索引，我们就不得不一下 B 树索引，前面我们简单了解了下二叉树，我们知道，二叉树的树高太大，会严重影响查询效率，为了解决这个问题，就有了 B 树&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912724&quot; alt=&quot;索引&quot; title=&quot;索引&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;B树是为了更好的实现索引结构而被创造出来的，它大幅度减少了磁盘访问的次数。除此之外，它还充分利用了“局部性原理”（数据有序，相关性强）。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;局部性原理：在一段时间内，整个程序的执行仅限于程序的某一部分，相应的，执行所访问的存储空间也局限于某个内存区域。局部性原理分为时间局部性和空间局部性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;时间局部性：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）&lt;/li&gt;&lt;li&gt;空间局部性：如果一个存储器的位置被引用，那么将来它附近的位置也会被引用&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;利用局部性原理可以实现磁盘预读，前面提过，InnoDB一次是读取一页的数据（16K），也就是说，每次我们实际加载的数据比我们需要的可能会多一些，这些数据可以缓存在内存中，未来我们需要读取的时候，就可以避免磁盘 IO 了。&lt;/p&gt;&lt;p&gt;但是B树有着下面两个缺陷&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个节点都存储数据，因此索引会变得很大，每个 Block 能够容纳的索引数就会变少，我们也就需要访问更多次的磁盘&lt;/li&gt;&lt;li&gt;对范围查询支持不是很好，需要中序遍历&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这两个问题，B+ 树就诞生了，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912725&quot; alt=&quot;索引&quot; title=&quot;索引&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;B+树只有叶子节点才存储数据，其它节点不再存储数据，所有的叶子节点都在同一层上，叶子节点之间增加了一条链表，通过这条链表，我们就可以依次直接遍历所有数据。这些变化，让 B+ 树拥有了比 B 树更优秀的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;非叶子节点不存储数据，可以实现查询加速（一次磁盘访问可以读取更多的索引记录，减少磁盘访问）&lt;/li&gt;&lt;li&gt;范围查询更加优秀，可以顺着叶子节点的链表直接查询出某一个范围内的数据&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;B+数是一棵 N 叉树，N 的大小取决于索引字段的大小，以整数字段索引为例，N≈1200，当树高为 4 的时候，就是 1200 的 3 次方，17亿。一个 10 亿行的表上一个整数字段索引，查找一个值最多只需要访问 3 次磁盘（树根一般在内存中）。&lt;/p&gt;&lt;p&gt;MySQL 的 InnoDB 就是采用了 B+ 树作为默认的索引算法，前面我们说了，B+树只在叶子节点存储数据，但是这个叶子节点存储的是什么数据呢? 我们根据叶子存储数据类型的不同分为两种索引&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主键索引，也成为聚簇索引（Clustered index），在叶子节点存储的是整行数据&lt;/li&gt;&lt;li&gt;非主键索引，也成为二级索引（Secondary index），叶子节点存储的是主键的值&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912726&quot; alt=&quot;image-20210326115557786&quot; title=&quot;image-20210326115557786&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;正因为在 InnoDB 中，我们的数据也是存储在一个索引（主键索引）里的，因此，我们称 InnoDB 是索引组织表。二级索引存储的是数据的主键，当我们使用二级索引查询一条数据的时候，首先会从二级索引中查询到这条记录的 ID，然后拿这个 ID 去主键索引查询真正的数据，我们称这个过程为 回表。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;因为二级索引存储的是主键的 ID，因此通常我们会选择 integer 或者 bigint 等整型类型作为主键，这样做的目的是可以减少二级索引占用空间的大小。如果用字符串作为主键，可想可知二级索引会有多大！&lt;/p&gt;&lt;p&gt;除了上面这个外，通常要求主键一定是要自增的，这样做是为了保证主键的有序，每次插入数据都是追加到 B+ 树，避免页分裂（如果数据页满了，则需要申请新的数据页，然后挪动部分数据过去，这个过程叫做 页分裂）的产生，提高数据写入性能。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;从上面讲的这些，我们可以想到下面几个优化索引的技巧&lt;/p&gt;&lt;ul&gt;&lt;li&gt;索引应该尽可能小，这样一次磁盘读取可以返回尽可能多的索引数据，在查询数据时就可以减少磁盘 IO&lt;/li&gt;&lt;li&gt;大表查询尽可能的使用索引，不使用索引就会造成全表扫描，想想一个查询，需要遍历几百万数据，读取成千上百次磁盘会有多慢&lt;/li&gt;&lt;li&gt;如果可能，尽量使用主键索引进行查询，使用主键索引可以直接触达数据，不需要执行回表，减少磁盘 IO&lt;/li&gt;&lt;li&gt;如果索引中包含了我们要查询的所有字段，那就不需要在进行回表，可以减少磁盘 IO，显著提升查询性能，我们把这种查询数据都在索引里面的情况叫做覆盖索引&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;这次分享中，我们先简单介绍了下两种简单的索引结构，然后从数据在磁盘的存储说起，从没有索引到建立多级索引，解释了为什么会出现树索引以及B树索引和 B+树索引，最后我们介绍了下 InnoDB 中关于主键索引和二级索引的概念和几个优化索引的技巧。&lt;/p&gt;&lt;p&gt;本文将会持续修正和更新，最新内容请参考我的 &lt;a href=&quot;https://link.segmentfault.com/?enc=EEqu1wvH%2Bicw4Q6AlzddVA%3D%3D.J3iqbgU3haTK5wpWhmTxI7dqua4Pwc7s3oeqlTLvNDI%3D&quot; rel=&quot;nofollow&quot;&gt;GITHUB&lt;/a&gt; 上的 &lt;a href=&quot;https://link.segmentfault.com/?enc=5XUVTlPU%2BCMk3No7yYyR2w%3D%3D.5hT6Tiz1beWVXmGt0TPUR0Lfncq14kHMJdDcKSkYR%2BpNMbCKsCYCdky%2BhAZiHRmE&quot; rel=&quot;nofollow&quot;&gt;程序猿成长计划&lt;/a&gt; 项目，欢迎 Star，更多精彩内容请 &lt;a href=&quot;https://link.segmentfault.com/?enc=xgvnO08KYatQ5F%2BWWsgYLQ%3D%3D.ciNNSwwnGpG%2Bif6gFWbeO4g1mpz532Li4581ugY9jPY%3D&quot; rel=&quot;nofollow&quot;&gt;follow me&lt;/a&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b85d90b9f8df4ae5fe265b343626eb17</guid>
<title>刨根问底 Redis， 面试过程真好使</title>
<link>https://toutiao.io/k/zr5xga5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，这里是 &lt;strong&gt;菜农曰&lt;/strong&gt;，欢迎来到我的频道。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;充满寒气的互联网如何在面试中脱颖而出，平时积累很重要，八股文更不能少！下面带来的这篇 Redis 问答希望能够在你的 offer 上增添一把🔥。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Web 应用发展的初期阶段，一个网站的访问量本身就不是很高，直接使用关系型数据库就可以应付绝大部分场景。但是随着互联网时代的崛起，人们对于网站访问速度有着越来越高的要求，直接使用关系型数据库的方案在性能上就出现了瓶颈。因此在客户端与数据层之间就需要一个缓存层来分担请求压力，而 Redis 作为一款优秀的缓存中间件，在企业级架构中占有重要的地位，因此 Redis 也作为面试的必问项。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9590551181102362&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBNmo8taIL9Ria7icMowvHrYW0pJsAcGic5HICbg4Eb0NiaaPDFtzsZ1icOrA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;635&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;本文通过30个问题，由浅入深，最大程度上覆盖整个Redis的问答内容&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.33264675592173&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBMEJiaINeicVO5po51KtujLkvRXbxKibt7IK2veJsicqWssPINRtDkvJia6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;971&quot;/&gt;&lt;/figure&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.42696629213483145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBUibeUjnqr4zLIvHv6HeHWfCvPMroJdTD2CEiaWj63DxSgAyhxXnUAYJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;267&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis（Remote Dictionary Server）是一个开源的、键值对型的数据存储系统。使用C语言编写，遵守BSD协议，可基于内存也可持久化的日志型数据库，提供了多种语言的API，被广泛用于数据库、缓存和消息中间件。并且支持多种类型的数据结构，用于应对各种不同场景。可以存储多种不同类型值之间的映射，支持事务，持久化，LUA 脚本以及多种集群方案等。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.37012987012987014&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBK5CnA01uEEjqicEvYIYM5a6YXw0umchMiaOLdib2xNC99WrIhELiaDoEzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;308&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;完全基于内存操作，性能极高，读写速度快，Redis 能够支持超过 100KB/s 的读写速率&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;支持高并发，支持10万级别的并发读写&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;支持主从模式，支持读写分离与分布式&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;具有丰富的数据类型与丰富的特性（发布订阅模式）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;支持持久化操作，不会丢失数据&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;数据库容量受到物理内存的限制，不能实现海量数据的高性能读写&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;相比关系型数据库，不支持复杂逻辑查询，且存储结构相对简单&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;虽然提供持久化能力，但实际更多是一个 disk-backed 功能，与传统意义上的持久化有所区别&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2608695652173913&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBtzAQ6udQvY7gDRfFOQQIp7fRgNOMqSwFDvSawFibQ84asRrWJxL5LVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;437&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Memcache 也是一个开源、高性能、分布式内存对象缓存系统。所有数据均存储在内存中，在服务器重启之后就会消失，需要重新加载数据，采用 hash 表的方式将所有数据缓存在内存中，采用 LRU 算法来逐渐把过期的数据清除掉。&lt;/p&gt;&lt;/blockquote&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;数据类型&lt;/strong&gt;：Memcache 仅支持字符串类型，Redis 支持 5 种不同的数据类型&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;数据持久化&lt;/strong&gt;：Memcache 不支持持久化，Redis 支持两种持久化策略，RDB 快照 和 AOF 日志&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;分布式&lt;/strong&gt;：Memcache 不支持分布式，只能在客户端使用一致性哈希的方式来实现分布式存储，Redis3.0 之后可在服务端构建分布式存储，Redis集群没有中心节点，各个节点地位平等，具有线性可伸缩的功能。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;内存管理机制&lt;/strong&gt;：Memcache数据量不能超出系统内存，但可以调整内存大小，淘汰策略采用LRU算法。Redis增加了 VM 特性，实现了物理内存的限制，它们之间底层实现方式以及客户端之间通信的应用协议不一样。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;数据大小限制&lt;/strong&gt;：Memcache 单个 key-value 大小有限制，一个Value最大容量为 1MB，Redis 最大容量为512 MB&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2638888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBUhSNxXKXEaPmYknHKsqhRhxUWqfz9Hiavwda3ja4Y2KMaQcicic0BccVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;432&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;基本数据类型：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;String（字符串）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Hash（哈希）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;List（列表）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Set（集合）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ZSet（Sorted Set 有序集合）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;高级数据类型：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;HyperLogLog：用来做基数统计的算法，在输入元素的数量或体积非常大时，计算基数所需的空间总是固定的，并且是很小的。HyperLogLog 只会根据输入元素来计算基数，而不会存储输入元素本身&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Geo：用来地理位置的存储和计算&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;BitMap：实际上不是特殊的存储结构，本质上是二进制字符串，可以进行位操作，常用于统计日活跃用户等&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;em&gt;扩展：&lt;/em&gt; geohash通过算法将1个定位的经度和纬度2个数值，转换成1个hash字符串。如果2个地方距离越近，那么他们的hash值的前缀越相同。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.23030303030303031&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBNVpfbor1yic7PJ6gPVzo9v2icjTt0nNzdnZUn7jhQ9oGWt1THegtcGaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;495&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 底层实现了简单动态字符串的类型（Simple Dynamic String，SDS）来表示 String 类型。没有直接使用C语言定义的字符串类型。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;SDS 实现相对于C语言String方式的提升&lt;/p&gt;&lt;/blockquote&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;避免缓冲区移除。对字符修改时，可以根据 len 属性检查空间是否满足要求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;获取字符串长度的复杂度较低&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;减少内存分配次数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;兼容C字符串函数，可以重用C语言库的一部分函数&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.25054466230936817&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBZ0WvKUGwiaYh7Y93DKibyfjHbliasf8UdLgAvIJ7sorYf0S5CWCh15iaBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;459&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 直接以内存的方式存储可以达到最快的读写速度，如果开启了持久化则通过异步的方式将数据写入磁盘，因此Redis 具有快速和数据持久化的特征。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内存中操作本身就比从磁盘操作更快，且不受磁盘I/O速度的影响。如果不将数据放在内存中而是保存到磁盘，磁盘I/O速度会严重影响到Redis 的性能，而数据集大小如果达到了内存的最大限定值则不能继续插入新值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果打开了虚拟内存功能，当内存用尽时，Redis就会把那些不经常使用的数据存储到磁盘，如果Redis中的虚拟内存被禁了，它就会操作系统的虚拟内存（交换内存），但这时Redis的性能会急剧下降。如果配置了淘汰机制，会根据已配置的数据淘汰机制来淘汰旧数据。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.26573426573426573&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB6Zn8xRkp7nzfzTDd06dcIdP1yX3PrcegYtB42I5VyMZV1v7NVUXZXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;429&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、&lt;strong&gt;尽可能使用哈希表（hash 数据结构）&lt;/strong&gt;：Redis 在储存小于100个字段的Hash结构上，其存储效率是非常高的。所以在不需要集合（set）操作或 list 的push/pop 操作的时候，尽可能使用 hash 结构。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、&lt;strong&gt;根据业务场景，考虑使用 BitMap&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、&lt;strong&gt;充分利用共享对象池&lt;/strong&gt;：Redis 启动时会自动创建【0-9999】的整数对象池，对于 0-9999的内部整数类型的元素，整数值对象都会直接引用整数对象池中的对象，因此尽量使用 0-9999 整数对象可节省内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、&lt;strong&gt;合理使用内存回收策略&lt;/strong&gt;：过期数据清除、expire 设置数据过期时间等&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2608695652173913&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB9UYADDrIFSibUVdEiaP6nsUIh5MxZtw6lpFvVvX4qu3sxp4S9ibvWUatg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;437&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Redis 能够用来实现分布式锁的命令有 INCR、SETNX、SET，并利用过期时间命令 expire 作为辅助&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式1：利用 INCR&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 key 不存在，则初始化值为 0，然后再利用 &lt;code&gt;INCR&lt;/code&gt; 进行加 1 操作。后续用户如果获取到的值大于等于 1，说明已经被其他线程加锁。当持有锁的用户在执行完任务后，利用 &lt;code&gt;DECR&lt;/code&gt; 命令将 key 的值减 1，则表示释放锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式2：利用 SETNX&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先使用 &lt;code&gt;setnx&lt;/code&gt; 来争抢锁，抢到之后利用 &lt;code&gt;expire&lt;/code&gt; 设置一个过期时间防止未能释放锁。&lt;code&gt;setnx&lt;/code&gt; 的意义是如果 key 不存在，则将key设置为 value，返回 1。如果已存在，则不做任何操作，返回 0。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式3：利用 SET&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;set&lt;/code&gt; 指令有非常复杂的参数，相当于合成了 &lt;code&gt;setnx&lt;/code&gt; 和 &lt;code&gt;expire&lt;/code&gt; 两条命令的功能。其命令格式如：&lt;code&gt;set($Key,$value, array(&#x27;nx&#x27;, &#x27;ex&#x27;=&amp;gt;$ttl))&lt;/code&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.30238726790450926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBNWPytZicN29qvK9Detvq0Jf0B1zralngkppWq3PXsqP7kibPzF1QsibcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;377&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;完全基于内存&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据结构简单，操作方便，并且不同数据结构能够应对于不同场景&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;采用单线程（网络请求模块使用单线程，其他模块仍用了多线程），避免了不必要的上下文切换和竞争条件，也不存在多进程或多线程切换导致CPU消耗，不需要考虑各种锁的问题。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;使用多路I/O复用模型，为非阻塞I/O&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Redis 本身设定了 VM 机制，没有使用 OS 的Swap，可以实现冷热数据分离，避免因为内存不足而造成访问速度下降的问题&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.29533678756476683&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBR2rFJicqUacqlLQlp3Ww2kLlM02RxslfBR4ssWSqccp1ia2MYYaF2kfQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;386&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1、RDB（Redis DataBase）持久化&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RDB 是 Redis 中默认的持久化机制，按照一定的时间将内存中的数据以快照的方式保存到磁盘中，它会产生一个特殊类型的文件 &lt;code&gt;.rdb&lt;/code&gt; 文件，同时可以通过配置文件中的 &lt;code&gt;save&lt;/code&gt; 参数来定义快照的周期&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 RDB 中有两个核心概念 &lt;code&gt;fork&lt;/code&gt; 和 &lt;code&gt;cow&lt;/code&gt;，在执行备份的流程如下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在执行&lt;code&gt;bgsave&lt;/code&gt;的时候，Redis 会 fork 主进程得到一个新的子进程，子进程是共享主进程内存数据的，会将数据写到磁盘上的一个临时的 &lt;code&gt;.rdb&lt;/code&gt; 文件中，当子进程写完临时文件后，会将原来的 &lt;code&gt;.rdb&lt;/code&gt; 文件替换掉，这个就是 fork 的概念。那 cow 全称是 copy-on-write ，当主进程执行读操作的时候是访问共享内存的，而主进程执行写操作的时候，则会拷贝一份数据，执行写操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;只有一个文件 dump.rdb ，方便持久化&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;容错性好，一个文件可以保存到安全的磁盘&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实现了性能最大化，fork 单独子进程来完成持久化，让主进程继续处理命令，主进程不进行任何 I/O 操作，从而保证了Redis的高性能&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;RDB 是一个紧凑压缩的二进制文化，RDB重启时的加载效率比AOF持久化更高，在数据量大时更明显&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;可能出现数据丢失，在两次RDB持久化的时间间隔中，如果出现宕机，则会丢失这段时间中的数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;由于RDB是通过fork子进程来协助完成数据持久化，如果当数据集较大时，可能会导致整个服务器间歇性暂停服务&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2、AOF（Append Only File）持久化&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;AOF 全称是 Append Only File（追加文件）。当 Redis 处理每一个写命令都会记录在 AOF 文件中，可以看做是命令日志文件。该方式需要设置 AOF 的同步选项，因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区中，同步选项有三种配置项选择：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;always&lt;/code&gt;：同步刷盘，可靠性高，但性能影响较大&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;everysec&lt;/code&gt;：每秒刷盘，性能适中，最多丢失 1 秒的数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;no&lt;/code&gt;：操作系统控制，性能最好，可靠性最差&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决 AOF 文件体检不断增大的问题，用户可以向 Redis 发送 &lt;code&gt;bgrewriteaof&lt;/code&gt; 命令，可以将 AOF 文件进行压缩，也可以选择自动触发，在配置文件中配置&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;auto-aof-rewrite-precentage 100&lt;br/&gt;auto-aof-rewrite-min-zise 64mb&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;实现持久化，数据安全，AOF持久化可以配置 appendfsync 属性为 always，每进行一次命令操作就记录到AOF文件中一次，数据最多丢失一次&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过 append 模式写文件，即使中途服务器宕机，可以通过 Redis-check-aof 工具解决数据一致性问题&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;AOF 机制的 rewrite 模式。AOF 文件的文件大小触碰到临界点时，rewrite 模式会被运行，重写内存中的所有数据，从而缩小文件体积&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;AOF 文件大，通常比 RDB 文件大很多&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;比 RDB 持久化启动效率低，数据集大的时候较为明显&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;AOF 文件体积可能迅速变大，需要定期执行重写操作来降低文件体积&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.304&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB6ANIPgtD87JYRLes0TzoVDwicsX5HO9ohkvf6tGxVVWah5UicicfU5slw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;375&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式1：定时删除&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在设置 Key 的过期时间的同时，会创建一个定时器 timer，定时器在 Key 过期时间来临时，会立即执行对 Key 的删除操作&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;特点：&lt;/em&gt; 对内存友好，对 CPU 不友好。存在较多过期键时，利用定时器删除过期键会占用相当一部分CPU&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式2：惰性删除&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;key 不使用时不管 key 过不过期，只会在每次使用的时候再检查 Key 是否过期，如果过期的话就会删除该 Key。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;特点：&lt;/em&gt; 对 CPU 友好，对内存不友好。不会花费额外的CPU资源来检测Key是否过期，但如果存在较多未使用且过期的Key时，所占用的内存就不会得到释放&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式3：定期删除&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每隔一段时间就会对数据库进行一次检查，删除里面的过期Key，而检查多少个数据库，则由算法决定&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;特点：&lt;/em&gt; 定期删除是对上面两种过期策略的折中，也就是对内存友好和CPU友好的折中方法。每隔一段时间执行一次删除过期键任务，并通过限制操作的时长和频率来减少对CPU时间的占用。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.31843575418994413&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBR5Na0yKib8MHYYXzqRWWIHIiby5tDicKsnrWTsiafzja9q41a9V6vw8Lag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;358&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Redis 主从同步分为增量同步和全量同步Redis 会先尝试进行增量同步，如果不成功则会进行全量同步。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;增量同步：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Slave 初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。增量同步的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;全量同步：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Slave 初始化时它会发送一个 &lt;code&gt;psync&lt;/code&gt; 命令到主服务器，如果是第一次同步，主服务器会做一次&lt;code&gt;bgsave&lt;/code&gt;，并同时将后续的修改操作记录到内存 buffer 中，待 &lt;code&gt;bgsave&lt;/code&gt; 完成后再将 RDB 文件全量同步到从服务器，从服务器接收完成后会将 RDB 快照加载到内存然后写入到本地磁盘，处理完成后，再通知主服务器将期间修改的操作记录同步到复制节点进行重放就完成了整个全量同步过程。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.27602905569007263&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB5IB2ickLPfNibvZs66gVdFYYG5TbNrXCuB6rX3ic0bRupq4EX4rzVibsnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;413&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在Redis中，最大使用内存大小由Redis.conf中的参数maxmemory决定，默认值为0，表示不限制，这时实际相当于当前系统的内存。但如果随着数据的增加，如果对内存中的数据没有管理机制，那么数据集大小达到或超过最大内存的大小时，则会造成Redis崩溃。因此需要内存数据淘汰机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;设有过期时间&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;volatile-lru&lt;/code&gt;：尝试回收最少使用的键&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;volatile-random&lt;/code&gt;：回收随机的键&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;volatile-ttl&lt;/code&gt;：优先回收存活时间较短的键&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;没有过期时间&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;allkey-lru&lt;/code&gt;：尝试回收最少使用的键&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;allkeys-random&lt;/code&gt;：回收随机的键&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;noeviction&lt;/code&gt;：当内存达到限制并且客户端尝试执行新增，会返回错误&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;em&gt;淘汰策略的规则&lt;/em&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allKeys-lru&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果数据呈现平等分布，也就是所有的数据访问频率大体相同，则使用 allKeys-random&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;关于 lru 策略，Redis中并不会准确的删除所有键中最近最少使用的键，而是随机抽取5个键（个数由参数maxmemory-samples决定，默认值是5），删除这5个键中最近最少使用的键。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3202247191011236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBswuUsyfaAaTE6bLTtMoJ513W618icxYoRrFvv1CLCkomdN7ic74gcfOg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;356&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题1：缓存穿透&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;缓存穿透是指缓存和数据库上都没有的数据，导致所有请求都落到数据库上，造成数据库短时间内承受大量的请求而导致宕机&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;解决：&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;使用布隆过滤器：将查询的参数都存储到一个 bitmap 中，在查询缓存前，如果 bitmap 存在则进行底层缓存的数据查询，如果不存在则进行拦截，不再进行缓存的数据查询&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缓存空对象：如果数据库查询的为空，则依然把这个数据缓存并设置过期时间，当多次访问的时候可以直接返回结果，避免造成多次访问数据库，但要保证当数据库有数据时及时更新缓存。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题2：缓存击穿&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），就会导致所有请求都落到数据库上，造成数据库段时间内承受大量的请求而宕机&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;解决：&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;设置热点数据永不过期&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可以使用互斥锁更新，保证同一进程中针对同一个数据不会并发请求到 DB，减小DB的压力&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用随机退避方式，失效时随机 sleep 一个很短的时间，再次查询，如果失败再执行更新&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题3：缓存雪崩&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;缓存雪崩是指大量缓存同一时间内大面积失效，后面的请求都会落到数据库上，造成数据库段时间无法承受大量的请求而宕掉&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;解决：&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个Key只允许一个线程查询和写缓存，其他线程等待&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过缓存 reload 机制，预先去更新缓存，在即将发生高并发访问前手动触发加载缓存&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对于不同的key设置不同的过期时间，让缓存失效的时间点尽量均匀，比如我们可以在原有的失效时间基础上增加一个随机值，比如1~5分钟随机，这样每一个缓存的过期时间的重复率就会降低。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;设置二级缓存，或者双缓存策略。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2590909090909091&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBFbIh5dnAib4icicWwKh8tFcIcspzRG3YbX5tI11BAlfzpFUdHTymal3Iw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;440&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缓存降级，其实都应该是指服务降级。在访问量剧增、服务响应出现问题（如响应延迟或不响应）或非核心服务影响到核心流程的性能的情况下，仍然需要保证核心服务可用，尽管可能一些非主要服务不可用，这时就可以采取服务降级策略。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;服务降级的最终目的是保证核心服务可用，即使是有损的。服务降级应当事先确定好降级方案，确定哪些服务是可以降级的，哪些服务是不可降级的。根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心服务的正常运行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。根据服务方式：可以拒接服务，可以延迟服务，也可以随机提供服务。根据服务范围：可以暂时禁用某些功能或禁用某些功能模块。总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2585034013605442&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBFmUHfS1q73gmLNhmfDYicUjVhQkcoRqSgriatzUbClhILbal9UJjvbXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;441&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;数据实时同步失效或更新。这是一种增量主动型的方案，能保证数据强一致性，在数据库数据更新之后，主动请求缓存更新&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据异步更新。这是一种增量被动型方案，数据一致性稍弱，数据更新会有延迟，更新数据库数据后，通过异步方式，用多线程方式或消息队列来实现更新&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;定时任务更新。这是一种增/全量被动型方案，通过定时任务按一定频率调度更新，数据一致性最差&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.26635514018691586&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBN8xgckvUUlHxZ1dB4UvXbdwhT0RCAC2we811ibbyH7DAbYINlHVudMA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;428&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;直接写个缓存刷新页面，上线时手工操作&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据量不大，可以在项目启动时自动进行加载&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;定时刷新缓存&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3149171270718232&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBGQn9eOL3KBgyyakEQqAuzxKCUDMtTXaZp98WgWYT7N7rywO3mjwicoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;362&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Sentinel（哨兵）适用于监控 Redis 集群中 Master 和 Slave 状态的工具，是Redis的高可用性解决方案&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;主要作用&lt;/strong&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;监控。哨兵会不断检查用户的Master和Slave是否运作正常&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;提醒。当被监控的某个Redis节点出现问题时，哨兵可以通过API向管理员或其他应用程序发送通知&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;自动故障迁移。当一个Master不能正常工作时，哨兵会开始一次自动故障迁移操作，它会将集群中一个Slave提升为新的Master，并让其他Slave改为与新的Master进行同步。当客户端试图连接失败的Master时，集群也会想客户端返回新的Master地址。当主从服务器切换后，新Master的Redis.conf，Slave的Redis.conf和Sentinel的Redis.conf三者配置文件都会发生相应的改变。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.28860759493670884&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBDdniblg7yicJ06gOSsTCu4MncKFo38k2zzr6BY3ic4p7XibYoO4azWYqUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;395&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题背景&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Redis 是基于TCP协议的请求/响应服务器，每次通信都要经过TCP协议的三次握手，所以当需要执行的命令足够复杂时，会产生很大的网络延迟，并且网络的传输时间成本和服务器开销没有计入其中，总的延迟可能更大。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Pipeline解决&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Pipeline 主要就是为了解决存在这种情况的场景，使用Pipeline模式，客户端可以一次性发送多个命令，无需等待服务端返回，这样可以将多次I/O往返的时间缩短为一次，大大减少了网络往返时间，提高了系统性能。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Pipeline 是基于队列实现，基于先进先出的原理，满足了数据顺序性。同时一次提交的命令很多的话，队列需要非常大量的内存来组织返回数据内容，如果大量使用Pipeline的话，应当合理分批次提交命令。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Pipeline的默认同步个数为&lt;code&gt;53&lt;/code&gt;个，累加到 53 条数据时会把数据提交&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;注意：&lt;/em&gt; Redis 集群中使用不了 Pipeline，对可靠性要求很高，每次操作都需要立即获取本次操作结果的场景都不适合用 Pipeline&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25054945054945055&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBUB8VaDpUO3Bqg6LEAkGfGEWxT3Teh3CHP02Xdzk90H2bqZuHvyuOnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;455&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Master 最好不要做 RDB 持久化，因为这时 save 命令调度 rdbSave 函数，会阻塞主线程的工作，当数据集比较大时可能造成主线程间断性暂停服务&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如果数据比较重要，将某个 Slave 节点开启AOF数据备份，策略设置为每秒一次&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;为了主从复制速度和连接的稳定性，Master 和 Slave 最好在同一个局域网中&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;尽量避免在运行压力很大的主库上增加从库&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;主从复制不要用图状结构，用单向链表结构更为稳定，&lt;code&gt;Mater-&amp;gt;Slave1-&amp;gt;Slave2-&amp;gt;Slave3...&lt;/code&gt; 这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换，如果 Master 崩溃，可以立即启用 Slave1替换Mater，而其他依赖关系则保持不变。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25733634311512416&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBbvxylAE9vKEUEzia14JSgXgh3q8JHrfgU5kS3UiaQ52hlAxocib3iaFt2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;443&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式1：先更新数据库，再更新缓存&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种是常规的做法，但是如果更新缓存失败，将会导致缓存是旧数据，数据库是新数据&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式2：先删除缓存，再写入数据库&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方式能够解决方式1的问题，但是仅限于低并发的场景，不然如果有新的请求在删完缓存之后，写数据库之前进来，那么缓存就会马上更新数据库更新之前数据，造成数据不一致的问题&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式3：延时双删策略&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方式是先删除缓存，然后更新数据库，最后延迟个几百毫秒再删除缓存&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式4：直接操作缓存，定期写入数据库&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2857142857142857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBkQJHfqiaUYsGmPdCSD4QAMs5WAaCBicSzyghs1ja0ets0SWPaBcJFqxg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;399&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;虽然Redis的Transactions 提供的并不是严格的 ACID的事务（如一串用EXEC提交执行的命令，如果在执行中服务器宕机，那么会有一部分命令执行一部分命令未执行），但这些Transactions还是提供了基本的命令打包执行的功能（在服务器不出问题的情况下，可以保证一连串的命令是顺序在一起执行的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 事务的本质就是四个原语：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;multi&lt;/code&gt;：用于开启一个事务，它总是返回 OK，当 multi 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会被立即执行，而是放到一个队列中，当 exec 命令被调用的时候，所有队列d 命令才会执行&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;exec&lt;/code&gt;：执行所有事务队列内的命令，返回事务内所有命令的返回值，当操作被打断的时候，返回空值 nil&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;watch&lt;/code&gt;：是一个乐观锁。可以为 redis 事务提供 CAS 操作，可以监控一个或多个键。一旦其中有一个键被修改（删除），之后的事务就不会执行，监控一直持续到 exec 命令执行之后&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;discard&lt;/code&gt;：调用 discard，客户端可以清空事务队列中的命令，并放弃执行事务&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事务支持一次执行多个命令，一个事务中的所有命令都会被序列化。在事务执行的过程中，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令队列中。Redis 不支持回滚事务，在事务失败的时候不会回滚，而是继续执行余下的命令。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2857142857142857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBEBT0EiaHhbADuHQRGJ8CCVrYqPlJ7PqBibvFibXo75KdSiaCMkBO16w4Gw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;399&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式1：Cluster 3.0&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是Redis 自带的集群功能，它采用的分布式算法是哈希槽，而不是一致性Hash。支持主从结构，可以扩展多个从服务器，当主节点挂了可以很快切换到一个从节点作主节点，然后其他从节点都会切换读取最新的主节点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式2：Twemproxy&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Twitter 开源的一个轻量级后端代理。可以管理 Redis 或 Memcache 集群。相对于 Redis 集群来说，易于管理。它的使用方法和Redis集群没有任何区别，只需要设置多个Redis实例后，在本需要连接 Redis 的地方改为连接 Twemproxy ，它就会以一个代理的身份接收请求并使用一致性Hash算法，将请求连接到具体的Redis节点上，将结果再返回Twemproxy。对于客户端来说，Twemproxy 相当于是缓存数据库的总入口，它不需要知道后端如何部署的。Twemproxy 会检测与每个节点的连接是否正常，如果存在异常节点就会将其剔除，等一段时间后，Twemproxy 还会再次尝试连接被剔除的节点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式3：Codis&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它是一个 Redis 分布式的解决方法，对于应用使用 Codis Proxy 的连接和使用Redis的服务没有明显区别，应用能够像使用单机 Redis 一样，让 Codis 底层处理请求转发，实现不停机实现数据迁移等工作。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3089430894308943&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB1PkXjLOib66Axv6oU1ia9B3F303DRIVRU7hQZSN7cibsHxib0iaCzBREOdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;369&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;什么是脑裂问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;脑裂问题通常是因为网络问题导致的。让 master、slave 和 sentinel 三类节点处于不同的网络分区。此时哨兵无法感知到 master 的存在，会将 slave 提升为 master 节点。此时就会存在两个 master，就像大脑分裂，那么原来的客户端往继续往旧的 master 写入数据，而新的master 就会丢失这些数据&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如何解决&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过配置文件修改两个参数&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;min-slaves-to-write 3  # 表示连接到 master 最少 slave 的数量&lt;br/&gt;min-slaves-max-lag 10  # 表示slave连接到master最大的延迟时间&lt;br/&gt;--------------------新版本写法-----------------&lt;br/&gt;min-replicas-to-write 3&lt;br/&gt;min-replicas-max-lag  10&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置这两个参数之后，如果发生集群脑裂，原先的master节点接收到写入请求就会拒绝，就会减少数据同步之后的数据丢失&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25165562913907286&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBLjSCaI1VLaicJWnpTLj6XCGpqEE58XWvWhlH3t8QXkxBWibSWksAahoQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;453&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般使用 &lt;code&gt;List&lt;/code&gt; 结构作为队列。&lt;code&gt;Rpush&lt;/code&gt; 生产消息，&lt;code&gt;Lpop&lt;/code&gt; 消费消息。当 &lt;code&gt;Lpop&lt;/code&gt; 没有消费的时候，需要适当 sleep 一会再重试。但是重复 sleep 会耗费性能，所以我们可以利用 list 的 &lt;code&gt;blpop&lt;/code&gt; 指令，在还没有消息到来时，它会阻塞直到消息到来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们也可以使用 &lt;code&gt;pub/sub&lt;/code&gt; 主题订阅者模式，实现 1：N 的消费队列，但是在消费者下线的时候，生产的消息会丢失&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.252212389380531&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uByB3BNdERA349D2YVz5OloKR7wUekRDNVrUExCPkKz3LL2oWLqNdA8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;452&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以使用 &lt;code&gt;zset&lt;/code&gt; 结构，可以拿时间戳作为 score，消息的内容作为key，通过调用 &lt;code&gt;zadd&lt;/code&gt; 来生产消息，消费者使用 &lt;code&gt;zrangebyscore&lt;/code&gt; 指令轮询获取 N 秒之前的数据进行处理&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2695035460992908&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBAefbJwy388IJv8USpH1aG5kCgngWDvZWs34CIj13RUjHeeo0QFOocw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;423&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis Cluster提供了自动将数据分散到各个不同节点的能力，但采用的策略并不是一致性Hash，而是哈希槽。Redis 集群将整个Key的数值域分成16384个哈希槽，每个Key通过 CRC16检验后对16384驱魔来决定放置到那个槽中，集群的每个节点都负责其中一部分的哈希槽。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3048128342245989&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB3nAA85P9Tvr05UuQ9nN2mjKVuJwZUxwfMxLhP6h2BorlNI7Rs6rWiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;374&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1、数据缓存&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经典的场景，现在几乎是所有中大型网站都在用的提升手段，合理地利用缓存能够提升网站访问速度&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2、排行榜&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以借助Redis提供的有序集合（&lt;code&gt;sorted set&lt;/code&gt;）能力实现排行榜的功能&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3、计数器&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以借助Redis提供的 &lt;code&gt;incr&lt;/code&gt; 命令来实现计数器功能，因为是单线程的原子操作，保证了统计不会出错，而且速度快&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;4、分布式session共享&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;集群模式下，可以基于 Redis 实现 session 共享&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;5、分布式锁&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在分布式架构中，为了保证并发访问时操作的原子性，可以利用Redis来实现分布式锁的功能&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;6、最新列表&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以借助Redis列表结构，&lt;code&gt;LPUSH&lt;/code&gt;、&lt;code&gt;LPOP&lt;/code&gt;、&lt;code&gt;LTRIM&lt;/code&gt;等命令来完成内容的查询&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;7、位操作&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以借助Redis中 &lt;code&gt;setbit&lt;/code&gt;、&lt;code&gt;getbit&lt;/code&gt;、&lt;code&gt;bitcount&lt;/code&gt; 等命令来完成数量上千万甚至上亿的场景下，实现用户活跃度统计&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;8、消息队列&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 提供了发布（&lt;code&gt;Publish&lt;/code&gt;）与订阅（&lt;code&gt;Subscribe&lt;/code&gt;）以及阻塞队列能力，能够实现一个简单的消息队列系统&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.26823529411764707&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBKCJj5KMFkZUsnicLbdXNzKv6FdmXNXCrfBZJbmWRsmBI6ibUrlTHGx3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;425&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;方式1：Set 结构&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以日期为 key，以用户 ID（对应数据库的 Primary Id）组成的集合为 value&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;查询某个用户的签到状态 &lt;code&gt;sismember key member&lt;/code&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;插入签到状态 &lt;code&gt;sadd key member&lt;/code&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;统计某天用户的签到人数 &lt;code&gt;scard key&lt;/code&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2、bitMap 结构&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Key的格式为&lt;code&gt;u:sign:uid:yyyyMM&lt;/code&gt;，Value则采用长度为4个字节（32位）的位图（最大月份只有31天）。位图的每一位代表一天的签到，1表示已签，0表示未签。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 用户2月17号签到&lt;/span&gt;&lt;br/&gt;SETBIT u:sign:1000:201902 16 1 # 偏移量是从0开始，所以要把17减1&lt;br/&gt;&lt;span&gt;&lt;br/&gt;#&lt;/span&gt;&lt;span&gt; 检查2月17号是否签到&lt;/span&gt;&lt;br/&gt;GETBIT u:sign:1000:201902 16 # 偏移量是从0开始，所以要把17减1&lt;br/&gt;&lt;span&gt;&lt;br/&gt;#&lt;/span&gt;&lt;span&gt; 统计2月份的签到次数&lt;/span&gt;&lt;br/&gt;BITCOUNT u:sign:1000:201902&lt;br/&gt;&lt;span&gt;&lt;br/&gt;#&lt;/span&gt;&lt;span&gt; 获取2月份前28天的签到数据&lt;/span&gt;&lt;br/&gt;BITFIELD u:sign:1000:201902 get u28 0&lt;br/&gt;&lt;span&gt;&lt;br/&gt;#&lt;/span&gt;&lt;span&gt; 获取2月份首次签到的日期&lt;/span&gt;&lt;br/&gt;BITPOS u:sign:1000:201902 1 # 返回的首次签到的偏移量，加上1即为当月的某一天&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;两者对比&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;使用 set 的方式所占用的内存只与数量相关，和存储哪些 ID 无关&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用 bitmap 的方式所占用的内存与数量没有绝对的关系，而是与最高位有关，比如假设 ID 为 500 W的用户签到了，那么从 1~4999999 用户不管是否签到，所占用的内存都是 500 w个bit，这边是最坏的情况&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用 bitmap 最大可以存储 2^32-1也就是 512M 数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用 bitmap 只适用存储只有两个状态的数据，比如用户签到，资源（视频、文章、商品）的已读或未读状态&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.22983870967741934&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uBfIOnBJ99ga3uzqIAHPEpiafSxRgLo9ia9txiakgib6XsF5mHRotcB8AiazA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;496&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis中 ZSet 是选择使用 &lt;code&gt;跳表&lt;/code&gt; 而不是红黑树&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;什么是跳表&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;跳表是一个随机化的数据结构，实质上就是一种可以进行二分查找的有序链表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跳表在原有的有序链表上增加了多级索引，通过索引来实现快速查找&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38055555555555554&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/P7WuIzkp9iaXuoibkSfkk1ia6m8UZqibD4uB2K7GaFZKRhglARgFAV8qFmtgibSN6z9gvUcwCFlWiaRtkPax4FVYVR1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;跳表是可以实现二分查找的有序链表&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每个元素插入时随机生成它的 level&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;最底层包含所有的元素&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果一个元素出现在 level(x)，那么它肯定出现在 x 以下的 level 中&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每个索引节点包含两个指针，一个向下，一个向右&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跳表查询、插入、删除的时间复杂度为 O(log n)，与平衡二叉树接近&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;为什么不选择红黑树来实现&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先来分析下 Redis 的有序集合支持的操作：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;插入元素&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删除元素&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;查找元素&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;有序输出所有元素&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;查找区间内的所有元素&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中前 4 项红黑树都可以完成，且时间复杂度与跳表一致，但是最后一个红黑树的效率就没有跳表高了。在跳表中，要查找区间的元素，只要定位到两个区间端点在最低层级的位置，然后按顺序遍历元素就可以了，非常高效。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，以上便是本篇的所有内容，如果觉得对你有帮助的小伙伴不妨点个关注做个伴，便是对小菜最大的支持。不要空谈，不要贪懒，和小菜一起做个&lt;code&gt;吹着牛X做架构&lt;/code&gt;的程序猿吧~ 咱们下文再见！&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;今天的你多努力一点，明天的你就能少说一句求人的话！&lt;/p&gt;&lt;p&gt;&lt;em&gt;我是小菜，一个和你一起变强的男人。&lt;/em&gt; &lt;code&gt;💋&lt;/code&gt;&lt;/p&gt;&lt;p&gt;微信公众号已开启，&lt;strong&gt;菜农曰&lt;/strong&gt;，没关注的同学们记得关注哦！&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>