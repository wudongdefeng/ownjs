<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ff4f19069d80a8c8019636036493a4fe</guid>
<title>流程引擎的架构设计</title>
<link>https://toutiao.io/k/3johyl2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h3&gt;1 什么是流程引擎&lt;/h3&gt;

&lt;p&gt;流程引擎是一个底层支撑平台，是为提供流程处理而开发设计的。流程引擎和流程应用，以及应用程序的关系如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/195d2868-2dcc-45f0-98d6-486ee5b18f4f20220721190151.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;常见的支撑场景有：Workflow、BPM、流程编排等。本次分享，主要从BPM流程引擎切入，介绍流程引擎的架构设计方法。&lt;/p&gt;

&lt;h4&gt;1.1 什么是流程&lt;/h4&gt;

&lt;p&gt;简单来说，流程就是一系列活动的组合。比如，用于企业办公的OA系统中，就存在大量的申请审批类的流程。在生产制造业，有大量的从销售端的订单，到生产制造，再到签收回款的生产销售流程。在机器学习领域，有亚马逊AWS Sagemaker的大数据处理、机器学习的应用。综上，流程是一个概念，在和具体实现结合时，就产生了不同的流程产品，如DevOps、Spring Data Stream等。&lt;br/&gt;
在流程实现方面，主要可以分为2种实现方式，一种是用代码实现，比如：用代码实现一个加班申请，那么就要自己对接SSO进行单点登录，通过接口拿到发起人和审批人的信息，同时保存表单数据。另一种方式是使用流程引擎来实现，流程引擎对接应用场景所需数据，如加班申请，流程引擎对接SSO、OU、审批人配置、权限等，实现这样一个流程，只需要关心流程配置、流程节点和流程表单即可，流程流转以及流程的数据处理，都通过流程引擎来完成。&lt;br/&gt;
流程引擎可以快速落地流程实现，这也是流程引擎存在的价值。&lt;/p&gt;

&lt;h4&gt;1.2 什么是引擎&lt;/h4&gt;

&lt;p&gt;一般而言，引擎是一个程序或一套系统的支持部分。常见的程序引擎有游戏引擎、搜索引擎、杀毒引擎等。引擎是脱离具体业务场景的某一类业务场景的高度抽象和封装。&lt;br/&gt;
比如，某OA公司，封装了一套审批用的workflow，实施人员只需要配置流程和表单即可交付项目。再比如，美国某公司做了一个AI引擎做NBA（Next Best Action）推荐，封装了推荐领域的常用算法，在不同的场景自动选择和组合多种算法，进行智能推荐。&lt;/p&gt;

&lt;h4&gt;1.3 流程设计器&lt;/h4&gt;

&lt;p&gt;流程设计器是流程和引擎的连接方，用户通过流程设计器，将某种layout和rule固化成某种流程，然后通过数据和数据上下文，使用流程引擎自动按照某种固化的流程进行执行。&lt;br/&gt;
我将目前见到的流程设计器的理论基础，分为以下三类：1，自定义系；2，UML中的活动图系；3，BPMN系。&lt;/p&gt;

&lt;p&gt;1.3.1 自定义系&lt;/p&gt;

&lt;p&gt;用于Sagemaker等场景的AWS Step Function（自定义流程节点）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/2ab8e767-603b-49ef-a771-7786e96168ff20220721190227.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;1.3.2 UML Activity Diagram&lt;/p&gt;

&lt;p&gt;Flowportal BPM的流程设计器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/3a365416-02f9-4eea-9b93-f587a21be48920220721190240.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;1.3.3 BPMN系&lt;/p&gt;

&lt;p&gt;activiti的流程设计器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/e410cbc3-a518-49ba-a968-fed123bc093d20220721190253.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;炎黄盈动的流程设计器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/a1d01ca2-1ade-44fd-a776-79ff3dbb5ca620220721190307.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;题外话：炎黄盈动的流程设计器，和processon中的流程设计器界面几乎一样，因为本质上是一家的。&lt;/p&gt;

&lt;h3&gt;2 流程引擎的应用&lt;/h3&gt;

&lt;h4&gt;2.1 Workflow&lt;/h4&gt;

&lt;p&gt;工作流管理联盟(Workflow Management Coalition，WfMC)作为工作流管理的标准化组织而成立。&lt;br/&gt;
WfMC对工作流给出定义为：工作流是指一类能够完全自动执行的经营过程，根据一系列过程规则，将文档、信息或任务在不同的执行者之间进行传递与执行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/d8cee1d5-9a52-450b-8ddc-7f325551fccd20220721190516.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在workflow中，流程引擎主要用于支撑流程审批和数据流转，应用场景非常广泛。&lt;br/&gt;
国外产品（开源或商用）通常需求和操作比较简单，不会有国内的需求那么复杂。国内的产品，经历了众多客户的锤炼，功能目前都比较强大。&lt;br/&gt;
一般而言，workflow使用场景最多的是OA产品。在OA办公中，包含了企业办公中的大量元素，这些元素足够形成特定的产品，比如门户系统、移动办公。在OA的项目落地过程中，结合行业、业务侧重点又可以形成行业解决方案和专题方案。&lt;br/&gt;
以下是某OA公司产品和解决方案。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/f8415b52-c267-4a7b-9bd1-94805353ed8f20220721190530.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.2 BPM（Business Process Management）&lt;/h4&gt;

&lt;p&gt;Workflow主要是解决审批和数据流转，而BPM主要是解决端到端、信息孤岛等问题而存在的。大多数用BPM产品的客户，都是在BPM基础上进行系统搭建，比如在BPM上面搭建OA、CRM、HR等系统。&lt;br/&gt;
BPM的使用场景，比Workflow更广泛，BPM产品中包含大量的和第三方系统交互的组件和自定义SQL、代码组件。比如，BPM系统中的文件触发器，可以在海关等交互场景下，通过监控FTP服务器中的文件，自动触发流程实例；可以通过定时器Timer，自动每日执行数据同步，并通过Mail节点将同步结果通知到相关运营成员等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/44faa3fb-8318-4d89-913d-59871c5712d120220721190548.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/70f7932f-0556-4d31-83ba-a67eeee4e77820220721190554.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;BPM的应用，可以按照执行前、执行中和执行后来划分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/fec79a78-4c77-4243-9599-a1696aa6fd3920220721190608.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.3 流程编排&lt;/h4&gt;

&lt;p&gt;流程编排是脱离流程业务领域的更高一层抽象，使用方可以通过流程编排系统，结合自己的业务场景进行业务定制。比如，可以将相关业务代码，封装成function，然后通过云厂商平台的FAAS平台，将不同业务的function进行关联和调度，从而完成某项任务。&lt;/p&gt;

&lt;h3&gt;3 流程引擎的架构设计&lt;/h3&gt;

&lt;p&gt;鉴于一些朋友可能没有使用和接触过流程引擎，先介绍流程引擎的组成单元，再介绍基于某个BPM产品的项目是如何进行开发的。我们通过BPM项目开发，对流程引擎的作用有个初步的认识。&lt;/p&gt;

&lt;h4&gt;3.1 BPM流程引擎的组成单元&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt; 组织、角色、用户、成员的组织架构托管；&lt;/li&gt;
&lt;li&gt; 流程资源文件的配置、校验、存储和执行，对不同的流程节点，流程引擎自动结合配置、数据处理其对应的业务逻辑，流程数据自动处理；&lt;/li&gt;
&lt;li&gt; 表单配置、数据绑定，表单数据的根据流程配置自动处理；&lt;/li&gt;
&lt;li&gt; 通用的数据接口；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;3.1.1 组织架构的设计&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/4ffe1507-bffb-444d-9775-5808a2c26be820220721200058.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3.1.2 流程设计器&lt;/p&gt;

&lt;p&gt;流程设计器包含左侧的分组节点列表，和右侧的画布。左侧的节点可以如下进行设计。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/0d602304-395f-43f0-bb01-62b3ad6ec4bd20220721200121.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;问题：对于一个XML或JSON格式的流程图，如何进行解析？&lt;/strong&gt;&lt;br/&gt;
不同的节点，按照不同的业务场景，配置不同的配置项。比如，对于Human Node需要配置审批人，配置审批环节的展示表单，审批环节能够修改哪些字段，哪些字段的修改要进行留痕等。&lt;/p&gt;

&lt;p&gt;3.1.3 表单设计器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/e9d24917-afd7-453d-8bab-979f62e7e9da20220721200134.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/bcd0a065-08c3-4bdf-a9c9-ff7c7998e54620220721200147.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这种是按照表单相关数据表，生成出一个表单，然后对表单字段进行配置和数据绑定。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/5b084e8d-e3e3-4696-8a2d-edfb5e0bc64a20220721200159.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/f3715735-d51a-4b69-9bc5-4b916eb3cb1720220721200211.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这种是Drag&amp;amp;Drop控件，然后配置控件的属性，如绑定字段等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/8a309588-e3ba-480a-aa05-8b05b12878d920220721200228.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这种是Drag&amp;amp;Drop控件，无需关联数据库表字段的表单&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/6654a811-1f7c-41f3-80e0-938f6a35b0a220220721200238.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;数据表生成表单的概要流程如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/a9ab5820-b2a7-4419-9ad2-798f333b8e0d20220721200247.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;拖拽控件绑定数据表字段的概要流程如下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/1a15c80c-37ab-4998-9237-cdec121466dd20220721200425.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;拖拽控件无需绑定数据表字段的概要流程。使用NoSQL的Document记录或使用RDS提供的JSON类型进行保存会比较方便。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/5eb984cb-f644-4e53-a0a2-78ba45dfc3df20220721200435.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3.1.4 接口设计&lt;/p&gt;

&lt;p&gt;结合Activity的接口设计，如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/ec165791-90b7-449a-b727-7aea61df8fce20220721200613.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;一些系统在创建一个流程任务的时候，要先按照流程模板先创建一个应用示例，再关联发起人和备注，调用RuntimeService，执行到StartNode，这类设计因人而异，这么做略显繁琐。&lt;/p&gt;

&lt;h4&gt;3.2 基于流程引擎的项目开发实践&lt;/h4&gt;

&lt;p&gt;3.2.1 流程项目实践流程&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 确定组织架构&lt;/li&gt;
&lt;li&gt; 确定流程，包括流程布局、审批人设置、权限&lt;/li&gt;
&lt;li&gt; 确定表单信息（字段、类型、数据源、校验规则）和表单样式&lt;/li&gt;
&lt;li&gt; 确定页面布局、样式、数据字段、搜索、导入、导出&lt;/li&gt;
&lt;li&gt; 报表&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;3.2.2 组织架构&lt;/p&gt;

&lt;p&gt;组织架构实现，有两种方法，一种是按照维度进行数据管理，另一种是在同一棵组织架构树下进行管理。&lt;br/&gt;
按照集团、公司、部门、用户等不同维度，进行数据管理，比较常见，这里不做讨论。下图为按维度维护数据的示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/14e1fafe-7461-4d03-b42e-ec05bf82490920220721200652.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;按照同一棵组织架构树进行数据维护，界面一般显示为左树右表。大多数商业化产品，都会将此组织架构树进行内存缓存，以方便审批人查找、开窗选择OrgUnit、Role、User、Member等场景。Member的引入是为了解决一人多职等场景。一般发起流程的时候，需要带出发起人拥有的Member列表，从而后续节点取合适的审批人。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/121dfd67-da98-407b-a3cc-cb3e01cca95120220721200840.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;对于组织架构而言，需要考虑，系统本身要具备OU存储的能力，对于没有组织架构的用户，可以直接在系统的组织架构中新建组织架构。同时，对于已有系统的客户，可以通过组织架构数据同步来进行数据自动维护。对于用AD域内部管控的客户来说，需要具备AD域身份认证的能力。对于复杂场景，比如用户是SaaS化等复杂场景，组织架构也需要在系统内部，支持使用API的方式来获取组织信息。&lt;br/&gt;
所以在组织架构设计的时候，要使用插件的方式来做，具体使用哪种插件，可以在配置文件中进行配置。以下为一个商业产品的组织架构操作界面示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/0c424e5a-e5a0-4407-905b-203b4239b54920220721200855.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;常见的组织架构操作还有组织架构同步，比如流程系统同步微信企业号、钉钉等，这里不再展开。&lt;/p&gt;

&lt;p&gt;3.2.3 流程设计&lt;/p&gt;

&lt;p&gt;我们想象的流程，可能是向下面的这种简单流程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/ab07af2b-aaaf-498f-b3df-71bec6ba1d4920220721200911.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;而实际项目，碰到的流程，一般是如下图所示的情景。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/48a78007-667c-4f15-820d-264f6848de5020220721200922.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;初步看几个流程的模型文件是什么样的，先有个印象。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/474fbaf7-ce59-4ea3-881d-d6d5c18efee320220721200933.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;
&amp;lt;definitions id=&quot;definitions&quot;
targetNamespace=&quot;http://activiti.org/bpmn20&quot;
xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot;
xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
xmlns:activiti=&quot;http://activiti.org/bpmn&quot;&amp;gt;

&amp;lt;process id=&quot;vacationRequest&quot; name=&quot;Vacation request&quot;&amp;gt;
&amp;lt;startEvent id=&quot;request&quot; activiti:initiator=&quot;employeeName&quot;&amp;gt;
&amp;lt;extensionElements&amp;gt;
&amp;lt;activiti:formProperty id=&quot;numberOfDays&quot; name=&quot;Number of days&quot; type=&quot;long&quot; value=&quot;1&quot; required=&quot;true&quot;/&amp;gt;
&amp;lt;activiti:formProperty id=&quot;startDate&quot; name=&quot;First day of holiday (dd-MM-yyy)&quot; datePattern=&quot;dd-MM-yyyy hh:mm&quot; type=&quot;date&quot; required=&quot;true&quot; /&amp;gt;
&amp;lt;activiti:formProperty id=&quot;vacationMotivation&quot; name=&quot;Motivation&quot; type=&quot;string&quot; /&amp;gt;
&amp;lt;/extensionElements&amp;gt;
&amp;lt;/startEvent&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;request&quot; targetRef=&quot;handleRequest&quot; /&amp;gt;
&amp;lt;userTask id=&quot;handleRequest&quot; name=&quot;Handle vacation request&quot; &amp;gt;
&amp;lt;documentation&amp;gt;
${employeeName} would like to take ${numberOfDays} day(s) of vacation (Motivation: ${vacationMotivation}).
&amp;lt;/documentation&amp;gt;
&amp;lt;extensionElements&amp;gt;
&amp;lt;activiti:formProperty id=&quot;vacationApproved&quot; name=&quot;Do you approve this vacation&quot; type=&quot;enum&quot; required=&quot;true&quot;&amp;gt;
&amp;lt;activiti:value id=&quot;true&quot; name=&quot;Approve&quot; /&amp;gt;
&amp;lt;activiti:value id=&quot;false&quot; name=&quot;Reject&quot; /&amp;gt;
&amp;lt;/activiti:formProperty&amp;gt;
&amp;lt;activiti:formProperty id=&quot;managerMotivation&quot; name=&quot;Motivation&quot; type=&quot;string&quot; /&amp;gt;
&amp;lt;/extensionElements&amp;gt;
&amp;lt;potentialOwner&amp;gt;
&amp;lt;resourceAssignmentExpression&amp;gt;
&amp;lt;formalExpression&amp;gt;management&amp;lt;/formalExpression&amp;gt;
&amp;lt;/resourceAssignmentExpression&amp;gt;
&amp;lt;/potentialOwner&amp;gt;
&amp;lt;/userTask&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;handleRequest&quot; targetRef=&quot;requestApprovedDecision&quot; /&amp;gt;
&amp;lt;exclusiveGateway id=&quot;requestApprovedDecision&quot; name=&quot;Request approved?&quot; /&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow3&quot; sourceRef=&quot;requestApprovedDecision&quot; targetRef=&quot;sendApprovalMail&quot;&amp;gt;
&amp;lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&amp;gt;${vacationApproved == &#x27;true&#x27;}&amp;lt;/conditionExpression&amp;gt;
&amp;lt;/sequenceFlow&amp;gt;
&amp;lt;task id=&quot;sendApprovalMail&quot; name=&quot;Send confirmation e-mail&quot; /&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow4&quot; sourceRef=&quot;sendApprovalMail&quot; targetRef=&quot;theEnd1&quot; /&amp;gt;
&amp;lt;endEvent id=&quot;theEnd1&quot; /&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow5&quot; sourceRef=&quot;requestApprovedDecision&quot; targetRef=&quot;adjustVacationRequestTask&quot;&amp;gt;
&amp;lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&amp;gt;${vacationApproved == &#x27;false&#x27;}&amp;lt;/conditionExpression&amp;gt;
&amp;lt;/sequenceFlow&amp;gt;
&amp;lt;userTask id=&quot;adjustVacationRequestTask&quot; name=&quot;Adjust vacation request&quot;&amp;gt;
&amp;lt;documentation&amp;gt;
Your manager has disapproved your vacation request for ${numberOfDays} days.
Reason: ${managerMotivation}
&amp;lt;/documentation&amp;gt;
&amp;lt;extensionElements&amp;gt;
&amp;lt;activiti:formProperty id=&quot;numberOfDays&quot; name=&quot;Number of days&quot; value=&quot;${numberOfDays}&quot; type=&quot;long&quot; required=&quot;true&quot;/&amp;gt;
&amp;lt;activiti:formProperty id=&quot;startDate&quot; name=&quot;First day of holiday (dd-MM-yyy)&quot; value=&quot;${startDate}&quot; datePattern=&quot;dd-MM-yyyy hh:mm&quot; type=&quot;date&quot; required=&quot;true&quot; /&amp;gt;
&amp;lt;activiti:formProperty id=&quot;vacationMotivation&quot; name=&quot;Motivation&quot; value=&quot;${vacationMotivation}&quot; type=&quot;string&quot; /&amp;gt;
&amp;lt;activiti:formProperty id=&quot;resendRequest&quot; name=&quot;Resend vacation request to manager?&quot; type=&quot;enum&quot; required=&quot;true&quot;&amp;gt;
&amp;lt;activiti:value id=&quot;true&quot; name=&quot;Yes&quot; /&amp;gt;
&amp;lt;activiti:value id=&quot;false&quot; name=&quot;No&quot; /&amp;gt;
&amp;lt;/activiti:formProperty&amp;gt;
&amp;lt;/extensionElements&amp;gt;
&amp;lt;humanPerformer&amp;gt;
&amp;lt;resourceAssignmentExpression&amp;gt;
&amp;lt;formalExpression&amp;gt;${employeeName}&amp;lt;/formalExpression&amp;gt;
&amp;lt;/resourceAssignmentExpression&amp;gt;
&amp;lt;/humanPerformer&amp;gt;
&amp;lt;/userTask&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow6&quot; sourceRef=&quot;adjustVacationRequestTask&quot; targetRef=&quot;resendRequestDecision&quot; /&amp;gt;
&amp;lt;exclusiveGateway id=&quot;resendRequestDecision&quot; name=&quot;Resend request?&quot; /&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow7&quot; sourceRef=&quot;resendRequestDecision&quot; targetRef=&quot;handleRequest&quot;&amp;gt;
&amp;lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&amp;gt;${resendRequest == &#x27;true&#x27;}&amp;lt;/conditionExpression&amp;gt;
&amp;lt;/sequenceFlow&amp;gt;
&amp;lt;sequenceFlow id=&quot;flow8&quot; sourceRef=&quot;resendRequestDecision&quot; targetRef=&quot;theEnd2&quot;&amp;gt;
&amp;lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&amp;gt;${resendRequest == &#x27;false&#x27;}&amp;lt;/conditionExpression&amp;gt;
&amp;lt;/sequenceFlow&amp;gt;
&amp;lt;endEvent id=&quot;theEnd2&quot; /&amp;gt;
&amp;lt;/process&amp;gt;
&amp;lt;/definitions&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个屏幕截图都截不完的流程，如果用代码去实现整个流程，其工作量和效率，可想而知。而实际做项目，使用基于流程引擎的产品来做项目的时候，只需要确定节点、节点配置、数据配置和权限即可。&lt;br/&gt;
问题：一般流程，都带有邮件通知的节点，如何实现邮件通知节点？请考虑以下情景。&lt;br/&gt;
流程流转和执行的时候，会遇到各种情况的错误，比如找不到审批人等，此时流程引擎要对数据做rollback，而邮件通知节点的业务逻辑已经执行过了。&lt;/p&gt;

&lt;p&gt;权限方面，对于流程资源，哪些部门可以申请，哪些角色不可申请，都应该做流程控制。而在流程执行过程中，流程数据、不是路程的相关人也都不应该看到流程，处理过流程的审批人，不可以再对流程进行处理等，都是权限方面要考虑的问题。&lt;/p&gt;

&lt;p&gt;3.2.4 表单设计&lt;/p&gt;

&lt;p&gt;如下图所示的表单，可以分析以下，一个流程表单有多个主表信息和多个子表信息。一般而言，如果是通过流程引擎做非流程的数据处理，子表通过主表ID来做关联，如果通过流程引擎做流程的数据处理，子表和主表通过TaskId来做关联。以下为示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/343f616f-51f3-4591-b822-9d944952e65e20220721201004.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;流程系统需要表单设计器，一个流程的不同节点可以挂接不同的表单，以方便不同角色的人关注不同维度的流程信息&lt;/p&gt;

&lt;p&gt;3.2.5 页面设计&lt;/p&gt;

&lt;p&gt;一般而言，对于流程的发起、审批、历史记录等，都是通用的系统界面。而一些业务场景，需要单独做列表界面，以方便使用。对于已有门户系统的客户，需要融合其界面样式。以下为曾经做过的项目示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/a75f68b0-3fcf-44eb-bfa4-b68a497250c220220721201024.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/550f3646-adea-4d19-a4a6-15fd382a3f4920220721201033.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3.2.6 报表&lt;/p&gt;

&lt;p&gt;由于不是所有客户都有报表系统，所以流程系统需要具备一个基本的报表功能。下图为示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/9b723bca-fdd7-4ea7-9cbe-1f24001eaf9520220721201050.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;有报表系统的客户，可以使用其商业版报表系统，获取（直接取、数仓）数据进行展示。常见的报表系统有FineReport、Tableau、PowerBI等。&lt;/p&gt;

&lt;h4&gt;3.3 BPM流程引擎架构设计&lt;/h4&gt;

&lt;p&gt;3.3.1 流程引擎的架构设计&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/27a03c1c-616d-42e6-b4f5-1ae92ef32d7320220721201118.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3.3.2 发起流程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/19f86ad4-2921-400f-8232-64ef47e2119d20220721201212.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;流程引擎处理过程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/1f1a864f-a484-461e-9141-fd6bdcecb81320220721201222.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;执行节点处理过程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/55f89a3a-0076-4613-863e-6f9a0bb0849220220721201233.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;问题：在流程引擎处理过程中，如果一个节点有多条连线，如何寻找FromNodeId是某个Node的连线？&lt;br/&gt;
人工处理时，指定连线text&lt;/p&gt;

&lt;h4&gt;3.4 流程引擎架构设计&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/40194f1f-778f-4d10-8a33-e1f70a43d46720220721201252.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;3.4.1 业务识别&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt; 识别业务场景中的配置项，使用集合或分组的方式，让业务可配置&lt;/li&gt;
&lt;li&gt; 支撑业务流程过程的可配置化&lt;/li&gt;
&lt;li&gt; 支撑业务场景中的数据，自动处理&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;3.4.2 流程引擎的实现&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt; 资源相关服务，资源加载，资源保存，资源加密等&lt;/li&gt;
&lt;li&gt; 配置项相关服务&lt;/li&gt;
&lt;li&gt; PVM虚拟机的实现，即通过某个节点（发起时为开始节点）作为初始节点，按照某个连线的action进行节点的自动执行的虚拟机&lt;/li&gt;
&lt;li&gt; 数据配置、数据权限&lt;/li&gt;
&lt;li&gt; 流程数据和业务数据的自动处理&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;4 商业机会&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Business Process Analysis (BPA) 流程分析，帮助企业进行流程调整和优化&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Process Assets Library（PAL）流程资产库，对企业流程进行知识化沉淀，将制度和流程落地做绑定，让审批人知晓流程中对应的职责&lt;/p&gt;&lt;/li&gt;
&lt;li&gt; Process Simulate 流程模拟，自动化测试&lt;/li&gt;
&lt;li&gt; Process Forecast 流程预测&lt;/li&gt;
&lt;li&gt; 低代码平台&lt;/li&gt;
&lt;li&gt; 更广泛的机会，在于业务领域+流程引擎，比如：DevOps、RPA、应用与服务编排、数据编排、FaaS编排等。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;作者：马瑞&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ee72454c26be5da86fc6db60eff167c8</guid>
<title>轻松搞定亿级用户中心系统架构</title>
<link>https://toutiao.io/k/tlp6f9a</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&quot; id=&quot;js_content&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;一、背景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;会员系统是一种基础系统，跟公司所有业务线的下单主流程密切相关。如果会员系统出故障，会导致用户无法下单，影响范围是全公司所有业务线。所以，会员系统必须保证高性能、高可用，提供稳定、高效的基础服务。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;随着同程和艺龙两家公司的合并，越来越多的系统需要打通同程APP、艺龙APP、同程微信小程序、艺龙微信小程序等多平台会员体系。例如微信小程序的交叉营销，用户买了一张火车票，此时想给他发酒店红包，这就需要查询该用户的统一会员关系。因为火车票用的是同程会员体系，酒店用的是艺龙会员体系，只有查到对应的艺龙会员卡号后，才能将红包挂载到该会员账号。除了上述讲的交叉营销，还有许多场景需要查询统一会员关系，例如订单中心、会员等级、里程、红包、常旅、实名，以及各类营销活动等等。所以，会员系统的请求量越来越大，并发量越来越高，今年五一小长假的秒并发tps甚至超过2万多。在如此大流量的冲击下，会员系统是如何做到高性能和高可用的呢？这就是本文着重要讲述的内容。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;二、ES高可用方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1. ES双中心主备集群架构&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;同程和艺龙两家公司融合后，全平台所有体系的会员总量是十多亿。在这么大的数据体量下，业务线的查询维度也比较复杂。有的业务线基于手机号，有的基于微信unionid，也有的基于艺龙卡号等查询会员信息。这么大的数据量，又有这么多的查询维度，基于此，我们选择ES用来存储统一会员关系。ES集群在整个会员系统架构中非常重要，那么如何保证ES的高可用呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们知道，ES集群本身就是保证高可用的，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;474&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8351851851851851&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibe1Rbvc6s1Ns4ymEO5t1lfbCI1ZNVYWg3hFFicdiazvHeH7RAZe7kw7bicg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当ES集群有一个节点宕机了，会将其他节点对应的Replica Shard升级为Primary Shard，继续提供服务。但即使是这样，还远远不够。例如ES集群都部署在机房A，现在机房A突然断电了，怎么办？例如服务器硬件故障，ES集群大部分机器宕机了，怎么办？或者突然有个非常热门的抢购秒杀活动，带来了一波非常大的流量，直接把ES集群打死了，怎么办？面对这些情况，让运维兄弟冲到机房去解决？这个非常不现实，因为会员系统直接影响全公司所有业务线的下单主流程，故障恢复的时间必须非常短，如果需要运维兄弟人工介入，那这个时间就太长了，是绝对不能容忍的。那ES的高可用如何做呢？我们的方案是ES双中心主备集群架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;291&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.512962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibe1Uch2gnjgyGU8ibfgJQdqWZPZiaGBlY0C3vX5H5nr1IBpZUiamNic2Khow/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们有两个机房，分别是机房A和机房B。我们把ES主集群部署在机房A，把ES备集群部署在机房B。会员系统的读写都在ES主集群，通过MQ将数据同步到ES备集群。此时，如果ES主集群崩了，通过统一配置，将会员系统的读写切到机房B的ES备集群上，这样即使ES主集群挂了，也能在很短的时间内实现故障转移，确保会员系统的稳定运行。最后，等ES主集群故障恢复后，打开开关，将故障期间的数据同步到ES主集群，等数据同步一致后，再将会员系统的读写切到ES主集群。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2. ES流量隔离三集群架构&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;双中心ES主备集群做到这一步，感觉应该没啥大问题了，但去年的一次恐怖流量冲击让我们改变了想法。那是一个节假日，某个业务上线了一个营销活动，在用户的一次请求中，循环10多次调用了会员系统，导致会员系统的tps暴涨，差点把ES集群打爆。这件事让我们后怕不已，它让我们意识到，一定要对调用方进行优先级分类，实施更精细的隔离、熔断、降级、限流策略。首先，我们梳理了所有调用方，分出两大类请求类型。第一类是跟用户的下单主流程密切相关的请求，这类请求非常重要，应该高优先级保障。第二类是营销活动相关的，这类请求有个特点，他们的请求量很大，tps很高，但不影响下单主流程。基于此，我们又构建了一个ES集群，专门用来应对高tps的营销秒杀类请求，这样就跟ES主集群隔离开来，不会因为某个营销活动的流量冲击而影响用户的下单主流程。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.49722222222222223&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibelCGzuiaGDCllalbsibvETLKUJCITZ9hBR4VYCOszEIwqeoEhw9mriahqw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3. ES集群深度优化提升&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;讲完了ES的双中心主备集群高可用架构，接下来我们深入讲解一下ES主集群的优化工作。有一段时间，我们特别痛苦，就是每到饭点，ES集群就开始报警，搞得每次吃饭都心慌慌的，生怕ES集群一个扛不住，就全公司炸锅了。那为什么一到饭点就报警呢？因为流量比较大， 导致ES线程数飙高，cpu直往上窜，查询耗时增加，并传导给所有调用方，导致更大范围的延时。那么如何解决这个问题呢？通过深入ES集群，我们发现了以下几个问题： &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ES负载不合理，热点问题严重。ES主集群一共有几十个节点，有的节点上部署的shard数偏多，有的节点部署的shard数很少，导致某些服务器的负载很高，每到流量高峰期，就经常预警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ES线程池的大小设置得太高，导致cpu飙高。我们知道，设置ES的threadpool，一般将线程数设置为服务器的cpu核数，即使ES的查询压力很大，需要增加线程数，那最好也不要超过“cpu core * 3 / 2 + 1”。如果设置的线程数过多，会导致cpu在多个线程上下文之间频繁来回切换，浪费大量cpu资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;shard分配的内存太大，100g，导致查询变慢。我们知道，ES的索引要合理分配shard数，要控制一个shard的内存大小在50g以内。如果一个shard分配的内存过大，会导致查询变慢，耗时增加，严重拖累性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;string类型的字段设置了双字段，既是text，又是keyword，导致存储容量增大了一倍。会员信息的查询不需要关联度打分，直接根据keyword查询就行，所以完全可以将text字段去掉，这样就能节省很大一部分存储空间，提升性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ES查询，使用filter，不使用query。因为query会对搜索结果进行相关度算分，比较耗cpu，而会员信息的查询是不需要算分的，这部分的性能损耗完全可以避免。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;节约ES算力，将ES的搜索结果排序放在会员系统的jvm内存中进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;增加routing key。我们知道，一次ES查询，会将请求分发给所有shard，等所有shard返回结果后再聚合数据，最后将结果返回给调用方。如果我们事先已经知道数据分布在哪些shard上，那么就可以减少大量不必要的请求，提升查询性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过以上优化，成果非常显著，ES集群的cpu大幅下降，查询性能大幅提升。ES集群的cpu使用率： &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;293&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5165615141955836&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibe1bxCU9Y5iaJbicA3EGAUFicoFU4N2SMWAtrBbyZc8uMpDvAcnGmdU2rlQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;会员系统的接口耗时：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.1064814814814814&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeG4vcZSdlKrrwsZegNcdJkc8f3JRrgqSicsI2VFsdcWibuBWJJx0n7plQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;三、会员Redis缓存方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;一直以来，会员系统是不做缓存的，原因主要有两个：第一个，前面讲的ES集群性能很好，秒并发3万多，99线耗时5毫秒左右，已经足够应付各种棘手的场景。第二个，有的业务对会员的绑定关系要求实时一致，而会员是一个发展了10多年的老系统，是一个由好多接口、好多系统组成的分布式系统。所以，只要有一个接口没有考虑到位，没有及时去更新缓存，就会导致脏数据，进而引发一系列的问题，例如：用户在APP上看不到微信订单、APP和微信的会员等级、里程等没合并、微信和APP无法交叉营销等等。那后来为什么又要做缓存呢？是因为今年机票的盲盒活动，它带来的瞬时并发太高了。虽然会员系统安然无恙，但还是有点心有余悸，稳妥起见，最终还是决定实施缓存方案。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1. ES近一秒延时导致的Redis缓存数据不一致问题的解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;在做会员缓存方案的过程中，遇到一个ES引发的问题，该问题会导致缓存数据的不一致。我们知道，ES操作数据是近实时的，往ES新增一个Document，此时立即去查，是查不到的，需要等待1秒后才能查询到。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;215&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3787037037037037&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeanMHnWYicrfnUSQINQMJYKFFn1TSSsJLZLicKbiaibgV4bKw3Ql8QxJx4g/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES的近实时机制为什么会导致redis缓存数据不一致呢？具体来讲，假设一个用户注销了自己的APP账号，此时需要更新ES，删除APP账号和微信账号的绑定关系。而ES的数据更新是近实时的，也就是说，1秒后你才能查询到更新后的数据。而就在这1秒内，有个请求来查询该用户的会员绑定关系，它先到redis缓存中查，发现没有，然后到ES查，查到了，但查到的是更新前的旧数据。最后，该请求把查询到的旧数据更新到redis缓存并返回。就这样，1秒后，ES中该用户的会员数据更新了，但redis缓存的数据还是旧数据，导致了redis缓存跟ES的数据不一致。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5721107927411653&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeRSFjW3MQZ6iafaLJqT0EiaJRicZOzT53pDC7RNw15Z4xPQ4uOMfRpjG4g/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1047&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对该问题，如何解决呢？我们的思路是，在更新ES数据时，加一个2秒的redis分布式并发锁，为了保证缓存数据的一致性，接着再删除redis中该会员的缓存数据。如果此时有请求来查询数据，先获取分布式锁，发现该会员ID已经上锁了，说明ES刚刚更新的数据尚未生效，那么此时查询完数据后就不更新redis缓存了，直接返回，这样就避免了缓存数据的不一致问题。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;309&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5444126074498568&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeP7GVRSPry4DJdpemSaiaNwWiakmTian3OJJ7gp4PfbXXRZoSpAGdHPRfA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1047&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述方案，乍一看似乎没什么问题了，但仔细分析，还是有可能导致缓存数据的不一致。例如，在更新请求加分布式锁之前，恰好有一个查询请求获取分布式锁，而此时是没有锁的，所以它可以继续更新缓存。但就在他更新缓存之前，线程block了，此时更新请求来了，加了分布式锁，并删除了缓存。当更新请求完成操作后，查询请求的线程活过来了，此时它再执行更新缓存，就把脏数据写到缓存中了。发现没有？主要的问题症结就在于“删除缓存”和“更新缓存”发生了并发冲突，只要将它们互斥，就能解决问题。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;280&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4935185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibesQc3FqyDSZRB7tHTia6IFviapEn36oSgK73S1YpriaM3ozcAt8MmsMyiag/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实施了缓存方案后，经统计，缓存命中率90%+，极大缓解了ES的压力，会员系统整体性能得到了很大提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2. Redis双中心多集群架构&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;接下来，我们看一下如何保障Redis集群的高可用。如下图所示： &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;322&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5673352435530086&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeBrbDaBAAzicQ5czsfOCGhAfMSrM1QOc0RmSgGTNefbMZN3aCzMlu7Hg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1047&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于Redis集群的高可用，我们采用了双中心多集群的模式。在机房A和机房B各部署一套Redis集群。更新缓存数据时，双写，只有两个机房的redis集群都写成功了，才返回成功。查询缓存数据时，机房内就近查询，降低延时。这样，即使机房A整体故障，机房B还能提供完整的会员服务。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;四、高可用会员主库方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;上述讲到，全平台会员的绑定关系数据存在ES，而会员的注册明细数据存在关系型数据库。最早，会员使用的数据库是SqlServer，直到有一天，DBA找到我们说，单台SqlServer数据库已经存储了十多亿的会员数据，服务器已达到物理极限，不能再扩展了。按照现在的增长趋势，过不了多久，整个SqlServer数据库就崩了。你想想，那是一种什么样的灾难场景：会员数据库崩了，会员系统就崩了；会员系统崩了，全公司所有业务线就崩了。想想就不寒而栗，酸爽无比，为此我们立刻开启了迁移DB的工作。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1. MySql双中心Partition集群方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;经过调研，我们选择了双中心分库分表的MySql集群方案，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;368&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6481481481481481&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibegoDHm7N0Py4WrOiceMicRwhpxmVmwaN6W1qiczBmnESNWd6qlX3JVX04Q/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;会员一共有十多亿的数据，我们把会员主库分了1000多个分片，平分到每个分片大概百万的量级，足够使用了。MySql集群采用1主3从的架构，主库放在机房A，从库放在机房B，两个机房之间通过专线同步数据，延迟在1毫秒内。会员系统通过DBRoute读写数据，写数据都路由到master节点所在的机房A，读数据都路由到本地机房，就近访问，减少网络延迟。这样，采用双中心的MySql集群架构，极大提高了可用性，即使机房A整体都崩了，还可以将机房B的Slave升级为Master，继续提供服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;双中心MySql集群搭建好后，我们进行了压测，测试下来，秒并发能达到2万多，平均耗时在10毫秒内，性能达标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2. 会员主库平滑迁移方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;接下来的工作，就是把会员系统的底层存储从SqlServer切到MySql上，这是个风险极高的工作，主要有以下几个难点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会员系统是一刻都不能停机的，要在不停机的情况下完成SqlServer到MySql的切换，就像是在给高速行驶的汽车换轮子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会员系统是由很多个系统和接口组成的，毕竟发展了10多年，由于历史原因，遗留了大量老接口，逻辑错综复杂。这么多系统，必须一个不落的全部梳理清楚，DAL层代码必须重写，而且不能出任何问题，否则将是灾难性的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据的迁移要做到无缝迁移，不仅是存量10多亿数据的迁移，实时产生的数据也要无缝同步到mysql。另外，除了要保障数据同步的实时性，还要保证数据的正确性，以及SqlServer和MySql数据的一致性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上痛点，我们设计了“全量同步、增量同步、实时流量灰度切换”的技术方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，为了保证数据的无缝切换，采用实时双写的方案。因为业务逻辑的复杂，以及SqlServer和MySql的技术差异性，在双写mysql的过程中，不一定会写成功，而一旦写失败，就会导致SqlServer和MySql的数据不一致，这是绝不允许的。所以，我们采取的策略是，在试运行期间，主写SqlServer，然后通过线程池异步写MySql，如果写失败了，重试三次，如果依然失败，则记日志，然后人工排查原因，解决后，继续双写，直到运行一段时间，没有双写失败的情况。通过上述策略，可以确保在绝大部分情况下，双写操作的正确性和稳定性，即使在试运行期间出现了SqlServer和MySql的数据不一致的情况，也可以基于SqlServer再次全量构建出MySql的数据，因为我们在设计双写策略时，会确保SqlServer一定能写成功，也就是说，SqlServer中的数据是全量最完整、最正确的。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;330&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5807067812798472&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeY2kvibC0Qtamz1UWvgfH55gzliaRHRR5ibUrpAyibcHRYqVnFicd812g6dQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1047&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 讲完了双写，接下来我们看一下“读数据”如何灰度。整体思路是，通过A/B平台逐步灰度流量，刚开始100%的流量读取SqlServer数据库，然后逐步切流量读取MySql数据库，先1%，如果没有问题，再逐步放流量，最终100%的流量都走MySql数据库。在逐步灰度流量的过程中，需要有验证机制，只有验证没问题了，才能进一步放大流量。那么这个验证机制如何实施呢？方案是，在一次查询请求里，通过异步线程，比较SqlServer和 MySql的查询结果是否一致，如果不一致，记日志，再人工检查不一致的原因，直到彻底解决不一致的问题后，再逐步灰度流量。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;328&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5778414517669532&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibesExtB7QRzajJ6aTzzcETzXSTwuySjcRzPVVWz8iahnewvZtZWOA9qvg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1047&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，整体的实施流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;125&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.22037037037037038&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeKCzFHfNibCBU851ibCSiaHxw8RC9znkqEPcAeNxogxO3edLqdDArPSnxA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，在一个夜黑风高的深夜，流量最小的时候，完成SqlServer到MySql数据库的全量数据同步。接着，开启双写，此时，如果有用户注册，就会实时双写到两个数据库。那么，在全量同步和实时双写开启之间，两个数据库还相差这段时间的数据，所以需要再次增量同步，把数据补充完整，以防数据的不一致。剩下的时间，就是各种日志监控，看双写是否有问题，看数据比对是否一致等等。这段时间是耗时最长的，也是最容易发生问题的，如果有的问题比较严重，导致数据不一致了，就需要从头再来，再次基于SqlServer全量构建MySql数据库，然后重新灰度流量，直到最后，100%的流量全部灰度到MySql，此时就大功告成了，下线灰度逻辑，所有读写都切到MySql集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3. MySql和ES主备集群方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;做到这一步，感觉会员主库应该没问题了，可dal组件的一次严重故障改变了我们的想法。那次故障很恐怖，公司很多应用连接不上数据库了，创单量直线往下掉，这让我们意识到，即使数据库是好的，但dal组件异常，依然能让会员系统挂掉。所以，我们再次异构了会员主库的数据源，双写数据到ES，如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;216&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.38055555555555554&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibeFONmFTTkWA6AiaOS7vWlaE0JVOibR1aZ7EXkyJY3cVUEKuL5VPBWNbnQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果dal组件故障或MySql数据库挂了，可以把读写切到ES，等MySql恢复了，再把数据同步到MySql，最后把读写再切回到MySql数据库。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;238&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4185185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibejOqmfkK30mGuVzf7V5yoiaibsPBvfmVaqedX6W9Mrfkh6YW5W3hN14gA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;五、异常会员关系治理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;会员系统不仅仅要保证系统的稳定和高可用，数据的精准和正确也同样重要。举个例子，一个分布式并发故障，导致一名用户的APP账户绑定了别人的微信小程序账户，这将会带来非常恶劣的影响。首先，一旦这两个账号绑定了，那么这两个用户下的酒店、机票、火车票订单是互相可以看到的。你想想，别人能看到你订的酒店订单，你火不火，会不会投诉？除了能看到别人的订单，你还能操作订单。例如，一个用户在APP的订单中心，看到了别人订的机票订单，他觉得不是自己的订单，就把订单取消了。这将会带来非常严重的客诉，大家知道，机票退订费用是挺高的，这不仅影响了该用户的正常出行，还导致了比较大的经济损失，非常糟糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这些异常会员账号，我们进行了详细的梳理，通过非常复杂烧脑的逻辑识别出这些账号，并对会员接口进行了深度优化治理，在代码逻辑层堵住了相关漏洞，完成了异常会员的治理工作。如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;294&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.51796875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibewezEgeC2qPcYFiaibcm9JrPPMXZdsaUpEibJdO9iaPyKdotyVYSq36ktqA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;六、展望：更精细化的流控和降级策略&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;任何一个系统，都不能保证百分之一百不出问题，所以我们要有面向失败的设计，那就是更精细化的流控和降级策略。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 更精细化的流控策略&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;热点控制。针对黑产刷单的场景，同一个会员id会有大量重复的请求，形成热点账号，当这些账号的访问超过设定阈值时，实施限流策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于调用账号的流控规则。这个策略主要是防止调用方的代码bug导致的大流量。例如，调用方在一次用户请求中，循环很多次来调用会员接口，导致会员系统流量暴增很多倍。所以，要针对每个调用账号设置流控规则，当超过阈值时，实施限流策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全局流控规则。我们会员系统能抗下tps 3万多的秒并发请求量，如果此时，有个很恐怖的流量打过来，tps高达10万，与其让这波流量把会员数据库、es全部打死，还不如把超过会员系统承受范围之外的流量快速失败，至少tps 3万内的会员请求能正常响应，不会让整个会员系统全部崩溃。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;297&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5222222222222223&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aLqFHnREiaQEsAPIUlX70ibez25LtIqWWdB0DgzZ2ICcygUUUGUTugh5cDFnCZxn35soojwB0X3hvA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2. 更精细化的降级策略&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;基于平均响应时间的降级。会员接口也有依赖其他接口，当调用其他接口的平均响应时间超过阈值，进入准降级状态。如果接下来 1s 内进入的请求，它们的平均响应时间都持续超过阈值，那么在接下的时间窗口内，自动地熔断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于异常数和异常比例的降级。当会员接口依赖的其他接口发生异常，如果1分钟内的异常数超过阈值，或者每秒异常总数占通过量的比值超过阈值，进入降级状态，在接下的时间窗口之内，自动熔断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，我们最大的痛点是会员调用账号的治理。公司内，想要调用会员接口，必须申请一个调用账号，我们会记录该账号的使用场景，并设置流控、降级策略的规则。但在实际使用的过程中，申请了该账号的同事，可能异动到其他部门了，此时他可能也会调用会员系统，为了省事，他不会再次申请会员账号，而是直接沿用以前的账号过来调用，这导致我们无法判断一个会员账号的具体使用场景是什么，也就无法实施更精细的流控和降级策略。所以，接下来，我们将会对所有调用账号进行一个个的梳理，这是个非常庞大且繁琐的工作，但无路如何，硬着头皮也要做好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;blockquote data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;12&quot; data-source-title=&quot;&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;来源：DBAPlus&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3134ed7dd258758f2254350756e3e6d1</guid>
<title>如何在 CentOS7 上搭建一套 ELK 系统？</title>
<link>https://toutiao.io/k/w3p5ee8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;/&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;span&gt;👇&lt;/span&gt;点击卡片&lt;/span&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;，&lt;/span&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;关注，置顶&lt;/span&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;公众号&lt;span&gt;👇&lt;/span&gt;&lt;/span&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;技术干货，及时送达！&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-id=&quot;MzU0ODk2MzE3MA==&quot; data-pluginname=&quot;mpprofile&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib178LnVu9br0VUuI4OKYwvXKpZnaGseFG3vyFJShp2VFcwVodS88CkUsNYcLDrglYLHPFoic6MJD4A/0?wx_fmt=png&quot; data-nickname=&quot;逻魔代码&quot; data-alias=&quot;lomagicode&quot; data-signature=&quot;逻魔代码，分享架构技术干货，打造有价值的经验分享社群，帮助后继者以前人的肩膀为基，建造更精妙的技术殿堂！&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;一、 问题背景&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;在 CentOS7 环境下，如何搭建一套 ELK 系统?&lt;/strong&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;elk 安装包&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;elasticsearch-7.8.0-x86_64.rpm + kibana-7.8.0-x86_64.rpm + logst如下图&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1861198738170347&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBibRD5CF87Mu2ss6SEuwW7S14ePJvu5R2n6I4uibN9br5cJ7CSLotXuCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;634&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;CentOS 7&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CentOS 7.4   64bit,  图略。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;说明&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上熟悉了docker的用法之后，使用docker和不使用docker差别不大，篇幅所限，只记录重点，不涉及docker环境下的安装和配置。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;注：里面提到的所有操作都是我亲测过的。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;二、 2. 安装（es 和 kibana）&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 安装es&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;rpm -ivh xxx.rpm&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装完毕后，需要配置内容。尤其是需要配置es&lt;code&gt;可以从远程机器访问&lt;/code&gt;。配置后启动，效果如下图。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7121879588839941&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBRCphnv5QPaMU6dibVPST1NemYvukLTsQPTFHjflYTmOfKjAB0XLstGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;681&quot;/&gt;&lt;strong&gt;要点：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;es依赖java环境，所以先安装&lt;code&gt;jdk&lt;/code&gt;，自行解决。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;es安装完成后，可能需要修改配置文件，如端口等&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;es启动时可能会报错，如 &lt;code&gt;can not run elasticsearch as root&lt;/code&gt;（新建其他用户，并配置各个目录权限即可解决，一搜即得）等，需要处理&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]&lt;/code&gt; 这个报错需要配置一下，参考这两个即可解惑。https://www.jianshu.com/p/692608b3b6f9  https://blog.csdn.net/weixin_40143280/article/details/105273199&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. 安装kibana&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;rpm -ivh xxx.rpm&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装完毕后，需要配置内容。尤其是需要配置kibana&lt;code&gt;可以从远程机器访问&lt;/code&gt;。配置后启动，效果如下图。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中遇到一个报错，解决办法：The Reporting plugin encountered issues launching Chromium in a self-test&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;启动后效果如图&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5840336134453782&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBJnQ2IejwbiaeFoBYwzG3Q4oSEN5Mia8VRSLWnvQYZ1WLZBL7eYYTkK9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1190&quot;/&gt;启动过程如图：&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBnOsBqBQ43bFic62oVZaszBicib7R9VVIGRUwZMUZmWfIElSBAQEHuyQcg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot;/&gt;我安装的kibana启动比较顺利。&lt;code&gt;/usr/share/kibana --allow-root&lt;/code&gt; 就成功了，有一些&lt;code&gt;WARN&lt;/code&gt;信息，但无所谓。当然地，如果不喜欢控制台的输出信息，可以这样：&lt;code&gt; nohup bin/kibana --allow-root &amp;amp;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;关键部分暂时部署完成，目标是通过.net 或 java 或logstash的方式 将数据存入es，然后在kibana可以灵活展示和使用&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时kibana可以直接连接到刚才部署的es上面，看和操作es的一些index。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;三、 使用&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自己的思路：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;只先安装es和kibana，es用来存数据（姑且可以先用kibana的 示例数据，或者 通过csv文件导入的数据来玩，暂不考虑如何向es中导入数据的问题）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用kibana自带的sample数据或自己导入的数据，熟悉&lt;code&gt;dashboard&lt;/code&gt;、&lt;code&gt;cavans&lt;/code&gt;、&lt;code&gt;visulize&lt;/code&gt; 等的概念，做到大致了解，心中有数。可以产生各种灵活的饼图柱状图折线图热力图之类的东西自己玩。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图：&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5435684647302904&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBlJicwE97TvcrQTAmO0ziaRNINwNZg1uicLbVepyYlGPN8ibPMqmwr7yp0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1928&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5046875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSB6rX75ibkb9SNCJGXYR0Yc83aiawBexz9gIgVibjzDLgTtJy1Tx2coKXZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6101083032490975&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBu2yicHHgHaKKVMLiaraSAgkkDDFblw2SrEORNp8NYdyghSu7Yibv5OvYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1385&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.562929061784897&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSB2BxN9Y440ibjmoVLoGeJeWDQpwPTEhGyAqmpEZia2p6Pd3wCM07Bbycw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1748&quot;/&gt;&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;四、 logstash的安装与使用&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;安装&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;rpm -ivh xxx.rpm&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装完毕后，需要配置内容，然后启动。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，启动报错是很正常的，遇到什么解决什么，见招拆招就行了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;跟前面的es和kibana一样，安装完成后，&lt;code&gt;/usr/share/logstash&lt;/code&gt; 和 &lt;code&gt;/etc/logstash&lt;/code&gt; 处出现文件。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;使用logstash&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我现在的目的是，通过logstash，不断地从一个mysql表中读数据，写入es的一个索引中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1269083969465649&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBgIwqxIXJDY3IWSyTpGLucXjApUjpf766WZiaVIdB2CrxvIs1edttUOQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1048&quot;/&gt;如图，画横线的两个conf文件就是我的两次导入需要的配置文件，内容仿照&lt;code&gt;logstash-sample.conf&lt;/code&gt;的格式，使用mysql数据源，如&lt;code&gt;ph3.conf&lt;/code&gt;内容如下:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;input {&lt;br/&gt;        jdbc {&lt;br/&gt;                &lt;span&gt;# jdbc_driver_library =&amp;gt; &quot;./mysql-connector-java-5.1.49.jar&quot;&lt;/span&gt;&lt;br/&gt;                jdbc_driver_library =&amp;gt; &lt;span&gt;&quot;/usr/share/logstash/mylib/5.1.45/mysql-connector-java-5.1.45.jar&quot;&lt;/span&gt;&lt;br/&gt;                jdbc_driver_class =&amp;gt; &lt;span&gt;&quot;com.mysql.jdbc.Driver&quot;&lt;/span&gt;&lt;br/&gt;                jdbc_connection_string =&amp;gt; &lt;span&gt;&quot;jdbc:mysql://1.2.3.4:13308/test?characterEncoding=UTF-8&amp;amp;useSSL=false&quot;&lt;/span&gt;&lt;br/&gt;                jdbc_user =&amp;gt; root&lt;br/&gt;                jdbc_password =&amp;gt; 123456&lt;br/&gt;                jdbc_paging_enabled =&amp;gt; &lt;span&gt;&quot;true&quot;&lt;/span&gt; &lt;span&gt;#是否进行分页&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;# jdbc_page_size =&amp;gt; &quot;50000&quot;&lt;/span&gt;&lt;br/&gt;                tracking_column =&amp;gt; &lt;span&gt;&quot;id&quot;&lt;/span&gt;&lt;br/&gt;                use_column_value =&amp;gt; &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;# statement_filepath =&amp;gt; &quot;sql文件路径，与下面的执行语句二选1&quot;&lt;/span&gt;&lt;br/&gt;                statement =&amp;gt; &lt;span&gt;&quot;SELECT * FROM ph3 where id &amp;gt; 0 &quot;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;# 设置监听间隔  各字段含义（由左至右）秒、分、时、天、月、年，全部为*默认含义为每分钟都更新&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;# schedule =&amp;gt; &quot; 10 * * * * *&quot;&lt;/span&gt;&lt;br/&gt;                schedule =&amp;gt; &lt;span&gt;&quot;5 * * * * *&quot;&lt;/span&gt;&lt;br/&gt;        }&lt;br/&gt;}&lt;br/&gt;output {&lt;br/&gt;        elasticsearch {&lt;br/&gt;                document_id =&amp;gt; &lt;span&gt;&quot;%{id}&quot;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;# document_type =&amp;gt; &quot;&quot;&lt;/span&gt;&lt;br/&gt;                index =&amp;gt; &lt;span&gt;&quot;ph4-new-index&quot;&lt;/span&gt;&lt;br/&gt;                hosts =&amp;gt; [&lt;span&gt;&quot;localhost:9200&quot;&lt;/span&gt;]&lt;br/&gt;        }&lt;br/&gt;        stdout{&lt;br/&gt;                codec =&amp;gt; rubydebug&lt;br/&gt;        }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后执行命令，启动logstash进程去完成这件事：&lt;code&gt;sudo bin/logstash -f /etc/logstash/ph3.conf --path.settings=/etc/logstash&lt;/code&gt;命令内容：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;-f 指定了配置文件
--path.settings 指定一个目录，用到一些其他的通用配置，不用管。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可能遇到一些报错，如提示找不到 logstash.yml 文件， --path.settings 指向的不是一个目录，权限不足等，都是网上一搜就能解决的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中特别注意，&lt;code&gt; tracking_column =&amp;gt; &quot;id&quot;&lt;/code&gt; 这一行 和 &lt;code&gt;document_id =&amp;gt; &quot;%{id}&quot;&lt;/code&gt;这行要体会一下意思，以免导入程序跑了半天数据库里只有1个document。这个问题可能会遇到，遇到也好解决，一搜就有。就是这个id字段不是随便写的，需要是mysql数据库的表里的字段，可以作为唯一标识的那种，比如int主键。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以下上个启动图。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7007462686567164&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBgG3VDicGqiaCDBPuN2CoLd4YZmm5WFYr5ZpfDGWENIl9OAuXEvdaBvUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1340&quot;/&gt;如图，红框部分就是任务已经开始执行起来了。然后在kibana网页的&lt;code&gt;索引模式&lt;/code&gt;里面，就可以把这个索引加入到kibana管理里了，然后就可以跟其他数据一样随意操作。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4720531267293857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib3vQ6EzNK1CZWFJgibqECcSBmOVib1VrIHS2kkib3olEWXkpWyt2vpE5ia1HtqOA2eGKGAVWNTUterJ4g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1807&quot;/&gt;自此这条路就完全打通了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;elk都安装且运行正常的情况下，
logstash 从mysql等数据源按照cron表达式确定的时间持续地从mysql中读取数据   ==&amp;gt;  把数据写入到es中  ==&amp;gt;  kibana管理这些数据，可以自定义出各种花样繁多的统计图统计表，导出统计数据等&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以后就很随意了。&lt;/p&gt;&lt;/section&gt;&lt;p mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;/p&gt;&lt;section mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19&quot;&gt;&lt;em&gt;&lt;span&gt;PS：文章有帮助的话，点赞、在看、转发吧！还可以打赏作者、鼓励原创哦！&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19&quot;&gt;&lt;span&gt;&lt;span&gt;-----------------------------------------------&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-tools=&quot;公众号：Java精选&quot; data-id=&quot;91842&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;section mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;section mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mp-original-font-size=&quot;16&quot; mp-original-line-height=&quot;25&quot;&gt;&lt;span mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22&quot;&gt;点击卡片关注我们，更多技术干货，&lt;span&gt;‍&lt;/span&gt;及时为您送达！&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-id=&quot;MzU0ODk2MzE3MA==&quot; data-pluginname=&quot;mpprofile&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/HmXWpTc2vib178LnVu9br0VUuI4OKYwvXKpZnaGseFG3vyFJShp2VFcwVodS88CkUsNYcLDrglYLHPFoic6MJD4A/0?wx_fmt=png&quot; data-nickname=&quot;逻魔代码&quot; data-alias=&quot;lomagicode&quot; data-signature=&quot;逻魔代码，分享架构技术干货，打造有价值的经验分享社群，帮助后继者以前人的肩膀为基，建造更精妙的技术殿堂！&quot; data-from=&quot;2&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;20&quot;&gt;&lt;p mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;20&quot;&gt;往期推荐&lt;/p&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;br mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU0ODk2MzE3MA==&amp;amp;mid=2247484572&amp;amp;idx=1&amp;amp;sn=259614b1319119b8d123d5d1d3196cea&amp;amp;chksm=fbb65291ccc1db87038934df758fca5cae05ba368393e6ae65bcd63fc07a94f381b5b201fe20&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Windows高效开发环境配置（一）&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Windows高效开发环境配置（一）&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU0ODk2MzE3MA==&amp;amp;mid=2247484621&amp;amp;idx=1&amp;amp;sn=813ca3f18e262efbcb186c1ab26695f1&amp;amp;chksm=fbb652c0ccc1dbd694c47effd9f003a8ed045aa3692a3bb06d5857ad14c7060ecf3a611ace1b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;【干货】彻底搞懂Eureka和Nacos的区别&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;【干货】彻底搞懂Eureka和Nacos的区别&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU0ODk2MzE3MA==&amp;amp;mid=2247484542&amp;amp;idx=1&amp;amp;sn=cb34e6b94c24c4b1088ea792c9f68005&amp;amp;chksm=fbb65273ccc1db651e2b61805f6fecf69825fb910861b086e448091912ee2836f88b67ab07e0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;【干货】MySQL索引背后的数据结构及算法原理&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;【干货】MySQL索引背后的数据结构及算法原理&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU0ODk2MzE3MA==&amp;amp;mid=2247484248&amp;amp;idx=1&amp;amp;sn=f5b9cb17c09cc283896c8171ed39e8c6&amp;amp;chksm=fbb65555ccc1dc43b1c607abfd48284aa33a2c7de5303300e8bd9273091022c17b0794add387&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;结合实操带你吃透Redis持久化&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;结合实操带你吃透Redis持久化&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;&gt;&lt;br mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19&quot;&gt;公&lt;/span&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19&quot;&gt;众号“逻魔代码”所发表内容注明来源的，版权归原出处所有（无法查证版权的或者未注明出处的均来自网络，系转载，转载的目的在于传递更多信息，版权属于原作者。如有侵权，请联系，笔者会第一时间删除处理！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>572c89eeb9b9d8965dd59e897243ab6c</guid>
<title>ClickHouse 挺快，esProc SPL 更快</title>
<link>https://toutiao.io/k/bbtd8ga</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;span&gt;开源分析数据库 ClickHouse 以快著称，真的如此吗？我们通过对比测试来验证一下。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;ClickHouse vs Oracle&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;先用 ClickHouse（简称 CH）、Oracle 数据库（简称 ORA）一起在相同的软硬件环境下做对比测试。测试基准使用国际广泛认可的 TPC-H，针对 8 张表，完成 22 条 SQL 语句定义的计算需求（Q1 到 Q22）。测试采用单机 12 线程，数据总规模 100G。TPC-H 对应的 SQL 都比较长，这里就不详细列出了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Q1 是简单的单表遍历计算分组汇总，对比测试结果如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.31666666666666665&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIC5wwM1aiaf4PiabwWT12qjKFFgRBy65smbaqvuCA4tzsXBgvTeiatoyIg/640?wx_fmt=png&amp;amp;random=0.40159775703001777&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;CH 计算 Q1 的表现要好于 ORA，说明 CH 的列式存储做得不错，单表遍历速度很快。而 ORA 主要吃亏在使用了行式存储，明显要慢得多了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;但是，如果我们加大计算复杂度，CH 的表现怎么样呢？继续看 TPC-H 的 Q2、Q3、Q7，测试结果如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45740740740740743&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIefC9xscAB1CTIoGCPkwnqhWdnsJ6Ugd0asN7n6UlNib3JH1gVPuxzSA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45740740740740743&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIefC9xscAB1CTIoGCPkwnqhWdnsJ6Ugd0asN7n6UlNib3JH1gVPuxzSA/640?wx_fmt=png&amp;amp;random=0.8213813373122316&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIefC9xscAB1CTIoGCPkwnqhWdnsJ6Ugd0asN7n6UlNib3JH1gVPuxzSA/640?wx_fmt=png&quot; data-index=&quot;2&quot;&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;计算变得复杂之后，CH 性能出现了明显的下降。Q2 涉及数据量较少，列存作用不大，CH 性能和 ORA 几乎一样。Q3 数据量较大，CH 占了列存的便宜后超过了 ORA。Q7 数据也较大，但是计算复杂，CH 性能还不如 ORA。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;做复杂计算快不快，主要看性能优化引擎做的好不好。CH 的列存占据了巨大的存储优势，但竟然被 ORA 用行式存储赶上，这说明 CH 的算法优化能力远不如 ORA。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;TPC-H 的 Q8 是更复杂一些的计算，子查询中有多表连接，CH 跑了 2000 多秒还没有出结果，应该是卡死了，ORA 跑了 192 秒。Q9 在 Q8 的子查询中增加了 like，CH 直接报内存不足的错误了，ORA 跑了 234 秒。其它还有些复杂运算是 CH 跑不出来的，就没法做个总体比较了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;CH 和 ORA 都基于 SQL 语言，但是 ORA 能优化出来的语句，CH 却跑不出来，更证明 CH 的优化引擎能力比较差。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;坊间传说，CH 只擅长做单表遍历运算，有关联运算时甚至跑不过 MySQL，看来并非虚妄胡说。想用 CH 的同学要掂量一下了，这种场景到底能有多大的适应面？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;esProc SPL 登场&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;开源 esProc SPL 也是以高性能作为宣传点，那么我们再来比较一下。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;仍然是跑 TPC-H 来看 ：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7416666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIb3o3crCckzQINMTUVKqeOP3UhCdVeFmibZ87QuaM3kypOyeBPVpPcUg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7416666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIb3o3crCckzQINMTUVKqeOP3UhCdVeFmibZ87QuaM3kypOyeBPVpPcUg/640?wx_fmt=png&amp;amp;random=0.8253380543320712&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIb3o3crCckzQINMTUVKqeOP3UhCdVeFmibZ87QuaM3kypOyeBPVpPcUg/640?wx_fmt=png&quot; data-index=&quot;3&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Q2、Q3、Q7 这些较复杂的运算，SPL 比 CH 和 ORA 跑的都快。CH 跑不出结果的 Q8、Q9，SPL 分别跑了 37 秒和 68 秒，也比 ORA 快。原因在于 SPL 可以采用更优的算法，其计算复杂度低于被 ORA 优化过的 SQL，更远低于 CH 执行的 SQL，再加上列存，最终是用 Java 开发的 SPL 跑赢了 C++ 实现的 CH 和 ORA。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;大概可以得到结论，esProc SPL 无论做简单计算，还是复杂计算性能都非常好。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;不过，Q1 这种简单运算，CH 比 SPL 还是略胜了一筹。似乎可以进一步证明前面的结论，即 CH 特别擅长简单遍历运算。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;且慢，SPL 还有秘密武器。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SPL 的企业版中提供了&lt;strong&gt;列式游标&lt;/strong&gt;机制，我们再来对比测试一下：在 8 亿条数据量下，做最简单的分组汇总计算，对比 SPL（使用列式游标）和 CH 的性能。（采用的机器配置比前面做 TPC-H 测试时略低，因此测出的结果不同，不过这里主要看相对值。）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;简单分组汇总对应 CH 的 SQL 语句是：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SQL1：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;mod&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; Aid, &lt;span class=&quot;code-snippet__keyword&quot;&gt;max&lt;/span&gt;(amount) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; Amax&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt; test.t&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;mod&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这个测试的结果是下图这样：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.30833333333333335&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIYPwXU4TybT4K33X1xUUfhNgLMqibJT66jLXzv1kciaiaibgIMzw3K0EsIw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.30833333333333335&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIYPwXU4TybT4K33X1xUUfhNgLMqibJT66jLXzv1kciaiaibgIMzw3K0EsIw/640?wx_fmt=png&amp;amp;random=0.16094650711713276&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIYPwXU4TybT4K33X1xUUfhNgLMqibJT66jLXzv1kciaiaibgIMzw3K0EsIw/640?wx_fmt=png&quot; data-index=&quot;4&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SPL 使用列式游标机制之后，简单遍历分组计算的性能也和 CH 一样了。如果在 TPC-H 的 Q1 测试中也使用列式游标，SPL 也会达到和 CH 同样的性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;测试过程中发现，8 亿条数据存成文本格式占用磁盘 15G，在 CH 中占用 5.4G，SPL 占用 8G。说明 CH 和 SPL 都采用了压缩存储，CH 的压缩比更高些，也进一步证明 CH 的存储引擎做得确实不错。不过，SPL 也可以达到和 CH 同样的性能，这说明 SPL 存储引擎和算法优化做得都比较好，高性能计算能力更加均衡。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前版本的 SPL 是用 Java 写的，Java 读数后生成用于计算的对象的速度很慢，而用 C++ 开发的 CH 则没有这个问题。对于复杂的运算，读数时间占比不高，Java 生成对象慢造成的拖累还不明显；而对于简单的遍历运算，读数时间占比很高，所以前面测试中 SPL 就会比 CH 更慢。列式游标优化了读数方案，不再生成一个个小对象，使对象生成次数大幅降低，这时候就能把差距拉回来了。单纯从存储本身看，SPL 和 CH 相比并没有明显的优劣之分。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来再看常规 TopN 的对比测试，CH 的 SQL 是：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SQL2：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt; test.t &lt;span class=&quot;code-snippet__keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; amount &lt;span class=&quot;code-snippet__keyword&quot;&gt;DESC&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;对比测试结果是这样的：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3148148148148148&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icI8CSb8XQYGP30RoMmrofyQh5vXjazKiaHxYoEa9WHrHywMR8OABp0sAw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3148148148148148&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icI8CSb8XQYGP30RoMmrofyQh5vXjazKiaHxYoEa9WHrHywMR8OABp0sAw/640?wx_fmt=png&amp;amp;random=0.9479209225685261&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icI8CSb8XQYGP30RoMmrofyQh5vXjazKiaHxYoEa9WHrHywMR8OABp0sAw/640?wx_fmt=png&quot; data-index=&quot;5&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;单看 CH 的 SQL2，常规 TopN 的计算方法是全排序后取出前 N 条数据。数据量很大时，如果真地做全排序，性能会非常差。SQL2 的测试结果说明，CH 应该和 SPL 一样做了优化，没有全排序，所以两者性能都很快，SPL 稍快一些。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;也就是说，无论简单运算还是复杂运算，esProc SPL 都能更胜一筹。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;进一步的差距&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;差距还不止于此。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;正如前面所说，CH 和 ORA 使用 SQL 语言，都是基于关系模型的，所以都面临 SQL 优化的问题。TPC-H 测试证明，ORA 能优化的一些场景 CH 却优化不了，甚至跑不出结果。那么，如果面对一些 ORA 也不会优化的计算，CH 就更不会优化了。比如说我们将 SQL1 的简单分组汇总，改为两种分组汇总结果再连接，CH 的 SQL 写出来大致是这样：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SQL3：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt; *&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt; ( &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;mod&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; Aid, &lt;span class=&quot;code-snippet__keyword&quot;&gt;max&lt;/span&gt;(amount) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; Amax &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt; test.t &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;mod&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  ) A &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;JOIN&lt;/span&gt; ( &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;floor&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt; / &lt;span class=&quot;code-snippet__number&quot;&gt;200000&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; Bid, &lt;span class=&quot;code-snippet__keyword&quot;&gt;min&lt;/span&gt;(amount) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; Bmin &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt; test.t &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;floor&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt; / &lt;span class=&quot;code-snippet__number&quot;&gt;200000&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  ) B &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;ON&lt;/span&gt; A.Aid = B.Bid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这种情况下，对比测试的结果是 CH 的计算时间翻倍，SPL 则不变：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4101851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIfJKNd48iab6p5IgxZrKRcRwxjUtXFwYYI7joOcb9z93yweTztoZyk7Q/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4101851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIfJKNd48iab6p5IgxZrKRcRwxjUtXFwYYI7joOcb9z93yweTztoZyk7Q/640?wx_fmt=png&amp;amp;random=0.863592389296526&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIfJKNd48iab6p5IgxZrKRcRwxjUtXFwYYI7joOcb9z93yweTztoZyk7Q/640?wx_fmt=png&quot; data-index=&quot;6&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这是因为 SPL 不仅使用了列式游标，还使用了&lt;strong&gt;遍历复用&lt;/strong&gt;机制，能在一次遍历过程中计算出多种分组结果，可以减少很多硬盘访问量。CH 使用的 SQL 无法写出这样的运算，只能靠 CH 自身的优化能力了。而 CH 算法优化能力又很差，其优化引擎在这个测试中没有起作用，只能遍历两次，所以性能下降了一倍。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SPL 实现遍历复用的代码很简单，大致是这样：&lt;/span&gt;&lt;/section&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;A&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;B&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;span&gt;=file(&quot;topn.ctx&quot;).open().cursor@mv(id,amount)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;cursor A1&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=A2.groups(id%100:Aid;max(amount):Amax)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;cursor&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=A3.groups(id\200000:Bid;min(amount):Bmin)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;span&gt;=A2.join@i(Aid,A3:Bid,Bid,Bmin)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;再将 SQL2 常规 TopN 计算，调整为分组后求组内 TopN。&lt;/span&gt;&lt;span&gt;对应 SQL 是：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;SQL4：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  gid,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  groupArray(&lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;)(amount) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; amount&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;SELECT&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;mod&lt;/span&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;10&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; gid,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    amount    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;FROM&lt;/span&gt; test.topn    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    gid &lt;span class=&quot;code-snippet__keyword&quot;&gt;ASC&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    amount &lt;span class=&quot;code-snippet__keyword&quot;&gt;DESC&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;AS&lt;/span&gt; a&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; gid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这&lt;/span&gt;&lt;span&gt;个分组 TopN 测试的对比结果是下面这样的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3925925925925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIj323s0tficGmayzPghQsOEn9dgBjiaXA8bNdIaHcwKdmv7O2Z2agxvZg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3925925925925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIj323s0tficGmayzPghQsOEn9dgBjiaXA8bNdIaHcwKdmv7O2Z2agxvZg/640?wx_fmt=png&amp;amp;random=0.00035276248240490027&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccsVUwqibupku1jlr7nnB4icIj323s0tficGmayzPghQsOEn9dgBjiaXA8bNdIaHcwKdmv7O2Z2agxvZg/640?wx_fmt=png&quot; data-index=&quot;7&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;CH 做分组 TopN 计算比常规 TopN 慢了 42 倍，说明 CH 在这种情况下很可能做了排序动作。也就是说，情况复杂化之后，CH 的优化引擎又不起作用了。与 SQL 不同，SPL 把 TopN 看成是一种聚合运算，和 sum、count 这类运算的计算逻辑是一样的，都只需要对原数据遍历一次。这样，分组求组内 TopN 就和分组求和、计数一样了，可以避免排序计算。因此，SPL 计算分组 TopN 比 CH 快了 22 倍。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;而且，SPL 计算分组 TopN 的代码也不复杂：&lt;/span&gt;&lt;/section&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=file(&quot;topn.ctx&quot;).open().cursor@mv(id,amount)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=A1.groups(id%10:gid;top(10;-amount)).news(#2;gid,~.amount)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;不只是跑得快&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;再来看看电商系统中常见的漏斗运算。SPL 的代码依然很简洁：&lt;/span&gt;&lt;/section&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;A&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;B&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=[&quot;etype1&quot;,&quot;etype2&quot;,&quot;etype3&quot;]&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=file(&quot;event.ctx&quot;).open()&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;span&gt;=B1.cursor(id,etime,etype;etime&amp;gt;=date(&quot;2021-01-10&quot;) &amp;amp;&amp;amp; etime&amp;lt;date(&quot;2021-01-25&quot;) &amp;amp;&amp;amp; A1.contain(etype) &amp;amp;&amp;amp; …)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=A2.group(id).(~.sort(etime))&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;=A3.new(~.select@1(etype==A1(1)):first,~:all).select(first)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;span&gt;=B3.(A1.(t=if(#==1,t1=first.etime,if(t,all.select@1(etype==A1.~ &amp;amp;&amp;amp; etime&amp;gt;t &amp;amp;&amp;amp; etime&amp;lt;t1+7).etime, null))))&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;5&lt;/span&gt;&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;&lt;span&gt;=A4.groups(;count(~(1)):STEP1,count(~(2)):STEP2,count(~(3)):STEP3)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;CH 的 SQL 无法实现这样的计算，我们以 ORA 为例看看三步漏斗的 SQL 写法：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;with&lt;/span&gt; e1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; (  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; gid,&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; step1,&lt;span class=&quot;code-snippet__keyword&quot;&gt;min&lt;/span&gt;(etime) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; t1  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; T  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; etime&amp;gt;= &lt;span class=&quot;code-snippet__keyword&quot;&gt;to_date&lt;/span&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;2021-01-10&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;yyyy-MM-dd&#x27;&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; etime&amp;lt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;to_date&lt;/span&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;2021-01-25&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;yyyy-MM-dd&#x27;&lt;/span&gt;)    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; eventtype=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;eventtype1&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; …  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;),&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;with&lt;/span&gt; e2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; (  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; gid,&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; step2,&lt;span class=&quot;code-snippet__keyword&quot;&gt;min&lt;/span&gt;(e1.t1) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; t1,&lt;span class=&quot;code-snippet__keyword&quot;&gt;min&lt;/span&gt;(e2.etime) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; t2  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; T &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; e2  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;join&lt;/span&gt; e1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;on&lt;/span&gt; e2.gid = e1.gid  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; e2.etime&amp;gt;= &lt;span class=&quot;code-snippet__keyword&quot;&gt;to_date&lt;/span&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;2021-01-10&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;yyyy-MM-dd&#x27;&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; e2.etime&amp;lt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;to_date&lt;/span&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;2021-01-25&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;yyyy-MM-dd&#x27;&lt;/span&gt;) &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; e2.etime &amp;gt; t1    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; e2.etime &amp;lt; t1 + &lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; eventtype=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;eventtype2&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; …  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;),&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;with&lt;/span&gt; e3 &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; (  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; gid,&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; step3,&lt;span class=&quot;code-snippet__keyword&quot;&gt;min&lt;/span&gt;(e2.t1) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; t1,&lt;span class=&quot;code-snippet__keyword&quot;&gt;min&lt;/span&gt;(e3.etime) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; t3  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; T &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; e3  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;join&lt;/span&gt; e2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;on&lt;/span&gt; e3.gid = e2.gid  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; e3.etime&amp;gt;= &lt;span class=&quot;code-snippet__keyword&quot;&gt;to_date&lt;/span&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;2021-01-10&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;yyyy-MM-dd&#x27;&lt;/span&gt;) &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; e3.etime&amp;lt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;to_date&lt;/span&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;2021-01-25&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;yyyy-MM-dd&#x27;&lt;/span&gt;) &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; e3.etime &amp;gt; t2    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; e3.etime &amp;lt; t1 + &lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; eventtype=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;eventtype3&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; …  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;sum&lt;/span&gt;(step1) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; step1,  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;sum&lt;/span&gt;(step2) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; step2,  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;sum&lt;/span&gt;(step3) &lt;span class=&quot;code-snippet__keyword&quot;&gt;as&lt;/span&gt; step3&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  e1  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;join&lt;/span&gt; e2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;on&lt;/span&gt; e1.gid = e2.gid  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;join&lt;/span&gt; e3 &lt;span class=&quot;code-snippet__keyword&quot;&gt;on&lt;/span&gt; e2.gid = e3.gid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ORA 的 SQL 写出来要三十多行，理解起来有相当的难度。而且这段代码和漏斗的步骤数量相关，每增加一步数就要再增加一段子查询。相比之下，SPL 就简单得多，处理任意步骤数都是这段代码。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这种复杂的 SQL，写出来都很费劲，性能优化更无从谈起。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;而 CH 的 SQL 还远不如 ORA，基本上写不出这么复杂的逻辑，只能在外部写 C++ 代码实现。也就是说，这种情况下只能利用 CH 的存储引擎。虽然用 C++ 在外部计算有可能获得很好的性能，但开发成本非常高。类似的例子还有很多，CH 都无法直接实现。&lt;/span&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;总结一下：CH 计算某些简单场景（比如单表遍历）确实很快，和 SPL 的性能差不多。但是，高性能计算不能只看简单情况快不快，还要权衡各种场景。对于复杂运算而言，SPL 不仅性能远超 CH，代码编写也简单很多。SPL 能覆盖高性能数据计算的全场景，可以说是完胜 CH。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0045249&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ce5ibR15d3hewLL1THeqrvJfSEZ4XjIY2mh7J1F3iawVj2xoXQoJCmAjd3D6SSzxicictFQU8pLMz3dMg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;random=0.41396681018949333&quot; data-type=&quot;png&quot; data-w=&quot;221&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ce5ibR15d3hewLL1THeqrvJfSEZ4XjIY2mh7J1F3iawVj2xoXQoJCmAjd3D6SSzxicictFQU8pLMz3dMg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-index=&quot;8&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;重磅！开源SPL交流群成立了&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;简单好用的SPL开源啦！&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了给感兴趣的技术人员提供一个相互交流的平台，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特地开通了交流群（群完全免费，不广告不卖课）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;需要进群的朋友，可长按扫描下方二维码&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccRquXadwB2EJbHw5TqekgYsUKErBDJ4urvJ0vcL8mC9B7H6MCB3oa3RlPm3wzvLCJlWgk6QogQwQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;430&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;248&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;248&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccRquXadwB2EJbHw5TqekgYsUKErBDJ4urvJ0vcL8mC9B7H6MCB3oa3RlPm3wzvLCJlWgk6QogQwQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;random=0.041397840360319016&quot; data-type=&quot;png&quot; data-w=&quot;430&quot;/&gt;&lt;span class=&quot;js_img_placeholder&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3dBJseibic1ccRquXadwB2EJbHw5TqekgYsUKErBDJ4urvJ0vcL8mC9B7H6MCB3oa3RlPm3wzvLCJlWgk6QogQwQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-index=&quot;9&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;本文感兴趣的朋友，请到阅读原文去收藏 ^_^&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b0e93c5a07c65c661b0326f46acdc285</guid>
<title>Flink Unaligned Checkpoint 在 Shopee 的优化和实践</title>
<link>https://toutiao.io/k/40oi4qm</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkzMDE5MDgwMQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06QOehJ8N23MsruOT4cvjbrbNia2W0CKMSSszTMW4Jtj03ia2gBMGb2W6kUOeNuhS8acRaU3Z3BNPbQ/0?wx_fmt=png&quot; data-nickname=&quot;Shopee技术团队&quot; data-alias=&quot;ShopeeTech&quot; data-signature=&quot;如何在海外多元、复杂场景下实践创新探索，解决技术难题？Shopee技术团队将与你一起探讨前沿技术思考与应用。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;点击关注公众号👆，探索更多Shopee技术实践&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;目录&lt;br/&gt;&lt;br/&gt;1. Checkpoint 存在的问题&lt;br/&gt;2. Unaligned Checkpoint 原理介绍&lt;br/&gt;3. 大幅提升 UC 收益&lt;br/&gt;4. 大幅降低 UC 风险&lt;br/&gt;5. UC 在 Shopee 的生产实践和未来规划&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Flink 做为大数据流计算的标杆，通过 Checkpoint 和 State 保证了 Exactly Once 语义。在生产实践中，Shopee 遇到了很多 Checkpoint 的问题，并尝试引入 Flink 的 Unaligned Checkpoint 去解决。但调研后发现效果与预期有一定差距，所以在内部版本对其进行了深度改进，并将大部分改进已经反馈给了 Flink 社区。&lt;/p&gt;&lt;p&gt;本文会介绍 Checkpoint 存在的问题、Unaligned Checkpoint 原理、Shopee 对 Unaligned Checkpoint 的改进、对 Flink 社区的贡献以及内部的实践和落地。&lt;/p&gt;&lt;/blockquote&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. Checkpoint 存在的问题&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.1 Checkpoint 存在的技术问题&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Flink 作业反压严重导致 Checkpoint 超时失败是 Flink 生产中普遍存在的问题，而持续的反压会造成长时间没有成功的 Checkpoint。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：外部查询或写入性能瓶颈、CPU 瓶颈、数据倾斜等在大促或高峰期常见的场景都会间接导致 Checkpoint 持续失败。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2 Checkpoint 持续失败对业务的影响&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）消费了半小时的 lag 数据，dev 发现这半小时任务的消费速率慢，达不到预期，想调大任务并行度并重启来提升消费能力。如果 Checkpoint 一直失败，则需要从半小时前的 Checkpoint 恢复，这半小时内消费过的数据会被重复消费，导致资源浪费和业务数据可能重复的风险。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）当消费 lag 时，如果 &lt;code&gt;tolerable-failed-checkpoints&lt;/code&gt;（容忍 CP 失败的次数默认是 0）太低，Flink job 可能进入死循环&lt;code&gt;（消费 lag 导致 job 反压严重，反压严重导致 Checkpoint 超时失败，Checkpoint 失败导致 job 失败，job 失败导致消费更多的 lag）&lt;/code&gt;，lag 永远不能消费完成。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3）无限容忍 Checkpoint 失败不是优雅的解决方案，如果容忍次数太高：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;生产上的问题不能及时地被发现；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些 Connector 在 Checkpoint 时会提交数据或文件。如果 Checkpoint 持续失败，这些数据或文件长时间不能被提交，它会导致数据延迟和事务超时。例如：Kafka Producer 事务超时会导致事务失败；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一旦作业重启，将有大量数据被重复消费。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4）业务高峰和大促与消费 lag 类似，会遇到相同的问题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.3 引入 Unaligned Checkpoint&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于上述背景，很多用户都希望在 Flink 任务有瓶颈（反压严重）时，Checkpoint 可以成功，所以 Flink 社区在 &lt;a href=&quot;https://cwiki.apache.org/confluence/display/FLINK/FLIP-76%3A+Unaligned+Checkpoints&quot; data-linktype=&quot;2&quot;&gt;FLIP-76&lt;/a&gt; 中引入了 Unaligned Checkpoint 机制（下文简称 UC）。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. Unaligned Checkpoint 原理介绍&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 UC 核心思路&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;反压严重时，Aligned Checkpoint（下文简称 AC）超时主要在于 Barrier 在数据流中排队。反压严重时，数据流动很慢导致 Barrier 流动很慢，最终导致 AC 超时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;UC 的核心思路是：当数据流动很慢时，Barrier 通过某些机制超越数据，从而使得 Barrier 可以快速地从 Source 一路超车到 Sink。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 Task 的 UC 流程详解&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设当前 Task 上游 Task 并行度为 3，下游并行度为 2。UC 开始后 Task 的 3 个 InputChannel 会陆续收到上游发送的 Barrier。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图所示，灰色框表示 buffer 中的一条条数据，InputChannel-0 先收到 Barrier，其他 InputChannel 还没收到 Barrier。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;228&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.39481268011527376&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6CicK4Fg97d28njvq39yupy9FC4iardNCQv5c52yQUpjV310YB7QCYRWMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3123&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当某一个 InputChannel 接收到 Barrier 时，会直接开启 UC 的第一阶段，即：UC 同步阶段。注意：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;只要有任意一个 Barrier 进入 Task 网络层的输入缓冲区，Task 直接开始 UC；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不用等其他 InputChannel 接收到 Barrier，也不需要处理完 InputChannel 内 Barrier 之前的数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，为了保证数据一致性，UC 同步阶段 Task 不能处理数据，同步阶段会做以下几个事情：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Barrier 超车：发送 Barrier 到所有的 ResultSubPartition 的头部，超越所有的 input&amp;amp;output buffer，Barrier 可以被快速发到下游 Task；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Buffer 进行快照：对所有超越的 input&amp;amp;output buffer 做快照；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;调用算子的 snapshotState 方法；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Flink 引擎对算子内部的 State 进行快照。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;229&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.3957732949087416&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6CubtR1hfwNnhtA31ScPhW3luAVskg1csVIYQXVJHjE5iaqaibNCah6BrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3123&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有几个注意事项：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;做 UC 时，Barrier 超越的 buffer 数据直接被跳过了。为了保证数据不丢失，这些 buffer 需要跟 State 一起写到 HDFS，从 Checkpoint 恢复时，这些数据会被消费；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;同步阶段 Task 不能处理数据，为了尽量减少阻塞的时间，同步阶段只是对 buffer 和状态数据进行一份引用，真正写数据到 HDFS 会通过异步完成；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;UC 同步阶段的最后两步与 AC 完全一致，对算子内部的 State 进行快照。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;UC 同步阶段完成后，Task 继续处理数据，同时开启 UC 的第二个阶段：Barrier 对齐和 UC 异步阶段。异步阶段将同步阶段浅拷贝的 State 以及 buffer 写到 HDFS 中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么 UC 还有 Barrier 对齐呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当 Task 开始 UC 时，有很多 InputChannel 没接收到 Barrier，这些 InputChannel 的 Barrier 之前可能还会有 network buffer 需要进行快照，所以 UC 第二阶段需要等所有 InputChannel 的 Barrier 都到达，且 Barrier 之前的 buffer 都需要快照。可以认为 UC 需要写三类数据到 HDFS 上：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;同步阶段引用的所有 input&amp;amp;output buffer；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;同步阶段引用的算子内部的 State；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;同步阶段后其他 InputChannel Barrier 之前的 buffer。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;异步阶段把这三部分数据全部写完后，将文件地址汇报给 JobManager，当前 Task 的 UC 结束。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注：理论上 UC 异步阶段的 Barrier 对齐会很快。如上述 Task 所示，Barrier 可以快速超越所有的 input&amp;amp;output buffer，优先发送 Barrier 给下游 Task，所以上游 Task 也类似：Barrier 超越上游所有的 buffer，快速发送给当前 Task。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 UC 实践中的问题&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当任意一个 Barrier 进入 Task 网络层的输入缓冲区时，Task 直接开始 UC。Barrier 快速超越所有的 buffer 被发送到下游，所以 UC 不受反压影响。理论上：无论反压有多严重，UC Barrier 都可以一路超车，快速从 Source 流到 Sink，每个 Task 都可以快速完成快照。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理论很美好，但我们在实际调研和任务使用过程中，发现 UC 效果达不到预期：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在很多场景，任务反压严重时，UC 仍然不能成功，导致 UC 预期收益大打折扣；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;UC 会显著增加写 HDFS 的文件数，对线上服务的稳定性有影响，增加了大范围应用的难度；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;UC 存在一些 bug。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后续部分会介绍上述问题，以及 Shopee 的解决方案和对社区的贡献。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3. 大幅提升 UC 收益&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Task 在处理数据的过程中不能处理 Checkpoint，必须将当前处理的这条数据处理完并将结果写入到 OutputBufferPool 中，才会检查是否 InputChannel 有接收到 UC Barrier，如果有则开始 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 Task 处理一条数据并写结果到 OutputBufferPool 超过 10 分钟，那么 UC 还是会超时。通常处理一条数据不会很慢，但写结果到 OutputBufferPool 可能会比较耗时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从 OutputBufferPool 的视角来看，上游 Task 是生产者，下游 Task 是消费者。所以下游 Task 有瓶颈时，上游 Task 输出结果到 OutputBufferPool 会卡在等待 buffer，不能开始 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决这个问题，Flink 社区在 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-14396&quot; data-linktype=&quot;2&quot;&gt;FLINK-14396&lt;/a&gt; 中引入了预留 buffer 的机制。解决思路是：Task 处理数据前检查 OutputBufferPool 是否有空闲的 buffer，如果没有空闲 buffer 则继续等待。详细流程如下图所示。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;241&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;241&quot; data-ratio=&quot;0.41644562334217505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05Te3ibmMQK188NPbyHys89rx5icptr1r6ohkRJkVvic9MB4VPiaVJnrJtGBBddJYwGQKbECCVbpopGgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3393&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;等 OutputBufferPool 中有空闲 buffer 了才去处理数据，来保证 Task 处理完数据后可以顺利地将结果写入到 OutputBufferPool 中，不会卡在第 5 步数据输出的环节。优化后如果没有空闲 buffer，Task 会卡在第 3 步等待空闲 buffer 和 UC Barrier 的环节，在这个环节当接收到 UC Barrier 时可以快速开始 UC。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 处理一条数据需要多个 buffer 场景的提升&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，由于只预留了一个 buffer，当处理一条数据需要多个 buffer 的场景，Task 处理完数据输出结果到 OutputBufferPool 时可能仍然会卡在第 5 步，导致 Task 不能处理 UC。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;241&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;241&quot; data-ratio=&quot;0.41644562334217505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn05Te3ibmMQK188NPbyHys89rD2rcD4TlIP3Hs56iaMgHpnk37bLT3FXA1ibpmCFIKvyzGlmibicbBWuia4Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3393&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：单条数据较大、flatmap、window 触发以及广播 watermark 都是处理一条数据需要多个 buffer 场景，这些场景下 Task 卡在第 5 步数据输出环节，导致 UC 表现不佳。解决这个问题的核心思路还是如何让 Task 不要卡在第 5 步而是卡在第 3 步的等待环节。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于上述问题，Shopee 在 &lt;a href=&quot;https://cwiki.apache.org/confluence/display/FLINK/FLIP-227%3A+Support+overdraft+buffer&quot; data-linktype=&quot;2&quot;&gt;FLIP-227&lt;/a&gt; 提出了 overdraft（透支） buffer 的提议，思路是：处理数据过程中，如果 buffer 不足且 TaskManager 有空余的 network 内存，则当前 Task 的 OutputBufferPool 会向 TM 透支一些 buffer，从而完成第 5 步数据处理环节。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注：OutputBufferPool 一定是在没有空闲 buffer 时才会使用透支 buffer。所以一旦透支 buffer 被使用，Task 在进行下一轮第 3 步进入等待 Barrier 和空闲 buffer 的环节时，Task 会认为 OutputBufferPool 没有空闲 buffer，直到所有透支 buffer 都被下游 Task 消费完且 OutputBufferPool 至少有一个空闲 buffer 时，Task 才会继续处理数据。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认 &lt;code&gt;taskmanager.network.memory.max-overdraft-buffers-per-gate=5&lt;/code&gt;，即：Task 的每个 OutputBufferPool 可以向 TM 透支 5 个 buffer。引入透支 buffer 机制后，当 TM network 内存足够时，如果处理一条数据需要 5 个 buffer，则 UC 完全不会卡住。如果 TM 的 network 内存比较多，可以调大参数兼容更多的场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Flink-1.16 开始支持透支 buffer 的功能，涉及到的 JIRA 有：&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-27522&quot; data-linktype=&quot;2&quot;&gt;FLINK-27522&lt;/a&gt;、&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-26762&quot; data-linktype=&quot;2&quot;&gt;FLINK-26762&lt;/a&gt;、&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-27789&quot; data-linktype=&quot;2&quot;&gt;FLINK-27789&lt;/a&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 Legacy Source 的提升&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从数据的来源划分有两种 Task，SourceTask 和非 SourceTask：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;SourceTask 从外部组件读数据到 Flink Job 中，非 SourceTask 从 InputChannel 中读数据，数据来源于上游 Task。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;非 SourceTask 从 InputChannel 读数据之前会对 OutputBufferPool 进行检查，有空闲 buffer 才会读取。SourceTask 从外部组件读取数据前如果不检查 OutputBufferPool 是否有空闲 buffer，则 UC 会表现不佳。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Flink 有两种 Source，分别是 Legacy Source 和新 Source：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;新 Source 与 Task 的工作模式是拉的模式，即：Task 向 Source 拉数据，工作模式跟 InputChannel 类似，Task 会检查 OutputBufferPool 有空闲 buffer 后，再从 Source 中拉数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Legacy Source 是推的模式，即：Legacy Source 从外部组件读到数据后直接往下游发送，当 OutputBufferPool 没有空闲 buffer 时，Legacy Source 就会卡住，不能正常处理 UC。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，我们生产环境几乎所有 Flink job 仍在使用 Legacy Source，由于 Legacy Source 已经被 Flink 社区废弃不再维护，所以 Shopee 内部对常用的 Legacy Source 做了改进。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;改进思路与上述思路类似：Legacy Source 检查 OutputBufferPool 有空闲 buffer 后，再往下游发数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Flink 中最常用的 FlinkKafkaConsumer 其实就是 Legacy Source，所以业界很多 Flink 用户都仍在使用 Legacy Source。我们将内部改进版的 Legacy Source 分享到了 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-26759&quot; data-linktype=&quot;2&quot;&gt;FLINK-26759&lt;/a&gt;。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4. 大幅降低 UC 风险&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过上述优化，反压严重时 UC 在 Legacy Source 和消费一条数据需要多个 buffer 的场景也可以快速成功，已经达到了一些 Flink 用户的预期效果，但 UC 仍然达不到大规模生产的标准。主要在于 UC 相比 AC 会写 network buffer 到 Checkpoint 中，所以引入了一些额外风险：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;会写更多的文件到 HDFS，给 NameNode 造成额外压力；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据的 schema 升级以后，如果序列化不兼容，则数据无法恢复；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当算子之间的连接发生变化时，算子之间的 buffer 数据无法恢复（例如：从 rebalance 改为 forward）。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.1 无法顺利地从 AC 切换成 UC&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用户希望既可以规避这些风险，又可以享受 UC 带来的收益，所以 Flink 社区引入了 Aligned checkpoint timeout 机制，即：默认 Checkpoint 是 AC，如果 AC 在指定时间内不能完成，则切换成 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;引入 AC timeout 机制后，UC 的风险并没有完全规避，只是在任务没有反压的情况下，仍然是 AC，不存在额外的风险。当反压严重 AC 会失败时，切换成 UC 来保证 Checkpoint 可以成功。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们假设 &lt;code&gt;AC timeout = 1min&lt;/code&gt; 且 &lt;code&gt;Checkpoint timeout = 5min&lt;/code&gt;，即：Checkpoint 仍然以 AC 开始，AC 一分钟不能成功则切换成 UC，Checkpoint 总时长超过 5 分钟就会超时失败。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;AC timeout 的发展总共有三个阶段，前两个阶段并达不到预期目标，即：1 分钟时间到了，Job 仍然不能从 AC 切换为 UC，甚至 5 分钟都不能切换成 UC 最终导致 Checkpoint 超时失败。我们可以带着目标去了解这三个阶段。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2 InputChannel 支持从 AC 切换为 UC&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-19680&quot; data-linktype=&quot;2&quot;&gt;FLINK-19680&lt;/a&gt; 首次支持了 AC timeout 机制，第一阶段的原理是：每个 Task 从接收到第一个 Barrier 开始计时，如果 Task 内 AC Barrier 对齐时间超过 AC timeout，则当前 Task 从 AC 切换为 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该机制存在的问题是：当 Job 的 Task 数较多，从 Source 到 Sink 要经过 10 个 Task。假设 10 个 Task 内部 Barrier 对齐时间都是 59 秒，则所有 Task 都不会切换成 UC，但 10 个 Task 都需要对齐，Checkpoint 总时长至少需要 590 秒（大于 5 分钟），所以最终 Checkpoint 仍然超时失败。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于阶段一的问题，&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-23041&quot; data-linktype=&quot;2&quot;&gt;FLINK-23041&lt;/a&gt; 进行了改进，第二阶段的原理是：Barrier 中携带 Checkpoint 开始的时间戳，当 InputChannel 收到 Barrier 后，用当前系统时间减 Checkpoint 开始的时间表示 Checkpoint 已经过去多久了：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如果已经超过 1 分钟，直接切换成 UC；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果少于 1 分钟，则用 1 分钟减 AC 已经消耗的时间，表示希望多久以后切换成 UC。设定一个定时器，时间到了，就会切换成 UC。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阶段二相比阶段一，解决了多个 Task 时间累加的问题，只要 InputChannel 接收到 Barrier，在指定时间内 AC 没有完成，就可以定时将 AC 切换成 UC。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3 Output buffer 支持从 AC 切换为 UC&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阶段二完成后，可以认为 InputChannel 已经较好地支持了 AC 切换为 UC。但存在的问题也很明显，即：output buffer 不支持从 AC 切换为 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果任务反压严重，Barrier 在 output buffer 中排队，如果在 5 分钟内 Barrier 不能发送到下游 Task 的 InputChannel，则 Checkpoint 仍然会超时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于这个问题，Shopee 在 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-27251&quot; data-linktype=&quot;2&quot;&gt;FLINK-27251&lt;/a&gt; 和 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-28077&quot; data-linktype=&quot;2&quot;&gt;FLINK-28077&lt;/a&gt; 提出了支持 output buffer 从 AC 切换成 UC 的改进。设计思路是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如果开启了 UC 且当前是 AC，则发送 Barrier 到 output buffer 的尾部。但过一会 AC 可能需要转换为 UC，所以需要设定一个定时器。&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;188&quot; data-backw=&quot;537&quot; data-ratio=&quot;0.3501454898157129&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6CFK12ujCQuIDNOQgCKpAU4iau8FAYT0wOGMLFGrvz45X29KpKPjqEaJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3093&quot;/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果定时器时间到了 Barrier 还在 output buffer 中排队，则将 AC 转换为 UC：Barrier 超车到 output buffer 头部，且图中超越的浅蓝色 buffer 需要被快照写到 Checkpoint 中。&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;188&quot; data-backw=&quot;537&quot; data-ratio=&quot;0.3501454898157129&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6C96lf6KmcxWMjuWAlVACLOlu9yaFYia2KO4dxXKZNFZ3hZhfTxmQicOqA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3093&quot;/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;社区早期为 Checkpoint 设计了 Benchmark 用来评估 Checkpoint 的性能，如下图所示，该优化 merge 到 Flink master 分支后 &lt;a href=&quot;http://codespeed.dak8s.net:8000/timeline/#/?exe=1&amp;amp;ben=checkpointSingleInput.UNALIGNED_1&amp;amp;env=2&amp;amp;revs=1000&quot; data-linktype=&quot;2&quot;&gt;UC 的性能提升了 11 倍&lt;/a&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;246&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4248800295311923&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6C7Gw6VL5CRaghic3GiauriaalpPY1ysVibAa9W1YGicahpExH22ibRMr8oeqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2709&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;179&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.30970837947582136&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6C2Bozb7ia9GwnInoDvlcGbDRmHRVGqmmVYkISic1SiaTmVDTjQUUTjCe0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2709&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.4 UC 小文件合并&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开启 AC timeout 机制后，Flink 可以做到反压不严重时使用 AC，反压严重时顺利切换成 UC。大大降低了 UC 的额外风险，也可以在反压严重时享受 UC 带来的收益。但在大规模生产中，仍然有风险。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认 Flink 每个 Subtask 为 buffer 写一个文件，假设任务有 10 个 Task，每个 Task 并发为 1000，则 UC 可能会额外写 1 万个小文件。假设 Kafka 集群出现故障或瓶颈，大量 Flink Job 写 Kafka 慢，会导致大量 Flink 任务从 AC 切换成 UC。这种情况大量任务瞬间写数十万的小文件到 HDFS，可能导致 NameNode 雪崩。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决小文件问题，Shopee 在 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-26803&quot; data-linktype=&quot;2&quot;&gt;FLINK-26803&lt;/a&gt; 和 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-28474&quot; data-linktype=&quot;2&quot;&gt;FLINK-28474&lt;/a&gt; 中提出了合并 UC 小文件的改进。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优化思路：多个 Task 共享同一个文件。每个 Task 不再单独创建文件，而是向 CheckpointStreamManager 获取文件流。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CheckpointStreamManager 会为 n 个 Task 分配一个文件，默认 &lt;code&gt;channel-state.number-of-tasks-share-file=5&lt;/code&gt;，即：5 个 Task 共享一个 UC 文件，UC 文件个数就会减少 5 倍。多个 Task 同时写同一个文件会有线程安全问题，所以写文件时要对文件流进行加锁来保证多个 Task 串行写文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从生产经验上来看，大量的 UC 小文件在 1MB 以内，所以 20 个 Task 共享一个文件也是可以接受的。当然，如果 NN 压力非常小且 Flink Job 更追求写效率，可以设置该参数为 1，表示 Task 不共享 UC 文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当前 UC 小文件合并的功能我们还在给社区贡献中。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5 修复 network buffer 死锁&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Shopee 对 UC 相关的贡献还包括：在 &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-22946&quot; data-linktype=&quot;2&quot;&gt;FLINK-22946&lt;/a&gt; 中解决了回收 network buffer 时的死锁问题。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5. UC 在 Shopee 的生产实践和未来规划&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1 UC 生产实践&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了规避 UC 带来的额外风险，Shopee 内部将 &lt;code&gt;aligned-checkpoint-timeout&lt;/code&gt; 设置为 1 分钟，表示任务反压不严重，如果 AC 可以在 1 分钟以内完成，则使用 AC。当反压严重 AC 在 1 分钟以内不能完成时，才切换为 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Shopee Flink 平台的开发页面也增加了 UC 的开关，用户可以选择是否为作业开启 Unaligned Checkpoint，目前已有上百个 Flink 任务开启 UC，且目前使用 UC 的作业表现良好，反压时 UC 也可以成功。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;448&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.7746835443037975&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6Cc0P7D2ibBuVvyFMsWKTFSfBBG0DhXoVJZicw6n7BQFQib8cmTIe9UovRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1580&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2 UC 未来规划&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们会持续关注用户在 UC 上遇到的问题，待稳定运行数月后，可以考虑开启 AC timeout 的前提下为全量任务开启 UC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Shopee 内部版本对 Flink 调度和 network 内存模块有较大改动，可以精确计算 TM 需要的 network 内存，未来会为 UC overdraft buffer 预留单独的内存。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;strong&gt;本文作者&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Rui、Guichao，来自 Shopee Data Infrastructure 团队。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;strong&gt;团队简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Shopee Data Infrastructure 团队专注于为公司构建稳定、高效、安全、易用的大数据基础设施和平台。&lt;/p&gt;&lt;p&gt;我们的业务包括：实时数据链路支持，Kafka、Flink 的相关开发；HDFS、Spark 等 Hadoop 生态组件的开发和维护；Linux 操作系统的运维和大数据组件的运维；OLAP 组件、Presto、Druid、Trino、Elasticsearch、ClickHouse 的开发和业务支持；大数据平台系统、资源管理、任务调度等平台的开发。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;27&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.04722222222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6CHoGbmbWNenbW5lKb1hHoYFopV9bXmBC5N1cSicB0a8BLyddD5s44wVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2160&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkzMDE5MDgwMQ==&amp;amp;mid=2247489737&amp;amp;idx=1&amp;amp;sn=a6d94fa72cd9468414d651cf28e31021&amp;amp;chksm=c27f5c77f508d5610b282be4f692f55bedb9b987eb9e7d920bb8bec9041b2f062a9fbac45e34&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;110&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.19&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6CL6iaOnRy18S8nfKnDR0R8dic0DhkWhO5pB42x6LOzcvOb4ItrialuKqVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkzMDE5MDgwMQ==&amp;amp;mid=2247487619&amp;amp;idx=1&amp;amp;sn=14f0f9c067008642f0a3dc1f870b7e47&amp;amp;chksm=c27f543df508dd2bedca02e71ea318e75499e5b5e2665e19e7384c8cc8e5ee8b5630560aea09&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;110&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.19&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6C3Wys0H2zkwN7BPNfXqVWtAqU0brjVOl5HSkxz5r7TGRxmib6xoBZY7w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkzMDE5MDgwMQ==&amp;amp;mid=2247489295&amp;amp;idx=1&amp;amp;sn=2c88c13f9ddb799b49a7d7be18ac5d15&amp;amp;chksm=c27f53b1f508daa7886fce38f7446895cc1facb0a119c23cc46eace71e203eba8984645d55d6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;110&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.19&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06ST67hK6ayeianMyCXZ5X6C76sSyFiaRIjUxUVYVevTuiap6cPsYjpO8NsrcGia1m3goUVHqgSBfw5vw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/figure&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkzMDE5MDgwMQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/euN1ic17Jn06QOehJ8N23MsruOT4cvjbrbNia2W0CKMSSszTMW4Jtj03ia2gBMGb2W6kUOeNuhS8acRaU3Z3BNPbQ/0?wx_fmt=png&quot; data-nickname=&quot;Shopee技术团队&quot; data-alias=&quot;ShopeeTech&quot; data-signature=&quot;如何在海外多元、复杂场景下实践创新探索，解决技术难题？Shopee技术团队将与你一起探讨前沿技术思考与应用。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>