<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ae864b1e321b95e6f8865c904892706b</guid>
<title>搞微服务还用Spring Cloud？Istio好用到爆！</title>
<link>https://toutiao.io/k/7xgh9xy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.11849710982658959&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8b6Lib0A0eic09h7UM0oewibib4JBPLkw1Mvb2p6sOzeHRtSHexOpy15TTJxdbibwBu97iamYXeGnEAfibOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1038&quot;/&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkwOTIxNDQ3OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YRIaicYx5pzj5Cxwick8DamnOgbTJu96QTibKyHEDZt1815yOV1r27oZ6HgoYTEYWYLRz4jIV4iasHgg/0?wx_fmt=png&quot; data-nickname=&quot;dbaplus社群&quot; data-alias=&quot;dbaplus&quot; data-signature=&quot;围绕Database、BigData、AIOps的企业级专业社群。资深大咖、技术干货，每天精品原创文章推送，每周线上技术分享，每月线下技术沙龙，每季度Gdevops&amp;amp;DAMS行业大会.&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;过去，我们运维着“能做一切”的大型单体应用程序。这是一种将产品推向市场的很好的方式，因为刚开始我们也只需要让我们的第一个应用上线。而且我们总是可以回头再来改进它的。部署一个大应用总是比构建和部署多个小块要容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;184&quot; data-backw=&quot;434&quot; data-ratio=&quot;0.423963133640553&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpNTPlfuRWKA2q7R41lYvDlTYMkDYQ1vUJW4jGFeaDk3xmLkic9e49GBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;434&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;187&quot; data-backw=&quot;470&quot; data-ratio=&quot;0.3970276008492569&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpD9V6w3SUdHDibPxXcafQ3JOtSLUR9ZncX6Lico0g9VxPRmBcG9lNGcLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;471&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;186&quot; data-backw=&quot;481&quot; data-ratio=&quot;0.3866943866943867&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpOtDJrhO6AwgwIsYYWXJMn6W9icKErhzVlr9jrLV37bTic0NbGHbibkY3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;481&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式和集中式会配合使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在搭建网站的时候，为了及时响应用户的请求，尤其是高并发请求的时候，我们需要搭建分布式集群来处理请求。我们一个服务器的处理能力是有限的。如果用我们一台设备当作服务器，那么当并发量比较大的时候，同一时间达到上百的访问量。那服务器就宕机了。然后只能重启服务器，当出现高并发访问的时候，就又会宕机。所以我们需要更多的服务器来并行工作，处理用户的请求。那么问题来了，我们服务器运行的时候，怎么分发大量的请求给不同的服务器呢？一般会采用(1apache+nTomcat)或者服务器模式来分发并处理请求，或者采用nginx分发请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微服务是运行在自己的进程中的可独立部署的服务套件。他们通常使用 HTTP 资源进行通信，每个服务通常负责整个应用中的某一个单一的领域。在流行的电子商务目录例子中，你可以有一个商品条目服务，一个审核服务和一个评价服务，每个都只专注一个领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用这种方法让多语言服务（使用不同语言编写的服务）也成为可能，这样我们就可以让 Java/C++ 服务执行更多的计算密集型工作，让 Rails / Node.js 服务更多来支持前端应用等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微服务会成为大规模分布式应用的主流架构。任何复杂的工程问题都会归结为devide and conquer（分而治之），意思就是就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。微服务本质是对服务的拆分，与工程领域惯用的“分而治之”的思路是一致的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;Spring Cloud 与 K8S 对比&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;两个平台 Spring Cloud 和 Kubernetes 非常不同并且它们之间没有直接的相同特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;219&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.3847352024922118&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpgEzmiakGGag4TsaAMpBwyayxialKZcpcq2OhMEYAc4MMSXEFXia3XtlDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;642&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section label=&quot;Copyright © 2015 Yead All Rights Reserved.&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;两种架构处理了不同范围的MSA障碍，并且它们从根本上用了不同的方法。Spring Cloud方法是试图解决在JVM中每个MSA挑战，然而Kubernetes方法是试图让问题消失，为开发者在平台层解决。Spring Cloud在JVM中非常强大，Kubernetes管理那些JVM很强大。同样的，它就像一个自然发展，结合两种工具并且从两个项目中最好的部分受益。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;从上图可以看到，里面差不多一半关注点是和运维相关的。&lt;/span&gt;&lt;span&gt;这么看来，似乎拿spring cloud和kubernetes比较有点不公平，spring cloud只是一个开发框架，对于应用如何部署和调度是无能为力的，而kubernetes是一个运维平台。&lt;/span&gt;&lt;span&gt;也许用spring cloud+cloud foundry去和kubernetes比较才更加合理，但需要注意的是，即使加入了cloud foundry的paas能力，spring cloud仍然是“侵入式”的且语言相关，而kubernetes是“非侵入式”的且语言无关。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;Spring Cloud vs Istio&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;274&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.48314606741573035&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpCFS3agVQXMPrgBqGlgHrA97PSmAUdF1ndGNb5Ec6nxf1AoVzZYQemA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;979&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;这里面哪些内容是我们可以拿掉或者说基于 Service Mesh（以 Istio 为例）能力去做的？分析下来，可以替换的组件包括网关（gateway 或者 Zuul，由Ingress gateway 或者 egress 替换），熔断器（hystrix，由SideCar替换），注册中心（Eureka及Eureka client，由Polit，SideCar 替换），负责均衡（Ribbon，由SideCar 替换），链路跟踪及其客户端（Pinpoint 及 Pinpoint client，由 SideCar 及Mixer替换）。这是我们在 Spring Cloud 解析中需要完成的目标：即确定需要删除或者替换的支撑模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;603&quot; data-backw=&quot;400&quot; data-ratio=&quot;1.5075&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpjMPxCZmV2iaVPwdkbDkD8bDBB3sAzsVFDlBPticaJuiaTvXv1N28iaoyuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以说，spring cloud关注的功能是kubernetes的一个子集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看出，两边的解决方案都是比较完整的。kubernetes这边，在Istio还没出来以前，其实只能提供最基础的服务注册、服务发现能力（service只是一个4层的转发代理），istio出来以后，具有了相对完整的微服务能力。而spring cloud这边，除了发布、调度、自愈这些运维平台的功能，其他的功能也支持的比较全面。相对而言，云厂商会更喜欢kubernetes的方案，原因就是三个字：非侵入。平台能力与应用层的解耦，使得云厂商可以非常方便地升级、维护基础设施而不需要去关心应用的情况，这也是我比较看好service mesh这类技术前景的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;Spring Boot + K8S&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;如果不用 Spring Cloud，那就是使用 Spring Boot + K8S。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;426&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpSq8oCs79nX5ibk7osyseJhRqSvS2kIibywiaLiaKuU2wWgXsFicywjL620g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里就需要介绍一个项目，Spring Cloud Kubernetes，作用是把kubernetes中的服务模型映射到Spring Cloud的服务模型中，以使用Spring Cloud的那些原生sdk在kubernetes中实现服务治理。具体来说，就是把k8s中的services对应到Spring Cloud中的services，k8s中的endpoints对应到Spring Cloud的instances。这样通过标准的Spring Cloud api就可以对接k8的服务治理体系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;老实说，个人认为这个项目的意义并不是很大，毕竟都上k8s了，k8s本身已经有了比较完善的微服务能力（有注册中心、配置中心、负载均衡能力），应用之间直接可以互相调用，应用完全无感知，你再通过sdk去调用，有点多此一举的感觉。而且现在强调的是语言非侵入，Spring Cloud一个很大的限制是只支持java语言（甚至比较老的j2ee应用都不支持，只支持Spring Boot应用）。所以我个人感觉，这个项目，在具体业务服务层面，使用的范围非常有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;借助于Spring Cloud Kubernetes项目，zuul可以以一种无侵入的方式提供api网关的能力，应用完全不需要做任何改造，并且网关是可插拔的，将来可以用其他网关产品灵活替换，整体耦合程度非常低。得益于k8s的service能力，zuul甚至支持异构应用的接入，这是Spring Cloud体系所不具备的。而本身基于java开发，使得java程序员可以方便地基于zuul开发各种功能复杂的filter，而不需要去学习go或者openresty这样不太熟悉的语言。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://lupeier.com/post/cloud-native-api-gateway-part-2/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;Service Mesh的价值&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;无论是单体应用，还是分布式应用，都可以建立在Service Mesh上，mesh上的sidecar支撑了所有的上层应用，业务开发者无须关心底层构成，可以用Java，也可以用Go等语言完成自己的业务开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当微服务架构体系越来越复杂的时候，需要将“业务服务”和“基础设施”解耦，将一个微服务进程一分为二：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;167&quot; data-backw=&quot;557&quot; data-ratio=&quot;0.2998204667863555&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpWtWDDyXBB8kfa0WBff2xoG8icQIvCGIDBDic8g1HRlsgog0rUOqhDpQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;557&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么代理会叫sidecar proxy？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7157360406091371&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YttyMm1RYobCrefZ9uOnkpwWpuNd1kxIOZaXjHqAqTricLSgYvupicAw2PyMuXZhA0mE2dhZyT2m0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;394&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看了上图就容易懂了，biz和proxy相生相伴，就像摩托车(motor)与旁边的车厢(sidecar)。未来，sidecar和proxy就指微服务进程解耦成两个进程之后，提供基础能力的那个代理进程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Istio的理论概念是Service Mesh（服务网络），我们不必纠结于概念实际也是微服务的一种落地形式有点类似上面的SideCar模式，它的主要思想是关注点分离，即不像SpringCloud一样交给研发来做，也不集成到k8s中产生职责混乱，Istio是通过为服务配 Agent 代理来提供服务发现、负载均衡、限流、链路跟踪、鉴权等微服务治理手段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Istio开始就是与k8s结合设计的，Istio结合k8s可以牛逼的落地微服务架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;istio 超越 spring cloud和dubbo 等传统开发框架之处，就在于不仅仅带来了远超这些框架所能提供的功能，而且也不需要应用程序为此做大量的改动，开发人员也不必为上面的功能实现进行大量的知识储备。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但结论是不是 spring cloud 能做到的，k8s + istio 也能做到？甚至更好？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;85988&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&amp;gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&amp;gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;参考资料&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.kubernetes.org.cn/1057.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;服务迁移之路 | Spring Cloud向Service Mesh转变&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://juejin.im/post/5ce26e266fb9a07eb67d619f&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://dubbo.apache.org/zh-cn/blog/dubbo-mesh-service-mesh-exploring.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://juejin.im/post/5d0357a5e51d4577555508bf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Istio分层架构？80%的人有误解&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://juejin.im/post/5d035a82e51d4510727c8084&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Java web 服务器集群 session共享解决思路&lt;/span&gt; &lt;span&gt;https://blog.csdn.net/xupeng874395012/article/details/65634343&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大型网站架构常用解决方案&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.e-learn.cn/topic/225574&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.servicemesher.com/blog/201909-build-full-micro-service-platform-by-spring-boot-with-kubernetes/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.cnblogs.com/assion/p/11250062.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://skyao.io/talk/201709-istio-introduction/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spring Cloud会在不久的将来被其他架构取代吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;https://www.zhihu.com/question/333618617&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在java中，如果不用spring cloud，可以搭建出好用的微服务架构的系统吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.zhihu.com/question/268835717&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;JAVA大军，开始把目光从spring cloud转向k8s甚至k8s+istio了么？&lt;/span&gt;&lt;span&gt;https://www.zhihu.com/question/345497663&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;span&gt;作者丨sp42a&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;来源丨网址：https://blog.csdn.net/zhangxin09/article/details/105342762?spm=1001.2014.3001.5501&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;dbaplus社群欢迎广大技术人员投稿，投稿邮箱：&lt;/span&gt;&lt;span&gt;editor@dbaplus.cn&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;205&quot; data-backw=&quot;568&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;568&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;205&quot; data-ratio=&quot;0.5&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ufWcjcomw8ZWAfZRqpibYHWGYu5cO4sp6Zu8Tt0Yb6rlnTbj3rFnezCMpnW39FdYCg8ew3FkaTibzgcchBDe0ibkA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07734375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8Zf2jiaBBH3vdgfP4A2rem5YEAHYH074dc4GibhojA5B3lLZrXLDRciaVnficveaHcAUCiaIPoDsTkAduA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>423b4da30482b0c0e5fe20cf490e6f5c</guid>
<title>聊聊分布式锁</title>
<link>https://toutiao.io/k/n11nix6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么我们需要一把分布式锁？&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为了效率(efficiency)，协调各个客户端避免做重复的工作。即使锁偶尔失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。比如重复发送了一封同样的 email（当然这取决于业务应用的容忍度）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为了正确性(correctness)。在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致(inconsistency)，数据丢失，文件损坏，订单重复，超卖或者其它严重的问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;分布式锁的三个属性&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;互斥（Mutual Exclusion），&lt;/strong&gt;这是锁最基本的功能，同一时刻只能有一个客户端持有锁；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;避免死锁（Dead lock free），&lt;/strong&gt;如果某个客户端获得锁之后花了太长时间处理，或者客户端发生了故障，锁无法释放会导致整个处理流程无法进行下去，所以要避免死锁。最常见的是通过设置一个 &lt;strong&gt;TTL(Time To Live，存活时间) 来避免死锁。&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;容错（Fault tolerance），&lt;/strong&gt;为避免单点故障，锁服务需要具有一定容错性。大体有两种容错方式，&lt;strong&gt;一种是锁服务本身是一个集群，&lt;/strong&gt;能够自动故障切换(ZooKeeper、etcd)；&lt;strong&gt;另一种是客户端向多个独立的锁服务发起请求，其中某个锁服务故障时仍然可以从其他锁服务读取到锁信息(Redlock)，代价是一个客户端要获取多把锁，&lt;/strong&gt;并且要求每台机器的时钟都是一样的，否则 TTL 会不一致，可能有的机器会提前释放锁，有的机器会太晚释放锁，导致出现问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;常见的分布式锁实现方案&lt;/h2&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;基于 Redis 的分布式锁&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;错误的加锁：非原子操作&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 Redis 的分布式锁，我们首先想到的是 setnx 命令，SET if Not Exists：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;SETNX lockKey value
EXPIRE lockKey 30&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 jedis 的客户端代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; (jedis.setnx(lockKey, val) == 1) {&lt;br/&gt;    jedis.expire(lockKey, timeout);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然这两个命令和前面算法描述中的一个 SET 命令执行效果相同，但却不是原子的。如果客户端在执行完 SETNX 后崩溃了，那么就没有机会执行 EXPIRE 了，导致它一直持有这个锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;加锁&lt;/strong&gt;和&lt;strong&gt;设置超时&lt;/strong&gt;两个操作是分开的，并非原子操作。假设加锁成功，但是设置锁超时失败，那么该 lockKey 永不失效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题 1：为什么这个锁必须要设置一个过期时间？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当一个客户端获取锁成功之后，假如它崩溃了，或者它忘记释放锁，或者由于发生了网络分割（network partition）导致它再也无法和 Redis 节点通信了，那么它就会一直持有这个锁，而其它客户端永远无法获得锁了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题 2：这个锁的有效时间设置多长比较合适？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面这个算法中出现的锁的有效时间(lock validity time)，设置成多少合适呢？如果设置太短的话，锁就有可能在客户端完成对于共享资源的访问之前过期，从而失去保护；如果设置太长的话，一旦某个持有锁的客户端释放锁失败，那么就会导致所有其它客户端都无法获取锁，从而长时间内无法正常工作。看来真是个&lt;strong&gt;两难的问题。&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;正确的加锁姿势&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 客户端为了&lt;strong&gt;获取锁，&lt;/strong&gt;向 Redis 节点发送如下命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;  SET lockKey requestId NX PX 30000&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;lockKey 是加锁的锁名；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;requestId 是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的；（下面会分析它的作用）&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;NX 表示只有当 lockKey 对应的 key 值不存在的时候才能 SET 成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PX 30000 设置过期时间，表示这个锁有一个 30 秒的自动过期时间。当然，这里 30 秒只是一个例子，客户端可以选择合适的过期时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Java 中使用 jedis 包的调用方法是：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;String result = jedis.set(lockKey, requestId, &lt;span&gt;&quot;NX&quot;&lt;/span&gt;, &lt;span&gt;&quot;PX&quot;&lt;/span&gt;, expireTime)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题：为什么要设置一个随机字符串 requestId？如果没有会出现什么问题？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面释放锁的时候给出答案。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;依赖 Redis 超时自动释放锁的问题&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果按照如下方式加锁：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;String result = jedis.set(lockKey, requestId, &lt;span&gt;&quot;NX&quot;&lt;/span&gt;, &lt;span&gt;&quot;PX&quot;&lt;/span&gt;, expireTime);&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; (&lt;span&gt;&quot;OK&quot;&lt;/span&gt;.equals(result)) {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加锁之后，每次都会到 &lt;strong&gt;expireTime&lt;/strong&gt; 之后才会释放锁，哪怕业务使用完这把锁了。所以更合理的做法是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;加锁；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;业务操作；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;主动释放锁；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果主动释放锁失败了，则达到超时时间，Redis 自动释放锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9036697247706422&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW51ZbJxYAb4ubHcF2y9ofoK6iaMILcggicaaDM6OdCjXo3MjyawnTwJiaNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1090&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何释放锁呢？Java 代码里在 finally 中释放锁，即无论代码执行成功或者失败，都要释放锁。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;try{&lt;br/&gt;    String result = jedis.set(lockKey, requestId, &lt;span&gt;&quot;NX&quot;&lt;/span&gt;, &lt;span&gt;&quot;PX&quot;&lt;/span&gt;, expireTime);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;&quot;OK&quot;&lt;/span&gt;.equals(result)) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;} finally {&lt;br/&gt;    unlock(lockKey);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;释放了别人的锁&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面那个 unlock(lockKey)代码释放锁有什么问题？&lt;strong&gt;可能会出现释放别人的锁的问题。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有的同学可能会反驳：线程 A 获取了锁之后，它要是没有释放锁，这个时候别的线程假如线程 B、C……根本不可能获取到锁，何来释放别人锁之说？&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5446780551905388&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW53SVdwDTYXSxNiaSLx97MDRGxPaqrDfVFfibQ6gAPqia8GLn3eAUSDRaUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1522&quot;/&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 获取锁成功。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 在某个操作上阻塞了很长时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;过期时间到了，锁自动释放了。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 2 获取到了对应同一个资源的锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 从阻塞中恢复过来，释放掉了客户端 2 持有的锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;另外线程客户端 3 此时可以成功请求到锁&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何解决这个问题：&lt;strong&gt;自己只能释放自己加的锁，不允许释放别人加的锁！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面使用 set 命令加锁的时候，除了使用 lockKey 锁标识之外，还使用了一个 requestId，这个 requestId 的作用是什么呢？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;requestId 是在释放锁的时候用的！！！&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;伪代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; (jedis.get(lockKey).equals(requestId)) {&lt;br/&gt;    jedis.del(lockKey);&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以在释放锁的时候，先要获取到该锁的值（就是每个加锁线程自己设置的 requestId），然后判断跟之前自己设置的值是否相同，如果相同才允许删除锁，返回成功，如果不同，直接返回失败。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题：为什么要设置一个随机字符串 requestId？如果没有会出现什么问题？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;设置一个随机字符串 requestId 是必要的，它保证了一个客户端释放的锁必须是自己持有的那个锁。假如获取锁时 SET 的不是一个随机字符串，而是一个固定值，那么可能导致释放别人的锁。所以要保证 requestId 全局唯一。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;释放锁的问题：非原子操作&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; (jedis.get(lockKey).equals(requestId)) {&lt;br/&gt;    jedis.del(lockKey);&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;显然，jedis.get(lockKey).equals(requestId) 这行代码包含了【获取该锁的值】，【判断是否是自己加的锁】，【删除锁】这三个操作，万一这三个操作中间的某个时刻出现阻塞&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4372523117569353&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW51Al8wrMpo4dquJESibwBqRG2tg6WGX6B3QDc4ar545ib6diaUnjjz6Elg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1514&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 获取锁成功；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 进行业务操作；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 为了释放锁，先执行’GET’操作获取随机字符串的值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 判断随机字符串的值，与预期的值相等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 由于某个原因阻塞住了很长时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;过期时间到了，锁自动释放了。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 2 获取到了对应同一个资源的锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 从阻塞中恢复过来，执行 DEL 操纵，释放掉了客户端 2 持有的锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上，如果不是客户端 1 阻塞住了，而是出现了大的网络延迟，也有可能导致类似的执行序列发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;问题的根源：&lt;strong&gt;锁的判断在客户端，但是锁的删除却在服务端！&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;正确的释放锁姿势&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正确的释放锁姿势——锁的判断和删除都在服务端（Redis），使用 lua 脚本保证原子性：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;  &lt;span&gt;if&lt;/span&gt; redis.call(&lt;span&gt;&quot;get&quot;&lt;/span&gt;,KEYS[1]) == ARGV[1] &lt;span&gt;then&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; redis.call(&lt;span&gt;&quot;del&quot;&lt;/span&gt;,KEYS[1])&lt;br/&gt;  &lt;span&gt;else&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; 0&lt;br/&gt;  end&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这段 Lua 脚本在执行的时候要把前面的 requestId 作为 ARGV[1]的值传进去，把 lockKey 作为 KEYS[1]的值传进去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;释放锁的操作为什么要使用 lua 脚本？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;释放锁其实包含三步操作：&lt;strong&gt;‘&lt;/strong&gt;&lt;strong&gt;GET’、判断和‘DEL’，用 Lua 脚本来实现能保证这三步的原子性。&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;锁超时问题&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果客户端 1 请求锁成功了，但是由于业务处理、GC、操作系统等原因导致它处理时间过长，超过了锁的时间，这时候 Redis 会自动释放锁，这种情况可能导致问题：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4830564784053156&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5E5TqYicgict3z3V7Iib1TfmTnOSMbqhjhoIeCvnd4iaI7SwSS7lZpWGO4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1505&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何解决这种问题？---- &lt;strong&gt;续期，&lt;/strong&gt;&lt;span&gt;J&lt;/span&gt;ava 里我们可以使用 TimerTask 类来实现自动续期的功能，伪代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;Timer timer = new Timer();&lt;br/&gt;timer.schedule(new &lt;span&gt;&lt;span&gt;TimerTask&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public void run(Timeout timeout) throws Exception {&lt;br/&gt;        //自动续期逻辑􁛔􀛖􁖅􀹗􁭦􁬋&lt;br/&gt;    }&lt;br/&gt;}, 10000, TimeUnit.MILLISECONDS);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个机制在 Redisson 框架中已经实现，而且还有一个比较霸气的名字 watchdog（看门狗）：加锁时没有指定加锁时间时会启用 watchdog 机制，默认加锁 30 秒，每 10 秒钟检查一次，如果存在就重新设置 过期时间为 30 秒（即 30 秒之后它就不再续期了）&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;lockWatchdogTimeout（监控锁的看门狗超时，单位：毫秒）&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;默认值：&lt;strong&gt;30000&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;监控锁的看门狗超时时间单位为毫秒。该参数只适用于分布式锁的加锁请求中未明确使用 leaseTimeout 参数的情况。如果该看门狗未使用 lockWatchdogTimeout 去重新调整一个分布式锁的 lockWatchdogTimeout 超时，那么这个锁将变为失效状态。这个参数可以用来避免由 Redisson 客户端节点宕机或其他原因造成死锁的情况。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4343891402714932&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW58SS4kSx3ic3mZqffMbosXDqm0ASCo9jdo7nl5z3tmOxscGALAYtvGzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1768&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Redis 主从架构数据同步复制问题&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们通常使用「Redis Cluster」或者「哨兵模式」这两种方式实现 Redis 的高可用，而这两种方式都是基于「主从架构数据同步复制」实现的，而 Redis 默认的主从复制是&lt;strong&gt;异步&lt;/strong&gt;的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面铺垫的 Redis 锁在单点实例中是没有问题的，因为并没有涉及 Redis 的高可用部署架构细节。但是如果多实例的情况下会出现什么问题呢？比如：主从、或者使用了哨兵模式、或者 Redis cluster。Redis 的主从架构如下所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7589803012746235&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5az54nNYzAyiczQrW6YDWddxqrVQWqDPibG6Y3A11l8toGaRAUkYgdjAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;863&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 所有的写操作都是先在 Master 上操作，然后同步更新到 Slave 上，Slave 只能读不能写。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;丢失数据场景：当网络发生脑裂（split-brain）或者 partitioned cluster 集群分裂为多数派与少数派，如果数据继续写入少数派的 Master，则当 Cluster 感知，并停止少数派 Master，或者重新选主时，则面临丢失刚才已写入少数派的数据&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主从发生重新选导致分布式锁出现问题的场景：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1535087719298245&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5Xzbribmf8Nc2MFqu3ZPCMicVZWjgtRmlpVjibZ1USmIFDFm43foGBZL6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;912&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;WAIT 命令能够为 Redis 实现强一致吗？&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WAIT numreplicas timeout&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;numreplicas：&lt;/strong&gt;指定副本（slave）的数量。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;timeout：&lt;/strong&gt;超时时间，时间单位为毫秒；当设置为 0 时，表示无限等待，即用不超时。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WAIT 命令作用：WAIT 命令阻塞当前客户端，直到所有先前的写入命令成功传输，并且由至少指定数量的副本（slave）确认。在主从、sentinel 和 Redis 群集故障转移中， WAIT 能够&lt;strong&gt;增强（仅仅是增强，但不是保证）&lt;/strong&gt;数据的安全性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;官方文档：&lt;span&gt;https://redis.io/commands/wait&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1053540587219344&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5JsqdiaJP8JjXFx2clzRFDQZmd9N1icPyqfdFWiahUyW89Or1FDsriayvsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1158&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;结论：WAIT 不能保证 Redis 的强一致性&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Redlock 算法&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对上面的问题，Redis 之父 antirez 设计了 Redlock 算法，Redlock 的算法描述就放在 Redis 的官网上：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;https://redis.io/topics/distlock&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Redlock 之前，很多人对于分布式锁的实现都是基于单个 Redis 节点的。而 Redlock 是基于多个 Redis 节点（都是 Master）的一种实现。前面基于单 Redis 节点的算法是 Redlock 的基础。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;加锁&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redlock 算法基于 N 个&lt;strong&gt;完全独立&lt;/strong&gt;的 Redis 节点，客户端依次执行下面各个步骤，来完成&lt;strong&gt;获取锁&lt;/strong&gt;的操作：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;获取当前时间 T1（毫秒数）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;使用相同的 key、value 按顺序依次向 N 个 Redis 节点执行获取锁的操作。这个获取操作跟前面基于单 Redis 节点的获取锁的过程相同，包含随机字符串 my_random_value，也包含过期时间(比如 PX 30000，即锁的有效时间)。为了保证在某个 Redis 节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个 Redis 节点获取锁失败以后，应该立即尝试下一个 Redis 节点。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;获取当前时间 T2 减去步骤 1 中的 T1，计算获取锁消耗了多长时间（T3= T2-T1），计算方法是用当前时间减去第 1 步记录的时间。如果客户端从大多数 Redis 节点（大于等于 N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第 3 步计算出来的获取锁消耗的时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果最终获取锁失败了（可能由于获取到锁的 Redis 节点个数少于 N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有 Redis 节点发起释放锁的操作（即前面介绍的 Redis Lua 脚本）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5627397260273973&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5UeGHQjapzNd5buoy91K7Sr1CApXrANmngHSWNbLVU34QJGpiaQoaIHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1825&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意！！！redLock 会直接连接多个 Redis 主节点，不是通过集群机制连接的。&lt;/p&gt;&lt;p&gt;RedLock 的写与主从集群无关，&lt;strong&gt;直接操作的是所有主节点，&lt;/strong&gt;所以才能避开主从故障切换时锁丢失的问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;失败重试（脑裂问题）&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高并发场景下，当多个加锁线程并发抢锁时，可能导致脑裂，最终造成任何一个线程都无法抢到锁的情况。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7944066515495087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5Mq05Fic38RCxrVicktkyVjftQr9yUaslUhE11IFmZxPtQSnSpg33X1YQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1323&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以当一个加锁线程无法获得锁的时候，应该在一个&lt;strong&gt;随机延时后&lt;/strong&gt;再一次尝试获得锁。加锁线程从多数 Redis 实例中获得锁越快，出现脑裂的窗口越小（重试的次数也越少）。所以理想情况下，加锁线程应该多路复用地同时向 N 个实例发送加锁命令。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;值得强调的是，如果获取大部分锁失败，加锁线程应该&lt;strong&gt;尽可能快&lt;/strong&gt;的释放（部分）已经获得了的锁。所以为了让锁能够再次被获得就没有必要等待 key 过期（然而如果发生了网络分区导致客户端无法再与 Redis 实例交互，那么就必须等待 key 过期才能重新抢到锁）。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;释放锁&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redlock 算法释放锁的过程比较简单：客户端向所有 Redis 节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题 1：为什么要在多个实例上加锁？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本质上为了&lt;strong&gt;容错，&lt;/strong&gt;部分实例异常宕机，剩余实例只要超过 N/2+1 依旧可用。多个实例节点，实际上构建了一个分布式锁系统。分布式系统中，总会有异常节点，所以需要考虑异常节点达到多少个，也不会影响整个系统的正确性。（可以参考一下拜占庭将军问题的分析）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题 2：为什么步骤 3 加锁成功之后，还要计算加锁的累计耗时？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为加锁操作的针对的是分布式中的多个节点，所以耗时肯定是比单个实例耗时更久，至少需要 N/2+1 个网络来回，还要考虑网络延迟、丢包、超时等情况发生，网络请求次数越多，异常的概率越大。所以即使 N/2+1 个节点加锁成功，但如果加锁的累计耗时已经超过了锁的过期时间，那么此时的锁已经没有意义了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题 3：为什么释放锁，要操作所有节点，对所有节点都释放锁？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为当对某一个 Redis 节点加锁时，可能因为网络原因导致加锁“失败”。注意这个“失败”，指的是 Redis 节点实际已经加锁成功了，但是返回的结果因为网络延迟并没有传到加锁的线程，被加锁线程丢弃了，加锁线程误以为没有成功，于是加锁线程去尝试下一个节点了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以释放锁的时候，不管以前有没有加锁成功，都要释放所有节点的锁，以保证清除节点上述图中发生的情况导致残留的锁。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;崩溃恢复（AOF 持久化）对 Redlock 算法影响&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设 Rodlock 算法中的 Redis 发生了崩溃-恢复，那么锁的安全性将无法保证。假设加锁线程在 5 个实例中对其中 3 个加锁成功，获得了这把分布式锁，这个时候 3 个实例中有一个实例被重启了。重启后的实例将丢失其中的锁信息，这个时候另一个加锁线程可以对这个实例加锁成功，此时两个线程同时持有分布式锁。锁的安全性被破坏。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1237993596584845&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5IpGm3QcXJicATh4E4PKMVcet6cXfVE96ib04CKmCO5SHb0fDsw8OpOvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;937&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们配置了 AOF 持久化，&lt;strong&gt;只能减少它发生的概率而无法保证锁的绝对安全。&lt;/strong&gt;断电的场景下，如果 Redis 被配置了默认每秒同步数据到硬盘，重启之后 lockKey 可能会丢失，理论上，如果我们想要保证任何实例重启的情况下锁都是安全的，需要在持久化配置中设置&lt;code&gt;fsync=always&lt;/code&gt;，但此时 Redis 的性能将大大打折扣。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了保证这一点，我们只需要让一个崩溃时间、不可用时间（实例崩溃后存在的锁的所有 key 所需的时间）比最大 TTL 还要长的实例变成非法和自动释放的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不配置 Redis 持久化，那么只能使用&lt;strong&gt;延迟重启&lt;/strong&gt;保证锁的安全性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;结论：为了保证 Redlock 算法的安全性，有如下两种手段&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;持久化配置中设置&lt;/span&gt;&lt;code&gt;&lt;span&gt;fsync=always&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，性能大大降低&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;恰当的运维，把崩溃节点进行延迟重启，超过崩溃前所有锁的 TTL 时间之后才加入 Redlock 节点组&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Redis 分布式锁官方文档翻译&lt;span/&gt;&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;4.664335664335664&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5Q4SGaRcfQjicEfJZVchaQhn1icBWW1kHf7rGnJcVuaic4dwkx9ajnYiaibA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1430&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Redlock 算法存在的问题&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Redlock 论战：Martin Kleppmann vs. Antirez&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Martin Kleppmann 是剑桥大学的分布式系统专家，《数据密集型应用系统设计》一书的作者。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Antirez 是 redis 的作者，redlock 算法的作者。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 之父 Antirez 实现 Redlock 算法之后。有一天，Martin Kleppmann 写了一篇 blog，分析了 Redlock 在安全性上存在的一些问题。然后 Redis 的作者立即写了一篇 blog 来反驳 Martin 的分析。但 Martin 表示仍然坚持原来的观点。随后，这个问题在 Twitter 和 Hacker News 上引发了激烈的讨论，很多分布式系统的专家都参与其中。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7747572815533981&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5MFC4DaGyOdn8HsNKW91I0XNc9nX7QibQbTaGOXcXSWLc21xPthb0GSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1030&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.828125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5xWQZDicXEMUE0WW4QGhuMVZ6Dv70fL3ho8JFsElbboqMw2rBa6xsCKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5328125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5rlxKLuCjnrWvhocml6BjrH7s3RxCq1tw9ThxlNdu3ibjoKmHn6dTBtA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;https://redis.io/topics/distlock&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://antirez.com/news/101&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Martin Kleppmann 在 2016-02-08 这一天发表了一篇 blog，名字叫“How to do distributed locking”，地址如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Martin 在这篇文章中谈及了分布式系统的很多基础性的问题（特别是分布式计算的异步模型），对分布式系统的从业者来说非常值得一读。这篇文章大体可以分为两大部分：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;前半部分，与 Redlock 无关。Martin 指出，即使我们拥有一个完美实现的分布式锁（带自动过期功能），在没有共享资源参与进来提供某种 fencing 机制的前提下，我们仍然不可能获得足够的安全性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;后半部分，是对 Redlock 本身的批评。Martin 指出，由于 Redlock 本质上是建立在一个同步模型之上，对系统的记时假设(timing assumption)有很强的要求，因此本身的安全性是不够的。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;客户端长期阻塞导致锁过期&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们讨论一下前半部分的关键点。Martin 给出了下面这样一份时序图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.36363636363636365&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5ibhy5wiaqKfK5RtcqvWuRZKxn5yVbTUP6OtMfQ7JOyqy0Qu4Eq8DF1hA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1100&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上面的时序图中，假设锁服务本身是没有问题的，它总是能保证任一时刻最多只有一个客户端获得锁。上图中出现的 lease 这个词可以暂且认为就等同于一个带有自动过期功能的锁。客户端 1 在获得锁之后发生了很长时间的 GC pause，在此期间，它获得的锁过期了，而客户端 2 获得了锁。当客户端 1 从 GC pause 中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时&lt;strong&gt;锁实际上被客户端 2 持有，&lt;/strong&gt;因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;初看上去，有人可能会说，既然客户端 1 从 GC pause 中恢复过来以后不知道自己持有的锁已经过期了，那么它可以在访问共享资源之前先判断一下锁是否过期。但仔细想想，这丝毫也没有帮助。因为 GC pause 可能发生在任意时刻，也许恰好在判断完之后。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也有人会说，如果客户端使用没有 GC 的语言来实现，是不是就没有这个问题呢？Martin 指出，系统环境太复杂，仍然有很多原因导致进程的 pause，比如虚存造成的缺页故障(page fault)，再比如 CPU 资源的竞争。即使不考虑进程 pause 的情况，网络延迟也仍然会造成类似的结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结起来就是说，即使锁服务本身是没有问题的，而仅仅是客户端有长时间的 pause 或网络延迟，仍然会造成两个客户端同时访问共享资源的冲突情况发生。而这种情况其实就是我们在前面已经提出来的“&lt;strong&gt;客户端长期阻塞导致锁过期&lt;/strong&gt;”的那个疑问。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;解决方案——fencing token&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那怎么解决这个问题呢？Martin 给出了一种方法，称为 fencing token。fencing token 是一个&lt;strong&gt;单调递增的数字，&lt;/strong&gt;当客户端成功获取锁的时候它随同锁一起返回给客户端。而客户端访问共享资源的时候带着这个 fencing token，这样提供共享资源的服务就能根据它进行检查，拒绝掉延迟到来的访问请求（避免了冲突）。如下图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.36363636363636365&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5ZWlia8Ht8QuHJU7yPiaMPFhrwic7JdkM8q75LkiatJcNxxUTLQO4qzrpCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1100&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上图中，客户端 1 先获取到的锁，因此有一个较小的 fencing token，等于 33，而客户端 2 后获取到的锁，有一个较大的 fencing token，等于 34。客户端 1 从 GC pause 中恢复过来之后，依然是向存储服务发送访问请求，但是带了 fencing token = 33。存储服务发现它之前已经处理过 34 的请求，所以会拒绝掉这次 33 的请求。这样就避免了冲突。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（&lt;strong&gt;问题：考虑网络延迟导致 33 号 token 比 34 号先到的情景&lt;/strong&gt;）&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;时间跳跃&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Martin 在文中构造了一些事件序列，能够让 Redlock 失效（两个客户端同时持有锁）。为了说明 Redlock 对系统记时(timing)的过分依赖，他首先给出了下面的一个例子（还是假设有 5 个 Redis 节点 A, B, C, D, E）：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 从 Redis 节点 A, B, C 成功获取了锁（多数节点）。由于网络问题，与 D 和 E 通信失败。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;节点 C 上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 2 从 Redis 节点 C, D, E 成功获取了同一个资源的锁（多数节点）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 和客户端 2 现在都认为自己持有了锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面这种情况之所以有可能发生，本质上是因为&lt;strong&gt;Redlock 的安全性(safety property)对系统的时钟有比较强的依赖，一旦系统的时钟变得不准确，&lt;/strong&gt;算法的安全性也就保证不了了。Martin 在这里其实是要指出分布式算法研究中的一些基础性问题，或者说一些常识问题，即好的分布式算法应该基于异步模型(asynchronous model)，算法的安全性不应该依赖于任何记时假设(timing assumption)。在异步模型中：进程可能 pause 任意长的时间，消息可能在网络中延迟任意长的时间，甚至丢失，系统时钟也可能以任意方式出错。&lt;strong&gt;一个好的分布式算法，这些因素不应该影响它的安全性(safety property)，只可能影响到它的活性(liveness property)，&lt;/strong&gt;也就是说，即使在非常极端的情况下（比如系统时钟严重错误），算法顶多是不能在&lt;strong&gt;有限的时间内给出结果而已，而不应该给出错误的结果。&lt;/strong&gt;这样的算法在现实中是存在的，像比较著名的&lt;strong&gt;Paxos，或 Raft。&lt;/strong&gt;但显然按这个标准的话，Redlock 的安全性级别是达不到的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Martin 的这篇文章中，还有一个很有见地的观点，就是对锁的用途的区分。他把锁的用途分为两种：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为了效率(efficiency)，协调各个客户端避免做重复的工作。即使锁偶尔失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。比如重复发送了一封同样的 email。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为了正确性(correctness)。在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致(inconsistency)，数据丢失，文件损坏，或者其它严重的问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，Martin 得出了如下的结论：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果是为了效率(efficiency)而使用分布式锁，允许锁的偶尔失效，那么使用单 Redis 节点的锁方案就足够了，简单而且效率高。Redlock 则是个过重的实现(heavyweight)。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果是为了正确性(correctness)在很严肃的场合使用分布式锁，那么不要使用 Redlock。它不是建立在异步模型上的一个足够强的算法，它对于系统模型的假设中包含很多危险的成分(对于 timing)。而且，它没有一个机制能够提供 fencing token。那应该使用什么技术呢？Martin 认为，应该考虑类似 Zookeeper 的方案，或者支持事务的数据库。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Martin 对 Redlock 算法的形容是：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;neither fish nor fowl （不伦不类）&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;【其它疑问】&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Martin 提出的 fencing token 的方案，需要对提供共享资源的服务进行修改，这在现实中可行吗？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;根据 Martin 的说法，看起来，如果资源服务器实现了 fencing token，它在分布式锁失效的情况下也仍然能保持资源的互斥访问。这是不是意味着分布式锁根本没有存在的意义了？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;资源服务器需要检查 fencing token 的大小，如果提供资源访问的服务也是包含多个节点的（分布式的），那么这里怎么检查才能保证 fencing token 在多个节点上是递增的呢？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Martin 对于 fencing token 的举例中，两个 fencing token 到达资源服务器的顺序颠倒了（小的 fencing token 后到了），这时资源服务器检查出了这一问题。如果客户端 1 和客户端 2 都发生了 GC pause，两个 fencing token 都延迟了，它们几乎同时到达了资源服务器，但保持了顺序，那么资源服务器是不是就检查不出问题了？这时对于资源的访问是不是就发生冲突了？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;问题一：节点重启&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;N 个 Redis 节点中如果有节点发生崩溃重启，会对锁的安全性有影响的。具体的影响程度跟 Redis 对数据的持久化程度有关。参考上面的&lt;strong&gt;“崩溃恢复（AOF 持久化）对 Redlock 算法影响”&lt;/strong&gt;分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;【备注】&lt;/span&gt;在默认情况下，Redis 的 AOF 持久化方式是每秒写一次磁盘（即执行 fsync），因此最坏情况下可能丢失 1 秒的数据。为了尽可能不丢数据，Redis 允许设置成每次修改数据都进行 fsync，但这会降低性能。当然，即使执行了 fsync 也仍然有可能丢失数据（这取决于系统而不是 Redis 的实现）。所以，上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何解决这个问题？&lt;/span&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 之父 antirez 提出了&lt;strong&gt;延迟重启&lt;/strong&gt;(delayed restarts)的概念。也就是说，&lt;strong&gt;一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。&lt;/strong&gt;这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1234375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5Z0P0iaPzicEFNvF4zicvQlbncc4Kkia5HMNRLZuW5JkLMmgiafpHxo85Sew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;问题二：时钟变迁&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redlock 的安全性(safety property)对系统的时钟有比较强的依赖，一旦系统的时钟变得不准确，算法的安全性也就保证不了了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;结论：Redis 的过期时间是依赖系统时钟的，如果时钟漂移过大时会影响到过期时间的计算。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么系统时钟会存在漂移呢？先简单说下系统时间，linux 提供了两个系统时间：clock realtime 和 clock monotonic&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;clock realtime 也就是 xtime/wall time，这个时间是可以被用户改变的，被 NTP 改变。Redis 的判断超时使用的 gettimeofday 函数取的就是这个时间，Redis 的过期计算用的也是这个时间。参考https://blog.habets.se/2010/09/gettimeofday-should-never-be-used-to-measure-time.html&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;clock monotonic，直译过来是单调时间，不会被用户改变，但是会被 NTP 改变。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最理想的情况是：所有系统的时钟都时时刻刻和 NTP 服务器保持同步，但这显然是不可能的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;clock realtime 可以被人为修改，在实现分布式锁时，不应该使用 clock realtime。不过很可惜，Redis 使用的就是这个时间，Redis 5.0 使用的还是 clock realtime。Antirez 说过后面会改成 clock monotonic 的。也就是说，人为修改 Redis 服务器的时间，就能让 Redis 出问题了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1543478260869566&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5cBXsTorsHM2cjuNsyn21sLYWjpoylNwJqGXqBiblkOe4hoXUIywEGtw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;920&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;加锁线程 1 从节点 Redis1, Redis2, Redis3 成功获取了锁（多数节点）。由于网络问题，与 Redis4、Redis5 通信失败。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;节点 Redis3 上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Redis5 成功获取了同一个资源的锁（多数节点）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;加锁线程 1 和加锁线程 2 现在都认为自己持有了锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;什么情况下会发生时钟变迁？&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;人为修改了时钟&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从 NTP 服务收到了一个大的时钟更新事件导致时钟漂移&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;闰秒（是指为保持协调世界时接近于世界时时刻，由国际计量局统一规定在年底或年中或者季末对协调世界时增加或减少 1 秒的调整，此时一分钟为 59 秒或者 61 秒，闰秒曾使许多大型系统崩溃）&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;……&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何解决这个问题？&lt;/span&gt;&lt;/h5&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Redis 之父 antirez 在 Redlock 论战中的解释：实际系统中是可以避免大的时钟跳跃的。当然，这取决于基础设施和运维方式。&lt;strong&gt;（实际上这种理想情况是很难达到的，不同的 redis 节点，毫秒级别的时间误差几乎是必然存在的。）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Fencing token 机制：类似 raft 算法、zab 协议中的全局递增数字，对这个 token 的校验需要后端资源进行校验，如此一来，相当于后端资源具备了互斥机制，这种情况下为什么还要一把分布式锁呢？而且涉及到后端资源的改造。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;RedLock 算法数建立在了 Time 是可信的模型上的一种分布式锁，所以时间被破坏的情况下它无法实现锁的绝对安全；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;RedLock 算法实现比较复杂，并且性能比较差；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;RedLock 需要恰当的运维保障它的正确性，故障-崩溃之后需要一套延迟重启的机制&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RedLock 的核心价值，在于&lt;strong&gt;多数派思想。&lt;/strong&gt;相比于基于单点 Redis 的锁服务，RedLock 解决了锁数据写入时多份的问题，从而可以克服单点故障下的数据一致性问题。在继承自基于单点的 Redis 锁服务缺陷（解锁不具备原子性；锁服务、调用方、资源方缺乏确认机制）的基础上，其核心的问题为：缺乏锁数据丢失的识别和感知机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RedLock 中的每台 Redis，充当的仍旧只是存储锁数据的功能，每台 Redis 之间各自独立，单台 Redis 缺乏全局的信息，自然也不知道自己的锁数据是否是完整的。在单台 Redis 数据的不完整的前提下，&lt;strong&gt;没有分布式共识机制，&lt;/strong&gt;使得在各种分布式环境的典型场景下（结点故障、网络丢包、网络乱序），没有完整数据但参与决策，从而破坏数据一致性。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;基于 MySQL 的分布式锁（ShedLock）&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 ShedLock 需要在 MySQL 数据库创建一张加锁用的表：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;CREATE TABLE shedlock&lt;br/&gt;(&lt;br/&gt;    name VARCHAR(64),&lt;br/&gt;    lock_until TIMESTAMP(3) NULL,&lt;br/&gt;    locked_at TIMESTAMP(3) NULL,&lt;br/&gt;    locked_by VARCHAR(255),&lt;br/&gt;    PRIMARY KEY (name)&lt;br/&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;加锁&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;通过插入同一个 name(primary key)，或者更新同一个 name 来抢，对应的 intsert、update 的 SQL 为：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;INSERT INTO shedlock&lt;br/&gt;(name, lock_until, locked_at, locked_by)&lt;br/&gt;VALUES&lt;br/&gt;(锁名字,  当前时间+最多锁多久,  当前时间, 主机名)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;UPDATE shedlock&lt;br/&gt;SET lock_until = 当前时间+最多锁多久,&lt;br/&gt;locked_at = 当前时间,&lt;br/&gt;locked_by = 主机名 WHERE name = 锁名字 AND lock_until &amp;lt;= 当前时间&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;释放锁：&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;通过设置 lock_until 来实现释放，再次抢锁的时候需要通过 lock_util 来判断锁失效了没。对应的 SQL 为：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;UPDATE shedlock&lt;br/&gt;SET lock_until = lockTime WHERE name = 锁名字&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;问题分析&lt;span/&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;单点问题；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;主从同步问题。假如使用全同步模式，分布式锁将会有性能上的问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;基于 ZooKeeper 的分布式锁&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ZooKeeper 的节点类型&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZooKeeper 的数据存储结构就像一棵树，这棵树由节点组成，这种节点叫做 Znode。Znode 分为四种类型：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;持久节点 （PERSISTENT）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认的节点类型。创建节点的客户端与 ZooKeeper 断开连接后，该节点依旧存在 。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;持久节点顺序节点（PERSISTENT_SEQUENTIAL）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所谓顺序节点，就是在创建节点时，ZooKeeper 根据创建的顺序给该节点名称进行编号：&lt;/p&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;临时节点（EPHEMERAL）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和持久节点相反，当创建节点的客户端与 ZooKeeper 断开连接后，临时节点会被删除：&lt;/p&gt;&lt;ol start=&quot;4&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;临时顺序节点（EPHEMERAL_SEQUENTIAL）&lt;/strong&gt;【使用该类型节点实现分布式锁】&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;顾名思义，临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，ZooKeeper 根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与 ZooKeeper 断开连接后，临时节点会被删除。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ZooKeeper 的 watch 机制&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZooKeeper 集群和客户端通过长连接维护一个 session，当客户端试图创建/lock 节点的时候，发现它已经存在了，这时候创建失败，但客户端不一定就此返回获取锁失败。客户端可以进入一种等待状态，等待当/lock 节点被删除的时候，ZooKeeper 通过 watch 机制通知它，这样它就可以继续完成创建操作（获取锁）。这可以让分布式锁在客户端用起来就像一个本地的锁一样：加锁失败就&lt;strong&gt;阻塞&lt;/strong&gt;住，直到获取到锁为止。这样的特性 Redis 的 Redlock 就无法实现。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8986988847583643&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5dibA75jo95EOGAXib5vvOBZjDQI3c0Co3vByDRZPicw1W4F9rv5INYx1A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1076&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;加锁&amp;amp;释放锁&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端尝试创建一个 znode 节点，比如/lock。那么第一个客户端就创建成功了，相当于拿到了锁；而其它的客户端会创建失败（znode 已存在），获取锁失败。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;持有锁的客户端访问共享资源完成后，将 znode 删掉，这样其它客户端接下来就能来获取锁了。&lt;strong&gt;（客户端删除锁）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;znode 应该被创建成 &lt;strong&gt;EPHEMERAL_SEQUENTIAL&lt;/strong&gt; 的。这是 znode 的一个特性，它保证如果&lt;strong&gt;创建 znode 的那个客户端崩溃了，那么相应的 znode 会被自动删除。&lt;/strong&gt;这保证了&lt;strong&gt;锁一定会被释放（ZooKeeper 服务器自己删除锁）。&lt;/strong&gt;另外保证了&lt;strong&gt;公平性，&lt;/strong&gt;后面创建的节点会加在节点链最后的位置，等待锁的客户端会按照先来先得的顺序获取到锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;762&quot; data-ratio=&quot;1.36484375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5XibVYyLLJqiam3OuVibJItFAAiak3vaiaRQklicZkykJibA1MyRTozPOouzqA/640?wx_fmt=jpeg&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;惊群效应：&lt;/strong&gt;错误的实现——如果实现 ZooKeeper 分布式锁的时候，所有后加入的节点都监听最小的节点。那么删除节点的时候，所有客户端都会被唤醒，这个时候由于通知的客户端很多，通知操作会造成 ZooKeeper 性能突然下降，这样会影响 ZooKeeper 的使用。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;时钟变迁问题&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZooKeeper 不依赖全局时间，它使用 zab 协议实现分布式共识算法，不存在该问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;超时导致锁失效问题&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZooKeeper 不依赖有效时间，它依靠心跳维持锁的占用状态，不存在该问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看起来这个锁相当完美，没有 Redlock 过期时间的问题，而且能在需要的时候让锁自动释放。但仔细考察的话，并不尽然。客户端可以删除锁，&lt;strong&gt;&lt;span&gt;Z&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;ooKeeper 服务器也可以删除锁，&lt;/strong&gt;会引发什么问题。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ZooKeeper 是怎么检测出某个客户端已经崩溃了呢？&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上，每个客户端都与 ZooKeeper 的某台服务器维护着一个 Session，这个 Session 依赖定期的心跳(heartbeat)来维持。如果 ZooKeeper 长时间收不到客户端的心跳（这个时间称为 Sesion 的过期时间），那么它就认为 Session 过期了，通过这个 Session 所创建的所有的 ephemeral 类型的 znode 节点都会被自动删除。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;基于 ZooKeeper 的分布式锁存在的问题：&lt;span/&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 创建了 znode 节点/lock，获得了锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 进入了长时间的 GC pause。（或者网络出现问题、或者 zk 服务检测心跳线程出现问题等等）&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 连接到 ZooKeeper 的 Session 过期了。znode 节点/lock 被自动删除。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 2 创建了 znode 节点/lock，从而获得了锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端 1 从 GC pause 中恢复过来，它仍然认为自己持有锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个场景下，客户端 1 和客户端 2 在一段窗口时间内同时获取到锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;结论：使用 ZooKeeper 的&lt;strong&gt;临时节点实现&lt;/strong&gt;的分布式锁，它的锁安全期是在客户端取得锁之后到 &lt;strong&gt;zk 服务器会话超时的阈值（跨机房部署很容易出现）&lt;/strong&gt;的时间之间。它无法设置占用分布式锁的时间，&lt;strong&gt;何时 zk 服务器会删除锁是不可预知的，&lt;/strong&gt;所以这种方式它比较适合一些客户端获取到锁之后能够快速处理完毕的场景。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;另一种方案&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外一种使用 zk 作分布式锁的实现方式：不使用临时节点，而是使用持久节点加锁，把 zk 集群当做一个 MySQL、或者一个单机版的 Redis，加锁的时候存储锁的到期时间，这种方案把&lt;strong&gt;锁的删除、判断过期&lt;/strong&gt;这两个职责交给客户端处理。（当做一个可以容错的 MySQL，性能问题！）&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ZooKeeper 分布式锁的优点和缺点&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结一下 ZooKeeper 分布式锁：&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;优点：&lt;span/&gt;&lt;/h4&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;ZooKeeper 分布式锁基于分布式一致性算法实现，能有效的解决分布式问题，不受时钟变迁影响，不可重入问题，使用起来也较为简单；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;当锁持有方发生异常的时候，它和 ZooKeeper 之间的 session 无法维护。ZooKeeper 会在 Session 租约到期后，自动删除该 Client 持有的锁，以避免锁长时间无法释放而导致死锁。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;缺点：&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZooKeeper 实现的分布式锁，性能并不太高。为啥呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为每次在创建锁和释放锁的过程中，都要&lt;strong&gt;动态创建、销毁瞬时节点&lt;/strong&gt;来实现锁功能。大家知道，ZK 中创建和删除节点只能通过 Leader 服务器来执行，然后 Leader 服务器还需要将数据同步不到所有的 Follower 机器上，这样频繁的网络通信，性能的短板是非常突出的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之，在高性能，高并发的场景下，不建议使用 ZooKeeper 的分布式锁。而由于 ZooKeeper 的高可用特性，所以在并发量不是太高的场景，推荐使用 ZooKeeper 的分布式锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;小结一下，基于 ZooKeeper 的锁和基于 Redis 的锁相比在实现特性上有两个不同：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在正常情况下，客户端可以持有锁任意长的时间，这可以确保它做完所有需要的资源访问操作之后再释放锁。这避免了基于 Redis 的锁对于有效时间(lock validity time)到底设置多长的两难问题。实际上，基于 ZooKeeper 的锁是依靠 Session（心跳）来维持锁的持有状态的，而 Redis 不支持 Sesion。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 ZooKeeper 的锁支持在获取锁失败之后等待锁重新释放的事件。这让客户端对锁的使用更加灵活。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Chubby&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提到分布式锁，就不能不提 Google 的 Chubby。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Chubby 是 Google 内部使用的分布式锁服务，有点类似于 ZooKeeper，但也存在很多差异。Chubby 对外公开的资料，主要是一篇论文，叫做“The Chubby lock service for loosely-coupled distributed systems”，下载地址如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;https://research.google.com/archive/chubby.html&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，YouTube 上有一个的讲 Chubby 的 talk，也很不错，播放地址：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;https://www.youtube.com/watch?v=PqItueBaiRg&amp;amp;feature=youtu.be&amp;amp;t=487
Chubby &lt;span&gt;自然也考虑到了延迟造成的锁失效的问题。论文里有一段描述如下：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;a process holding a lock L may issue a request R, but then fail. Another process may ac- quire L and perform some action before R arrives at its destination. If R later arrives, it may be acted on without the protection of L, and potentially on inconsistent data.&lt;/p&gt;&lt;p&gt;（译文：一个进程持有锁 L，发起了请求 R，但是请求失败了。另一个进程获得了锁 L 并在请求 R 到达目的方之前执行了一些动作。如果后来请求 R 到达了，它就有可能在没有锁 L 保护的情况下进行操作，带来数据不一致的潜在风险。）&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这跟前面 Martin 的分析大同小异。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6140625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5ibQUJGib3uETv8ZVtqflQla2EKZDBY0fia1VPFQwsfAaNW9CtcEdicevAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38828125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5EcwYhllQOiaX5MUx8S2oZIuoRSA2CrW5Dm3wiaBcLVm2J8f1Lmc8DhXzRTFhxFU8Cic1GGY4lFMick0YGSvD6OGPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Chubby 给出的用于解决（&lt;strong&gt;缓解&lt;/strong&gt;）这一问题的机制称为 sequencer，类似于 fencing token 机制。锁的持有者可以随时请求一个 sequencer，这是一个字节串，它由三部分组成：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;锁的名字。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;锁的获取模式（排他锁还是共享锁）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;lock generation number（一个 64bit 的单调递增数字）。作用相当于 fencing token 或 epoch number。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;sequencer：&lt;/strong&gt;客户端拿到 sequencer 之后，在操作资源的时候把它传给资源服务器。然后，资源服务器负责对 sequencer 的有效性进行检查。检查可以有两种方式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;调用 Chubby 提供的 API，CheckSequencer()，将整个 sequencer 传进去进行检查。这个检查是为了保证客户端持有的锁在进行资源访问的时候仍然有效。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将客户端传来的 sequencer 与资源服务器当前观察到的&lt;strong&gt;最新的 sequencer 进行对比检查。&lt;/strong&gt;可以理解为与 Martin 描述的对于 fencing token 的检查类似。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;锁延期机制：&lt;/strong&gt;当然，如果由于兼容的原因，资源服务本身不容易修改，那么 Chubby 还提供了一种机制：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;lock-delay。Chubby 允许客户端为持有的锁指定一个 lock-delay 的时间值（默认是 1 分钟）。当 Chubby 发现客户端&lt;strong&gt;被动失去联系&lt;/strong&gt;的时候，并不会立即释放锁，而是会在 lock-delay 指定的时间内阻止其它客户端获得这个锁。这是为了在把锁分配给新的客户端之前，让之前持有锁的客户端有充分的时间把请求队列排空(draining the queue)，尽量防止出现延迟到达的未处理请求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可见，为了应对锁失效问题，Chubby 提供的两种处理方式：CheckSequencer()检查与上次最新的 sequencer 对比、lock-delay，它们对于安全性的保证是从强到弱的。而且，&lt;strong&gt;这些处理方式本身都没有保证提供绝对的正确性(correctness)。&lt;/strong&gt;但是，Chubby 确实提供了单调递增的 lock generation number，这就允许资源服务器在需要的时候，利用它提供更强的安全性保障。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结起来，Chubby 引入了资源方和锁服务的验证，来避免了锁服务本身孤立地做预防死锁机制而导致的破坏锁安全性的风险。同时依靠 Session 来维持锁的持有状态，在正常情况下，客户端可以持有锁任意长的时间，这可以确保它做完所有需要的资源访问操作之后再释放锁。这避免了基于 Redis 的锁对于有效时间(lock validity time)到底设置多长的两难问题。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 ZooKeeper 的分布式锁，适用于高可靠（高可用）而并发量不是太大的场景；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 Redis 的分布式锁，适用于并发量很大、性能要求很高的、而可靠性问题可以通过其他方案去弥补的场景。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 MySQL 的分布式锁一般均有单点问题，高并发场景下对数据库的压力比较大；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;需要考虑的问题：&lt;/strong&gt;我们的业务对极端情况的容忍度，为了一把绝对安全的分布式锁导致过度设计，引入的复杂性和得到的收益是否值得。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6d44eaf0b3f1bf087daac3e50cdf0ecc</guid>
<title>阿里云Elasticsearch日志场景最佳实践及引擎内核优化</title>
<link>https://toutiao.io/k/9q34zj7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;145&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;274&quot; data-ratio=&quot;0.25&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPhm0926ffJFbE0JcibbZGBJ2XqbfChW05V5icYqtHnIqJaPF8A04Y6WxwM21G6sXtS3PZApxVI2cp7A/640?wx_fmt=jpeg&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;322&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.47148148148148145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYfEK2VGW2P11WicLEoxJ7NxF3lVcHPHR086untzMO2H2ko1ZnWSs4juQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; title=&quot;截屏2022-05-12 22.58.28.png&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-style=&quot;margin-bottom: -10px; margin-left: -8px; max-width: 100%; width: 18px; height: 18px; border-top: 8px solid rgb(54, 65, 173); border-left: 8px solid rgb(54, 65, 173); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-bgopacity=&quot;50%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot; data-style=&quot;max-width: 100%; width: 543.333px; background: rgb(247, 247, 247); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;p&gt;&lt;span&gt;分享嘉宾：&lt;/span&gt;&lt;span&gt;郭嘉梁 阿里巴巴 技术专家&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;出品平台：DataFunTalk&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-style=&quot;max-width: 100%; width: 18px; height: 18px; border-bottom: 8px solid rgb(54, 65, 173); border-right: 8px solid rgb(54, 65, 173); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;导读：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;全文将围绕以下四点展开：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;阿里云Elasticsearch日志场景最佳实践&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;阿里云Elasticsearch引擎内核优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;阿里云Elasticsearch性能评测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;阿里云Elasticsearch产品演示&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section data-type=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;阿里云Elasticsearch日志场景最佳实践&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 阿里云Elasticsearch日志场景概况&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿里云Elasticsearch（简称ES）在线上拥有1W+的集群和6W+节点，为用户提供线上检索和分析服务，在这些集群中，日志集群占比35%，其平均CPU核数超过40个，数据量达到PB级别。日志集群具有数量多、单集群规模大的特点，覆盖包括游戏、医药、汽车等领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 日志场景集群特点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在进行引擎内核优化之前，首先需要了解日志场景集群的共性特点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;写入吞吐高&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在线头部用户的单日写入吞吐量可达数十TB级。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;查询秒级响应&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：日志场景集群通常会作为微服务的问题排查，或监控数据的大盘展示，因此查询端的响应是否及时，直接影响用户端的体验。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;存储数据量大&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：日志场景集群的单日写入量大，数据存储周期长。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;倾向访问近期数据&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;376&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.65&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYR2qhicdQ7k37GW96ErtTdjjdiaicnbQHaNGIGU4E0a5W4Sme5QYLnGvpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 日志场景自建集群的痛点：性价比低&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;贵&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：写入吞吐高，存储时间长，导致计算资源和存储资源成本高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;慢&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：数据量大，导致扩容/宕机恢复慢, 数据迁移慢。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;差&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：冷/热查询没有隔离机制，导致稳定性差。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;难&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：索引多，生命周期不同，导致冷/热数据迁移难管理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. 日志场景最佳实践大图&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上痛点，ES日志场景进行了诸多&lt;strong&gt;优化&lt;/strong&gt;，主要包含以下五个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;283&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.48984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYUnfKGjSHjtEdfTMsnBqxb6o9FyeAmgMkshBSFnP70VTtktWsf5KKmw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5. 日志场景最佳实践成果&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES日志场景最佳实践，为用户提供了高性价比的服务，主要体现在四个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①高稳定：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②低成本：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能海量存储引擎让存储成本降低70%。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;冷热共享计算资源技术让计算成本降低50%。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;③高易用：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;④高可用：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;阿里云Elasticsearch引擎内核优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 共享冷/热计算资源&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;407&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.70390625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYgZibQeR7uKuZJoPfib4yz2vPx8Ceve1GkuSjY1a3sctHOSMEMsvwMiaGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 查询性能优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①冷存储（Lucene查询剖析）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能海量存储引擎的单次IO访问延迟可达到100毫秒以上，使用Lucene原生查询框架的端到端查询，对于这种延迟是无法接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Lucene查询模型分为四个步骤（见下图）：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据用户的查询语句进行倒排链求交，获取文档ID列表；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如用户有排序或聚合的需求，根据文档ID列表串行查询DocValue索引，获取文档ID对应的指定字段值；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对指定字段值进行排序和聚合操作；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如客户有召回原文的需求，则需要查询原文索引并返回原文。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;601&quot; data-backw=&quot;578&quot; data-ratio=&quot;1.03984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY4hzZoeKiaoiaurF2PIE3uMjraYDhvP5KeyXWmibpDt2MlQQXAich7kuAvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中第二步访问DocValue的随机查询，是导致查询延迟高的重点。假设用户召回100个文档ID，单次IO查询是100毫秒，那么100个文档的排序或聚合操作就有10秒的端到端查询延迟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②冷存储&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对上述查询延迟问题，对Lucene的原生执行模式进行了如下&lt;strong&gt;改造&lt;/strong&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;501&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.8671875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYeZXP3LZia4Sg0ydWEEJwoJYSbJ7gJOUvzOZfL1iaRzxG89a0iaCu58h7A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;③冷存储（智能缓存）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在查询模式基础上提供智能缓存机制，在智能海量存储引擎中加入SmartCache，对多种不同类型的索引采用自适应的淘汰策略，可以适配多种查询场景。比如针对DocValue索引采用了N-LRU的淘汰策略，防止一次对历史数据的分析型查询直接将DocValue的Cache刷满，导致淘汰一些有效数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;496&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.8578125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY0xCFL2Q9TXNkibE7DCtFuia2rM5UApbvgkz0wBA0FbA1NAN2ZsfibBiaFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3. 写入性能优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用Indexing Service中心化索引构建集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;402&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYVoyV2reE7bKZ5NfyicialZnjibhIzohPLCJmUoh4ezb9BQkic8k8TqasZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 计算存储分离&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;冷数据采用智能海量存储引擎的存储介质，属于共享存储，用户的写入只在主分片进行构建，所有副本节点都是加载共享存储中的数据，真正做到一写多读，以及计算和存储解耦。由于数据只存储一份，在节点扩容或节点宕机时，无需进行节点间的数据拷贝，彻底消除海量数据迁移的开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;349&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6037414965986394&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYVM2picvHtvxnbV2d1CI0B6eOicpIvqav2d3PU79dLZKtxeBR41vZc0qg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;588&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;阿里云Elasticsearch性能评测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 智能海量存储引擎查询性能评测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;①智能海量存储引擎成本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能海量存储引擎的存储单价是0.15元/GB/月，对比高效云盘的0.35元/GB/月，降低了60%；对比SSD的1元/GB/月，降低80%以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;504&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.871875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYEbicmESfk5XVserZt6qpacQU6gGjpv2ffNS2WKBFM5k8ia1uHhlB5e3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;②智能海量存储引擎查询延迟&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化后的智能海量存储引擎，对比高效云盘在查询延迟方面有显著降低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;489&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.84609375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY1Tfru3n7muokGsoPMJyYIB9uLoHibXlTMBBwhyefEXoATdh34Faav1A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能海量存储引擎与高效云盘查询延迟对比图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在智能海量存储引擎与高效云盘的查询延迟对比图中，查询数据级是1.5TB索引，在24个16C64GB节点进行测试，单位是毫秒，针对两种查询语句分别进行测试，一种是只有对时间字段的简单查询，一种是对指定字段有AGG聚合分析的分析型查询。测试结果表明，智能海量存储引擎的查询性能更好，查询延迟降低了30%左右。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上对比高效云盘，智能海量存储引擎的成本降低了60%，而总体查询性能提升了30%，智能海量存储引擎为用户提供了高性价比的存储介质选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. Indexing Service写入性能评测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对开启Indexing Service的集群和通用商业版集群进行写入TPS对比，对三种不同规格组（2C8GB、4C16GB、8C32GB）进行对比。对比结果显示：无论在哪个规格组，Indexing Service的写入性能比原生ES写入性能提高了7-10倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;323&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.559375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYDEQmI0hJIjXh82icuu6bb5BibiaQnvic05qGoEWOLIib4bKep1svb3cqmqQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;04&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;阿里云Elasticsearch产品演示&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 进入阿里云Elasticsearch产品控制台&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://elasticsearch.console.aliyun.com/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;279&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.48253968253968255&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYNniagD4wTe1pQuHdvbsEhGzI5spolkcsDqI1uOdjDfxZeUe7XePoPvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;945&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 创建Elasticsearch实例&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;182&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.3142857142857143&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY9KTXjTq0iaZezcqdymvP6EtGqb5LIEibz7hNibmKXialKTw4AuvrQ9nYVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;945&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 进入阿里云Elasticsearch购买页面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中有两种类型的集群供选择：通用商业版和日志增强版。日志增强版提供上面提到的针对日志场景的内核优化，如果用户需要存储日志数据，并希望享受阿里云提供的自研能力，可以选择日志增强版进行创建。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;284&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4910242872228089&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY5ia2AeebGfwqJjmfhwIODsuN3xvV1cZ25pxthFMKj8DJj0y4mMuctXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;947&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. 进行集群配置&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户可以选择实例所在区域和可用区。在实例规格栏可以看到提供的冷热共享资源规格组和智能海量存储引擎存储。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;283&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.48936170212765956&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYbBrsETGibHzYpdmgj95HgmOBbsEdbNkHzibMRclsgsSQKibEEOCZicmJGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;940&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5. 进入集群网络资源配置，选择专有网络和虚拟交换机&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;254&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.440084835630965&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY5jeA7yAobDEYFepleTgM4VDXaRO7nU74iaTGubYYI6EZhqW10ib59N0g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;943&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6. 设置集群实例名称、登录名称及密码&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;290&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5010615711252654&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYiaLu0YT8SbibP0pBsVcvpPSwaXW0wTerlx2MibmDDicb54bib6RSzLibsqEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;942&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7. 进入订单确认页面，注意要勾选服务协议&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;284&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.49208025343189016&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYM6tsIJ7sAMDq9iak8yABBdtXWt6mXK4WRtUG7b2yRqicXfOZlicXiaQhiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;947&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;8. 通过控制台的Kibana访问ES实例&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;164&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.28299894403379094&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY2iarwpnfJy2WqAVAzQTiaUicovbL2ZWSqLPj5DPejHfygw6pc2Ts8QWpg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;947&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. Kibana可视化控制默认公网无法访问，因此需要先配置公网的白名单入口&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;217&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3761854583772392&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYcZ8AnRs5X3lVadaaIKza7m3TjmFDYOlmfc4IeKa2ib2x4KM3zbqKKYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;949&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;配置公网访问的白名单IP：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;117&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.20277481323372465&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYJ9G3lzL1x7l0Ibq662xGLpcwibRAKMuJIEZiaia0iczukTD0KRY4Mjf6Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;937&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;10. 进入Kibana登录页面，输入集群的用户名和密码后进入Kibana控制台&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;324&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5598705501618123&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYahSrhFozuul2ZhW9fibS5vOysdX4aKQB3rft1AibPVU04icnGRXRU0ibDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;618&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;251&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.43414120126448896&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYqysje8DGh6ia0f6JALIQj3decoyb3ibobq21md7udVqPenemGf5SDHMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;949&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;11. 在Kibana开发工具中进行ES集群API访问，如访问集群元数据，创建索引，创建文档并插入数据，搜索数据等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;395&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6828046744574291&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYia0Oe7CSPyXLq2rxROnkhNriarp5aIaBuliaoDYfHgqtia8XHRAcMlBR0g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;599&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;207&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.35856992639327023&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYfU0u79auq70iaB7bIcoLHHvDPWSsyCD4jr5mJYRuQupBz6gGPDdU3QA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;951&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;240&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.41509433962264153&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYZJT3ae206s1AsQibfpjUZOdktSeIYUeXyWGf1MLAsiaxD2oDu4oKm1Tg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;795&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;239&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.41309823677581864&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYfV0HKMeIvgM2aK0GNIkf5HYC2UaXJN0wPiauJ4Jd10jvuPulwzhVFRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;794&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;240&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.41509433962264153&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPY6NlOhiahDuuTtOw288aNpEPEvGsRkNZjJBo9V8eiav5ecaHc0nQILmlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;795&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;12. 高级监控和报警功能。用户在高级监控页面可以看到集群层面和节点层面的监控信息，同时可以根据集群或节点的使用水位，配置相应的报警规则&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;326&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5640362225097024&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYWhQXHkd1BLibTU8vaBuXXmZhe7HeIicR02yqyU03QMbMdzQeOnJFWmoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;773&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;13. 日志数据查询&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为方便集群问题排查，系统提供了集群的日志展示，包括主日志、Searching慢日志、Indexing慢日志、GC日志和ES访问日志。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;245&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.42430703624733473&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYysAzNHxFLqesheso6DocvPcPSib0uUZybVgKJNOia6vKZHM8kBu9a0SQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;938&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户在搜索框输入自定义查询语句和指定时间范围，即可进行日志数据查询。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;273&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.47158403869407495&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYjsiaib7iarkaeL6p7b89QcX3MVV97QiaThPF9fdboEpvLcZ1w7ibybK9D4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;827&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上是Elasticsearch控制台中的案例体验Demo。欢迎大家到阿里云Elasticsearch平台进行实例体验。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;265&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4588607594936709&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjY0RSbOf4xuVMg7Up95ZPYevlDiashOWUIVzh0KiaPDJngJyQNEt11icAts4FibHJwWn5b4Ayvr9pF0g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;948&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;今天的分享就到这里，谢谢大家。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;在文末分享、点赞、在看，给个3连击呗~&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;&lt;span&gt;01&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;分享嘉宾&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;289&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjMBALia4B1bopnBbOBQHGtAaqHtc7K25PcAiarP8DGZDJqWMZawicqzxk5YKB0SG7EtJTo1UbvDEdMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;&lt;span&gt;02&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;免费下载资料&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;247&quot; data-backw=&quot;203&quot; data-ratio=&quot;0.47148148148148145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPhm0926ffJFbE0JcibbZGBJ2NAia8kZibLfm72wNQgORuADnaia908Mf4tOZJtnq0aHib17Jm3Z4rEuCuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; title=&quot;大数据专题书.png&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;报名看直播 免费领PPT&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;803&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;803&quot; data-ratio=&quot;1.3888888888888888&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPhm0926ffJFbE0JcibbZGBJ2KzNGMjOfwJZZ16AbLWYZZ37Eyu2nNRj19HNJGLL7NZayXibX6VU6YAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; title=&quot;文章尾部banner.png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;04&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;/&lt;/span&gt;&lt;/strong&gt;&lt;strong data-md5=&quot;9a9a0&quot;&gt;&lt;span&gt;关于我们&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;DataFun：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;专注于大数据、人工智能技术应用的分享与交流。发起于2017年，在北京、上海、深圳、杭州等城市举办超过100+线下和100+线上沙龙、论坛及峰会，已邀请超过2000位专家和学者参与分享。其公众号 DataFunTalk 累计生产原创文章700+，百万+阅读，14万+精准粉丝&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU1NTMyOTI4Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPh87SyjsEtoRFs9iaLyPXYh9ls0BcsiaPDnFkg72xgLsvku13ZRYibyq93DgRoCaTaTkbJj7Hia4dvI1w/0?wx_fmt=png&quot; data-nickname=&quot;DataFunTalk&quot; data-alias=&quot;datafuntalk&quot; data-signature=&quot;专注于大数据、人工智能技术应用的分享与交流。致力于成就百万数据科学家。定期组织技术分享直播，并整理大数据、推荐/搜索算法、广告算法、NLP 自然语言处理算法、智能风控、自动驾驶、机器学习/深度学习等技术应用文章。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;🧐 &lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;分享、点赞、在看&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，给个&lt;/span&gt;&lt;span&gt;&lt;strong&gt;3连击&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;呗&lt;/span&gt;&lt;/span&gt;&lt;span&gt;！&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;👇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e5939af41d5f842a1956265748522bc1</guid>
<title>Kafka学习笔记</title>
<link>https://toutiao.io/k/ruk1lvr</link>
<content:encoded>&lt;div&gt;&lt;body class=&quot;notion-body&quot; id=&quot;readabilityBody&quot;&gt;&lt;p id=&quot;notion-app&quot;/&gt;&lt;/body&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>df83bc98d90417d2e4f3f36cfca32e3a</guid>
<title>Go中的一些优化笔记，简约而不简单</title>
<link>https://toutiao.io/k/8gjzmtu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们这里简单聊一下优化本身，然后我们直接从实际的示例开始。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;为什么要优化呢？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你资源占有较高的话会需要很大的成本，虽然现在服务器资源也不是很贵，但是你还是需要针对的做一些优化工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外每个优化应该建立在一个&lt;strong&gt;benchmark&lt;/strong&gt;的基础上，需要体现它给我们带来多大的收益。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面主要从slice、string、struct、function、map、interface、channel、pointer等方面罗列了一些常见的优化点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;数组和slice优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;提前为slice分配内存&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尽量使用第三个参数：&lt;code&gt; make([]T, 0, len)&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你事先不知道确切的数量并且slice是临时的，你可以设置得大一些，只要slice在运行时不会增长。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;不要忘记使用“copy”&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们尽量不要在复制时使用 append，例如，在合并两个或多个slice时。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;正确地使用迭代&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们有一个包含很多元素或比较大的元素的slice，我们会尝试使用“for”或 range 单个元素。通过这种方法，可以避免不必要的复制。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;学会复用slice&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们需要对传入的slice进行某种操作并返回结果，我们可以直接return，但已经修改了。这样我们就可以避免了新的内存分配。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;不要留下未使用的slice&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们需要从slice中切下一小块并仅使用它，其实主要部分也会保留下来。可以使用copy产生一个新的slice，而旧的对象让GC回收。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;string-字符串优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;正确地进行拼接&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果拼接字符串可以在一个语句中完成，那么可以使用“+”，如果需要在循环中执行此操作，那么可以使用&lt;code&gt;string.Builder&lt;/code&gt;。通过“Grow”也可以预先指定&lt;code&gt;builder&lt;/code&gt;的大小。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;使用转换优化&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于字符串是由字节组成的，因此有时这两种类型之间的转换可以避免内存分配。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;使用池化技术&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以池化字符串，从而帮助编译器只存储一次相同的字符串。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;避免内存分配&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以使用map来替代复合键，我们也可以使用&lt;code&gt;[]byte&lt;/code&gt;。尽量不要使用&lt;code&gt;fmt&lt;/code&gt;包，因为它的所有函数都使用了反射。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;struct-结构体优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;避免复制大的struct&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们理解的小&lt;code&gt;struct&lt;/code&gt;，是指不超过 4 个字段的&lt;code&gt;struct&lt;/code&gt;，不超过一个&lt;em&gt;机器字&lt;/em&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;标准的copy案例&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;转换成interface&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;接收和发送到channel&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;替换map中的item&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;向slice添加元素&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;迭代（range）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;避免通过指针来访问struct中的字段&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解引用是比较昂贵的，我们可以尽量少做，尤其是在循环中。我们也会失去使用快速寄存器的能力。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;使用小型的struct&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这项工作由编译器优化的，这意味着它的工作量很小。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;通过内存对齐来减小struct大小&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以对齐struct（根据字段的大小，以正确的顺序排列），从而可以减小struct本身的大小。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;func-函数优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;使用内联函数或自己内联&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们尽量编写一些可供编译器内联的小函数——它很快，但自己从函数中嵌入代码则更快。&lt;strong&gt;对于热路径&lt;/strong&gt;函数尤其如此。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;什么情况下不会被内联？&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;recovery 函数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;select&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;类型声明&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;defer&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;goroutine&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;for-range&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;明智地选择你的函数参数&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们尽量使用“小”参数，因为它们的拷贝会被特别优化。我们也尝试在拷贝和GC的负载的与增长堆栈之间保持平衡。避免使用大量的参数——让你的程序使用超快速的寄存器（寄存器的数量是有限的）&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;声明一个命名好的return结果&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这似乎比在函数体中声明这些变量更高效。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;保存函数中间的结果&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;帮助编译器优化你的代码，保存中间结果，然后会有更多的选择来优化你的代码。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;谨慎使用“defer”&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尽量不要使用 &lt;code&gt;defer&lt;/code&gt;，或者至少 &lt;strong&gt;不要在循环中使用&lt;code&gt;defer&lt;/code&gt;&lt;/strong&gt; 。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;为“hot path”提供便利&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;避免在这些地方分配内存，尤其是短期对象。首先要检查的的就是最常见的分支（if，switch）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里 &lt;span&gt;hot path在Go源码中&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;也出现多次，根据&lt;span&gt;在 sync.Once 的上下文中，“hot path”是什么意思？&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;中的回答，这里翻译为热路径是非常频繁执行的指令序列。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;map优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;提前分配内存&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一切都和其他地方一样。初始化map时，指定其大小。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;使用空结构作为值&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;struct{}&lt;/code&gt;什么都不是，因此例如对信号值使用这种方法是非常有益的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;清空map&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;map只能增长，不能缩小。我们需要控制这一点——完全而明确地重置map。因为删除其所有元素无济于事。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;尽量不要在键和值中使用指针&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 map 不包含指针，那么 GC 就不会在它上面浪费宝贵的时间。而且要知道字符串也是指针——使用&lt;code&gt;[]byte&lt;/code&gt;而不是字符串作为键。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;减少更改的次数&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样，我们不想使用指针，但我们可以使用 map 和 slice 的复合体，并将键存储在 map 中，将可以不受限制地更改的值存储在slice中。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;interface优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;计算内存分配&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请记住，要给一个接口赋值，你首先需要将其拷贝到某处，然后粘贴一个指针。关键字是拷贝。事实证明，装箱和拆箱的成本将近似于结构体的大小和一次分配。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;选择最佳的类型&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在某些情况下，装箱/拆箱期间不会进行内存分配。例如，比较小的和布尔值的变量和常量、具有一个简单字段的struct、指针（包括&lt;em&gt;map、chan、func&lt;/em&gt;）&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;避免内存分配&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与其他地方一样，我们尽量避免不必要的内存分配。例如，将一个接口分配给一个接口，而不是装箱两次。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;仅在需要时使用&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;避免在小型、频繁调用的函数的参数和结果中使用接口。我们不需要额外的包装和拆包。减少使用接口方法调用的频率，哪怕只是因为它可以防止内联。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;指针、chan、BCE(Bounds Check Elimination-边界检查) 优化篇&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;避免不必要的解引用&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尤其是在循环中，因为事实证明它太昂贵了。解引用是我们不想以牺牲自己为代价执行的一系列必要操作。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;channel使用效率是低效的&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用channel会比其他同步方法慢。另外，select 中的 case 越多，我们的程序就越慢。但是&lt;em&gt;select、case + default&lt;/em&gt;是优化过了的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;尽量避免不必要的边界检查&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这也很昂贵，我们应该尽一切可能避免它。例如，一次检查（获取）最大slice索引比多次检查更正确。最好是立即尝试获得极端的选项。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这篇文章中，我们看到了一些相同的优化规则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;帮助编译器做出正确的决定。在编译时分配内存，使用中间结果，并尽量保持代码的可读性。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不要忘记使用内置的分析和trace跟踪工具。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后小土也祝你在优化的路上做到尽善尽美。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;Golang: simple optimization notes: &lt;em&gt;https://medium.com/scum-gazeta/golang-simple-optimization-notes-70bc64673980&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;hot path在Go源码中: &lt;em&gt;https://cs.opensource.google/search?q=%22hot%20path%22&amp;amp;ss=go%2Fgo&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;在 sync.Once 的上下文中，“hot path”是什么意思？: &lt;em&gt;https://stackoverflow.com/questions/59174176/what-does-hot-path-mean-in-the-context-of-sync-once&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>