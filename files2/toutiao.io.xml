<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>4ecc1d76f8f8cf60b8ee45e66a24c9ab</guid>
<title>复盘：如何更好的进行技术面试</title>
<link>https://toutiao.io/k/hkbzn4k</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6245704467353952&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWj8AjbfcbjaOic54pKhjNrL3hgymNicZ3pwsTicaVlZ22XODYz9fLcqlJ4XnkeG9IGgZSkOKeTaE08MA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2328&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近佛系找工作中，经历了几次面试，我本人之前做过多次面试官，面试过很多候选人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章，我想聊聊对于技术同学来说，如何更好的进行技术面试。内容仅代表个人观点，供参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;自我介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;面试的第一个环节，基本都是自我介绍，当然也有面试官会直奔主题。在自我介绍环节，需要明白如下三点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1-你是谁&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;span&gt;主要介绍自己的名字，毕业院校，专业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目的是让面试官快速了解你的个人信息，专业匹配和同院校或同地区上学，会有潜在的加分项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2-你的擅长的领域：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;span&gt;工作年限，某个行业或领域的造诣深度，之前工作中主要做哪些具体的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如：五年工作经验，之前主要做性能测试，在性能测试领域有丰富的实践经验，有全链路压测的落地实践经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3-企业为什么要录用你&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;span&gt;换个角度理解，就是“相比于其他竞争者你的优势在哪里”。举例如下：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3年技术团队管理经验(20人)，善于流程建设&amp;amp;人才培养&amp;amp;技术体系搭建；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对公司整体业务和系统架构有较为全面的了解，能独立解决复杂测试任务；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能与其他团队建立良好的合作关系，保持高效协同，能主导推动完成工作落地；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自驱能力强，持续学习，善于思考总结（后面可以附你的博客或者公众号链接）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有丰富的电商、供应链、支付等业务测试经验（&lt;/span&gt;&lt;strong&gt;&lt;span&gt;从后续你的项目经验中体现&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;专业知识&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;自我介绍环节之后，一般都是进入专业的技术知识面试环节。这个环节，问题一般集中于以下三方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1-通用基础概念&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对测试同学来说，可能会问到之前工作中的研发交付流程，比如：需求评审/工时评估/提测冒烟卡点/bug管理/质量度量等方面的知识。只要日常工作中稍加注意和总结，面试前准备一下就不会有太大问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2-针对性领域知识&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一部分&lt;/span&gt;&lt;strong&gt;&lt;span&gt;主要和候选人自己的工作实践以及面试岗位匹配度比较高&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。举例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3-具体的工程实践&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一部分，对&lt;/span&gt;&lt;strong&gt;&lt;span&gt;个人技术能力/沟通表达能力的要求最高，也隐含着对候选人思维逻辑能力和复盘总结能力的考察&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;我这段时间面试，在技术工程实践方面，主要问到了如下几个方面，都是和我的项目经验高度匹配的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;工程实践方面的问题，个人建议从如下几个方面展开回答：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目的背景是什么，当时面临哪些问题？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;问题如何评估分析，如何制定落地的技术方案？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;落地过程遇到了哪些挑战，当时是如何解决的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;项目上线后结果如何，有哪些收获，哪里做的不足？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;团队管理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;团队管理这方面，主要看个人是否有管理经验，以及面试的岗位是否有要求带团队。当然有时候面试官为了后续的工作规划，也会问到这方面的问题。下面列举几个我面试时候问到的团队管理方面的问题，供大家参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1-2人和20人的团队，分别如何管理？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2-作为团队Leader，在团队管理方面要注意哪些事项？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3-谈一谈你对OKR和KPI的理解，它们有哪些不足之处？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4-为团队打绩效，用OKR还是KPI？如何确保团队目标和执行落地保持一致？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;团队管理方面没有统一答案，更多的看个人的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有个坑，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;如果你的回答和面试官有较大的分歧，或者管理风格差别很大，很容易减分&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;当然，有坑也有个好处就是避免掉坑里。&lt;/span&gt;&lt;span&gt;如果遇到和自己管理方式差别很大的领导，即使入职了也是个煎熬的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;开放问题&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;这个环节因人而异，有些面试官会问到下面这些问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1-最近在读什么书，哪本书对你影响最大？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2-最近是否有学习某方面的技术，它有哪些特点，学习收获是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3-如何平衡工作和写公众号文章/参加技术沙龙（我本人遇掉坑里了）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4-假设你入职后让你负责某方面的业务/项目/团队，你打算如何做？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开放问题比较难回答，但我建议按照自己的想法回答，但要注意和面试官多沟通，秉持互相交流的方式会更好。&lt;/span&gt;&lt;span&gt;沟通交流时要注意这几点：&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;提问环节&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;好了，面试的最后环节一般都会让候选人来主动提问，下面是我会经常问的一些问题：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;请面试官点评我的面试表现，在哪些方面表现的不足，有什么建议；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;面试过程中遇到的技术盲点或者难点，请面试官给出提示或者答案；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;企业氛围/同事相处/遇到问题处理方式（前提是觉得面试感受双方都觉得不错）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，面试结束建议进行复盘，对遇到的问题，疑难点，表现好的不好的进行全面总结思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;复盘的过程是不断明确自身定位和认识自己的过程，也是个很好的提升自己的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-id=&quot;67311&quot; data-type=&quot;lspecial02&quot; data-tools=&quot;速排小蚂蚁编辑器&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile data-index=&quot;0&quot; data-id=&quot;Mzg2NDAwMjM1NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWhnnG3FnMGxk4tujZAJv8cPZibDbChbEzPK3FJD5aM9XFQQicu4Lu3L3eo5ldtz5Q63ctdpxhAD25rw/0?wx_fmt=png&amp;amp;wx_head=1&quot; data-nickname=&quot;老张的求知思考世界&quot; data-alias=&quot;Engineer_Way&quot; data-signature=&quot;专注互联网技术及相关领域，也分享职场成长、读书思考的内容。这是一个求知探索之人，在寻找更多可能性的旅途中的记录。&quot; data-origin_num=&quot;162&quot; data-is_biz_ban=&quot;0&quot; data-isban=&quot;0&quot; class=&quot;js_wx_tap_highlight&quot; data-from=&quot;2&quot; has-insert-preloading=&quot;1&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如果喜欢我文章，点赞、关注、在看三连走起。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如果想阅读更多的文章，可以关注我的公众号。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484399&amp;amp;idx=1&amp;amp;sn=976c9ac63a76a65e3ec7671af82765b2&amp;amp;chksm=ce714bb3f906c2a5f675e9f49929b919c69df92e8d5588a9eada95d2016e6674b324eb939c89&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;软件质量保障体系建设&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;strong&gt;&lt;span&gt;软件质量保障体系建设&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247485216&amp;amp;idx=1&amp;amp;sn=90c9049c58daae3b0df9188c87b36f12&amp;amp;chksm=ce714f7cf906c66a0377662f5a2caefe72ea0af8f8bc432ef60b36e7cf25b45f1f2898aa6839&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊我对质量度量的看法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;strong&gt;&lt;span&gt;聊聊我对质量度量的看法&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484975&amp;amp;idx=1&amp;amp;sn=254c19f9d5d94328e1d584b379bb8138&amp;amp;chksm=ce714e73f906c765ddc8242228f25aec791ebfc69e63f533e3a5cf2025c961b8c134ac8a17e8&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;如何建立高效的质量保障机制&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;strong&gt;&lt;span&gt;如何建立高效的质量保障机制&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484931&amp;amp;idx=1&amp;amp;sn=e215598ab61c56bf641549f3d68f4c5f&amp;amp;chksm=ce714e5ff906c7493b9b3691d6690f9ee4aef48de09fb3ca6deaae9be9242a07a8c415b38add&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;复盘归因，提高交付质量的秘诀&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;strong&gt;&lt;span&gt;复盘归因，提高交付质量的秘诀&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>aebf18c0cc938ae2e83074772983a573</guid>
<title>Redis 异步客户端选型及落地实践</title>
<link>https://toutiao.io/k/7uwb6h6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h4&gt;作者：京东科技 王晨&lt;/h4&gt;

&lt;h1&gt;Redis异步客户端选型及落地实践&lt;/h1&gt;

&lt;p&gt;可视化服务编排系统是能够通过线上可视化拖拽、配置的方式完成对接口的编排，可在线完成服务的调试、测试，实现业务需求的交付，详细内容可参考：&lt;a href=&quot;https://mp.weixin.qq.com/s/5oN9JqWN7n-4Zv6B9K8kWQ%E3%80%82&quot;&gt;https://mp.weixin.qq.com/s/5oN9JqWN7n-4Zv6B9K8kWQ。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;为了支持更加广泛的业务场景，可视化编排系统近期需要支持对缓存的操作功能，为保证编排系统的性能，服务的执行过程采用了异步的方式，因此我们考虑使用Redis的异步客户端来完成对缓存的操作。&lt;/p&gt;

&lt;h2&gt;Redis客户端&lt;/h2&gt;

&lt;h3&gt;Jedis/Lettuce&lt;/h3&gt;

&lt;p&gt;Redis官方推荐的Redis客户端有Jedis、Lettuce等等，其中Jedis 是老牌的 Redis 的 Java 实现客户端，提供了比较全面的 Redis 命令的支持，在spring-boot 1.x 默认使用Jedis。&lt;/p&gt;

&lt;p&gt;但是Jedis使用阻塞的 IO，且其方法调用都是同步的，程序流需要等到 sockets 处理完 IO 才能执行，不支持异步，在并发场景下，使用Jedis客户端会耗费较多的资源。&lt;/p&gt;

&lt;p&gt;此外，Jedis 客户端实例不是线程安全的，要想保证线程安全，必须要使用连接池，每个线程需要时从连接池取出连接实例，完成操作后或者遇到异常归还实例。当连接数随着业务不断上升时，对物理连接的消耗也会成为性能和稳定性的潜在风险点。因此在spring-boot 2.x中，redis客户端默认改用了Lettuce。&lt;/p&gt;

&lt;p&gt;我们可以看下 Spring Data Redis 帮助文档给出的对比表格，里面详细地记录了两个主流Redis客户端之间的差异。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c87340655018894435308642340140c43c5.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;异步客户端Lettuce&lt;/h3&gt;

&lt;p&gt;Spring Boot自2.0版本开始默认使用Lettuce作为Redis的客户端。Lettuce客户端基于Netty的NIO框架实现，对于大多数的Redis操作，只需要维持单一的连接即可高效支持业务端的并发请求 —— 这点与Jedis的连接池模式有很大不同。同时，Lettuce支持的特性更加全面，且其性能表现并不逊于，甚至优于Jedis。&lt;/p&gt;

&lt;p&gt;Netty是由JBOSS提供的一个java开源框架，现为 Github上的独立项目。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。&lt;/p&gt;

&lt;p&gt;也就是说，Netty 是一个基于NIO的客户、服务器端的编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户、服务端应用。Netty相当于简化和流线化了网络应用的编程开发过程，例如：基于TCP和UDP的socket服务开发。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4e13d32114e6b3cebff848e45fe2188c26d.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;上图展示了Netty NIO的核心逻辑。NIO通常被理解为non-blocking I/O的缩写，表示非阻塞I/O操作。图中Channel表示一个连接通道，用于承载连接管理及读写操作；EventLoop则是事件处理的核心抽象。一个EventLoop可以服务于多个Channel，但它只会与单一线程绑定。EventLoop中所有I/O事件和用户任务的处理都在该线程上进行；其中除了选择器Selector的事件监听动作外，对连接通道的读写操作均以非阻塞的方式进行 —— 这是NIO与BIO（blocking I/O，即阻塞式I/O）的重要区别，也是NIO模式性能优异的原因。&lt;/p&gt;

&lt;p&gt;Lettuce凭借单一连接就可以支持业务端的大部分并发需求，这依赖于以下几个因素的共同作用：&lt;/p&gt;

&lt;p&gt;1.Netty的单个EventLoop仅与单一线程绑定，业务端的并发请求均会被放入EventLoop的任务队列中，最终被该线程顺序处理。同时，Lettuce自身也会维护一个队列，当其通过EventLoop向Redis发送指令时，成功发送的指令会被放入该队列；当收到服务端的响应时，Lettuce又会以FIFO的方式从队列的头部取出对应的指令，进行后续处理。&lt;/p&gt;

&lt;p&gt;2.Redis服务端本身也是基于NIO模型，使用单一线程处理客户端请求。虽然Redis能同时维持成百上千个客户端连接，但是在某一时刻，某个客户端连接的请求均是被顺序处理及响应的。&lt;/p&gt;

&lt;p&gt;3.Redis客户端与服务端通过TCP协议连接，而TCP协议本身会保证数据传输的顺序性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1a84895cc63423612699ed2126523169255.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如此，Lettuce在保证请求处理顺序的基础上，天然地使用了&lt;strong&gt;管道模式&lt;/strong&gt;（pipelining）与Redis交互 —— 在多个业务线程并发请求的情况下，客户端不必等待服务端对当前请求的响应，即可在同一个连接上发出下一个请求。这在加速了Redis请求处理的同时，也高效地利用了TCP连接的全双工特性（full-duplex）。而与之相对的，在没有显式指定使用管道模式的情况下，Jedis只能在处理完某个Redis连接上当前请求的响应后，才能继续使用该连接发起下一个请求。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-dd5e45cc92614f05454db4ceabdd08e1cb8.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在并发场景下，业务系统短时间内可能会发出大量请求，在管道模式中，这些请求被统一发送至Redis服务端，待处理完成后统一返回，能够大大提升业务系统的运行效率，突破性能瓶颈。R2M采用了Redis Cluster模式，在通过Lettuce连接R2M之前，应该先对Redis Cluster模式有一定的了解。&lt;/p&gt;

&lt;h2&gt;Redis Cluster模式&lt;/h2&gt;

&lt;p&gt;在redis3.0之前，如果想搭建一个集群架构还是挺复杂的，就算是基于一些第三方的中间件搭建的集群总感觉有那么点差强人意，或者基于sentinel哨兵搭建的主从架构在高可用上表现又不是很好，尤其是当数据量越来越大，单纯主从结构无法满足对性能的需求时，矛盾便产生了。&lt;/p&gt;

&lt;p&gt;随着redis cluster的推出，这种海量数据+高并发+高可用的场景真正从根本上得到了有效的支持。&lt;/p&gt;

&lt;p&gt;cluster 模式是redis官方提供的集群模式，使用了Sharding 技术，不仅实现了高可用、读写分离、也实现了真正的分布式存储。&lt;/p&gt;

&lt;h3&gt;集群内部通信&lt;/h3&gt;

&lt;p&gt;在redis cluster集群内部通过gossip协议进行通信，集群元数据分散的存在于各个节点，通过gossip进行元数据的交换。&lt;/p&gt;

&lt;p&gt;不同于zookeeper分布式协调中间件，采用集中式的集群元数据存储。redis cluster采用分布式的元数据管理，优缺点还是比较明显的。在redis中集中式的元数据管理类似sentinel主从架构模式。集中式有点在于元数据更新实效性更高，但容错性不如分布式管理。gossip协议优点在于大大增强集群容错性。&lt;/p&gt;

&lt;p&gt;redis cluster集群中单节点一般配置两个端口，一个端口如6379对外提供api，另一个一般是加1w，比如16379进行节点间的元数据交换即用于gossip协议通讯。&lt;/p&gt;

&lt;p&gt;gossip协议包含多种消息，如ping pong，meet，fail等。&lt;/p&gt;

&lt;p&gt;1.meet：集群中节点通过向新加入节点发送meet消息，将新节点加入集群中。&lt;/p&gt;

&lt;p&gt;2.ping：节点间通过ping命令交换元数据。&lt;/p&gt;

&lt;p&gt;3.pong：响应ping。&lt;/p&gt;

&lt;p&gt;4.fail：某个节点主观认为某个节点宕机，会向其他节点发送fail消息，进行客观宕机判定。&lt;/p&gt;

&lt;h3&gt;分片和寻址算法&lt;/h3&gt;

&lt;p&gt;hash slot即hash槽。redis cluster采用的正式这种hash槽算法实现的寻址。在redis cluster中固定的存在16384个hash slot。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d27caaac98de2192a4c3bf4860b1b1651f0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，如果我们有三个节点，每个节点都是一主一从的主从结构。redis cluster初始化时会自动均分给每个节点16384个slot。当增加一个节点4，只需要将原来node1~node3节点部分slot上的数据迁移到节点4即可。在redis cluster中数据迁移并不会阻塞主进程。对性能影响是十分有限的。总结一句话就是hash slot算法有效的减少了当节点发生变化导致的数据漂移带来的性能开销。&lt;/p&gt;

&lt;h3&gt;集群高可用和主备切换&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;主观宕机和客观宕机：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;某个节点会周期性的向其他节点发送ping消息，当在一定时间内未收到pong消息会主观认为该节点宕机，即主观宕机。然后该节点向其他节点发送fail消息，其他超过半数节点也确认该节点宕机，即客观宕机。十分类似sentinel的sdown和odown。&lt;/p&gt;

&lt;p&gt;客观宕机确认后进入主备切换阶段及从节点选举。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;节点选举：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成 master。&lt;/p&gt;

&lt;p&gt;每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。&lt;/p&gt;

&lt;p&gt;所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。&lt;/p&gt;

&lt;p&gt;从节点执行主备切换，从节点切换为主节点。&lt;/p&gt;

&lt;h2&gt;Lettuce的使用&lt;/h2&gt;

&lt;h3&gt;建立连接&lt;/h3&gt;

&lt;p&gt;使用Lettuce大致分为以下三步：&lt;/p&gt;

&lt;p&gt;1.基于Redis连接信息创建RedisClient&lt;/p&gt;

&lt;p&gt;2.基于RedisClient创建StatefulRedisConnection&lt;/p&gt;

&lt;p&gt;3.从Connection中获取Command，基于Command执行Redis命令操作。&lt;/p&gt;

&lt;p&gt;由于Lettuce客户端提供了响应式、同步和异步三种命令，从Connection中获取Command时可以指定命令类型进行获取。&lt;/p&gt;

&lt;p&gt;在本地创建Redis Cluster集群，设置主从关系如下：&lt;/p&gt;

&lt;p&gt;7003(M) --&amp;gt; 7001(S)&lt;/p&gt;

&lt;p&gt;7004(M) --&amp;gt; 7002(S)&lt;/p&gt;

&lt;p&gt;7005(M) --&amp;gt; 7000(S)&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;List&amp;lt;RedisURI&amp;gt; servers = new ArrayList&amp;lt;&amp;gt;();
servers.add(RedisURI.create(&quot;127.0.0.1&quot;, 7000));
servers.add(RedisURI.create(&quot;127.0.0.1&quot;, 7001));
servers.add(RedisURI.create(&quot;127.0.0.1&quot;, 7002));
servers.add(RedisURI.create(&quot;127.0.0.1&quot;, 7003));
servers.add(RedisURI.create(&quot;127.0.0.1&quot;, 7004));
servers.add(RedisURI.create(&quot;127.0.0.1&quot;, 7005));
//创建客户端
RedisClusterClient client = RedisClusterClient.create(servers);
//创建连接
StatefulRedisClusterConnection&amp;lt;String, String&amp;gt; connection = client.connect();
//获取异步命令
RedisAdvancedClusterAsyncCommands&amp;lt;String, String&amp;gt; commands = connection.async();
//执行GET命令
RedisFuture&amp;lt;String&amp;gt; future = commands.get(&quot;test-lettuce-key&quot;);
try {
    String result = future.get();
    log.info(&quot;Get命令返回:{}&quot;, result);
} catch (Exception e) {
    log.error(&quot;Get命令执行异常&quot;, e);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到成功地获取到了值，由日志可以看出该请求发送到了7004所在的节点上，顺利拿到了对应的值并进行返回。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3340d12283421854c29ed7371c04b743a5e.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;作为一个需要长时间保持的客户端，保持其与集群之间连接的稳定性是至关重要的，那么集群在运行过程中会发生哪些特殊情况呢？作为客户端又应该如何应对呢？这就要引出智能客户端（smart client）这个概念了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;智能客户端&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Redis Cluster运行过程中，所有的数据不是永远固定地保存在某一个节点上的，比如遇到cluster扩容、节点宕机、数据迁移等情况时，都会导致集群的拓扑结构发生变化，此时作为客户端需要对这一类情况作出应对，来保证连接的稳定性以及服务的可用性。随着以上问题的出现，smart client这个概念逐渐走到了人们的视野中，智能客户端会在内部维护hash槽与节点的映射关系，大家耳熟能详的Jedis和Lettuce都属于smart client。客户端在发送请求时,会先根据CRC16(key)%16384计算key对应的hash槽,通过映射关系,本地就可实现键到节点的查找,从而保证IO效率的最大化。&lt;/p&gt;

&lt;p&gt;但如果出现故障转移或者hash槽迁移时,这个映射关系是如何维护的呢？&lt;/p&gt;

&lt;h3&gt;客户端重定向&lt;/h3&gt;

&lt;h4&gt;MOVED&lt;/h4&gt;

&lt;p&gt;当Redis集群发生数据迁移时，当对应的hash槽已经迁移到变的节点时，服务端会返回一个MOVED重定向错误，此时并告诉客户端这个hash槽迁移后的节点IP和端口是多少；客户端在接收到MOVED错误时，会更新本地的映射关系，并重新向新节点发送请求命令。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-54da863df05ceb9eb1a578969bad8ef55dc.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;ASK&lt;/h4&gt;

&lt;p&gt;Redis集群支持在线迁移槽（slot）和数据来完成水平伸缩，当slot对应的数据从源节点到目标节点迁移过程中，客户端需要做到智能识别，保证键命令可正常执行。例如当一个slot数据从源节点迁移到目标节点时，期间可能出现一部分数据在源节点，而另一部分在目标节点，如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ac2f94c38e21d669c070767bb34addef53b.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;当出现上述情况时，客户端键命令执行流程将发生变化，如下所示：&lt;/p&gt;

&lt;p&gt;1）客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直 接执行并返回结果给客户端&lt;/p&gt;

&lt;p&gt;2）如果键对象不存在，则可能存在于目标节点，这时源节点会回复 ASK重定向异常。&lt;/p&gt;

&lt;p&gt;3）客户端从ASK重定向异常提取出目标节点信息，发送asking命令到目标节点打开客户端连接标识，再执行键命令。如果存在则执行，不存在则返回不存在信息。&lt;/p&gt;

&lt;p&gt;在客户端收到ASK错误时，不会更新本地的映射关系&lt;/p&gt;

&lt;h2&gt;节点宕机触发主备切换&lt;/h2&gt;

&lt;p&gt;上文提到，如果redis集群在运行过程中，某个主节点由于某种原因宕机了，此时就会触发集群的节点选举机制，选举其中一个从节点作为新的主节点，进入主备切换，在主备切换期间，新的节点没有被选举出来之前，打到该节点上的请求理论上是无法得到执行的，可能会产生超时错误。在主备切换完成之后，集群拓扑更新完成，此时客户端应该向集群请求新的拓扑结构，并更新至本地的映射表中，以保证后续命令的正确执行。&lt;/p&gt;

&lt;p&gt;有意思的是，Jedis在集群主备切换完成之后，是会主动拉取最新的拓扑结构并进行更新的，但是在使用Lettuce时，发现在集群主备切换完成之后，连接并没有恢复，打到该节点上的命令依旧会执行失败导致超时，必须要重启业务程序才能恢复连接。&lt;/p&gt;

&lt;p&gt;在使用Lettuce时，如果不进行设置，默认是不会触发拓扑刷新的，因此在主备切换完成后，Lettuce依旧使用本地的映射表，将请求打到已经挂掉的节点上，就会导致持续的命令执行失败的情况。&lt;/p&gt;

&lt;p&gt;可以通过以下代码来设置Lettuce的拓扑刷新策略，开启基于事件的自适应拓扑刷新，其中包括了MOVED、 ASK、PERSISTENT_RECONNECTS等触发器，当客户端触发这些事件，并且持续时间超过设定阈值后，触发拓扑刷新，也可以通过enablePeriodicRefresh（）设置定时刷新，不过建议这个时间不要太短。&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;// 设置基于事件的自适应刷新策略
ClusterTopologyRefreshOptions topologyRefreshOptions = ClusterTopologyRefreshOptions.builder()
        //开启自适应拓扑刷新
        .enableAllAdaptiveRefreshTriggers()
        //自适应拓扑刷新事件超时时间，超时后进行刷新
        .adaptiveRefreshTriggersTimeout(Duration.ofSeconds(30))
        .build();

redisClusterClient.setOptions(ClusterClientOptions.builder()
        .topologyRefreshOptions(topologyRefreshOptions)
        // redis命令超时时间
        .timeoutOptions(TimeoutOptions.enabled(Duration.ofSeconds(30)))
        .build());

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进行以上设置并进行验证，集群在主备切换完成后，客户端在段时间内恢复了连接，能够正常存取数据了。&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;对于缓存的操作，客户端与集群之间连接的稳定性是保证数据不丢失的关键，Lettuce作为热门的异步客户端，对于集群中产生的一些突发状况是具备处理能力的，只不过在使用的时候需要进行设置。本文目的在于将在开发缓存操作功能时遇到的问题，以及将一些涉及到的底层知识做一下总结，也希望能给大家一些帮助。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b007db9e179d1044d4ec7ff78d252315</guid>
<title>一分钟读论文：《战争与和平：世界政治对软件生态系统的影响》</title>
<link>https://toutiao.io/k/l12t8wz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;article-post&quot;&gt;                
&lt;p&gt;两国交战，平民是否有罪？国际人道法约定“战争时要尽可能限制对妇女和儿童以及其他平民的影响”。开源许可证明确规定“不歧视个⼈或群体。License 不得歧视任何⼈”。 俄乌冲突中开源如何影响开发者呢？我们来看看日本奈良科学技术大学和澳大利亚墨尔本大学合著的论文&lt;a href=&quot;https://www.semanticscholar.org/reader/19d4db23117ccedc3d7fb7b245e2fe0ee9de86c8&quot;&gt;《In war and peace: the impact of world politics on software ecosystems》&lt;/a&gt;中研究的几个例子：当开源项目的维护者将他们的开源项目化为抗议软件（Protestware）。&lt;/p&gt;

&lt;p&gt;抗议软件不仅在政治冲突的背景下具有相关性，⽽且开源维护者有自己的⽴场。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Faker.js&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Colors.js&lt;/code&gt; 这两个拥有超过 21,000 个依赖应⽤程序和超过 2200 万每周下载量的库的维护者故意发布了⼀个更新给亚⻢逊云开发⼯具包的⽤⼾带来了问题，该更新产⽣了⼀个⽆限循环，导致依赖应⽤程序喷出以“Liberty Liberty Liberty”作为开头的乱码。作者在 README 表明自己的立场，要求6位数的年薪作为报酬。&lt;/p&gt;

&lt;h2 id=&quot;俄乌冲突中的真实案例&quot;&gt;俄乌冲突中的真实案例&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;恶意抗议软件 Node-ipc：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Node-ipc 是使用广泛的 npm 开源组件，其作者出于其个人政治立场在仓库中加入将俄罗斯与白俄罗斯区域用户数据抹除的恶意代码，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vue.js 生态中的 vue-cli 包依赖了它使得漏洞影响范围很大（一周内上百万次下载）&lt;/code&gt;，GitHub 宣布这是一个严重漏洞，漏洞跟踪编号 CVE-2022-23812。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;温和的抗议软件：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;其一，同样是 node-ipc 的维护者，只是这次改成在用户桌面创建反战标语，维护者还在 REAMDE 中要求开发者不喜欢就锁定使用正常的版本。&lt;/li&gt;
  &lt;li&gt;其二，AWS terraform 的维护者在自己的项目的 License 描述中添加了反战标语。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;制裁开发者：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;MongoDB 决定不向俄罗斯买家出其产品。&lt;/li&gt;
  &lt;li&gt;甲骨文终止对俄罗斯用户的支持。&lt;/li&gt;
  &lt;li&gt;GitHub 暂停了俄罗斯账⼾。被暂停的⽤⼾的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;整个活动和历史都消失了&lt;/code&gt;。更⼤的问题是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GitHub 没有向库维护⼈员提供任何警告&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;知名互联网公司的制裁：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;微软暂停在俄罗斯的销售其产品。&lt;/li&gt;
  &lt;li&gt;苹果暂停在俄罗斯的销售其产品。&lt;/li&gt;
  &lt;li&gt;SAP 暂停在俄罗斯的销售其产品。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;论文引发的10个思考题&quot;&gt;论文引发的10个思考题&lt;/h2&gt;
&lt;p&gt;在高度互连的大型软件生态系统中，平均包可以直接依赖超过五个其他包，抗议软件对整个生态系统的影响可能是毁灭性的，特别恶意软件。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;抗议软件在传播政治⽅⾯的效果如何？&lt;/li&gt;
  &lt;li&gt;抗议软件对软件生态系统的直接影响是什么？&lt;/li&gt;
  &lt;li&gt;谁受到抗议软件的影响，他们与抗议软件维护者有什么关系（如果有）？&lt;/li&gt;
  &lt;li&gt;项目使用哪些缓解策略来保护或修复其供应链，这些缓解策略的有效性如何？&lt;/li&gt;
  &lt;li&gt;供应链冗余在提高弹性方面的效果如何？&lt;/li&gt;
  &lt;li&gt;将库变成抗议软件的变化与其他软件演变有何不同？&lt;/li&gt;
  &lt;li&gt;我们自动检测抗议软件的准确度如何？&lt;/li&gt;
  &lt;li&gt;软件生态系统中其他利益相关者认为维护者的责任是什么？&lt;/li&gt;
  &lt;li&gt;抗议软件如何影响整个生态系统的信任？&lt;/li&gt;
  &lt;li&gt;抗议软件如何在生态系统层面受到监管？&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;


                
&lt;/article&gt;


&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c644b8083f53d6507e3c784cf7d360f1</guid>
<title>万字长文：AI 产品经理视角的 ChatGPT 全解析</title>
<link>https://toutiao.io/k/7ev21h2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近一段时间持续在关注两个技术方向：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ChatGPT所代表的大语言模型对NLP领域的推动&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Diffusion算法对图像领域的推动&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天这篇会先展开说一说ChatGPT，大致上包含以下方面：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;讲明白ChatGPT的技术原理（放心，是科普向的原理，没有任何公式）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;说明白ChatGPT的技术到底牛在哪里&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ChatGPT可能的落地应用方向&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AI产品经理在这波浪潮中可以做些什么&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;全文10389个字，阅读需要几分钟我也不知道哈哈。&lt;/p&gt;&lt;p&gt;对技术不感兴趣的可以直接滑动到屏幕将近一半的位置阅读第三部分和第四部分。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;前言 一个AI产品经理的触动&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2022年11月30日，chatgpt发布，5天内涌入100W用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他拥有持续的上下文对话能力，同时支持文章写作、诗词生成、代码生成等能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果用旧技术去理解他，我们通常会认为他的背后是由&lt;strong&gt;复合Agent&lt;/strong&gt;组合起来支撑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;复合Agent是什么意思呢？即有若干个术业有专攻的Agent：有一个负责聊天对话的，一个负责诗词生成的，一个负责代码生成的， 一个负责写营销文案的等等等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个Agent只擅长做自己的那部分事情，而在用户使用的过程中，系统会先判定用户的意图是什么，应该是哪个Agent，然后再将用户的命令分发给对应的agent去解决并提供答案。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此看起来是很厉害的机器人，背后其实是若干个术业有专攻的机器人。事实上Siri、小爱、小度，小冰甚至包括各个平台的客服机器人都是这种模式。这样当你要上线一个新能力（例如写古诗），你只需要新增训练一个Agent，然后将这个Agent接入到总控的分类意图器下就行。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是当前时代的一个缩影，不管外行人如何看待你从事的行业，不管媒体是如何一次次人云亦云地说警惕AI取代人类，你一直都知道，你在做的只是训练出一个术业有专攻的机器人而已，离真正的人工智能十万八千里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但ChatGPT的能力不再是这种模式了，他所采用的模式是大语言模型+Prompting。所有的能力通过一个模型实现，背后只有一个什么都会的机器人（即大语言模型），并支持用户借助文字下达命令（即Prompting，提示/指示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然这种能力的表现还不算完美，但是他开启了一条一种通向“通用型人工智能”的道路，曾经科幻故事里的Jarvis，moss好像真的有了那么一点可能。而这才是7年前，我踏入这个行业所憧憬的东西啊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可能你对我的震撼有点无法理解，我接下来会讲明白他的技术原理，带你慢慢感知这项技术的牛逼之处，下面正式进入正文。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第一部分 ChatGPT的技术原理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们要弄明白，NLP&lt;span&gt;任务&lt;/span&gt;（自然语言处理，AI的一个技术领域，即文本类的AI任务）的核心逻辑是一个“猜概率”的游戏。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，“我今天被我老板___”，经过大量的数据训练后，AI预测空格出会出现的最高概率的词是“CPU了”，那么CPU就会被填到这个空格中，从而答案产生——“我今天被我老板CPU了”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然非常不可思议，但事实就是这样，现阶段所有的NLP任务，都不意味着机器真正理解这个世界，他只是在玩文字游戏，进行一次又一次的概率解谜，本质上和我们玩报纸上的填字游戏是一个逻辑。只是我们靠知识和智慧，AI靠概率计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在目前的“猜概率”游戏环境下，基于大型语言模型（LLM，Large Language Model）演进出了最主流的两个方向，即Bert和GPT。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中BERT是之前最流行的方向，几乎统治了所有NLP领域，并在自然语言理解类任务中发挥出色（例如文本分类，情感倾向判断等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而GPT方向则较为薄弱，最知名的玩家就是OpenAI了，事实上在GPT3.0发布前，GPT方向一直是弱于BERT的（GPT3.0是ChatGPT背后模型GPT3.5的前身）。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来我们详细说说BERT和GPT两者之间的差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;BERT&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;双向 预训练&lt;strong&gt;语言&lt;/strong&gt;模型+fine-tuning（微调）&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;GPT：&lt;span&gt;自回归 预训练语言模型+Prompting（指示/提示）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个字都认识，连到一起就不认识了是吗哈哈。没关系，接下来我们把这些术语逐个拆解一遍就懂了：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;「预训练&lt;strong&gt;语言&lt;/strong&gt;模型」&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通常认知里的AI，是针对具体任务进行训练。例如一个能分辨猫品种的Agent，需要你提供A-缅因猫，B-豹猫这样的数据集给他，让它学习不同品种之间的特征差异，从而学会分辨猫品种这项能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但大语言模型不是这样运作的，他是通过一个大一统模型先来认识这个世界。再带着对这个世界的认知对具体领域进行降维打击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里让我们先从从NLP领域的中间任务说起。&lt;/span&gt;&lt;span&gt;像中文分词，词性标注，NER，句法分析等NLP任务。他们本身无法直接应用，不产生用户价值，但这些任务又是NLP所依赖的，所以称之为中间任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以前，这些中间任务都是NLP领域必不可少的。但是随着大型语言模型的出现，这些中间任务事实上已经逐步消亡。而大型语言模型其实就是标题中的“语言预训练模型”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他的实现方式是将海量的文本语料，直接喂给模型进行学习，在这其中模型对词性、句法的学习自然而然会沉淀在模型的参数当中。我们看到媒体对ChatGPT铺天盖地的宣传里总是离不开这样一句话——在拥有&lt;strong&gt;3000亿单词&lt;/strong&gt;的语料基础上预训练出的拥有&lt;strong&gt;1750亿参数&lt;/strong&gt;的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里面3000亿单词就是训练数据。而1750亿参数就是沉淀下来的AI对这个世界的理解，其中一部分沉淀了Agent对各类语法、句法的学习（例如应该是两个馒头，而不是二个馒头，这也是中间任务为什么消亡的原因）。而另外一部分参数参数则储存了AI对于事实的认知（例如美国总统是拜登）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是经过预训练出一个这样的大语言模型后，AI理解了人类对语言的使用技巧（句法、语法、词性等），也理解了各种事实知识，甚至还懂得了代码编程，并最终在这样的一个大语言模型的基础上，直接降维作用于垂直领域的应用（例如闲聊对话，代码生成，文章生成等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而BERT和GPT两者都是基于大语言模型的，他们在这一点上是相同的。他们的不同在于双向/自回归，fine-tuning/Prompting这两个维度，我们接下来会重点弄明白这四个术语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;「双向 VS 自回归」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BERT：双向。双向是指这个模型在“猜概率的时候”，他是两个方向的信息利用起来同时猜测。例如“我__20号回家”，他在预测的时候，是同时利用“我”+“20号回家”两端的信息来预测空格中的词可能为“打算”。有点像我们做英文的完形填空，通常都是结合空格两端的信息来猜测空格内应该是哪个单词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPT：自回归。自回归就是猜概率的时候&lt;span&gt;从左往右做预测，不会利用文本中右侧的内容，和BERT相反。这就有点像我们写作文的时候，我们肯定是一边写一边想。&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两者基本理念的区别导致BERT在&lt;strong&gt;之前&lt;/strong&gt;更擅长自然语言理解类任务，而GPT更擅长自然语言生成类任务（例如聊天、写作文）。——注意，我说的是之前，后面的章节我会介绍现在的情况发生了什么变化。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;「fine-tuning VS Prompting」&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设现在预训练好的大模型要针对具体领域工作了，他被安排成为一名鉴黄师，要分辨文章到底有没有在搞黄色。那么BERT和GPT的区别在哪里呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BERT：fine-tuning（微调）。微调是指模型要做某个专业领域任务时，需要收集相关的专业领域数据，做模型的小幅调整，更新相关参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我收集一大堆标注数据，A-是黄色，B-没有搞黄色，然后喂给模型进行训练，调整他的参数。经过一段时间的针对性学习后，模型对于分辨你们是否搞黄色的能力更出色了。这就是fine-tuning，二次学习微调。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPT：Prompting。prompt是指当模型要做某个专业领域的任务时，我提供给他一些示例、或者引导。但不用更新模型参数，AI只是看看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我提供给AI模型10张黄色图片，告诉他这些是搞黄色的。模型看一下，效果就提升了。大家可能会说，这不就是fine-tuning吗？不是一样要额外给一些标注数据吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两者最大的区别就是：这种模式下，模型的参数不会做任何变化升级，这些数据就好像仅仅是给AI看了一眼——嘿，兄弟，参考下这个，但是别往心里去。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不可思议吧，但他成功了！而&lt;span&gt;更令人疯狂的是，到目前为止，关于prompt明明没有对参数产生任何影响，但确实又明显提升了任务的效果，还是一个未解之谜。&lt;/span&gt;暂时而言大家就像程序员对待bug一样——I don&#x27;t know why , but it work lol .&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种Prompt其实就是ICT（in-Context Learning），或者你也可以称为Few shot Promot，用大白话说就是“给你一点小提示”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时还有另外一种Promot，称之为Zero shot Promot。&lt;span&gt;ChatGPT就是Zero shot promot模式，目前一般称之为instruct了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种模式下用户直接用人类的语言下达命令，例如“给我写首诗”，“给我做个请教条”，但是你可以在命令的过程中用一些人类语言增强AI的效果，例如“在输出答案之前，你先每一步都想一想”。就只是增加这样一句话，AI的答案效果就会明显提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会问这是什么魔法咒语？！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个比较靠谱的猜测是这句话可能让AI回想起了学习的资料中那些推理知识好像前面都会有这句话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后这一切莫名激活起了他死去的记忆，不自觉开始仿造那些严密的推理过程中一步步推导。而这些推导会将一个复杂问题分解成若干子问题，AI因为对这些子问题的推导，从而导致最终答案效果提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上对比下来，你会发现好像GPT这种模式比起BERT模式更符合我们对人工智能的想象：通过海量的知识成长起来，然后经过稍微引导（Prompt），他就能具备不同领域的强大能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后总结一下，ChatGPT背后的GPT模型是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个超大语料基础上预训练出的&lt;strong&gt;大语言模型（LLM）&lt;/strong&gt;，采用从左到右进行填字概率预测的&lt;strong&gt;自回归语言模型&lt;/strong&gt;，并基于&lt;strong&gt;prompting&lt;/strong&gt;（提示）来适应不同领域的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果只基于上面的描述，你可能大概弄懂了他背后的原理，但是对于为什么他这么牛逼，你仍然无法理解。没关系，我们接着进入第二部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;第二部分 GPT牛逼在哪里&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;他可能是通用型人工智能的开始&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们原始的幻想里，AI是基于对海量数据的学习，锻炼出一个无所不知无所不能的模型，并借助计算机的优势（计算速度、并发可能）等碾压人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我们目前的AI，不管是AlphaGo还是图像识别算法，本质上都是服务于专业领域的技术工人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5616666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/dzhS9Lf5dlVjTl3HONdBcTBAEMRWJS5iahfibicxL11WiamQpmJC91rZribqgLKROAjGENTym8EsoLmSCK6EGUqgXRQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;br/&gt;&lt;span&gt;我们心目中的机器人，无所不能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6811989100817438&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/dzhS9Lf5dlVjTl3HONdBcTBAEMRWJS5iav31ljqkFYXicm7Kib07FRW7jl4znsx9THhbMRxyeEmBS3nE0N0PoxU2g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;734&quot;/&gt;&lt;br/&gt;&lt;span&gt;现实里的机器人，只解决某个领域的问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而GPT目前看似只能解决自然生成领域的任务，但实际上，他展现出了通用型人工智能的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在前面，我们讲过，&lt;strong&gt;目前而言&lt;/strong&gt;，BERT擅长自然语言理解类任务（完形填空），GPT擅长自然语言生成类任务（写作文）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但在Google的FLAN-T5模型上已经实现了两类任务在输入输出形式上的统一，从而使得用GPT来做完形填空成为可能。也就是可以用一个大模型来解决所有NLP领域的问题。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3439767779390421&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dzhS9Lf5dlVjTl3HONdBcTBAEMRWJS5iaqiclqNBEEhTWxMCN5lNlqKvVI7evodEJDCFLqGiav279mlgN3DSkJ9cA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1378&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么再进一步地，是否GPT可以从NLP领域走向其他AI领域呢？当然有可能！在去年年中爆火的AI绘画，其中一个关键技术门槛其实就是Text-图像的转化，这同样是来自OpenAI所开源的CLIP模型实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此GPT在图像领域的能力同样也令人期待。同理在多模态如音频、视频，本质上也能转化为Text-everthing的问题去求解，从而让大语言模型发挥成吨的威力。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然你可能会问，那么只要大语言模型就可以呀，为什么是GPT，而不是BERT呢？接着往下看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Promot模式相较fine-tuning更具生命力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，BERT的fine-tuning模式有两个痛点。&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我需要准备某个专业领域的标注数据，这个数据还不能少，如果太少，AI模型训练后就会形成过拟合（就是AI直接背下了整本习题册，册里的问题100%正确回答，但是稍微变幻题型就GG&lt;span&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我需要部署大语言模型，才能对他进行进行微调，那么部署大语言模型的成本，甚至进一步对他进行微调的能力，并不是所有公司都具备的。这注定是一个只有少数玩家能参与的游戏。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;而Promot模式恰恰相反，不需要太多的数据量，不需要对模型参数进行改动（也就意味着可以不部署模型，而是接入公开的大语言模型服务）。那么他的调试就会呈现百花齐放的姿态，玩家越多，创造力涌现就越猛烈&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;全新的人机交互方式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的人机交互，指的是人-模型之间的交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前ChatGPT采用的是模型侧的Few shot prompt，即给一点示例提示，让AI提升表现，虽然暂时未知为什么不更新模型仅仅只是给AI看一眼就能带来巨幅提升，但这种交互模式无疑是更友好的。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而更具颠覆性的是输入端的Zero shot prompt，即我们用人类的语言逐步引导AI思考——比如我们可以说，你仔细想好步骤，再给出答案。就仅仅是多加一句“你仔细想好步骤”，AI的答案靠谱率就会明显提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这种交互方式的演变，就是我们梦想中的人机交互模式。我不需要专业的能力，不需要高端的设备，我就是开口，说出我的诉求，AI就能够理解并帮我实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;GPT开始尝试讨好人类，并成功了&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在12月的媒体通稿里，一大堆对ChatGPT的溢美集中于他的“仿真性”，仿佛通过了图灵测试一般。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这种仿真性，直观来说，我们会认为是AI的“智力”提升了，他更聪明了。但实际上，ChatGPT背后的GPT3.5，更多的提升在于“用人类所喜欢的方式回答”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上ChatGPT背后的GPT3.5的模型，相较GPT3.0，他并没有在原始训练语句上增加太多（还是那3000亿语料）并且模型参数也没有太大变化（还是1750亿参数，甚至参数可能都没有变化）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之所以他会让人产生质变的感觉是因为他做了人类偏好处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如以前的输入模式可能需要这样：&lt;br/&gt;&amp;gt; 执行翻译任务&lt;br/&gt;&amp;gt; 输入是“我爱北京天安门（中文）”&lt;br/&gt;&amp;gt; 翻译目标语种是英文”&lt;br/&gt;&lt;br/&gt;而现在你直接说：&lt;br/&gt;&amp;gt; 帮我把我爱北京天安门翻译成法语&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;又或者是，以前你提一个问题，他会不加选择的回答，而现在他会考虑答案有害性：&lt;br/&gt;&amp;gt; 如何毁灭世界——你可以召唤三体人降临（此处应有一个潘寒hhh）&lt;br/&gt;&amp;gt; 如何毁灭世界——亲，请不要毁灭世界，地球是人类共同的家园&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这些对于人类偏好的攻略依赖于三个步骤：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建人类偏好数据。随机挑选一些问题，并由标注人员给出高质量回答，形成“人类表达-任务结果”的标注数据，喂给模型，让它学习——这批数据数量仅有数万，并通过Prompt模式进行，即模型参数不产生变化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练一个回报模型。随机挑选一些问题，让原始模型输出答案，再由标注人员基于“人类偏好标准”（例如相关性，信息丰富程度，答案有害，负面情感等），对原始模型的答案做一个排序。&lt;br/&gt;然后我们利用这批标注好的“人类偏好”数据，训练一个回报模型，这个回报模型会对原始模型的结果进行打分，告诉他什么答案分高，什么答案分低。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过强化学习循环整个过程。强化学习会将回报模型和原始模型链接到一起，当原始模型输出的结果，在回报模型中获得较低分值，他就收到惩罚，被要求重新学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;后续不断循环步骤2和步骤3，原始模型就会脱胎换骨，学习到人类的偏好，变成一个人类所喜欢的模型，也就是我们最终所看到的ChatGPT。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这让我们有理由相信，模型的表现不好，不一定是他没学到知识，可能只是他不知道对于人类而言，哪种答案才是人类想要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这种人类偏好学习，目前来看是集中在Prompt模式下的GPT的，而非fine-tuning模式下的BERT。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后请不要着急焦虑，还没到AI取代全世界的时候&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的一段时间，我看到大量的噱头文章，美国高校封禁ChatGPT，技术论坛封禁ChatGPT。&lt;span&gt;媒体迎合着公众的狂欢情绪，照旧掀起一波AI毁灭一切的氛围。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.46495726495726497&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dzhS9Lf5dlWo1goq0EHicX3S7rjjORvbhIg5JtIUnawvlfNV0AJhLMnFFzC5Gibic6P7GibNVJOONoRZtHNFCScY0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1170&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但实际上，就目前而言，GPT暂时还只是一种很有潜力的趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;首先，人家自己都说不行&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;附上openAI CEO的回复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8662420382165605&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dzhS9Lf5dlWo1goq0EHicX3S7rjjORvbh2qUzmaia0Bz7HrajAiaj2ibYRpfXTHRCQnTEcsYulru2tCou2JrjDW6fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1256&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;其次，落地成本高&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ChatGPT的复现依托于大模型，他的落地有三种路径：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于instruct GPT复现（ChatGPT的姐妹模型，有公开paper）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于OpenAI目前开放的GPT3.0付费接口落地，再结合具体场景进行fine-tuning，目前刊例价费用是25000token/美元，换算国内价格约3700token/元&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于OpenAI试点中的ChatGPT PRO落地，42美元/月，换算后约284元/月&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;第一种路径依赖于新玩家的进入，但大概只能是大玩家的赛道。&lt;br/&gt;第二种和第三种路径需要打平付费接口的成本，需要针对的场景具备足够价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然成本的问题可以期待被快速解决，就像AI绘画领域一样。不过目前而言，成本仍然是ChatGPT落地的一个制约因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后&lt;/strong&gt;&lt;strong&gt;，最重要的是ChatGPT目前的能力仍然存在缺陷：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结果不稳定。这会导致无法直接应用，必定需要人工review，更多是瞄准辅助性场景或本身就不追求稳定的场景。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推理能力有限。例如询问现在的美国总统是谁，会回答奥巴马，或特朗普，但又能回答出拜登是46届总统。我们可以发现模型中事实存在，但他无法推理出正确答案。&lt;br/&gt;如果要优化，一方面是输入的时候，可以通过Prompt逐步引导，另一方面是在模型侧的Few Shot Prompt环节中采用思维链技术（CoT,&lt;span&gt;Chain of Thought&lt;/span&gt;）或采用代码数据集来改进。就目前而言，进展可喜，但能力仍然有限。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;知识更新困难。一方面整个模型的重新训练成本很大，另一方面知识更新也会带来知识遗忘的隐忧，即你不知道他这次更新是不是在学会什么的同时，也忘记了什么。也就是说ChatGPT在解决这个问题之前，他的知识将始终落后一段时间。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上，ChatGPT很惊艳，但更多在于它的潜力和未来，基于当下要做应用的话是需要做非常多适配和场景探索的。接下来进入我们第三部分，探索ChatGPT为代表的GPT大语言模型应用方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第三部分 ChatGPT所代表的大语言模型应用方向&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从目前来看，应用方向可以分成三种&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;模型服务&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以OpenAI为典型代表，孵化大模型后，开放接口，提供公共模型能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前OpenAI的接口支持GPT3.0的能力调用，同时支持二次tuning。而在大规模的商业合作上，notion、office全家桶、bing都在推进当中。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2B垂直工具&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以COPY AI，Jasper为例，主打生成内容，并且瞄准了有明确价值需求的领域。例如自动生成SEO文章、广告创意、ins文案等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一类目前海外发展得较好，一方面受益于对SaaS付费的接受度，另一方面也是因为瞄准了明确的用户群——电商从业者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上代码校验提示，会议纪要生成，专业文档写作等都可能是这个方向的扩展。但一方面要看fine-tuning效果如何，另一方面商业价值确实也不如电商领域高。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;C端娱乐类&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;C端应该说是场景最匹配ChatGPT应用的方向了，毕竟用户的忍受度相当高，智障音箱都能忍，何况升级后的GPT。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但困难的在于两方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，要找到可供能力落地的C端场景，毕竟单纯聊天是没有价值的，附加了场景才产生价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，要找到商业模式突破成本线。按照GPT3.0的刊例价来算，要求这个产品每输出3700个字，就要从用户身上赚到1块钱（作为参考：目前国内头部小说网站起点的付费阅读是20000字/元）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;海外的C端娱乐应用我不太了解（之前用的账号过期了，最近懒得弄）。搜索了一下国内应用，最近社交分类Glow这个APP冲上了第7名，扩展往下看会发现主流的娱乐类Chat基本上是围绕二次元/宅群体进行的。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果围绕这个用户群稍作扩展，在年轻/黏性/新事物尝试等维度的组合下，明星粉丝也是一个可能的方向。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但也不好说就锁死在这些群体上——你猜猜给一个独居的二大爷尝试ChatGPT他会喜欢吗？给一个流水线的工人尝试呢？毕竟孤独，一直是人类永恒的命题，谁也不知道下一个爆款来自哪里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;第四部分 AI产品经理能做什么？&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;商业层&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的互联网环境，收益已经是第一位的事情了，不管是外部投融资还是内部项目盘点，商业变现都是最核心的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;商业上的事情其实又可以拆成两个模块，战略上的，战术上的，依据公司的规模和团队结构不同，AI PM的话语权会有不同程度的衰减。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举例子说明一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;战略层的问题：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我要启动一个ChatGPT项目，用户群是什么，商业模式是什么，壁垒在哪里，演进的步骤是什么？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些问题的产生在“决定项目做不做”，“接下来项目往哪走”的环节。假设对这方面有话语权，不管大还是小，那么都会是一件非常锻炼人的事情。这个环节中无非就是两种能力：知识获取以及知识的推理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知识获取包括你过往的行业经验，业务经验，以及临时抱佛脚所调研的行业信息。这方面依赖的是知识的挖掘、辨别、结构化整理能力，特别是现在这个时代的信息环境，真的是屎山里找金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知识的推理是对这些知识有选择地推导，从知识中得出商业答案。这个环节可以利用一些思维工具去结构化推导（例如商业画布），多推几次后，本身自己会沉淀下来一些商业分析的肌肉记忆，工具反而退居其次了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;战术层的问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：产品做出来了，甚至免费运作一段时间了，那么接下来产品怎么定价？价格阶梯如何设置？个体消费者和企业消费者的价格会不同吗？渠道服务商的价格和直售的价格一样吗？我的成本线是多少，盈利线是多少？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只是围绕一个价格，就会延伸出一堆细碎繁杂的问题。更何况关联产生的产品方案，渠道政策，广告ROI等模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;战术层的问题因其细碎和宽泛，会被拆成非常多不同的方向，每个方向其实都没那么复杂，只是需要一些敲门进去的方法论，剩下的就是一些实战经验。所以我们会看到，现在大厂招人，往往倾向在垂直细分方向找一个有相关经验的人，这样会节约上手时间和试错成本，例如会员产品经理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术层&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的技术其实没那么技术。AI产品经理和传统产品经理最大的不同就在于，他所依赖的产品核心是AI技术，因此将商业、用户需求转化为算法需求是他的主要职责。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里面我们所提出的问题，是会有技术层面的深浅不同的。举个例子，我们遇到了一个问题“需要Chatbot能够记住用户的偏好知识，例如他喜欢下雨天，喜欢达芬奇，喜欢黄金时代”，现在我们需要算法团队帮我们实现，那么可能有不同层次的提法：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;chatbot要支持记忆用户输入的偏好信息，例如喜欢黄金时代，储存时间为永久，并且支持知识的互斥与整合（例如先说喜欢下雨天，后面又说讨厌下雨天）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要chatbot支持记忆用户输入的偏好信息，并且这个能否不要用模型参数去学习，而是搭建一个独立的知识库，再通过模型另外调用？这样用户可以可视化地修正自己的偏好知识。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;加装一个意图识别器，发现是用户偏好知识的时候转到知识库进行储存和整合，如果非偏好知识则正常走大模型结果。意图识别器这里可以用xxx技术，你看看这篇paper，是有相关实现经验的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家会发现三个层次在技术层面是由浅到深的。那么什么时候深什么时候浅取决于什么呢？&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;取决于产品的技术实力。有时候你的技术实力就决定了你深不了。没关系，其实到第三个层次并不是必须的，一般到第二个层次就够用了，甚至到不了第二层次，就在第一个层次上你把需求讲明白，也是能跑的下去。只是这样产品的权威性，你对需求的判断，ROI的平衡判断都会产生很大的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;取决于需求的目的，例如第一个层次的需求没有专门提及知识库，那这个时候用模型去学习记录也可以，用知识库也可以。但是第二个需求中就明确要求了基于知识库的实现方法，因为他需要用户可视化修改自己的偏好知识。（甚至有时候最后不一定是用知识库的方法，但没关系，提出你的idea，与算法团队深入讨论，多少都是一种启发）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;取决于你和算法团队磨合出的边界。要找到你们之间最舒适的交织区域，一般而言是产品往技术多走几步，算法往业务多走几步，这样能发挥1+1＞2的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;当然，不管是需求提到哪种技术层次，都需要铭记一个基本原则，说明白你这个需求的背景、目的、价值。例如第二个例子中，其实是要额外说明用户可视化修正偏好知识到底能带来什么，值不值得做，这些业务价值会与技术实现的成本互相PK，取得平衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI产品经理在技术层能做的事情有点像在做fine-tuning，在模型不那么适配场景，或者场景延伸出新能力诉求的时候，发现他，分析他，并与算法团队深度讨论后方案后在成本和收益之间做平衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;应用层&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用层的事情其实和技术层有点交织，因为大部分时候你上一个新的应用功能，背后多数是需要技术支撑的。&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过这里我们搞简单点，把有技术诉求的那部分剔除掉，只保留无技术依赖或低技术依赖的来讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我举个大家习以为常，但效果巨大的例子：当我们做人脸验证，或者银行卡图像识别的时候，他一定会有一个虚拟框，要求你将脸或者银行卡摆放在固定位置。这个功能毫无技术要求，就是加一个透明浮层而已。但是他能极大提升采集图像的质量，从而提升算法效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在chatbot里面其实也可以类似的做法。例如ChatGPT有时候会崩溃，输出结果在一半的时候就中断。他的原理其实就是自然语言生成本质上是持续性在预测下一个字是什么，然后预测出一篇文章。那么当模型在还不应该结束的时候不小心预测出一个END字符的时候，AI就认为我可以在这里停止了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决方案有高大上的技术方案，我们这里可以土肥圆做个low一点的——加装一个按钮“你还没说完呢”，用户点击后，AI就会自动再次重跑一遍这个input，输出结果。这样顺便还能采集一下对于这种END崩溃的bad case数据。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;增长层&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只要你做的产品是给人用的，不管是2B还是2C，那么就离不开增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只是2B和2C的增长是两套完全不同的方法论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2B其实更多应该被归到商业层，你需要做产品定价，做渠道政策，做客户成功，并打磨你整个销售链路，找到薄弱点优化他。在这个过程中你要清晰认识到2B与2C在付费决策上的显著不同，2B是多用户下关键决策人掌握公有资产进行付费判断，而2C是用户个体掌握私有资产进行付费资产。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过教育行业这个市场会和2B有一点点相似，他是学生使用，家长付费，学校/机构影响，也是一个多用户下关键决策人的结构，不过掌握的是私有资产。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而2C就更不用说了，2C的增长产品是一个非常独立细分的行业。&lt;span&gt;可以通过投放，SEO，新客进入，老客留存，社交裂变等等命题去做努力，反正核心就是拉更多的人赚更多的钱。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只是目前而言，我们在说ChatGPT，那么他大概还是一个新项目新产品。那么大概率初始不会配备相应的增长产品，AI产品也需要兼顾关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后大家如果想做一些练习，可以找这个领域的一些C端应用试试看，例如glow，糖盒等（可能还有更多，欢迎私信指点我）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是我个人不建议拿各类市面上的chatbot或B端产品来尝试，前者发展到现在很成熟了，后者则很多时候需要面对B端特殊的场景，没有做过B端很难明白里面的细节。而glow、糖盒这类C端新起步的产品会是一个比较好的练手对象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我这里就不罗列对这两个产品的分析或者产品建议了，我个人觉得站在局外做产品建议是很扯淡的事情。产品的魅力在于根据有限的资源和环境，选择局部最优解来推动demo慢慢成长。如果不在局内的话，很多建议和迭代我都倾向于不公开，否则局内人看起来会很蠢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说觉得对话不智能，需要提升智能，建议接入GPT3.0。那么会不会这个产品的受众其实不那么需要智能，或者他们的需求无法与接入GPT3.0的费用平衡呢？这个需求有可能不是一个技术问题，而是一个商业问题。所以我觉得教张小龙做产品其实是个伪命题。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是自己练习一下还是可以的，有一个具现的产品做逻辑推导的练习，会比只阅读理论文章来得更有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;【彩蛋】&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;近期，我们在“&lt;strong&gt;AI产品经理大本营&lt;/strong&gt;”里整理了一份“&lt;span&gt;&lt;strong&gt;AIGC精华资料包&lt;/strong&gt;&lt;/span&gt;”（&lt;span&gt;&lt;strong&gt;34份干货报告&lt;/strong&gt;&lt;/span&gt;）。&lt;/p&gt;&lt;p&gt;其中，不仅包含常见的行业报告，还有 AIGC / OpenAI /ChatGPT 等相关核心内容的图表展示，以及我们在付费社群里的部分原创内容——&lt;span&gt;‍‍‍‍‍‍‍‍‍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6299212598425197&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/TS56qMjSfEgOYxynWo8mL2u8TmXsozKH14oqt5SCRUNhPZAPQF2lGo2stXgKxEQz7ryybgoiajEUXe1NUSznuicw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1270&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;领取方式&lt;/strong&gt;&lt;/span&gt;：&lt;strong&gt;在本公众号（hanniman）后台回复“&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;1234&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;”&lt;/strong&gt;，即可&lt;strong&gt;返回下载链接&lt;/strong&gt;&lt;span&gt;（无需添加微信好友）&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;最后，如果这篇文章对你有帮助，期望点赞、在看、转发，一键三连~ 好运连连～&lt;/p&gt;&lt;p&gt;&lt;span&gt;---------------------&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄钊hanniman，前腾讯PM，前图灵机器人-人才战略官/AI产品经理，10年AI、13年互联网背景；垂直于“AI产品经理”的第一社群（知识星球“&lt;/span&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzA5OTAwMA==&amp;amp;mid=2650007403&amp;amp;idx=1&amp;amp;sn=332709a833e0efc221566a79c5fc28ef&amp;amp;chksm=bed863fc89afeaea39e9c16da3b03b66d324ea8fce5a5a87e340a796bd26e75a43e53930a67c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;AI产品经理大本营&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;AI产品经理大本营&lt;/a&gt;&lt;/span&gt;&lt;span&gt;”，5年），作品有《&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzA5OTAwMA==&amp;amp;mid=2650007401&amp;amp;idx=1&amp;amp;sn=19a57c27e997cf15e4b53a93797ae543&amp;amp;chksm=bed863fe89afeae81e50b56c879f6f6fa72a9263742a8c182564635593abaaebf4472c03a29b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;AI产品经理的实操手册&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;AI产品经理的实操手册&lt;/span&gt;&lt;/a&gt;&lt;span&gt;》、《人工智能产品经理的新起点》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fe1316dc2f08eaa1640b7b9d48223a2f</guid>
<title>如何用油猴提升前端开发效率</title>
<link>https://toutiao.io/k/1mdth9p</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 起因&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;时隔一年，油猴脚本系列又来了，起因是那天洗澡的时候，突然灵光一闪，想到平时在前端开发中，有很多工作完全是一些机械的，没有什么难度的活，但是又异常的花时间！其实就是对一些表格字段。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前为止我还在开发之前的那个百万级ERP项目，项目中的列表非常的多，目前大概有几百个吧，而且每个列表都有非常多的字段，通常情况下都在20个字段左右，而后端写的时候会在对应的接口中返回一大堆字段，你需要从返回的字段中挑选出列表中需要的字段。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可能一个两个还好，但是几十个几百个列表一个字段一个字段的对起来就很耗时耗力，所以这个时候我就有一个想法：有没有那么一种方法，将原型图上列表字段提取出来，然后与swagger中该接口下面的字段注释做一个对比，如果对的上，则生成Antd可以使用的表头代码，如果没有对上，那么就统一将这些没有对上的字段展示出来，然后用肉眼去对，如果依然没有找到这些字段，那么就发给后端，让后端添加上这些字段。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一想到这个可能性，马上就想迫不及待的想要进行实现，这时我回忆起一年前用过油猴脚本做了一些事情，那么这次这个突发奇想是否也可以用油猴脚本进行实现。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 油猴脚本&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我在去年已经写过几篇关于油猴脚本的文章，其中提到过通过Webpack打包，可以开发特别复杂的脚本，甚至可以开发一些工程级的脚本，同时也可以使用npm上的包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是由于webpack配置的复杂性，所以我首先是没有考虑使用webpack打包工具的，而是先想到了另一个零配置打包工具：parcel。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是很遗憾，失败了，不知道为什么通过parcel打包后的js文件直接通过油猴引入外部资源的方法会报错，于是这个时候我还想到了一个打包js文件的工具：Rollup。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;遗憾的是，同样失败了，不知道为什么引入油猴后就是会报错，于是这个时候我就放弃抵抗，选择了webpack进行打包，结果不出意料，webpack打包后的js文件引入油猴中没有任何问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为我之前已经这么做过了，还总结了相关的文章：&lt;strong&gt;强大的油猴Tampermonkey脚本开发环境搭建&lt;/strong&gt;，所以关于油猴的基础部分就不再赘述。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1 打包的好处&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么要通过webpack打包？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为在编写一些复杂脚本时，我们往往会需要使用到非常多的库，而且也会将脚本进行模块化，分成非常多的文件，同时如果你还想编写一些CSS样式，那么你也可以直接写CSS文件或者Less或者Sass文件，通过webpack可以将这些文件统一起来，打包成一个js，然后通过油猴提供的外部引入方式进行引入。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着我对React越发的得心应手，要实现上面说的自动比对字段的功能React也是不可少的一环，而我个人非常喜欢使用TypeScript，因为它会给予代码更多的提示，让你在写代码的时候不容易犯一些低级错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而使用React的时候就不得不提到Antd，Antd这个UI组件库提供了非常多的方便的组件，不光是解决了一些样式问题，同时它还解决了很多交互层面的东西，比如它的Form表单，也是非常好用的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上所述，如果你要开发一个油猴脚本，那么通过webpack进行打包就是一个非常好的选择。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3. jQuery&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正如我年前的那篇文章所说，jQuery是一个非常值得学习的库，因为对于编写油猴脚本来说，没有什么比用jQuery去提取界面上的信息更方便的了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于jQuery的易用性，使用jQuery你可以轻易的从界面上提取到你要的信息，虽然使用正则可以达到差不多的效果，但jQuery代码写起来比正则更快，也更不容易出错。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4. 正则&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;编写脚本，非常多的情况会使用到正则，因为要精确的匹配到对应的字符，正则是你的不二之选，在做一些自动生成代码工具的时候，因为涉及到字符匹配的问题，学会正则就显得非常的重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里就要推荐一个非常好的正则测试网站：&lt;strong&gt;RegExr: 学习、构建和测试正则表达式Test RegEx&lt;/strong&gt;，因为有时候你无法判断你写的正则对不对，所以这个时候你就可以先在这个网站上面测试一下，如果测试结果符合你的预期，再将正则表达式复制到你的项目中进行测试，这样编写起正则来就方便的多，使用方法也非常简单，去该网站上面点两下大致就能明白如何使用。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5. 爬虫基础&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你要提取一些界面上的信息，那么你得会一些爬虫基础知识，知道怎么获取到界面上的某些信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理论上一个网页上面所有的信息，都能通过正则表达式进行提取，但由于正则表达式在编写的过程中可能会比较容易出错，这个时候jQuery就能有效的帮你提取出这些页面数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里就对爬虫入门时90%的人都会选择的&lt;strong&gt;豆瓣排行榜&lt;/strong&gt;做一个页面信息提取。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6. 实例&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面所想的那个脚本我其实已经实现了，但碍于swagger上面有公司项目的接口信息，所以这里就不拿那个脚本作为演示。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么这里我就拿jQuery爬取到的豆瓣排行榜信息作为演示吧：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要实现的功能就是，在输入框中输入电影名称，然后将电影相关的信息进行匹配并且展示出来：&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6.1 触发事件构建&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要执行你已经写好的代码，你通常可能需要&lt;strong&gt;一个按钮、一个输入框&lt;/strong&gt;或者其它元素进行触发，在本脚本的开发中，我就使用了&lt;strong&gt;Antd的按钮+Antd的模态框+Antd的输入框&lt;/strong&gt;这3种组件来搭建脚本。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6.2 最终效果&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最终的效果像下面这样，代码其实并不难。这里贴上最终的代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;import { Button, ConfigProvider, Form, Modal } from &lt;span&gt;&quot;antd&quot;&lt;/span&gt;;&lt;br/&gt;import &lt;span&gt;&quot;antd/dist/antd.css&quot;&lt;/span&gt;;&lt;br/&gt;import TextArea from &lt;span&gt;&quot;antd/es/input/TextArea&quot;&lt;/span&gt;;&lt;br/&gt;import zhCN from &lt;span&gt;&quot;antd/lib/locale/zh_CN&quot;&lt;/span&gt;;&lt;br/&gt;import * as $ from &lt;span&gt;&quot;jquery&quot;&lt;/span&gt;;&lt;br/&gt;import { useState } from &lt;span&gt;&quot;react&quot;&lt;/span&gt;;&lt;br/&gt;import { render } from &lt;span&gt;&quot;react-dom&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;interface InfoDataList {&lt;br/&gt;  /** 电影的名称 */&lt;br/&gt;  title: string;&lt;br/&gt;  /** 分数 */&lt;br/&gt;  score: string;&lt;br/&gt;  /** 评价数 */&lt;br/&gt;  number: string;&lt;br/&gt;  /** 简介 */&lt;br/&gt;  info: string;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;&lt;span&gt;AppButton&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;  const [infoDataList, setInfoDataList] = useState&amp;lt;InfoDataList[]&amp;gt;([]);&lt;br/&gt;&lt;br/&gt;  const [showData, setShowData] = useState&amp;lt;InfoDataList&amp;gt;();&lt;br/&gt;&lt;br/&gt;  const [visible, setVisible] = useState(&lt;span&gt;false&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; (&lt;br/&gt;    &amp;lt;&amp;gt;&lt;br/&gt;      &amp;lt;Button&lt;br/&gt;        onClick={() =&amp;gt; {&lt;br/&gt;          /** 整理后的信息 */&lt;br/&gt;          const info: InfoDataList[] = [];&lt;br/&gt;&lt;br/&gt;          // 这里是提取界面信息&lt;br/&gt;          $(&lt;span&gt;&quot;.info&quot;&lt;/span&gt;).each(&lt;span&gt;function&lt;/span&gt; (this) {&lt;br/&gt;            const infoItem: InfoDataList = {} as InfoDataList;&lt;br/&gt;            // 这里是所有的信息，下面组件提取各种信息&lt;br/&gt;            $(this)&lt;br/&gt;              .find(&lt;span&gt;&quot;.title&quot;&lt;/span&gt;)&lt;br/&gt;              .each(&lt;span&gt;function&lt;/span&gt; (this, index) {&lt;br/&gt;                // 只取第一个电影名字&lt;br/&gt;                &lt;span&gt;if&lt;/span&gt; (index === 0) infoItem.title = this.innerHTML;&lt;br/&gt;              });&lt;br/&gt;&lt;br/&gt;            // 取分数&lt;br/&gt;            $(this)&lt;br/&gt;              .find(&lt;span&gt;&quot;.rating_num&quot;&lt;/span&gt;)&lt;br/&gt;              .each(&lt;span&gt;function&lt;/span&gt; (this) {&lt;br/&gt;                infoItem.score = this.innerHTML;&lt;br/&gt;              });&lt;br/&gt;&lt;br/&gt;            // 评价数&lt;br/&gt;            $(this)&lt;br/&gt;              .find(&lt;span&gt;&quot;.star &amp;gt; span:nth-child(4)&quot;&lt;/span&gt;)&lt;br/&gt;              .each(&lt;span&gt;function&lt;/span&gt; (this) {&lt;br/&gt;                infoItem.number = this.innerHTML;&lt;br/&gt;              });&lt;br/&gt;&lt;br/&gt;            // 取信息&lt;br/&gt;            $(this)&lt;br/&gt;              .find(&lt;span&gt;&quot;.inq&quot;&lt;/span&gt;)&lt;br/&gt;              .each(&lt;span&gt;function&lt;/span&gt; (this) {&lt;br/&gt;                infoItem.info = this.innerHTML;&lt;br/&gt;              });&lt;br/&gt;&lt;br/&gt;            info.push(infoItem);&lt;br/&gt;          });&lt;br/&gt;&lt;br/&gt;          setInfoDataList(info);&lt;br/&gt;          // 打开弹窗&lt;br/&gt;          setVisible(&lt;span&gt;true&lt;/span&gt;);&lt;br/&gt;        }}&lt;br/&gt;        style={{ position: &quot;fixed&quot;, right: &quot;100px&quot;, bottom: &quot;100px&quot; }}&lt;br/&gt;      &amp;gt;&lt;br/&gt;        点我&lt;br/&gt;      &amp;lt;/Button&amp;gt;&lt;br/&gt;      &amp;lt;Modal&lt;br/&gt;        title=&lt;span&gt;&quot;自动对字段&quot;&lt;/span&gt;&lt;br/&gt;        visible={visible}&lt;br/&gt;        centered&lt;br/&gt;        destroyOnClose&lt;br/&gt;        width={1000}&lt;br/&gt;        onCancel={() =&amp;gt; {&lt;br/&gt;          setVisible(&lt;span&gt;false&lt;/span&gt;);&lt;br/&gt;        }}&lt;br/&gt;      &amp;gt;&lt;br/&gt;        &amp;lt;Form&lt;br/&gt;          preserve={&lt;span&gt;false&lt;/span&gt;}&lt;br/&gt;          onValuesChange={async (value) =&amp;gt; {&lt;br/&gt;            // 如果没有值，则不匹配&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (!value.text) {&lt;br/&gt;              setShowData(undefined);&lt;br/&gt;              &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;            }&lt;br/&gt;            const rgx = RegExp(value.text);&lt;br/&gt;&lt;br/&gt;            const data = infoDataList.find((item) =&amp;gt; rgx.test(item.title));&lt;br/&gt;            setShowData(data);&lt;br/&gt;          }}&lt;br/&gt;        &amp;gt;&lt;br/&gt;          &amp;lt;Form.Item name=&lt;span&gt;&quot;text&quot;&lt;/span&gt;&amp;gt;&lt;br/&gt;            &amp;lt;TextArea rows={10} /&amp;gt;&lt;br/&gt;          &amp;lt;/Form.Item&amp;gt;&lt;br/&gt;        &amp;lt;/Form&amp;gt;&lt;br/&gt;        {/* 这里是将对的字段展示出来 */}&lt;br/&gt;        &amp;lt;ul&amp;gt;&lt;br/&gt;          &amp;lt;li&amp;gt;电影名：{showData?.title}&amp;lt;/li&amp;gt;&lt;br/&gt;          &amp;lt;li&amp;gt;分数：{showData?.score}&amp;lt;/li&amp;gt;&lt;br/&gt;          &amp;lt;li&amp;gt;评价数：{showData?.number}&amp;lt;/li&amp;gt;&lt;br/&gt;          &amp;lt;li&amp;gt;简介：{showData?.info}&amp;lt;/li&amp;gt;&lt;br/&gt;        &amp;lt;/ul&amp;gt;&lt;br/&gt;      &amp;lt;/Modal&amp;gt;&lt;br/&gt;    &amp;lt;/&amp;gt;&lt;br/&gt;  );&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// 添加一个div作为React的入口文件&lt;br/&gt;$(&lt;span&gt;&quot;body&quot;&lt;/span&gt;).append(`&amp;lt;div id=&lt;span&gt;&quot;ccll-app&quot;&lt;/span&gt;/&amp;gt;`);&lt;br/&gt;&lt;br/&gt;render(&lt;br/&gt;  &amp;lt;ConfigProvider locale={zhCN}&amp;gt;&lt;br/&gt;    &amp;lt;AppButton /&amp;gt;&lt;br/&gt;  &amp;lt;/ConfigProvider&amp;gt;,&lt;br/&gt;  document.getElementById(&lt;span&gt;&quot;ccll-app&quot;&lt;/span&gt;)&lt;br/&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7. webpack配置&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面是我自己搭建并且使用的一套&lt;code&gt;webpack.config.js&lt;/code&gt;，添加了对&lt;code&gt;CSS&lt;/code&gt;、&lt;code&gt;TypeScript&lt;/code&gt;、&lt;code&gt;Less&lt;/code&gt;的支持，并且还对&lt;code&gt;JavaScript&lt;/code&gt;做了兼容性处理，可以直接将下面的代码复制过去尝试。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;const { resolve } = require(&lt;span&gt;&quot;path&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;module.exports = {&lt;br/&gt;  entry: [&lt;span&gt;&quot;./index.js&quot;&lt;/span&gt;],&lt;br/&gt;  output: {&lt;br/&gt;    path: resolve(__dirname, &lt;span&gt;&quot;build&quot;&lt;/span&gt;),&lt;br/&gt;    filename: &lt;span&gt;&quot;index.js&quot;&lt;/span&gt;,&lt;br/&gt;    publicPath: &lt;span&gt;&quot;/&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  module: {&lt;br/&gt;    rules: [&lt;br/&gt;      {&lt;br/&gt;        &lt;span&gt;test&lt;/span&gt;: /.(js|jsx|mjs)$/,&lt;br/&gt;        exclude: /node_modules/,&lt;br/&gt;        use: [&lt;br/&gt;          {&lt;br/&gt;            loader: &lt;span&gt;&quot;babel-loader&quot;&lt;/span&gt;,&lt;br/&gt;            options: {&lt;br/&gt;              // 预设：指示babel做怎么样的兼容性处理。&lt;br/&gt;              presets: [&lt;br/&gt;                [&lt;br/&gt;                  &lt;span&gt;&quot;@babel/preset-env&quot;&lt;/span&gt;,&lt;br/&gt;                  {&lt;br/&gt;                    corejs: {&lt;br/&gt;                      version: 3,&lt;br/&gt;                    }, // 按需加载&lt;br/&gt;                    useBuiltIns: &lt;span&gt;&quot;usage&quot;&lt;/span&gt;,&lt;br/&gt;                  },&lt;br/&gt;                ],&lt;br/&gt;                &lt;span&gt;&quot;@babel/preset-react&quot;&lt;/span&gt;,&lt;br/&gt;              ],&lt;br/&gt;            },&lt;br/&gt;          },&lt;br/&gt;        ],&lt;br/&gt;      },&lt;br/&gt;      {&lt;br/&gt;        &lt;span&gt;test&lt;/span&gt;: /.tsx?$/,&lt;br/&gt;        use: &lt;span&gt;&quot;ts-loader&quot;&lt;/span&gt;,&lt;br/&gt;        exclude: /node_modules/,&lt;br/&gt;      },&lt;br/&gt;      {&lt;br/&gt;        &lt;span&gt;test&lt;/span&gt;: /.css$/,&lt;br/&gt;        // 使用哪些 loader 进行处理&lt;br/&gt;        use: [&lt;br/&gt;          // use 数组中 loader 执行顺序：从右到左，从下到上 依次执行&lt;br/&gt;          // 创建 style 标签，将 js 中的样式资源插入进行，添加到 head 中生效&lt;br/&gt;          &lt;span&gt;&quot;style-loader&quot;&lt;/span&gt;,&lt;br/&gt;          // 将 css 文件变成 commonjs 模块加载 js 中，里面内容是样式字符串&lt;br/&gt;          &lt;span&gt;&quot;css-loader&quot;&lt;/span&gt;,&lt;br/&gt;        ],&lt;br/&gt;      },&lt;br/&gt;      {&lt;br/&gt;        &lt;span&gt;test&lt;/span&gt;: /.less$/,&lt;br/&gt;        // 使用哪些 loader 进行处理&lt;br/&gt;        use: [&lt;br/&gt;          // use 数组中 loader 执行顺序：从右到左，从下到上 依次执行&lt;br/&gt;          // 创建 style 标签，将 js 中的样式资源插入进行，添加到 head 中生效&lt;br/&gt;          &lt;span&gt;&quot;style-loader&quot;&lt;/span&gt;,&lt;br/&gt;          // 将 css 文件变成 commonjs 模块加载 js 中，里面内容是样式字符串&lt;br/&gt;          &lt;span&gt;&quot;css-loader&quot;&lt;/span&gt;,&lt;br/&gt;          {&lt;br/&gt;            loader: &lt;span&gt;&quot;less-loader&quot;&lt;/span&gt;,&lt;br/&gt;            options: {&lt;br/&gt;              lessOptions: {&lt;br/&gt;                javascriptEnabled: &lt;span&gt;true&lt;/span&gt;,&lt;br/&gt;              },&lt;br/&gt;            },&lt;br/&gt;          },&lt;br/&gt;        ],&lt;br/&gt;      },&lt;br/&gt;    ],&lt;br/&gt;  },&lt;br/&gt;  resolve: {&lt;br/&gt;    extensions: [&lt;span&gt;&quot;.tsx&quot;&lt;/span&gt;, &lt;span&gt;&quot;.ts&quot;&lt;/span&gt;, &lt;span&gt;&quot;.js&quot;&lt;/span&gt;],&lt;br/&gt;  },&lt;br/&gt;  mode: &lt;span&gt;&quot;production&quot;&lt;/span&gt;,&lt;br/&gt;  devtool: &lt;span&gt;&quot;source-map&quot;&lt;/span&gt;,&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;8. 最后&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本篇文章没有拿我的那个最终实现的脚本进行演示，而是模拟了另一个例子，主要是起到一个抛砖引玉的作用，我想表达的意思就是&lt;strong&gt;油猴被我们前端开发者所忽略了，其实它是一个非常好的能够提升开发效率的工具&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从文章中可以看到，编写一个脚本需要掌握的知识还是比较多的，尤其是jQuery和正则，当然如果你对原生js熟悉的话，你完全可以使用原生js代码来代替jQuery的那些代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就我个人编写油猴脚本的经验来讲，jQuery几乎在每个脚本中都会用到，虽然用到的东西不是特别深，主要是提取界面信息，而正则用到的也非常多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实这里还留下了一个问题，就是引入了&lt;code&gt;React&lt;/code&gt;+&lt;code&gt;Antd&lt;/code&gt;后，打包的时间往往会达到10s左右，而打包后的代码通常会达到2M左右，下一篇文章就讲如何在油猴中使用CDN引入，让打包时间减少到1s左右，代码体积减少到几十kb左右。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过这次的灵光乍现，我想到平时在写业务代码时，一些重复的机械的工作都可以交给脚本去实现，提高自己的开发效率，做一个准点下班的程序员。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>