<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>d533b06d2a3aeb6393d9ff4b9ce791d8</guid>
<title>一文详解扩散模型：DDPM</title>
<link>https://toutiao.io/k/pulcqkj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h4&gt;&lt;strong&gt;作者：京东零售 刘岩&lt;/strong&gt;&lt;/h4&gt;

&lt;h1&gt;扩散模型讲解&lt;/h1&gt;

&lt;h2&gt;前沿&lt;/h2&gt;

&lt;p&gt;人工智能生成内容（AI Generated Content，AIGC）近年来成为了非常前沿的一个研究方向，生成模型目前有四个流派，分别是生成对抗网络（Generative Adversarial Models，GAN），变分自编码器（Variance Auto-Encoder，VAE），标准化流模型（Normalization Flow， NF）以及这里要介绍的扩散模型（Diffusion Models，DM）。扩散模型是受到热力学中的一个分支，它的思想来源是非平衡热力学（Non-equilibrium thermodynamics）。扩散模型的算法理论基础是通过变分推断（Variational Inference）训练参数化的马尔可夫链（Markov Chain），它在许多任务上展现了超过GAN等其它生成模型的效果，例如最近非常火热的OpenAI的DALL-E 2，Stability.ai的Stable Diffusion等。这些效果惊艳的模型扩散模型的理论基础便是我们这里要介绍的提出扩散模型的文章[1]和非常重要的DDPM[2]，扩散模型的实现并不复杂，但其背后的数学原理却非常丰富。在这里我会介绍这些重要的数学原理，但省去了这些公式的推导计算，如果你对这些推导感兴趣，可以学习参考文献[4,5,11]的相关内容。我在这里主要以一个相对简单的角度来讲解扩散模型，帮助你快速入门这个非常重要的生成算法。&lt;/p&gt;

&lt;h2&gt;1. 背景知识: 生成模型&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b35372caf579b4088aa6d7c466f12dfeed9.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;目前生成模型主要有图1所示的四类。其中GAN的原理是通过判别器和生成器的互相博弈来让生成器生成足以以假乱真的图像。VAE的原理是通过一个编码器将输入图像编码成特征向量，它用来学习高斯分布的均值和方差，而解码器则可以将特征向量转化为生成图像，它侧重于学习生成能力。流模型是从一个简单的分布开始，通过一系列可逆的转换函数将分布转化成目标分布。扩散模型先通过正向过程将噪声逐渐加入到数据中，然后通过反向过程预测每一步加入的噪声，通过将噪声去掉的方式逐渐还原得到无噪声的图像，扩散模型本质上是一个马尔可夫架构，只是其中训练过程用到了深度学习的BP，但它更属于数学层面的创新。这也就是为什么很多计算机的同学看扩散模型相关的论文会如此费力。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e5ee1ec9f3394e07bd29a6f8b08f49ac%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_1.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图1：生成模型的四种类型 [4]&lt;/p&gt;

&lt;p&gt;扩散模型中最重要的思想根基是马尔可夫链，它的一个关键性质是平稳性。即如果一个概率随时间变化，那么再马尔可夫链的作用下，它会趋向于某种平稳分布，时间越长，分布越平稳。如图2所示，当你向一滴水中滴入一滴颜料时，无论你滴在什么位置，只要时间足够长，最终颜料都会均匀的分布在水溶液中。这也就是扩散模型的前向过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8686ee33155e4057988a594858ac1b7a%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_2.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图2：颜料分子在水溶液中的扩散过程&lt;/p&gt;

&lt;p&gt;如果我们能够在扩散的过程颜料分子的位置、移动速度、方向等移动属性。那么也可以根据正向过程的保存的移动属性从一杯被溶解了颜料的水中反推颜料的滴入位置。这边是扩散模型的反向过程。记录移动属性的快照便是我们要训练的模型。&lt;/p&gt;

&lt;h3&gt;2. 扩散模型&lt;/h3&gt;

&lt;p&gt;在这一部分我们将集中介绍扩散模型的数学原理以及推导的几个重要性质，因为推导过程涉及大量的数学知识但是对理解扩散模型本身思想并无太大帮助，所以这里我会省去推导的过程而直接给出结论。但是我也会给出推导过程的出处，对其中的推导过程比较感兴趣的请自行查看。&lt;/p&gt;

&lt;h4&gt;2.1 计算原理&lt;/h4&gt;

&lt;p&gt;扩散模型简单的讲就是通过神经网络学习从纯噪声数据逐渐对数据进行去噪的过程，它包含两个步骤，如图3：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-53d22dbd9ac0e75ed50fd292909a6079957.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/df9ff9ba24a146658ed124607bf495c1%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_3.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图3：DDPM的前向加噪和后向去噪过程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4461c951853c3e8234f9df3cc159e71d869.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.1 前向过程&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-61c9bd6062262503faa96fa4cf31ba7e38a.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a642b6099d5eb4b0c08752adb46205fb532.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.2 后向过程&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-93dbc0d9867a95b4ae21476c068827e63b0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.3 目标函数&lt;/h4&gt;

&lt;p&gt;那么问题来了，我们究竟使用什么样的优化目标才能比较好的预测高斯噪声的分布呢？一个比较复杂的方式是使用变分自编码器的最大化证据下界（Evidence Lower Bound, ELBO）的思想来推导，如式(6)，推导详细过程见论文[11]的式(47)到式(58)，这里主要用到了贝叶斯定理和琴生不等式。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-48ea665f2dafa4ee17686d0e29bffc910a4.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;式(6)的推导细节并不重要，我们需要重点关注的是它的最终等式的三个组成部分，下面我们分别介绍它们：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c5d9c7467bc0258b4fc0cbffcc14e27ba52.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e23fcc641f454a6b846d97fbe8010dda%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_4.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图4：扩散模型的去噪匹配项在每一步都要拟合噪音的真实后验分布和估计分布&lt;/p&gt;

&lt;p&gt;真实后验分布可以使用贝叶斯定理进行推导，最终结果如式(8)，推导过程见论文[11]的式(71)到式(84)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b0def3f1985ebf2a6011cd37ef3d710aa39.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1b1640b37c37b8a0439ebf9046c7e990418.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;\(p{\boldsymbol{\theta}}\left(\boldsymbol{x}{t-1} \mid \boldsymbol{x}t\right) = \mathcal N(\boldsymbol x{t-1}; \mu\theta(\boldsymbol x_t, t), \Sigma_q(t)) \tag9\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b30476658b394d0b2a107e243965a2577d5.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4203a42c77277969e683d070453f222e497.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8ceb423af6ecd50cb25139eb9130d76c3f0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8ec4359ea3ccc0150c6cf59fd053998f1e3.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.4 模型训练&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-73ef2dbc80d583bc5a25bf5972c9a423680.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;虽然上面我们介绍了很多内容，并给出了大量公式，但得益于推导出的几个重要性质，扩散模型的训练并不复杂，它的训练伪代码见算法1。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0f071ea6ca0146878914cb9a33e041ca%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_ag1.png&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;2.1.5 样本生成&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0be5c14e1d629154e6ad509bba2d6fc0d92.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c198a3c52e4486d96d6c414fd57c630%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_ag2.png&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;2.2 算法实现&lt;/h3&gt;

&lt;h4&gt;2.2.1模型结构&lt;/h4&gt;

&lt;p&gt;DDPM在预测施加的噪声时，它的输入是施加噪声之后的图像，预测内容是和输入图像相同尺寸的噪声，所以它可以看做一个Img2Img的任务。DDPM选择了U-Net[9]作为噪声预测的模型结构。U-Net是一个U形的网络结构，它由编码器，解码器以及编码器和解码器之间的跨层连接（残差连接）组成。其中编码器将图像降采样成一个特征，解码器将这个特征上采样为目标噪声，跨层连接用于拼接编码器和解码器之间的特征。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c150054c5fe242f191439c05398856ea%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_5.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图5：U-Net的网络结构&lt;/p&gt;

&lt;p&gt;下面我们介绍DDPM的模型结构的重要组件。首先在U-Net的卷积部分，DDPM使用了宽残差网络（Wide Residual Network，WRN）[12]作为核心结构，WRN是一个比标准残差网络层数更少，但是通道数更多的网络结构。也有作者复现发现ConvNeXT作为基础结构会取得非常显著的效果提升[13,14]。这里我们可以根据训练资源灵活的调整卷积结构以及具体的层数等超参。因为我们在扩散过程的整个流程中都共享同一套参数，为了区分不同的时间片，作者借鉴了Transformer [15]的位置编码的思想，采用了正弦位置嵌入对时间$t$进行了编码，这使得模型在预测噪声时知道它预测的是批次中分别是哪个时间片添加的噪声。在卷积层之间，DDPM添加了一个注意力层。这里我们可以使用Transformer中提出的自注意力机制或是多头自注意力机制。[13]则提出了一个线性注意力机制的模块，它的特点是消耗的时间以及占用的内存和序列长度是线性相关的，对比传统注意力机制的平方相关要高效很多。在进行归一化时，DDPM选择了组归一化（Group Normalization，GN）[16]。最后，对于U-Net中的降采样和上采样操作，DDPM分别选择了步长为2的卷积以及反卷积。&lt;/p&gt;

&lt;p&gt;确定了这些组件，我们便可以搭建用于DDPM的U-Net的模型了。从第2.1节的介绍我们知道，模型的输入为形状为(batch_size, num_channels, height, width)的噪声图像和形状为(batch_size,1)的噪声水平，返回的是形状为(batch_size, num_channels, height, width)的预测噪声，我们搭建的用于噪声预测的模型结构如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 首先在噪声图像\( \boldsymbol x_0\)上应用卷积层，并为噪声水平$t$计算时间嵌入；&lt;/li&gt;
&lt;li&gt; 接下来是降采样阶段。采用的模型结构依次是两个卷积（WRNS或是ConvNeXT）+GN+Attention+降采样层；&lt;/li&gt;
&lt;li&gt; 在网络的最中间，依次是卷积层+Attention+卷积层；&lt;/li&gt;
&lt;li&gt; 接下来是上采样阶段。它首先会使用Short-cut拼接来自降采样中同样尺寸的卷积，再之后是两个卷积+GN+Attention+上采样层。&lt;/li&gt;
&lt;li&gt; 最后是使用WRNS或是ConvNeXT作为输出层的卷积。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;U-Net类的forword函数如下面代码片段所示，完整的实现代码参照[3]。&lt;/p&gt;

&lt;pre lang=&quot;python&quot;&gt;&lt;code&gt;def forward(self, x, time):
    x = self.init_conv(x)
    t = self.time_mlp(time) if exists(self.time_mlp) else None
    h = []
    # downsample
    for block1, block2, attn, downsample in self.downs:
        x = block1(x, t)
        x = block2(x, t)
        x = attn(x)
        h.append(x)
        x = downsample(x)
    # bottleneck
    x = self.mid_block1(x, t)
    x = self.mid_attn(x)
    x = self.mid_block2(x, t)
    # upsample
    for block1, block2, attn, upsample in self.ups:
        x = torch.cat((x, h.pop()), dim=1)
        x = block1(x, t)
        x = block2(x, t)
        x = attn(x)
        x = upsample(x)
    return self.final_conv(x)




&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2.2.2 前向加噪&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-30ecf8ea1e3f8e121c12c1860b7b12c4ac9.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/963eee81349d406d95c18fa29805fb98%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_6.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图6：一张图依次经过0次，50次，100次，150次以及199次加噪后的效果图&lt;/p&gt;

&lt;p&gt;根据式(14)我们知道，扩散模型的损失函数计算的是两张图像的相似性，因此我们可以选择使用回归算法的所有损失函数，以MSE为例，前向过程的核心代码如下面代码片段。&lt;/p&gt;

&lt;pre lang=&quot;python&quot;&gt;&lt;code&gt;def p_losses(denoise_model, x_start, t, noise=None, loss_type=&quot;l1&quot;):
    # 1. 根据时刻t计算随机噪声分布，并对图像x_start进行加噪
    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)
    # 2. 根据噪声图像以及时刻t，预测添加的噪声
    predicted_noise = denoise_model(x_noisy, t)
    # 3. 对比添加的噪声和预测的噪声的相似性
    loss = F.mse_loss(noise, predicted_noise)
    return loss




&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2.2.3 样本生成&lt;/h4&gt;

&lt;p&gt;根据2.1.5节介绍的样本生成流程，它的核心代码片段所示，关于这段代码的讲解我通过注释添加到了代码片段中。&lt;/p&gt;

&lt;pre lang=&quot;python&quot;&gt;&lt;code&gt;@torch.no_grad()
def p_sample(model, x, t, t_index):
    betas_t = extract(betas, t, x.shape)
    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape)
    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)
    # 使用式(13)计算模型的均值
    model_mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t)
    if t_index == 0:
        return model_mean
    else:
        # 获取保存的方差
        posterior_variance_t = extract(posterior_variance, t, x.shape)
        noise = torch.randn_like(x)
        # 算法2的第4行
        return model_mean + torch.sqrt(posterior_variance_t) * noise 

# 算法2的流程，但是我们保存了所有中间样本
@torch.no_grad()
def p_sample_loop(model, shape):
    device = next(model.parameters()).device
    b = shape[0]
    # start from pure noise (for each example in the batch)
    img = torch.randn(shape, device=device)
    imgs = []
    for i in tqdm(reversed(range(0, timesteps)), desc=&#x27;sampling loop time step&#x27;, total=timesteps):
        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)
        imgs.append(img.cpu().numpy())
    return imgs




&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后我们看下在人脸图像数据集下训练的模型，一批随机噪声经过逐渐去噪变成人脸图像的示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f7df428bb1c34532836ffda5aac66c31%7Etplv-k3u1fbpfcp-watermark.image?&quot; alt=&quot;DDPM_7.gif&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图7：扩散模型由随机噪声通过去噪逐渐生成人脸图像&lt;/p&gt;

&lt;h2&gt;3. 总结&lt;/h2&gt;

&lt;p&gt;这里我们以DDPM为例介绍了另一个派系的生成算法：扩散模型。扩散模型是一个基于马尔可夫链的数学模型，它通过预测每个时间片添加的噪声来进行模型的训练。作为近日来引发热烈讨论的ControlNet， Stable Diffusion等模型的底层算法，我们十分有必要对其有所了解。DDPM的实现并不复杂，这得益于大量数学界大佬通过大量的数学推导将整个扩散过程和反向去噪过程进行了精彩的化简，这才有了DDPM的大道至简的实现。DDPM作为一个扩散模型的基石算法，它有着很多早期算法的共同问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; 采样速度慢：DDPM的去噪是从时刻$T$到时刻$1$的一个完整的马尔可夫链的计算，尤其是DDPM还需要一个比较大的$T$才能保证比较好的效果，这就导致了DDPM的采样过程注定是非常慢的；&lt;/li&gt;
&lt;li&gt; 生成效果差：DDPM的效果并不能说是非常好，尤其是对于高分辨率图像的生成。这一方面是因为它的计算速度限制了它扩展到更大的模型；另一方面它的设计还有一些问题，例如逐像素的计算损失并使用相同权值而忽略图像中的主体并不是非常好的策略。&lt;/li&gt;
&lt;li&gt; 内容不可控：我们可以看出，DDPM生成的内容完全还是取决于它的训练集。它并没有引入一些先验条件，因此并不能通过控制图像中的细节来生成我们制定的内容。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们现在已经知道，DDPM的这些问题已大幅得到改善，现在基于扩散模型生成的图像已经达到甚至超过人类多数的画师的效果，我也会在之后逐渐给出这些优化方案的讲解。&lt;/p&gt;

&lt;h2&gt;Reference&lt;/h2&gt;

&lt;p&gt;[1] Sohl-Dickstein, Jascha, et al. &quot;Deep unsupervised learning using nonequilibrium thermodynamics.&quot; &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;. PMLR, 2015.&lt;/p&gt;

&lt;p&gt;[2] Ho, Jonathan, Ajay Jain, and Pieter Abbeel. &quot;Denoising diffusion probabilistic models.&quot; &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt; 33 (2020): 6840-6851.&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://huggingface.co/blog/annotated-diffusion&quot;&gt;https://huggingface.co/blog/annotated-diffusion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#simplification&quot;&gt;https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#simplification&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://openai.com/blog/generative-models/&quot;&gt;https://openai.com/blog/generative-models/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] Nichol, Alexander Quinn, and Prafulla Dhariwal. &quot;Improved denoising diffusion probabilistic models.&quot; &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;. PMLR, 2021.&lt;/p&gt;

&lt;p&gt;[7] Kingma, Diederik P., and Max Welling. &quot;Auto-encoding variational bayes.&quot; &lt;em&gt;arXiv preprint arXiv:1312.6114&lt;/em&gt; (2013).&lt;/p&gt;

&lt;p&gt;[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. &quot;Reducing the dimensionality of data with neural networks.&quot; &lt;em&gt;science&lt;/em&gt; 313.5786 (2006): 504-507.&lt;/p&gt;

&lt;p&gt;[9] Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.&lt;/p&gt;

&lt;p&gt;[10] Long, Jonathan, Evan Shelhamer, and Trevor Darrell. &quot;Fully convolutional networks for semantic segmentation.&quot; &lt;em&gt;Proceedings of the IEEE conference on computer vision and pattern recognition&lt;/em&gt;. 2015.&lt;/p&gt;

&lt;p&gt;[11] Luo, Calvin. &quot;Understanding diffusion models: A unified perspective.&quot; &lt;em&gt;arXiv preprint arXiv:2208.11970&lt;/em&gt; (2022).&lt;/p&gt;

&lt;p&gt;[12] Zagoruyko, Sergey, and Nikos Komodakis. &quot;Wide residual networks.&quot; &lt;em&gt;arXiv preprint arXiv:1605.07146&lt;/em&gt; (2016).&lt;/p&gt;

&lt;p&gt;[13] &lt;a href=&quot;https://github.com/lucidrains/denoising-diffusion-pytorch&quot;&gt;https://github.com/lucidrains/denoising-diffusion-pytorch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[14] Liu, Zhuang, et al. &quot;A convnet for the 2020s.&quot; &lt;em&gt;Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition&lt;/em&gt;. 2022.&lt;/p&gt;

&lt;p&gt;[15] Vaswani, Ashish, et al. &quot;Attention is all you need.&quot; &lt;em&gt;Advances in neural information processing systems&lt;/em&gt; 30 (2017).&lt;/p&gt;

&lt;p&gt;[16] Wu, Yuxin, and Kaiming He. &quot;Group normalization.&quot; &lt;em&gt;Proceedings of the European conference on computer vision (ECCV)&lt;/em&gt;. 2018.&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7516b1aa46398c0bf027d3ba990a4806</guid>
<title>研发提效利器：聊聊 mock 服务化</title>
<link>https://toutiao.io/k/uw0f4l3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;老张的求知思考世界&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;For-Think&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;专注互联网领域相关技术实践和思考，也分享职场成长、读书杂谈等内容。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1db2c9e25b2e4c3ce8bcef672eb9742e</guid>
<title>借助这款 AI 工具，立马让你成为大师级绘画选手</title>
<link>https://toutiao.io/k/2draq0s</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content              autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;AI绘画是一项新兴的技术，它利用人工智能算法和机器学习技术，能够自动地生成艺术作品，如绘画、插图、图像、视频等，放在今天看已经不是新技术了，去年就已经火爆起来了，只不过今年借着ChatGPT的东风再次被提及，之前的文章中有介绍几款AI绘画的应用（参看：&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwMjE3MDIwMA==&amp;amp;mid=2247487276&amp;amp;idx=1&amp;amp;sn=b758c662aaf3b17beaf7fabe5146733d&amp;amp;chksm=96e3851ba1940c0dcdad646c4a41ec898d6cf49514f63bdaf9daacd35885303ce62a396ce902&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;ChatGPT 大行其道，带你走近 AIGC&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;ChatGPT 大行其道，带你走进 AIGC&lt;/a&gt;）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不会色彩搭配，不懂素描技巧，也没有实践过，又想画出精彩的画片，究竟可不可能？放在以前可能被认为天方夜谭，现在有了AI的加持已经可以轻松应用。借助NLP技术，你只要把画面描述的足够清晰，剩下的工具交给AI，安静的等几分钟就可以了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看几张图感受一下 AI 绘画的魅力吧。（以下图片均出自Midjourney，文末有体验地址）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提示词：&lt;span&gt;大漠孤烟直,长河落日圆&lt;/span&gt; &lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/EwukgicNDWBv2Pq3HeMfvDWx6yyuR4X9fodUomDowkQTnc64eGLNgicGgwqIgqr8HXSPHqp9VDVQpe0ad3gWkWqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于图1，使用V1指令&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/EwukgicNDWBv2Pq3HeMfvDWx6yyuR4X9fSg5JgZAQGiaCkoY3ic1y8kIic6cbHHu9vfU60ffBOMaxYrt5Ypynx5KVQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提示词：&lt;span&gt;飞流直下三干尺,疑是银河落九天&lt;/span&gt; &lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/EwukgicNDWBv2Pq3HeMfvDWx6yyuR4X9f6cWobgC4cJbttghP6W8ciaT146QQez97wZYqW7p2fr9EWlWje0lAibJg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于图1，使用V1指令&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/EwukgicNDWBv2Pq3HeMfvDWx6yyuR4X9f2NIs3MdpHLIPFYTpicD9IyJVTBBuYZfEMHicKGA7KVk8tKArGEvBfrbA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提示词：&lt;span&gt;左边是树，远处是山，右侧近处是小的灌木，整体色调黄绿&lt;/span&gt; &lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/EwukgicNDWBv2Pq3HeMfvDWx6yyuR4X9fJCzjyvVs69pyAy3VhxNdqZAVF8JliaL0WzkoDYrcicMTs2AEP33NGeqg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提示词：&lt;span&gt;几个可爱的孩子飞向太空，卡通风格&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/EwukgicNDWBv2Pq3HeMfvDWx6yyuR4X9fOQTwAy3Aoy8rJtr4zT71gUe9Kkwc3lFDRF6icgiaeEvx6bNwLU3MicsEw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;怎么做到的呢？这是 Midjourney 中国版内测QQ频道创作的内容，绘画时提供”想象“与”漫画“两个模式，使用方式也极为简单，在频道的开放区域，向机器人描述相关的信息即可，生成图片后，机器人会@你，提供U和V两种形式的指令，按上下左右4张图的顺序，U1/U2/U3/U4-放大，V1/V2/V3/V4-变化（变化就是在此图的基础上继续生成新图，直到自己满意为止，如第二组图是基于第一组图的图1变化而来）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Midjourney是一个由Midjourney研究实验室开发的人工智能程序，可在公开测试阶段（2022年7月12日）内完成以下各项操作，使用者可借助机器人指令在Discord平台上进行，是目前AI绘画商业化领域绝对的王者，出图的效果极佳。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;人像卡通化：将人物照片转换成有趣的卡通形象。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;轮廓生成：根据输入的文字描述生成对应的图像轮廓。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;色彩生成：利用GAN模型生成具有艺术感和创意的彩色图像。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;视频换脸：对视频中人物的面部进行换脸操作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;视觉问答：通过图像识别和自然语言处理技术回答有关图像的提问。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;人脸合成：将不同人物的面部特征进行合成，生成新的面孔。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;关注公众号后回复 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;MJ &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;即可获取&lt;/span&gt;&lt;strong&gt;&lt;span&gt;体验资格的申请地址&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-weui-theme=&quot;light&quot; data-id=&quot;MzIwMjE3MDIwMA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/EwukgicNDWBswFxJHbKiad1jnJCFQiaWQrRnSdQGnrHiaicTyc2FR4CId2GQk1TABicoY87kQIeoeI1z3GnwanWMg1YQ/0?wx_fmt=png&quot; data-nickname=&quot;MavenTalk&quot; data-alias=&quot;mavenTalk&quot; data-signature=&quot;15+年IT人，创业者，关注人与自然的和谐成长.&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fd3bd46ba7592eddf2b740d489131106</guid>
<title>【云原生 • Docker】Docker 核心 UTS Namespace 原理实践</title>
<link>https://toutiao.io/k/2gwwzi7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;【云原生 • Docker】Docker核心UTS Namespace原理实践&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Docker&lt;/code&gt;三大支柱核心技术：&lt;code&gt;Namespace&lt;/code&gt;、&lt;code&gt;Cgroups&lt;/code&gt;和&lt;code&gt;UnionFS&lt;/code&gt;，这节通过一个&lt;code&gt;UTS Namespace&lt;/code&gt;简单实践小案例，更加直观理解&lt;code&gt;Namespace&lt;/code&gt;资源隔离技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;UTS Namespace&lt;/code&gt; 主要是用来隔离主机名和域名的隔离，它允许每个 &lt;code&gt;UTS Namespace&lt;/code&gt; 拥有一个独立的主机名。例如我们的主机名称为 &lt;code&gt;VM-4-14-centos&lt;/code&gt;，使用 &lt;code&gt;UTS Namespace&lt;/code&gt; 可以实现在容器内的主机名称为 &lt;code&gt;container-docker&lt;/code&gt; 或者其他任意自定义主机名。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;UTS Namespace案例实践&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在进行&lt;code&gt;UTS Namespace&lt;/code&gt;案例实践之前，我们先来了解个关键指令：&lt;strong&gt;「unshare，运行一些与父级不共享某些名称空间的程序。」&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;root@node3:~&lt;span&gt;# unshare --help&lt;/span&gt;&lt;br/&gt;Usage:&lt;br/&gt; unshare [options] &amp;lt;program&amp;gt; [&amp;lt;argument&amp;gt;...]&lt;br/&gt;&lt;br/&gt;Run a program with some namespaces unshared from the parent.&lt;br/&gt;&lt;br/&gt;Options:&lt;br/&gt;-h，--&lt;span&gt;help&lt;/span&gt;&lt;br/&gt;显示帮助文本并退出。&lt;br/&gt;-i，-- ipc 取消共享IPC名称空间。&lt;br/&gt;-m，-- mount 取消共享安装名称空间。&lt;br/&gt;-n，-- net 取消共享网络名称空间。&lt;br/&gt;-p，-- pid 取消共享pid名称空间。另请参见--fork和--mount-proc选项。&lt;br/&gt;-u，-- uts 取消共享UTS名称空间。&lt;br/&gt;-U，--user 取消共享用户名称空间。&lt;br/&gt;-f，-将指定程序fork为取消共享的子进程，而不是直接运行它。这在创建新的pid命名空间时很有用。&lt;br/&gt;--mount-proc [=mountpoint]在运行程序之前，将proc文件系统挂载到mountpoint （默认为/ proc）。这在创建新的pid名称空间时很有用。这也意味着创建一个新的挂载名称空间，因为/ proc挂载否则会破坏系统上的现有程序。新的proc文件系统显式安装为私有文件（由MS_PRIVATE | MS_REC）。&lt;br/&gt;-r，-- map-root-user 仅在当前有效的用户和组ID已映射到新创建的用户名称空间中的超级用户UID和GID之后，才运行该程序。这样即使在没有特权的情况下运行，也可以方便地获得管理新创建的名称空间各个方面所需的功能（例如，在网络名称空间中配置接口或在安装名称空间中安装文件系统）。仅作为一项便利功能，它不支持更复杂的用例，例如映射多个范围的UID和GID。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们通过一个实例来验证下 &lt;code&gt;UTS Namespace&lt;/code&gt; 的作用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、首先我们使用 &lt;code&gt;unshare&lt;/code&gt; 命令来创建一个 &lt;code&gt;UTS Namespace&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# unshare --uts --fork /bin/bash&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建好 &lt;code&gt;UTS Namespace&lt;/code&gt; 后，宿主机&lt;code&gt;shell&lt;/code&gt;下&lt;code&gt;lsns&lt;/code&gt;列出&lt;code&gt;namespace&lt;/code&gt;信息，会发现最后一条就是我们使用&lt;code&gt;unshare&lt;/code&gt;创建了一个&lt;code&gt;uts&lt;/code&gt;类型的&lt;code&gt;namespace&lt;/code&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.19814814814814816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb0hib0az5PRibUuS8dobHA0LPx79ib0iblo1Zqe4JUwmxcic3WFYeadc5KX2PUArjM2TmgR38z7ibk494RA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、回到上步&lt;code&gt;uts&lt;/code&gt;命名空间&lt;code&gt;shell&lt;/code&gt;下，使用 &lt;code&gt;hostname&lt;/code&gt; 命令设置一下主机名：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;VM-4-14-centos&lt;br/&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname -b container-docker&lt;/span&gt;&lt;br/&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;container-docker&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过上面命令的输出，我们可以看到当前 &lt;code&gt;UTS Namespace&lt;/code&gt; 内的主机名已经被修改为 &lt;code&gt;container-docker&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、回到宿主机&lt;code&gt;shell&lt;/code&gt;下，查看一下主机的 &lt;code&gt;hostname&lt;/code&gt;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;VM-4-14-centos&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到主机的名称仍然为 &lt;code&gt;VM-4-14-centos&lt;/code&gt;，并没有被修改，这就是使用&lt;code&gt;UTS Namespace&lt;/code&gt;技术实现主机名隔离功能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;Docker原理验证&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、使用&lt;code&gt;docker run&lt;/code&gt;创建并运行一个&lt;code&gt;Docker&lt;/code&gt;容器：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# docker run -d --name test-nginx --hostname docker-nginx nginx&lt;/span&gt;&lt;br/&gt;0fd5ec42923553ec2600c51ef4f119e4025ebf5adf13561b0e847cd816f332b7&lt;br/&gt;[root@VM-4-14-centos ~]&lt;span&gt;# docker exec -it 0fd sh&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;docker-nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;--hostname指定docker容器的hostname，上面指定--hostname docker-nginx，通过docker exec指令进入到docker容器中，使用hostname查看Docker容器的hostname已被正确修改。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、查看刚创建的Docker容器对应的宿主机&lt;code&gt;PID&lt;/code&gt;信息：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# docker inspect -f {{.State.Pid}} test-nginx&lt;/span&gt;&lt;br/&gt;29424&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或者通过&lt;code&gt;lsns&lt;/code&gt;指令也可以查看到我们刚才创建的Docker容器Namespace信息：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.22314814814814815&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/O2TDJPu7cb0hib0az5PRibUuS8dobHA0LPfMk4ycWJFviclaFYpIP6TMjm8obibV3RyRUdQARviaWgmQ7AqoNWfGwfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、在宿主机&lt;code&gt;shell&lt;/code&gt;下使用&lt;code&gt;nsenter&lt;/code&gt;指令可以进入到Docker容器相同的Namespace下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@VM-4-14-centos ~]&lt;span&gt;# nsenter -t 29424 -u -n&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说明：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;-t：指定被进入命名空间的目标进程的pid，即指定Docker容器在宿主机上对应pid；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-u：进入uts命令空间；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-n：进入net命令空间。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;&lt;strong&gt;「nsenter：一个可以在指定进程的命令空间下运行指定程序的命令。」&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;有很多image内部是没有bash的，所以我们docker exec是无法进入容器的，此时如果还想看一下容器内的情况，其实只需要想办法加入到容器对应的namespace就可以了。我们使用nsenter工具即可实现，该工具启动后会将自己加入到指定的namespace中，然后exec执行我们指定的程序（通常就是bash）。&lt;/p&gt;&lt;p&gt;这个命令大家在容器网络调试下可能常用，比如在一些没有网络调试工具(&lt;code&gt;ip address&lt;/code&gt;，&lt;code&gt;ping&lt;/code&gt;，&lt;code&gt;telnet&lt;/code&gt;，&lt;code&gt;ss&lt;/code&gt;，&lt;code&gt;tcpdump&lt;/code&gt;)的容器内利用宿主机上的命令进行容器内网络连通性的调试等等。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、使用&lt;code&gt;hostname&lt;/code&gt;和&lt;code&gt;ip addr&lt;/code&gt;验证，和Docker容器在相同的&lt;code&gt;UTS Namespace&lt;/code&gt;和&lt;code&gt;Network Namespace&lt;/code&gt;下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[root@docker-nginx ~]&lt;span&gt;# hostname&lt;/span&gt;&lt;br/&gt;docker-nginx&lt;br/&gt;[root@docker-nginx ~]&lt;span&gt;# ip addr&lt;/span&gt;&lt;br/&gt;1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000&lt;br/&gt;    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00&lt;br/&gt;    inet 127.0.0.1/8 scope host lo&lt;br/&gt;       valid_lft forever preferred_lft forever&lt;br/&gt;40: eth0@if41: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default &lt;br/&gt;    link/ether 02:42:ac:11:00:07 brd ff:ff:ff:ff:ff:ff link-netnsid 0&lt;br/&gt;    inet 172.17.0.7/16 brd 172.17.255.255 scope global eth0&lt;br/&gt;       valid_lft forever preferred_lft forever&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>990f7ef9bc04df46f960f9a96adba5de</guid>
<title>如何简单实现 ELT？</title>
<link>https://toutiao.io/k/ofyvyqz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot; itemprop=&quot;articleBody&quot;&gt;&amp;#13;
&lt;p&gt;在商业中，数据通常和业务、企业前景以及财务状况相关，有效的数据管理可以帮助决策者快速有效地从大量数据中分析出有价值的信息。数据集成(Data Integration)是整个数据管理流程中非常重要的一环，它是指将来自多个数据源的数据组合在一起，提供一个统一的视图。&lt;/p&gt;
&lt;p&gt;数据集成可以通过各种技术来实现，本文主要介绍如何用ELT(extract, load, transform)实现数据集成。区别于传统的ETL和其他的技术，ELT非常适合为数据湖仓或数据集市提供数据管道，并且可以用更低的成本，根据需求，随时对大量数据进行分析。&lt;/p&gt;
&lt;p&gt;接下来将通过一个简单的示例（Demo）介绍如何实现ELT流程，具体的需求是将原始的电影票房数据保存到数据仓库，然后再对原始数据进行分析，得出相关的结果并且保存在数据仓库，供数据分析团队使用，帮助他们预测未来的收入。&lt;/p&gt;
&lt;h2&gt;技术栈选择&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Data Warehouse： Snowflake&lt;br/&gt;
Snowflake是最受欢迎，最容易使用的数据仓库之一，并且非常灵活，可以很方便地与AWS、Azure以及Google Cloud集成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Extract：通过k8s的cronjob将数据库的数据存到S3。&lt;/p&gt;
&lt;p&gt;这里的技术选型比较灵活，取决于源数据库的类型以及部署的平台。Demo中将源数据从数据库提取出来后放在AWS S3，原因是Snowflake可以很方便与S3集成，支持复制数据到仓库并且自动刷新。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Load：通过Snowflake的External Tables将S3中的数据复制进数据仓库。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transform：dbt&lt;/p&gt;
&lt;p&gt;dbt支持使用SQL来进行简单的转换，同时提供了命令行工具，使用dbt我们可以进行良好的工程实践比如版本控制，自动化测试以及自动化部署。但对于比较复杂的业务场景来说，转换的过程一般都通过自己写代码实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orchestrator: Airflow&lt;/p&gt;
&lt;p&gt;Airflow和Oozie相比有更加丰富的监控数据以及更友好的UI界面。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图描述了如何使用上述技术栈实现ELT：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-1.png&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-1.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图中使用的Logo来自snowflake，dbt和Airflow的官方网站&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;工具介绍&lt;/h2&gt;
&lt;h3&gt;Snowflake：数据存储&lt;/h3&gt;
&lt;p&gt;Snowflake是一个将全新的SQL查询引擎与一个专为云设计的创新架构相结合的数据云平台，它支持更快更灵活地进行数据存储、处理以及分析。&lt;/p&gt;
&lt;p&gt;示例中将Snowflake作为数据仓库，存储原始数据电影院票房数量以及转换后的数据。&lt;/p&gt;
&lt;h4&gt;权限管理&lt;/h4&gt;
&lt;p&gt;和AWS类似，注册Snowflake后会持有一个拥有所有权限的root account。 如果直接使用此账号进行操作会非常危险，所以可以通过Snowflake提供的user和role来进行细粒度的权限管理。&lt;/p&gt;
&lt;p&gt;最佳实践是用root account创建新的user并通过role赋予足够的权限，后续的操作都使用新创建的user来进行。&lt;/p&gt;
&lt;p&gt;在下面的示例中，创建了一个名为TRANSFORMER的role，并且赋予它足够的权限。然后再创建一个使用这个role的user，在更方便地管理权限的同时，也实践了最小权限原则：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- create role

CREATE ROLE TRANSFORMER COMMENT = &#x27;Role for dbt&#x27;;

-- grant permission to the role

GRANT USAGE, OPERATE ON WAREHOUSE TRANSFORMING TO ROLE TRANSFORMER;

GRANT USAGE, CREATE SCHEMA ON DATABASE PROD TO ROLE TRANSFORMER;

GRANT ALL ON SCHEMA &quot;PROD&quot;.&quot;RAW&quot; TO ROLE TRANSFORMER;

GRANT ALL ON SCHEMA &quot;PROD&quot;.&quot;ANALYTICS&quot; TO ROLE TRANSFORMER;

GRANT SELECT ON ALL TABLES IN SCHEMA &quot;PROD&quot;.&quot;RAW&quot; TO ROLE TRANSFORMER;

GRANT SELECT ON FUTURE TABLES IN SCHEMA &quot;PROD&quot;.&quot;RAW&quot; TO ROLE TRANSFORMER;

-- create user with role TRANSFORMER

create user user_demo password=&#x27;abc123&#x27; default_role = TRANSFORMER must_change_password = true;&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;数据结构&lt;/h4&gt;
&lt;p&gt;每一个Snowflake的数据库都可以有多个schema，这里我们根据常见的实践，创建了schema RAW和ANALYTICS，分别用来存放原始数据和转换之后的数据：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-2.jpg&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-2.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;每一个schema下面都可以有table、view和stage等数据库object。&lt;/p&gt;
&lt;p&gt;stage是snowflake提供的一个空间，它支持我们将数据文件上传到这里，然后通过copy命令把外部数据导入到Snowflake。图中MY_S3_STAGE就是Demo中用来加载存放在AWS S3中的数据文件的，我们过这个stage实现了ELT中的L(Loading)。&lt;/p&gt;
&lt;h3&gt;dbt (data build tool)：原始数据转化&lt;/h3&gt;
&lt;p&gt;在完成了原始数据的&lt;strong&gt;E&lt;/strong&gt;xtract和&lt;strong&gt;L&lt;/strong&gt;oading后，怎样根据需求对它们进行&lt;strong&gt;T&lt;/strong&gt;ransform从而获得隐藏在数据中的有效信息呢？&lt;/p&gt;
&lt;p&gt;这里我们选择dbt来进行数据的转化，它是一个支持我们通过简单地编写select语句来进行数据转换的工具，在Demo中它帮助完成了历史票房数据的统计工作。&lt;/p&gt;
&lt;h4&gt;Model&lt;/h4&gt;
&lt;p&gt;一个model就是一个写在.sql文件中的select语句，通常会默认使用文件名作为transform结果的表名。下面是demo中的一个model，from语句后面跟着的是一个dbt提供的引用源数据的方法。在model目录里的配置文件中声明源数据表之后，就可以直接通过source()方法来引用source table了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select *

from {{ source(&#x27;ticket_sales&#x27;,&#x27;annual_ticket_sales&#x27;) }}

where ticket_year &amp;gt; ‘2010’
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Jinja Function&lt;/h4&gt;
&lt;p&gt;当需求变得更复杂时，如果仅仅通过SQL实现转换将会很困难，所以可以通过Jinja Function来实现在SQL中无法做到的事。&lt;/p&gt;
&lt;p&gt;比如在有多个Model的dbt工程中，通常会有一些可以复用的逻辑，类似于编程语言中的函数。有了Jinja Function，就可以把要复用的逻辑提取成单独的Model，然后在其他Model中通过表达式{{ ref() }}来引用它：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select sum(total_inflation_adjusted_office) as total_sales

from {{ ref(&#x27;annual_ticket_sales&#x27;) }}&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Materializations&lt;/h4&gt;
&lt;p&gt;在上一部分的场景中，通常不希望把可复用的逻辑持久化在数据仓库中。&lt;/p&gt;
&lt;p&gt;这里就可以引入配置Materializations来改变dbt对于model的持久化策略，比如将此配置设置为&lt;strong&gt;Ephemeral&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;{{ config(materialized=&#x27;table&#x27;) }}&lt;/p&gt;
&lt;p&gt;这样model就仅被当作临时表被其他model引用而不会被持久化在数据仓库中。如果设置为View，model就会被在数据仓库中创建为视图。除此之外这个配置还支持类型：Table以及Incremental&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;Test&lt;/h4&gt;
&lt;p&gt;为了防止原始数据有脏数据，所以在这里引入测试帮助保证最后结果的正确性。dbt提供了两种级别的测试：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generic test：这是一种比较通用的测试，为&lt;strong&gt;字段&lt;/strong&gt;级别，它通常可以加在对Source和Target的声明里，应用于某一个字段并且可以重复使用。比如在demo中，我们希望ticket_year这个字段不为空并且是不会重复的：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;    tables:

         - name: annual_ticket_sales

           columns:

             - name: ticket_year

               description: &quot;Which year does the sales amount stands for&quot;

               tests:

                 - not_null

                 - unique

             - name: tickets_sold

               tests:

                 - not_null

             - name: total_box_office

               tests:

                 - not_null
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Singular Test：它是通过一段SQL语句来定义的测试，是&lt;strong&gt;表&lt;/strong&gt;级别。&lt;br/&gt;
比如查询源数据表里total_box_office小于0的记录，当查询不到结果时表示测试通过: &lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;    select total_box_office

    from {{source(&#x27;ticket_sales&#x27;,&#x27;annual_ticket_sales&#x27;)}}

    where total_box_office &amp;lt; 0&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Airflow：任务编排&lt;/h3&gt;
&lt;p&gt;有了把原始数据集成进数据仓库的方法，也完成了数据转化的工程， 那么如何才能让它们有顺序地、定时地运行呢？&lt;/p&gt;
&lt;p&gt;这里我们选择用Airflow进行任务的编排，它是一个支持通过编程编写data pipeline，并且调度和监控各个任务的平台。&lt;/p&gt;
&lt;h4&gt;DAG&lt;/h4&gt;
&lt;p&gt;第一步就是为我们的ELT流程创建一个流水线，在Airflow中，一个DAG(Directed Acyclic Graph)就可以看作是一个pipeline。声明它的时候需要提供一些基本的属性，比如DAG name, 运行间隔以及开始日期等等。&lt;/p&gt;
&lt;p&gt;Airflow支持使用Python语言编写pipeline的代码，因此也具有较强的扩展性。&lt;/p&gt;
&lt;p&gt;Demo中我们设置这个DAG的开始日期是2022年5月20号，并且期望它每天运行一次：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;default_args = {

   &#x27;start_date&#x27;: datetime(2022, 5, 20)

}

with DAG(&#x27;annual_ticket_processing&#x27;, schedule_interval=&#x27;@daily&#x27;,

        default_args=default_args, catchup=True) as dag:
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Task&lt;/h4&gt;
&lt;p&gt;流水线创建完成之后，我们需要将ELT的各个步骤加入到这个流水线中。这里的每一个步骤被称为Task，Task是Airflow中的基本执行单位，类似于pipeline中的step。在Demo中，在数据仓库中创建表、把原始数据加载到数据仓库、测试和数据转化分别是一个task。&lt;/p&gt;
&lt;p&gt;在Airflow中，可以通过Operator快速声明一个task，Operator是一个提前定义好的模版，只需要提供必要的参数比如task id，SQL语句等即可。&lt;/p&gt;
&lt;p&gt;下面这个task的功能是在Snowflake中创建表，需要提供的是一个连接Snowflake的Connection，要运行的SQL语句以及目标database和schema：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;snowflake_create_table = SnowflakeOperator(

       task_id=&#x27;snowflake_create_table&#x27;,

       snowflake_conn_id=&#x27;love_tech_snowflake&#x27;,

       sql=CREATE_TABLE_SQL_STRING,

       database=&#x27;PROD&#x27;,

       schema=&#x27;RAW&#x27;,

   )&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Task dependency&lt;/h4&gt;
&lt;p&gt;当我们对于task的运行顺序有特定要求时，比如为了保证最后报告的准确性，希望在对原始数据的测试通过之后再进行数据转化。这时可以通过定义task之间的依赖关系，来对它们的运行顺序进行编排，如下的依赖关系表示先在Snowflake创建数据表，然后将原数据加载到其中，完成后对于原始数据进行测试，如果测试失败就不会再运行后续的task：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;snowflake_create_table &amp;gt;&amp;gt; copy_into_table &amp;gt;&amp;gt; dbt_test &amp;gt;&amp;gt; transform_data&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Backfill&lt;/h4&gt;
&lt;p&gt;在平时的工作中，我们经常会遇到业务变动导致数据表里新增一个字段的情况，此时就需要将原始数据重新同步一遍。这时就可以利用Airflow提供的Backfill机制，帮助我们一次性回填指定区间内缺失的所有历史任务。&lt;/p&gt;
&lt;p&gt;比如Demo中DAG的start date是5月20日，所以在打开开关之后，Airflow帮我们回填了start date之后的所有DAG run：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-3.jpg&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-3.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上图中DAG是在5月25日创建的，但Airflow却只从开始日期创建任务到24号，看起来缺失了25号的任务。原因是上图的24号是&lt;strong&gt;logical date&lt;/strong&gt;(execution date)，即trigger DAG run的日期。因为在定义DAG的时候将schedule_interval属性设置为daily，所以在25日(Actually Execute Date)当天只会执行24日(logical date)的任务。&lt;/p&gt;
&lt;h4&gt;监控和调试&lt;/h4&gt;
&lt;p&gt;Airflow提供了友好的UI界面让我们可以更方便地从各种维度监控以及调试，比如查看一年的运行情况：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-4.jpg&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-4.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;br/&gt;
或者每一个task的运行时间：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-5.png&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-5.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以及task的log：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-6.jpg&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-6.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;等等，这里只列举了其中几个，大家有兴趣的话可以自己探索。&lt;/p&gt;
&lt;h4&gt;Parallelism&lt;/h4&gt;
&lt;p&gt;通常我们需要把多个数据源的数据，集成到同一个数据仓库中便于进行分析，因为这些task之间互相没有影响，所以可以通过同步运行它们来提高效率。&lt;/p&gt;
&lt;p&gt;这种场景下，一方面可以通过配置参数Parallelism来控制Airflow worker的数量，也就是同时可以运行的task的数量，另一方面也需要更改Executor的类型，因为默认的Sequential Executor只支持同时运行一个task。&lt;/p&gt;
&lt;p&gt;假设task的依赖关系声明为：task_1 &amp;gt;&amp;gt; [task_3, task_2] &amp;gt;&amp;gt; task_4&lt;/p&gt;
&lt;p&gt;，在更换到Local Executor并且设置parallelism为5之后，启动Airflow，可以发现Airflow会创建5个worker。这时再触发DAG run，task2和task3就可以同时运行了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~ yunpeng$ ps -ax | grep &#x27;airflow worker&#x27;

 59088 ttys017    0:02.81 airflow worker -- LocalExecutor

 59089 ttys017    0:02.82 airflow worker -- LocalExecutor

 59090 ttys017    0:02.81 airflow worker -- LocalExecutor

 59091 ttys017    0:02.82 airflow worker -- LocalExecutor

 59092 ttys017    0:02.81 airflow worker -- LocalExecutor&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;DEMO运行结果&lt;/h2&gt;
&lt;p&gt;原始数据被加载到Snowflake的RAW schema中，dbt project可以随时引用这些数据：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-7.jpg&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-7.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;转换结果被持久化在ANALYTICS schema里，这些数据可以直接用来分析，也可以作为源数据被再次引用：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-8.jpg&quot;&gt;&lt;img src=&quot;https://insights.thoughtworks.cn/wp-content/uploads/2023/03/how-to-implement-elt-8.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Repo link&lt;/h2&gt;
&lt;p&gt;dbt project: &lt;a href=&quot;https://github.com/littlepainterdao/dbt_development&quot;&gt;https://github.com/littlepainterdao/dbt_development&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Airflow: &lt;a href=&quot;https://github.com/littlepainterdao/airflow&quot;&gt;https://github.com/littlepainterdao/airflow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文整体比较基础，希望之前没有接触过ELT的同学可以通过这篇文章对它以及Snowflake，dbt和Airflow有初步的了解。&lt;/p&gt;
&amp;#13;
&lt;/div&gt;&amp;#13;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>