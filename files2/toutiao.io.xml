<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>98965bb9896272c595c7b61b5be20e6e</guid>
<title>Chromium + Mitmproxy 组合使用踩坑</title>
<link>https://toutiao.io/k/bz4e46a</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section class=&quot;toc-content post no-image&quot;&gt;
      &lt;h2 id=&quot;%E8%83%8C%E6%99%AF&quot;&gt;背景&lt;/h2&gt;&lt;p&gt;众所周知，Chromium 目前是事实上的地表最强浏览器内核，Mitmproxy 是事实上地表最强的中间人代理工具。二者组合使用可以非常方便的进行控制与数据分离的自动化数据提取。不过在实际生产中大规模使用时，还是会或多或少的遇到了一些难以察觉的坑。。。&lt;/p&gt;&lt;h2 id=&quot;mitmproxy-%E4%BD%8E%E7%89%88%E6%9C%AC%E9%95%BF%E6%9C%9F%E8%BF%90%E8%A1%8C%E6%98%93-oom&quot;&gt;Mitmproxy 低版本长期运行易 OOM&lt;/h2&gt;&lt;h3 id=&quot;%E7%8E%B0%E8%B1%A1&quot;&gt;现象&lt;/h3&gt;&lt;p&gt;在容器中部署 chromium + mitmproxy 后，发现在多次访问某些类型网站时，mitmproxy 经常周期性地出现内存缓慢增长，直到超过 docker 限制而被 OOMKilled。虽然有 docker 的自动重启进程功能，但是总会不可避免的导致业务上网络连接的周期性断开。&lt;/p&gt;&lt;h3 id=&quot;%E5%88%86%E6%9E%90&quot;&gt;分析&lt;/h3&gt;&lt;p&gt;初步怀疑是流量本身过多（chromium 对 mitmproxy 是“多对一”）以及给 mitmproxy 分配的内存过低导致内存不足。于是尝试将 mitmproxy 的内存配额从 200MB 增长到 1G。&lt;/p&gt;&lt;p&gt;但是实际结果却是这只是延长了 OOM 的时间，并没有解决问题。于是考虑是出现了内存泄漏问题，但是业务脚本无论如何也排查不出问题，因此只能暂时用 docker 自动重启进程的功能保持服务的大致可用。&lt;/p&gt;&lt;p&gt;同时发现似乎在 chromium 中增加 &lt;code&gt;--disable-http2&lt;/code&gt; 的启动参数后，内存泄漏的情况会有所缓解。&lt;/p&gt;&lt;h3 id=&quot;%E8%A7%A3%E5%86%B3&quot;&gt;解决&lt;/h3&gt;&lt;p&gt;经过一段时间，偶然回头一看才检索到 mitmproxy 有一个 &lt;a href=&quot;https://github.com/mitmproxy/mitmproxy/issues/4786&quot;&gt;#4786&lt;/a&gt; 的相关 issue。原来在较低版本中（8.0.0及以下），拦截的 HttpFlow 长连接对象的确存在连接泄漏导致内存不断膨胀直至 OOM 的问题。（这样一想强制关闭 http2 长连接的确有概率会降级到短连接，从而缓解长连接的 OOM 问题。）&lt;/p&gt;&lt;p&gt;这个问题终于在 8.1.0 版本得到了修复（&lt;a href=&quot;https://github.com/mitmproxy/mitmproxy/blob/main/CHANGELOG.md&quot;&gt;CHANGELOG&lt;/a&gt;）：&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image.png 1000w, https://blog.mythsman.com/content/images/size/w1600/2023/03/image.png 1600w, https://blog.mythsman.com/content/images/2023/03/image.png 1754w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们要做的就是直接使用最新稳定版的 mitmproxy 即可。不过这件事情也没有想象中的容易。&lt;/p&gt;&lt;p&gt;如果你的系统是 ubuntu:focal (20.04 LTS) 的版本，默认安装的 python3 版本应当是 3.8.x ，这时你会发现无论如何也装不上 mitmproxy@8.1.0 版本：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 20.04.5 LTS
Release: 20.04
Codename: focal

$ python3 --version
Python 3.8.10

$ pip3 install mitmproxy==8.1.0
ERROR: Could not find a version that satisfies the requirement mitmproxy==8.1.0 (from versions: 0.8, 0.8.1, 0.9, 0.9.1, 0.9.2, 0.10, 0.10.1, 0.11, 0.11.1, 0.11.2, 0.11.3, 0.12.0, 0.12.1, 0.13, 0.14.0, 0.15, 0.18.1, 0.18.2, 0.18.3, 1.0.0, 1.0.1, 1.0.2, 2.0.0, 2.0.1, 2.0.2, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 4.0.0, 4.0.1, 4.0.3, 4.0.4, 5.0.0, 5.0.1, 5.1.0, 5.1.1, 5.2, 5.3.0, 6.0.0, 6.0.1, 6.0.2, 7.0.0, 7.0.1, 7.0.2, 7.0.3, 7.0.4, 8.0.0)
ERROR: No matching distribution found for mitmproxy==8.1.0&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的关键是要记得去 &lt;a href=&quot;https://pypi.org/&quot;&gt;pypi&lt;/a&gt; 上去看下 mitmproxy 对不同 python 版本的支持：&lt;a href=&quot;https://pypi.org/project/mitmproxy/8.0.0/&quot;&gt;8.0.0&lt;/a&gt; 的最低支持 python 版本是 3.8；而刚巧修复了 bug 的 &lt;a href=&quot;https://pypi.org/project/mitmproxy/8.1.0/&quot;&gt;8.1.0&lt;/a&gt; 的最低支持 python 版本就跳到了 3.9。于是这里又要继续升级 python3 到 3.9 以上。&lt;/p&gt;&lt;p&gt;这里又有两条路：要么需要在 20.04 的 ubuntu 里增加新的 python3.9 的源，把老的 python3.8 的相关数据清理干净，再安装新的 python3.9 ；要么直接升级到 jammy (22.04 LTS)。&lt;/p&gt;&lt;p&gt;经过一番尝试，发现在老的镜像里升级 python3.9 还是非常麻烦的，处理不好经常会残留一些老版本的库。于是我这里选择了直接将基础镜像换成了 ubuntu:22.04 。&lt;/p&gt;&lt;p&gt;全部升级完成后，正常运行的 mitmproxy 的内存占用基本都会维持在 100MB 左右了，还是非常稳定的。&lt;/p&gt;&lt;h2 id=&quot;chromium-%E5%BF%BD%E7%95%A5%E8%AF%81%E4%B9%A6%E6%A0%A1%E9%AA%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88&quot;&gt;Chromium 忽略证书校验会导致缓存失效&lt;/h2&gt;&lt;h3 id=&quot;%E7%8E%B0%E8%B1%A1-1&quot;&gt;现象&lt;/h3&gt;&lt;p&gt;原先的系统架构是先启动一个 mitmdump 服务监听 8888 端口，再使用一个基于 chromium 内核的浏览器，通过 &lt;code&gt;--proxy-server=localhost:8888&lt;/code&gt;  将流量指向代理服务，再通过 &lt;code&gt;--ignore-certificate-erros&lt;/code&gt; 参数忽略对 mitmdump 的自签名证书的校验，保证流量器正常访问。&lt;/p&gt;&lt;p&gt;同时为了减少图片、视频等带来的带宽损失，结合具体任务，在 mitmdump 的脚本里将视频、图片等相关的请求 drop 掉，保持对流量的高效利用。&lt;/p&gt;&lt;p&gt;本来这就是一个非常的朴素、透明、易理解的普通架构，线上也稳定运行了多年，没啥大的变动也没人想着改。不过近期业务流量逐渐大了起来，发现出口带宽有点撑不住了。于是增加了个对响应体的 Content-Type 监控，发现流量的大头竟然是 application/javascript 这一类的东西。&lt;/p&gt;&lt;p&gt;这显然不太合理，因为这些 javascript 资源理论上都是走的 cdn，数据都会带 Cache-Control 相关 header 方便浏览器进行本地缓存。在重复执行类似网页的时候，大概率应当会复用之前已经缓存好的 javascript 文件。&lt;/p&gt;&lt;h3 id=&quot;%E5%88%86%E6%9E%90-1&quot;&gt;分析&lt;/h3&gt;&lt;p&gt;仔细审查了一下正常浏览器请求和线上环境下请求的资源请求情况，果然发现了不同点。&lt;/p&gt;&lt;p&gt;本地环境：&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image-1.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image-1.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image-1.png 1000w, https://blog.mythsman.com/content/images/2023/03/image-1.png 1024w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;线上环境：&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image-2.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image-2.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image-2.png 1000w, https://blog.mythsman.com/content/images/2023/03/image-2.png 1024w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;可见本地环境的各种 javascript 资源在多次请求时都是要么命中了 memory cache ，要么命中了 disk cache，从而正常节省了流量。而 线上环境的各种 javascript 资源却只会命中 memory cache 而从未命中过 disk cache。&lt;/p&gt;&lt;p&gt;仔细对比了二者的环境下 chromium 的启动参数差别，多次实验后（&lt;strong&gt;需要注意每次实验之间一定要清空用户目录&lt;/strong&gt;）终于发现区别只在于 &lt;strong&gt;本地环境没有使用 mitmproxy 抓包，而线上环境配置了mitmproxy抓包 &lt;/strong&gt;。在本地环境下配置了 mitmproxy 抓包后终于复现了线上场景。&lt;/p&gt;&lt;p&gt;经过一番搜索，竟然在 MicrosoftEdge 的项目 &lt;a href=&quot;https://github.com/MicrosoftEdge/WebView2Feedback/issues/2634&quot;&gt;issue #2634&lt;/a&gt; 里找到了对 chromium 问题的解释，具体原因可以参见 &lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=110649#c8&quot;&gt;chromium&lt;/a&gt; 这里的解释：&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;Status:&lt;/strong&gt; WontFix : The rule is actually quite simple: any error with the certificate means the page will not be cached.&lt;/blockquote&gt;&lt;p&gt;没错，chromium 做了这样一个规定：&lt;strong&gt;证书错误的页面不会被持久化缓存&lt;/strong&gt;，即使你配置了忽略证书校验。&lt;/p&gt;&lt;h3 id=&quot;%E8%A7%A3%E5%86%B3-1&quot;&gt;解决&lt;/h3&gt;&lt;p&gt;问题原因发现了，解决起来也就容易了。至少有两种方案可以处理：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 mitmproxy 层基于 Http 的 Cache-Control 相关协议，自己实现一层静态资源的持久化缓存。&lt;/li&gt;&lt;li&gt;chromium 不配置 &lt;code&gt;--ignore-certificate-errors&lt;/code&gt; ，而是直接想办法将 mitmproxy 的证书种到 chromium 信任的 CA 里，保证对 TLS 流量的正常解析。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;实测下来，二者都能很好地优化大并发任务下的网络请求。javascript 相关请求量近似跌零，整体的流量会减少 70% 以上。不过总体看下来，方案二处理起来更加便捷和稳妥。&lt;/p&gt;&lt;h2 id=&quot;chromium-%E9%BB%98%E8%AE%A4%E4%B8%8D%E4%BF%A1%E4%BB%BB-linux-%E4%B8%8B%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%AF%81%E4%B9%A6&quot;&gt;Chromium 默认不信任 Linux 下的系统证书&lt;/h2&gt;&lt;h3 id=&quot;%E7%8E%B0%E8%B1%A1-2&quot;&gt;现象&lt;/h3&gt;&lt;p&gt;话接上一个问题的解决方案二，想将证书种到 chromium 中其实并不简单。一个 Ubuntu 下的通用种 mitmproxy 证书的方法是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从 &lt;code&gt;$HOME/.mitmproxy/mitmproxy-ca-cert.pem&lt;/code&gt; 中拿到 mitmproxy 的默认证书；或者自己用 openssl 生成一对证书+私钥，并放在 mitmproxy 的相应位置下。&lt;/li&gt;&lt;li&gt;将上述的 &lt;code&gt;mitmproxy-ca-cert.pem&lt;/code&gt;  复制到 &lt;code&gt;/usr/local/share/ca-certificates&lt;/code&gt; 下，并重命名为 &lt;code&gt;mitm.crt&lt;/code&gt;  （一定要以 crt 为后缀）。&lt;/li&gt;&lt;li&gt;执行 &lt;code&gt;update-ca-certificates&lt;/code&gt; ，会自动将 mitm.crt 按证书信息重命名并软链接到 &lt;code&gt;/etc/ssl/certs&lt;/code&gt; 中。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样搞完，例如 curl wget 等绝大多数应用就都能认得我们自签名的证书了。&lt;/p&gt;&lt;p&gt;可惜 chromium 不是这绝大多数，实测下来依然不信任我们已经种在系统 CA 里的自签名证书。&lt;/p&gt;&lt;h3 id=&quot;%E5%88%86%E6%9E%90-2&quot;&gt;分析&lt;/h3&gt;&lt;p&gt;其实不信任系统默认 CA 证书的事情也很常见，比如很多 App &lt;strong&gt;为了安全考虑&lt;/strong&gt;会自己做 SSL Pinning，不信任用户机器上的证书；或者像 Java 这种工具&lt;strong&gt;为了跨平台的考虑&lt;/strong&gt;也不会使用系统的证书，而是使用自己存储的 keystore。这里 Chromium 可能是也是出于类似考虑，反正也是默认只信任了自己安装时带过来的证书。对于用户新增的证书，也是希望直接通过软件本身的配置进行管理。&lt;/p&gt;&lt;p&gt;官方配置中添加自签名证书的方法是通过 &lt;code&gt;chrome://settings/certificates&lt;/code&gt;  自行导入。&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image-3.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image-3.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image-3.png 1000w, https://blog.mythsman.com/content/images/2023/03/image-3.png 1024w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;不过显然，这中配置方式对于打镜像并不合适，我们还是要寻找通过配置文件进行配置的方案。&lt;/p&gt;&lt;h3 id=&quot;%E8%A7%A3%E5%86%B3-2&quot;&gt;解决&lt;/h3&gt;&lt;p&gt;一番搜索后，从 &lt;a href=&quot;https://superuser.com/questions/1695693/adding-self-signed-certificate-into-trusted-ca-on-chromium-for-linux&quot;&gt;superuser&lt;/a&gt; 中的这篇文章大概了解了 chromium 对自定义证书的管理方式。官方的说明是在 chromium 的 &lt;a href=&quot;https://chromium.googlesource.com/chromium/src.git/+/refs/heads/main/docs/linux/cert_management.md&quot;&gt;cert_management&lt;/a&gt; 文档中。&lt;/p&gt;&lt;p&gt;简而言之，Linux 下的 Chromium 使用的是公共 nssdb 来管理证书。数据存放在 &lt;code&gt;$HOME/.pki/nssdb&lt;/code&gt; 下。&lt;/p&gt;&lt;p&gt;如果这个目录不存在，那么在第一次打开 Chromium 时会自动创建。不过对于预构建的环境来说，这里还是需要自己事先初始化下的。&lt;/p&gt;&lt;p&gt;具体步骤如下：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ mkdir -p ~/.pki/nssdb                                       # 准备路径和文件夹

$ certutil -d ~/.pki/nssdb -N --empty-password                # 初始化DB环境

$ ls ~/.pki/nssdb/                                            # 查看DB文件
cert9.db  key4.db  pkcs11.txt

$ certutil -d ~/.pki/nssdb -L                                 # 查看证书信息（目前为空）

Certificate Nickname                                         Trust Attributes
                                                             SSL,S/MIME,JAR/XPI

$ certutil -d ~/.pki/nssdb -A -t &quot;C,,&quot; -n mitm -i ~/mitm.crt  # 将准备好的证书导入进 CA

$ certutil -d ~/.pki/nssdb -L                                 # 查看导入后的证书信息

Certificate Nickname                                         Trust Attributes
                                                             SSL,S/MIME,JAR/XPI

mitm                                                         C,,
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;正常情况下，这样处理是没有问题的，不过具体使用时，还是踩了一些坑。&lt;/p&gt;&lt;p&gt;注意到 chromium 文档中给出的所有 nssdb 相关指令的 -d 参数和我上述用的有所不同，多带了一个 &lt;code&gt;sql:&lt;/code&gt; 的前缀：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ certutil -d sql:$HOME/.pki/nssdb -L&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是因为在本地测试时，由于 bash 用习惯了，直接用 ~ 代替了 $HOME 。结果命令敲出来结果就是这样：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ certutil -d sql:~/.pki/nssdb -L
certutil: function failed: SEC_ERROR_BAD_DATABASE: security library: bad database.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;报了一个奇怪的错，想了半天没想明白问题出在哪，随手试了试将 &lt;code&gt;sql:&lt;/code&gt; 前缀干掉，发现一切又都能 work 了，也就是我上述记录的命令。&lt;/p&gt;&lt;p&gt;回头仔细看了下文档：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;       -d [prefix]directory
           Specify the database directory containing the certificate and key database files.

           certutil supports two types of databases: the legacy security databases (cert8.db, key3.db, and secmod.db) and new
           SQLite databases (cert9.db, key4.db, and pkcs11.txt).

           NSS recognizes the following prefixes:

           o   sql: requests the newer database

           o   dbm: requests the legacy database

           If no prefix is specified the default type is retrieved from NSS_DEFAULT_DB_TYPE. If NSS_DEFAULT_DB_TYPE is not set
           then dbm: is the default.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;原来 nssdb 是有两种模式的，可以通过为 -d 参数加不同前缀指定。但是坑爹的是如果指定了前缀，似乎就无法识别 bash 下的 ~ 。。。因此这里要么不用 ~ 、改用完整路径，要么就不指定 db ，使用默认配置即可。&lt;/p&gt;&lt;p&gt;最后，这个 pki 的文件权限也要注意，开启 chromium 的用户一定要对这个目录有&lt;strong&gt;读写权限&lt;/strong&gt;。一个稳妥的方法就是 &lt;code&gt;chown -R&lt;/code&gt; 一下，保证用户权限没问题。&lt;/p&gt;&lt;p&gt;这样一番配置后，终于可以在 &lt;code&gt;chrome://settings/certificates&lt;/code&gt; 下看到新增的自签名证书了。&lt;/p&gt;
    &lt;/section&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>19bddc1c1a55e1957bd0a1073980a663</guid>
<title>Go 错误处理：100+ 提案全部被拒绝，为何现阶段仍用 if err != nil？</title>
<link>https://toutiao.io/k/qxnnoy8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content               autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是煎鱼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些年给 Go 提新的错误处理提案的人络绎不绝，挡都挡不住。Ian Lance Taylor 作为历史的亲历者之一特意梳理了《&lt;span&gt;language: Go 2: error handling meta issue&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;》。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天结合我自己写过的内容分享给大家，以后有人再问可以甩给他们，这样他就懂前因后果了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;背景&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 2018 年 8 月，现任 Go 核心团队负责人 Russ Cox 给 Go2 的错误处理画了一个大大的蓝图，并介绍了一个未实现的设计草案。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5185185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4h0wTibBUMmh4XfVfKK0pvulNc22qMxiaibtic3LnictWdssau7mic631ZnmDQ2LbEdLvA3wSv5IKVQ5H6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体目标如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;期望 Go 的错误检查更轻量级，能够减少被大家吐槽的错误检查的程序文本数量。整体上要确保错误处理更加方便，复杂度不能变高。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;错误检查和错误处理都必须保持显式，这意味着在 Go 程序中是可见的。我们不想重复异常处理的陷阱。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;必须保证现有的 Go 代码的兼容性，不能有破坏性升级。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在此之后，也由于 Go 的热浪，许多新的提案作为 Go2 的错误处理变更提交，Go 邮件也有大量的讨论，拥有许多尝试，但&lt;strong&gt;迄今为止没有一个被接受&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是现在 Go 错误处理的背景。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;错误处理合集&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，这个合集并不 100% 全面，如果需要全查看一遍，可以自行在 go/issues 库搜索 error-handling 标签就可以了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以下是一些值得关注的错误处理提案合集：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;画过的大饼 Go2 check/handle 方法&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;常被提起的 try-catch 方法&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;像 Rust 用 ! ? 作为错误检查&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;简化 if err != nil {} 减少代码量&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;使用左侧函数和表达式来替代&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的基本是这几类，有许多雷同的，或被拒绝原因类似的提案，在社区管理上最终都会被指向到一起并关闭。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可以通过上述提案的前因后果，可以看到 Go 核心团队的一些衡量标杆。基本就是：&lt;strong&gt;显式、简洁、省心、好用&lt;/strong&gt;。这就是新错误处理提案的要求。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 的 “新” 错误处理已经经历了 3，5 年了，许多社区友人已经想了许多许多，也提出了许多提案。在 error-handling 标签下共有 100+ 个提案，无一幸免，全部被拒绝。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4444444444444444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4hfv3bRDNIRibReBP0vE3PSpdDpCgcOicphTQqLopUianicNoBAlLftkPlwn8pLZeX2BcvzySKXPnvic8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现阶段还是好好的用 if err != nil，也是许多人认可的。或是自己团队内封装一套共识标准，也是可以的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;让风再吹一会。也许不会改变了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;推荐阅读&lt;span/&gt;&lt;/h4&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;language: Go 2: error handling meta issue: &lt;em&gt;https://github.com/golang/go/issues/40432&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关注和加煎鱼微信，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一手消息和知识，拉你进技术交流群&lt;span&gt;&lt;span&gt;👇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9988738738738738&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KVl0giak5ib4jVkzHVvaqjo3O0BIqDRJKkEyib7SJsryxHBFGsvek0FkdiczfJP6AdbWnK25DvlX3dY8wRObPbVJQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;888&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07106598984771574&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/486RHs1WbcgGib6o96dHbvGUGGwPicd8wusUGH1cXR29tM4bO0lNzialzkQhvU6m5ZUdaKibmcF2OQayjMe9Bia6iaXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;394&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是煎鱼，&lt;span&gt;出版过 Go 畅销书《Go 语言编程之旅》，再到获得 GOP（Go 领域最有观点专家）荣誉，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxMDI4MDc1NA==&amp;amp;mid=2247483854&amp;amp;idx=1&amp;amp;sn=ec422fbf4d846975f2930ddeb5e81373&amp;amp;chksm=f9041493ce739d85a4b987eece14da627206cdad798f645cc770868312e4a22b6df24804f186&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;点击蓝字查看我的出书之路&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;点击蓝字查看我的出书之路&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;日常分享高质量文章，输出 Go 面试、工作经验、架构设计，&lt;span&gt;加微信拉读者交流群，和大家交流！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>2f8d13e1bf614c44a0dfd73e8891858a</guid>
<title>线上问题零发生，闲鱼稳定性问题治理与监控优化</title>
<link>https://toutiao.io/k/k8ay7s5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、灰度&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安全生产环境是由集团层面为保障线上稳定性的灰度流量生产环境。通过接入层网关的流量控制为环境提供1%线上流量+100%办公网流量，还原线上环境为系统验证提供场所。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;453&quot; data-backw=&quot;541&quot; data-ratio=&quot;0.8373382624768947&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/XxT9TiaJ1ibf3lkuGhR43dNLZ4lZotibVdwUXo1XAMQlcqNkEgnav9GWAf2icB0jD3BnRjAdtqRO1pOvnV9iblbOJiaSx9EwjXSib4W/640?wx_fmt=svg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;541&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们以安全生产环境为基础展开一系列治理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;常规场景下，安全生产流量能保证从入口到后续全链路都在安全生产环境闭环。但在闲鱼消息场景里，强依赖MQ做流量的负载均衡，而安全生产流量经过MQ之后会被均匀打散，逃逸到线上，失去灰度观察能力。针对该问题，我们通过spring的Conditional条件注入能力，将线上和安全生产的MQ bean隔离，从而将线上和安全生产MQ topic隔离，使流量能够在安全生产环境完整闭环。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;128&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.22595830531271016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/XxT9TiaJ1ibf3lkuGhR43dNLZ4lZotibVdwFvDCWGnY1vodPaenK8QxNvYraI7PiaRVex4ic7L7QgddWia8qhF15F9exHtFOXaDYiak/640?wx_fmt=svg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1487&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安全生产环境和生产环境的监控基线不同，告警阈值不同，为了能及时发现灰度问题，我们以安全生产环境的水位单独配置了监控告警。覆盖调用量、RT、错误量、消息延迟等多个指标维度，覆盖发送消息、创建会话等所有核心链路场景。我们将安全生产监控聚合成监控大盘，实时和线上监控水位做对比，不仅能发现变更引起的问题，还能发现变更对性能指标的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控告警是实时的异常指标监控，而离线报表是更长时间窗口的指标聚合。我们针对安全生产环境配置独立的离线监控报表，它不仅能发现细微波动的异常指标，也能发现变更对业务指标（例如消息到达率、点击率）的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化回归保障系统的底线，核心场景回归能避免引起严重的问题。我们将自动化回归与CICD集成，当发布到安全生产环境时自动执行自动化回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完善安全生产建设后，如果没有规范去标准化流程，建立行为准则同样达不到保障稳定性的目标。我们结合消息本身的业务特点，约定了消息团队内部的发布规范：发布必须在安全生产停留一晚，第二天灰度放量。确保：1. 覆盖时间相关的代码逻辑。2. 足够久的灰度观测。3. 产出t+1的离线监控报表&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、监控告警&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控告警的生命周期可以分为监控数据准备、监控配置、监控验证、告警配置、告警验证五个环节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;305&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5368126747437092&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DUwiayJ0Mj1GdDic1VabvGpFuLJfw0uorMIxXzLCL4JwWIJ1TPYZqVdL6SibKribj8SA3jK6lnqicGmEF3fzAY3JavA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1073&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控数据准备环节我们有完善的基础设施。基于这个基础，我们对监控告警进行覆盖率、及时性、有效性治理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;治理的第一个目标是要确保监控覆盖全，不遗漏。我们分为三步确保覆盖完整：1. 梳理出系统的核心场景链路，链路上的核心观测指标，查缺补漏监控告警。2. 通用的监控告警作为兜底，覆盖资源水位、接口调用、中间件性能等基础指标。3. 最后，通过监控告警离线报表整体性review监控告警覆盖率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;治理的第二个目标是能及时发现问题、有效发现问题。告警的及时性与有效性是互斥的关系，为达到告警及时性与有效性的最佳平衡，我们按照从严到松的方式逐步调整告警条件。同时为了持续维持告警及时性有效性，我们建立监控告警离线报表，定期review告警记录，对告警调优。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控告警治理需要持续投入，持续保鲜。我们搭建了监控告警离线报表，它包含所有的监控告警配置，告警历史流水，提供告警历史的聚合试图。为我们覆盖率治理、有效性治理提供全局视图，支撑我们定期对监控告警调优。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;691&quot; data-backw=&quot;568&quot; data-ratio=&quot;1.2169625246548323&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DUwiayJ0Mj1GdDic1VabvGpFuLJfw0uorMgHbTQpgEHuOEUUgn3d5sSjhMldYPVvoKWMWicYCrbI04wh8I89q8yeA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1014&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、自动化回归&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化回归的目标是保障底线，确保核心链路场景的稳定性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;端到端级别的自动化回归能从真实使用角度去验证稳定性。我们设计端到端的自动化回归用例，覆盖软件从安装、使用、卸载的完整生命周期，覆盖消息核心场景链路。我们将自动化回归与CICD集成，每天定时自动化回归，在发布流程做自动化回归卡口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;69&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.12115384615384615&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/XxT9TiaJ1ibf3lkuGhR43dNLZ4lZotibVdwD0HL1QlLiaM8IdrVB6yPMDIibPJvKKVYulnRz0Up05ibFBEV2TjhrYGA2icLNw4obcdj/640?wx_fmt=svg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1040&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;176&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.3101851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DUwiayJ0Mj1GdDic1VabvGpFuLJfw0uorMef2e2qLK1Ayibgm7lDTO6YYqj6WF1RvEhiasxRfLvCJCxFUYyiaPdq7pg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;凤凰回放工具是基于JVMTI实现的流量回放测试工具。我们使用凤凰回放工具录制RPC流量，回放流量，diff结果，验证接口级别的稳定性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、依赖治理&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;依赖治理的目标是强弱依赖关系合理，并且弱依赖具备降级快恢能力。我们进行了以下治理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖梳理：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;代码级别review依赖的合理性，review是否具备降级快恢能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖改造：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对不合理的强依赖降级为弱依赖，完善弱依赖的监控告警，降级快恢预案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖演练：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;依赖演练是对依赖治理的验收环节。目的是验证强弱依赖关系和预期一致，避免出现“我以为”但“实际是”的问题，同时验证弱依赖的问题发现能力，降级快恢能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>758f624b28d631cf075c2732ada11535</guid>
<title>聊聊「订单」业务的设计与实现</title>
<link>https://toutiao.io/k/gjiunzv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content               autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;blockquote&gt;&lt;p&gt;订单，业务的核心模块；&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;&lt;span&gt;一、背景简介&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;订单业务一直都是系统研发中的核心模块，订单的产生过程，与系统中的很多模块都会高度关联，比如账户体系、支付中心、运营管理等，即便单看订单本身，也足够的复杂；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.575&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfndlrbMXzljcjc8NxTbcGQIjeZa0NggShL65rUPr8vrE8CU4Q1apHSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;业务在发展的过程中，必然会导致订单量的持续增加，订单自身、数据体量、实现流程，都需要不断的迭代更新，如果在订单流程的研发初期，没有相对全面的考量，那么很有可能导致中后期的重构；&lt;/p&gt;&lt;p&gt;从实践经验上说，围绕订单业务：&lt;strong&gt;建议过度设计，轻量级分步实现&lt;/strong&gt;；&lt;/p&gt;&lt;p&gt;在产品初期先做好全面的设计，场景和流程上做好可扩展性的保留，在数据层面规划好不同体量的应对方案，走在订单业务的前面避免被动，尽量不要被业务的发展和演变甩在身后；&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、订单业务&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、订单体系&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;订单体系从角色上看，主要涉及：用户、商户、平台三个核心参与方，其订单流程的搭建就是围绕三方的交易场景展开；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.05&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfn3ochKKtOZNiaUtEJ6llyicjC1HsppGojicsEBR3QOyI6U9OOStsxzroA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;这里需要说明一些细节：商户可以是第三方商家，也可以是平台方自己，不影响概念上的划分；商品也存在多种形式，所以用交付来描述，可以覆盖物流的定义；&lt;/p&gt;&lt;p&gt;用户：通过应用端，进行商品的选择和下单；平台：实现订单交易链路和支付能力，以及对整个流程的调度；商户：提供商品和交付能力；&lt;/p&gt;&lt;p&gt;在图中，只是围绕订单体系做一个框架性的宽泛描述，在成熟的订单业务中，其复杂程度远超上图，下面围绕核心节点来细致分析；&lt;/p&gt;&lt;h2&gt;&lt;span&gt;2、流程管理&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;2.1 流程拆分&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;订单的业务属性是极高的，流程本身也比较复杂，从不同的参与方来看，其流程分段策略完全不一样，这里仅站位研发视角，把订单逻辑分为：创建、支付、交付三个阶段；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.32222222222222224&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfwoqh0e5SZibvghyU7D3wplYAIib3g7uGVrRV1lASE7RCibKKE4gxgq8tw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;订单创建：围绕用户的下单路径做管理，从商品的访问点击并选中，到购车下单或者直接下单，从而完成订单的创建；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;订单支付：各种支付渠道的对接是交易场景的基础功能，订单的核心状态即支付成功；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;订单交付：在订单支付完成之后，开始进行商品的交付流程，可能是商家的发货或者服务提供，交付成功即订单完成；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果将整个订单场景统筹起来看的话，还存在很多隐性的流程，与订单衔接的上下游业务还有很多，这里只是专注于订单功能自身的边界做划分；&lt;/p&gt;&lt;h3&gt;&lt;span&gt;2.2 正向流程&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在理想的状态下，订单从购物车结算下单开始，到交易支付完成，最终到商家完成交付，是非常复杂的流程链路；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7777777777777778&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfRoV3Fw8ebVeEqoOFX7f6mAQfmyXlfGmFaMlRUCkPBGpteTfV0fRvuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;在实现上，订单的正向流程链路都是分段管理的，比如购物车、订单创建之后、支付完成、交付等诸多关键节点，并不是一个即时的流程；&lt;/p&gt;&lt;h3&gt;&lt;span&gt;2.3 逆向流程&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;对于订单这种极度复杂的流程，导致订单流程逆向的情况，要细致的考虑并且提供相应的解决方案，尽量确保程序可以兜底流程逆向，人工干预的成本和风险都极高；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.55&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfv5wYdxoHGxPVueNYJgRf4FqwbQGzUaB7vh5wGIIVW8h34FGRUE72Dw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;取消动作：用户主动取消订单，发起退款流程等；商户因为交付失败，主动发起流程退回等动作；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;超时情况：订单创建后，指定时间内没有支付；订单支付后，指定时间内商家没有交付等多个超时场景；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;节点异常：系统平台的在订单调度时的业务异常，或者程序异常，又或者支付等第三方渠道异常等；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些常见的异常问题，在一般的场景下可能不会引发效应问题，对于订单这种异步解耦的复杂场景中，需要一个稳定的机制快速执行逆向流程；比如下单后未支付导致持续锁定库存，或者交付超时影响用户体验等；&lt;/p&gt;&lt;h3&gt;&lt;span&gt;2.4 调度与监控&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;订单属于核心流程又兼具复杂的特性，自然依赖系统平台的调度与监控手段，无论是正向还是逆向流程，都依赖调度手段提高订单的完成率，或者促使逆向流程有序执行，在这个过程中需要对订单路径有完整的监控能力；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4777777777777778&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfUS99VjALSEnotictF65sXicnhXgSlbx55py2pQJiaCzCJ632HicKicGlS9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;调度机制&lt;/strong&gt;：更侧重订单被动状态的处理，多见于各种超时的场景，用来提前对用户和商户进行消息提醒触达，或者进行订单流程的处理；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;监控策略&lt;/strong&gt;：更侧重对订单的主动干预处理，在发现订单中断或者异常时，可以通过产品层面的入口进行主动修复，或者系统层面的主动重试，当然也不排除最后的手动干预；&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3、结构设计&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;围绕订单场景，涉及的数据结构非常复杂，不论是商品还是支付，亦或是订单自身的结构，在具体的业务中都会拓展出很多关联表；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.45740740740740743&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfPGrlra4QFDtibl84LxTIwEe96evITwUVfqcD15FJexZ7zcnhlbBLDEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;订单结构的设计和管理，基于场景复杂度考虑，可能要融合商家、仓储货架、用户、渠道和类型等；在订单量增长之后，还需要结合业务场景，进行数据体量层面的拆分处理；&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、技术方案&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、订单ID&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;订单主体的唯一ID标识，在数据体量不大的情况下，使用表的自增ID主键即可，从长期看的话并不友好，如果订单量比较大，可能涉及分库分表的流程，则需要制定ID生成策略；&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;UUID&lt;/strong&gt;：生成唯一字符串识别码，订单ID直接使用即可；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;雪花算法&lt;/strong&gt;：分布式ID生成算法策略，生成的ID遵循时间的顺序；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;自定义ID&lt;/strong&gt;：除了唯一的属性外，在订单ID中添加其他的关键业务标识；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;span&gt;2、并行与异步&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;并行操作&lt;/strong&gt;，在订单详情的加载过程中，涉及到的查询信息非常多，比如：商品、商户、订单、用户等，可以通过并行的方式，提高响应的时间，如果采用串行的方式，则接口性能会差很多；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.3537037037037037&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfcQmIUAA3Mbu8DVM5BYeJGLbk4TgzZLcDFqFG5de4bNVU0hvoNYItEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;异步操作&lt;/strong&gt;，订单是个复杂的流程，显然不可能在一次流程中完成所有逻辑，流程分段异步常规手段，就是借助MQ消息的方式，同样可以极大的提升服务性能；不论是订单的正逆向流程，都可以基于状态、事件、动作进行异步解耦处理；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.35833333333333334&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfekPdcjlrwKuFeffxibGgoPib5XewZ6mnia7j4dL7LRGnBgNAh2nHgPAZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3、超时问题&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;订单超时问题的本质在于，指定时间段之后需要执行一个动作；比如最经典的场景，下单之后超过&lt;code&gt;15||30&lt;/code&gt;分钟未支付，订单自动取消并且被关闭，释放商品的库存，并通知用户；&lt;/p&gt;&lt;p&gt;实现一个动作延迟执行的方式有很多，比如延期队列，过期监听，消息延时消费等，不过这些方式在复杂的订单系统中并不常见，主流的话还是采用定时任务调度的方式；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2972222222222222&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEf6Yy8lEWqtv1xj5qMOYHXv74639XuXglVXRXKbSETVB6eX5nbRpRibWQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;任务调度时，对订单的处理，同样要确保业务流程操作的幂等性，数据层面的一致性等问题，如果出现异常单则进行重试，分析异常原因不断优化流程也同样重要；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果订单体量大，任务调度能完成吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;订单体量和订单实时量不是一个概念，系统沉淀的订单量和任务要处理的量不是一个等级，常规的数据体量做好分库分表的设计和查询优化即可，不会成为调度任务的瓶颈问题；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;如果订单数据实时体量大，比如每天超千万的水平？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这就更不是应用的问题了，订单体量能达到每日千万的规模，公司会提前很长时间就把数据团队拉到应用团队中，解决这种核心的棘手问题，此前在数据公司搬砖时，每日单量刚过百万，就安排数据团队做解决方案了；&lt;/p&gt;&lt;h2&gt;&lt;span&gt;4、分布式事务&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;订单涉及支付对接、库存管理、结算对账等各种复杂的流程，自然对数据一致性有极高的要求，如果数据层面出现问题导致异常单出现，难免需要人工介入处理，所以对流程的各阶段做好细致的事务和逻辑管理极其重要；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.29814814814814816&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfmBMkojib1DTInHxBSuMwuw6KTzL7DDyplvibzrDRD1NibM9Uib8CLGFrEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;订单流程是异步解耦的方式推进的，在分布式事务的策略上追求的是最终结果一致性即可，不过这并不妨碍在分段的流程中，进行局部的事务管理，事务成功，流程正向推进，事务失败，流程重试或逆向回滚；&lt;/p&gt;&lt;h1&gt;&lt;span&gt;四、数据方案&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、转化分析&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;经典的订单指标体系，用户下单过程的路径统计，从而深度的分析转化率问题，不断的对流程和场景优化，从而提高成交量；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4685185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEficJsmhLOBibgg7QX5yJvpK1Oa6WoDNKGbHlOkL511lHYIJyD48P03gtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;交易的转化路径分析，是产品和运营重点关注的指标体系，在数据层面，埋点采集的数据通常是上传第三方平台，方便进行用户和业务分析，并且有助于同类客群的营销推广；&lt;/p&gt;&lt;h2&gt;&lt;span&gt;2、分库分表&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;数据在到达一定体量之后，需要进行分库分表的操作，从而解决各种性能方面的问题；将订单数据按照特定的维度进行计算，从而将数据分流到不同的库表中，解决读和写的瓶颈；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4722222222222222&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEfy6P1a0a1HwlVK1hwp5k4Y1Bl5rGIGuQtqyuIN57FkdjvtfUqCAzVGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;基于订单ID计算拆分的逻辑是最常见的，在特殊情况下，也会基于用户ID或商户ID进行计算，从而将相关的数据堆放在一起，如果有必要，也可以考虑多维度拆分的多写模式；&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3、数据同步&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;订单数据分库分表虽然解决存储问题，但是也带来了很多查询方面的阻碍，通过搜索引擎来解决查询问题也是常用的技术选型；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.3296296296296296&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvByAaLXcL8ztah8AMC4baEf9MEZDxLhIlicGian3GckHsANEb60x6qFykPlpzZhTJT7mr2GBxHZhhicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;订单数据在库和搜索引擎之间同步的方法有很多：同步双写，对数据的实时性要求极高；异步解耦，流程存在轻微的延迟；定时任务，存在明显的时效问题；组件同步，采用第三方数据同步组件；订单场景的话推荐同步双写的方式。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;五、参考源码&lt;/span&gt;&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;编程文档：&lt;br/&gt;https://gitee.com/cicadasmile/butte-java-note&lt;br/&gt;&lt;br/&gt;应用仓库：&lt;br/&gt;https://gitee.com/cicadasmile/butte-flyer-parent&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-support=&quot;96编辑器&quot; data-style-id=&quot;30792&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;97816&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>de46983cc83300c3fedc3b08c60c0b45</guid>
<title>复杂度分析：如何分析、统计算法的执行效率和资源消耗</title>
<link>https://toutiao.io/k/mt22bnf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;&lt;strong&gt;作者：京东物流 崔旭&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们都知道，数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。&lt;/p&gt;

&lt;h3&gt;1 为什么需要复杂度分析？&lt;/h3&gt;

&lt;p&gt;你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比实实在在跑一遍得到的数据更准确吗？&lt;/p&gt;

&lt;p&gt;首先可以肯定地说，这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。&lt;/p&gt;

&lt;h4&gt;1.1 测试结果非常依赖测试环境&lt;/h4&gt;

&lt;p&gt;测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。&lt;/p&gt;

&lt;h4&gt;1.2 测试结果受数据规模的影响很大&lt;/h4&gt;

&lt;p&gt;对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！&lt;/p&gt;

&lt;p&gt;所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法，这就是我们接下来要说的大O复杂度表示法。&lt;/p&gt;

&lt;h3&gt;2 大O复杂度表示法&lt;/h3&gt;

&lt;p&gt;算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？&lt;/p&gt;

&lt;p&gt;这里有段非常简单的代码，求 1,2,3…n 的累加和。现在，一块来估算一下这段代码的执行时间吧。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/ab6a5ba0-ad13-45b4-a98d-0715c36e20c020220421141047.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？&lt;/p&gt;

&lt;p&gt;第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n_unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)_unit_time。可以看出来，所有代码的执行时间 T(n) 与每行代码的执行次数成正比。&lt;/p&gt;

&lt;p&gt;按照这个分析思路，我们再来看这段代码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/9e84fa78-747e-44da-a646-a296db81107720220421141103.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？&lt;/p&gt;

&lt;p&gt;第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n_unit_time 的执行时间，第 7、8 行代码循环执行了 n²遍，所以需要 2n²_unit_time 的执行时间。所以，整段代码总的执行时间 T(n) = (2n²+2n+3)*unit_time。&lt;/p&gt;

&lt;p&gt;尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/3fe49660-5e63-4fed-b731-5db9eb2baec620220421141119.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。&lt;/p&gt;

&lt;p&gt;所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = (2n²+2n+3)。这就是大O时间复杂度表示法。大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度，简称时间复杂度。&lt;/p&gt;

&lt;p&gt;当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n²)。&lt;/p&gt;

&lt;h3&gt;3 时间复杂度分析&lt;/h3&gt;

&lt;p&gt;前面介绍了大 O 时间复杂度的由来和表示方法。现在我们来看下，如何分析一段代码的时间复杂度？&lt;/p&gt;

&lt;h4&gt;3.1 只关注循环执行次数最多的一段代码&lt;/h4&gt;

&lt;p&gt;大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。&lt;/p&gt;

&lt;p&gt;为了便于你理解，我还拿前面的例子来说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/4a89e370-66b7-410b-acde-35ef6706fc0d20220421141153.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。&lt;/p&gt;

&lt;h4&gt;3.2 加法法则：总复杂度等于量级最大的那段代码的复杂度&lt;/h4&gt;

&lt;p&gt;这里还有一段代码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/2213964c-18de-45de-8278-85cd6566cf5820220421141237.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。&lt;/p&gt;

&lt;p&gt;第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。&lt;/p&gt;

&lt;p&gt;即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。&lt;/p&gt;

&lt;p&gt;那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n²)。&lt;br/&gt;
综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n²)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：&lt;/p&gt;

&lt;p&gt;如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).&lt;/p&gt;

&lt;h4&gt;3.3 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积&lt;/h4&gt;

&lt;p&gt;刚讲了一个复杂度分析中的加法法则，这儿还有一个乘法法则。类比一下，你应该能“猜到”公式是什么样子的吧？&lt;/p&gt;

&lt;p&gt;如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)_T2(n)=O(f(n))_O(g(n))=O(f(n)*g(n)).&lt;/p&gt;

&lt;p&gt;也就是说，假设 T1(n) = O(n)，T2(n) = O(n²)，则 T1(n) * T2(n) = O(n³)。落实到具体的代码上，我们可以把乘法法则看成是嵌套循环，我举个例子给你解释一下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/a0a7d038-e8e8-43d0-bb8a-a1c5511f6d4320220421141312.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n)_T2(n) = O(n_n) = O(n²)。&lt;/p&gt;

&lt;h4&gt;3.4 几种常见时间复杂度实例分析&lt;/h4&gt;

&lt;p&gt;虽然代码千差万别，但是常见的复杂度量级并不多。稍微总结了一下，这些复杂度量级几乎涵盖了大部分的场景。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;  常量阶 O(1)&lt;/li&gt;
&lt;li&gt;  对数阶 O(logn)&lt;/li&gt;
&lt;li&gt;  线性阶 O(n)&lt;/li&gt;
&lt;li&gt;  线性对数阶 O(nlogn)&lt;/li&gt;
&lt;li&gt;  平方阶 O(n²)&lt;/li&gt;
&lt;li&gt;  立方阶 O(n³) …&lt;/li&gt;
&lt;li&gt;  指数阶 O(2ⁿ)&lt;/li&gt;
&lt;li&gt;  阶乘阶 O(n!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2ⁿ) 和 O(n!)。&lt;/p&gt;

&lt;p&gt;当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。我们主要来看几种常见的多项式时间复杂度。&lt;/p&gt;

&lt;p&gt;1.O(1)&lt;/p&gt;

&lt;p&gt;首先你必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/fc055270-4406-46a2-b46c-ec4a77d381c120220421141358.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。&lt;/p&gt;

&lt;p&gt;2.O(logn)、O(nlogn)&lt;/p&gt;

&lt;p&gt;对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/650a7d56-035d-4dd0-8e82-123f66f5f6ff20220421141417.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。&lt;br/&gt;
从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。&lt;/p&gt;

&lt;p&gt;实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/cee2d15e-1c19-42bd-a73a-4d4dc31edb9c20220421141436.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2ˣ=n 求解 x ，x=log₂n，所以，这段代码的时间复杂度就是 O(log₂n)。&lt;/p&gt;

&lt;p&gt;现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/0082ab49-cab2-43a6-aff3-779805e4560e20220421141533.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 O(log₃n)。&lt;/p&gt;

&lt;p&gt;实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？&lt;/p&gt;

&lt;p&gt;我们知道，对数之间是可以互相转换的，log₃n 就等于 log₃2_log₂n，所以 O(log₃n) = O(C_log₂n)，其中 C=log₃2 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log₂n) 就等于 O(log₃n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。&lt;/p&gt;

&lt;p&gt;如果你理解了O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。&lt;/p&gt;

&lt;p&gt;3.O(m+n)、O(m*n)&lt;/p&gt;

&lt;p&gt;我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。老规矩，先看代码！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/979b91f5-cc4e-4c2c-8e87-2833ac14c31b20220421141600.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。&lt;/p&gt;

&lt;p&gt;针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)_T2(n) = O(f(m)_f(n))。&lt;/p&gt;

&lt;h3&gt;4 空间复杂度分析&lt;/h3&gt;

&lt;p&gt;前面，咱们花了很长时间讲大 O 表示法和时间复杂度分析，理解了前面讲的内容，空间复杂度分析方法学起来就非常简单了。&lt;/p&gt;

&lt;p&gt;时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。&lt;/p&gt;

&lt;p&gt;还是拿具体的例子来说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/68c88ae8-c5cc-4e58-98f2-faed38b7de3b20220421141628.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。&lt;br/&gt;
我们常见的空间复杂度就是 O(1)、O(n)、O(n²)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。&lt;/p&gt;

&lt;h3&gt;5 内容小结&lt;/h3&gt;

&lt;p&gt;复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n²)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/61faa60a-a6da-416c-98ba-92605400733820220421141647.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>