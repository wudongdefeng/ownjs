<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f81fa78f47a5b5cbbc2d830743e8356d</guid>
<title>团队一盘散沙，怎么破？</title>
<link>https://toutiao.io/k/kdzpdh5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原创不易，求分享、求一键三连&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近有个粉丝问了一道&lt;strong&gt;大题&lt;/strong&gt;：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;blockquote&gt;&lt;p&gt;小钗，我最近空降到一个小公司做技术负责人，感觉团队士气很低，同学们要么有力无处使，要么常规摸鱼，这种一盘散沙的团队该如何带呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;这道题我还真会！&lt;/strong&gt;只不过这是一道大题，没那么简单，需要大家耐着性子读完，这里先给出解题思路：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;直面问题，分析成因；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;目标确定，合理分解；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;梯队确定，奖善罚恶；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;资源确定，粮草先行；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;机制流程，抹平障碍；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来我们现身说法，依次分解。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;直面问题，分析成因&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;顶层梳理&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队为什么会一团散沙，首先要有自己的基本判断，比如我们团队的问题是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;去年有一次比较大的团队合并，单就技术团队算是150+120的合并规模，正常情况，这种合并效果都不会太好，加上互联网寒冬，所以导致了第二个问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后疫情时代，降本增效成了很多公司的主题，与多数公司一样，我们进行了大规模的人员优化，半年优化量多达70%！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;人员优化倒是完成了，而服务规模却未减少。单后端来说，当前103个服务无人维护；少数核心同学维护服务又超过70个，风险很大，却又无可奈何。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;几轮人员优化下来，剩下的同学不免人心惶惶，而这个时期负责人也难以打包票&lt;strong&gt;不会再发生&lt;/strong&gt;，而且正常情况这时候应该有一波团队激励，但这次情况特殊，整个公司都锁死了，于是粮草也不足...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;人的问题盘点完，还要盘点事的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队合并导致的最大问题是两套技术体系，特别是后端完全是两个技术栈：Golang、Java，在后端整体人数受限的情况下，很难重用，直接导致战斗力减半！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此常见的业务历史债就不多赘述了，每个团队都有，就看严重程度了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，双技术栈加上几波裁员情况下，30%团队要维护原来100%的业务，还没加薪，这个团队士气不低就奇怪了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自己有了初步判断后，还得收集一线同学的想法。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基层视角&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;收集一线信息的方法比较简单，发一个调查问卷，再找几个关键人聊天即可：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;你觉得当前团队最大的问题是什么；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你觉得产生这些问题的原因是什么；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你觉得该如何处理；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由此可以形成一个脑图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.636726546906188&quot; data-type=&quot;png&quot; data-w=&quot;501&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTAhJicnwkIFHbXOTYtyvH1rf80d8KfMCCibXl1OaIdASvfOyOJb5drHB2dFWicJ0jFweQgIaWMqWFibVA/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，一线同学看到的点跟我们的认知还是统一的：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;历史债重；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;激励不足；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;氛围不好；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;业务拉胯；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;目标不清晰；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;...&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;貌似这个比我们两年前遇到的问题更糟糕了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;3.198148148148148&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTAhJicnwkIFHbXOTYtyvH1rf729yroAPpV0sv2uIQhjrr0CQlP3faH6ic6aAfj142GURFnbq4cQictSg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比较有意思的是，其中一些问题之前已经解决，但是过一段时间后又回来了，所以这个过程总是循环往复啊，那么如何解决呢？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;目标是什么：选题&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的选题，就是把自己的疑惑，将业务中碰到的问题，整理成一些课题，将这些课题指派给团队的“专家组”进行研讨，找到答案形成方案，选题的重点有二：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;找准问题；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;问题切割；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;工作中问题很多，不能眉毛胡子一把抓，要发现主要矛盾是什么，要有优先级，所以一定要找准要解决的问题，集中资源解决；找准问题后要做问题切割，问题大了资源不足做不了，问题小了没有效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;思考选题时要卷入足够的资源、足够的意见，但不要被轻易带偏，要有自己的坚持，自己的主见，选题能力就是战略能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，现在有那么多问题，我们要先解决什么，后解决什么，光说不练假把式，一起来实操下吧！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;俗话说得好，兵草未动，粮草先行，如果人心不稳，就算有明确的目标也没人想做，所以第一步是稳住人，众所周知，稳住人最好的办法是&lt;strong&gt;给他钱&lt;/strong&gt;或者&lt;strong&gt;帮他成长&lt;/strong&gt;能赚更多钱。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面说了，今年情况特殊，想要加钱是比较难的，但比较难并非不能实现，只不过这种时候要站在公司角度思考问题：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;我为什么要给你钱；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我应该给谁钱；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;怎么证明这笔钱花得值；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;公司事实上也不是一毛不拔的，毕竟还要维持运营，但公司需要识别谁是团队可用之才，并且需要证据链，这种时候由于屁股问题，不能听负责人的一面之词了，所以我们需要准备证据链，做两个事：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;识别团队人才；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;证明人才的ROI；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何做呢，有一个简单的解法是，证明人才同等时间做的事情更多更好就行了，而高级程序员的效率相较初级程序员确实会高不少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们这里第一个要实现的目标是：&lt;strong&gt;找出团队不可或缺的20%，并证明他们优秀，想办法说服公司给予激励&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个目标是帮他成长，那么对应的&lt;strong&gt;梯队建设&lt;/strong&gt;，上升通道以及人才运营机制需要重新设计并维护起来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;粮草只能暂时解决人才焦虑问题，远大的目标才能让所有人走得更远，关于目标问题有几个点要注意：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;技术团队难以影响业务团队目标，所以不要妄图&lt;strong&gt;技术驱动业务&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;现阶段技术基建资源会很有限，所以不可能有太多资源&lt;strong&gt;投入技术基建&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;新的目标要可达成、有成就感、并且技术说了可以算；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总而言之，要让技术有尊严，最好能解决&lt;strong&gt;安全感&lt;/strong&gt;问题，那么这只有一条路可以走：&lt;strong&gt;创造营收，甚至自己养活一部分自己！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如何做呢，这里有个&lt;strong&gt;“比较摆烂”&lt;/strong&gt;的策略：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;开展外包业务；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;开展技术培训业务；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也不要看到&lt;strong&gt;外包&lt;/strong&gt;就难受，如果跟业务方撕逼的时候真的将自己当外包团队，很多问题可以迎刃而解：&lt;strong&gt;别跟我扯犊子，什么排期我都行，只不过得加钱！&lt;/strong&gt;并且，外公司都是这么给钱的！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有几个点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;搞定老板，让他同意；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;真要外包，最多解决团队10%的人力成本就行，有个证明就行，不用占比太多；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;搞培训的话，优先抓大学生，有好的苗子可以留下培养；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上把自己当外包团队是个很妙的想法，团队内部的关注点都会逐渐转移至：&lt;strong&gt;如何养活自己&lt;/strong&gt;；团队外部对于一些不认可的业务方，便可以堂而皇之的降低其需求优先级了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体效果，等我试过后跟大家聊，这里有个一定要注意的点：&lt;strong&gt;不要把主业务搞崩了&lt;/strong&gt;，注意尺度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，这里可以给团队设定第三个目标：&lt;strong&gt;技术团队承担人力成本的10%！&lt;/strong&gt;，具体赚的钱可以跟公司分账，具体怎么分要聊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是为了保证生存，依旧要有保证核心业务的目标，不然就真做成外包团队了...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面提了一下成长问题，但公司级的上升通道建设，职级体系还是得有，如果公司这块不成熟，需要推动建设。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么职级体系很重要呢，因为升职一般伴随着加薪，所有人都看着的呢，需要规定&lt;strong&gt;做了什么工作可以获得什么成就。&lt;/strong&gt;其实只要职级体系做得好，可以解决很大的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队需要做的是将培训和分享做起来，特别是针对Leader层的干训班，具体怎么做后面有介绍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，第四、五个目标是将团队的&lt;strong&gt;职级体系搭起来&lt;/strong&gt;，其次要把&lt;strong&gt;内部培训分享搞起来&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解决了主观能动性和目标问题，接下来就要解决环境问题，要去实地考察当前环境中什么流程是多余的，什么是割裂的，多的流程要去掉，没有的流程要补，所以第六个目标是：&lt;strong&gt;核心机制流程补足&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后总结一下，为了解决我们的问题，我们提出了以下目标：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;找出团队不可或缺的20%，并证明他们优秀，想办法说服公司给予激励；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;梯队建设（职级体系+分享培训体系）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;技术团队承担人力成本的10%；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;核心机制流程补足；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来依次说说每个目标的实现思路。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;人才识别&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一步依旧是要想办法要钱，这里第一个问题就是如何证明我优秀，这里的实操思路是：&lt;strong&gt;统计每个人每周/月完成了多少任务&lt;/strong&gt;，步骤是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;周会、项目日会等会上提出待完成的任务；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;将任务分给不同的人；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;任务完成后，进行简单任务定级，存档；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;任务一般是一周以内的工作，任务过大应该被设置为OKR，然后在OKR的基础下再分解任务，所以一个周期结束，可以看到所有人完成的任务以及完成了什么样的任务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理想的情况下还可以对任务定价，那么一个人一个月赚了多少钱可以计算出来，最后任务赚来的钱/员工工资，ROI就出来了...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你拿到所有人的所有任务，并可以细化到每个人的ROI去找老板聊天的时候，相信我，他首先会给你钱，其次会让你把这套工具复用到整个公司。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;衍生一下，如果以任务为单位的形式运行的好的话，是可以算出业务方的需求价值的，如果业务方的需求没有外包的需求价值高，还可以反向PUA。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;萦绕很久的效能度量问题，结果被市场经济运作下的外包模式解决了，我真的是醉了！&lt;/strong&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;梯队建设&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的梯队建设核心围绕着上升通道（职级体系）与分享培训体系展开。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上升通道首先必须拉着HR玩，让他定义清楚当前部门的职级，并且每年什么时候达成什么条件可以升级，升级后的匹配奖励是是什么，没有这个东西，大家都只能抓瞎！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于团队成长还是首推三件事：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;CaseStudy；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;干训班培训；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;技术分享；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中技术分享不多说，说下CS与干训班：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对平时工作中爆发的工程或组织问题，需要责任人写CS（CaseStudy）文档，每周二下午，相关人一起做复盘的机制，旨在杜绝类似问题产生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于如何做CaseStudy的文章，之前复盘时候介绍了，这里不展开。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一路打怪（做项目、OKR）升级，如果”运气好“成为小leader，那么就进入了干训班辐射范围，干训班事实上更多是面向经理的”福利“，帮助经理建立管理认知的培训实践课程，比如就会涉及以下信息：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;向上管理怎么做，如何拿到资源；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;跨部门沟通的诀窍，我为什么要配合你；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;从理论到实战的差距是什么；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如何用数据说话；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;系统性解决问题，竖井效应与内卷；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;...&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些培训一般由几种元素构成（不是每个案例都会完整覆盖）：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;事件案例 -&amp;gt; 案例分析 -&amp;gt; 观点阐述 -&amp;gt; 理论、机制形成 -&amp;gt; 讨论（辩论）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果案例本身比较经典，再进一步会考虑：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要不要纳入团队机制 -&amp;gt; HowTo -&amp;gt; OKR -&amp;gt; 执行人 -&amp;gt; 形成团队案例 -&amp;gt; ......&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个公司案例不尽相同，大家不可完全套用。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;营收思路&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;技术话语权弱，也是一个长时间萦绕心间的问题，其实想要话语权只需要做两件事：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;带来营收；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;证明自己跟营收有绝对联系；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前我的想法是自己跨出圈子去做业务方，这样就能带来营收了，但是转念一想，这个其实只能证明我能带来营收，并不能证明技术团队能带来营收；而强行跟业务方拉关系，分他们的营收蛋糕，无异于低人一等，都不是好的解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，如果将自己作为&lt;strong&gt;外包团队&lt;/strong&gt;，在市场经济下，似乎情况又有所变化，我们只需要说服老板：&lt;strong&gt;我们可以自己养活自己&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来的操作就是，所有的业务方跟技术团队提需求，我们先说好一个需求多少钱，你如果不满意可以真的去找外包，这么一来的话，技术团队其实是处于公司的外包团队，我们可以选择不接有些需求：&lt;strong&gt;对不起，你那个需求太烂了，钱也少，我们不做，你去找外包吧&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们是用自身的技术能力赚取服务费用，我们&lt;strong&gt;自己养活了自己&lt;/strong&gt;，当然，不可避免可能会谈崩几次，导致赚钱的费用不足以覆盖所有技术的人力成本，这个时候就只有两个方案：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;裁员；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;接外包；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;站起来肯定要付出一些代价，但越做越小肯定不是我们的初衷，所以真实的方案只有接外包一途，这里要注意：&lt;strong&gt;接外包不可太过&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;外包带来的营收不要超过团队的10%，或者能够保证不裁员就好，不要接太多，因为多少还是有点&lt;strong&gt;不务正业的&lt;/strong&gt;，尝到甜头乐此不疲可能真的演变成外包团队，那不会是团队想要的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于如何接到外包，这个是个商务问题，大家自己去思考吧。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;流程机制&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大目标定了，如何让目标执行的更顺畅，这就需要流程机制的匹配了，比如：业务团队如何采买服务能力，如何定价，财务如何结算等等都需要有一套完整的流程，并且需要&lt;strong&gt;系统化！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是我们需要一套内部管理工具来匹配这些目标，我这里的思路是：实现了一套以任务为核心的OKR系统，具体系统如何，使用过后再拿出来分享吧。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后回到问题本身，如果当前团队一团散沙，首先要思考钱的问题，没钱的激励人们很难有启动的动力；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队初步启动后要思考目标的问题，找准当前问题的核心，和当前环境最适合解决什么；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目标落定后要解决环境问题，匹配对应的流程机制，让目标更容易发生，具体到目标实现的时候，一定要注意目标切割，先打造小案例，实现小目标，激励大家的信心，一步一步，后续就会顺畅很多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，今天的分享就到这。如果本文对你有帮助的话，欢迎&lt;strong&gt;点赞&amp;amp;评论&amp;amp;在看&amp;amp;分享&lt;/strong&gt;，这对我非常重要，感谢🙏🏻。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要更多交流可以加我微信：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5549076773566569&quot; data-type=&quot;png&quot; data-w=&quot;2058&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTAhJicnwkIFHbXOTYtyvH1rfP2N5l9gf7IviaxXFYHQ4KTAKBPjwHurzRTeIWRz55USveXYiaPNXaWMA/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9cfac4b2751da44d99562ee6d23143bf</guid>
<title>社区点赞业务缓存设计优化探索</title>
<link>https://toutiao.io/k/rplztap</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;h1&gt;&lt;strong&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内容点赞业务在得物社区中是一个非常高频的业务场景，功能本身复杂度不高，但是业务场景多、QPS高、而且由于社区的用户体量，整体点赞的数据量非常大。其中最核心、对响应性能要求最高的主要是“用户是否点赞内容”和“内容点赞数”场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在得物社区中凡是有内容消费的场景，都会有上面两个点赞场景的处理，所以整体点赞业务的&lt;span&gt;QPS&lt;/span&gt;在社区都是非常高的。当我们在刷各种Feed流时，每一次下滑，都需要对数十篇内容进行登录用户是否点赞状态的判断。作为基础业务，内容点赞业务的高性能响应，对上游内容场景的消费体验有极大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文对得物社区的点赞业务如何做到高性能响应以及历史上在缓存使用上关于高性能、稳定性、低成本上的优化探索过程进行讲述，希望能给读者带来一些收获。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;演进探索&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;v1.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社区各种Feed流及内容详情页“登录用户是否已点赞内容” “内容被赞总数” “内容最新点赞用户列表”几个场景消费展示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点赞业务整体的高性能是基于Redis+MySQL架构。&lt;span&gt;M&lt;/span&gt;&lt;span&gt;y&lt;/span&gt;&lt;span&gt;SQL&lt;/span&gt;做数据存储和查询支持，Redis撑起业务的高性能响应。在1.0版本中，服务架构还是单体PHP服务，技术方案上将动态下所有的点赞用户查询出来放到PHP数组里，然后序列化为Json字符串以Key/Value的方式存储到Redis中，当用户浏览内容时，取出缓存数据，反序列化Json为PHP数组，然后通过in_array和count方法判断是否已点赞及内容点赞数。在缓存的维护上，则是每一次有新用户点赞或取消赞则直接清除Redis。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构图下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ini&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cId =&amp;gt; &#x27;[uid1,uid2,uid3...]&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;786&quot; data-backw=&quot;578&quot; data-ratio=&quot;1.3598553345388789&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLjVTPsuVkaBsIeRZTsHhGAY8ggzlZOCtJStdKJYpXibsic3GdbRTVropw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1106&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;主要问题&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个版本的方案存在比较多待优化点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一、缓存构造时要查询动态下所有点赞用户数据，数据量大，容易产生慢SQL，对DB和带宽都可能有比较大的压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二、缓存存储数据结构上为Key/Value结构，每次使用时需先从Redis查询，再反序列化成PHP数组，in_array()和count()方法都有比较大的开销，尤其是查询热门动态时，对服务器的CPU和MEM资源都有一定浪费，对Redis也产生了比较大的网络带宽开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三、缓存维护上，每次新增点赞都直接清除缓存，热门动态大量点赞操作下会出现缓存击穿，会造成大量DB回查操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;v2.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家都知道一些热点事件很容易在社区中发酵，得物社区自然也存在这种情况。在某一场热点事件中，得物社区瞬间出现多篇热点内容，大量用户进入得物社区浏览相关动态并点赞，从v1.0版本的点赞维护流程上可以看出执行缺陷，即每次有新点赞都会清除缓存！当有大量用户浏览热点动态，同时又有大量用户在点赞而导致缓存清除的场景下，缓存被击穿的风险非常高，这样会导致大量查询请求打到DB层，研发侧在评估风险之后，连夜进行了缓存改造。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、解决热点内容缓存击穿的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、优化代码层面对缓存数据序列化和反序列化导致的服务器资源消耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次改造，除了优化解决缓存击穿的风险外，也针对之前缓存本身的一些不足之处，思考了一些更高效的实现。在缓存数据结构上摒弃了之前的Key/Value结构，采用了集合结构。集合的特性保证集合中的用户ID不会出现重复，可以准确维护了动态下的点赞总数，通过查看用户是否在集合中，可以高效判断用户是否点赞内容。这样解决每次查询时需要从Redis中获取全部数据和每次需要代码解析Json的过程，Redis集合支持直接通过&lt;strong&gt;SISMEMBER&lt;/strong&gt;和&lt;strong&gt;SCARD&lt;/strong&gt;接口判断是否赞和计算点赞数，从而提升了整个模块的响应速度和服务负载。在缓存维护上，每次有新增点赞时，主动向集合中添加用户ID，并更新缓存过期时间。每次查询时，也同样会查询缓存的剩余过期时间，如果低于三分之一，就会重新更新过期时间，这样避免了热门动态有大量新增点赞动作时，出现缓存击穿的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ini&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid =&amp;gt; [uid1,uid2,uid3...]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.191806331471136&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLDicyrXfQaoxKX0pl0RxZib22Cb6ITapfXbxszeTZiau4noCLntDOZWvgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1074&quot;/&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;主要问题&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在技术方案中，会将动态下全部的点赞记录全部查出，放入一个集合中，当动态是一个热门动态时，点赞用户量会非常大，此时集合变成了一个大Key，而大Key的清理对Redis的稳定性有比较大的影响，随时可能会因为缓存过期，而引起Redis的抖动，进而引起服务的抖动。并且每次查询出全部的点赞用户，容易产生慢SQL，对网络带宽也比较有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;v3.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、解决V2.0版本中缓存大Key风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、优化缓存重建时查询内容全部点赞用户产生的慢SQL场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在3.0版本中，对大Key进行了打散处理，对同一个动态下的点赞用户，进行打散分片再维护到缓存，每次操作缓存时先根据用户ID计算分片值，这样每个分片都具有更小的体积和更快的维护和响应速度。而点赞总数的获取，此时社区服务已经迁移到Go服务架构，我们也搭建了单独的计数服务，单独维护内容的被赞总数，节省了scard接口的消耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;makefile&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid_slice1 =&amp;gt; [uid1,uid11,uid111...] &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid_slice2 =&amp;gt; [uid2,uid22,uid222...] &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cid_slice3 =&amp;gt; [uid3,uid33,uid333...] &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.85546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLAdA9TF7thuH4gyqE2hWj1As2BM7I7iahRJwNjMbM0ibFuBIJwndCZkkg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;主要问题&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果仅仅从技术实现上看v3.0版本，似乎已经暂时达到了一个水平，在一定时间内也能正常支撑社区点赞业务的高性能响应。但是如果从业务角度和全局观念上去考虑，这个设计方案仍旧存在比较多的优化点。例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存分片中仍旧维护了被浏览动态下全部的点赞用户数据，消耗了非常大的Redis资源，也增加了缓存维护难度。缓存数据的有效使用率很低，推荐流场景下，用户浏览过的动态，几乎不会再次浏览到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前技术方案针对单篇内容进行设计，在各种Feed流场景中，查询任务在点赞服务里其实放大了十数倍。这种放大对服务器、Redis以及DB，都产生一定的资源消耗浪费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些点赞量特别多的历史动态，有人访问时均会重建缓存，重建成本高，但使用率不高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存集合分片的设计维护了较多无用数数据，也产生了大量的Key，Key在Redis中同样是占用内存空间的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;... ...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下，较高的服务器负载、Redis请求量、DB请求量。非常大的Redis资源使用(几十GB)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们需要一个更优的方案，解决优化以下现象：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Feed流场景下批量查询内容任务放大导致的服务器负载，Redis请求，DB请求放大现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、缓存更高效的存储和使用，降低缓存整体的使用量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、缓存更高的命中率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、区分冷热数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h5&gt;&lt;strong&gt;&lt;span&gt;实际Feed场景下的实现逻辑：&lt;/span&gt;&lt;/strong&gt;&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;批量查询动态点赞数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLB38awZK3hiaIGUJNVN9Nqm7bzmV4DUZCfPR7JX5uqomicapgby9RXtqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;V4.0版本&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;功能需求&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合实际业务场景，大部分场景上游服务都是批量判断是否点赞，社区的动态本身也存在一定的新鲜度(冷热)。对新缓存的要求是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、能解决Feed流场景下批量查询流量放大现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、缓存数据区分冷热，减少无效存储（能在内容和点赞用户角度都区分冷热数据）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、缓存结构要简单易维护，使业务实现要清晰明了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;实现方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、批量查询任务之所以放大是因为之前的缓存是以内容为维度进行设计，新方案要以用户为维度进行设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、旧方案中访问内容点赞数据会重建缓存，有些老旧内容重建缓存性价比低，而且内容下的点赞用户并不是一直活跃和会重新访问内容，新方案要等区分冷热数据，冷数据直接访问DB，不再进行缓存的重建/更新维护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、旧方案在维护缓存过期时间和延长过期时间的设计中，每次操作缓存都会进行ttl接口操作，QPS直接x2。新方案要避免ttl操作，但同时又可以维护缓存过期时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、缓存操作和维护要简单，期望一个Redis接口操作能达到目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以新方案Redis数据结构的选择中，能判断是否点赞、是否是冷热数据、是否需要延长过期时间，之前的集合是不能满足了，我们选择&lt;strong&gt;H&lt;/strong&gt;&lt;strong&gt;ash表结构。&lt;/strong&gt;用户ID做Key，contentId做field，考虑到社区内容ID是趋势递增的，一定程度上coententID能代表数据的冷热，在缓存中只维护&lt;strong&gt;一定时间和一定数量&lt;/strong&gt;的contentID，并且增加minCotentnID用于区分冷热数据，为了减少ttl接口的调用，还增加ttl字段用户判断缓存有效期和延长缓存过期时间。一举三得！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存结构如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &quot;userId&quot;:{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;ttl&quot;:1653532653,    //缓存新建或更新时时间戳&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;cid1&quot;:1,            //用户近一段时间点赞过的动态id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;cid2&quot;:1,            //用户近一段时间点赞过的动态id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;cidn&quot;:1,            //用户近一段时间点赞过的动态id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &quot;minCid&quot;:3540575,    //缓存中最小的动态id，用以区分冷热，&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLCnodPSI7jVfJ81oJeHBtNPLbE34s9V08HEAxXKPO3w9oYsdTRtdR2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过流程图，我们可以清晰看到， 上游Feed流，一次批量查询请求，没有了循环逻辑，最优情况下，只有一次Redis操作，业务实现也非常简单明了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后Redis查询量QPS日常峰值下降了20倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLE9DsIfsRGOCAkUYiaTibpIGbHQibIVxw11Hx7HWx9AmlZamQhku4P0jng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后接口平均RT下降了10倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2671875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLkic6aXGFTSEoZgiazeul8HfDsoeEAJaMr2oxQhPNhvYicnrGlfTdW2kcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后DB查询量QPS日常峰值下降了6倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.41605839416058393&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLmQmCMr22roW8oacLxWlGTTLQIVh3BYHb4p5Fwkbk2j6N5T4cm5XiaMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1096&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.400355871886121&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoL12TMMGz2BiaE09ic0yucknpQWcdQXUQGVOkQG6zMmLQ9xegG3mqXwXEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1124&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化前后缓存节省了16G左右存储空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.26171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74Aaicmia2Xq5pcmWYBGPEUwoLyhWgnibqzt9XJgQFcQKUFeMIE0uTM3XWQc91c9WLeMR6892QlY0Iyew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;后续&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优化不会结束，技术不会停止，技术方案会随着业务的演进而演进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本篇文章中对得物社区点赞业务缓存优化的探索演进做了相关历史背景和技术方案的解析，当前其中还有更多的细节。而这么多次版本的优化，都是根据实际的业务场景中出现的风险点以及需求不断摸索出来的，每个版本的方案也都不是完美方案，v4.0也不是最终方案，还需要开发人员也需要进一步思索，探索更优的技术方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且随着业务的不断发展迭代，会涌现出更多的场景和困难，我们一直在优化探索的路上。&lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;strong mp-original-font-size=&quot;11&quot; mp-original-line-height=&quot;17.600000381469727&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;*文&lt;/span&gt;&lt;/strong&gt;&lt;strong mp-original-font-size=&quot;11&quot; mp-original-line-height=&quot;17.600000381469727&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;/慎之&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;br mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;/&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;svg viewbox=&quot;0 0 1 1&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;section mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;svg viewbox=&quot;0 0 1 1&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt; 关注得物技术，每周一三五晚18:30更新技术干货&lt;br mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;/&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkxNTE3ODU0NA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74DWvZPADM5XknnTibzgrxuvzvLtcjycF3pIbYqpsXSWwxz9QLfqbWCufybUH4agABGQlhkqfdI0pNw/0?wx_fmt=png&quot; data-nickname=&quot;得物技术&quot; data-alias=&quot;&quot; data-signature=&quot;技术知识分享交流平台，与你一同走向技术的云端。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot; mp-original-font-size=&quot;14&quot; mp-original-line-height=&quot;22.399999618530273&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;活动推荐&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主题：得物技术沙龙-算法专场&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间：7月30日 13:50-18:00&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;报名方式：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_live_iframe&quot; data-pluginname=&quot;videosnap&quot; data-headimgurl=&quot;https://wx.qlogo.cn/finderhead/Q3auHgzwzM6A15Sbkl3fcb3MH3giciciaiaypmMpAKzLbz2rnKDXs4ia2bg/0&quot; data-username=&quot;v2_060000231003b20faec8cae28b1dc7d5cf02ea3db07785f6268ca44f543d593c9d5004c1e666@finder&quot; data-nickname=&quot;得物Tech&quot; data-desc=&quot;将在07月30日 13:50 直播&quot; data-intro=&quot;得物技术沙龙算法专场，已邀请得物电商搜索算法负责人&amp;amp;推荐算法负责人、阿里机器学习平台高级专家、阿里智能引擎技术专家分享&quot; data-noticeid=&quot;finderlivenotice-v2_060000231003b20faec8cae28b1dc7d5cf02ea3db07785f6268ca44f543d593c9d5004c1e666@finder-1658132882814577-1566451037&quot; data-type=&quot;live&quot;/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4b6a3d5b5fbcdc69307aa42eda015a79</guid>
<title>Flink Exactly-Once 投递实现浅析</title>
<link>https://toutiao.io/k/d9sm1pe</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;大数据技术与架构&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;import_bigdata&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;大数据开发、大数据面试、大数据框架、大数据实时计算、大数据离线计算Flink/Spark/Hadoop/数仓开发，干货，面试，资料下载，源码解读等&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>67dd0113c56deb9f35e0e5e0a78b29ea</guid>
<title>Babylon.js 将成构建元宇宙重要工具？专访 Babylon.js 团队负责人 | 卓越技术团队访谈录</title>
<link>https://toutiao.io/k/baoeair</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.66640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/XIibZ0YbvibkXsHOtVicBlAIxYmJfnS5KHvedAjKARITfcp1m96CJUqnHSHYqScGGtn0jSfPmKL6ulicDB3whJbxNg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;采访嘉宾 | Jason Carter&lt;/section&gt;&lt;section&gt;采访编辑 | 闫园园&lt;/section&gt;&lt;p&gt;近期，微软旗下 WebGL 框架 Babylon.js 开发者之一 David Rousset 在接受采访时透漏，微软将很快披露其在元宇宙中的愿景，同时他还在访谈中谈到了自己对元宇宙的看法。根据 Rousset 的描述，未来的互联网用户应该能够从网络上的 3D 场景或网页 ( 例如用 Babylon.js 构建 )，通过 VR 中的链接，“被传送到另一个网站，该网站将处于另一个元宇宙”。&lt;/p&gt;&lt;p&gt;虽然这只是 Rousset 个人的设想，并不代表微软的官方说法，但外界依然从他的描述中猜测微软或将把 Web 标准纳入其元宇宙战略中。而这也意味着，Babylon.js 很大概率上会成为微软构建元宇宙的重要工具。&lt;/p&gt;&lt;p&gt;Babylon.js 刚刚于五月初正式发布了 5.0 版本，带来了诸多新特性，例如跨平台原生开发、Mixed Reality Toolkit 等等。那么对于 Babylon.js 团队来说，他们接下来的目标是什么？在开发支持 WebGPU 中，有没有遇见问题和挑战？又如何看待 WebVR 和元宇宙之间的联系？针对这些问题，InfoQ 有幸采访了微软 Babylon.js 的首席工程和产品负责人 Jason Carter，以下为其部分回答译文。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：首先，请您向介绍一下自己以及您的团队目前在做的工作。&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;大家好，我叫 Jason Carter，负责领导 Babylon.js 开发团队。Babylon.js 是一套使用 JS 的开源 Web 渲染与游戏引擎，我们的目标是把它打造成世界上最强大、最美观、最简单同时也是最开放的 Web 渲染平台之一。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：请您讲讲 Babylon.js 开发的初衷是什么？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;开发 Babylon.js 的初衷，是希望帮助所有 Web 开发者在应用程序中充分运用 GPU 的强大功能。&lt;/p&gt;&lt;p&gt;WebGL 是一个面向浏览器的强大图形 API，目前已经得到全部主流浏览器的支持，但其本身既复杂又极具深度。很多 Web 开发者发现，直接使用 WebGL API 进行编程难度非常高。因此，Babylon.js 希望可以降低，甚至消除这种门槛。&lt;/p&gt;&lt;p&gt;Babylon.js 是一个非常简单的 JavaScript API，对所有开发人员都非常友好，它的意义就是简化开发流程，让更多 Web 开发者能够在自己的应用程序中利用 GPU 资源。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：有开发者认为 Babylon.js 相较其他 WebGL 框架入门稍难，您有没有推荐新手快速上手的方法？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;每个人的教育背景和从业经历有所不同，这些使我们有了不同于他人的知识和技能储备。所以在学习新的技术平台时，我们总会结合自己的独特知识、经验做出判断，比如觉得它似乎很好上手，又或者不容易掌握。&lt;/p&gt;&lt;p&gt;Babylon.js 也不例外，有些人觉得它平易近人，但也有人觉得门槛太高。但无论大家的教育背景如何，我总会向 Babylon.js 学习者推荐三大资源：&lt;/p&gt;&lt;p&gt;首先是 Babylon.js playground&lt;span&gt; &lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;https://playground.babylonjs.com/&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;，这里是最适合新手的入门课堂。大家可以在这里更改代码，并立即查看渲染结果，全程无需任何特殊设置。&lt;/p&gt;&lt;p&gt;第二个就是 Babylon.js 丰富的说明文档&lt;span&gt;（https://doc.babylonjs.com/）&lt;/span&gt;。Babylon.js 整个社区都在努力提供丰富、完整且易于理解的文档资源，这也是开启 Babylon.js 学习之旅的最佳起点。我们也一直在对文档内容做出改进，希望它能受到所有人，包括缺少开发经验的新手们的欢迎。就在两周之前，我们刚撰写了最新文档，题为《你的第一步》&lt;span&gt;（&lt;/span&gt;&lt;span&gt;https://doc.babylonjs.com/journey/theFirstStep&lt;/span&gt;&lt;span&gt;）&lt;/span&gt;，这份新文档将提供完整引导，帮助初学者一步步打开 Playground，做出更改，下载准备就绪的托管网站，最终把成果托管并运行起来。&lt;/p&gt;&lt;p&gt;最后推荐给 Babylon.js 学习者们的是社区论坛。Babylon.js 论坛&lt;span&gt;（&lt;/span&gt;&lt;span&gt;https://forum.babylonjs.com/&lt;/span&gt;&lt;span&gt;）&lt;/span&gt;汇聚了世界各地友好、善良、乐于助人的贡献者们。我想把所有美好的词汇都献给我们的社区。总之，强烈建议各位学习者来看看 Babylon.js 论坛，打个招呼并开始提问。无论什么样的问题，都会有全世界最强的 Babylon 用户热情为你解答。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：在开发 WebGPU 版本中，有没有遇见问题和挑战，是如何解决的？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;近两年来，我们一直致力于在 Babylon.js 中支持 WebGPU 。这是段疯狂、艰险，但又充满意义的探索。WebGPU 为 Web 开发者们带来了一系列令人难以置信的全新功能，例如使用计算着色器执行更高级的 GPU 运算。&lt;/p&gt;&lt;p&gt;但是想支持 WebGPU，最复杂的问题在于其中涉及一种全新的着色器语言（WGSL）。因为我们建立 Babylon.js 的目的就是发挥 WebGL 的能力，所以之前就已经完全支持 GLSL 。而这一次，我们必须考虑让 Babylon.js 支持多种着色器语言。&lt;/p&gt;&lt;p&gt;我们一直希望 Babylon.js 能够成为 Web 开发者访问 GPU 的唯一 API，避免纷繁复杂的底层浏览器 API（WebGL、WebGL2 或者 WebGPU ）再给开发者带来额外的困扰。为此，我们决定开发一些特殊的工具，将 WGSL 着色器转换为 GLSL 着色器。&lt;/p&gt;&lt;p&gt;大家可以参考此处文档，了解关于这些工具的更多信息和演示案例&lt;span&gt;（&lt;span&gt;https://doc.babylonjs.com/advanced_topics/webGPU/webGPUWGSL&lt;/span&gt;）&lt;/span&gt;。&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：在开发 Babylon.js 时，团队是如何平衡包体积、性能、功能等因素的？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;这确实是个复杂的问题，因为每位开发人员的需求各不相同。使用 Babylon.js 平台的开发者很多，所以唯一的解决方案就是提升灵活性。我们努力采用最新的 Web 标准和技术，允许大家在 Babylon.js 中进行高级摇树优化，从而在尽可能削减包大小的同时，继续保留必要的一部分功能。&lt;/p&gt;&lt;p&gt;如此一来，每个人都能获得最适合自身需求的 Babylon.js 定制版本。当然，如果各位想在浏览器上开发 3A 级游戏，需要使用到 Babylon.js 的全部功能，那也可以照单全收。总之，Babylon.js 的构建充分考虑到模块化设计，保证每位开发者的需求都能得到完美满足。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：有开发者认为 Babylon.js 包体积偏大，您和团队怎么看待这个问题？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;大家也可以根据实际需求构建定制化 Babylon.js 包。我们已经看到不少 Web 应用程序在特定场景中使用定制化 Babylon.js 包，大小仅为 92 kb；但如果需要完整功能集，大家也可以在 Web 应用中使用完整包。&lt;/p&gt;&lt;p&gt;Babylon.js 具备模块化特性，能够满足所有开发人员的具体需求。关于 Babylon.js 摇树设计的更多细节信息，请参阅我们的相关文档&lt;span&gt;（&lt;span&gt;https://doc.babylonjs.com/divingDeeper/developWithBjs/treeShaking&lt;/span&gt;）&lt;/span&gt;。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：有开发者提到，Babylon.js 面向游戏开发缺少必要的工作流和组件化设计，对此您怎么看？未来会增加必要工作流和组件化设计吗？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;其实这方面工作会一直持续下去。我们始终在努力为游戏开发者提供更多备受期待的现代功能和特性。我们也在 Babylon.js 身上倾注了不少野心勃勃的理想，希望能进一步降低游戏开发者的使用门槛，改进使用体验。&lt;/p&gt;&lt;p&gt;然而 JavaScript 仍然只支持单线程，所以 Web 游戏的开发只能依赖于一种不同于原生游戏开发的独特解决思路。但已经有不少游戏开发者利用 Babylon.js 带来了令人难以置信的精彩体验。《我的世界：经典版》、《神庙逃亡 2》等等案例都是明证，大家可以参阅此处链接&lt;span&gt;（&lt;span&gt;https://www.babylonjs.com/games/&lt;/span&gt;）&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;另外，我们还使用最新的 Babylon.js 5.0 版本开发了一段全新的《太空海盗》游戏演示&lt;span&gt;（&lt;span&gt;https://nam06.safelinks.protection.outlook.com/url=https%3A%2F%2Fspacepirates.babylonjs.com%2F&amp;amp;data=05%7C01%7Cjaca%40microsoft.com%7C5ac0429e40524ff0794708da38d66fb3%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637884790896265505%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;amp;sdata=CeLepyXYyfjIqPg1ibSNdykx4Rz8Q2sdjfq0B8MW7%2BY%3D&amp;amp;reserved=0&lt;/span&gt;）&lt;/span&gt;&lt;span&gt;，大家可以看看&lt;/span&gt;。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：目前 WebVR 技术的发展现状是怎样的？您认为元宇宙等概念是否会对推动其有较大的发展？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;WebVR 在很大程度上已经被更新的 WebXR API 所取代。Babylon.js 一直保持着对 WebXR 最新功能的跟进和支持。随着沉浸式设备在各国市场变得更便宜，普及度更高，相信人们会对创建沉浸式网络体验产生更强烈的兴趣。实际上，我们最近发现这一领域的人气和关注度已经出现了爆发式增长。&lt;/p&gt;&lt;p&gt;随着新冠疫情席卷全球，很多人被迫长期居家，远程办公。于是乎，很多企业开始使用 Babylon.js 构建起真实、生动的元宇宙体验。Frame&lt;span&gt;（&lt;/span&gt;&lt;span&gt;https://nam06.safelinks.protection.outlook.com/url=https%3A%2F%2Fframevr.io%2F&amp;amp;data=05%7C01%7Cjaca%40microsoft.com%7C5ac0429e40524ff0794708da38d66fb3%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637884790896265505%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;amp;sdata=xSHXL9%2BQD42bZ5PvrpPFDQWCQq1KRclcuxWuyU6tiFk%3D&amp;amp;reserved=0）&lt;/span&gt;就是个很好的例子。这种令人难忘的虚拟共享与共存体验完全建立在 Babylon.js 之上，也真正展现出元宇宙的价值所在。&lt;/p&gt;&lt;p&gt;所以大众对于虚拟世界的关注和渴望，一定会吸引更多人投向于沉浸式共享虚拟体验的开发中来。未来，我们也会看到更多开发者在 Babylon.js 的支持下将这种灵感转化为现实。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：Babylon.js 接下来短期目标和长期目标是什么？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;我们刚刚发布了迄今为止体量最大，变化最多，最雄心勃勃的 Babylon.js 版本——Babylon.js 5.0。但这并不是终点，我们已经在为下个版本积极筹备。我们目前最核心的开发目标，就是让开发者们能使用 Babylon.js API 在所有平台上（包括 Web 和原生平台）创建体验。&lt;/p&gt;&lt;p&gt;我们正在开发 Babylon Native 技术集合，希望让创作者们能够以 Web 优先的方式开发出跨平台体验。在这方面，我们必须想办法保证为开发者提供统一的渲染和体验效果。我们遵从社区成员们的呼吁，正在为此努力。&lt;/p&gt;&lt;p&gt;必须承认，大部分现代游戏和渲染解决方案在“跨平台”功能中并没有充分考虑到 Web 端的需求。但我们想要有所突破，从出色的 Web 体验起步，再慢慢通过统一的性能、沉浸效果和部署流程满足访问者的一切期待。我们正在关注并思考这个问题，Babylon Native 正是这项计划中的关键一环。&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：Three.js 和 Babylon.js 经常会拿来一起作比较，对此您怎么看？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;其实没啥冲突。我们也很喜欢 Three.js，欣赏那些使用 Three.js 将精彩的想法转化成现实的开发人员。我们双方相互激励，共同进步。我们有着相同 的热情，就是想把强大的 GPU 功能交付到 Web 开发者手中。&lt;/p&gt;&lt;p&gt;Three.js 和 Babylon.js 都在为这个目标而努力，我们也乐于看到共同的热情孕育出相似的成果，把理想中的效果鲜活展现在每个人眼前。所以两个有着共同努力方向的项目怎么会有冲突呢，我觉得双方更像是队友的关系。&lt;span&gt;😊&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：您认为 WebGL 标准的前景如何？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;WebGL 是个令人印象深刻的 API，而 WebGL 2 基本已经被行业视为“最终完整版”。&lt;/p&gt;&lt;p&gt;在 Babylon.js 上，我们期待能在支持 WebGPU 的浏览器上直接连通 GPU。我们坚信这个全新 API 能为全球 Web 开发者们解锁更多超能力，也为 Babylon.js 能够全面支持 WebGPU 感到无比自豪！&lt;/p&gt;&lt;section&gt;&lt;span/&gt; InfoQ：最后，您有没有想对中国开发者们想说的话？&lt;/section&gt;&lt;p&gt;&lt;strong&gt;Jason Carter：&lt;/strong&gt;感谢各位中国开发者对沉浸式 Web 开发的关注，也感谢大家支持 Babylon.js。在这里，我诚邀大家加入 Babylon.js 大家庭，了解其中蕴藏的无穷可能性。请相信，这个友好、温暖、乐于互助的社区正在敞开怀抱，欢迎你来！&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Jason Carter：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Babylon.js 负责人和技术布道者。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;本文选自《中国卓越技术团队访谈录》（2022 年第二季），本期精选了微软 Edge、蚂蚁可信原生、明源云、文因互联、Babylon.js 等技术团队在技术落地、团队建设方面的实践经验及心得体会。本期电子书已经在 InfoQ 网站上线，大家可以扫描下图二维码下载，查看更多精彩内容。&lt;/p&gt;&lt;p&gt;《中国卓越技术团队访谈录》是 InfoQ 打造的重磅内容产品，以各个国内优秀企业的 IT 技术团队为线索策划系列采访，希望向外界传递杰出技术团队的做事方法 / 技术实践，让开发者了解他们的知识积累、技术演进、产品锤炼与团队文化等，并从中获得有价值的见解。&lt;/p&gt;&lt;p&gt;访谈录现开放长期报名通道，如果你身处传统企业经历了数字化转型变革，或者正在互联网公司进行创新技术的研发，并希望 InfoQ 可以关注和采访你所在的技术团队，可以添加微信：caifangfang842852，请注明来意及公司名称。&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5555555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VNWv1iaCichLBficxsMqXQphHAPib23MgNCaI1MOAibB5X3dNzYvxYMUhRTyF9M6J5VGfQicYqMjjnh4zjw/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/p&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>39e45cda073ce3e977fd5c2ed9d032de</guid>
<title>Go 垃圾回收器指南</title>
<link>https://toutiao.io/k/kce21o1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;简介&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本指南旨在帮助高级Go语言用户更好地了解Go语言垃圾回收器的使用成本。它还提供了Go用户如何利用这些知识来提高应用程序的资源利用率的指导。它并不假设你了解垃圾回收，但假设你熟悉Go语言。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言负责安排Go语言值的存储。在大多数情况下，Go语言开发人员根本不需要关心这些值存储在哪里，或者为什么要存储。然而，在实践中，这些值通常需要存储在计算机&lt;strong&gt;物理内存&lt;/strong&gt;中，而物理内存是有限的资源。因为内存是有限的，所以必须小心地管理和回收内存，以避免在执行Go语言程序时耗尽内存。Go语言的工作就是根据需要分配和回收内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自动回收内存的另一个说法是&lt;strong&gt;垃圾回收&lt;/strong&gt;。从较高的层次上讲，垃圾回收器（或简称为GC）是一个系统，这个系统通过标识内存的哪些部分不再需要来代表应用程序回收内存。Go语言的标准工具链提供了一个运行时库，它随每个应用程序一起提供，并且这个运行时库包含了一个垃圾回收器。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，Go语言规范并不能保证本指南所描述的垃圾回收器的存在，只不过Go语言本身负责管理Go语言值的底层存储。这一省略是有意的，并允许使用完全不同的内存管理技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，本指南是关于Go语言的一个具体实现的指导，可能不适用于其他实现。具体来说，本指南适用于标准工具链（gc Go compiler和工具）。Gccgo和Gollvm都使用非常相似的GC实现，因此许多相同的概念都适用，但细节可能会有所不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，这是一个一直在修正的文档，随着时间的推移而变化，以最好地反映Go语言的最新版本。本文档目前描述的是Go语言1.19中的垃圾回收器。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;价值所在&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在深入研究GC之前，让我们首先讨论一下不需要由GC管理的内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，存储在局部变量中的非指针Go语言的值可能根本不会被Go语言的GC管理，Go语言会安排内存的分配，并将其绑定到创建它的&lt;span&gt;词法作用域&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;中。一般来说，这比依赖GC更有效率，因为Go语言编译器能够预先确定何时释放内存，并发出清理内存的机器指令。通常，我们把这种为Go语言的值分配内存的方式称为“&lt;strong&gt;栈分配&lt;/strong&gt;”，因为空间存储在goroutine栈中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果Go语言的值不能以这种方式分配内存，则Go语言编译器无法确定它的生存期，那么这些值就被称为“&lt;strong&gt;逃逸到堆&lt;/strong&gt;”。“堆”可以被认为是内存分配的一个大杂烩，Go语言的值需要被放置在堆的某个地方。在堆上分配内存的操作通常称为“动态内存分配”，因为编译器和运行库都很少会对如何使用内存以及何时可以清理内存做出假设。这就是GC的用武之地：它是一个专门标识和清理动态内存分配的系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言的值需要逃逸到堆中的原因有很多。一个原因可能是其大小是动态确定的。例如，考虑一个切片的支持数组，它的初始大小由一个变量而不是一个常量确定。请注意，逃逸到堆也必须是可传递的：如果一个Go值的引用被写入到另一个已经被确定为逃逸的Go值中，那么这个值也必须逃逸。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言的值是否逃逸取决于使用它的上下文和Go语言编译器的逃逸分析算法。当价值观逃逸时，试图准确地列举它将是脆弱和困难的：算法本身相当复杂，并且在不同的Go语言版本中会有所变化。有关如何识别哪些值逃逸而哪些值不逃逸的详细信息，请参阅&lt;span&gt;消除堆分配&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;一节。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;跟踪垃圾回收&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垃圾回收可能指自动回收内存的众多实现方法，例如引用计数。在本文档的上下文中，垃圾回收指的是跟踪垃圾回收，其通过循着指针来标识正在使用的、所谓的活动对象。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;让我们更严格地定义这些术语:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;对象&lt;/strong&gt; - 对象是一个动态分配的内存块，包含一个或多个Go值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;指针&lt;/strong&gt; - 指向对象内任何值的内存地址。这自然包括 &lt;code&gt;*T&lt;/code&gt; 形式的Go语言值，但也包括部分内置Go语言值。字符串、切片、通道、map和接口值都包含GC必须跟踪的内存地址。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对象和指向其他对象的指针一起形成&lt;strong&gt;对象图&lt;/strong&gt;。为了识别活动内存，GC从程序的&lt;strong&gt;根&lt;/strong&gt;开始遍历对象图，程序明确使用的对象的指针。根的两个例子是局部变量和全局变量。遍历对象图的过程被称为&lt;strong&gt;扫描&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此基本算法对所有跟踪GC通用。跟踪GC的不同之处在于，一旦它们发现内存是活的，它们会做什么。Go语言的GC使用了&lt;strong&gt;标记(mark)&lt;strong&gt;—&lt;/strong&gt;清除(sweep)&lt;strong&gt;技术，这意味着为了跟踪它的过程，GC也会将它遇到的值&lt;/strong&gt;标记&lt;/strong&gt;为活动的。跟踪完成后，GC将遍历堆中的所有内存，并使所有未标记的对象的内存设置为可用于分配的内存。此过程称为**扫描(scanning)**。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;您可能熟悉的另一种技术是将对象实际移动到内存的新部分，并留下一个转发指针，以后将使用该指针更新应用程序的所有指针。我们称以这种方式移动对象的GC为&lt;strong&gt;移动GC&lt;/strong&gt;; Go的GC不是这样子的，它是&lt;strong&gt;非移动GC&lt;/strong&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;GC循环&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于Go GC是一个标记—清除GC，因此它大致分为两个阶段：&lt;strong&gt;标记阶段&lt;/strong&gt;和&lt;strong&gt;清扫阶段&lt;/strong&gt;。虽然这句话似乎是重复的，但它包含了一个重要的见解：在跟踪完所有内存之前，不可能释放内存以供分配，因为可能仍有未扫描的指针使对象保持活动状态。因此，清扫动作必须与标记动作完全分开。此外，当没有与GC相关的工作要做时，GC也可能根本不活动。GC在离开(off)、标记和扫描这三种状态之间不断循环，这就是所谓的GC循环。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来的几个章节我们将集中讨论如何直观地了解GC的成本，以帮助用户调整GC参数，从而为自己谋福利。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;了解成本&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GC本质上是一个构建在更复杂系统上的复杂软件。当试图理解GC并调整其行为时，很容易陷入细节的泥潭。本节旨在提供一个框架，用于说明Go GC的开销和调优参数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开始讨论前，先了解基于四个简单公理的GC成本模型。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在GC执行时，应用程序会暂停。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;GC只涉及两种资源：CPU时间和物理内存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;GC的内存开销包括活动堆内存、标记阶段之前分配的新堆内存，以及元数据空间（即使与前两个的开销成比例，但相比之下元数据空间开销也很小）。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：活动堆内存是由上一个GC周期确定为活动的内存，而新堆内存是在当前周期中分配的任何内存，在结束时可能是活动的，也可能不是活动的。&lt;/p&gt;&lt;/blockquote&gt;&lt;ol start=&quot;4&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;GC的CPU成本被建模为每个周期的固定成本，以及与活动堆的大小成比例的边际成本(marginal cost)。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：从渐进的角度来说，清扫的伸缩性比标记和扫描要差，因为它必须执行与整个堆的大小成比例的工作，包括被确定为非活动（即“死”）的内存。然而，在当前的实现中，清扫操作比标记和扫描快得多，因此在本讨论中可以忽略其相关成本。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种模型简单而有效：它准确地对GC的主要成本进行了分类。然而，这个模型没有说明这些成本的规模，也没有说明它们是如何相互作用的。为了对此建模，考虑以下情况，我们称这种场景为&lt;strong&gt;稳态&lt;/strong&gt;(steady-stat)。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;应用程序分配新内存的速率（以字节/秒为单位）是恒定的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：重要的是要理解这个分配率与这个新内存是否是活动的完全无关。没有一个是活的，所有的都是活的，或者一部分是活的都有可能。(除此之外，一些旧的堆内存也可能死亡，因此，如果该内存是活动的，活动堆大小不一定会增长。）
更具体地说，假设有一个web服务为它处理的每个请求分配2 MiB的总堆内存。在请求过程中，2 MiB中最多有512 KiB在请求进行期间保持活动状态，当服务完成对请求的处理时，所有这些内存都会死亡。稳定的请求流（比如每秒100个请求）会产生200 MiB/s的分配率和50 MiB的峰值活动堆。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;应用程序的对象图每次看起来都大致相同（对象的大小相似，指针的数量大致恒定，图的最大深度大致恒定）。另一种思考方式是GC的边际成本是恒定的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：稳态可能看起来是人为的，但它的确代表了应用程序在某个恒定工作负载下的行为。当然，在应用程序执行时，工作负载也可能发生变化，但通常应用程序行为看起来总体上像是一串稳定状态，中间穿插着一些瞬态行为。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：稳定状态对活动堆没有任何假设。它可能会随着每个后续GC周期而增长，可能会缩小，也可能会保持不变。然而，试图在下面的解释中包含所有这些情况很无聊乏味，而且不是很有说明性，所以本指南将重点放在活动堆保持不变的示例上。GOGC一节会更详细地探讨了非常量活动堆的场景。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在活动堆大小不变的稳定状态下，只要GC在经过相同的时间后执行，每个GC周期在成本模型中看起来都是相同的。这是因为在固定的时间内，如果应用程序的分配速率是固定的，则将分配固定数量的新堆内存。因此，在活动堆大小不变的情况下，新的堆大小&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在活动堆大小不变的稳定状态下，只要GC在经过相同的时间后执行，每个GC周期在成本模型中看起来都是相同的。这是因为在固定的时间内，如果应用程序的分配速率是固定的，则将分配固定数量的新堆内存。因此，在活动堆大小和新堆内存保持不变的情况下，内存使用量将始终保持不变。而且因为活动堆的大小相同，所以边际GC CPU成本也相同，并且固定成本将以某个固定间隔发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在考虑GC如果延迟，发生在稍后时间应该运行的点之后， 因此将分配更多的内存，但每个GC周期仍将导致相同的CPU开销。但是，在其他固定的时间窗口中，完成的GC周期会更少，从而降低了总体CPU成本。如果GC决定提前启动，则情况正好相反：将分配较少的内存并且将更频繁地引起CPU成本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况代表了GC可以在CPU时间和内存之间进行的基本权衡，由GC实际执行的频率来控制。换句话说，折衷完全由GC的频率定义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一个细节需要定义，那就是GC应该决定何时开始。注意，这直接设置了任何特定稳态下的GC频率，从而定义了折衷。在Go语言中，决定GC何时启动是用户可以控制的主要参数。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;GOGC&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GOGC是Go GC的一个调优参数，它通过控制GC频率直接反映了CPU时间和内存之间的平衡。更具体地说，GOGC设置GC的目标堆大小，或者在标记阶段完成之前应该分配的新内存量。GOGC被定义为GC需要完成的工作量的百分比开销。这项工作目前被定义为活动堆的大小加上GC根的大小（以字节为单位）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个例子，假设一个Go语言程序，它有8 MiB的堆，1 MiB的goroutine栈，1 MiB的全局变量指针。如果GOGC值为100，则在下一次GC运行之前将分配的新内存量将为10 MiB，或10 MiB工作量的100%，总堆占用量为18 MiB。如果GOGC值为50，则它将为50%，即分配的新内存量为5 MiB。如果GOGC值为200，则为200%，即分配的新内存量20 MiB。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：GOGC可以更精确地描述为定义在下一个扫描阶段开始之前可以分配的新内存量。从技术上讲，这个记时对于本指南目前使用的GC模型来说是正确的，但是它也适用于Go语言使用的真实GC实现，在延迟一节中会有更详细的讨论。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以这种方式定义权衡(trade-off)的好处是，无论GC必须完成的工作量如何（也就是说，无论活动堆和根集的大小如何），GC的成本在稳态下都保持不变，因为频率总是与必须完成的工作量成比例。换句话说，它代表了CPU成本和内存使用之间权衡的一个固定点。(需要注意的是，如果稳定状态也发生变化，则此固定点也可能发生偏移，但关键是它不依赖于活动堆的大小。）&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：GOGC 自Go 1.18开始包含根集， 以前它只对活动堆进行计数。通常，goroutine堆栈中的内存量非常小，并且活动堆的大小支配着GC的所有其他工作来源, (所以先前的计算大概也没问题,) 但是当程序有几十万个goroutine时，GC会做出错误的判断。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GOGC可以通过GOGC环境变量（所有Go语言程序都能识别）或者&lt;code&gt;runtime/debug&lt;/code&gt;包中的&lt;code&gt;SetGCPercent&lt;/code&gt; API来配置。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;请注意，GOGC也可用于通过设置&lt;code&gt;GOGC=off&lt;/code&gt;或调用&lt;code&gt;SetGCPercent(-1)&lt;/code&gt;来完全关闭GC（前提是memory limit没有使用）。从概念上讲，此设置等效于将GOGC设置为无穷大值，因为在触发GC之前新内存的数量是无限的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了更好地理解我们到目前为止讨论的所有内容，请尝试下面的交互式可视化，它是基于前面讨论的GC成本模型构建的。该可视化描述了某个程序的执行，该程序的非GC工作需要10秒的CPU时间才能完成。在进入稳定状态之前的第一秒，它执行一些初始化步骤（增长其活动堆）。应用程序总共分配200 MiB，其中20 MiB一次处于活动状态。它假设要完成的唯一相关GC工作来自活动堆，并且（不现实地）应用程序不使用额外的内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用滑块调整GOGC的值，以查看应用程序在总持续时间和GC开销方面的响应情况。每次GC循环都会在新堆降为零时发生。X轴移动以始终显示程序的完整CPU持续时间。请注意，GC使用的额外CPU时间会增加总持续时间。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/figure&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.26171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvtoF5TwxAA6PLTA6yFzgu1KGadaab09l269c1I8tVq4JDq2r6YUPzrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，GC总是会导致一些CPU和峰值内存开销。随着GOGC的增加，这些CPU开销降低，但峰值内存与活动堆大小成比例增加。随着GOGC的减小，峰值内存需求也会减少，但会增加额外的CPU开销。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：图形显示的是CPU时间，而不是完成程序所需的挂钟时间(wall-clock time)。如果程序在1个CPU上运行并充分利用其资源，则它们是等效的。真实的的程序可能运行在多核系统上，并且不会始终100%地利用CPU。在这些情况下，GC的挂钟时间影响会比较低。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：Go GC的最小总堆大小为4 MiB，因此如果GOGC设置的目标值低于该值，则会取整。这个图形展示反映此细节。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有一个动态的和更有真实感的例子。同样，在没有GC的情况下，应用程序需要10个CPU秒才能完成，但在中途，稳态分配率急剧增加，并且活动堆大小在第一阶段发生了一些变化。这个示例演示了当活动堆大小实际上发生变化时，稳定状态可能是什么样子的，以及更高的分配率如何导致更频繁的GC周期。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvBSPKjA2kjicsCcIia0OL7ib6gmwiaYfqLIHw8GKTI0c1LmAsZTG7MJIoLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;内存限制 （memory limit）&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在Go 1.19之前，GOGC是唯一一个可以用来修改GC行为的参数。虽然它作为一种设置权衡(trade-off)的方式非常有效，但它没有考虑到可用内存是有限的。考虑当活动堆大小出现短暂峰值时会发生什么情况：因为GC将选择与活动堆大小成比例的总堆大小，所以GOGC必须被配置为峰值活动堆大小相匹配的值，即使在通常情况下，较高的GOGC值会提供了更好的权衡效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面的可视化演示了这种瞬态堆峰值情况。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.28203125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvomNjpheNo6vdiagYXPJSTL35zxvmuJL59ZLsuibAy8fic3OtLMJIicy3VQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果示例工作负载在可用内存略高于60 MiB的容器中运行，则GOGC不能增加到100以上，即使其余GC周期有可用内存来使用该额外内存。此外，在一些应用中，这些瞬时峰值可能是罕见的并且难以预测，从而导致偶然的、不可避免的并且可能代价高昂的内存不足情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是为什么在1.19版本中，Go语言增加了对设置运行时内存限制的支持。内存限制可以通过所有Go语言程序都能识别的&lt;strong&gt;GOMEMLIMIT&lt;/strong&gt;环境变量来配置，也可以通过&lt;code&gt;runtime/debug&lt;/code&gt;包中的&lt;code&gt;SetMemoryLimit&lt;/code&gt;函数来配置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个内存限制设置了Go语言运行时可以使用的最大内存总量。包含的特定内存集是&lt;code&gt;runtime.MemStats&lt;/code&gt;的&lt;code&gt;Sys - HeapReleased&lt;/code&gt;的值，或者等价于&lt;code&gt;runtime/metrics&lt;/code&gt;的公式&lt;code&gt;/memory/classes/total:bytes - /memory/classes/heap/released:bytes&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为Go GC可以显式控制它使用多少堆内存，所以它会根据这个内存限制和Go运行时使用的其他内存来设置总的堆大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面的可视化描述了来自GOGC部分的相同的单阶段稳态工作负载，但这次Go运行时额外增加了10 MiB的开销，并且内存限制可调。尝试在GOGC和内存限制之间移动，看看会发生什么。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvfIBw2MJVATFp8E2WxW8JNDTPG31PvI0y1wawlI2nAtSQGu1K5ic4pBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，当内存限制降低到GOGC确定的峰值内存（GOGC为100时为42 MiB）以下时，GC会更频繁地运行，以将峰值内存保持在限制的内存之下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回到我们前面的瞬态堆峰值的例子，通过设置内存限制并打开GOGC，我们可以获得两个世界的最佳结果：不违反内存限制，且更好地节约资源。请尝试以下交互式可视化。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.25625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/0qAgGEpTiazHIibWGwmibB23l1RKKFQecibvfXkURiaQu1cQ2tgvMHMA5Welhle78YLYFI3JTuqBQShj9Iqj21v3O8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，对于GOGC的某些值和内存限制，峰值内存使用在内存限制为多少时停止，但程序执行的其余部分仍然遵守GOGC设置的总堆大小规则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一观察引出了另一个有趣的细节：即使GOGC设置为关闭，内存限制仍然有效! 实际上，这种特定的配置代表了资源经济的最大化，因为它设置了维持某个内存限制所需的最小GC频率。在这种情况下，所有程序的执行都会使堆大小增加以满足内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在，虽然内存限制显然是一个强大的工具，&lt;strong&gt;但使用内存限制并不是没有代价的&lt;/strong&gt;，当然也不会使GOGC的实用性失效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请考虑当活动堆增长到足以使总内存使用量接近内存限制时会发生什么。在上面的稳定状态可视化中，尝试关闭GOGC，然后慢慢地进一步降低内存限制，看看会发生什么。请注意，应用程序花费的总时间将开始以无限制的方式增长，因为GC不断地执行以维持不可能的内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况，即程序由于不断的GC循环而无法取得合理的进展，称为系统颠簸(thrashing)。这是特别危险的，因为它严重地拖延了程序。更糟糕的是，它可能会发生在我们试图避免使用GOGC的情况下：一个足够大临时堆尖峰会导致程序无限期地停止! 尝试在瞬态堆峰值可视化中降低内存限制（大约30 MiB或更低），并注意最坏的行为是如何从堆峰值开始的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在许多情况下，无限期暂停比内存不足情况更糟，因为后者往往会导致更快的失败以便我们发现和处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，内存限制被定义为软限制。Go语言运行时并不保证在任何情况下都能保持这个内存限制;它只承诺了一些合理的努力。内存限制的放宽对于避免系统颠簸行为至关重要，因为它为GC提供了一条出路：让内存使用超过限制以避免在GC中花费太多时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这在内部是如何工作的？GC mitigates 设置了一个在某个时间窗口内可以使用的CPU时间量的上限（对于CPU使用中非常短的瞬时峰值，有一些滞后）。此限制当前设置为大约50%，具有&lt;code&gt;2 * GOMAXPROCS CPU-second&lt;/code&gt;窗口。限制GC CPU时间的结果是GC的工作被延迟，同时Go程序可能会继续分配新的堆内存，甚至超过内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;50% GC CPU限制背后的直觉是基于对具有充足可用内存的程序的最坏情况影响。在内存限制配置错误的情况下，它被错误地设置得太低，程序最多会慢2倍，因为GC占用的CPU时间不能超过50%。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：此页上的可视化不会模拟GC CPU限制。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;建议用法&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然内存限制是一个强大的工具，Go语言运行时也会采取措施来减少误用造成的最坏行为，但谨慎使用它仍然很重要。下面是一些关于内存限制在哪些地方最有用，以及在哪些地方可能弊大于利的建议。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当Go语言程序的执行环境完全在你的控制之下，并且Go语言程序是唯一可以访问某些资源的程序时（也就是说，某种内存预留，就像容器内存限制一样），一定要利用内存限制。一个很好的示例是将web服务部署到具有固定可用内存量的容器中。&lt;strong&gt;在这种情况下，一个很好的经验法则是，留出额外的5-10%的空间来处理Go语言运行时不知道的内存资源。&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;请随时调整内存限制，以适应不断变化的条件。一个很好的例子是cgo程序，其中C库暂时需要使用更多的内存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;如果Go语言程序可能会与其他程序共享有限的内存，那么不要将GOGC设置为off，因为这些程序通常与Go语言程序是解耦的。相反，保留内存限制，因为它可能有助于抑制不需要的瞬态行为，但将GOGC设置为某个较小的、对于一般情况而言合理的值。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然尝试为共享程序“保留”内存是很诱人的，但除非程序完全同步（例如，Go程序在被调用程序执行时调用某些子进程和阻塞），否则结果将不太可靠，因为两个程序都不可避免地需要更多内存。让Go程序在不需要内存的时候使用更少的内存，总体上会产生更可靠的结果。此建议也适用于过量使用的情况，在这种情况下，在一台计算机上运行的容器的内存限制之和可能会超过该计算机可用的实际物理内存。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当部署到您无法控制的执行环境时，不要使用内存限制，特别是当程序的内存使用与其输入成比例时。CLI工具或桌面应用程序就是一个很好的例子。在不清楚可能输入什么类型的输入，或者系统上可能有多少可用内存时，将内存限制写入程序可能会导致混乱的崩溃和性能下降。此外，高级最终用户可以根据需要设置内存限制。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当程序已经接近其环境的内存限制时，不要设置内存限制以避免内存不足的情况。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这有效地将内存不足的风险替换为严重的应用程序速度减慢的风险，这通常不是一个有利的交易，即使Go语言努力减轻系统颠簸。在这种情况下，提高环境的内存限制（然后可能设置内存限制）或降低GOGC（这提供了比系统颠簸缓解更干净的权衡）将更加有效。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;延迟时间&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到目前为止，本文将应用程序建模在在GC执行时会暂停这一公理上。确实存在这样的GC实现，它们被称为&lt;strong&gt;stop-the-world&lt;/strong&gt; GC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，Go GC并不是完全停止工作，实际上它的大部分工作都是与应用程序同时进行的。这样做的主要原因是它减少了应用程序延迟。具体来说，延迟是指单个计算单元（例如，web请求）的端到端持续时间。到目前为止，本文主要考虑应用程序吞吐量，或这些操作的聚合（例如，每秒处理的web请求）。请注意，GC周期部分中的每个示例都侧重于执行程序的总CPU持续时间。然而，这样的持续时间对于例如web服务来说意义要小得多，web服务的持续时间主要捕获可靠性（即uptime）而不是成本。虽然吞吐量（即每秒的查询数）对于web服务仍然很重要，但通常每个单独请求的延迟甚至更重要，因为它与其他重要指标相关。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就延迟而言，stop-the-world GC可能需要相当长的时间来执行其标记和扫描阶段，在此期间，应用程序以及在web服务的上下文中的任何正在进行的请求都无法取得进一步的进展。相反，Go GC确保了任何全局应用程序暂停的长度都不会以任何形式与堆的大小成比例，并且在应用程序主动执行的同时执行核心跟踪算法。这种选择并非没有成本，因为在实践中，它往往会导致吞吐量较低的设计，但需要注意的是，低延迟并不必然意味着低吞吐量，即使在许多情况下，这两者并不一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，Go GC的并发特性可能看起来与前面介绍的成本模型有很大的不同。幸运的是，模型背后的直觉仍然适用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然第一条公理不再成立，但它开始并不是那么重要;其余的成本仍然如模型所描述的那样，并且使用相同的稳态概念。因此，GC频率仍然是GC在CPU时间和内存吞吐量之间进行权衡的主要方式，它还承担了延迟的角色。关于吞吐量，只要假设并发GC所产生的所有小开销都发生在GC周期的末尾，就很容易回到模型的范围内。关于延迟，GC增加的延迟中的大部分特别来自标记阶段处于活动状态的时间段。因此，GC处于标记阶段的频率越高，这些成本就越频繁地发生，因此等待时间也跟随GC频率。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;更具体地，调整GC参数以降低GC频率也可以导致延迟改善。这意味着需要增加GOGC和/或内存限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，理解延迟通常比理解吞吐量更复杂，因为它是程序即时执行的产物，而不仅仅是成本的聚合之物。因此，延迟和GC频率之间的联系更加脆弱，可能不那么直接。下面是一个可能导致延迟的来源列表，供那些倾向于深入研究的人使用。这些延迟源在执行跟踪中是可见的。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;当GC在标记和清除阶段之间转换时，&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;调度延迟是因为GC在标记阶段占用了25%的CPU资源，&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;用户goroutine贡献出来以便辅助GC处理高内存分配率&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当GC处于标记阶段时，指针写入需要额外的处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;运行中的goroutine必须被暂停，以便扫描它们的根。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;其他资源&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然上面提供的信息是准确的，但它缺乏充分理解Go GC设计中的成本和权衡的细节。有关详细信息，请参阅以下其他资源。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;The GC Handbook&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt; — 一个垃圾收集器设计的优秀通用资源和参考资料。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;TCMalloc&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt; — C/C++内存分配器TCMalloc的设计文档，Go内存分配器就是基于此。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Go 1.5 GC announcement&lt;/span&gt;&lt;sup&gt;[5]&lt;/sup&gt; — 官方介绍Go 1.5并发GC的博客文章，其中更详细地描述了算法。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Getting to Go&lt;/span&gt;&lt;sup&gt;[6]&lt;/sup&gt; — 深入介绍Go GC设计到2018年的演变&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Go 1.5 concurrent GC pacing&lt;/span&gt;&lt;sup&gt;[7]&lt;/sup&gt; — 确定何时开始并发标记阶段的设计文档&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Smarter scavenging&lt;/span&gt;&lt;sup&gt;[8]&lt;/sup&gt; — 订正Go运行时向操作系统返回内存的方式的设计文档&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Scalable page allocator&lt;/span&gt;&lt;sup&gt;[9]&lt;/sup&gt; — 订正Go运行时管理其从操作系统获得的内存的方式的设计文档&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;GC pacer redesign (Go 1.18)&lt;/span&gt;&lt;sup&gt;[10]&lt;/sup&gt; — 用于修改算法以确定何时开始并发标记阶段的设计文件&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Soft memory limit (Go 1.19)&lt;/span&gt;&lt;sup&gt;[11]&lt;/sup&gt; — 软内存限制的设计文件&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;关于虚拟内存注意事项&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本指南主要关注GC的物理内存使用，但经常出现的一个问题是你到底想说个啥，以及它与虚拟内存的比较（通常在像top这样的程序中表示为“VSS”）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;物理内存是大多数计算机中实际物理RAM芯片中的内存。虚拟内存是由操作系统提供的物理内存上的抽象，用于将程序彼此隔离。程序保留完全不映射到任何物理地址的虚拟地址空间通常也是可以接受的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;由于虚拟内存只是操作系统维护的映射，因此保留不映射到物理内存的大型虚拟内存通常非常便宜。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go语言运行时通常在以下几个方面依赖于这种虚拟内存开销视图：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Go语言运行时不会删除它所映射的虚拟内存。相反，它使用大多数操作系统提供的特殊操作来显式释放与某个虚拟内存范围相关联的任何物理内存资源。该技术被显式地用于管理内存限制，并将Go语言运行时不再需要的内存返回给操作系统。Go运行时也会在后台连续释放不再需要的内存。有关详细信息，请参阅其他资源。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;在32位平台上，Go运行时会为堆预留128 MiB到512 MiB的地址空间，以限制碎片问题。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Go语言运行时在实现几个内部数据结构时使用了大量的虚拟内存地址空间预留。在64位平台上，它们通常具有大约700 MiB的最小虚拟内存占用量。在32位平台上，它们的占用空间可以忽略不计。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，虚拟内存指标，比如top中的“VSS”，在理解Go语言程序的内存占用方面通常不是很有用。相反，应该关注“RSS”和类似的度量，它们更直接地反映了物理内存的使用情况。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;优化指南&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;确定成本&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在尝试优化Go语言应用程序与GC的交互方式之前，首先确定GC是一个主要的开销，这一点很重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go生态系统提供了大量的工具来识别成本和优化Go应用程序。有关这些工具的简要概述，请参阅&lt;span&gt;诊断指南&lt;/span&gt;&lt;sup&gt;[12]&lt;/sup&gt;。在这里，我们将重点讨论这些工具的一个子集，以及应用它们的合理顺序，以便理解GC的影响和行为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;** 1、CPU profile**&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优化程序的一个很好的起点是&lt;span&gt;CPU profiling&lt;/span&gt;&lt;sup&gt;[13]&lt;/sup&gt;。CPU profiling提供了CPU时间花费在何处的概述，尽管对于未经训练的眼睛来说，可能很难确定GC在特定应用程序中所起作用的大小。幸运的是，理解profile的GC主要归结为了解&lt;code&gt;runtime&lt;/code&gt;包中不同函数的含义即可。以下是这些函数中用于解释CPU profile文件的有用子集。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：下面列出的函数不是叶函数，因此它们可能不会显示在pprof工具为top命令提供的默认值中。相反，使用&lt;code&gt;top cum&lt;/code&gt;命令或直接对这些函数使用&lt;code&gt;list&lt;/code&gt;命令，并将注意力集中在累计百分比列上。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;runtime.gcBgMarkWorker&lt;/strong&gt;: 专用标记工作goroutine的入口点。这里花费的时间与GC频率以及对象图的复杂性和大小成比例。它表示应用程序标记和扫描所用时间的基准。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：在一个大部分时间都处于空闲状态的Go应用程序中，Go GC会消耗额外的（空闲的）CPU资源来更快地完成任务。结果，该符号可以表示它认为是免费采样部分。一个常见的原因是，一个应用程序完全在一个goroutine中运行，但是GOMAXPROCS &amp;gt; 1。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;runtime.mallocgc&lt;/strong&gt;:堆内存的内存分配器的入口点。此处花费的大量累积时间（&amp;gt; 15%）通常表示分配了大量内存。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;runtime.gcAssistAlloc&lt;/strong&gt;: goroutine进入这个函数是为了腾出一些时间来帮助GC进行扫描和标记。这里花费的大量累积时间（&amp;gt; 5%）表明应用程序在分配速度方面可能超过了GC。它表示GC的影响程度特别高，并且还表示应用程序在标记和扫描上花费的时间。请注意，它包含在&lt;code&gt;runtime.mallocgc&lt;/code&gt;调用树中，因此它也会使该调用树累计时间增加。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2、执行跟踪&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然CPU profile文件非常适合用于确定时间在聚合中的花费点，但对于指示更细微、更罕见或与延迟具体相关的性能成本，它们的用处不大。另一方面，执行跟踪提供了Go语言程序执行的一个短窗口的丰富而深入的视图。它们包含了与Go GC相关的各种事件，可以直接观察到具体的执行路径，沿着应用程序与Go GC的交互方式。所有被跟踪的GC事件都在跟踪查看器中被方便地标记为GC事件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有关如何开始使用执行跟踪的信息，请参阅 &lt;span&gt;runtime/trace&lt;/span&gt;&lt;sup&gt;[14]&lt;/sup&gt; 的文档。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;** 3、GC跟踪**&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当所有其他方法都失败时，Go GC还提供了一些不同的特定跟踪，这些跟踪提供了对GC行为的更深入的了解。这些踪迹总是被直接打印到 STDERR 中，每个GC循环一行，并且通过所有Go语言程序都能识别的 GODEBUG 环境变量来配置。它们主要用于调试Go GC本身，因为它们需要对GC实现的细节有一定的了解，但是偶尔也可以用于更好地理解GC的行为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过设置&lt;code&gt;GODEBUG=gctrace=1&lt;/code&gt;，可以启用核心GC跟踪。此跟踪生成的输出记录在&lt;span&gt;runtime&lt;/span&gt;&lt;sup&gt;[15]&lt;/sup&gt;包文档的环境变量部分中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个称为&lt;code&gt;pacer trace&lt;/code&gt;的技术用来补充GC跟踪，提供了更深入的见解，它通过设置&lt;code&gt;GODEBUG=gcpacertrace=1&lt;/code&gt;来启用。解释这个输出需要理解GC的&lt;code&gt;pacer&lt;/code&gt;（参见&lt;span&gt;其他参考资料&lt;/span&gt;&lt;sup&gt;[16]&lt;/sup&gt;），这超出了本指南的范围。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;消除堆分配&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;降低GC成本的一种方法是让GC开始管理较少的值。下面描述的技术可以带来一些最大的性能改进，因为正如GOGC部分所展示的，Go语言程序的分配率是GC频率的一个主要因素，GC频率是本指南使用的关键成本度量。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;堆分析&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在确定GC是一个巨大开销的来源之后，消除堆分配的下一步是找出它们中的大多数来自哪里。为此，内存 profile 文件（实际上是堆内存 profile 文件）非常有用。请查看&lt;span&gt;文档&lt;/span&gt;&lt;sup&gt;[17]&lt;/sup&gt;以了解如何开始使用它们。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存 profile 文件描述了程序堆中分配的来源，并通过分配时的堆栈跟踪来标识它们。每个内存 profile 文件可以按四种方式分析：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;inuse_objects - 活动对象的数量&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;inuse_space - 按活动对象使用的内存量（以字节为单位&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;alloc_objects - 自Go程序开始执行以来已经分配的对象数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;alloc_space - 自Go程序开始执行以来所分配的内存总量&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这些不同的堆内存视图之间切换可以通过pprof工具的 &lt;code&gt;-sample_index&lt;/code&gt;标志来完成，或者在交互式使用该工具时通过&lt;code&gt;sample_index&lt;/code&gt;选项来完成。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：默认情况下，内存 profile 文件只对堆对象的子集进行采样，因此它们不会包含有关每个堆分配的信息。但是，这足以找到热点。若要更改采样率，请参见&lt;span&gt;runtime.MemProfileRate&lt;/span&gt;&lt;sup&gt;[18]&lt;/sup&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了降低GC成本，alloc_space通常是最有用的视图，因为它直接对应于分配率。此视图将指示可提供最大益处的分配热点。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;逃逸分析&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦在&lt;span&gt;堆 profile 文件&lt;/span&gt;&lt;sup&gt;[19]&lt;/sup&gt;的帮助下确定了候选堆分配点，如何消除它们？关键是要利用Go语言编译器的逃逸分析，让Go语言编译器为这个内存找到替代的、更有效的存储空间，比如在goroutine栈中。幸运的是，Go语言编译器能够描述为什么要将Go语言的值逃逸到堆中。有了这些知识，就变成了重新组织源代码以改变分析结果的问题（这通常是最困难的部分，但超出了本指南的范围）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于如何从Go语言编译器的逃逸分析中获取信息，最简单的方法是通过Go语言编译器支持的调试标志，该标志以文本格式描述了对某个包应用或未应用的所有优化。这包括值是否逃逸。尝试下面的命令，其中&lt;code&gt;package&lt;/code&gt;是Go语言包的路径:&lt;code&gt;$go build-gcflags=-m=3 软件包&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此信息也可以在VS代码中可视化为覆盖图。此覆盖在VS Code Go插件设置中配置和启用:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;设置&lt;span&gt;ui.codelenses设置以包括gc_details&lt;/span&gt;&lt;sup&gt;[20]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过&lt;span&gt;将ui.diagnostic.annotations设置为包括逃逸，启用逃逸分析的覆盖&lt;/span&gt;&lt;sup&gt;[21]&lt;/sup&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，Go编译器以机器可读（JSON）格式提供了这些信息，可以用来构建其他定制工具。有关这方面的更多信息，请参见&lt;span&gt;Go语言源代码中的文档&lt;/span&gt;&lt;sup&gt;[22]&lt;/sup&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;基于特定实现的优化&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go GC对活动内存的人口统计很敏感，因为对象和指针的复杂图既限制了并行性，又为GC生成了更多的工作。因此，GC包含了一些针对特定公共结构的优化。下面列出了对性能优化最直接有用的方法。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：应用下面的优化可能会因为混淆意图而降低代码的可读性，并且可能无法在Go语言的各个版本中保持。希望只在最重要的地方应用这些优化。可以使用确定成本一节中列出的工具来确定这些地点。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，从并不严格需要指针的数据结构中消除指针可能是有利的，因为这减少了GC施加在程序上的缓存压力。因此，依赖于指针值上的索引的数据结构虽然类型化较差，但可能执行得更好。只有当对象图很复杂并且GC花费大量时间进行标记和扫描时，才值得这样做。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，将结构类型值中的指针字段分组在值的开头可能是有利的。只有当应用程序花费大量时间进行标记和扫描时，才值得这样做。(理论上，编译器可以自动执行此操作，但尚未实现，并且结构字段的排列方式与源代码中所写的相同。）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，GC必须与它所看到的几乎每个指针交互，因此，例如，使用切片中的索引而不是指针，可以帮助降低GC成本。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;译者著， 这篇文章， 和Russ Cox的那三遍关于Go内存的模型一样， 里面有众多的未解释的名词，不是那么容易进行翻译，而Go语言规范和Go内存相对就容易理解和翻译了。我之所以尝试翻译，最重要的原因想深入学习本文介绍的相关知识，疏漏之处，欢迎斧正。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go官方原文: &lt;span&gt;A Guide to the Go Garbage Collector&lt;/span&gt;&lt;sup&gt;[23]&lt;/sup&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;词法作用域: &lt;em&gt;https://go.dev/ref/spec#Declarations_and_scope&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;消除堆分配: &lt;em&gt;https://tip.golang.org/doc/gc-guide#Eliminating_heap_allocations&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;The GC Handbook: &lt;em&gt;https://tip.golang.org/doc/gc-guide#:~:text=following%20additional%20resources.-,The%20GC%20Handbook,-%E2%80%94An%20excellent%20general&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;TCMalloc: &lt;em&gt;https://google.github.io/tcmalloc/design.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[5]&lt;/span&gt;&lt;p&gt;Go 1.5 GC announcement: &lt;em&gt;https://go.dev/blog/go15gc&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[6]&lt;/span&gt;&lt;p&gt;Getting to Go: &lt;em&gt;https://go.dev/blog/ismmkeynote&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[7]&lt;/span&gt;&lt;p&gt;Go 1.5 concurrent GC pacing: &lt;em&gt;https://docs.google.com/document/d/1wmjrocXIWTr1JxU-3EQBI6BK6KgtiFArkG47XK73xIQ/edit&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[8]&lt;/span&gt;&lt;p&gt;Smarter scavenging: &lt;em&gt;https://github.com/golang/go/issues/30333&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[9]&lt;/span&gt;&lt;p&gt;Scalable page allocator: &lt;em&gt;https://github.com/golang/go/issues/35112&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[10]&lt;/span&gt;&lt;p&gt;GC pacer redesign (Go 1.18): &lt;em&gt;https://github.com/golang/go/issues/44167&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[11]&lt;/span&gt;&lt;p&gt;Soft memory limit (Go 1.19): &lt;em&gt;https://github.com/golang/go/issues/48409&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[12]&lt;/span&gt;&lt;p&gt;诊断指南: &lt;em&gt;https://tip.golang.org/doc/diagnostics&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[13]&lt;/span&gt;&lt;p&gt;CPU profiling: &lt;em&gt;https://pkg.go.dev/runtime/pprof#hdr-Profiling_a_Go_program&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[14]&lt;/span&gt;&lt;p&gt;runtime/trace: &lt;em&gt;https://pkg.go.dev/runtime/trace&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[15]&lt;/span&gt;&lt;p&gt;runtime: &lt;em&gt;https://pkg.go.dev/runtime#hdr-Environment_Variables&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[16]&lt;/span&gt;&lt;p&gt;其他参考资料: &lt;em&gt;https://tip.golang.org/doc/gc-guide#Additional_resources&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[17]&lt;/span&gt;&lt;p&gt;文档: &lt;em&gt;https://pkg.go.dev/runtime/pprof#hdr-Profiling_a_Go_program&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[18]&lt;/span&gt;&lt;p&gt;runtime.MemProfileRate: &lt;em&gt;https://pkg.go.dev/runtime#pkg-variables&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[19]&lt;/span&gt;&lt;p&gt;堆 profile 文件: &lt;em&gt;https://tip.golang.org/doc/Heap_profiling&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[20]&lt;/span&gt;&lt;p&gt;ui.codelenses设置以包括gc_details: &lt;em&gt;https://github.com/golang/vscode-go/wiki/settings#uicodelenses&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[21]&lt;/span&gt;&lt;p&gt;将ui.diagnostic.annotations设置为包括逃逸，启用逃逸分析的覆盖: &lt;em&gt;https://github.com/golang/vscode-go/wiki/settings#uidiagnosticannotations&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[22]&lt;/span&gt;&lt;p&gt;Go语言源代码中的文档: &lt;em&gt;https://cs.opensource.google/go/go/+/master:src/cmd/compile/internal/logopt/log_opts.go;l=25;drc=351e0f4083779d8ac91c05afebded42a302a6893&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[23]&lt;/span&gt;&lt;p&gt;A Guide to the Go Garbage Collector: &lt;em&gt;https://tip.golang.org/doc/gc-guide?continueFlag=bf311ba190bf0d160b5d3461e092f0f4&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>