<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f9d8b54a397f6bcb9565e23b1a87232d</guid>
<title>Go 语言性能剖析利器：pprof 实战</title>
<link>https://toutiao.io/k/ye9g2eb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;作者：耿宗杰&lt;/p&gt;

&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;关于pprof的文章在网上已是汗牛充栋，却是千篇一律的命令介绍，鲜有真正实操的，本文将参考Go社区资料，结合自己的经验，实战Go程序的性能分析与优化过程。&lt;/p&gt;

&lt;h1&gt;优化思路&lt;/h1&gt;

&lt;p&gt;首先说一下性能优化的一般思路。系统性能的分析优化，一定是从大到小的步骤来进行的，即从业务架构的优化，到系统架构的优化，再到系统模块间的优化，最后到代码编写层面的优化。业务架构的优化是最具性价比的，技术难度相对较小，却可以带来大幅的性能提升。比如通过和同事或外部门沟通，减少了一些接口调用或者去掉了不必要的复杂的业务逻辑，可以轻松提升整个系统的性能。&lt;/p&gt;

&lt;p&gt;系统架构的优化，比如加入缓存，由http改进为rpc等，也可以在少量投入下带来较大的性能提升。最后是程序代码级别的性能优化，这又分为两方面，一是合格的数据结构与使用，二才是在此基础上的性能剖析。比如在Go语言中使用slice这种方便的数据结构时，尽可能提前申请足够的内存防止append超过容量时的内存申请和数据拷贝；使用并发保护时尽量由RWMutex 代替mutex，甚至在极高并发场景下使用更细粒度的原子操作代替锁等等。&lt;/p&gt;

&lt;h1&gt;优化实践&lt;/h1&gt;

&lt;p&gt;下面进入正文，待优化程序是社区中一个例子，代码有点长，实现的算法是著名的计算机科学家Tarjan的求图的强连通分量算法，关于这个算法的思想请自行google（就别自行百度了~）。以下为实操过程（会有那么一丢丢长。。。）：&lt;/p&gt;

&lt;p&gt;初始版本代码 havlak1.go:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Go from multi-language-benchmark/src/havlak/go_pro// Copyright 2011 Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at////     http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.// Test Program for the Havlak loop finder.//// This program constructs a fairly large control flow// graph and performs loop recognition. This is the Go// version.//package mainimport (   &quot;flag&quot;   &quot;fmt&quot;   &quot;log&quot;   &quot;os&quot;   &quot;runtime/pprof&quot;)type BasicBlock struct {   Name     int   InEdges  []*BasicBlock   OutEdges []*BasicBlock}func NewBasicBlock(name int) *BasicBlock {   return &amp;amp;BasicBlock{Name: name}}func (bb *BasicBlock) Dump() {   fmt.Printf(&quot;BB#%06d:&quot;, bb.Name)   if len(bb.InEdges) &amp;gt; 0 {      fmt.Printf(&quot; in :&quot;)      for _, iter := range bb.InEdges {         fmt.Printf(&quot; BB#%06d&quot;, iter.Name)      }   }   if len(bb.OutEdges) &amp;gt; 0 {      fmt.Print(&quot; out:&quot;)      for _, iter := range bb.OutEdges {         fmt.Printf(&quot; BB#%06d&quot;, iter.Name)      }   }   fmt.Printf(&quot;\n&quot;)}func (bb *BasicBlock) NumPred() int {   return len(bb.InEdges)}func (bb *BasicBlock) NumSucc() int {   return len(bb.OutEdges)}func (bb *BasicBlock) AddInEdge(from *BasicBlock) {   bb.InEdges = append(bb.InEdges, from)}func (bb *BasicBlock) AddOutEdge(to *BasicBlock) {   bb.OutEdges = append(bb.OutEdges, to)}//-----------------------------------------------------------type CFG struct {   Blocks []*BasicBlock   Start  *BasicBlock}func NewCFG() *CFG {   return &amp;amp;CFG{}}func (cfg *CFG) NumNodes() int {   return len(cfg.Blocks)}func (cfg *CFG) CreateNode(node int) *BasicBlock {   if node &amp;lt; len(cfg.Blocks) {      return cfg.Blocks[node]   }   if node != len(cfg.Blocks) {      println(&quot;oops&quot;, node, len(cfg.Blocks))      panic(&quot;wtf&quot;)   }   bblock := NewBasicBlock(node)   cfg.Blocks = append(cfg.Blocks, bblock)   if len(cfg.Blocks) == 1 {      cfg.Start = bblock   }   return bblock}func (cfg *CFG) Dump() {   for _, n := range cfg.Blocks {      n.Dump()   }}//-----------------------------------------------------------type BasicBlockEdge struct {   Dst *BasicBlock   Src *BasicBlock}func NewBasicBlockEdge(cfg *CFG, from int, to int) *BasicBlockEdge {   self := new(BasicBlockEdge)   self.Src = cfg.CreateNode(from)   self.Dst = cfg.CreateNode(to)   self.Src.AddOutEdge(self.Dst)   self.Dst.AddInEdge(self.Src)   return self}//-----------------------------------------------------------// Basic Blocks and Loops are being classified as regular, irreducible,// and so on. This enum contains a symbolic name for all these classifications//const (   _             = iota // Go has an interesting iota concept   bbTop                // uninitialized   bbNonHeader          // a regular BB   bbReducible          // reducible loop   bbSelf               // single BB loop   bbIrreducible        // irreducible loop   bbDead               // a dead BB   bbLast               // sentinel)// UnionFindNode is used in the Union/Find algorithm to collapse// complete loops into a single node. These nodes and the// corresponding functionality are implemented with this class//type UnionFindNode struct {   parent    *UnionFindNode   bb        *BasicBlock   loop      *SimpleLoop   dfsNumber int}// Init explicitly initializes UnionFind nodes.//func (u *UnionFindNode) Init(bb *BasicBlock, dfsNumber int) {   u.parent = u   u.bb = bb   u.dfsNumber = dfsNumber   u.loop = nil}// FindSet implements the Find part of the Union/Find Algorithm//// Implemented with Path Compression (inner loops are only// visited and collapsed once, however, deep nests would still// result in significant traversals).//func (u *UnionFindNode) FindSet() *UnionFindNode {   var nodeList []*UnionFindNode   node := u   for ; node != node.parent; node = node.parent {      if node.parent != node.parent.parent {         nodeList = append(nodeList, node)      }   }   // Path Compression, all nodes&#x27; parents point to the 1st level parent.   for _, ll := range nodeList {      ll.parent = node.parent   }   return node}// Union relies on path compression.//func (u *UnionFindNode) Union(B *UnionFindNode) {   u.parent = B}// Constants//// Marker for uninitialized nodes.const unvisited = -1// Safeguard against pathological algorithm behavior.const maxNonBackPreds = 32 * 1024// IsAncestor//// As described in the paper, determine whether a node &#x27;w&#x27; is a// &quot;true&quot; ancestor for node &#x27;v&#x27;.//// Dominance can be tested quickly using a pre-order trick// for depth-first spanning trees. This is why DFS is the first// thing we run below.//// Go comment: Parameters can be written as w,v int, inlike in C, where//   each parameter needs its own type.//func isAncestor(w, v int, last []int) bool {   return ((w &amp;lt;= v) &amp;amp;&amp;amp; (v &amp;lt;= last[w]))}// listContainsNode//// Check whether a list contains a specific element. //func listContainsNode(l []*UnionFindNode, u *UnionFindNode) bool {   for _, ll := range l {      if ll == u {         return true      }   }   return false}// DFS - Depth-First-Search and node numbering.//func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {   nodes[current].Init(currentNode, current)   number[currentNode] = current   lastid := current   for _, target := range currentNode.OutEdges {      if number[target] == unvisited {         lastid = DFS(target, nodes, number, last, lastid+1)      }   }   last[number[currentNode]] = lastid   return lastid}// FindLoops//// Find loops and build loop forest using Havlak&#x27;s algorithm, which// is derived from Tarjan. Variable names and step numbering has// been chosen to be identical to the nomenclature in Havlak&#x27;s// paper (which, in turn, is similar to the one used by Tarjan).//func FindLoops(cfgraph *CFG, lsgraph *LSG) {   if cfgraph.Start == nil {      return   }   size := cfgraph.NumNodes()   nonBackPreds := make([]map[int]bool, size)   backPreds := make([][]int, size)   number := make(map[*BasicBlock]int)   header := make([]int, size, size)   types := make([]int, size, size)   last := make([]int, size, size)   nodes := make([]*UnionFindNode, size, size)   for i := 0; i &amp;lt; size; i++ {      nodes[i] = new(UnionFindNode)   }   // Step a:   //   - initialize all nodes as unvisited.   //   - depth-first traversal and numbering.   //   - unreached BB&#x27;s are marked as dead.   //   for i, bb := range cfgraph.Blocks {      number[bb] = unvisited      nonBackPreds[i] = make(map[int]bool)   }   DFS(cfgraph.Start, nodes, number, last, 0)   // Step b:   //   - iterate over all nodes.   //   //   A backedge comes from a descendant in the DFS tree, and non-backedges   //   from non-descendants (following Tarjan).   //   //   - check incoming edges &#x27;v&#x27; and add them to either   //     - the list of backedges (backPreds) or   //     - the list of non-backedges (nonBackPreds)   //   for w := 0; w &amp;lt; size; w++ {      header[w] = 0      types[w] = bbNonHeader      nodeW := nodes[w].bb      if nodeW == nil {         types[w] = bbDead         continue // dead BB      }      if nodeW.NumPred() &amp;gt; 0 {         for _, nodeV := range nodeW.InEdges {            v := number[nodeV]            if v == unvisited {               continue // dead node            }            if isAncestor(w, v, last) {               backPreds[w] = append(backPreds[w], v)            } else {               nonBackPreds[w][v] = true            }         }      }   }   // Start node is root of all other loops.   header[0] = 0   // Step c:   //   // The outer loop, unchanged from Tarjan. It does nothing except   // for those nodes which are the destinations of backedges.   // For a header node w, we chase backward from the sources of the   // backedges adding nodes to the set P, representing the body of   // the loop headed by w.   //   // By running through the nodes in reverse of the DFST preorder,   // we ensure that inner loop headers will be processed before the   // headers for surrounding loops.   //   for w := size - 1; w &amp;gt;= 0; w-- {      // this is &#x27;P&#x27; in Havlak&#x27;s paper      var nodePool []*UnionFindNode      nodeW := nodes[w].bb      if nodeW == nil {         continue // dead BB      }      // Step d:      for _, v := range backPreds[w] {         if v != w {            nodePool = append(nodePool, nodes[v].FindSet())         } else {            types[w] = bbSelf         }      }      // Copy nodePool to workList.      //      workList := append([]*UnionFindNode(nil), nodePool...)      if len(nodePool) != 0 {         types[w] = bbReducible      }      // work the list...      //      for len(workList) &amp;gt; 0 {         x := workList[0]         workList = workList[1:]         // Step e:         //         // Step e represents the main difference from Tarjan&#x27;s method.         // Chasing upwards from the sources of a node w&#x27;s backedges. If         // there is a node y&#x27; that is not a descendant of w, w is marked         // the header of an irreducible loop, there is another entry         // into this loop that avoids w.         //         // The algorithm has degenerated. Break and         // return in this case.         //         nonBackSize := len(nonBackPreds[x.dfsNumber])         if nonBackSize &amp;gt; maxNonBackPreds {            return         }         for iter := range nonBackPreds[x.dfsNumber] {            y := nodes[iter]            ydash := y.FindSet()            if !isAncestor(w, ydash.dfsNumber, last) {               types[w] = bbIrreducible               nonBackPreds[w][ydash.dfsNumber] = true            } else {               if ydash.dfsNumber != w {                  if !listContainsNode(nodePool, ydash) {                     workList = append(workList, ydash)                     nodePool = append(nodePool, ydash)                  }               }            }         }      }      // Collapse/Unionize nodes in a SCC to a single node      // For every SCC found, create a loop descriptor and link it in.      //      if (len(nodePool) &amp;gt; 0) || (types[w] == bbSelf) {         loop := lsgraph.NewLoop()         loop.SetHeader(nodeW)         if types[w] != bbIrreducible {            loop.IsReducible = true         }         // At this point, one can set attributes to the loop, such as:         //         // the bottom node:         //    iter  = backPreds[w].begin();         //    loop bottom is: nodes[iter].node);         //         // the number of backedges:         //    backPreds[w].size()         //         // whether this loop is reducible:         //    type[w] != BasicBlockClass.bbIrreducible         //         nodes[w].loop = loop         for _, node := range nodePool {            // Add nodes to loop descriptor.            header[node.dfsNumber] = w            node.Union(nodes[w])            // Nested loops are not added, but linked together.            if node.loop != nil {               node.loop.Parent = loop            } else {               loop.AddNode(node.bb)            }         }         lsgraph.AddLoop(loop)      } // nodePool.size   } // Step c}// External entry point.func FindHavlakLoops(cfgraph *CFG, lsgraph *LSG) int {   FindLoops(cfgraph, lsgraph)   return lsgraph.NumLoops()}//======================================================// Scaffold Code//======================================================// Basic representation of loops, a loop has an entry point,// one or more exit edges, a set of basic blocks, and potentially// an outer loop - a &quot;parent&quot; loop.//// Furthermore, it can have any set of properties, e.g.,// it can be an irreducible loop, have control flow, be// a candidate for transformations, and what not.//type SimpleLoop struct {   // No set, use map to bool   basicBlocks map[*BasicBlock]bool   Children    map[*SimpleLoop]bool   Parent      *SimpleLoop   header      *BasicBlock   IsRoot       bool   IsReducible  bool   Counter      int   NestingLevel int   DepthLevel   int}func (loop *SimpleLoop) AddNode(bb *BasicBlock) {   loop.basicBlocks[bb] = true}func (loop *SimpleLoop) AddChildLoop(child *SimpleLoop) {   loop.Children[child] = true}func (loop *SimpleLoop) Dump(indent int) {   for i := 0; i &amp;lt; indent; i++ {      fmt.Printf(&quot;  &quot;)   }   // No ? operator ?   fmt.Printf(&quot;loop-%d nest: %d depth %d &quot;,      loop.Counter, loop.NestingLevel, loop.DepthLevel)   if !loop.IsReducible {      fmt.Printf(&quot;(Irreducible) &quot;)   }   // must have &amp;gt; 0   if len(loop.Children) &amp;gt; 0 {      fmt.Printf(&quot;Children: &quot;)      for ll := range loop.Children {         fmt.Printf(&quot;loop-%d&quot;, ll.Counter)      }   }   if len(loop.basicBlocks) &amp;gt; 0 {      fmt.Printf(&quot;(&quot;)      for bb := range loop.basicBlocks {         fmt.Printf(&quot;BB#%06d &quot;, bb.Name)         if loop.header == bb {            fmt.Printf(&quot;*&quot;)         }      }      fmt.Printf(&quot;\b)&quot;)   }   fmt.Printf(&quot;\n&quot;)}func (loop *SimpleLoop) SetParent(parent *SimpleLoop) {   loop.Parent = parent   loop.Parent.AddChildLoop(loop)}func (loop *SimpleLoop) SetHeader(bb *BasicBlock) {   loop.AddNode(bb)   loop.header = bb}//------------------------------------// Helper (No templates or such)//func max(x, y int) int {   if x &amp;gt; y {      return x   }   return y}// LoopStructureGraph//// Maintain loop structure for a given CFG.//// Two values are maintained for this loop graph, depth, and nesting level.// For example://// loop        nesting level    depth//----------------------------------------// loop-0      2                0//   loop-1    1                1//   loop-3    1                1//     loop-2  0                2//var loopCounter = 0type LSG struct {   root  *SimpleLoop   loops []*SimpleLoop}func NewLSG() *LSG {   lsg := new(LSG)   lsg.root = lsg.NewLoop()   lsg.root.NestingLevel = 0   return lsg}func (lsg *LSG) NewLoop() *SimpleLoop {   loop := new(SimpleLoop)   loop.basicBlocks = make(map[*BasicBlock]bool)   loop.Children = make(map[*SimpleLoop]bool)   loop.Parent = nil   loop.header = nil   loop.Counter = loopCounter   loopCounter++   return loop}func (lsg *LSG) AddLoop(loop *SimpleLoop) {   lsg.loops = append(lsg.loops, loop)}func (lsg *LSG) Dump() {   lsg.dump(lsg.root, 0)}func (lsg *LSG) dump(loop *SimpleLoop, indent int) {   loop.Dump(indent)   for ll := range loop.Children {      lsg.dump(ll, indent+1)   }}func (lsg *LSG) CalculateNestingLevel() {   for _, sl := range lsg.loops {      if sl.IsRoot {         continue      }      if sl.Parent == nil {         sl.SetParent(lsg.root)      }   }   lsg.calculateNestingLevel(lsg.root, 0)}func (lsg *LSG) calculateNestingLevel(loop *SimpleLoop, depth int) {   loop.DepthLevel = depth   for ll := range loop.Children {      lsg.calculateNestingLevel(ll, depth+1)      ll.NestingLevel = max(loop.NestingLevel, ll.NestingLevel+1)   }}func (lsg *LSG) NumLoops() int {   return len(lsg.loops)}func (lsg *LSG) Root() *SimpleLoop {   return lsg.root}//======================================================// Testing Code//======================================================func buildDiamond(cfgraph *CFG, start int) int {   bb0 := start   NewBasicBlockEdge(cfgraph, bb0, bb0+1)   NewBasicBlockEdge(cfgraph, bb0, bb0+2)   NewBasicBlockEdge(cfgraph, bb0+1, bb0+3)   NewBasicBlockEdge(cfgraph, bb0+2, bb0+3)   return bb0 + 3}func buildConnect(cfgraph *CFG, start int, end int) {   NewBasicBlockEdge(cfgraph, start, end)}func buildStraight(cfgraph *CFG, start int, n int) int {   for i := 0; i &amp;lt; n; i++ {      buildConnect(cfgraph, start+i, start+i+1)   }   return start + n}func buildBaseLoop(cfgraph *CFG, from int) int {   header := buildStraight(cfgraph, from, 1)   diamond1 := buildDiamond(cfgraph, header)   d11 := buildStraight(cfgraph, diamond1, 1)   diamond2 := buildDiamond(cfgraph, d11)   footer := buildStraight(cfgraph, diamond2, 1)   buildConnect(cfgraph, diamond2, d11)   buildConnect(cfgraph, diamond1, header)   buildConnect(cfgraph, footer, from)   footer = buildStraight(cfgraph, footer, 1)   return footer}var cpuprofile = flag.String(&quot;cpuprofile&quot;, &quot;&quot;, &quot;write cpu profile to this file&quot;)func main() {   flag.Parse()   if *cpuprofile != &quot;&quot; {      f, err := os.Create(*cpuprofile)      if err != nil {         log.Fatal(err)      }      pprof.StartCPUProfile(f)      defer pprof.StopCPUProfile()   }   lsgraph := NewLSG()   cfgraph := NewCFG()   cfgraph.CreateNode(0) // top   cfgraph.CreateNode(1) // bottom   NewBasicBlockEdge(cfgraph, 0, 2)   for dummyloop := 0; dummyloop &amp;lt; 15000; dummyloop++ {      FindHavlakLoops(cfgraph, NewLSG())   }   n := 2   for parlooptrees := 0; parlooptrees &amp;lt; 10; parlooptrees++ {      cfgraph.CreateNode(n + 1)      buildConnect(cfgraph, 2, n+1)      n = n + 1      for i := 0; i &amp;lt; 100; i++ {         top := n         n = buildStraight(cfgraph, n, 1)         for j := 0; j &amp;lt; 25; j++ {            n = buildBaseLoop(cfgraph, n)         }         bottom := buildStraight(cfgraph, n, 1)         buildConnect(cfgraph, n, top)         n = bottom      }      buildConnect(cfgraph, n, 1)   }   FindHavlakLoops(cfgraph, lsgraph)   for i := 0; i &amp;lt; 50; i++ {      FindHavlakLoops(cfgraph, NewLSG())   }   fmt.Printf(&quot;# of loops: %d (including 1 artificial root node)\n&quot;, lsgraph.NumLoops())   lsgraph.CalculateNestingLevel()}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们借助macbook系统上的time命令来打印程序运行的时间（内核态、用户态、总时间）：&lt;/p&gt;

&lt;p&gt;编译后运行程序：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b1c287dfbd5c4448bc055996f7aca517%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;用户态耗时23.07s，内核态耗时0.4s，总耗时13.7s（用了两个核，170%）。因为程序里面已经先开启了pprof统计cpu耗时，直接top命令看：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f11b769cab54f20bef9aa8f8f4c7e09%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，pprof数据采集持续了12.99s，采样时长是19.49s（还是两核的缘故）。&lt;/p&gt;

&lt;p&gt;这里要说一下，无论是cpu耗时统计还是内存占用统计，都是间隔采样。cpu耗时时每隔一段时间（大概是10ms）对调用栈的函数进行记录，最后分析在所有的记录次数中，各个函数出现的次数，包括在运行中的次数，和入栈次数（说明它调用了别的函数）。内存占用统计是每分配512K记录一次分配路径。&lt;/p&gt;

&lt;p&gt;耗时最多的是mapaccess1_fast64，这是运行时中的map读写时的数据查询函数。如果编译程序时没有禁用内联，看到的会有所不同，其中会显示FindHavlakLoops函数，并标识为inline。因为FindHavlakLoops里面就调用了FindLoops，所以在编译器会直接把这个函数展开，用FindLoops替换FindHavlakLoops函数。也可以在不禁用内联编译时，设置pprof的noinlines开关为true，默认为false，即noinlines=true。&lt;/p&gt;

&lt;p&gt;这里看到最大的函数并不是业务函数而是系统函数，那没啥好优化系统函数的（只能是咱用的不对了呗~）。就看是哪里调用的这个系统函数：&lt;/p&gt;

&lt;p&gt;web mapaccess1_fast64&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f4cd13caad3b4f95b7a1e6d983be2c3a%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，调用最多的是DFS和FindLoops。那就看看这俩函数里面是怎么使用map的，来看DFS：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e657652219a348aab8c144aa0f19f3c3%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，DFS函数里耗时较长又是map操作的，是242 246 和250三行。对于这里的优化方法，是用list结构代替map结构，因为能用list达到效果的情况下没必要用map。这个咋一看没问题，但好像又有点别扭对吧？其实是因为这个程序的本身特点，这里有明显的一点，就是BasicBlock结构的特殊性，本身的Name属性就是自身的索引下标。查找某个BasicBlock不需要使用map来记录，直接通过下标访问显然是最低的时间复杂度（关于map和list的时间复杂度就不多说了，map看起来是O1，但其实没有考虑hash计算本身的过程和解决hash冲突的成本，而list是必然的O1）。通过把这部分的map修改为list数据结构，版本H2，再编译查看耗时情况：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3911f3af78954fc0a9dcc4182c489729%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;此时耗时降低到了8s。再次查看cpu耗时分布：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c8e70976c5f14e93b896a62ba3857c24%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，top1变成了scanobject函数，不再是map读写了。看到这个函数，以及下边的mallocgc，我们要知道，这都是内存相关的，前者是内存对象扫描的处理函数，是垃圾回收三色标记的一个过程，后者则是直接管理内存分配和回收的（注意是同时负责内存分配和回收，malloc &amp;amp;&amp;amp; gc）。这说明目前程序花了很多时间在进行内存管理，看比例是8%。那就要分析一下了，是什么东西产生了这么多内存变化，合不合理。分析内存，就是pprof的memprofile功能了。添加一下相关的内存统计代码，具体怎么添加大家肯定都会，就不贴了（网上多得是）。添加完之后，重新编译生成版本H3，执行H3，生成对应的内存监测文件：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/64a821e17b6440d79d1871d6be3a54f0%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;查看内存的分配情况，在这里不禁止内联，因为在实际运行时该内联的函数也是会被展开替换掉的：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6c76579c6b664119a21486e7ac6ece4b%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，节点创建是第一，FindLoops是第二。因为创建BasicBlock首先很简单，没有复杂的过程，其次这是程序中的一个基础对象结构，若要改结构体，那可能涉及到算法也得改，这个显然是不合适的，不仅可能改出bug，还可能收益不高。那我们就顺着看第二位的FindLoops，这个就是前边我们看到的调用mapaccess内置函数的另一个业务函数，所以优化的方法跟上面类似，还是优化map的使用，替换为list。这里有一点特殊的是，替换成list之后，map的追加需要改一下，加一个判断重复的逻辑，所以新加了一个appendUnique方法。再次编译，版本H4，查看耗时：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7b59cf00cc2743a9b6f9a092c08fcd70%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;这时程序耗时降到了5.6s。再次查看内存分配，确认优化效果：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de8ab14770744074a9af71e5a5a6fedf%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，FindLoops函数已经不在高位，内存消耗降下去了。再看一下此时的cpu耗时分布：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/140f481e60754c189bc926a7046cb9fd%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，FindLoops成为top1，scanobject函数成了第二位。这就对了，因为&lt;strong&gt;我们就是要让cpu更多的去运行业务代码，把时间花到真正需要的地方&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这时就可以进行下一轮的性能优化了（这就是性能调优，一遍一遍的排查耗时，压缩不必要的cpu时间，压榨计算性能）。继续看一下此时FindLoops到底在哪儿化的时间多，是否合理：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dee2767b996f403491b41539816ca113%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;从各个语句的耗时来看，好像没啥大问题，没有很离谱的耗时（360ms那行是因为循环的缘故）。这说明编码上没有大问题，按照我们前边一开始说的程序优化的步骤，就需要往上找了，看能不能优化逻辑来减少不必要的计算，以达到提升性能的目的（即，每一个计算步骤处理的都没啥大问题了，那能不能少算点儿）。这里FindLoops在程序入口，花了不少时间来初始化一系列临时变量，加起来有180ms，这就意味着每次调用FindLoops函数，都要先花180ms的准备工作。这部分临时变量的多次创建+初始化，可以通过加内存缓存的方式来减少重复创建和申请，这里涉及到的标准解法其实就是对象池（像Go创建的web服务，在并发量很高的情况下，每一次http请求的解析都需要创建对象+申请内存+反序列这一系列的初始动作，这时就可以借助sync.Pool来减少这种重复工作，提升性能）。同理，这里也是加入了一个内存缓存对象cache：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3e27db17ac344e0f8e1a3283334407a2%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;把原本的内存申请初始化过程做了替换。在原有缓存不够的情况下，申请新的变量，否者截取原有缓存使用，减少内存申请：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9a25914cc8d41639315e25db3997304%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;调整完毕后，编译新版本H5，再看下耗时：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/69fa905ddb274902bb2f97bd9446b246%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;这时候程序的耗时已经降到4.1s，相比一开始的13.7s，已经提升了两倍多。看下现在的cpu耗时分布：&lt;/p&gt;

&lt;p&gt;﻿&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9da5964e347c49f1929c501c1617bb9f%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;﻿﻿  &lt;/p&gt;

&lt;p&gt;可以看到，相比上次的分布，前两位都是业务代码函数了，说明进一步提高了业务代码的耗时占比，降低了无关系统函数的负载。这种直接使用全局变量的方式加cache不是并发安全的，但是因为这里程序的逻辑本身也不是并发的，所以这里没问题。&lt;/p&gt;

&lt;p&gt;到这里，实操的优化过程就走完了。提炼总结一下优化的步骤和使用的主要方法命令有：&lt;/p&gt;

&lt;p&gt;1.通过top5查看cpu耗时：确定是字典数据操作占比最大；&lt;/p&gt;

&lt;p&gt;2.通过web命令查看是谁主要调用了字典操作函数：确定有DFS和FindLoops；&lt;/p&gt;

&lt;p&gt;3.使用list 命令查看DFS函数中每行代码的耗时，找到跟map操作相关的部分，确定优化方法：把map换成list；&lt;/p&gt;

&lt;p&gt;4.重新运行，再用top命令查看cpu耗时分布：找到耗时最大的是内存对象扫描函数scanobject；&lt;/p&gt;

&lt;p&gt;5.加入内存剖析代码，运行查看内存分配的大小分布：确定FindLoops占用较大；&lt;/p&gt;

&lt;p&gt;6.使用list命令查看FindLoops函数的每行内存开销：确定是map创建占用内存较大；&lt;/p&gt;

&lt;p&gt;7.同样使用list数据结构替换map，重新运行，再看内存大小分布：确定FindLoops已不在高位，同时再看CPU耗时时，scanobject已经降下去了，目的达到；&lt;/p&gt;

&lt;p&gt;8.此时又开始新的一轮排查，继续查看cpu耗时排行榜，FindLoops耗时居首；&lt;/p&gt;

&lt;p&gt;9.继续使用list方法看FindLoops函数每行的耗时，没有明显的问题。那就要换思路，从排查编码问题转换为排查逻辑问题，减少计算过程：这里是加缓存；&lt;/p&gt;

&lt;p&gt;10.加完缓存看到性能明显提升了，说明优化对了。这时又该循环进入下一轮的排查的优化了，以此往复。。。直到压榨出我们能达到的最大性能！&lt;/p&gt;

&lt;p&gt;以上就是本次程序优化的整体步骤和思路，过程中秉持的思路方法是一贯的，&lt;strong&gt;就是不断的用pprof排查top级的函数耗时和内存占用，通过优化数据结构、减少不必要的计算过程、降低内存分配和回收的负担等方式来提升性能，这一点对所有的程序都适用，也是后续可以借鉴的方法论&lt;/strong&gt;。&lt;/p&gt;

&lt;h1&gt;两点感悟&lt;/h1&gt;

&lt;p&gt;1.&lt;strong&gt;优化程序的大前提是你一定要对程序有足够深入的理解！&lt;/strong&gt; （或者说我们不能优化程序优化出bug来啊。。。）。最后生产H6版本，之所以又对性能提升了一倍，全是建立在作者对程序完全理解的基础之上的，所以他才可以调整循环逻辑，复用程序对象，调整调用逻辑等等。这一层再往上层思考，就到了程序逻辑，系统架构内置整体的业务架构层面了。这其实就又回到了一开始我们说的程序优化由大到小的总体思路上了。&lt;/p&gt;

&lt;p&gt;2.&lt;strong&gt;带GC的语言相比不带的，反而更考验内存管理的技术&lt;/strong&gt;。Go语言在开发效率上的提升，是把垃圾回收交给了系统来处理，但别忘了，消耗的依然是我们自己的cpu时间（羊毛，那不得从羊身上来...）。所以我们在使用每种结构体，进行每种计算操作时，都要明白其背后涉及的内存开销，要把内存变化放到潜意识里去管理。&lt;/p&gt;

&lt;p&gt;以上就是本次pprof优化Go程序的实操过程及总结感想，供参考，感谢~&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>be779641978f1bdefd07f5897cc67d3b</guid>
<title>实战总结！18 种接口优化方案的总结</title>
<link>https://toutiao.io/k/cpmcbd6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;之前工作中，遇到一个&lt;/span&gt;&lt;code&gt;504&lt;/code&gt;&lt;span&gt;超时问题。原因是因为接口耗时过长，超过&lt;/span&gt;&lt;code&gt;nginx&lt;/code&gt;&lt;span&gt;配置的&lt;/span&gt;&lt;code&gt;10&lt;/code&gt;&lt;span&gt;秒。然后
真枪实弹搞了一次接口性能优化，最后接口从&lt;/span&gt;&lt;code&gt;11.3s&lt;/code&gt;&lt;span&gt;降为&lt;/span&gt;&lt;code&gt;170ms&lt;/code&gt;&lt;span&gt;。本文将跟小伙伴们分享接口优化的&lt;/span&gt;&lt;strong&gt;一些通用&lt;/strong&gt;&lt;span&gt;方案。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48668639053254437&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibh1ElZffVRmicXGtf6pOibI8pvcF7ycFgKaLyhibOfhJM0cukXaNysdO5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2028&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 批量思想：批量操作数据库&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;优化前：&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;//&lt;span&gt;for&lt;/span&gt;循环单笔入库&lt;br/&gt;&lt;span&gt;for&lt;/span&gt;(TransDetail detail:transDetailList){&lt;br/&gt;  insert(detail);  &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;优化后：&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;batchInsert(transDetailList);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;打个比喻：&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;打个比喻:假如你需要搬一万块砖到楼顶,你有一个电梯,电梯一次可以放适量的砖（最多放&lt;code&gt;500&lt;/code&gt;）,
你可以选择一次运送一块砖,也可以一次运送&lt;code&gt;500&lt;/code&gt;,你觉得哪种方式更方便，时间消耗更少?&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 异步思想：耗时操作，考虑放到异步执行&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;耗时操作，考虑用&lt;strong&gt;异步处理&lt;/strong&gt;，这样可以降低接口耗时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设一个转账接口，匹配联行号，是同步执行的，&lt;strong&gt;但是它的操作耗时有点长&lt;/strong&gt;，优化前的流程：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8900634249471459&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLib7PjUFDMKMOeYsD6o8vmFPcm8ticgj2umic35JXPvTRdgiafRV2j7BP5Uw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;473&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了降低接口耗时，更快返回，你可以把&lt;strong&gt;匹配联行号&lt;/strong&gt;移到&lt;strong&gt;异步处理&lt;/strong&gt;，优化后：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7041420118343196&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibKbKe1DsXQSZOv3AHuDe5ia68fB8c1kInJHxjvUnogTjjY4qVJ5NPic5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;507&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;除了转账这个例子，日常工作中还有很多这种例子。比如：&lt;strong&gt;用户注册成功后，短信邮件通知，也是可以异步处理的&lt;/strong&gt;~&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;至于异步的实现方式，&lt;strong&gt;你可以用线程池，也可以用消息队列实现&lt;/strong&gt;。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3. 空间换时间思想：恰当使用缓存。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在适当的业务场景，恰当地使用缓存，是可以大大提高接口性能的。缓存其实就是一种&lt;strong&gt;空间换时间的思想&lt;/strong&gt;，就是你把要查的数据，提前放好到缓存里面，需要时，&lt;strong&gt;直接查缓存，而避免去查数据库或者计算的过程&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的缓存包括：&lt;code&gt;Redis&lt;/code&gt;缓存，&lt;code&gt;JVM&lt;/code&gt;本地缓存，&lt;code&gt;memcached&lt;/code&gt;，或者&lt;code&gt;Map&lt;/code&gt;等等。我举个我工作中，一次使用缓存优化的设计吧，比较简单，但是思路很有借鉴的意义。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;那是一次转账接口的优化，&lt;strong&gt;老代码&lt;/strong&gt;，每次转账，都会根据客户账号，查询数据库，计算匹配联行号。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.817910447761194&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibDw2Jn3ia171gZr6yfd938iaaxTiak54Rd4tdLsIXysRXhZV0IPia3DrYJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;335&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为每次&lt;strong&gt;都查数据库，都计算匹配，比较耗时&lt;/strong&gt;，所以&lt;strong&gt;使用缓存&lt;/strong&gt;，优化后流程如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0737704918032787&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibfE3PGuYdme6via3UUonhJMUOCe0iam6xoYzu0PibTfSLKZicf4QMEKHyjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;488&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4. 预取思想：提前初始化到缓存&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;预取思想很容易理解，就是&lt;strong&gt;提前把要计算查询的数据，初始化到缓存&lt;/strong&gt;。如果你在未来某个时间需要用到某个经过复杂计算的数据，&lt;strong&gt;才实时去计算的话，可能耗时比较大&lt;/strong&gt;。这时候，我们可以采取预取思想，&lt;strong&gt;提前把将来可能需要的数据计算好，放到缓存中&lt;/strong&gt;，等需要的时候，去缓存取就行。这将大幅度提高接口性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我记得以前在第一个公司做视频直播的时候，看到我们的直播列表就是用到&lt;strong&gt;这种优化方案&lt;/strong&gt;。就是启动个任务，&lt;strong&gt;提前把直播用户、积分等相关信息，初始化到缓存&lt;/strong&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5. 池化思想：预分配与循环使用&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家应该都记得，&lt;strong&gt;我们为什么需要使用线程池&lt;/strong&gt;？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;线程池可以帮我们管理线程，避免增加创建线程和销毁线程的资源损耗。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;如果你每次需要用到线程，都去创建，就会有增加一定的耗时，而线程池可以重复利用线程，避免不必要的耗时。&lt;/strong&gt; 池化技术不仅仅指线程池，很多场景都有池化思想的体现，它的本质就是&lt;strong&gt;预分配与循环使用&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如&lt;code&gt;TCP&lt;/code&gt;三次握手，大家都很熟悉吧，它为了减少性能损耗，引入了&lt;code&gt;Keep-Alive长连接&lt;/code&gt;，避免频繁的创建和销毁连接。当然，类似的例子还有很多，如数据库连接池、&lt;code&gt;HttpClient&lt;/code&gt;连接池。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们写代码的过程中，&lt;strong&gt;学会池化思想&lt;/strong&gt;，最直接相关的就是使用线程池而不是去&lt;code&gt;new&lt;/code&gt;一个线程。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6. 事件回调思想：拒绝阻塞等待。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你调用一个系统&lt;code&gt;B&lt;/code&gt;的接口，但是它处理业务逻辑，耗时需要&lt;code&gt;10s&lt;/code&gt;甚至更多。然后你是一直&lt;strong&gt;阻塞等待，直到系统B的下游接口返回&lt;/strong&gt;，再继续你的下一步操作吗？这样&lt;strong&gt;显然不合理&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们参考&lt;strong&gt;IO多路复用模型&lt;/strong&gt;。即我们不用阻塞等待系统&lt;code&gt;B&lt;/code&gt;的接口，而是先去做别的操作。等系统&lt;code&gt;B&lt;/code&gt;的接口处理完，通过&lt;strong&gt;事件回调&lt;/strong&gt;通知，我们接口收到通知再进行对应的业务操作即可。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7. 远程调用由串行改为并行&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设我们设计一个APP首页的接口，它需要查用户信息、需要查banner信息、需要查弹窗信息等等。如果是串行一个一个查，比如查用户信息&lt;code&gt;200ms&lt;/code&gt;，查banner信息&lt;code&gt;100ms&lt;/code&gt;、查弹窗信息&lt;code&gt;50ms&lt;/code&gt;，那一共就耗时&lt;code&gt;350ms&lt;/code&gt;了，如果还查其他信息，那耗时就更大了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.20555555555555555&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibTm7AKP23GGya6Mcbg27r9rRPTfaGJOmT51w86K9Bxm6ap0bhRGgmXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实我们可以改为并行调用，即查用户信息、查banner信息、查弹窗信息，可以同时&lt;strong&gt;并行发起&lt;/strong&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5670731707317073&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibAXl1VeaT5P3POibOmLnnSFkvkHgEzt7eOMfbAIBt2LY8NQh6IDFGkhA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;最后接口耗时将大大降低&lt;/strong&gt;。有些小伙伴说，不知道如何使用并行优化接口?&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;8. 锁粒度避免过粗&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在高并发场景，为了防止&lt;strong&gt;超卖等情况&lt;/strong&gt;，我们经常需要&lt;strong&gt;加锁来保护共享资源&lt;/strong&gt;。但是，如果加锁的粒度过粗，是很影响接口性能的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;什么是加锁粒度呢？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;其实就是就是你要锁住的范围是多大。&lt;strong&gt;比如你在家上卫生间，你只要锁住卫生间就可以了吧&lt;/strong&gt;，不需要将整个家都锁起来不让家人进门吧，卫生间就是你的加锁粒度。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不管你是&lt;code&gt;synchronized&lt;/code&gt;加锁还是&lt;code&gt;redis&lt;/code&gt;分布式锁，只需要在共享临界资源加锁即可，不涉及共享资源的，就不必要加锁。&lt;strong&gt;这就好像你上卫生间，不用把整个家都锁住，锁住卫生间门就可以了。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，在业务代码中，有一个&lt;code&gt;ArrayList&lt;/code&gt;因为涉及到多线程操作，所以需要加锁操作，假设刚好又有一段比较耗时的操作（代码中的&lt;code&gt;slowNotShare&lt;/code&gt;方法）不涉及线程安全问题。&lt;strong&gt;反例加锁，就是一锅端，全锁住&lt;/strong&gt;:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;//不涉及共享资源的慢方法&lt;br/&gt;private void &lt;span&gt;&lt;span&gt;slowNotShare&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;    try {&lt;br/&gt;        TimeUnit.MILLISECONDS.sleep(100);&lt;br/&gt;    } catch (InterruptedException e) {&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;//错误的加锁方法&lt;br/&gt;public int &lt;span&gt;&lt;span&gt;wrong&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;    long beginTime = System.currentTimeMillis();&lt;br/&gt;    IntStream.rangeClosed(1, 10000).parallel().forEach(i -&amp;gt; {&lt;br/&gt;        //加锁粒度太粗了，slowNotShare其实不涉及共享资源&lt;br/&gt;        synchronized (this) {&lt;br/&gt;            slowNotShare();&lt;br/&gt;            data.add(i);&lt;br/&gt;        }&lt;br/&gt;    });&lt;br/&gt;    log.info(&lt;span&gt;&quot;cosume time:{}&quot;&lt;/span&gt;, System.currentTimeMillis() - beginTime);&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; data.size();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;正例：&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;public int &lt;span&gt;&lt;span&gt;right&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;    long beginTime = System.currentTimeMillis();&lt;br/&gt;    IntStream.rangeClosed(1, 10000).parallel().forEach(i -&amp;gt; {&lt;br/&gt;        slowNotShare();//可以不加锁&lt;br/&gt;        //只对List这部分加锁&lt;br/&gt;        synchronized (data) {&lt;br/&gt;            data.add(i);&lt;br/&gt;        }&lt;br/&gt;    });&lt;br/&gt;    log.info(&lt;span&gt;&quot;cosume time:{}&quot;&lt;/span&gt;, System.currentTimeMillis() - beginTime);&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; data.size();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;9. 切换存储方式：文件中转暂存数据&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果数据太大，落地数据库实在是慢的话，&lt;strong&gt;就可以考虑先用文件的方式暂存&lt;/strong&gt;。先保存文件，再异步&lt;strong&gt;下载文件，慢慢保存到数据库&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里可能会有点抽象，给大家分享一个，我之前的一个&lt;strong&gt;真实的优化案例&lt;/strong&gt;吧。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;之前开发了一个转账接口。如果是并发开启，10个并发度，每个批次&lt;code&gt;1000&lt;/code&gt;笔转账明细数据，数据库插入会特别耗时，&lt;strong&gt;大概6秒左右&lt;/strong&gt;；这个跟我们公司的数据库同步机制有关，并发情况下，因为优先保证同步，所以并行的插入变成串行啦，就很耗时。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;优化前&lt;/strong&gt;，&lt;code&gt;1000&lt;/code&gt;笔明细转账数据，先落地&lt;code&gt;DB&lt;/code&gt;数据库，返回处理中给用户，再异步转账。如图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8794688457609806&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibx0y6JOmed407ic0EPjWGbhch11hWnzpaONjvPZ14FJ6Hicic7E3WoEGrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;979&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;记得当时压测的时候，高并发情况，这&lt;code&gt;1000&lt;/code&gt;笔明细入库，耗时都比较大。所以我转换了一下思路，&lt;strong&gt;把批量的明细转账记录保存的文件服务器，然后记录一笔转账总记录到数据库即可&lt;/strong&gt;。接着异步再把明细下载下来，进行转账和明细入库。最后优化后，性能提升了&lt;strong&gt;十几倍&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;优化后&lt;/strong&gt;，流程图如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0397727272727273&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibkglC7Zib9Ania7I4ia3EV80CeS0oSF3CJic20DhqaoO2fh12nxLBrgNzibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你的接口耗时瓶颈就&lt;strong&gt;在数据库插入操作这里&lt;/strong&gt;，用来批量操作等，还是效果还不理想，就可以考虑用文件或者&lt;code&gt;MQ&lt;/code&gt;等暂存。有时候批量数据放到文件，会比插入数据库效率更高。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;10. 索引&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提到接口优化，很多小伙伴都会想到&lt;strong&gt;添加索引&lt;/strong&gt;。没错，&lt;strong&gt;添加索引是成本最小的优化&lt;/strong&gt;，而且一般优化效果都很不错。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;索引优化这块的话，一般从这几个维度去思考：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;你的SQL加索引了没？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你的索引是否真的生效？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你的索引建立是否合理？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;10.1 SQL没加索引&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们开发的时候，容易疏忽而忘记给SQL添加索引。所以我们在写完&lt;code&gt;SQL&lt;/code&gt;的时候，就顺手查看一下 &lt;code&gt;explain&lt;/code&gt;执行计划。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;explain select * from user_info &lt;span&gt;where&lt;/span&gt; userId like &lt;span&gt;&#x27;%123&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你也可以通过命令&lt;code&gt;show create table &lt;/code&gt;，整张表的索引情况。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;show create table user_info;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果某个表忘记添加某个索引，可以通过&lt;code&gt;alter table add index&lt;/code&gt;命令添加索引&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;alter table user_info add index idx_name (name);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般就是：&lt;code&gt;SQL&lt;/code&gt;的&lt;code&gt;where&lt;/code&gt;条件的字段，或者是&lt;code&gt;order by 、group by&lt;/code&gt;后面的字段需需要添加索引。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;10.2 索引不生效&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候，即使你添加了索引，但是索引会失效的。&lt;strong&gt;田螺哥整理了索引失效的常见原因&lt;/strong&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;10.3 索引设计不合理&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们的索引不是越多越好，需要合理设计。比如：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;删除冗余和重复索引。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引一般不能超过&lt;code&gt;5&lt;/code&gt;个&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;索引不适合建在有大量重复数据的字段上、如性别字段&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;适当使用覆盖索引&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果需要使用&lt;code&gt;force index&lt;/code&gt;强制走某个索引，那就需要思考你的索引设计是否真的合理了&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;11. 优化SQL&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;处了索引优化，其实SQL还有很多其他有优化的空间。比如这些：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1148491879350348&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibI8PKz3jHyPY2l4rhojL1F5BwzoodMbhZrpbSGUsQ4x4TjYPz2ueb9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;862&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;12.避免大事务问题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了保证数据库数据的一致性，在涉及到多个&lt;strong&gt;数据库修改&lt;/strong&gt;操作时，我们经常需要用到事务。而使用&lt;code&gt;spring&lt;/code&gt;声明式事务，又非常简单，只需要用一个注解就行&lt;code&gt;@Transactional&lt;/code&gt;，如下面的例子：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;@Transactional&lt;br/&gt;public int createUser(User user){&lt;br/&gt;    //保存用户信息&lt;br/&gt;    userDao.save(user);&lt;br/&gt;    passCertDao.updateFlag(user.getPassId());&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; user.getUserId();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这块代码主要逻辑就是创建个用户，然后更新一个通行证&lt;code&gt;pass&lt;/code&gt;的标记。如果现在新增一个需求，创建完用户，调用远程接口发送一个&lt;code&gt;email&lt;/code&gt;消息通知，很多小伙伴会这么写：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;@Transactional&lt;br/&gt;public int createUser(User user){&lt;br/&gt;    //保存用户信息&lt;br/&gt;    userDao.save(user);&lt;br/&gt;    passCertDao.updateFlag(user.getPassId());&lt;br/&gt;    sendEmailRpc(user.getEmail());&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; user.getUserId();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样实现可能会有坑，事务中嵌套&lt;code&gt;RPC&lt;/code&gt;远程调用，即事务嵌套了一些非&lt;code&gt;DB&lt;/code&gt;操作。如果这些非&lt;code&gt;DB&lt;/code&gt;操作耗时比较大的话，可能会出现&lt;strong&gt;大事务问题&lt;/strong&gt;。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;所谓大事务问题就是，就是&lt;strong&gt;运行时间长的事务&lt;/strong&gt;。由于事务一致不提交，就会导致数据库连接被占用，即并发场景下，数据库连接池被占满，影响到别的请求访问数据库，&lt;strong&gt;影响别的接口性能&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大事务引发的问题主要有：&lt;strong&gt;接口超时、死锁、主从延迟&lt;/strong&gt;等等。因此，为了优化接口，我们要规避大事务问题。我们可以通过这些方案来规避大事务：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;RPC远程调用不要放到事务里面&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些查询相关的操作，尽量放到事务之外&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;事务中避免处理太多数据&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;13. 深分页问题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在以前公司分析过几个接口耗时长的问题，最终结论都是因为&lt;strong&gt;深分页问题&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;深分页问题，为什么会慢？我们看下这个SQL&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;select id,name,balance from account &lt;span&gt;where&lt;/span&gt; create_time&amp;gt; &lt;span&gt;&#x27;2020-09-19&#x27;&lt;/span&gt; &lt;span&gt;limit&lt;/span&gt; 100000,10;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;limit 100000,10&lt;/code&gt;意味着会扫描&lt;code&gt;100010&lt;/code&gt;行，丢弃掉前&lt;code&gt;100000&lt;/code&gt;行，最后返回&lt;code&gt;10&lt;/code&gt;行。即使&lt;code&gt;create_time&lt;/code&gt;，也会回表很多次。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过&lt;strong&gt;标签记录法和延迟关联法&lt;/strong&gt;来优化深分页问题。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;13.1 标签记录法&lt;span/&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;就是标记一下上次查询到哪一条了，下次再来查的时候，从该条开始往下扫描。就好像看书一样，上次看到哪里了，你就折叠一下或者夹个书签，下次来看的时候，直接就翻到啦。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设上一次记录到&lt;code&gt;100000&lt;/code&gt;，则SQL可以修改为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;select  id,name,balance FROM account &lt;span&gt;where&lt;/span&gt; id &amp;gt; 100000 &lt;span&gt;limit&lt;/span&gt; 10;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样的话，后面无论翻多少页，性能都会不错的，因为命中了&lt;code&gt;id&lt;/code&gt;主键索引。但是这种方式有局限性：&lt;strong&gt;需要一种类似连续自增的字段。&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;13.2 延迟关联法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;延迟关联法，就是把条件转移到主键索引树，然后减少回表。优化后的SQL如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;select  acct1.id,acct1.name,acct1.balance FROM account acct1 INNER JOIN (SELECT a.id FROM account a WHERE a.create_time &amp;gt; &lt;span&gt;&#x27;2020-09-19&#x27;&lt;/span&gt; &lt;span&gt;limit&lt;/span&gt; 100000, 10) AS acct2 on acct1.id= acct2.id;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;优化思路就是&lt;/strong&gt;，先通过&lt;code&gt;idx_create_time&lt;/code&gt;二级索引树查询到满足条件的主键ID，再与原表通过主键ID内连接，这样后面直接走了主键索引了，同时也减少了回表。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;14. 优化程序结构&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优化程序逻辑、程序代码，是可以节省耗时的。比如，&lt;strong&gt;你的程序创建多不必要的对象、或者程序逻辑混乱，多次重复查数据库、又或者你的实现逻辑算法不是最高效的&lt;/strong&gt;，等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我举个简单的例子：&lt;strong&gt;复杂的逻辑条件，有时候调整一下顺序，就能让你的程序更加高效。&lt;/strong&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;假设业务需求是这样：如果用户是会员，第一次登陆时，需要发一条感谢短信。如果没有经过思考，代码直接这样写了&lt;/p&gt;&lt;/blockquote&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt;(isUserVip &amp;amp;&amp;amp; isFirstLogin){&lt;br/&gt;    sendSmsMsg();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设有&lt;code&gt;5&lt;/code&gt;个请求过来，&lt;code&gt;isUserVip&lt;/code&gt;判断通过的有&lt;code&gt;3&lt;/code&gt;个请求，&lt;code&gt;isFirstLogin&lt;/code&gt;通过的只有&lt;code&gt;1&lt;/code&gt;个请求。那么以上代码，&lt;code&gt;isUserVip&lt;/code&gt;执行的次数为&lt;code&gt;5&lt;/code&gt;次，&lt;code&gt;isFirstLogin&lt;/code&gt;执行的次数也是&lt;code&gt;3&lt;/code&gt;次，如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1346153846153846&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibIXhAeweBewjndBKiaAA7RvKgJibZS7nicmftQCXkfW8FRiauLbu3AYlPCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;832&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果调整一下&lt;code&gt;isUserVip&lt;/code&gt;和&lt;code&gt;isFirstLogin&lt;/code&gt;的顺序：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt;(isFirstLogin &amp;amp;&amp;amp; isUserVip ){&lt;br/&gt;    sendMsg();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;isFirstLogin&lt;/code&gt;执行的次数是&lt;code&gt;5&lt;/code&gt;次，&lt;code&gt;isUserVip&lt;/code&gt;执行的次数是&lt;code&gt;1&lt;/code&gt;次：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.12776412776412777&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1PmpwP7aJCPYSrFvUia0Vo4NxLibz8ocQeiagnZk72M9GL3ZWnyqHgWMBicZJeicZoibwqiczPmwRZGm3Ew4Hzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;814&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;酱紫程序是不是变得更高效了呢？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;15. 压缩传输内容&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;压缩传输内容，传输报文变得更小，因此传输会更快啦。&lt;code&gt;10M&lt;/code&gt;带宽，传输&lt;code&gt;10k&lt;/code&gt;的报文，一般比传输&lt;code&gt;1M&lt;/code&gt;的会快呀。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;打个比喻，一匹千里马，它驮着100斤的货跑得快，还是驮着10斤的货物跑得快呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再举个视频网站的例子：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果不对视频做任何压缩编码，因为带宽又是有限的。&lt;strong&gt;巨大的数据量在网络传输的耗时会比编码压缩后，慢好多倍&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;16. 海量数据处理，考虑NoSQL&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前看过几个慢&lt;code&gt;SQL&lt;/code&gt;，都是跟深分页问题有关的。&lt;strong&gt;发现用来标签记录法和延迟关联法，效果不是很明显&lt;/strong&gt;，原因是要统计和模糊搜索，并且统计的数据是真的大。最后跟组长对齐方案，就把数据同步到&lt;code&gt;Elasticsearch&lt;/code&gt;，然后这些模糊搜索需求，都走&lt;code&gt;Elasticsearch&lt;/code&gt;去查询了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我想表达的就是，如果数据量过大，一定要用关系型数据库存储的话，就可以分库分表。但是有时候，我们也可以使用&lt;code&gt;NoSQL，如Elasticsearch、Hbase&lt;/code&gt;等。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;17. 线程池设计要合理&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们使用线程池，就是让&lt;strong&gt;任务并行处理，更高效地完成任务&lt;/strong&gt;。但是有时候，如果线程池设计不合理，接口执行效率则不太理想。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般我们需要关注线程池的这几个参数：&lt;strong&gt;核心线程、最大线程数量、阻塞队列&lt;/strong&gt;。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如果核心线程过小，则达不到很好的并行效果。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果阻塞队列不合理，不仅仅是阻塞的问题，甚至可能会&lt;code&gt;OOM&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果线程池不区分业务隔离，&lt;strong&gt;有可能核心业务被边缘业务拖垮&lt;/strong&gt;。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家可以看下我之前两篇有关于线程池的文章：&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;18.机器问题 （fullGC、线程打满、太多IO资源没关闭等等）。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候，我们的接口慢，就是机器处理问题。主要有&lt;code&gt;fullGC&lt;/code&gt;、线程打满、太多IO资源没关闭等等。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;之前排查过一个&lt;code&gt;fullGC&lt;/code&gt;问题：运营小姐姐导出&lt;code&gt;60多万&lt;/code&gt;的&lt;code&gt;excel&lt;/code&gt;的时候，说&lt;strong&gt;卡死&lt;/strong&gt;了，接着我们就收到监控告警。后面排查得出，我们老代码是&lt;code&gt;Apache POI&lt;/code&gt;生成的&lt;code&gt;excel&lt;/code&gt;，导出&lt;code&gt;excel&lt;/code&gt;数据量很大时，当时JVM内存吃紧会直接&lt;code&gt;Full GC&lt;/code&gt;了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果线程打满了，也会导致接口都在等待了。所以。如果是高并发场景，&lt;strong&gt;我们需要接入限流，把多余的请求拒绝掉&lt;/strong&gt;。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果&lt;strong&gt;IO资源没关闭，也会导致耗时增加&lt;/strong&gt;。这个大家可以看下，平时你的电脑一直打开很多很多文件，是不是会觉得很卡。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a8482f4f881adde76936a1bade11046e</guid>
<title>JVM 垃圾回收器：分代堆内存管理，堆设计+分代边界+回收设计思路</title>
<link>https://toutiao.io/k/y5v6q06</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100032171&quot; data-ratio=&quot;0.271875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/RQueXibgo0KP4mOic3fe02VJ1icuIJYLUIUUENk0IicFwiaWH8ZOV5RkvNoBoictFGmBqTtbwHpwybGMZ6e0vlPgpBsw/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;h1 data-track=&quot;4&quot;&gt;&lt;span&gt;◆ &lt;/span&gt;JVM垃圾回&lt;span&gt;收器详解&lt;/span&gt;&lt;/h1&gt;&lt;p data-track=&quot;5&quot;&gt;&lt;span&gt;垃圾回收器是JVM中最重要的组件之一，几乎每一个JDK的大版本都对垃圾回收进行重大的更新。另外，由于JDK发布策略的改变，在最近3年的版本发布中，每一个大版本都至少合入一个（甚至数个）关于垃圾回收的JEP。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;44&quot;&gt;&lt;span&gt;垃圾回收的快速发展主要受两个方面的影响：一方面是现代计算机的配置越来越好，应用实际可使用的内存也越来越多（虽然微服务架构改变了这一现象，但是微服务拆分过多，将导致公共资源消耗过多，这是JDK的另外一个发展方向）；另一方面是应用性能要求也越来越高，期望垃圾回收尽可能少的暂停。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;46&quot;&gt;&lt;span&gt;这些诉求要求不断优化垃圾回收，甚至出现新的垃圾回收实现。根据JDK版本支持的策略，JDK 8、JDK 11和JDK 17是目前长期支持的版本。目前这3个版本共支持7个垃圾回收器，分别是串行回收（简称SerialGC）、并行回收（Parallel Scavenge，简称Parallel GC）、并发标记清除（Concurrent Mark Sweep，简称CMS）、垃圾优先（Garbage First，简称G1）、Shenandoah GC、ZGC、Epsilon（实验特性，仅支持分配不回收，实际场景中不会采用）。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;45&quot;&gt;&lt;span&gt;由于垃圾回收技术发展很快，所以这3个版本中JDK支持的垃圾回收器并不完全相同，其中CMS仅在JDK 8和JDK 11中支持，ZGC在JDK11中为实验特性，在JDK 17中为正式产品，Shenandoah在JDK 17中为正式产品，Epsilon在JDK 11和JDK 17中为实验特性。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;22&quot;&gt;&lt;span&gt;JVM实现的垃圾回收算法从不同的角度可以归属到不同的类别。通常会从执行角度和内存管理角度进行划分。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;24&quot;&gt;&lt;span&gt;从执行角度可以分为以下3种：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;25&quot;&gt;&lt;span&gt;串行执行：串行指的是当垃圾回收启动时，只有一个垃圾回收线程在工作，而Java应用程序则暂停执行。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;27&quot;&gt;&lt;span&gt;并行执行：JVM中的并行指多个垃圾回收相关线程在OS之上并发地运行。这里的并行强调的是只有垃圾回收线程工作，Java应用程序暂停执行。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;30&quot;&gt;&lt;span&gt;并发执行：JVM中的并发指垃圾回收相关的线程并发地运行（如果启动多个线程），且这些工作线程会与Java应用程序并发地运行。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;32&quot;&gt;&lt;span&gt;从内存管理角度可以分为以下两种：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;33&quot;&gt;&lt;span&gt;连续内存管理：JVM管理一块内存区域，在对象分配时会请求一块可容纳对象大小的内存块才能分配成功，在回收时会一次性回收整个内存区域。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;36&quot;&gt;&lt;span&gt;分区内存管理：内存区域被划分成多个分区，在进行对象分配时，对象所需的内存可以由多个不连续的内存分区组成，在回收时一般也只回收部分分区。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;39&quot;&gt;&lt;span&gt;按照执行和内存管理的角度，JVM支持的垃圾回收可以归纳如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.18733153638814015&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaMFvoYv1tIOVnQdTFibnRtC90O6BFLb8ZefMdIwgGmbb04vZmxyYWQEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1484&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-track=&quot;40&quot;&gt;&lt;span&gt;在垃圾回收的实现中，可能会根据对象的生命周期管理实现分代，不同生命周期的对象放入不同的内存区域，不同的内存区域通常采用不同的回收算法。按照分代可以将垃圾回收器划分为单代内存回收器和两代内存回收器。单代内存回收器采用一种回收算法，两代内存回收器通常采用两种算法或者采用同一种算法但不同的回收策略。按照分代的划分，JVM支持的垃圾回收可以归纳如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14052953156822812&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaibichVAIyQU6tLVXibkib1GVDyCfiaZgGaY5lnNdu9K7eW9DichU0ibKrYOlw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1473&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1 data-track=&quot;4&quot;&gt;&lt;span&gt;◆ &lt;/span&gt;串行回收&lt;/h1&gt;&lt;p data-track=&quot;51&quot;&gt;&lt;span&gt;串行回收器是JVM中最早实现的垃圾回收器。从工程实现角度看，它是最简单的垃圾回收器，但目前串行回收器的使用场景已经非常有限，除了少部分特殊的场景以外几乎都不会考虑使用它。串行回收器是一款暂停应用执行的垃圾回收器，且在垃圾回收执行过程仅有一个GC工作线程执行垃圾回收的动作，它逻辑清晰、实现简单，是学习和研究垃圾回收器的首选。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;56&quot;&gt;&lt;span&gt;虽然串行回收器是JVM中最简单的垃圾回收器，但它也包含了很多有意思的设计，而且这些设计和后面介绍的其他垃圾回收器有许多共同的地方。通常对于一款垃圾回收器的实现，需要回答以下问题：如何进行分代内存管理？新生代如何进行内存管理？老生代（或者整个堆空间）如何进行内存管理？新生代和老生代之间是否需要交互？怎样交互？这些问题在本章中都有回答。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-track=&quot;4&quot;&gt;&lt;span&gt;◆ &lt;/span&gt;分代堆内存管理概述&lt;/h1&gt;&lt;p data-track=&quot;63&quot;&gt;&lt;span&gt;在2.3.4节介绍分代回收时，提到分代有一些问题需要回答，最简单的问题是分代边界是否固定？串行回收采用边界固定的分代方法，将整个堆空间划分为两个代：新生代和老生代。在内存管理方面，新生代采用复制算法进行垃圾回收，整个堆空间采用标记压缩算法进行垃圾回收，复制算法采用的是变异的Cheney复制算法。整个堆内存管理示意图如图3-1所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4889908256880734&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaJ4iaVEU1O7biabU7e1leszDpRYbBnq0Pfz58Xodd9Pb6XibBEzkTHdg8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1090&quot;/&gt;&lt;/p&gt;&lt;p&gt;图3-1 串行回收堆空间管理示意图&lt;/p&gt;&lt;p data-track=&quot;68&quot;&gt;&lt;span&gt;串行回收的特点如下：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;69&quot;&gt;&lt;span&gt;1）内存是连续的。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;70&quot;&gt;&lt;span&gt;2）新生代和老生代&lt;/span&gt;&lt;span&gt;边界固定，边界在JVM启动时确定&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;71&quot;&gt;&lt;span&gt;3）新生代空间划分为3个子空间，分别是Eden、From、To空间，并且Eden、From、To空间的大小在&lt;/span&gt;&lt;span&gt;启动时确定&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;73&quot;&gt;&lt;span&gt;4）新生代空间的垃圾回收采用的是&lt;/span&gt;&lt;span&gt;复制算法&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;74&quot;&gt;&lt;span&gt;5）整个堆空间的垃圾回收采用的是&lt;/span&gt;&lt;span&gt;标记压缩算法&lt;/span&gt;&lt;span&gt;。注意，标记压缩算法针对的是整个堆空间，串行回收中没有只回收老生代的算法，具体原因后文讨论。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-track=&quot;4&quot;&gt;&lt;span&gt;◆ &lt;/span&gt;堆设计&lt;/h1&gt;&lt;p data-track=&quot;78&quot;&gt;&lt;span&gt;从应用程序运行的角度来说，应用所需的堆空间大小与应用程序中对象的分配速率和运行时间相关。由于应用对象分配速率和运行时间不同，且对于堆空间大小的需求不尽相同，因此应用启动时应该告诉JVM需要多少堆空间，常见的做法是在应用启动时通过参数设置堆空间大小。除了需要确定堆空间的大小以外，使用者还需要根据垃圾回收器堆的设计了解如何使用堆空间，才能充分利用堆空间。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;84&quot;&gt;&lt;span&gt;JVM管理的堆空间是基于OS管理的内存之上的，应用在启动时向OS请求整个运行期所需要的全部内存。当然这样的设计并非完美，至少存在两个问题：其一，从OS直接请求内存是相对耗时的操作，请求运行时全部内存将导致JVM启动时间过长；其二，JVM启动时从OS请求了内存但并不会立即使用，实际上造成了资源浪费。JVM如此设计的原因在于：应用都是较长时间运行，期望通过启动初始化运行时所需的内存加快运行的效率。那么有没有比较好的方案既能保证应用的执行效率，又能兼顾应用启动速度和内存利用率呢？&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;91&quot;&gt;&lt;span&gt;JVM通过细化堆空间设计解决这个问题。JVM提供了两个参数：一个是最小的堆空间，另一个是最大的堆空间。假定这两个参数分别记为InitialHeapSize和MaxHeapSize&lt;/span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;span&gt;。设计思路修改为：JVM启动时向OS请求最小的堆空间，并在运行时根据内存使用的情况逐步扩展，直到堆空间达到参数设置的最大堆空间。这样的设计在一定程度上解决了JVM启动慢、资源利用率低的问题，其本质是把应用启动时的内存资源初始化请求推迟到应用运行时，这可能导致应用运行性能受到内存资源扩展的影响。所以在一些应用中为了减少运行时内存扩展带来的影响，会在启动时把最小堆空间和最大堆空间设置成相同的值。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;100&quot;&gt;&lt;span&gt;1.5节讨论垃圾回收工作范围时，提到垃圾回收不仅包含向OS请求内存，还包含向OS归还申请的内存。早期JVM设计主要考虑的是如何合理地向OS请求内存，很少考虑如何向OS归还内存。但这样的设计在一些场景中存在问题。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;124&quot;&gt;&lt;span&gt;例如，一个应用在运行过程中内存使用越来越多，在业务处理高峰时内存使用达到了最大堆空间，但当业务峰值下降之后，由于没有合理的内存归还机制，申请的内存一直被占用但没有再次使用，这实际上造成了资源浪费。这样的问题在云场景中表现得非常明显，在云场景中，用户按资源使用付费，不愿意也不应该为未使用的内存付费，所以最新的JVM都会考虑在什么情况下向OS归还内存。需要指出的是，向OS归还内存也是一个耗时的操作，不当的设计和实现会导致程序暂停时间过长。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;125&quot;&gt;&lt;span&gt;另外，归还时机和归还的内存数量不当，也可能导致内存归还后应用内存不足，会立即向OS再次请求内存，从而发生内存使用颠簸，这也会引起应用性能下降。针对这一问题，一个可能的设计是引入一个新的参数，假定参数记为SoftMaxHeapSize&lt;/span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;span&gt;，用于控制内存归还的边界。该参数满足条件：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;114&quot;&gt;&lt;span&gt;InitialHeapSize≤SoftMaxHeapSize&lt;/span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;span&gt;≤MaxHeapSize，这3个参数的作用如下：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;116&quot;&gt;&lt;span&gt;InitialHeapSize作为应用启动时最小的堆空间。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;117&quot;&gt;&lt;span&gt;根据运行的需要，应用程序使用的内存可以扩展，但最大使用量不超过MaxHeapSize。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;119&quot;&gt;&lt;span&gt;SoftMaxHeapSize作为控制参数，当内存使用超过该阈值到MaxHeapSize之间的部分，在满足一定条件的情况下，可以归还给OS。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;121&quot;&gt;&lt;span&gt;对于不支持SoftMaxHeapSize的垃圾回收器，可以简单地认为SoftMaxHeapSize等于MaxHeapSize。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;123&quot;&gt;&lt;span&gt;根据这3个参数的含义，堆空间的划分如图3-2所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.27812223206377323&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaAENibXuDZbLMTErIotQiatpqYILSK2kLtpVW9sotBQLqApnKLvvN8g5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1129&quot;/&gt;&lt;/p&gt;&lt;p&gt;图3-2 堆空间划分示意图&lt;/p&gt;&lt;p data-track=&quot;126&quot;&gt;&lt;span&gt;那么在实际工作中该如何设置这3个参数值？通常的原则如下：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;127&quot;&gt;&lt;span&gt;1）MaxHeapSize是对应用程序&lt;/span&gt;&lt;span&gt;最大&lt;/span&gt;&lt;span&gt;内存量的估计。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;128&quot;&gt;&lt;span&gt;2）SoftMaxHeapSize是对应用程序常见&lt;/span&gt;&lt;span&gt;工作负载&lt;/span&gt;&lt;span&gt;使用的内存量的估计。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;129&quot;&gt;&lt;span&gt;3）InitialHeapSize一方面是对应用程序启动后所需&lt;/span&gt;&lt;span&gt;最小&lt;/span&gt;&lt;span&gt;内存使用量的估计（最小内存一般指应用满足最小工作负载时的内存使用量），另一方面是在启动速度和资源利用之间寻找一个平衡值（即在最小内存使用量和最大内存使用量之间寻找一个合适的值）。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;133&quot;&gt;&lt;span&gt;在JVM的实现中，应用也可以不提供这3个参数值。如果应用启动时没有提供参数值，那么JVM会为参数提供一个默认值，然后根据系统的硬件配置启发式地为参数推导一个“合适”的值。例如，JVM运行在32位系统之上，MaxHeapSize的默认值是96MB；JVM运行在64位系统之上，MaxHeapSize的默认值是124.8MB。然后JVM进一步启发式地推导：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;154&quot;&gt;&lt;span&gt;在小内存系统中使用50%的物理内存作为MaxHeapSize的上限（小内存指的是默认值大于50%的物理内存），否则使用25%的物理内存作为MaxHeapSize的上限，然后再通过其他参数加以调整（具体公式会在第9章详细介绍）。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;141&quot;&gt;&lt;span&gt;JVM的设计者推荐Out-Of-Box（开箱即用）的使用方式，即JVM使用者无须进行任何参数配置即可较好地使用JVM。但是在实际工作中，对于堆空间这样重要的参数，使用者还是需要明确地设置，如明确设置MaxHeapSize等相关参数，既能确保资源没有浪费，又能保证资源充分利用。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-track=&quot;4&quot;&gt;&lt;span&gt;◆ &lt;/span&gt;分代边界&lt;/h1&gt;&lt;p data-track=&quot;146&quot;&gt;&lt;span&gt;在固定边界的分代内存管理中，边界该如何确定？因为整个堆空间划分为新生代和老生代两个代，所以只要确定其中一个代的大小，另外一个代的大小也就确定下来，边界也就确定了。JVM通过确定新生代的大小来确定边界，假定新生代的大小记为MaxNewSize。从整体的堆空间中确定新生代空间大小常用的方法有以下两种：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;151&quot;&gt;&lt;span&gt;1）绝对值划分：设置一个新生代的大小。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;152&quot;&gt;&lt;span&gt;2）比例划分：设置一个比例，假定记为NewRatio，假定堆大小记为HeapSize，在JVM中新生代大小可以通过公式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14947683109118087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaZ6bqxmatkpY97oh8YDyrVPibk6Dusux5YiaXNfAIrZfGZRU8R7Qicj73w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-track=&quot;155&quot;&gt;&lt;span&gt;计算得到。&lt;/span&gt;&lt;span&gt;该参数的含义是：新生代和老生代的比例为1∶NewRatio&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;156&quot;&gt;&lt;span&gt;JVM同时支持两种设置方式，这意味着使用者既可以通过设置新生代大小（绝对值方式）确定边界，也可以通过设置新生代占用整个堆空间的比例来确定边界。由于JVM同时支持两种方式，而两种方式修改的是同一个参数，如果两种方式同时使用，则会造成参数设置冲突。而在实际工作中，笔者也遇到过一些用户对于参数不了解或者错误使用的情况，同时设置这两种参数，从而造成了参数冲突。在JVM实现中，为了防止误用，需要解决这样的冲突。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;162&quot;&gt;&lt;span&gt;通常解决这类冲突的方法是对这两种参数的设置方式使用不同的优先级，当设置高优先级参数时，低优先级参数失效。在JVM中，绝对值参数设置方式优先级更高，即假设使用者同时设置了参数MaxNewSize和NewRatio，只有MaxNewSize有效，NewRatio无效。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;166&quot;&gt;&lt;span&gt;笔者在实际工作中遇到过许多JVM使用者不知道或者忘记设置新生代大小的情况，新生代大小的设置实际上对应用的性能有较大的影响（新生代用于应用程序对象的分配，所以新生代的大小会直接影响应用的效率。参考2.3节垃圾回收的基础知识）。JVM中关于新生代大小参数设置的效果如表3-1所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25075711689884916&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaiakPTmO9eP1qjLicT4qsbyReOO8hdLwSmbglaA1MtDiarKAicgzY9VRXlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1651&quot;/&gt;&lt;/p&gt;&lt;p&gt;表3-1 新生代大小参数设置效果&lt;/p&gt;&lt;p data-track=&quot;171&quot;&gt;&lt;span&gt;在讨论分代边界的时候，我们假定堆空间大小固定为HeapSize，并根据上面的方法计算新生代和老生代的大小，进而确定边界。但是在上一节的讨论中，使用的堆空间并不固定，存在最大堆空间和最小堆空间。那么边界是与最大堆空间相关，一直保持不变，还是与实际使用的堆空间相关，随着使用堆空间的大小变化而变化呢？其实这个问题并没有一个绝对的设计原则。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;176&quot;&gt;&lt;span&gt;串行回收使用固定的边界，其好处如下：&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;49&quot;&gt;&lt;span&gt;1）新生代扩展处理简单。假设边界随着堆空间的实际使用量的变化而变化，在新生代需要扩展的时候该如何处理？根据图3-1所示的内存对象布局，为了保持新生代和老生代管理内存的连续性，只能把老生代管理的内存向后移动，移动出的空闲部分归新生代扩展使用。移动内存是非常耗时的操作，而使用固定边界可以避免内存移动，从而获得更高性能。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;181&quot;&gt;&lt;span&gt;2）代际信息管理简单。通常为了高效地进行垃圾回收，可以使用引用集管理代际之间的引用，例如使用卡表。当边界固定时，卡表相关的写屏障处理简单，通过比较对象地址和边界的关系，非常容易判断对象是位于新生代中还是老生代中，从而减少写屏障的额外消耗。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;185&quot;&gt;&lt;span&gt;固定新生代大小最大的缺点是内存管理的灵活性差，应用在启动时就需要确定新生代大小，这通常并不容易。当然垃圾回收算法可以增强，将固定边界优化为浮动边界。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;189&quot;&gt;&lt;span&gt;结合堆空间大小动态变化和边界固定的特点，将图3-1和图3-2组合后，&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;190&quot;&gt;&lt;span&gt;应用堆空间的内存布局如图3-3所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.31101094655505473&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjiaWNH3K46sAkpmCiaWVibqpYBaEfv6zibDFt7Y8OnmIsBc6TgwujYT1EPAQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1553&quot;/&gt;&lt;/p&gt;&lt;p&gt;图3-3 增加分代后的堆空间设计&lt;/p&gt;&lt;h1 data-track=&quot;4&quot;&gt;&lt;span&gt;◆ &lt;/span&gt;回收设计思路&lt;/h1&gt;&lt;p data-track=&quot;192&quot;&gt;&lt;span&gt;在上文中提到，分代后针对不同的内存空间使用不同的垃圾回收算法。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;193&quot;&gt;&lt;span&gt;这需要进一步考虑两个代使用的场景，以及何时可以启动垃圾回收。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;194&quot;&gt;&lt;span&gt;1）新生代的内存主要用于响应应用程序内存的分配请求，所以新生代的回收时机是在无法响应应用的内存分配请求时。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;196&quot;&gt;&lt;span&gt;2）老生代的内存主要用于新生代垃圾回收以后对象的晋升，老生代GC对象晋升导致空间不足，所以老生代回收的时机一般是无法响应新生代回收中对象的晋升请求时。另外，在一些特殊情况下（如超大对象的分配），Mutator也可以直接在老生代中直接分配对象。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;200&quot;&gt;&lt;span&gt;从两个内存代的使用场景来说，希望针对新生代的垃圾回收（称为MinorGC）触发更为频繁，针对老生代的垃圾回收（Major GC）触发次数少一些。&lt;/span&gt;&lt;/p&gt;&lt;p data-track=&quot;202&quot;&gt;&lt;span&gt;通常两种GC工作方式如图3-4所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.28035043804755944&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RQueXibgo0KNBubb61Y1jPCgl8iaQ1vqjialmFB61D2GkT6yvATYVFMguLu2wvvm3bDW9vu1yb3SrkmD6d6dWxnEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;799&quot;/&gt;&lt;/p&gt;&lt;p&gt;图3-4 Minor GC和Major GC理论触发模型&lt;/p&gt;&lt;p data-track=&quot;203&quot;&gt;&lt;span&gt;在JVM中通常使用Major GC指代老生代的回收，用Full GC指代整个堆空间的回收。上面提到串行回收上并不存在Major GC，当老生代无法响应MinorGC对象晋升时直接触发Full GC。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来源&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;https://www.toutiao.com/article/7175781049492931110/?log_from=567d419a87628_1671152862870&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span&gt;“IT大咖说”欢迎广大技术人员投稿，投稿邮箱：aliang@itdks.com&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;94329&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100032172&quot; data-ratio=&quot;0.3208955223880597&quot; data-type=&quot;gif&quot; data-w=&quot;134&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/RQueXibgo0KNrzPFsmantZnUrxKJEnD7KM7UXUc0VMDKiaguau3uRf6zm5msPR7GJgQKViaUBU1fIXu2qj5IdOa8A/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;来都来了，走啥走，留个言呗~&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; IT大咖说  | &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt; 关于版权&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;由“IT大咖说（ID：itdakashuo）”原创的文章，转载时请注明作者、出处及微信公众号。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;投稿、约稿、转载请加微信：ITDKS10（备注：投稿），茉莉小姐姐会及时与您联系！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感谢您对IT大咖说的热心支持！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;blockquote&gt;&lt;section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1cf5fcdbfb36d2adeae0e905f31f3b83</guid>
<title>浅谈 Remote Work</title>
<link>https://toutiao.io/k/qn17x2c</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;span&gt;今天，来聊一下 &lt;strong&gt;&lt;span&gt;Remote Work&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5294117647058824&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/la8s6uvJibdSEHaQmoV09x0BeUWhxibRSvicl9zGDzPwWMn1f5QXz7vO7vsicfbqQc2ozLnQ0107aaroUHyM7icBCiaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;850&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Remote Work &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;(远程办公) 近几年慢慢为人熟知，一定程度上和 &lt;span&gt;&lt;strong&gt;&lt;span&gt;Work From Home &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;(居家办公) 有很大关系。但事实上, &lt;strong&gt;&lt;span&gt;Remote Work &lt;/span&gt;&lt;/strong&gt;和 &lt;strong&gt;&lt;span&gt;Work From Home &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;并不是一回事。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Remote Work&lt;/span&gt;&lt;/strong&gt;，&lt;/span&gt;&lt;span&gt;指的是在公司办公室外进行的工作。是的，远程可能发生在家里，但也可能发生在旅途、咖啡馆、酒店等，办公地点完全由员工选择。而&lt;/span&gt;&lt;span&gt; &lt;span&gt;&lt;strong&gt;&lt;span&gt;Work From Home &lt;/span&gt;&lt;/strong&gt;专指团队成员必须在家中或居住地工作的工作模式，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;一般仅作为 &lt;strong&gt;&lt;span&gt;On-site&lt;/span&gt;&lt;/strong&gt; 一个替代方案。你看，疫情好转后，很多公司取消了 &lt;strong&gt;&lt;span&gt;Work From Home &lt;/span&gt;&lt;/strong&gt;的政策，要求大家继续去办公室搬砖。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;下面，我结合自己最近远程工作的经历，来聊聊：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Remote Work &lt;/span&gt;&lt;/strong&gt;的优缺点&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;申请&lt;strong&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;Remote Work&lt;/span&gt;&lt;/strong&gt; 的常用网站&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;拿到&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; Remot&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;e Work Offer &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;的一些 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Tips&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1. &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Remote Work &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;的优缺点&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;优点&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每天至少可以省下两个小时的通勤时间。而这两个小时，我可以用来练习英语，或者偶尔站在窗边发发呆，或者去学校接小孩；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每天可以陪伴家人，陪孩子慢慢长大。即使工作的时候一般不和家人不说话，但你要知道，有一个大活人就坐书房，家人会觉得很心安&lt;span&gt;；&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;拒绝地沟油，每天都能吃到爱心早餐、午餐和晚餐；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;除了时间开销，经济开销也少了，每个月停车费+油费+餐费，可节省 2k 多；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每天和来自不同国家，不同时区，操着不同语言的小伙伴一起工作，口语和见识多少是有些进步的；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;办公地点不受限制，如果不考虑子女教育和医疗，完全可以去三四线城市生活，看下面的画面来感受一下：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9143356643356644&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/la8s6uvJibdSEHaQmoV09x0BeUWhxibRSvZ8FribsSYe9DKXZjcXUz4icHicT45ZEWibe7mf4icjLhlG8RbAnotCfC8sQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2288&quot;/&gt; &lt;/section&gt;&lt;p&gt;&lt;span&gt;缺点&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;很难有现场办公那样的高效、及时的沟通：你明明看到那个人的 Slack 是在线的，但 Ta 可能就是临时走开了，只能等；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要有完善的 O&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;ncall&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 机制，不然出现问题的时候，你是找不到人的；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;工作时间一般是超过 8 小时的，尤其是晚上 12 点你准备休息的时候，可能西半球的同事早上 9 点刚上线，有很多事想找你沟通；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该死的孤独感：快乐没有那么强烈，悲伤却可以持续一段时间，所以要找到适合自己的方式排解；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;健康问题：久坐会导致脖子酸，脊椎痛，还有肉眼可见的赘肉，不断塌陷；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;可能需要自己处理社保和税收问题: 可参考 &lt;/span&gt;&lt;span&gt;https://eleduck.com/posts/mbfBXa&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2. &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;申请&lt;/span&gt;&lt;span&gt;&lt;span&gt; Remote Work &lt;/span&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span&gt;常用网站&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;国内常用网站&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;V2EX&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;https://www.v2ex.com/go/jobs&lt;/span&gt;&lt;span&gt;,  &lt;/span&gt;&lt;span&gt;需要科学上网，里面不仅有远程的职位，也有一些大厂和独角兽的内推信息。整体而言，发帖质量比较高，信息也比较可靠；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;电鸭&lt;/span&gt;&lt;span&gt;: &lt;/span&gt;&lt;span&gt;https://eleduck.com/categories/5&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;国内找远程岗位的主要阵地，但帖子的质量参差不齐。查看联系方式需要付费，建议不要去联系那些&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt; 写着高薪，但工作内容语焉不详的公司，自己需要有判断力；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Brix Labs&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;:  &lt;/span&gt;&lt;span&gt;https://brix-zh.webflow.io&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;这其实是一个远程人才的服务平台，帮国外的雇主招聘远程人才，解决远程雇员的薪资和福利问题。需要通过平台自身的面试（算法 + 英语），然后有专人跟进，推荐到雇主再进行面试。个人经历下来，是比较靠谱的一个平台。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;国外常用网站&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅推荐自己使用过、投递后有反馈、有面试的网站：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;LinkedIn:&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;https://www.linkedin.com/jobs/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;AngelLi&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;st：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://angel.co/jobs&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Fiverr: &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://www.fiverr.com/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Upwork&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;:&lt;/span&gt;&lt;/strong&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://www.upwork.com/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;We Work Remotely&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;:&lt;/span&gt;&lt;/strong&gt;  &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://weworkremotely.com/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Remotive&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;: &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://remotive.com/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Web3&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt; 远程岗位&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;https://web3.career/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;h&lt;/span&gt;&lt;span&gt;ttps://www.marswork.xyz/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;h&lt;/span&gt;&lt;span&gt;ttps://findweb3.com/jobs&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;h&lt;/span&gt;&lt;span&gt;ttps://www.defi.jobs/&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;拿到&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt; Remote Work Offer &lt;/span&gt;&lt;span&gt;的一些 &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Tips&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综合各大远程网站的招聘信息，整体而言，目前远程雇主对人才的需求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小伙伴们可以结合自己的技术栈，有针对性地去选择和准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，要拿到一份适合自己的远程 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Offer&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; ，接下来还要做些功课&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;练好口语！练好口语！练好口语！&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;重要的事情说三遍。英语口语真的很重要，特别是对于我们国内那些技术能力比较强，书面英语也不错，但就是不会开口说的工程师来说，口语可以说是打开远程世界的一扇窗。当然，我得承认，我的口语目前也不溜，但一年多下来，基本能 hold 住每天近 &lt;/span&gt;&lt;span&gt;30&lt;/span&gt;&lt;span&gt; 分钟的晨会了；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LeetCode &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;上&lt;/span&gt;&lt;span&gt;的 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;HOT 100 &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;算法题，建议多刷几遍。因为国外的技术面试基本需要考 1-2 轮的算法, 没有一定的题量输入的话，面试时很难临场想出破解之法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;准备一些 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;System Design&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 的题目，尤其是像 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Twitter timeline&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, &lt;/span&gt;&lt;strong&gt;&lt;span&gt;K-V storage&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 这些，理清思路后多用英语对着镜子说几遍，面试时不要忘了要和面试官多互动互动。当然，面试之前找个人 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;mock interview&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 一下也是不错的建议；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;准备一些 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Behavioural Questions&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，比如：以往工作中遇到冲突怎么处理？遇到任务延期怎么处理？等等。油管上有很多好的视频，可以移步去学习。 &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;等拿到了远程的 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;offer&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，接下来就得为自己准备一个舒服的办公环境了，个人觉得这个投入是必要的：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一把舒服的人体工程学椅子：能缓解久坐对脊柱和腰椎的部分伤害；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个可以肆意敲击，再也不用担心会干扰到其他同事的机械键盘。它可以提醒你，你在好好工作！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至少备两个能&lt;/span&gt;&lt;span&gt;科&lt;/span&gt;&lt;span&gt;学&lt;/span&gt;&lt;span&gt;上网的&lt;/span&gt;&lt;span&gt;软件；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个番茄钟，防止自己走神；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Google Suit&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Google meeting + Google Doc + Google Calendar&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slack&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;外企常用工作沟通软件。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;By the way&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slack&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 有个抱团功能很好用，在 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Slack &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;上&lt;span&gt;拉&lt;/span&gt;几个人开会很方便，一定程度上可以代替 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Zoom&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Jira + Confluence&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：外企产研部门必备套件。用于日常研发任务管理以及一些工作文档的沉淀。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Good Luck, Guys!&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0bad4978097fc13f399dd52c9a88bb65</guid>
<title>云知声: 基于 JuiceFS 的超算平台存储实践</title>
<link>https://toutiao.io/k/62pwkxk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;blockquote data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;📖 &lt;span&gt;本文作者：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吕冬冬，云知声超算平台架构师，负责云知声大规模分布式机器学习平台架构设计与新功能演进，负责深度学习算法应用优化与 AI 模型加速。研究领域包括大规模集群调度、高性能计算、分布式文件存储、分布式缓存等。云原生开源社区爱好者。JuiceFS社区版多个重要特性贡献者。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.52&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3EcuPIickyyEwbzUrMVnXJaXicEHYVRUz1Xar9X3Tic8ZUNJ3IfuVNP8wUpaKiafwYOY6lfXjlYbcJUJklKI7psbsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;h2&gt;01 背景&lt;/h2&gt;&lt;p&gt;云知声从一家专注于语音及语言处理的技术公司，现在技术栈已经发展到具备图像、自然语言处理、信号等全栈式的 AI 能力，是国内头部人工智能独角兽企业。公司拥抱云计算，在智慧医疗、智慧酒店、智慧教育等方面都有相应的解决方案。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.56953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtB2XFOBBKfm7iaIURKprI264OfgUy13MwRVHD4WIiaQOuMmZsWbgm8vQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;p&gt;Atlas 是云知声的底层基础技术平台，支撑着云知声所有模型的迭代：&lt;/p&gt;&lt;p&gt;第一层是业务层，主要是公司的业务如语音处理、图像处理、自然语言处理等。&lt;/p&gt;&lt;p&gt;第二层是控制中心，从数据生产、数据接入到模型发布都可以一站式完成。&lt;/p&gt;&lt;p&gt;第三层是核心的计算层，主要支持深度学习，以及数据预处理。&lt;/p&gt;&lt;p&gt;最底层是基础架构层，主要是由 GPU 集群、CPU 集群以及分布式存储构成，所有的机器都是用 100Gbps 的 InfiniBand 高速网互联。&lt;/p&gt;&lt;h2&gt;02 存储场景与需求&lt;/h2&gt;&lt;p&gt;云知声初期的建设目标就是要建成一站式的 AI 平台，包含 AI 模型的生产，数据预处理，模型开发，模型训练以及最后模型的上线。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.284375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtodJvgqAxbVfibglcBibibztZUgR2AWgjA9F4QXTYa3y4fic4aI6WqAIqwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;p&gt;如上图所示，&lt;strong&gt;每个步骤都需要跟数据交互，其中数据预处理和模型训练需要比较大的 IO&lt;/strong&gt;。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;• 数据预处理，主要是语音处理会提取语音特征，会把语音特征转成 numpy 格式的文件；图像处理的过程中，会对图像做预处理，做训练数据的格式转换；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 模型开发，主要是算法工程师做代码的编辑，模型算法的调试；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 模型训练，途中会需要做多轮数据读取，以及模型会输出到相应的存储上，这个步骤所需要的 IO 非常大；在模型上线的时候，服务会去读取存储系统中的模型文件。&lt;strong&gt;总结一下我们对存储的需求：&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 能够对接整个模型开发的的全链路，在几个比较核心的功能块中都要能够支持；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 支持 CPU、GPU 的数据读取的任务；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3. 我们的场景主要是语音、文本和图像数据，这些场景的特点是文件大小都比较小，所以要支持小文件场景下的高性能处理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;4. 我们的业务场景主要是读多入写少，模型训练的时候大部分是在读取数据，基本不会写入数据。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;基于以上这些需求点，我们需要一套高性能可靠的分布式存储系统。&lt;/p&gt;&lt;h2&gt;03 云知声存储建设历程&lt;/h2&gt;&lt;p&gt;早期的时候，我们的 GPU 只有十几台左右，当时使用 NFS 做了一个小规模的集群。同时在 2016 年引入了 CephFS 的测试环境，当时那个版本的 CephFS 在小文件场景下性能不太好，所以就没有把 CephFS 带入到生产环境。 &lt;/p&gt;&lt;p&gt;后来我们继续做了调研，发现 Lustre 在 HPC 领域是最为常用的高性能文件系统。测试表明 Lustre 在规模化的构建以及性能方面表现都不错，于是从2017 年到 2022 年，我们全部是用 Lustre 来承载所有的数据业务。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;但是随着使用的 GPU 越来越多，现在有 5.7 亿亿次/秒左右的浮点处理能力，底层存储的 IO 已经跟不上上层计算能力。&lt;/strong&gt;&lt;span&gt;于是，我们开始探索新的存储，为后续的存储扩容做升级，同时在使用 Lustre 的过程中也遇到了一些问题。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一：运维方式&lt;/strong&gt;，Lustre 主要是基于内核的，直接嵌在内核，有时候定位问题会涉及到机器的重启之类的操作；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二：技术栈&lt;/strong&gt;，因为我们的云平台的开发主要是以 golang 为主，所以比较偏向于使用与开发语言比较契合的存储。Lustre 使用的是 C 语言，在定制优化方面需要有较多人力精力。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三：数据的可靠性&lt;/strong&gt;，Lustre 主要依赖硬件可靠性（比如 RAID 技术），软件层面主要是实现元数据节点和对象跟数据节点的 HA 方案。相比这些，我们还是更希望使用三副本或者是纠删码这类更可靠的软件方案。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第四：多级缓存的功能的需求，&lt;/strong&gt;在 2021 年的时候，我们用了 Fluid + Alluxio 来作为 Lustre 的分布式加速，Alluxio 能够较好的为我们的集群做计算提速，减轻底层存储的压力。但是我们一直在探索希望直接从存储系统来进行客户端缓存，这样操作对用户来说能够更加透明一点。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.22265625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtjQ1mHcqqDzqHibVjDF7wU8QQscUicOfbzmC3icJH2nZbzZnjRich2RIfCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;p&gt;在 2021 年的时候 JuiceFS 刚开源时，我们就对它的特性做了调研。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一，产品特性&lt;/strong&gt;：JuiceFS 支持 POSIX 接口，能够以 HostPath 的方式去挂载，这种方式跟我们在使用 NAS 的方式是一模一样的，用户在使用时基本不用做任何改变；JuiceFS 元数据以及对象存储，都有比较多的可选方案，像Redis、 TiKV在AI领域是比较合适的。底层 Ceph、MinIO 还有一些公有云的对象存储用户都可以自行选择。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二，上层调度&lt;/strong&gt;：JuiceFS 除了支持 HostPath，同时也是支持CSI 驱动方式，能够以更加云原生的方式让用户去接入相应的存储。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三，业务框架适配&lt;/strong&gt;：POSIX 接口适配深度学习框架。第四，运维：元数据引擎以及对象存储，业界方案都比较成熟，选择也比较多，而且 JuiceFS 有元数据自动备份以及回收站功能。JuiceFS 与业务比较契合，因此我们进行了 POC 测试。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;562&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;331&quot; data-ratio=&quot;0.428125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dt02AkD1jkOiamsV196xc7OPv61N4dmCt3D6eZXIwnuxZUoIkAhpKfgyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1600&quot;/&gt;&lt;/section&gt;&lt;p&gt;测试环境如上图所示，结果发现 Lustre 跟 JuiceFS 来相比，由于JuiceFS 直接用到了内核页缓存，相比 Lustre 直接访问机械盘，性能有很大提升（如下图所示，越小越好）。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;247&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5885947046843177&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtJb38m2nMryOFACMQDFxYRqeFc804fOdDon5B4lvMENcULZ60icA7u3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;982&quot;/&gt;&lt;/p&gt;&lt;p&gt;经过了 POC 测试，我们决定把JuiceFS 带入生产环境。目前整个Atlas 的集群所有 GPU 的计算节点，以及所有的开发调试节点，都安装了 JuiceFS 客户端。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5082474226804123&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtBk4TG1ib5OCX24lCnyQBpAvb0oaZUE6S7QLYWyalT3IDbPHho5JDvzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;970&quot;/&gt;&lt;/section&gt;&lt;p&gt;JuiceFS 直接对接redis 集群和ceph，计算节点大部分用的 HostPath 方式接入。同时 Atlas 集群也部署了 JuiceFS CSI Driver，用户可以以云原生的方式接入。&lt;/p&gt;&lt;h2&gt;04 JuiceFS 在 Atlas 的使用方式&lt;/h2&gt;&lt;p&gt;为了保证数据的安全性，超算平台上的每个组归属于不同的目录，&lt;strong&gt;每个目录下是各自组内或者部门内的成员，不同组之间的目录是不可见的。&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4774193548387097&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtb2lSqiaSEjo3WC4yHQ0iclkPYXTQlmiagbHLI7jTnhTYgiayhOU8C7NCUA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;/section&gt;&lt;p&gt;目录的权限是基于 Linux 的权限管控机制。用户在 Atlas 集群提交训练任务的时候，集群的任务提交工具会自动读取系统上用户的 UID 与 GID 信息，然后将其注入用户提交的任务 Pod 的 SecurityContext 字段，则 Atlas 集群上运行的容器 Pod 内所有容器的进程运行的 UID 与存储系统上的信息一致，保证权限不越界。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6934306569343066&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dt2tHNWX58UHsG1Jdg6mEdzHQjxavNTZGTicVwebMqjoIvxb9XK32Lq2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1096&quot;/&gt;&lt;/section&gt;&lt;p&gt;节点访问 JuiceFS，实现了多级缓存：&lt;/p&gt;&lt;p&gt;2021 年初的时候，云知声和 JuiceFS 团队一起把 JuiceFSRuntime 集成到 Fluid 上面。因为以裸机的方式去用缓存，我们发现用户对缓存的可见性比较不好，缓存的清理全部是系统自动做的，用户的可控性没那么高，所以才会把 JuiceFS 集成到 Fluid 。&lt;/p&gt;&lt;p&gt;Fluid 会启动 JuiceFS 相关的组件，包括 FUSE 和 Worker Pod。其中 FUSE Pod 提供了 JuiceFS 客户端的缓存能力，Worker Pod 则实现了对缓存生命周期的管理，Atlas 平台的 AI 离线训练任务通过与 FUSE Pod 客户端交互，进行 AI 训练数据的读取。&lt;/p&gt;&lt;p&gt;通过 Fluid 提供的缓存调度能力以及数据集的可观测性，平台的用户可以通过亲和调度将缓存部署在特定的计算节点上，同时用户能够直观的看到缓存的使用情况（例如缓存数据集的大小、缓存的百分比、缓存的容量等）。&lt;/p&gt;&lt;p&gt;具体用法可以参考“&lt;a target=&quot;_blank&quot; href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247486009&amp;amp;idx=1&amp;amp;sn=3b226a7701cc3b3c154cee2ee3dc3602&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;如何在 Kubernetes 集群中玩转 Fluid + JuiceFS&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;如何在 Kubernetes 集群中玩转 Fluid + JuiceFS&lt;/a&gt;”，模&lt;span&gt;型训练时，主要是用 JuiceFS FUSE 客户端去读整个元数据引擎和对象存储的数据。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;05 JuiceFS 的建设实践&lt;/h2&gt;&lt;p&gt;目前 Atlas 不能访问公网，是在专用的隔离网内，因此我们全部都是私有化部署。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.41188524590163933&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtG0HDeARuiamE6JgX3cVHtJyIyB8Uk7ZQGNsLoTTwX6AUn567MdcrhibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;976&quot;/&gt;&lt;/section&gt;&lt;p&gt;我们生产环境的元数据引擎采用 Redis，2020 年的时候，TiKV 对接到 JuiceFS 还不是很成熟，我们计划首先用 Redis 来做过渡，对象存储的是用 Ceph。Redis 节点的系统盘做了 RAID1，同时 Redis 持久化的数据会定期同步到另一台备份节点上。Redis 的数据持久化我们采用 AOF + RDB 的方案，每秒进行一次数据持久化。&lt;/p&gt;&lt;p&gt;对象存储采用自建的 Ceph 集群，Ceph 集群采用 Cephadm 进行部署，目前生产环境用的是 Octopus 版本。我们当时借鉴了很多业界的方案，对存储器在存储器层面做了一些优化，以及在软件层面也做了相应的调优，主要如下：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;服务器层面（参考）：&lt;/strong&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;• 42 Cores 256GB 24*18T HDD&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 系统盘: 2* 960G SAS SSD&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• BlueStore&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 关闭 NUMA&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 升级 kernel: 5.4.146 开启 io_uring&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• Kernel pid max，修改 /proc/sys/kernel/pid_max&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Ceph 配置方面：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;重点提下，要把 Ceph 集群的内核升到比较新的版本，然后开启 io_uring 功能，这样性能会有比较大的提升。在软件方面我们是直接调用了rados 的接口，就不走 S3 协议了，效率会稍微高一点，所有的节点用 100G 的 InfiniBand 高速网络去做互联。&lt;/p&gt;&lt;p&gt;云知声环境中 JuiceFS 对接的对象存储是 Ceph RADOS，JuiceFS 采用 librados 与 Ceph 进行交互，因此需要重新编译 JuiceFS 客户端，建议 librados 的版本要跟 Ceph 的对应，这点要注意一下。如果用 CSI Driver 的时候,在 PV/PVC 的创建，会读取 &lt;code&gt;/etc/ceph/ceph.conf&lt;/code&gt; 也要注意版本的支持。&lt;/p&gt;&lt;h3&gt;完善的监控体系&lt;/h3&gt;&lt;p&gt;现在整个链路比较长了，底层有元数据引擎集群、Ceph 对象存储集群，还有上层的客户端以及业务，每层都要有相应的监控方案。 &lt;/p&gt;&lt;p&gt;客户端节点，我们主要是做日志的收集，需要注意的是各个挂载点 JuiceFS 客户端日志要做汇聚，error 告警，避免日志将系统磁盘打爆或者节点无法写。 &lt;/p&gt;&lt;p&gt;各个 JuiceFS 客户端也要有相应的监控手段，比如查看各挂载点的 .stat 文件和日志观察指标是否正常，然后看看 Redis 跟 Ceph 集群的 IO 与日志，要保证整个链路都是可控的，这样定位问题就比较方便。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.251180358829084&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtMHssIfh7pQ8ZgOU3wBXMDLOUxlcdHe8raZnOehxTDo8F3wrmFekQBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1059&quot;/&gt;&lt;/section&gt;&lt;p&gt;上图是 Ceph 的监控图，因为我们的客户端节点用的是 SSD 的缓存，现在数据基本不会读取到 Ceph，大部分是缓存在读取，所以 Ceph 的流量不大。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2796610169491525&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtGyGHwsWurMlabVSrHSia9OEQSqeCZEDJJNWx1iaycPwU0oFXks0WdJXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot;/&gt;&lt;/section&gt;&lt;p&gt;上图是 JuiceFS 监控上截取的数据，可以看到节点的基本百分百至百分之九十几都能够命中，缓存命中率还是比较高的，大部分数据还是在走缓存的。&lt;/p&gt;&lt;h3&gt;参与JuiceFS 社区建设&lt;/h3&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.34207764952780695&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtw8G8fROUic4D27tSvYvVnYXicvtb0PYMkhjEibGeyD37UgtqFbUdT19rg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;953&quot;/&gt;&lt;/section&gt;&lt;p&gt;云知声在使用 JuiceFS 社区版的过程中，一直积极参与社区建设。在 2021 年和 JuiceData 团队合作开发了上文中提到的 Fluid JuiceFS Runtime。近期， 我们发现社区版基于目录的配额还没有开发，于是在前几个月我们开发了一个版本，对目录的文件数跟文件大小做了限制， PR 目前已经提交，现在也正在跟 JuiceFS 社区一起进行合并的工作。&lt;/p&gt;&lt;h2&gt;06 JuiceFS 在 Atlas 的使用场景与收益&lt;/h2&gt;&lt;p&gt;JuiceFS 客户端多级缓存目前主要应用在我们的文字识别、语音降噪以及语音识别场景。由于 AI 模型训练的数据读取特点是读多写少，我们充分利用 JuiceFS 客户端的缓存带来 IO 读取的加速收益。&lt;/p&gt;&lt;h3&gt;收益一：加速 AI模型训练&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1）语音降噪测试&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;降噪场景模型的测试中使用的是散文件，每个数据都是 wav 格式，小于 100k 的语音小文件，在降噪场景我们测试了数据 dataload 阶段的 I/O 数据，JuiceFS 客户端节点的内存缓存为 512G，在 500h 规模的数据下、以 40 的 batch size 进行测试。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5872781065088757&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dt4qXxCsgbYj990vGVnRlHdMA8WaDodGeBCcribtDA7LdA95MV2GJibLkg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;676&quot;/&gt;&lt;/section&gt;&lt;p&gt;从测试结果来看，单从数据读取效率上，在 wav 小文件方面，JuiceFS 为 6.45 it/s，而 Lustre 为 5.15 it/s，性能提升 25%。JuiceFS 有效加速了我们端到端的模型训练，整体缩短了模型的产出时间。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2）文字识别场景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在文字识别场景中，模型为 CRNN backbone 为 MobileNet v2 ，测试环境如下：&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.38828125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtB0b2bWmJKf8OXeJYYJSNzdGdynu1WcicTbBibBibKiclIzn8oRKL2TJZCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;p&gt;生成了一个 LMDB 的大数据文件，这时候 IO 对带宽的要求比较高，而不是对小文件的性能要求。200G 内存缓存是能支撑整个数据的，所以我们没有走底层的存储，而是直接从客户端读取，整体性能也有比较大的提升。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5841584158415841&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtiaL2YFLCN6ziaqtKU4VFtu1d9iaRszkOEda5SH52Fz4FiaIZ1nbEWy8doA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;606&quot;/&gt;&lt;/section&gt;&lt;p&gt;在这个测试中，主要做了 JuiceFS 跟 Lustre 的速度对比，从实验的结果来看从 Lustre 读每个 batch 耗时 1.5s，从 JuiceFS 读每个 batch 耗时为 1.1s，提升36%。从模型收敛的时间来看，从 Lustre 的 96 小时下降到 JuiceFS 的 86 小时，使用 JuiceFS 能够将 CRNN 模型的产出时间缩短 10 小时。&lt;/p&gt;&lt;h3&gt;模型调试与数据处理&lt;/h3&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6813186813186813&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZn5pE0qAgA4U6UmMIm667dtBHw0J6DSH9llJErXw4vPZd8Swsb4tI5DbDHBESuK1wF83OCNtV2ATA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1092&quot;/&gt;&lt;/section&gt;&lt;p&gt;做代码调试时，多个用户会同时在一台调试机上去运行模型测试，以及代码的遍历，当时统计了大部分用户是会使用一些远程的 IDE，连接到调试节点，然后构建自己的虚拟环境，会把大量的安装包提前安装在Lustre上。&lt;/p&gt;&lt;p&gt;大部分都是几十k 或者几百k 的小文件，要把这些包导入在我们内存上。之前使用 Lustre 时，因为用户太多了所以需求吞吐较高，同时对小文件性能要求比较高，发现效果不是很好，在 import 包时会比较卡，导致代码调试的时候比较慢，整体效率比较低。&lt;/p&gt;&lt;p&gt;后来使用了JuiceFS 客户端的缓存，在第一次编译时也比较慢，但第二次的编译时因为数据已经全部落在缓存上，速度和效率就比较高了，代码跳转也就比较快，代码提示 import 也比较快。用户测试后大概有 2~4 倍的速度提升。&lt;/p&gt;&lt;h2&gt;07 结语&lt;/h2&gt;&lt;h3&gt;从 Lustre 到JuiceFS&lt;/h3&gt;&lt;p&gt;从 2017 年到 2021 的时候，我们用 Lustre 也是比较稳定的，集群存储量少于 50% 的时候，软件的稳定性都是比较高的。&lt;/p&gt;&lt;p&gt;Lustre 作为老牌 HPC 领域的存储系统，为许多全球最大的超算系统提供动力，具有多年的生产环境经验。其具有符合 POSIX 标准、支持各种高性能低时延的网络，允许 RDMA 访问的优点，适用于传统 HPC 领域的高性能计算，跟深度学习的接口是契合的，所有的业务都是不需要做代码修改。但是也有一些缺点：&lt;/p&gt;&lt;p&gt;第一，Lustre 无法支持云原生 CSI Driver。&lt;/p&gt;&lt;p&gt;第二，Lustre 对运维人员的要求比较高，因为全部是以 C 语言写的，有时候出一些 Bug 无法快速解决，整体社区的开放性和活跃度不是很高。&lt;/p&gt;&lt;p&gt;JuiceFS 有这样一些特点：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一，JuiceFS 是一款云原生领域的分布式存储系统产品&lt;/strong&gt;，提供了 CSI Driver 以及 Fluid 等方式使用能够更好地与 Kubernetes 进行结合。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二，JuiceFS 的部署方案比较灵活，元数据引擎可选性高&lt;/strong&gt;，对象存储如果用户网络允许，其实对接到公有云的对象存储会更好。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三，在存储扩容运维方面较为简单&lt;/strong&gt;。完全兼容 POSIX 标准使得深度学习的应用可以无缝迁移，但是由于后端对象存储的特点,使得 JuiceFS 在随机写方面会有较高的延迟。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第四，JuiceFS 支持本地缓存、内核页缓存，实现了冷热数据的分层和加速&lt;/strong&gt;。这一点是我们比较看重的，在我们的业务场景是比较合适的，但是在随机写的时候就不太合适。社区版本目前分布式缓存的功能也还不提供。&lt;/p&gt;&lt;h3&gt;后续规划&lt;/h3&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;• 元数据引擎升级，TiKV 适合在 1 亿以上文件数量（最多可以支撑到百亿级文件），对性能以及数据安全都有较高要求的场景，目前我们已经完成了 TiKV 的内部测试也在积极跟进社区的进展，后续要将元数据引擎迁移到 TiKV。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 目录配额优化，目前已经把基础版本的功能合入到了JuiceFS 社区版本，也跟 JuiceFS 社区进行了讨论，在一些场景上有些性能还需要优化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 希望去做一些 Nonroot 的功能，现在所有的节点都是 root 权限能访问所有的数据，权限太大我们希望只在特定节点去开放 root 的权限。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;• 最后也会去看看社区这边的话是否有 QoS 的方案，比如基于 UID 或者 GID 的限速。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;strong&gt;有任何 JuiceFS 问题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;欢迎加入&lt;/strong&gt;用户群交流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p dir=&quot;ltr&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;153&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;148&quot; data-fileid=&quot;100002283&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/F446RY3QsZnicUqZp3Z8kiaYTeutdibxV6AzEciaNND2C30ZXAicFAW9pXQYFkWJT0bhuJj1ia8qW37XDCAob2RCTdYA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;396&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;合伙人&lt;/span&gt;&lt;span&gt;兼社群助手&lt;/span&gt;&lt;/p&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;p&gt;&lt;span&gt;苏锐全天在线&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;用户案例&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247487472&amp;amp;idx=1&amp;amp;sn=fad1bd5f9c27ecf4db54fe2b0129abdc&amp;amp;chksm=c03d84bef74a0da8aca5b055b93b1c94fb305ac05b14c1939eb3be2f039ed1cd6c3f7647fd80&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍一面数据 Hadoop 上云&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;一面数据 Hadoop 上云&lt;/span&gt;&lt;/a&gt;&lt;span&gt;   &lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247486950&amp;amp;idx=1&amp;amp;sn=08ae30278c08eb17a4ceb5705a8ea8f7&amp;amp;chksm=c03d86a8f74a0fbe060e7addb3eaa56cd6a918bd2fbb61fce8346795d30dc3309867f2334b7e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;AI for Science-深势科技&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;AI for Science-深势科技&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247487472&amp;amp;idx=1&amp;amp;sn=fad1bd5f9c27ecf4db54fe2b0129abdc&amp;amp;chksm=c03d84bef74a0da8aca5b055b93b1c94fb305ac05b14c1939eb3be2f039ed1cd6c3f7647fd80&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot; 理想汽车：从Hadoop到云上&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;span&gt; 理想汽车&lt;/span&gt;：从Hadoop 到云上&lt;/span&gt;&lt;/a&gt;&lt;span&gt;    &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485993&amp;amp;idx=1&amp;amp;sn=99d8bab067233cac450c8c930e89bc4a&amp;amp;chksm=c03d8167f74a08718c282f483fd0fbc886bc515f7159b798fed9ee5270b9a5fc5cae333243b7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;知乎&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;知乎&lt;/a&gt;    &lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485840&amp;amp;idx=1&amp;amp;sn=2b60bb01450ac4f10dcb2915eb1e339a&amp;amp;chksm=c03d82def74a0bc88b35bfc8b3c249a672ea8b5d0b94d6391eaac15ba5c6eb3d5b7f39cff6a6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;在线设计平台：稿定科技&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;在线设计平台：稿定科技&lt;/span&gt;&lt;/a&gt;&lt;span&gt;  &lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247483788&amp;amp;idx=1&amp;amp;sn=58dd2ff44ee8461cf2fe9b142f4e5c3d&amp;amp;chksm=c03d8ac2f74a03d4c7226223272f48493c44a8af022ac9db036f85a0205ed0059f2891af3ad4&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;大搜车 &quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;大搜车 &lt;/span&gt;&lt;/a&gt;&lt;span&gt;   &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247483785&amp;amp;idx=1&amp;amp;sn=058e055ad9883cc55981ef7985595505&amp;amp;chksm=c03d8ac7f74a03d1319780d881c6e02c5ac42883f65c89ebf729529feeb5371c886ff109e4b8&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;环球易购&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;环球易购&lt;/span&gt;&lt;/a&gt;&lt;span&gt;   &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485547&amp;amp;idx=1&amp;amp;sn=07c962144b549d0091e0ac0b39f419b8&amp;amp;chksm=c03d8325f74a0a33feb9012651172152f90a080d620e1478f23b1d7c0f283144db479dac4e67&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;趣头条&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;趣头条&lt;/span&gt;&lt;/a&gt;&lt;span&gt;    &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485830&amp;amp;idx=1&amp;amp;sn=fd0a48ac1f7cd192ebfb91ce98155976&amp;amp;chksm=c03d82c8f74a0bdee80401268107e2f74d68b3737b50a351eebd2c33b4fbee616489036f33c7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot; Shopee&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;Shopee&lt;/span&gt;&lt;/a&gt;  &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247487518&amp;amp;idx=1&amp;amp;sn=4a5034411a8f2aa68537dfcaba9ee9a2&amp;amp;chksm=c03d9b50f74a1246de65cbb2b8166daafd7c10a20b4dd725c416edd424853cb3bbe766eac0b0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;携程冷数据场景&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;携程冷数据场景&lt;/a&gt;&lt;span&gt;    &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247487979&amp;amp;idx=1&amp;amp;sn=202e90f2c9fcdb8ed68c11a0e87102a8&amp;amp;chksm=c03d9aa5f74a13b380be82e2c9a06fbcbb1b31e6bb43c849243f1e13f2600d5b5f3949f88384&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;金山云日志服务&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;金山云日志服务&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;最佳实践&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247487047&amp;amp;idx=1&amp;amp;sn=117b4dee65baf0ae4c27a7c51376533a&amp;amp;chksm=c03d8509f74a0c1fc128b3b0868cca71a271282af311de2365b12b14d7d7d0af34eaa3a9922f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;元数据性能提升40倍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;元数据备份性能提升40倍&lt;/span&gt;&lt;/a&gt;&lt;span&gt; &lt;span&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247487104&amp;amp;idx=1&amp;amp;sn=77fa0a3b58851bc5f95951c0c45b179d&amp;amp;chksm=c03d85cef74a0cd8db91b7d205acf7eb55d70272520b86cd68d1e41d22842dab7b973f646ff3&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;元数据-Redis &quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;元数据-Redis &lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485950&amp;amp;idx=1&amp;amp;sn=942e620176edee9f64bd42c81fd891b8&amp;amp;chksm=c03d82b0f74a0ba6f8afc0f021d44e8ee9d132905d6e6548c64600db50ed099e87acb61e3d20&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;CSI Driver &quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;CSI Driver &lt;/span&gt;&lt;/a&gt;&lt;span&gt;   &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485753&amp;amp;idx=1&amp;amp;sn=ab2e615fbd564879ed7a93260a033723&amp;amp;chksm=c03d8277f74a0b61022a478ab1f5200248f283f2cc17868985623cede0a7d6546ac3e600c341&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;性能分析和调优&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;性能分析和调优&lt;/span&gt;&lt;/a&gt;&lt;span&gt;   &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247484563&amp;amp;idx=1&amp;amp;sn=9e295996afae83e8031bb24ffdf107f7&amp;amp;chksm=c03d8fddf74a06cb2daf308bd5a44398da65e6298da9ad3408f939d0ba9520521361a56eb9ba&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;HDFS数据迁移&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;HDFS数据迁移&lt;/a&gt;  &lt;br/&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247484530&amp;amp;idx=1&amp;amp;sn=d840512b948037bec45fd89cf8418677&amp;amp;chksm=c03d8f3cf74a062ab547f44a8a5bd26ccfebd91c5009098c0d6b9b50a5ae27442c3d8a17d55d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;跨云数据搬迁&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;跨云数据搬迁&lt;/span&gt;&lt;/a&gt;&lt;span&gt;    &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247485465&amp;amp;idx=1&amp;amp;sn=f4fd7f8ef8ecfa56f9315e07ff0b855b&amp;amp;chksm=c03d8357f74a0a41981872a7496cc9ddb7720b8289e04f2cb15bfdfeb051c565f78a854e2a29&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;ClickHouse架构探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;ClickHouse架构探索&lt;/span&gt;&lt;/a&gt;&lt;span&gt;  &lt;br/&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5MjUyNjExMw==&amp;amp;mid=2247483786&amp;amp;idx=1&amp;amp;sn=03e93207369fdd66f426db9b6794f1fa&amp;amp;chksm=c03d8ac4f74a03d2d101af6980b7ef81894a5225476bebb255126d5ad2568bb1114daccd98e9&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;MySQL备份验证性提升10倍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;MySQL备份验证性提升10倍&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;关于Juicedata&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Juicedata，杭州果汁数据科技有限公司是一家企业级存储服务供应商，开发了云原生分布式文件系统 JuiceFS，致力于在大数据时代下，为客户打造安全、高性能、自主可控的存储基础设施及服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2021年，JuiceFS正式在GitHub上开源，已经获得7.1 K star，欢迎开发者加入我们。 &lt;span&gt;（github.com/juicedata/juicefs）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot; data-opacity=&quot;1&quot; data-rotate=&quot;0&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt; JuiceFS 用起来还不错，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点个“在看”  让更多人知道&lt;/span&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-ratio=&quot;1.0377358490566038&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/F446RY3QsZnlSdiaziagqrvTdLvZic4XXGgd01LkbeicgsYqnSjJcurjibBMzAWPZnjtAOThia6JHcSkicIh4XmGRdqtg/640?wx_fmt=gif&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&quot; data-type=&quot;gif&quot; data-w=&quot;53&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>