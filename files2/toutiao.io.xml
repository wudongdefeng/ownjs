<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>31be97703c45fb6d1e27f144dde10c16</guid>
<title>数据同步 Gossip 协议原理与应用场景介绍</title>
<link>https://toutiao.io/k/ofebmur</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;作者：京东物流 冯鸿儒 &lt;/p&gt;

&lt;h1&gt;1 简介&lt;/h1&gt;

&lt;p&gt;Gossip是一种p2p的分布式协议。它的核心是在去中心化结构下，通过将信息部分传递，达到全集群的状态信息传播，传播的时间收敛在O（Log（N））以内，其中N是节点的数量。基于gossip协议，可以构建出状态一致的各种解决方案。&lt;br/&gt;
一些常见的分布式协议如二阶段提交协议和 Raft 算法，你发现它们都需要全部节点或者大多数节点正常运行，才能稳定运行。而Gossip即使只有一个节点可用也能提供服务。&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;1.1 适用场景&lt;/h2&gt;

&lt;p&gt;适用于AP 场景的数据一致性处理：分布式数据库中节点同步数据使用（如Apache Cassandra、Redis Cluster）；&lt;br/&gt;
其他场景如信息扩散、集群成员身份确认、故障探测等（如Consul）。&lt;/p&gt;

&lt;h1&gt;&lt;a href=&quot;&quot;/&gt;1.2 优势&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;  学习成本：实现简单&lt;/li&gt;
&lt;li&gt;  扩展性：允许节点的任意增加和减少，新增节点的状态 最终会与其他节点一致。&lt;/li&gt;
&lt;li&gt;  容错：任意节点的宕机和重启都不会影响 Gossip 消息的传播，具有天然的分布式系统容错特性。可以在一定程度上避免网络分割带来的问题。&lt;/li&gt;
&lt;li&gt;  去中心化：无需中心节点，所有节点都是对等的，任意节点无需知道整个网络状况，只要网络连通，任意节点可把消息散播到全网。&lt;/li&gt;
&lt;li&gt;  性能：指数级一致性收敛。消息会以“一传十的指数级速度”在网络中传播，因此系统状态的不一致可以在很快的时间内收敛到一致。消息传播速度达到了 logN。&lt;br/&gt;
Gossip协议的最大的好处是，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。如Consul管理的集群规模能横向扩展到数千个节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;1.3 劣势&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;  消息延迟：节点随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网；不可避免的造成消息延迟。&lt;/li&gt;
&lt;li&gt;  消息冗余：节点定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤；不可避免的引起同一节点消息多次接收，增加消息处理压力。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;&lt;a href=&quot;&quot;/&gt;2 细节介绍&lt;/h1&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;2.1 传播方式&lt;/h2&gt;

&lt;p&gt;Gossip 协议的消息传播方式主要有两种：Anti-Entropy(反熵传播)和 Rumor-Mongering(谣言传播)。&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;&quot;/&gt;2.1.1 反熵传播&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;  定义：反熵（指消除不同节点中数据的差异，提升节点间数据的相似度，降低熵值）。反熵传播：以固定的概率传播所有的数据，可用来避免因为UDP数据包丢失或者新节点的加入而导致的集群元数据不一致问题。&lt;/li&gt;
&lt;li&gt;  过程：集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性。&lt;/li&gt;
&lt;li&gt;  适用场景：执行反熵时，相关的节点都是已知的，而且节点数量不能太多，如果是一个动态变化或节点数比较多的分布式环境（比如在 DevOps 环境中检测节点故障，并动态维护集群节点状态），这时反熵就不适用了。&lt;/li&gt;
&lt;li&gt;  缺点：消息数量非常庞大，且无限制；通常只用于新加入节点的数据初始化。可以通过引入校验和（Checksum）等机制，降低需要对比的数据量和通讯消息等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d049754043634711a9652f16014171f7%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;&quot;/&gt;2.1.2 谣言传播&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;  定义：当一个节点有了新数据后，这个节点变成活跃状态，并周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据。&lt;/li&gt;
&lt;li&gt;  过程：消息只包含最新 update，谣言消息在某个时间点之后会被标记为 removed，并且不再被传播。&lt;/li&gt;
&lt;li&gt;  当一个新节点A连接到Gossip集群内的某个节点B时，A节点会将自己的信息发送给B节点，然后B节点会在集群中随机选取几个未被传染的节点，向他们广播A节点的信息（首次传染），集群中的其他节点收到A节点的信息后，又会像B节点那样广播A节点的信息给其他未被传染的节点（二次传染）。直至多次传染后，集群所有节点都收到了A节点的信息，同步完成。&lt;/li&gt;
&lt;li&gt;  适用场景：适合动态变化的分布式系统。&lt;/li&gt;
&lt;li&gt;  缺点：系统有一定的概率会不一致，通常用于节点间数据增量同步。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c650cb5033048e09fb19aa7e2132604%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;2.2 通信方式&lt;/h2&gt;

&lt;p&gt;Gossip 协议最终目的是将数据分发到网络中的每一个节点。根据不同的具体应用场景，网络中两个节点之间存在三种通信方式：推送模式、拉取模式、Push/Pull。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;  Push: 节点 A 将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新 A 中比自己新的数据&lt;/li&gt;
&lt;li&gt;  Pull：A 仅将数据 key, version 推送给 B，B 将本地比 A 新的数据（Key, value, version）推送给 A，A 更新本地&lt;/li&gt;
&lt;li&gt;  Push/Pull：与 Pull 类似，只是多了一步，A 再将本地比 B 新的数据推送给 B，B 则更新本地&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果把两个节点数据同步一次定义为一个周期，则在一个周期内，Push 需通信 1 次，Pull 需 2 次，Push/Pull 则需 3 次。虽然消息数增加了，但从效果上来讲，Push/Pull 最好，理论上一个周期内可以使两个节点完全一致。直观上，Push/Pull 的收敛速度也是最快的。&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;2.3 执行示例&lt;/h2&gt;

&lt;h3&gt;&lt;a href=&quot;&quot;/&gt;2.3.1 状态的传播&lt;/h3&gt;

&lt;p&gt;以Gossip协议同步状态的思路类似于流言的传播,如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a05910d0e3e4992b7718ea8882c3b75%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;A节点率先知道了某个流言（msg），它首先将此信息传播到集群中的部分节点（比如相邻的两个节点）B和C，后者再将其传递到它们所选择的“部分”节点，例如B选择了D和E，C选择了将流言传播到B和F。以此类推，最终来自于A的这条流言在3轮交互后被传播到了集群中的所有节点。&lt;br/&gt;
在分布式系统的实践中，这个“流言”可能是：某个节点所感知到的关于其它节点是否宕机的认识；也可能是数据水平拆分的缓存集群中，关于哪些hash桶分布在哪些节点上的信息。每个节点起初只掌握部分状态信息，不断地从其它节点收到gossip信息，每个节点逐渐地掌握到了整个集群的状态信息。因此解决了状态同步的第一个问题：全集状态的获取。&lt;br/&gt;
对于集群中出现的部分网络分割，消息也能通过别的路径传播到整个集群。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8f7d42930fe142119d2519606692b9ef%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;&quot;/&gt;2.3.2 状态的一致&lt;/h3&gt;

&lt;p&gt;状态同步的第二个问题：对于同一条状态信息，不同的节点可能掌握的值不同，也能通过基于gossip通信思路构建的协议包版本得到解决。例如水平拆分的redis缓存集群，初始状态下hash桶在各个节点的分布如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39da9835e9f14c5e87090c23f93edafe%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;此时各个节点预先通过某种协议（比如Gossip）得知了集群的状态全集，此时新加入了节点D，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f62312d5cd34383865390f36bb38206%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;D分担了C的某个hash桶，此时C/D和集群中其它节点就C所拥有哪些hash这件事发生了分歧：A/B认为C目前有6/7/8个hash桶。此时通过为gossip消息体引入版本号，使得关于C的最新状态信息（只有6/7两个桶了）在全集群达到一致。例如B收到来自A和C的gossip消息时会将版本号更新的消息（来自C的v2）更新到自己的本地副本中。&lt;br/&gt;
各个节点的本地副本保存的集群全量状态也可能用来表示各个节点的存活状态。对于部分网络分割的情况如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b973baa269494f09bf5eef6a0bfa0e46%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;例如A和C的网络断开，但A和C本身都正常运行，此时A和C互相无法通信，C会将A标记为不可用状态。对于中心化思路的协议，如果C恰好是中心节点，那么A不可用的信息将会同步到集群的所有节点上，使得这些节点将其实可用的A也标记为宕机。而基于gossip这类去中心化的协议进行接收到消息后的实现逻辑扩展（例如只有当接收到大多数的节点关于A已经宕机的消息时，才更新A的状态），最终保证A不被误判为宕机。&lt;/p&gt;

&lt;h1&gt;&lt;a href=&quot;&quot;/&gt;3 开源软件中的应用&lt;/h1&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;3.1 Fabric&lt;/h2&gt;

&lt;p&gt;Fabric gossip使用push（从成员视图随机选出活跃邻居，给他们转发消息），pull（定期探测，请求遗失的消息）的方式扩散区块。&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;3.2 Cassandra&lt;/h2&gt;

&lt;p&gt;Cassandra使用的是pull-push，这种方式是均等的，会有3次发送，但是发送完以后双方都可以更新彼此的信息。利用pull-push方式，如果A要与B节点同步，需要进行如下图的三个通信阶段。&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;3.3 RedisCluster&lt;/h2&gt;

&lt;p&gt;Redis Cluster 在运行时，每个实例上都会保存 Slot 和实例的对应关系（也就是 Slot 映射表），以及自身的状态信息。新节点加入、节点故障、Slot 变更等事件发生时，实例间也可以通过 gossip协议进行PING、PONG 消息的传递，完成集群状态在每个实例上的同步。&lt;br/&gt;
redisCluster默认组建集群的方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;  通过cluster meet命令将一个节点跟集群中其中一个节点建立连接（此时只能被集群中这一个节点认识）&lt;/li&gt;
&lt;li&gt;  通过Gossip消息转播给其他节点，其他节点收到消息后，再通过类似meet的命令来跟对新节点建立集群连接（需要一定时间的扩散）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;使用gossip算法利用PFAIL和FAIL flags的转换和传播来判定故障&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;&quot;/&gt;3.4 Consul&lt;/h2&gt;

&lt;p&gt;一致性协议采用 Raft 算法,用来保证服务的高可用.&lt;br/&gt;
成员管理和消息广播 采用GOSSIP协议，支持ACL访问控制。&lt;br/&gt;
consul是建立在serf之上的，它提供了一个完整的gossip协议，用在很多地方。Serf提供了成员，故障检测和事件广播。Gossip的节点到节点之间的通信使用了UDP协议。&lt;br/&gt;
Consul的每个Agent会利用Gossip协议互相检查在线状态，本质上是节点之间互Ping，分担了服务器节点的心跳压力。如果有节点掉线，不用服务器节点检查，其他普通节点会发现，然后用Gossip广播给整个集群。&lt;/p&gt;

&lt;h1&gt;&lt;a href=&quot;&quot;/&gt;4 总结&lt;/h1&gt;

&lt;p&gt;gossip协议是很多开源中间件和区块链实现的一种底层通信机制，掌握它的原理和细节能更好的理解中间件和区块链的一些行为和分布式特性。&lt;/p&gt;

&lt;hr/&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>454381e3025eae4cd712139935a02c93</guid>
<title>数字化来了，该如何选择大数据存储？主流架构 MPP 与 Hadoop 的对比</title>
<link>https://toutiao.io/k/9hr5lcz</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    随着云计算、大数据产业的不断发展，传统使用单机数据库进行数据存储的模式已经不能满足业界日益增长需求，海量数据处理成为一个关键问题。目前主流的海量数据处理架构分为两种:1基于传统数据库及数据仓库所衍生出的MPP(Massively Parallel Processing)架构;2 基&lt;/span&gt;&lt;span&gt;于Hadoop 并行计算框架的分布式架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    传统关系型数据库随着数据量增长性能急剧下降，业&lt;/span&gt;&lt;span&gt;界提出一种横向扩展(scale out)方式，通过增加节点使用更多廉价的机器构建更强的集群系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;   在这种背景下，分布式数据库和数据仓库越来越受到重视，其中基于MPP架构的数据库是主流解决方案，越来越多的厂商选择使用它改造和升级原有软件系统。&lt;/span&gt;&lt;span&gt;Hadoop是一种分布式数据处理框架，使用普通 X86 计算机组成分布式系统处理海量数据及进行大数据分析。&lt;/span&gt;&lt;span&gt;Hadoop 架构近年伴随着云计算而兴，其生态系统和大数据紧密联系在一起，不仅仅因为它是开源系统，更主要的是它形成了一个完整的技术生态圈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;   混合架构则综合了MPP 架构和 Hadoop 架构各自特点，通过混合部署将各自的优点充分发挥出来。&lt;/span&gt;&lt;span&gt;将 Hadoop 生态系统与 ETL、Spark 处理引擎一起使用， 结合基于MPP 的海量并行处理数据库(MPP)实现银行综合风险管理系统，具有更好的性能;基于 MPP- Hadoop 混合框架构建一套融合多种不同结构数据的数据集成系统 ，提升了数据查询和加载效率。&lt;/span&gt;&lt;span&gt;同时，混合架构 案例近年得到长足发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   本文对 MPP 和 Hadoop 两种架构进行深入分析，并对 比各自优缺点以及适用范围，给出不同类型应用的技术架 构选型推荐方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 基于 MPP 的数据处理架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    MPP 指处于不同部分的多个处理器对程序进行协同处理的过程，每个处理器使用自己的操作系统、内存、总线 和磁盘等，如图 1 所示。通常 MPP 处理器使用某些消息传 递接口进行通信。在某些实现中，同一应用程序最多可以 使用 200 个或更多处理器，这种结构最大的特点在于共享资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7078313253012049&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zq3UiaicibYdyS1TGInJmpHWjzUfJtUZT4ae8XvkpvkW5TpKkr529iaMQTO5t16xHueZ8XfbXysKic499oHtA3jYEvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1328&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MPP 数据库(MPP DB)基于MPP架构，通过并行化各种操作提高性能，如加载数据、构建索引以及使用并行的 多个 CPU 和磁盘等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     MPP 数据库通常具有无共享架构，因为每个系统都有自己的CPU、内存和磁盘。通过数据库软件和高速互连，系统可以整体运行，并且可通过添加新服务器对集群进行扩展。MPP 数据库通常比托管在大型多处理器服务器上的传统 RDBMS 更灵活，可伸缩且更具成本优势，可提供快速的交互式查询响应，如图 所示。这种架构特征是任务 并 行 执 行 、数 据 分 布 式 存 储( 本 地 化 )、分 布 式 计 算 、资 源 私 有、可横向扩展等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.42158273381294964&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zq3UiaicibYdyS1TGInJmpHWjzUfJtUZT4aicibKuM3aQZxrGPiaiccfmfj5H3BnCrakj7aEnFavTKUwApkvfPlO0tAqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1390&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.1 MPP 数据库集群架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  MPP 数据库集群架构分为以下两种架构&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (1)有专职Master。Master 节点的主要功能是作为系&lt;/span&gt;&lt;span&gt;统访问入口，对存储在系统中的元数据进行管理，以及实 现 SQL Parser，生成执行计划和任务调度等。&lt;/span&gt;&lt;span&gt;Master 有两 个节点，会进行数据同步，在出现故障时可切换。&lt;/span&gt;&lt;span&gt;典型产品有 Greenplum、AsterData、ParAccel、Hawg 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   (2)无专职 Master。Master 节点和数据节点共享一台物理机，先连接上的节点会作为系统的 Master。典型产品 有 Gbase8a、Vertica、Teradata、DB2、Impala 、IBM BigSQL、 HP DragonRed、VerticaVIVE 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1.2 MPP 架构选择 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    两种架构各有优缺点，在超大规模分布式集群中，第2&lt;/span&gt;&lt;span&gt;种架构更有优势，可演变为“多 master”架构(如 Gbase8a 和 Vertica 集群)。&lt;/span&gt;&lt;span&gt;此种架构下，通过 Zookeeper 等分布式一致性软件协调多个master，提供高可用性、透明性以及扩展性，同时数据节点具有对等性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7177914110429447&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zq3UiaicibYdyS1TGInJmpHWjzUfJtUZT4ak3gI4ibYDd0vY1d2XjBpcGsqib8NwOzbBlDZpJYtzpFkFZ3gA8SaOPhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;978&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 基于Hadoop架构的数据处理框架&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.1 Hadoop 数据分块&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   Hadoop 架构与 MPP 架构相似，下图显示 Hadoop 处理&lt;/span&gt;&lt;span&gt;数据过程。&lt;/span&gt;&lt;span&gt;名称服务器（NameNode）充当目录查找服务。&lt;/span&gt;&lt;span&gt;Hadoop 将数据分成任意块，大小一般设为 128Mb，将其复制到至少两个其它节点以实现分布式存储。&lt;/span&gt;&lt;span&gt;小文件(小于128Mb的文 件)完全保存在单个节点上，甚至1G大小的文件也只需要 分布在8个节点(加上副本)上。&lt;/span&gt;&lt;span&gt;因此，Hadoop可处理非常大的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   由于小表格分布在较少服务器上，因此对于 50~100Gb 以下的数据文件不是理想选择。在 Hadoop 上处理小数据集是一个挑战，因为在某些情况下，单个节点上处理数据 完全按顺序运行而不是并行运行。许多 Hadoop集群倾向于使用大量相对较慢且价格便宜的服务器，因此小数据性能可能较差。此外，随着小文件数量增加，名称服务器管理问题会越来越多。经验表明，在大多数中型数据仓库平台(大约 10Tb 的数据)上只有大约 10%的表拥有超过 100Gb 的数据，而 70%的表不足 1Gb 数据。即使两个最大的表超过 1Tb，对于在 Hadoop 上部署也不是很有利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.326271186440678&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zq3UiaicibYdyS1TGInJmpHWjzUfJtUZT4aMAE42lQHwpSdgicN53SLItMc3D7BvqO8ibKJCvvSDXSbICnCYickS4kBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1888&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.2 &lt;/span&gt;Hadoop 集群架构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    Hadoop 处理框架包括 3 个模块:HDFS、MapReduce 和&lt;/span&gt;&lt;span&gt;YARN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5980113636363636&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zq3UiaicibYdyS1TGInJmpHWjzUfJtUZT4aHHT9N1DQ211ibia688w6JqCqBy5dX1CFnEZfTclvT0eWz71qOIAxvEpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1408&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (1)HDFS 是一个分布式文件系统，用于将单个集群扩&lt;/span&gt;&lt;span&gt;展到数百个甚至数千个节点，具有高度的容错能力，部署 在低成本硬件上。&lt;/span&gt;&lt;span&gt;HDFS 提供应用程序高吞吐量数据访 问，适用于具有大数据集的应用程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (2)MapReduce 是一个软件框架，以高可靠性、高容错 方式并行处理大型集群(数千个节点)上的海量数据(多 TB 数据集)。MapReduce作业通常将输入数据集拆分为独立 的块，这些任务以完全并行的方式进行处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (3)YARN:Hadoop 集群资源管理主要依靠资源管理器 (YARN)提供细粒度的资源管理。MapReduce 作业不需要&lt;/span&gt;&lt;span&gt;并行运行所有计算任务，因此可以处理大量的计算任务， 具有可扩展性及支持长寿命容器等功能，但它比 MPP 资源管理器要慢，有时对于并发性管理支持不是很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.3 Hadoop 数据查询&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   Hadoop 的 SQL接口有多种工具供选择，包括 MR/&lt;/span&gt;&lt;span&gt;Tez/Spark 上运行的 Hive、SparkSQL、Impala、HAWQ 或 IBM BigSQL。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   (1)Hive 将 SQL 查询转换为 MR / Tez / Spark 作业并在集群上执行。所有作业均基于相同的 MapReduce 概念 构建，提供良好的集群利用率，以及与其它 Hadoop 堆栈技 术的良好集成。缺点是执行查询延迟大，尤其表连接性能 较低，没有查询优化器(至少目前是这样)，因此即使是最 不合理的查询引擎也会执行操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   (2)SparkSQL 是介于 MapReduce 和 MPP-over-Hadoop 方法之间的一种工具，兼顾两者优点。与 MapReduce 相 似，将工作分解为一组单独计划任务以提供更好的稳定 性。在执行阶段之间进行流式传输数据以加快处理速度， 使用类似 MPP 中的固定执行程序概念减少查询延迟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   (3)混合方案如 Impala 和 HAWQ 类的解决方案，是 Hadoop 之上的 MPP 执行引擎，可处理 HDFS 中存储的数 据。与其它 MPP 引擎一样，可提供更低的延迟和更少的查 询处理时间，但代价是可伸缩性和稳定性较低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 Hadoop 与 MPP 架构选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.1 节点架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (1)底层数据库。MPP 底层运行的是SQL引擎，而&lt;/span&gt;&lt;span&gt;Hadoop 底层处理是 MapReduce 程序。&lt;/span&gt;&lt;span&gt;(2)扩展程度。&lt;/span&gt;&lt;span&gt;MPP虽然支持横向扩展，但一般只支&lt;/span&gt;&lt;span&gt;持扩展到百个节点级别，Hadoop 则可以扩展到千个节点 级别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  基于 Hadoop 框架的数据平台可看作是新一代的分布式数据仓库产品，而 MPP 数据库会应用与大数据类似的解决方案。针对不同使用场景，其发挥的作用和给用户带来的体验也不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;  MPP 和 Hadoop 平台互为补充，分别用于不同场景。MPP 用于高端数据库产品，Hadoop 可部署到普通 X86 集群。MPP和Hadoop底层支持的硬件不同，Hadoop控制机制大多通过 Java 代码实现，而 MPP 产品则通过SQL进行查询。Hadoop 的子项目“Hive”本质上也是通过 MapRe&lt;/span&gt;&lt;span&gt;duce 提供SQL抽象。在许多情况下，与编写 MapReduce 作业相比，SQL 更容易且生产率更高，具有 SQL 技能的数据库专业人员比 Hadoop 专家更多且成本更低。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.2 CAP 理论&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  CAP 定 理(CAP theorem)又 称 布 鲁 尔 定 理(Brewer&#x27;s theorem)，在理论计算机科学中指一个分布式系统最多只 能满足以下 3 个特征中的两个:1一致性(Consistency):同 一时间系统中所有的节点都具有相同的数据值;2可用性&lt;/span&gt;&lt;span&gt;(Availability):系统中即使一个或多个节点发生故障，客户端的任何请求仍将获得响应;3分区容忍性(Partition toler&lt;/span&gt;&lt;span&gt;⁃&lt;/span&gt;&lt;span&gt; ance):即使系统节点之间发生许多通信故障，集群也必继续工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   CAP 理论是 MPP 架构扩展性弱的原因，因为 MPP 数&lt;/span&gt;&lt;span&gt;据库设计仍然以数据查询为主要目的，首先考虑一致性， 其次考虑可用性，最后在可能的情况下考虑分区容忍性。&lt;/span&gt;&lt;span&gt;而 Hadoop 是为并行处理与存储设计的，所以数据均以文 件存储，有限考虑分区容忍性，然后考虑可用性，一致性则 最后考虑，所以可靠性上 Hadoop 要优于 MPP。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.3 数据扩展制约性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (1)高可用。MPP 数据库通过将哈希算法应用于分配&lt;/span&gt;&lt;span&gt;键列值，在数据切片之间确定数据存储的物理机器，而 Ha&lt;/span&gt;&lt;span&gt;⁃&lt;/span&gt;&lt;span&gt; doop 则是通过数据分块实现分布式存储，因而 Hadoop 可 用性更强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (2)并行任务。&lt;/span&gt;&lt;span&gt;虽然 MPP 是根据 Hash 切分数据的，但 是它的任务没有切分，因此任务都会在每个节点上运行一次。&lt;/span&gt;&lt;span&gt;(3)文件系统。&lt;/span&gt;&lt;span&gt;在 MPP 数据库中，虽然数据被切分了，&lt;/span&gt;&lt;span&gt;但文件数量并未减少，每个表在节点上有一个或多个文件。&lt;/span&gt;&lt;span&gt;存储的表越多节点数就越多，导致系统存储过多文 件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (4)网络瓶颈。MPP 数据库大多使用对等节点架构， 对等的点对点连接消耗大量网络宽带，限制系统线性扩 展。Hadoop 使用主从节点架构，在线性扩展上强于 MPP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (5)其它关系数据库限制。关系型数据库中的锁机制、日志系统、权限管理、节点管理等瓶颈均限制 MPP 规模扩大，而 Hadoop 没有使用关系型数据库，并且有专用的分 布式一致性管理软件，因此这些性能要优于 MPP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.4 技术选择&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hadoop 架构数据存储、传统数据仓库、MPP 数据库技&lt;/span&gt;&lt;span&gt;术性能及适用场景对比如表 2 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.588235294117647&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zq3UiaicibYdyS1TGInJmpHWjzUfJtUZT4ae0A7WLSbLMTib6pzUwb2VR7G8GhMiaWmCVFz6l4nLiagZiaImMpXNdTaUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;986&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  因此，Hadoop 和 MPP 两种技术应根据具体业务以及&lt;/span&gt;&lt;span&gt;场景进行选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;  (1)对于半结构化和非结构化数据，Hadoop 在处理上&lt;/span&gt;&lt;span&gt;比 MPP 有一定优势，适合于海量数据批处理类应用，如海 量数据 ETL、非结构化数据分析与挖掘(关键词提取、情感 分析等)。&lt;/span&gt;&lt;span&gt;若系统对非结构化数据存储需求较大且数据量巨大，需要动态扩展数据节点等，则使用 Hadoop 架构更为合适。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (2)MPP 架构更适合对现有关系型数据库和数据仓库 系统进行升级或替换，其在数据查询类业务上比 Hadoop 更具优势，适合处理 SQL 类事务请求、多维度数据分析、展 示数据报表等。若大部分存储数据是结构化数据，数据量不是很大，未来不会爆炸式增长，或业务人员习惯使用 SQL 场景，则可优先考虑使用 MPP 数据库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  (3)MPPDB+Hadoop 混合架构是未来海量数据处理发展趋势。用 MPP 处理 PB 级结构化数据存储与查询，提供 完整的 SQL 与事务支持功能。用 Hadoop 处理半结构化、 非结构化数据，提供灵活的自定义模型与算法开发能力， 同时满足多种数据类型处理需求，并在实时查询与离线分析上都能提供较高性能。但MPP+Hadoop混合架构开发成本及维护成本可能较高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   在数据爆炸时代，传统的数据库架构处理系统已经不 能满足行业需要。本文从理论及应用角度将两种主流的 海量数据处理架构 MPP 和 Hadoop 进行对比，分析各自的 技术特点，论述它们与传统数据处理的优势。通过分析两 大框架底层核心技术，对其优缺点进行了归纳。Hadoop 对 海量半结构化、非结构化数据存储与处理有一定优势，但 在处理速度和易用性上不及 MPP。Hadoop 灵活性较强，企业可根据自身业务特点进行定制开发。MPP优势在海量结构化数据处理、响应性能和衍生工具等方面，适用于查询业务场景较多的项目。随着 Hadoop 生态圈的不断发展，如Hadoop的SQL性能提升、BI工具的不断丰富，MPP 技术发展会向 Hadoop 靠拢。基于MPP与Hadoop框架并结合Spark内存计算、流计算等技术的混合架构平台，会成为大型数据处理项目的理想选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;js_darkmode__bg__0 js_darkmode__0&quot; data-style=&quot;display: inline-block; vertical-align: top; width: 35%; background-position: 50% 50%; background-repeat: no-repeat; background-size: 100%; background-attachment: scroll; background-image: url(&amp;quot;https://mmbiz.qpic.cn/mmbiz_gif/zq3UiaicibYdyRlZaAIDHTmcBlM4FZgibibrJdwBYoRm5SUBJX17RcWtib63q6GNkHDtnVXictSymt2TRGb1fwNe09HZQ/640?wx_fmt=gif&amp;quot;); box-sizing: border-box;&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8638889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zq3UiaicibYdyRlZaAIDHTmcBlM4FZgibibrJjRaG5ZOjVqWOibDMDJ2GndXlgfktG5NXa6DT2GOrDha7n2J7QibaojJw/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section data-style=&quot;padding: 2px; display: inline-block; background-color: rgb(243, 191, 30); box-sizing: border-box;&quot; class=&quot;js_darkmode__1&quot;&gt;&lt;section&gt;&lt;p&gt;数元斋&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;长按识别二维码，私聊我&lt;/p&gt;&lt;p&gt;了解更多数字化咨询与知识！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5490741&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zq3UiaicibYdyRlZaAIDHTmcBlM4FZgibibrJAJeGOXDxpIBVXO0ZTyEBv0abqy05pjUf8qrwoQrMuOXPTZQemMVdKw/640?wx_fmt=jpeg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b47a945456cc6072975951eade90d8ee</guid>
<title>解读 Java 云原生实践中的内存问题</title>
<link>https://toutiao.io/k/23by4f8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-1g0fqss&quot; options=&quot;[object Object]&quot;&gt;&lt;p data-first-child=&quot;&quot; data-pid=&quot;mQseWA1n&quot;&gt;Java 凭借着自身活跃的开源社区和完善的生态优势，在过去的二十几年一直是最受欢迎的编程语言之一。步入云原生时代，蓬勃发展的云原生技术释放云计算红利，推动业务进行云原生化改造，加速企业数字化转型。&lt;/p&gt;&lt;p data-pid=&quot;JLGJot5F&quot;&gt;然而 Java 的云原生转型之路面临着巨大的挑战，Java 的运行机制和云原生特性存在着诸多矛盾。企业借助云原生技术进行深层次成本优化，资源成本管理被上升到前所未有的高度。公有云上资源按量收费，用户对资源用量十分敏感。在内存使用方面，基于 Java 虚拟机的执行机制使得任何 Java 程序都会有固定的基础内存开销，相比 C++/Golang 等原生语言，Java 应用占用的内存巨大，被称为“内存吞噬者”，因此 Java 应用上云更加昂贵。并且应用集成到云上之后系统复杂度增加，普通用户对云上 Java 应用内存没有清晰的认识，不知道如何为应用合理配置内存，出现 OOM 问题时也很难排障，遇到了许多问题。&lt;/p&gt;&lt;p data-pid=&quot;1jCaPpd4&quot;&gt;为什么堆内存未超过 Xmx 却发生了 OOM？怎么理解操作系统和JVM的内存关系？为什么程序占用的内存比 Xmx 大不少，内存都用在哪儿了？为什么线上容器内的程序内存需求更大？本文将 EDAS 用户在 Java 应用云原生化演进实践中遇到的这些问题进行了抽丝剥茧的分析，并给出云原生 Java 应用内存的配置建议。&lt;/p&gt;&lt;h2&gt;背景知识&lt;/h2&gt;&lt;h2&gt;K8s 应用的资源配置&lt;/h2&gt;&lt;p data-pid=&quot;z0646Mci&quot;&gt;云原生架构以 K8s 为基石，应用在 K8s 上部署，以容器组的形态运行。K8s 的资源模型有两个定义，资源请求（request）和资源限制（limit），K8s 保障容器拥有 request数量的资源，但不允许使用超过limit数量的资源。以如下的内存配置为例，容器至少能获得 1024Mi 的内存资源，但不允许超过 4096Mi，一旦内存使用超限，该容器将发生OOM，而后被 K8s 控制器重启。 &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; spec:
  containers:
  - name: edas
    image: alibaba/edas
    resources:
      requests:
        memory: &quot;1024Mi&quot;
      limits:
        memory: &quot;4096Mi&quot;
    command: [&quot;java&quot;, &quot;-jar&quot;, &quot;edas.jar&quot;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;容器 OOM&lt;/h2&gt;&lt;p data-pid=&quot;ZxOhLbM9&quot;&gt;对于容器的 OOM 机制，首先需要来复习一下容器的概念。当我们谈到容器的时候，会说这是一种沙盒技术，容器作为一个沙盒，内部是相对独立的，并且是有边界有大小的。容器内独立的运行环境通过 Linux的Namespace 机制实现，对容器内 PID、Mount、UTS、IPD、Network 等 Namespace 进行了障眼法处理，使得容器内看不到宿主机 Namespace 也看不到其他容器的 Namespace；而所谓容器的边界和大小，是指要对容器使用 CPU、内存、IO 等资源进行约束，不然单个容器占用资源过多可能导致其他容器运行缓慢或者异常。Cgroup 是 Linux 内核提供的一种可以限制单个进程或者多个进程所使用资源的机制，也是实现容器资源约束的核心技术。容器在操作系统看来只不过是一种特殊进程，该进程对资源的使用受 Cgroup 的约束。当进程使用的内存量超过 Cgroup 的限制量，就会被系统 OOM Killer 无情地杀死。&lt;/p&gt;&lt;p data-pid=&quot;vpGrLJgQ&quot;&gt;所以，所谓的容器 OOM，实质是运行在Linux系统上的容器进程发生了 OOM。Cgroup 并不是一种晦涩难懂的技术，Linux 将其实现为了文件系统，这很符合 Unix 一切皆文件的哲学。对于 Cgroup V1 版本，我们可以直接在容器内的 /sys/fs/cgroup/ 目录下查看当前容器的 Cgroup 配置。&lt;/p&gt;&lt;p data-pid=&quot;bthEBA3M&quot;&gt;对于容器内存来说，memory.limit_in_bytes 和 memory.usage_in_bytes 是内存控制组中最重要的两个参数，前者标识了当前容器进程组可使用内存的最大值，后者是当前容器进程组实际使用的内存总和。一般来说，使用值和最大值越接近，OOM 的风险越高。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; # 当前容器内存限制量
$ cat /sys/fs/cgroup/memory/memory.limit_in_bytes
4294967296
# 当前容器内存实际用量
$ cat /sys/fs/cgroup/memory/memory.usage_in_bytes
39215104&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;JVM OOM&lt;/h2&gt;&lt;p data-pid=&quot;blT3oEIn&quot;&gt;说到 OOM，Java 开发者更熟悉的是 JVM OOM，当 JVM 因为没有足够的内存来为对象分配空间并且垃圾回收器也已经没有空间可回收时，将会抛出 java.lang.OutOfMemoryError。按照 JVM 规范，除了程序计数器不会抛出 OOM 外，其他各个内存区域都可能会抛出 OOM。最常见的 JVM OOM 情况有几种：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;E3N1jscr&quot;&gt;java.lang.OutOfMemoryError:Java heap space 堆内存溢出。当堆内存 (Heap Space) 没有足够空间存放新创建的对象时，就会抛出该错误。一般由于内存泄露或者堆的大小设置不当引起。对于内存泄露，需要通过内存监控软件查找程序中的泄露代码，而堆大小可以通过-Xms,-Xmx等参数修改。&lt;/li&gt;&lt;li data-pid=&quot;JZAECE2A&quot;&gt;java.lang.OutOfMemoryError:PermGen space / Metaspace 永久代/元空间溢出。永久代存储对象包括class信息和常量，JDK 1.8 使用 Metaspace 替换了永久代(Permanent Generation)。通常因为加载的 class 数目太多或体积太大，导致抛出该错误。可以通过修改 -XX:MaxPermSize 或者 -XX:MaxMetaspaceSize 启动参数, 调大永久代/元空间大小。&lt;/li&gt;&lt;li data-pid=&quot;zfFfbxC5&quot;&gt;java.lang.OutOfMemoryError:Unable to create new native thread 无法创建新线程。每个 Java 线程都需要占用一定的内存空间, 当 JVM 向底层操作系统请求创建一个新的 native 线程时, 如果没有足够的资源分配就会报此类错误。可能原因是 native 内存不足、线程泄露导致线程数超过操作系统最大线程数 ulimit 限制或是线程数超过 kernel.pid_max。需要根据情况进行资源升配、限制线程池大小、减少线程栈大小等操作。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;为什么堆内存未超过 Xmx 却发生了 OOM？&lt;/h2&gt;&lt;p data-pid=&quot;IWEqeLZk&quot;&gt;相信很多人都遇到过这一场景，在 K8s 部署的 Java 应用经常重启，查看容器退出状态为exit code 137 reason: OOM Killed 各方信息都指向明显的 OOM，然而 JVM 监控数据显示堆内存用量并未超过最大堆内存限制Xmx，并且配置了 OOM 自动 heapdump 参数之后，发生 OOM 时却没有产生 dump 文件。&lt;/p&gt;&lt;p data-pid=&quot;0yxqKr5v&quot;&gt;根据上面的背景知识介绍，容器内的 Java 应用可能会发生两种类型的 OOM 异常，一种是 JVM OOM，一种是容器 OOM。JVM 的 OOM 是 JVM 内存区域空间不足导致的错误，JVM 主动抛出错误并退出进程，通过观测数据可以看到内存用量超限，并且 JVM 会留下相应的错误记录。而容器的 OOM 是系统行为，整个容器进程组使用的内存超过 Cgroup 限制，被系统 OOM Killer 杀死，在系统日志和 K8s 事件中会留下相关记录。&lt;/p&gt;&lt;p data-pid=&quot;VoAXT0TB&quot;&gt;总的来说，Java程序内存使用同时受到来自 JVM 和 Cgroup 的限制，其中 Java 堆内存受限于 Xmx 参数，超限后发生 JVM OOM；整个进程内存受限于容器内存limit值，超限后发生容器 OOM。需要结合观测数据、JVM 错误记录、系统日志和 K8s 事件对 OOM 进行区分、排障，并按需进行配置调整。&lt;/p&gt;&lt;h2&gt;怎么理解操作系统和 JVM 的内存关系？&lt;/h2&gt;&lt;p data-pid=&quot;HPdv3Eq-&quot;&gt;上文说到 Java 容器 OOM 实质是 Java 进程使用的内存超过 Cgroup 限制，被操作系统的 OOM Killer 杀死。那在操作系统的视角里，如何看待 Java 进程的内存？操作系统和 JVM 都有各自的内存模型，二者是如何映射的？对于探究 Java 进程的 OOM 问题，理解 JVM 和操作系统之间的内存关系非常重要。&lt;/p&gt;&lt;p data-pid=&quot;k5i4c17s&quot;&gt;以最常用的 OpenJDK 为例，JVM 本质上是运行在操作系统上的一个 C++ 进程，因此其内存模型也有 Linux 进程的一般特点。Linux 进程的虚拟地址空间分为内核空间和用户空间，用户空间又细分为很多个段，此处选取几个和本文讨论相关度高的几个段，描述 JVM 内存与进程内存的映射关系。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-20e117aefcacf4e97e8e3e8fc1b1c51b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;526&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-20e117aefcacf4e97e8e3e8fc1b1c51b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;526&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-20e117aefcacf4e97e8e3e8fc1b1c51b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-20e117aefcacf4e97e8e3e8fc1b1c51b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li data-pid=&quot;Vl_mvXOV&quot;&gt;代码段。一般指程序代码在内存中的映射，这里特别指出是 JVM 自身的代码，而不是Java代码。&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li data-pid=&quot;-2MlVeMP&quot;&gt;数据段。在程序运行初已经对变量进行初始化的数据，此处是 JVM 自身的数据。&lt;/li&gt;&lt;li data-pid=&quot;E4XzlbDU&quot;&gt;堆空间。运行时堆是 Java 进程和普通进程区别最大的一个内存段。Linux 进程内存模型里的堆是为进程在运行时动态分配的对象提供内存空间，而几乎所有JVM内存模型里的东西，都是 JVM 这个进程在运行时新建出来的对象。而 JVM 内存模型中的 Java 堆，只不过是 JVM 在其进程堆空间上建立的一段逻辑空间。&lt;/li&gt;&lt;li data-pid=&quot;hd2RrW8B&quot;&gt;栈空间。存放进程的运行栈，此处并不是 JVM 内存模型中的线程栈，而是操作系统运行 JVM 本身需要留存的一些运行数据。&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;QeL0jnw_&quot;&gt;如上所述，堆空间作为 Linux 进程内存布局和 JVM 内存布局都有的概念，是最容易混淆也是差别最大的一个概念。Java 堆相较于 Linux 进程的堆，范围更小，是 JVM 在其进程堆空间上建立的一段逻辑空间，而进程堆空间还包含支撑 JVM 虚拟机运行的内存数据，例如 Java 线程堆栈、代码缓存、GC 和编译器数据等。&lt;/p&gt;&lt;h2&gt;为什么程序占用的内存比 Xmx 大不少，内存都用在哪了？&lt;/h2&gt;&lt;p data-pid=&quot;X8zo4HSj&quot;&gt;在 Java 开发者看来，Java 代码运行中开辟的对象都放在 Java 堆中，所以很多人会将 Java 堆内存等同于 Java 进程内存，将 Java 堆内存限制参数Xmx当作进程内存限制参数使用，并且把容器内存限制也设置为 Xmx 一样大小，然后悲催地发现容器被 OOM 了。&lt;/p&gt;&lt;p data-pid=&quot;a-rKN_vF&quot;&gt;实质上除了大家所熟悉的堆内存(Heap)，JVM 还有所谓的非堆内存(Non-Heap)，除去 JVM 管理的内存，还有绕过 JVM 直接开辟的本地内存。Java 进程的内存占用情况可以简略地总结为下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f517b9a3170a0def00e056f3c4b3c1f8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;553&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-f517b9a3170a0def00e056f3c4b3c1f8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;553&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-f517b9a3170a0def00e056f3c4b3c1f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f517b9a3170a0def00e056f3c4b3c1f8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;hy3E_liH&quot;&gt;JDK8 引入了 Native Memory Tracking (NMT)特性，可以追踪 JVM 的内部内存使用。默认情况下，NMT 是关闭状态，使用 JVM 参数开启：-XX:NativeMemoryTracking=[off | summary | detail]&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; $ java -Xms300m -Xmx300m -XX:+UseG1GC -XX:NativeMemoryTracking=summary -jar app.jar&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;JL8ke7CB&quot;&gt;此处限制最大堆内存为 300M，使用 G1 作为 GC 算法，开启 NMT 追踪进程的内存使用情况。&lt;/p&gt;&lt;blockquote data-pid=&quot;yVSAkqiW&quot;&gt;注意：启用 NMT 会导致 5% -10% 的性能开销。&lt;/blockquote&gt;&lt;p data-pid=&quot;_uWh_C4h&quot;&gt;开启 NMT 后，可以使用 jcmd 命令打印 JVM 内存的占用情况。此处仅查看内存摘要信息，设置单位为 MB。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; $ jcmd &amp;lt;pid&amp;gt; VM.native_memory summary scale=MB&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;JVM 总内存&lt;/h2&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Native Memory Tracking:

Total: reserved=1764MB, committed=534MB&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;omdFpYG-&quot;&gt;NMT 报告显示进程当前保留内存为 1764MB，已提交内存为 534MB，远远高于最大堆内存 300M。保留指为进程开辟一段连续的虚拟地址内存，可以理解为进程可能使用的内存量；提交指将虚拟地址与物理内存进行映射，可以理解为进程当前占用的内存量。&lt;/p&gt;&lt;p data-pid=&quot;IH8EKWWb&quot;&gt;需要特别说明的是，NMT 所统计的内存与操作系统统计的内存有所差异，Linux 在分配内存时遵循 lazy allocation 机制，只有在进程真正访问内存页时才将其换入物理内存中，所以使用 top 命令看到的进程物理内存占用量与 NMT 报告中看到的有差别。此处只用 NMT 说明 JVM 视角下内存的占用情况。&lt;/p&gt;&lt;h3&gt;Java Heap&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Java Heap (reserved=300MB, committed=300MB)
    (mmap: reserved=300MB, committed=300MB)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;_ZfjPO3f&quot;&gt;Java 堆内存如设置的一样，实际开辟了 300M 的内存空间。&lt;/p&gt;&lt;h3&gt;Metaspace&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Class (reserved=1078MB, committed=61MB)
      (classes #11183)
      (malloc=2MB #19375) 
      (mmap: reserved=1076MB, committed=60MB)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;jnOMOlrc&quot;&gt;加载的类被存储在 Metaspace，此处元空间加载了 11183 个类，保留了近 1G，提交了 61M。&lt;/p&gt;&lt;p data-pid=&quot;2cRZDmyn&quot;&gt;加载的类越多，使用的元空间就越多。元空间大小受限于-XX:MaxMetaspaceSize（默认无限制）和 -XX:CompressedClassSpaceSize（默认 1G）。&lt;/p&gt;&lt;h3&gt;Thread&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Thread (reserved=60MB, committed=60MB)
       (thread #61)
       (stack: reserved=60MB, committed=60MB)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;Uta4Cqqt&quot;&gt;JVM 线程堆栈也需要占据一定空间。此处 61 个线程占用了 60M 空间，每个线程堆栈默认约为 1M。堆栈大小由 -Xss 参数控制。&lt;/p&gt;&lt;h3&gt;Code Cache&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Code (reserved=250MB, committed=36MB)
     (malloc=6MB #9546) 
     (mmap: reserved=244MB, committed=30MB)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;D074t0x5&quot;&gt;代码缓存区主要用来保存 JIT 即时编译器编译后的代码和 Native 方法，目前缓存了 36M 的代码。代码缓存区可以通过 -XX:ReservedCodeCacheSize 参数进行容量设置。&lt;/p&gt;&lt;h3&gt;GC&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;GC (reserved=47MB, committed=47MB)
   (malloc=4MB #11696) 
   (mmap: reserved=43MB, committed=43MB)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;gtZMyZxx&quot;&gt;GC 垃圾收集器也需要一些内存空间支撑 GC 操作，GC 占用的空间与具体选用的 GC 算法有关，此处的 GC 算法使用了 47M。在其他配置相同的情况下，换用 SerialGC:&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; GC (reserved=1MB, committed=1MB)
   (mmap: reserved=1MB, committed=1MB)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;Xv9JHFPr&quot;&gt;可以看到 SerialGC 算法仅使用 1M 内存。这是因为 SerialGC 是一种简单的串行算法，涉及数据结构简单，计算数据量小，所以内存占用也小。但是简单的 GC 算法可能会带来性能的下降，需要平衡性能和内存表现进行选择。&lt;/p&gt;&lt;h3&gt;Symbol&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; Symbol (reserved=15MB, committed=15MB)
       (malloc=11MB #113566) 
       (arena=3MB #1)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;yYTrf5RO&quot;&gt;JVM 的 Symbol 包含符号表和字符串表，此处占用 15M。&lt;/p&gt;&lt;h2&gt;非 JVM 内存&lt;/h2&gt;&lt;p data-pid=&quot;RlOqdCQk&quot;&gt;NMT 只能统计 JVM 内部的内存情况，还有一部分内存不由JVM管理。除了 JVM 托管的内存之外，程序也可以显式地请求堆外内存 ByteBuffer.allocateDirect，这部分内存受限于 -XX:MaxDirectMemorySize 参数（默认等于-Xmx）。System.loadLibrary 所加载的 JNI 模块也可以不受 JVM 控制地申请堆外内存。综上，其实并没有一个能准确估量 Java 进程内存用量的模型，只能够尽可能多地考虑到各种因素。其中有一些内存区域能通过 JVM 参数进行容量限制，例如代码缓存、元空间等，但有些内存区域不受 JVM 控制，而与具体应用的代码有关。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Total memory = Heap + Code Cache + Metaspace + Thread stacks + 
               Symbol + GC + Direct buffers + JNI + ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;为什么线上容器比本地测试内存需求更大？&lt;/h2&gt;&lt;p data-pid=&quot;CoLUV6vH&quot;&gt;经常有用户反馈，为什么相同的一份代码，在线上容器里跑总是要比本地跑更耗内存，甚至出现 OOM。可能的情况的情况有如下几种：&lt;/p&gt;&lt;h2&gt;没有使用容器感知的 JVM 版本&lt;/h2&gt;&lt;p data-pid=&quot;MlPAv-Vs&quot;&gt;在一般的物理机或虚拟机上，当未设置 -Xmx 参数时，JVM 会从常见位置（例如，Linux 中的 /proc目录下）查找其可以使用的最大内存量，然后按照主机最大内存的 1/4 作为默认的 JVM 最大堆内存量。而早期的 JVM 版本并未对容器进行适配，当运行在容器中时，仍然按照主机内存的 1/4 设置 JVM最 大堆，而一般集群节点的主机内存比本地开发机大得多，容器内的 Java 进程堆空间开得大，自然更耗内存。同时在容器中又受到 Cgroup 资源限制，当容器进程组内存使用量超过 Cgroup 限制时，便会被 OOM。为此，8u191 之后的 OpenJDK 引入了默认开启的 UseContainerSupport 参数，使得容器内的 JVM 能感知容器内存限制，按照 Cgroup 内存限制量的 1/4 设置最大堆内存量。&lt;/p&gt;&lt;h2&gt;线上业务耗费更多内存&lt;/h2&gt;&lt;p data-pid=&quot;5rh42Qvm&quot;&gt;对外提供服务的业务往往会带来更活跃的内存分配动作，比如创建新的对象、开启执行线程，这些操作都需要开辟内存空间，所以线上业务往往耗费更多内存。并且越是流量高峰期，耗费的内存会更多。所以为了保证服务质量，需要依据自身业务流量，对应用内存配置进行相应扩容。&lt;/p&gt;&lt;h2&gt;云原生 Java 应用内存的配置建议&lt;/h2&gt;&lt;ol&gt;&lt;li data-pid=&quot;t9X2UWDV&quot;&gt;使用容器感知的 JDK 版本。对于使用 Cgroup V1 的集群，需要升级至 8u191+、Java 9、Java 10 以及更高版本；对于使用 Cgroup V2 的集群，需要升级至 8u372+ 或 Java 15 及更高版本。&lt;/li&gt;&lt;li data-pid=&quot;QMvh5zC8&quot;&gt;使用 NativeMemoryTracking(NMT) 了解应用的 JVM 内存用量。NMT 能够追踪 JVM 的内存使用情况，在测试阶段可以使用 NMT 了解程序JVM使用内存的大致分布情况，作为内存容量配置的参考依据。JVM 参数 -XX:NativeMemoryTracking 用于启用 NMT，开启 NMT 后，可以使用 jcmd 命令打印 JVM 内存的占用情况。&lt;/li&gt;&lt;li data-pid=&quot;cu8Itdfs&quot;&gt;根据 Java 程序内存使用量设置容器内存 limit。容器 Cgroup 内存限制值来源于对容器设置的内存 limit 值，当容器进程使用的内存量超过 limit，就会发生容器 OOM。为了程序在正常运行或业务波动时发生 OOM，应该按照 Java 进程使用的内存量上浮 20%～30% 设置容器内存 limit。如果初次运行的程序，并不了解其实际内存使用量，可以先设置一个较大的 limit 让程序运行一段时间，按照观测到的进程内存量对容器内存 limit 进行调整。&lt;/li&gt;&lt;li data-pid=&quot;N60wsuPg&quot;&gt;OOM 时自动 dump 内存快照，并为 dump 文件配置持久化存储，比如使用 PVC 挂载到 hostPath、OSS 或 NAS，尽可能保留现场数据，支撑后续的故障排查。&lt;/li&gt;&lt;/ol&gt;&lt;p data-pid=&quot;Hu4IZJ9K&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//click.aliyun.com/m/1000367867/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;原文链接&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;4THH1bJU&quot;&gt;&lt;b&gt;本文为阿里云原创内容，未经允许不得转载。&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>73f655c43dd3763340aa84fb8c9fbcdf</guid>
<title>ChatGPT 真的可以取代基础工作岗位吗？</title>
<link>https://toutiao.io/k/ob4bgj5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;老张的求知思考世界&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;For-Think&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;专注互联网领域相关技术实践和思考，也分享职场成长、读书杂谈等内容。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8a666e009475fddb4d6443d04664c479</guid>
<title>用 Vite + DaisyUI 快速搭建一个前端工程</title>
<link>https://toutiao.io/k/q0qw47z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;


&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;我今天写的这篇文章，就是用来呼应两天前发布的这个&lt;a href=&quot;https://green-tiles.vercel.app/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;项目&lt;/a&gt;的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上个月是我第一次用前端框架写项目，众所周知，前端领域百花齐放，各种框架工具命令行满天飞，虽然本质上都是 JavaScript ，但互不兼容。想去 GitHub 上学习别人的优秀项目，但往往被项目中庞大的文件数量劝退，看起来有很多像是自动生成的文件，但又不敢确定， Readme 中只提到如何编译运行，却不会详细说明这个项目是如何从零开始创建的（可能前端工程师们觉得这些太小儿科了），因此摸索的过程占据了大部分时间，真正的功能实现反而是项目中最简单的一块。作为第一次接触前端项目开发的初学者，我觉得还是有必要简单记录一下自己用 &lt;a href=&quot;https://vitejs.dev/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;Vite&lt;/a&gt; 和 &lt;a href=&quot;https://daisyui.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;DaisyUI &lt;/a&gt;搭建项目框架的整个过程，虽然内容看起来非常初级，但对于一名前端新手来说却是必要的。&lt;/p&gt;
&lt;p&gt;阅读本篇之前，请确保本地已经安装了 &lt;a href=&quot;https://pnpm.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;pnpm&lt;/a&gt; 。&lt;/p&gt;
&lt;h2&gt;用 Vite 初始化项目&lt;/h2&gt;
&lt;p&gt;根据官网的教程，在想要创建项目的路径下执行&lt;/p&gt;

&lt;p&gt;接下来它会弹出一系列选择项，可以根据自己的实际情况选择填写，在这里我把项目命名为 &lt;code&gt;my-vite-project&lt;/code&gt; ，框架使用 &lt;a href=&quot;https://vuejs.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;Vue.js&lt;/a&gt; ，编程语言选择 &lt;a href=&quot;https://www.typescriptlang.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;TypeScript&lt;/a&gt; 。&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-bash&quot; data-lang=&quot;Bash&quot;&gt;&lt;code&gt;✔ Project name: … my-vite-project
✔ Select a framework: › Vue
✔ Select a variant: › TypeScript&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接着进入新建的项目，安装依赖并执行&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-bash&quot; data-lang=&quot;Bash&quot;&gt;&lt;code&gt;cd my-vite-project
pnpm install
pnpm run dev&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在浏览器中打开 &lt;code&gt;http://localhost:5174/&lt;/code&gt; （如果你没有去 &lt;code&gt;vite.config.ts&lt;/code&gt; 改端口的话），将会看到这样的页面&lt;/p&gt;
&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-1024x754.png&quot; alt=&quot;&quot; class=&quot;wp-image-1601 jetpack-lazy-image&quot; data-lazy-srcset=&quot;https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-1024x754.png 1024w, https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-300x221.png 300w, https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-768x565.png 768w, https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_.png 1365w&quot; data-lazy-sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot; data-lazy-src=&quot;https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-1024x754.png?is-pending-load=1&quot; srcset=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot;/&gt;&lt;noscript&gt;&lt;img data-lazy-fallback=&quot;1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-1024x754.png&quot; alt=&quot;&quot; class=&quot;wp-image-1601&quot; srcset=&quot;https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-1024x754.png 1024w, https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-300x221.png 300w, https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_-768x565.png 768w, https://old-panda.com/wp-content/uploads/2023/02/localhost_5174_.png 1365w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;/noscript&gt;&lt;figcaption class=&quot;wp-element-caption&quot;&gt;Vite 默认页面&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;说明项目创建成功，下面可以开始安装 UI 库 DaisyUI 了。&lt;/p&gt;
&lt;h2&gt;安装 UI 库&lt;/h2&gt;
&lt;p&gt;DaisyUI 基于 &lt;a href=&quot;https://tailwindcss.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;Tailwind CSS&lt;/a&gt; 开发，所以首先需要安装 Tailwind CSS 。&lt;/p&gt;
&lt;p&gt;虽然 Tailwind CSS 提供了非常强大的用户交互界面组件，但对于我这样的新手来说过于繁杂，我所希望使用的只是简单的几个组件，有文本，有输入框，有按钮就足够了， DaisyUI 恰好满足了我的需求，又足够简单，文档清晰明了，示例代码可以拿来即用。&lt;/p&gt;
&lt;p&gt;安装之前，先暂停在上一步运行的进程。&lt;/p&gt;
&lt;h3&gt;安装 Tailwind CSS&lt;/h3&gt;
&lt;p&gt;同样根据&lt;a href=&quot;https://tailwindcss.com/docs/guides/vite#vue&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;官网&lt;/a&gt;教程，&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-bash&quot; data-lang=&quot;Bash&quot;&gt;&lt;code&gt;pnpm install -D tailwindcss postcss autoprefixer
pnpx tailwindcss init -p&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后编辑上一步生成的 &lt;code&gt;tailwind.config.cjs&lt;/code&gt; 文件，结果如下&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-js&quot; data-lang=&quot;JavaScript&quot;&gt;&lt;code&gt;/** @type {import(&#x27;tailwindcss&#x27;).Config} */
module.exports = {
  content: [
    &quot;./index.html&quot;,
    &quot;./src/**/*.{vue,js,ts,jsx,tsx}&quot;,
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再把 Tailwind CSS 相关的内容添加到文件 &lt;code&gt;./src/style.css&lt;/code&gt; 中。在这个项目中我准备直接使用 Tailwind CSS 提供的组件，并不打算自己编写 css 代码（其实是不会写），因此文件中原有的内容可以全部删掉，只保留下面三行。&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-css&quot; data-lang=&quot;CSS&quot;&gt;&lt;code&gt;@tailwind base;
@tailwind components;
@tailwind utilities;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;安装 DaisyUI&lt;/h3&gt;
&lt;p&gt;安装 DaisyUI 就非常简单了，&lt;a href=&quot;https://daisyui.com/docs/install/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;官网&lt;/a&gt;上只有两步，为了阅读本文时不需要在各个页面之间来回跳转，我在这里复述一遍。&lt;/p&gt;
&lt;p&gt;首先安装依赖本身，&lt;/p&gt;

&lt;p&gt;然后在 Tailwind CSS 的配置文件 &lt;code&gt;tailwind.config.cjs&lt;/code&gt; 中声明使用 DaisyUI 。&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-js&quot; data-lang=&quot;JavaScript&quot;&gt;&lt;code&gt;module.exports = {
  //...
  plugins: [require(&quot;daisyui&quot;)],
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;至此，所有的前置准备步骤已经完成。&lt;/p&gt;
&lt;h2&gt;验证&lt;/h2&gt;
&lt;p&gt;重新运行项目&lt;/p&gt;

&lt;p&gt;这样我们在文件中的每个修改都可是实时地反映到页面上。&lt;/p&gt;
&lt;p&gt;下面从 DaisyUI 官网上拿一些组件过来试试，编辑文件 &lt;code&gt;./src/App.vue&lt;/code&gt; ，&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-html&quot; data-lang=&quot;HTML&quot;&gt;&lt;code&gt;&amp;lt;script setup lang=&quot;ts&quot;&amp;gt;
import HelloWorld from &#x27;./components/HelloWorld.vue&#x27;
&amp;lt;/script&amp;gt;

&amp;lt;template&amp;gt;
  &amp;lt;HelloWorld msg=&quot;Hello world!&quot; /&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后编辑 HelloWorld 组件文件 &lt;code&gt;./src/components/HelloWorld.vue&lt;/code&gt; ，添加 &lt;a href=&quot;https://daisyui.com/components/card/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;&quot;&gt;Card&lt;/a&gt; 组件，并稍加修改，&lt;/p&gt;
&lt;div class=&quot;hcb_wrap&quot;&gt;&lt;pre class=&quot;prism line-numbers lang-html&quot; data-lang=&quot;HTML&quot;&gt;&lt;code&gt;&amp;lt;script setup lang=&quot;ts&quot;&amp;gt;
import { ref } from &#x27;vue&#x27;

defineProps&amp;lt;{ msg: string }&amp;gt;()

const count = ref(0)
&amp;lt;/script&amp;gt;

&amp;lt;template&amp;gt;
  &amp;lt;div class=&quot;card w-1/3 bg-base-100 shadow-xl&quot;&amp;gt;
    &amp;lt;figure&amp;gt;&amp;lt;img src=&quot;https://evercam.com/wp-content/uploads/sites/11/2019/11/big-red-button.jpg&quot; alt=&quot;Red Button&quot; /&amp;gt;
    &amp;lt;/figure&amp;gt;
    &amp;lt;div class=&quot;card-body&quot;&amp;gt;
      &amp;lt;h2 class=&quot;card-title&quot;&amp;gt;{{ msg }}&amp;lt;/h2&amp;gt;
      &amp;lt;p&amp;gt;This is a magic button showing how many clicks on it&amp;lt;/p&amp;gt;
      &amp;lt;div class=&quot;card-actions justify-end&quot;&amp;gt;
        &amp;lt;button class=&quot;btn btn-primary&quot; @click=&quot;count++&quot;&amp;gt;count is {{ count }}&amp;lt;/button&amp;gt;
      &amp;lt;/div&amp;gt;
    &amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;回到地址 &lt;code&gt;http://localhost:5174/&lt;/code&gt; ，不出意外应该可以看到一个大大的按钮图片，下方配有简单的文字，每点一次按钮，数字就会加一。&lt;/p&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;
&lt;figure class=&quot;aligncenter size-full&quot;&gt;&lt;img decoding=&quot;async&quot; src=&quot;https://old-panda.com/wp-content/uploads/2023/02/image.png&quot; alt=&quot;&quot; class=&quot;wp-image-1609 jetpack-lazy-image&quot; data-lazy-srcset=&quot;https://old-panda.com/wp-content/uploads/2023/02/image.png 643w, https://old-panda.com/wp-content/uploads/2023/02/image-300x295.png 300w&quot; data-lazy-sizes=&quot;(max-width: 643px) 100vw, 643px&quot; data-lazy-src=&quot;https://old-panda.com/wp-content/uploads/2023/02/image.png?is-pending-load=1&quot; srcset=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot;/&gt;&lt;noscript&gt;&lt;img data-lazy-fallback=&quot;1&quot; decoding=&quot;async&quot; loading=&quot;lazy&quot; src=&quot;https://old-panda.com/wp-content/uploads/2023/02/image.png&quot; alt=&quot;&quot; class=&quot;wp-image-1609&quot; srcset=&quot;https://old-panda.com/wp-content/uploads/2023/02/image.png 643w, https://old-panda.com/wp-content/uploads/2023/02/image-300x295.png 300w&quot; sizes=&quot;(max-width: 643px) 100vw, 643px&quot;/&gt;&lt;/noscript&gt;&lt;figcaption class=&quot;wp-element-caption&quot;&gt;Card Demo&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;p&gt;大功告成！可以开始编写自己的业务代码了。&lt;/p&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;

&lt;p id=&quot;jp-relatedposts&quot; class=&quot;jp-relatedposts&quot;&gt;
&lt;/p&gt; &lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>