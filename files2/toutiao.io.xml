<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>b66e9d8e885072593aafe45f0a5b4b9e</guid>
<title>京东到家埋点治理实践</title>
<link>https://toutiao.io/k/2y51ec7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&quot; id=&quot;js_content&quot;&gt;&lt;p&gt;&lt;strong&gt;导读：&lt;/strong&gt;京东到家作为行业领先的即时零售电商平台，又是数据驱动型的公司，埋点的价值日益重要，埋点的可用性、准确率也成了一直在攻克的难题。本文主要讲解京东到家在治理埋点数据、提高埋点数据质量工作中的一些实践经验。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;目录：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一 什么是埋点&lt;/p&gt;&lt;p&gt;二 为什么要治理埋点&lt;/p&gt;&lt;p&gt;三 如何治理埋点&lt;/p&gt;&lt;p&gt;     3.1 建立统一的埋点流程&lt;/p&gt;&lt;p&gt;     3.2 建立完善的埋点规范&lt;/p&gt;&lt;p&gt;     3.3 建立完善的质量规范&lt;/p&gt;&lt;p&gt;     3.4 优化埋点平台&lt;/p&gt;&lt;p&gt;四 埋点治理收益&lt;/p&gt;&lt;p&gt;五 总结与展望&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;一 什么是埋点？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3261538461538461&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alRnDm6XJyolwXvsyTr4bfJViciccLdvAwXRPKeibWGICexdNF7rc7wtQWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1300&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;埋点数据可以为后续的优化和运营策略提供数据支撑。&lt;/span&gt;&lt;span&gt;在京东到家最常见的埋点场景是在商品，例如在商品“曝光”、“点击”、“加车”、“结算”、“提单”这五种行为上做埋点，形成数据漏斗来了解商品、商家、品牌的售卖情况，进而了解用户更喜欢购买哪类商品、哪些商家或者哪个品牌。&lt;/span&gt;&lt;span&gt;很明显，如果某个商品用户不喜欢购买，相应的加车会比较少，如果某个商品被多次加购，说明用户喜欢购买这个商品，这样可以评估哪种品类更受欢迎，给后续的用户体验优化做一些数据支撑。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;二 为什么要治理埋点&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;section&gt;埋点是数据的来源，通过大数据处理、数据统计、数据分析、数据挖掘等加工处理，可以得到衡量产品状态的一些基本指标，从而洞察产品的状态。&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2323462414578588&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0aldLh98KqiaLTXWvJWBs0rMwUgpUhgnujrib3WZ7F93HicC0TDNAP3qvhGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;878&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;京东到家历史的埋点是可以满足一些常规的数据分析的，但随着业务的发展，历史埋点方案的弊端也就逐渐体现出来了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;流程规划缺失：&lt;/strong&gt;没有统一的流程规范，关键节点缺失，埋点上线难；&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设计规范缺失：&lt;/strong&gt;埋点上报时机不一致、同样的业务组件上报的内容不一致、数据差异性高；&lt;/p&gt;&lt;section&gt;&lt;strong&gt;开发不规范：&lt;/strong&gt;各端的技术方案不统一、扩展性较差；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;质量保障难：&lt;/strong&gt;缺少质量标准，埋点错误数据非常多，数据信任度比较低；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;冗余埋点严重：&lt;/strong&gt;无用埋点很多，造成资源浪费，维护成本也高；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;埋点使用困难：&lt;/strong&gt;各业务各端不同的规范，以及大量的脏数据，导致数据分析不能用同一种规则去解析，跨业务打通也比较困难。&lt;/section&gt;&lt;section&gt;要解决上述问题，就需要进行埋点治理，提高埋点质量。首先要建立统一的埋点流程，使得产品、研发、测试、数据团队都按照这个规范进行执行落地。其次要建立统一的埋点规范，将历史埋点进行梳理，结合数据团队的使用情况，无用的埋点给予下线，节省资源消耗和降低维护成本，错误的或者不完善的埋点升级成新规范的埋点，节省研发开发的成本以及数据同学提取数据的成本。最后约定质量规范，提高埋点数据质量，从而提高整体效率。&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;三 如何治理埋点&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;section&gt;京东到家一共有5个平台包括android、ios、rn、h5、wechat_app，为了确保埋点治理能够被很好的推进，就需要数据产品制定统一的埋点流程和规范，使整个规划可以顺利的进行落地。&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 建立统一的埋点流程&lt;span/&gt;&lt;/h3&gt;&lt;section&gt;京东到家目前包括跟版和非跟版需求，不管什么类型的需求，埋点涉及到的团队几乎都是一样的。埋点体系上涉及到的团队非常多，不止涉及到数据产品一个团队，一般埋点体系涉及到的人员有：业务方（常说的需求方、市场运营团队），产品（专指前端产品），数据产品（负责埋点需求和全流程），开发（埋点开发人员），测试（埋点数据测试），数仓（解析埋点并规范落库），数据分析师（使用埋点数据进行取数或分析）。每一环又都不可或缺，任何一个环节出现问题，都会导致埋点数据不准确。统一和规范了埋点治理流程是实现埋点治理的关键的一步，也是埋点整体治理体系的第一步。&lt;/section&gt;&lt;section&gt;埋点治理新流程，如图：&lt;br/&gt;&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8183361629881154&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alfcEnnnwzDIcia2u43rrYxzdLhvKlAbN41krLac8gq74VKopgS8aYAzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1178&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;经过几个版本的需求迭代，我们发现埋点治理新流程有如下&lt;/span&gt;&lt;strong&gt;优势：&lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;1）&lt;strong&gt;提升了设计质量&lt;/strong&gt;：数据产品对业务更加了解，设计埋点的效率提升了50%，同时埋点设计考虑更加全面，比如全归因、推荐场景等；&lt;/p&gt;&lt;p&gt;2）&lt;strong&gt;埋点支持扩展、复用&lt;/strong&gt;：比如商品组件，节省研发以及测试成本，无需重复开发；&lt;/p&gt;&lt;p&gt;3）&lt;strong&gt;埋点需求口径一致&lt;/strong&gt;：节省了数据分析30%的人力成本。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 建立完善的埋点规范&lt;span/&gt;&lt;/h3&gt;&lt;section&gt;埋点体系上涉及到的团队非常多，为了能够使上述流程可以很好地进行下去，就需要对有关团队制定规范并执行落地。&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3.2.1 产品提需规范&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;随着项目的增多，数据埋点&lt;span&gt;并行&lt;/span&gt;上报、量级会对负载能力以及存储能力造成一定的影响，尤其是大促期间，海量的数据会导致埋点的入库&lt;span&gt;延迟&lt;/span&gt;，同时也会提高存储设备、服务器、带宽等固定成本，故需要我们在埋点接收环节对埋点进行一定的管控，比如：需求是否合理、是否有遗漏、参数是否完善等；还需要统计每个环节使用的人力成本，统计埋点去向以及分析产生的业务价值。&lt;/section&gt;&lt;section&gt;为了使&lt;span&gt;数据产品、研发、测试、数据团队可以对埋点的口径达成统一，我们要求&lt;/span&gt;所有的需求都需要通过前端产品在埋点管理平台进行需求提报,包括填写页面、版本、需求名称、需求描述、前置路径、关键参数以及上传对应UI图（标记埋点位置）等。&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5145493257629524&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0aldAKGdASHLcyG2tldEQ6iapUH123pmSqSs9F3dKDSltRHpXJ7X9p0fBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2818&quot;/&gt;&lt;/figure&gt;&lt;section&gt;&lt;strong&gt;3.2.2 数据设计规范&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;我们对历史埋点进行梳理，从中归纳了四大类型，包括ep精准曝光、浏览、点击、api接口下发：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ep精准曝光：&lt;/strong&gt;资源位露出并且达到一定条件的时候，在同一接口ID下，组合够一定的条数进行上报。&lt;/p&gt;&lt;section&gt;支持配置有效曝光的条件，无需发版：&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;section&gt;&lt;span&gt;&quot;epDuration&quot;&lt;/span&gt;:1，&lt;span&gt;&quot;epPercent&quot;&lt;/span&gt;:0.5&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;资源位：一般由网关下发userAction给前端，主要下发资源位spm_id，
拼接规则：&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;section&gt;res_type|unit_index|res_unit|tpl|index|res_name|sub_page&lt;br/&gt;&lt;br/&gt;res_type---资源位类型&lt;br/&gt;unit_index---实际楼层&lt;br/&gt;res_unit---实际房间号&lt;br/&gt;tpl----资源位样式&lt;br/&gt;index---cms配置的楼层&lt;br/&gt;res_name---资源位名称&lt;br/&gt;sub_page---资源位所属父级tab&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;采用资源位的方式，是一旦参数有所变化，是不需要前端发版就可以随时上线的，缩短了数据周期。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;浏览：&lt;/strong&gt;在页面有点击行为且有落地页承接的需要处理成PV埋点，&lt;/section&gt;&lt;section&gt;PV四要素：上一页面名称、当前页面名称、当前页面参数、上一页面资源位参数。&lt;/section&gt;&lt;section&gt;页面有进入和返回，进入的时候携带上一页的资源位信息、页面信息、接口信息，返回的时候增加一个字段进行区分&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;p&gt;示例：&lt;br/&gt;正向触发：&lt;br/&gt;pv参数{&lt;br/&gt;当前页面参数，&lt;br/&gt;ref_par{&lt;br/&gt;来源页相关参数&lt;br/&gt;}}&lt;br/&gt;----------------------------------&lt;br/&gt;逆向触发：&lt;br/&gt;pv参数{&lt;br/&gt;当前页面参数，&lt;br/&gt;ret_Type:back&lt;br/&gt;}}&lt;/p&gt;&lt;/pre&gt;&lt;section&gt;&lt;strong&gt;点击：&lt;/strong&gt; 点击某一个可点区域或者按钮（非跳页）时进行上报，&lt;/section&gt;&lt;section&gt;点击信息主要包括上一页面名称、当前页面名称、点击名称、点击参数。&lt;/section&gt;&lt;section&gt;在场景上主要分为以下6类，包括&lt;/section&gt;&lt;section&gt;1）点击：clickXX&lt;/section&gt;&lt;section&gt;2）点击选中：selectXX&lt;/section&gt;&lt;section&gt;3）点击唤起弹层：showXXLayer&lt;/section&gt;&lt;section&gt;4）点击进入某个地方:goXX&lt;/section&gt;&lt;section&gt;5）用点击模拟曝光：epLayerOpen&lt;/section&gt;&lt;section&gt;6）用点击代替查询结果：getXXResult&lt;/section&gt;&lt;section&gt;大家通过名称就可以知道埋点是用来做什么的，以及具体的功能场景是如何的，代入感比较强。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;api接口下发：&lt;/strong&gt;没有资源位且不需要精准曝光的，只是评估某个功能好坏的采用api，即接口下发数据就上报，主要包括接口名称、接口中对应功能的信息字段。&lt;/section&gt;&lt;section&gt;api的埋点命名采用接口信息，是为了方便大家口径保持一致，精准定位问题。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;除了以上四种类型，同时各端各业务还需从以下六个方向在全局上保持统一：&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;公参提取：&lt;/strong&gt; 针对不同的类型制定了不同的公参，包括必须上报以及选择上报的公参，同时还设置了可扩展参数，用于后续公参的补充；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;上报时机：&lt;/strong&gt; 是点击上报还是调用接口上报，避免各端各业务有不一样的上报时机；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;组件化&lt;/strong&gt;：相同业务特性，进行组件抽取，相同设计进行复用，比如点击优惠券“click_coupon”，所有页面点击命名一致，通过页面、资源位信息以及优惠券ID来识别具体的优惠券；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;事件命名&lt;/strong&gt;：各端各页面相同业务，采用同样的埋点方式以及埋点命名，比如“加车、结算、提单、支付”等；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;字段&lt;/strong&gt;：各端各页面相同业务所涉及到字段采用同样的，比如商品ID、门店ID等。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;事件串联&lt;/strong&gt;：整体通过页面ID（pageId--唯一ID，产生一条进入pv就生成一次，返回pv与进入保持一致）、接口ID（traceId---唯一ID，识别具体哪次请求产生的埋点）、资源位信息进行精细化地串联，实现前后路径的一对一衔接。&lt;/section&gt;&lt;p&gt;&lt;strong&gt;3.2.3 研发落地规范&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;埋点接入&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.16106604866743918&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alKhDOsT6mKgnWANK4441guhfKgmTbQxSEbKSAbe6gZW6kj4zKtZzEtA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1726&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;埋点开发&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;严格按照数据产品方案落地，包括上报时机和技术规则；&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.43257261410788383&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alYAXYQL2W2aYd2ZtwHBrTrvZf9oibaY6MQokxpAVCow066djcic2WZnzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1928&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;埋点组件化&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;根据不同类型的埋点制作成标准埋点组件，比如“加减车组件”，&lt;/span&gt;&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6685714285714286&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0allZJxwm3qQBibaNKukiaGVqKZmke3SbPP82BHjcUbm0P807koVXs3No6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/figure&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;private void addCart(View v) {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (entity == null || context==null || (context instanceof Activity) &amp;amp;&amp;amp; ((Activity) context).isFinishing()) {&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (entity.getIconType() == 1) {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (isAllCart(params)) {&lt;br/&gt;                //全局购物车spu加车&lt;br/&gt;                addCartSpu(v);&lt;br/&gt;            } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;                //mini购物车spu加车&lt;br/&gt;                &lt;span&gt;if&lt;/span&gt; (context != null &amp;amp;&amp;amp; params != null) {&lt;br/&gt;                    String userAction;&lt;br/&gt;                    &lt;span&gt;if&lt;/span&gt; (!TextUtils.isEmpty(entity.getUserActionSku())) {&lt;br/&gt;                        userAction = entity.getUserActionSku();&lt;br/&gt;                    } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;                        userAction = entity.getUserAction();&lt;br/&gt;                    }&lt;br/&gt;                    DataPointUtil.addRefPar(DataPointUtil.transToActivity(context), pageName, &lt;span&gt;&quot;userAction&quot;&lt;/span&gt;, userAction, &lt;span&gt;&quot;traceId&quot;&lt;/span&gt;, traceId);&lt;br/&gt;                    new SpuSelectDialog(context, params).showDialog();&lt;br/&gt;                }&lt;br/&gt;            }&lt;br/&gt;            //加车监听spu&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (onClickAddListener != null) {&lt;br/&gt;                onClickAddListener.onClickSpu(v);&lt;br/&gt;            }&lt;br/&gt;        } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;            //mini购物车sku加车&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (isMiniCart(params)) {&lt;br/&gt;                addMiniCartSku(v, params);&lt;br/&gt;            } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (isAllCart(params)) {&lt;br/&gt;                //全局购物车sku加车&lt;br/&gt;                addCartSku(v, (OnSpuAdapterParams) params);&lt;br/&gt;            }&lt;br/&gt;            //加车监听sku&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (onClickAddListener != null) {&lt;br/&gt;                onClickAddListener.onClickSku(v);&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;        //sku加车埋点&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (params != null &amp;amp;&amp;amp; params.getPointData() != null) {&lt;br/&gt;            pointData.put(&lt;span&gt;&quot;storeId&quot;&lt;/span&gt;, entity.getStoreId());&lt;br/&gt;            pointData.put(&lt;span&gt;&quot;skuId&quot;&lt;/span&gt;, entity.getSkuId());&lt;br/&gt;            pointData.put(&lt;span&gt;&quot;spuId&quot;&lt;/span&gt;, entity.getSpuId());&lt;br/&gt;            pointData.put(&lt;span&gt;&quot;traceId&quot;&lt;/span&gt;, traceId);&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (pointData.get(&lt;span&gt;&quot;userAction&quot;&lt;/span&gt;) == null) {&lt;br/&gt;                &lt;span&gt;if&lt;/span&gt; (!TextUtils.isEmpty(entity.getUserActionSku())) {&lt;br/&gt;                    pointData.put(&lt;span&gt;&quot;userAction&quot;&lt;/span&gt;, entity.getUserActionSku());&lt;br/&gt;                } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;                    pointData.put(&lt;span&gt;&quot;userAction&quot;&lt;/span&gt;, entity.getUserAction());&lt;br/&gt;                }&lt;br/&gt;            }&lt;br/&gt;            DataPointUtil.addClick(DataPointUtil.transToActivity(context), pageName, &lt;span&gt;&quot;click_add&quot;&lt;/span&gt;, pointData);&lt;br/&gt;        }&lt;br/&gt;    }&lt;/p&gt;&lt;/pre&gt;&lt;section&gt;&lt;strong&gt;埋点自测&lt;/strong&gt;：通过埋点管理平台研发自测设置为必填项，来限制研发必须进行自测，才可以流转到测试团队。&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6462167689161554&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alC2z13PycDG6kG6COIe7CG2HGrvM4Q8bz0DHXibc78I1ePtwoppGuwhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1956&quot;/&gt;&lt;/figure&gt;&lt;section&gt;&lt;strong&gt;埋点下线&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;禁止在没有业务需求下，下线任意埋点，下线埋点均需经过数据产品审核。&lt;/span&gt;&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14338919925512103&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alxrWBpCbURXzfEZhUebUAz4k8fXcwV3Dicg9CibD8AT1Kv1B74qSWbxZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2148&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3 建立完善的质量规范&lt;span/&gt;&lt;/h3&gt;&lt;section&gt;为确保埋点的质量就要做到上线前的测试以及上线后灰度期间的验收。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.40902021772939345&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alibG51OYxic5Ebp8p25ZMyedPcbBExXsrianmtreZ7LictBTAvqobfGXGQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1286&quot;/&gt;&lt;/p&gt;&lt;section&gt;埋点测试范围包含各点击、ep精准曝光、浏览、api接口下发，埋点参数信息，以及由埋点SDK获取的各类字段：&lt;/section&gt;&lt;section&gt;1）埋点上报时机；&lt;/section&gt;&lt;section&gt;2）埋点上报参数；&lt;/section&gt;&lt;section&gt;3）埋点上报场景；&lt;/section&gt;&lt;section&gt;4）埋点是否重复上报；&lt;/section&gt;&lt;section&gt;5）埋点上报是否出现多余的埋点；&lt;/section&gt;&lt;section&gt;6）埋点上报是否有空数组。&lt;/section&gt;&lt;section&gt;埋点验收主要为上线后灰度期间的数据验收，主要是运用简易数据报表验证埋点数据是否适合逻辑上报、量级上是否满足，前后关联是否满足，是否可实现逻辑上的串联。&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6852941176470588&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alPiaria60lB2AMWzxZMQF8MwPUvthRGlJOd3elhTy0YEKpLRT5nyQMwJw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2040&quot;/&gt;&lt;/figure&gt;&lt;section&gt;&lt;span&gt;3.4 优化埋点平台&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;数据分析对于埋点的口径、上报时机、用途不是很清晰，为了提升双方的沟通效率，在埋点质量平台增加了“页面大全、资源位大全以及埋点大全”，数据团队可以清楚地了解埋点的动态。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5117773019271948&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alnZEQc1gMhkWt7Wc6ic7p2e9OibkxibPIr2rmrD6eaEcNsn6RDHheIoVBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2802&quot;/&gt;&lt;/p&gt;&lt;section&gt;同时通过“数据治理平台”也可以查看各页面的基础信息，包括访问量、用户数等。&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5644916540212443&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0alAxYpZTCb8khwDk5V0CW7hvHGPYW3mAVfrMeKSg9Rt0HRcreQMpgRnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2636&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;四 埋点治理收益&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;section&gt;京东到家目前的埋点准确率已经平均达到了96.5%，在搜推比较精细化的场景下甚至达到了99%以上，比治理之前有了巨大的提升。来来推业务、京明管家业务、B端业务也都复用了目前京东到家业务的整套治理方案。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5214050493962679&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJUjNJmBDhDxvlaWjzUibu0aldUsjRbMrQsia52KNcveeMiby57uYjmsu0ibVJqwteianjJic06ZBJyBYNXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1822&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;五 总结与展望&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p&gt;随着京东到家用户的逐渐壮大和新项目的启动，业务越来越复杂，埋点的数据质量必须得到保障，我们不得不考虑埋点的种种隐患，做到未雨绸缪。埋点数据上报不准确、每个版本人工回溯核心埋点成本的上升、埋点量级的上升对存储以及服务器的压力等，都需要我们有一个完善的埋点监控机制，来持续改善我们的现状。到家埋点后续将重点在监控完善的道路上继续前进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzAwMzg1ODMwNw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/PNm6V9cebJXiceZGCcxwiaBWCsfyZjibdQfkhbOKqgNPJkHWNwibaGupDicA7sXCUs9jCM8lTeYaribatAd9NaibGBj3A/0?wx_fmt=png&quot; data-nickname=&quot;达达集团技术&quot; data-alias=&quot;dada-tech&quot; data-signature=&quot;分享达达集团大研发部在打磨产品、精进技术方面的心得体会，与极客们互相切磋、共同成长&quot; data-from=&quot;1&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>047cab0f643786f74c4cf477e85d0250</guid>
<title>Http 2.0 一篇就够了</title>
<link>https://toutiao.io/k/tpj25u1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&quot; id=&quot;js_content&quot;&gt;&lt;p&gt;自1997年HTTP/1.1发布之后，HTTP/1.1便迅速占领了市场，时至今日(2022年)仍是当前使用最广泛的http协议。但是，这并不能说明HTTP/1.1就完美无缺了，仍然存在很多问题。&lt;/p&gt;&lt;h1&gt;HTTP1.1 当前存在的问题&lt;/h1&gt;&lt;p&gt;  当前HTTP1.1其实在协议本身的格式以及功能上在经历过HTTP0.9、HTTP1.0等几次迭代之后，已经逐渐趋于稳定。当前协议的主要问题是：协议制定初期原始依赖的底层协议带来的问题，即依赖TCP带来的问题：效率慢。&lt;/p&gt;&lt;p&gt;  在http协议制定初期，谁也不会想到一个小小的浏览器能够出现这么丰富多彩的内容，最初的设定，仅仅是为了发布和共享文件，根本不会考虑&quot;交互&quot;的体验问题，压根想象不到当今的浏览器客户端一个页面下来，会产生这么多的请求。当初的设定很简单：只是为了让欧洲的学者之间能够共享文件，保证学术信息的分享；所以，可靠性是当初优先考虑的问题，TCP是可靠连接，理所当然就选择了TCP。&lt;/p&gt;&lt;p&gt;  可是后来随着互联网的发展，当初选择TCP作为底层协议的弊端逐渐凸显：建立连接复杂，效率低。TCP建立连接需要三次握手和四次挥手，创建和断开过程繁琐，效率很低。&lt;/p&gt;&lt;p&gt;  在http1.1协议之前，每一个请求都要新建一个链接；已知平均一个站点有65 ~ 79个请求(2019年统计)，那么打开这么一个网站，就需要 65 ~ 79次请求...好在在http1.1之后新增了&lt;code&gt;keep-alive&lt;/code&gt;字段，可以复用原有的TCP链接，无需每来一个请求就三次握手创建一个TCP链接，也无需一个响应结束四次挥手关闭一个TCP链接，在一定程度上提高了整体协议效率。但是，依然存在其他问题，例如：对头阻塞问题(Head-of-line blocking)。在http1.1协议下，同一个网站内所有HTTP请求的请求顺序是流水线式的顺序执行的，即虽然可能共用了同一个TCP链接通道，但是同一个TCP链接通道下的两个请求会存在阻塞等待的情况：如果前一个HTTP请求没有处理完，第二个http请求只能阻塞等待，这样停滞时间会影响整体协议的传输效率。并且，在不同的浏览器中，同一域名下并发连接的数目都是有限的，例如Chrome浏览器，同一域名下只允许最多&lt;code&gt;6&lt;/code&gt;个并发连接数，这样一来，如果平均一个网站需要 65 ~ 79 个http请求(2019年官方统计数据)，假设都在同一域名下，至少需要 &lt;code&gt;65 / 6&lt;/code&gt; 11个请求等待，才能将所有请求发送完毕。而且假设其中一个链接通道中某个请求延迟或者等待，将直接阻塞后面队列中的请他请求的请求时间。&lt;br/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;571&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;671&quot; data-ratio=&quot;1.1751313485113835&quot; data-type=&quot;png&quot; data-w=&quot;571&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVaulMxt0pibXVF18dWJuAtFQsho2KgIKxsRzLCzIfBxfqvq90ia6bVYtfA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h1&gt;HTTP2.0 做的改进&lt;/h1&gt;&lt;p&gt;  为提高http的整体性能，http2.0在不改变当前协议整体格式及语义的前提下，对http协议的传输进行了优化，使得http2.0的整体传输效率得到了很大的提升。可以点击以下链接感受一下速度：https://http2.akamai.com/demo&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6411214953271028&quot; data-type=&quot;png&quot; data-w=&quot;1070&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVa0J2SuaBtPziabfhtvXmibpU9mWgicfAxOLI9gTXCSuwCZYdt4AlXs4p3A/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;HTTP2.0的改进主要是针对HTTP性能的提升。&lt;/p&gt;&lt;p&gt;  影响http网络通信性能的因素主要有两个：延迟 和 带宽。随着硬件能力的不断提升以及5G的普及，带宽逐渐不是影响网络通信效率的因素，延迟成了影响http网络通信的主要因素。而想要提升延迟，需要从网络协议的本身来找原因。早在2009年，Google就开始了对提升http性能的因素做研究；当时研发了一种叫做&lt;code&gt;SPDY&lt;/code&gt;的协议，并在2012年得到了Chrome、Firefox以及Opera等浏览器的支持，并成功应用到了Google、Twitter、Facebook等大型网站中来；从此以后，越来越多的公司想要使用SPDY。&lt;/p&gt;&lt;p&gt;  HTTP官方看到了这个趋势，决定仿照依赖&lt;code&gt;SPDY&lt;/code&gt;协议的模型，对HTTP协议进行改造，于是就有了现在的HTTP2.0。前期HTTP2.0基本继承了&lt;code&gt;SPDY&lt;/code&gt;协议，后来又在此基础上做了扩展。与&lt;code&gt;SPDY&lt;/code&gt;协议类似，HTTP2.0遵循了如下原则：&lt;/p&gt;&lt;p&gt;  HTTP2.0和SPDY的原理很简单，就是仿照TCP的拆包解包来解决当前HTTP的队头阻塞(Head-of-Line blocking）的问题，以实现多个请求并发传输、多路复用的效果。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5024390243902439&quot; data-type=&quot;other&quot; data-w=&quot;820&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVakbpl5cNpR3IlP0pQwIIJjEVcMY2Y3Kfic3LSFk9dmiaiaKpkt94Gvzt4Q/640?wx_fmt=other&quot;/&gt; 下面，就来详细说说http2.0的改进：&lt;/p&gt;&lt;h2&gt;HTTP2.0 二进制分帧&lt;/h2&gt;&lt;p&gt;  二进制分帧，算是HTTP2.0最重大的改变了，HTTP2.0的多路复用就是基于这个才得以实现。&lt;/p&gt;&lt;p&gt;  二进制分帧是在当前HTTPS的TLS协议之上，抽象了一层（也就是说，使用HTTP2.0的前提是必须使用HTTPS）。可以在传输的时候把一个请求拆分成多个很小的数据包，多个请求可以同时拆成许多数据包一起发送，到了服务端，服务端再根据数据包的序号进行拼接，得到完整的每一个请求。&lt;/p&gt;&lt;p&gt;  这些拆分的请求最小粒度叫&lt;code&gt;frame&lt;/code&gt;，按照类型可分为两类结构：&lt;code&gt;Headers frame&lt;/code&gt;和&lt;code&gt;data frame&lt;/code&gt;。&lt;code&gt;headers frame&lt;/code&gt;是对请求头做了抽象，&lt;code&gt;data frame&lt;/code&gt;是针对请求体做了抽象。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;292&quot; data-ratio=&quot;0.5052854122621564&quot; data-type=&quot;png&quot; data-w=&quot;2838&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVahictZrDLOJYLANOoPw9AhHMUmF2A6EHDlGMnQiaaGuQUt7bPsYO3OjbA/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;p&gt;除了&lt;code&gt;frame&lt;/code&gt;结构外，整个二进制分帧层还有&lt;code&gt;message&lt;/code&gt;、&lt;code&gt;stream&lt;/code&gt;两种数据结构，这几种数据结构存在包含关系：&lt;code&gt;frame&lt;/code&gt;最小，&lt;code&gt;message&lt;/code&gt;包含多个&lt;code&gt;frame&lt;/code&gt;，&lt;code&gt;stream&lt;/code&gt;包含多个&lt;code&gt;message&lt;/code&gt;； &lt;code&gt;frame&lt;/code&gt;、&lt;code&gt;message&lt;/code&gt;、&lt;code&gt;stream&lt;/code&gt;三种数据结构共同构成了http2.0的二进制分帧层。三种数据结构的联系和作用分别如下：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;frame&lt;/code&gt;是最小的传输单位，内部有特殊标识，能够区分此&lt;code&gt;frame&lt;/code&gt;属于哪个&lt;code&gt;stream&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;message&lt;/code&gt;是逻辑层面的东西，在具体实现中没有体现，多用于表示是请求&lt;code&gt;message&lt;/code&gt;还是相应&lt;code&gt;message&lt;/code&gt;，一个&lt;code&gt;messsage&lt;/code&gt;包含多个&lt;code&gt;frame&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;stream&lt;/code&gt;是HTTP2.0传输的最大粒度的&quot;包&quot;，它包含唯一性字段和优先级信息，能够包含请求或者相应&lt;code&gt;message&lt;/code&gt;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;472&quot; data-ratio=&quot;0.8172531214528944&quot; data-type=&quot;png&quot; data-w=&quot;1762&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVaOumVY7V8NIGT3YAbzLkZgIQiaAeMtpzlryryrnssX6ewjpicTtS38qaA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;那么，http2.0具体是怎样实现多路复用、解决http1.1的队头阻塞(head of block)问题的呢？&lt;/p&gt;&lt;p&gt;首先，http2.0的所有请求都&lt;code&gt;只在一条tcp连接中传输的&lt;/code&gt;，http2.0会把当前所有请求拆成无数小的frame(其实这时候已经区分出不同stream了)&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;378&quot; data-ratio=&quot;0.6542857142857142&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVafnSbM2cQbnfwK50H33b3uhePDic9m3ezLzl2tclVA6rAiaVQicz7ZkJng/640?wx_fmt=png&quot;/&gt; 然后根据各个frame中的标识信息(frame中标有stream标识)，组成一个个的stream，最后把各种的stream在一条tcp双向管道中进行传输。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;416&quot; data-ratio=&quot;0.7192857142857143&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVaV2gBYiatBibFOTrsG6iaAxayib1SSWAfDY8biak9j7zvX2ycMVrkicaqLElQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;注意：虽然二进制分帧协议中有&lt;code&gt;message&lt;/code&gt;结构，但是，这只是一种逻辑层面的结构，用于区分是请求还是响应信息片段，并不参与真正的协议实现。底层实现仅仅有&lt;code&gt;stream&lt;/code&gt;和&lt;code&gt;frame&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;226&quot; data-ratio=&quot;0.39151599443671764&quot; data-type=&quot;png&quot; data-w=&quot;2876&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVa2ibKZuVszUdIS5Re6mDeuUuCvQoYdk34QXhMrWWtXrJGyMY9XsahIBg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;client端和server端在收到各类stream后，根据steam的标识，拼出完整的请求或者响应stream数组，再根据stream数组中的&lt;code&gt;frame&lt;/code&gt;信息，解析出完整的请求或者响应信息。&lt;/p&gt;&lt;p&gt;这样，就实现了http在传输过程中的多路复用。&lt;/p&gt;&lt;p&gt;值得一提的是，在http2.0在传输过程中，我们不再使用纯文本，而是把请求的数据都采用二进制(0或者1)的形式进行传输，这样也减少文本转义带来的额外性能开销；&lt;/p&gt;&lt;h2&gt;HTTP2.0 头部压缩&lt;/h2&gt;&lt;p&gt;  在http1.1传输过程中，请求体可以根据 gzip进行压缩，但是对请求头没有做处理，随着网站请求量的增多，在http2.0之后，对请求头也做了压缩处理。&lt;/p&gt;&lt;p&gt;  对于一个站点，大部分的请求中请求头的信息都是重复的，不同的仅仅只有少数头部属性。&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;463&quot; data-ratio=&quot;0.8004385964912281&quot; data-type=&quot;png&quot; data-w=&quot;1824&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVaebeWicBcwYovY7eRV51LolSxErEFPibEFrlU8FNh2kopbBlYhYsNs8Zw/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;p&gt;为了增加传输速率，http2.0在传输的时候，会维护一张请求头部信息的哈希表，并同时存储在客户端和服务端，每次传输的时候，如果发现传输的头部信息在哈希表中已经存在，则只传哈希表的index值，不再传输具体的内容，这样一来，就极大减少了数据的传输。同时，如果有新的头部字段，这张哈希表也会动态的在客户端以及服务端增加新值，后续再有相同字段的时候，将不会再传输，只会传哈希表的index值。&lt;/p&gt;&lt;p&gt;  事实上，上文所谓的那张哈希表细分下来是两张表：一张叫静态表，一张叫动态表。静态表是存放HTTP协议本身固定的一些常见值：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;347&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;306&quot; data-ratio=&quot;0.8819444444444444&quot; data-type=&quot;png&quot; data-w=&quot;576&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVaboYic9sQibhK6ibj4syJewib3ibFLl0TwNh6HVicH3O8PC4iaw9OVCqH2EcDg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;动态表存放一些网站特定的属性字段，而且会随着请求中字段的变化而进行增加。&lt;/p&gt;&lt;p&gt;之后，请求头的内容变成了除少量header字段外大部分是哈希表index值的数据；但是这还没有结束，http2.0还会将现有的数据内容进行&lt;code&gt;霍夫曼编码处理&lt;/code&gt;，再一次进行压缩。&lt;/p&gt;&lt;p&gt;以上便是http2.0头部压缩的算法，叫做HACK算法。&lt;/p&gt;&lt;h2&gt;HTTP2.0 数据推送&lt;/h2&gt;&lt;p&gt;  不同于http1.1的请求-响应模式，http2.0可以由服务端向客户端推送消息，但这里的推送方式又有别于tcp、或者websocket的双向通信，有一定的局限性。&lt;/p&gt;&lt;p&gt;  在常见的http1.1协议下，client端和服务端严格按照 “请求-响应”的方式进行通信。这样会出现一种情况：某些请求显得很多余。例如，请求一个网站页面，在返回主要的html文件后，html文件中内联的css 、js等文件内容必须通过额外的客户端请求，才能从服务端拿到数据；而这些内联的数据文件，是一定且必须拿到的，这样看来，http1.1场景下，这些内联的数据文件必须由客户端再次发起请求，才能得到服务端的响应数据；而在http2.0的场景下，服务端会根据文件中关联的其他文件，预判并主动推送下次请求中必须的数据。http2.0的数据推送仅限于此了，不同于tcp、websocket的双向通信，要特别注意。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;253&quot; data-ratio=&quot;0.438498957609451&quot; data-type=&quot;png&quot; data-w=&quot;2878&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibzvyarYOcFI5BMUzb61lciaVabC38cv78KJOFOoqnVxUOSoBialxKVo2NHpXPhcK0hFnOcB93D9aicR0Q/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;这里可能会有人要问：“http提供了缓存能力，如果推送来的数据客户端缓存里有，该怎么办？” 其实很简单，如果服务端推送数据过来，客户端可以针对推送的数据自行选择放弃或者保存，但是如果客户端将推送来的数据主动放弃，这样其实就白白浪费了一次http响应传输；http2.0还有更好的方式是将客户端已有的缓存信息标识告诉服务端，服务端通过判断之后，只推送不存在的数据信息即可。&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzAwMjcwOTA3NA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/f2nwBpf5ibztoBhtqTiaSHIibBLJS3b7LH5huqHWs5rP3R58NM5FDOe1PuWGpwwZoaGJcCC6ID5Tmlx6DAooYXspA/0?wx_fmt=png&quot; data-nickname=&quot;码农RyuGou&quot; data-alias=&quot;ryugou&quot; data-signature=&quot;分享挨踢人的工作生活&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3158cf8288d1fd2e78af6f9b69824cea</guid>
<title>基于 tauri 打造的 HTTP API 客户端工具-CyberAPI</title>
<link>https://toutiao.io/k/byc6nnw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;markdown-body entry-content container-lg&quot; itemprop=&quot;text&quot;&gt;&lt;h1 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-基于tauri打造的http-api客户端工具-cyberapi&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#基于tauri打造的http-api客户端工具-cyberapi&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;基于tauri打造的HTTP API客户端工具-CyberAPI&lt;/h1&gt;
&lt;p dir=&quot;auto&quot;&gt;国庆长假和朋友聚会的时候，和朋友谈起最近这段时间捣鼓&lt;a href=&quot;https://github.com/tauri-apps/tauri&quot;&gt;tauri&lt;/a&gt;，写了一个HTTP API客户端工具。『你写了这么多东西，其实有想过是为了啥不？』为了啥这是一个很大的命题，当初每个项目的时候都想过它应该解决些啥，最终每个项目好像完成了它的使命，也好像还在征途之上。不是每个人的追求都是诗和远方、星辰大海，而我只是闲着也是闲着，所以做了点啥，不是为了啥。&lt;/p&gt;
&lt;p dir=&quot;auto&quot;&gt;选择使用&lt;code&gt;tauri&lt;/code&gt;并不是因为它的优缺点(如果想了解的大家可以直接去官网上查看)，只是因为我自己想学习一下rust(不要问我有没有学会，再问就没办法聊天了)，在了解过一些rust比较热门的项目之后，刚好也想学习一下桌面应用开发，因此&lt;a href=&quot;https://github.com/vicanso/cyberapi&quot;&gt;CyberAPI&lt;/a&gt;也在此巧合之下开始创建。&lt;/p&gt;
&lt;p dir=&quot;auto&quot;&gt;CyberAPI大概在6月中的时候开始，到现在基本4个月左右，由于rust完全不会，开发过程一堆的坑坑洼洼，个中辛酸不说，这年头谁没遇到点苦难，但是无言以对的是，我觉得自己现在还是完全不会rust。开发CyberAPI的过程中主要遇到以下几个问题：&lt;/p&gt;
&lt;ul dir=&quot;auto&quot;&gt;
&lt;li&gt;基于系统自带的webview，可能存在兼容性问题(开发时遇到macos接口图标切换后有残留，而windows无此问题，切换为png图片解决)&lt;/li&gt;
&lt;li&gt;javascript与rust调用如果大数据交互(10MB)，处理时长在3秒左右(tauri已知issue，官方在下一版本优化)&lt;/li&gt;
&lt;li&gt;最开始选择所有的数据均保存至浏览器IndexedDB，存储的数据较多导入导出较慢，因此切换至使用rust版本的sqlite&lt;/li&gt;
&lt;li&gt;支持Dark/Light主题，部分组件未自适应调整&lt;/li&gt;
&lt;li&gt;多语言支持未实现实时变化，通过设置后重启应用解决&lt;/li&gt;
&lt;/ul&gt;
&lt;p dir=&quot;auto&quot;&gt;上面的问题其实都只是小问题，虽然系统托盘以及自动升级当前版本并未使用上，tauri对我而言已经可以满足桌面应用开发，精通WEB前端的开发者完全可以直接基于浏览器实现绝大部分的功能，有边缘项目的可以考虑尝尝鲜，但是其各类的插件还是较少，如果项目更多的依赖于系统接口，则建议对rust有较深功底再入坑。&lt;/p&gt;
&lt;p dir=&quot;auto&quot;&gt;下面介绍一下CyberAPI的主要特性：&lt;/p&gt;
&lt;ul dir=&quot;auto&quot;&gt;
&lt;li&gt;支持macos、windows以及linux平台，安装包均在10MB以下(rust编译强行精简)&lt;/li&gt;
&lt;li&gt;单个项目上千个接口秒级打开，内存占用较低(电脑较好,mac air m2)&lt;/li&gt;
&lt;li&gt;支持Dark/Light主题以及中英语言(英文翻译较差)&lt;/li&gt;
&lt;li&gt;简单易用的操作及配置方式(对我而言)&lt;/li&gt;
&lt;li&gt;可快速导入postman与insomnia的配置(拉新专用)&lt;/li&gt;
&lt;li&gt;关键字筛选支持中文拼音或者首字母(中文必须支持)&lt;/li&gt;
&lt;li&gt;可按接口、功能、项目导出配置，方便团队内共用(我只是个人使用)&lt;/li&gt;
&lt;li&gt;各类自定义的函数，方便各请求间关联数据(我用的较多)&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&quot;center&quot; dir=&quot;auto&quot;&gt;
    &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;/vicanso/articles/blob/master/assets/cyberapi.jpg&quot;&gt;&lt;img src=&quot;/vicanso/articles/raw/master/assets/cyberapi.jpg&quot; alt=&quot;cyberapi&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p dir=&quot;auto&quot;&gt;CyberAPI的缺点则是：没有缺点(自己的项目，打死都要撑着)。不过由于只是个人的业余项目，如果有优化建议只能尽可能支持，如果是BUG则必须支持的(不能打脸，我也不会硬撑说不是BUG)，如果大家使用得开心的，那小手一点给个Star，如果用得不开心那更要Star，以后哪天心情不爽就过来怼一下，对不对。&lt;/p&gt;
&lt;p dir=&quot;auto&quot;&gt;项目在github上开源，开源协议为Apache License 2.0，可以放心使用，地址为：&lt;a href=&quot;https://github.com/vicanso/cyberapi&quot;&gt;https://github.com/vicanso/cyberapi&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3e41fae7422a55dabe67615a552a58e4</guid>
<title>常用 Shell 分析服务器日志命令，运维快收藏</title>
<link>https://toutiao.io/k/y451jnx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content             autoTypeSetting24psection&quot; id=&quot;js_content&quot;&gt;&lt;section&gt;&lt;section data-tools=&quot;新媒体管家&quot; data-label=&quot;powered by xmt.cn&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.11310592459605028&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/yNKv1P4Q9eVribgKqFaAJCb0jAWhyvJtodWYdjJPzIyO1CibiagC90AsPQe50IHheI50tRG72GQTmfQudOXQFiaEiaA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;557&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;386&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;325&quot; data-ratio=&quot;0.6670212765957447&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/yNKv1P4Q9eUsqck1E6JDMA1Cqic27Yqy0bXlHOWnQVicDgfWgK6XktgAUatH0ibe0nhhnXWY22NicU3eKj5e9oSDCA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;940&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自己的小网站跑在阿里云的 ECS 上面, 偶尔也去分析分析自己网站服务器日志,看看网站的访问量。看看有没有黑阔搞破坏！于是收集，整理一些服务器日志分析命令，大家可以试试！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、查看有多少个IP访问：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{print $1}&#x27; log_file|sort|uniq|wc -l&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;2、查看某一个页面被访问的次数：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;grep &quot;/index.php&quot; log_file | wc -l&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;3、查看每一个IP访问了多少个页面：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{++S[$1]} END {for (a in S) print a,S[a]}&#x27; log_file &amp;gt; log.txt&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;sort -n -t &#x27; &#x27; -k 2 log.txt 配合sort进一步排序&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;4、将每个IP访问的页面数进行从小到大排序：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{++S[$1]} END {for (a in S) print S[a],a}&#x27; log_file | sort -n&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;5、查看某一个IP访问了哪些页面：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;grep ^111.111.111.111 log_file| awk &#x27;{print $1,$7}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;6、去掉搜索引擎统计的页面：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{print $12,$1}&#x27; log_file | grep ^\&quot;Mozilla | awk &#x27;{print $2}&#x27; |sort | uniq | wc -l&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;7、查看2015年8月16日14时这一个小时内有多少IP访问:&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{print $4,$1}&#x27; log_file | grep 16/Aug/2015:14 | awk &#x27;{print $2}&#x27;| sort | uniq | wc -l&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;8、查看访问前十个ip地址&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{print $1}&#x27; |sort|uniq -c|sort -nr |head -10 access_log&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;uniq -c 相当于分组统计并把统计数放在最前面&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log|awk &#x27;{print $1}&#x27;|sort|uniq -c|sort -nr|head -10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ruby&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log|awk &#x27;{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;9、访问次数最多的10个文件或页面&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat log_file|awk &#x27;{print $11}&#x27;|sort|uniq -c|sort -nr | head -10&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat log_file|awk &#x27;{print $11}&#x27;|sort|uniq -c|sort -nr|head -20&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{print $1}&#x27; log_file |sort -n -r |uniq -c | sort -n -r | head -20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;访问量最大的前20个ip&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;10、通过子域名访问次数，依据referer来计算，稍有不准&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log | awk &#x27;{print $11}&#x27; | sed -e &#x27; s/http:\/\///&#x27; -e &#x27; s/\/.*//&#x27; | sort | uniq -c | sort -rn | head -20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;11、列出传输大小最大的几个文件&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;apache&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat www.access.log |awk &#x27;($7~/\.php/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}&#x27;|sort -nr|head -100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;12、列出输出大于200000byte(约200kb)的页面以及对应页面发生次数&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat www.access.log |awk &#x27;($10 &amp;gt; 200000 &amp;amp;&amp;amp; $7~/\.php/){print $7}&#x27;|sort -n|uniq -c|sort -nr|head -100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;13、如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;apache&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat www.access.log |awk &#x27;($7~/\.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}&#x27;|sort -nr|head -100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;14、列出最最耗时的页面(超过60秒的)的以及对应页面发生次数&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat www.access.log |awk &#x27;($NF &amp;gt; 60 &amp;amp;&amp;amp; $7~/\.php/){print $7}&#x27;|sort -n|uniq -c|sort -nr|head -100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;15、列出传输时间超过 30 秒的文件&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat www.access.log |awk &#x27;($NF &amp;gt; 30){print $7}&#x27;|sort -n|uniq -c|sort -nr|head -20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;16、列出当前服务器每一进程运行的数量，倒序排列&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ps -ef | awk -F &#x27; &#x27; &#x27;{print $8 &quot; &quot; $9}&#x27; |sort | uniq -c |sort -nr |head -20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;17、查看apache当前并发访问数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比httpd.conf中MaxClients的数字差距多少&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -an | grep ESTABLISHED | wc -l&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;18、可以使用如下参数查看数据&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ps -ef|grep httpd|wc -l&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;1388&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;统计httpd进程数，连个请求会启动一个进程，使用于Apache服务器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表示Apache能够处理1388个并发请求，这个值Apache可根据负载情况自动调整&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -nat|grep -i &quot;80&quot;|wc -l&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;4341&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;netstat -an会打印系统当前网络链接状态，而grep -i “80”是用来提取与80端口有关的连接的，wc -l进行连接数统计。&lt;br/&gt;最终返回的数字就是当前所有80端口的请求总数&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -na|grep ESTABLISHED|wc -l&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;netstat -an会打印系统当前网络链接状态，而grep ESTABLISHED 提取出已建立连接的信息。然后wc -l统计&lt;br/&gt;最终返回的数字就是当前所有80端口的已建立连接的总数。&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -nat||grep ESTABLISHED|wc&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;可查看所有建立连接的详细记录&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;19、输出每个ip的连接数，以及总的各个状态的连接数&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -n | awk &#x27;/^tcp/ {n=split($(NF-1),array,&quot;:&quot;);if(n&amp;lt;=2)++S[array[(1)]];else++S[array[(4)]];++s[$NF];++N} END {for(a in S){printf(&quot;%-20s %s\n&quot;, a, S[a]);++I}printf(&quot;%-20s %s\n&quot;,&quot;TOTAL_IP&quot;,I);for(a in s) printf(&quot;%-20s %s\n&quot;,a, s[a]);printf(&quot;%-20s %s\n&quot;,&quot;TOTAL_LINK&quot;,N);}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;20、其他的收集&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分析日志文件下 2012-05-04 访问页面最高 的前20个 URL 并排序&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;perl&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log |grep &#x27;04/May/2012&#x27;| awk &#x27;{print $11}&#x27;|sort|uniq -c|sort -nr|head -20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;查询受访问页面的URL地址中 含有 www.abc.com 网址的 IP 地址&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access_log | awk &#x27;($11~/\www.abc.com/){print $1}&#x27;|sort|uniq -c|sort -nr&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;获取访问最高的10个IP地址 同时也可以按时间来查询&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat linewow-access.log|awk &#x27;{print $1}&#x27;|sort|uniq -c|sort -nr|head -10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;时间段查询日志时间段的情况&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat log_file | egrep &#x27;15/Aug/2015|16/Aug/2015&#x27; |awk &#x27;{print $1}&#x27;|sort|uniq -c|sort -nr|head -10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;分析 2015/8/15 到 2015/8/16 访问”/index.php?g=Member&amp;amp;m=Public&amp;amp;a=sendValidCode”的IP倒序排列&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ruby&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat log_file | egrep &#x27;15/Aug/2015|16/Aug/2015&#x27; | awk &#x27;{if($7 == &quot;/index.php?g=Member&amp;amp;m=Public&amp;amp;a=sendValidCode&quot;) print $1,$7}&#x27;|sort|uniq -c|sort -nr&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;($7~/.php/) $7里面包含.php的就输出,本句的意思是最耗时的一百个PHP页面&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;apache&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat log_file |awk &#x27;($7~/\.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}&#x27;|sort -nr|head -100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;列出最最耗时的页面(超过60秒的)的以及对应页面发生次数&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log |awk &#x27;($NF &amp;gt; 60 &amp;amp;&amp;amp; $7~/\.php/){print $7}&#x27;|sort -n|uniq -c|sort -nr|head -100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;统计网站流量（G)&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log |awk &#x27;{sum+=$10} END {print sum/1024/1024/1024}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;统计404的连接&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;($9 ~/404/)&#x27; access.log | awk &#x27;{print $9,$7}&#x27; | sort&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;统计http status&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log |awk &#x27;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log |awk &#x27;{print $9}&#x27;|sort|uniq -c|sort -rn&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;每秒并发&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;watch &quot;awk &#x27;{if($9~/200|30|404/)COUNT[$4]++}END{for( a in COUNT) print a,COUNT[a]}&#x27; log_file|sort -k 2 -nr|head -n10&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;带宽统计&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat apache.log |awk &#x27;{if($7~/GET/) count++}END{print &quot;client_request=&quot;count}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;找出某天访问次数最多的10个IP&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;perl&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat /tmp/access.log | grep &quot;20/Mar/2011&quot; |awk &#x27;{print $3}&#x27;|sort |uniq -c|sort -nr|head&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;当天ip连接数最高的ip都在干些什么&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;perl&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;cat access.log | grep &quot;10.0.21.17&quot; | awk &#x27;{print $8}&#x27; | sort | uniq -c | sort -nr | head -n 10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;小时单位里ip连接数最多的10个时段&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk -vFS=&quot;[:]&quot; &#x27;{gsub(&quot;-.*&quot;,&quot;&quot;,$1);num[$2&quot; &quot;$1]++}END{for(i in num)print i,num[i]}&#x27; log_file | sort -n -k 3 -r | head -10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;找出访问次数最多的几个分钟&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;{print $1}&#x27; access.log | grep &quot;20/Mar/2011&quot; |cut -c 14-18|sort|uniq -c|sort -nr|head&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;取5分钟日志&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;if [ $DATE_MINUTE != $DATE_END_MINUTE ] ;then #&lt;/code&gt;&lt;br/&gt;&lt;span&gt;则判断开始时间戳与结束时间戳是否相等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;START_LINE=sed -n &quot;/$DATE_MINUTE/=&quot; $APACHE_LOG|head -n1&lt;/code&gt; &lt;span&gt;#如果不相等，则取出开始时间戳的行号，与结束时间戳的行号&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看tcp的链接状态&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -nat |awk &#x27;{print $6}&#x27;|sort|uniq -c|sort -rn &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -n | awk &#x27;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&#x27; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -n | awk &#x27;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&#x27; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -n | awk &#x27;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;\t&quot;,arr[k]}&#x27; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -n |awk &#x27;/^tcp/ {print $NF}&#x27;|sort|uniq -c|sort -rn &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ant | awk &#x27;{print $NF}&#x27; | grep -v &#x27;[a-z]&#x27; | sort | uniq -c&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ant|awk &#x27;/ip:80/{split($5,ip,&quot;:&quot;);++S[ip[1]]}END{for (a in S) print S[a],a}&#x27; |sort -n &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ant|awk &#x27;/:80/{split($5,ip,&quot;:&quot;);++S[ip[1]]}END{for (a in S) print S[a],a}&#x27; |sort -rn|head -n 10 &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;awk &#x27;BEGIN{printf (&quot;http_code\tcount_num\n&quot;)}{COUNT[$10]++}END{for (a in COUNT) printf a&quot;\t\t&quot;COUNT[a]&quot;\n&quot;}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;查找请求数前20个IP（常用于查找攻来源）：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -anlp|grep 80|grep tcp|awk &#x27;{print $5}&#x27;|awk -F: &#x27;{print $1}&#x27;|sort|uniq -c|sort -nr|head -n20 &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ant |awk &#x27;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&#x27; |sort -rn|head -n20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;用tcpdump嗅探80端口的访问看看谁最高&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; &#x27;{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}&#x27; | sort | uniq -c | sort -nr |head -20&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;查找较多time_wait连接&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;netstat -n|grep TIME_WAIT|awk &#x27;{print $5}&#x27;|sort|uniq -c|sort -rn|head -n20&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;找查较多的SYN连接&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;netstat -an | grep SYN | awk &#x27;{print $5}&#x27; | awk -F: &#x27;{print $1}&#x27; | sort | uniq -c | sort -nr | more&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据端口列进程&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ntlp | grep 80 | awk &#x27;{print $7}&#x27; | cut -d/ -f1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;查看了连接数和当前的连接数&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;perl&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ant | grep $ip:80 | wc -l &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -ant | grep $ip:80 | grep EST | wc -l&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;查看IP访问次数&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -nat|grep &quot;:80&quot;|awk &#x27;{print $5}&#x27; |awk -F: &#x27;{print $1}&#x27; | sort| uniq -c|sort -n&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;Linux命令分析当前的链接状况&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;nginx&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;netstat -n | awk &#x27;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;watch &quot;netstat -n | awk &#x27;/^tcp/ {++S[\$NF]} END {for(a in S) print a, S[a]}&#x27;&quot;&lt;/code&gt; &lt;span&gt;# 通过watch可以一直监控&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;LAST_ACK 5 #关闭一个TCP连接需要从两个方向上分别进行关闭，双方都是通过发送FIN来表示单方向数据的关闭，当通信双方发送了最后一个FIN的时候，发送方此时处于LAST_ACK状态，当发送方收到对方的确认（Fin的Ack确认）后才真正关闭整个TCP连接；&lt;/p&gt;&lt;p&gt;SYN_RECV 30 # 表示正在等待处理的请求数；&lt;/p&gt;&lt;p&gt;ESTABLISHED 1597 # 表示正常数据传输状态；&lt;/p&gt;&lt;p&gt;FIN_WAIT1 51 # 表示server端主动要求关闭tcp连接；&lt;/p&gt;&lt;p&gt;FIN_WAIT2 504 # 表示客户端中断连接；&lt;/p&gt;&lt;p&gt;TIME_WAIT 1057 # 表示处理完毕，等待超时结束的请求数；&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;来源：https://segmentfault.com/a/1190000009745139&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;XOps 风向标！GOPS  2022 · 上海站，&lt;strong&gt;&lt;span&gt;10月28-29日，&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;字节、&lt;/span&gt;&lt;/strong&gt;腾讯、阿里、平安银行等互联网、金融、通信云原生、DevOps、安全、数字化转型经验，扫码解锁更多精彩⏬&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.7786667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/yNKv1P4Q9eUsqck1E6JDMA1Cqic27Yqy0opTJsyJoRxNzqCFia8b8zasK7ynUwJmx1cq7hAOhfG9m5xOfw28BticA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;1.7786667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/yNKv1P4Q9eUsqck1E6JDMA1Cqic27Yqy0lBsmC4JdLCVEzWaib2u3LXKwzib3ncDibUsw4OiaiafH3EJhXib5UDBD1Kfg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;1.7786667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/yNKv1P4Q9eUsqck1E6JDMA1Cqic27Yqy0pxvd69RtPb9rSqwI4Rmiac3LDTiapD5npicaRRicIafZdic9ff6Jm0cKYBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;1.7786667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/yNKv1P4Q9eUsqck1E6JDMA1Cqic27Yqy0YfhqDu22gicXcEPq4RxnBicG0ibQzVNrj9tEZl0GyOXHUxlbkI1ibZM61w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&amp;lt;&amp;lt;  滑动查看下一张图片  &amp;gt;&amp;gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;近期好文：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;“高效运维”公众号诚邀广大技术人员投稿&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;投稿邮箱：jiachen@greatops.net，或添加联系人微信：greatops1118。&lt;/span&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;94248&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.6222222222222222&quot; data-type=&quot;png&quot; data-w=&quot;45&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/d5TCS9b3zE1d63yHRpJDZ2G0wgx1wY6ciaaPcfRr35t8sZ2H1qkica0UTZY6pTqGNxd6XkRo0rU9WvcSqBb9w5icQ/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;点个“在看”，一年不宕机&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1ee832cf58bc13f369469ae3fcbe9b6f</guid>
<title>开源 2 年半，除了性能优化我们啥也没做</title>
<link>https://toutiao.io/k/swk2aqc</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-4em6pe&quot; options=&quot;[object Object]&quot; lazyloadimageprops=&quot;[object Object]&quot; usegifprops=&quot;[object Object]&quot;&gt;&lt;p data-first-child=&quot;&quot; data-pid=&quot;35PvLZmM&quot;&gt;性能优化是个十分广泛的话题，它涉及 CPU、内存、磁盘、网络等方面。MegEngine 作为一个训推一体的深度学习框架，也在持续不断探索性能优化的最优解。&lt;/p&gt;&lt;p data-pid=&quot;Ro9Ed9A1&quot;&gt;本篇整理了 Bot 过往发布的相关文章，希望能帮助大家更好的理解和掌握 MegEngine 使用技巧。&lt;/p&gt;&lt;h2 id=&quot;h_569058143_0&quot; data-into-catalog-status=&quot;&quot;&gt;工欲善其事必先利其器&lt;/h2&gt;&lt;h3 id=&quot;h_569058143_1&quot; data-into-catalog-status=&quot;&quot;&gt;&lt;b&gt;学会使用性能评测工具&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;HV_5WhgO&quot;&gt;提到性能优化，笔者认为性能优化人员的技术水平大概可被分为以下三类：&lt;/p&gt;&lt;ol&gt;&lt;li data-pid=&quot;DPxcSgBS&quot;&gt;“瞎着写“。这类技术水平的人员一般不会在意其他，遇事先上”三板斧“，如循环展开，向量化，指令重排。性能好往往也不知其所以然，性能不好也没有什么后续的优化思路。&lt;/li&gt;&lt;li data-pid=&quot;xDIhl2AU&quot;&gt;”摸着写”。这类技术水平的人员与第一类的一个显著的分水岭是学会使用性能评测工具，通过工具能够摸到程序的瓶颈在何处，然后进行对应的优化。&lt;/li&gt;&lt;li data-pid=&quot;TpUKqWRY&quot;&gt;”瞄着写“。这类人员有了量化分析程序性能的能力。当面临同一个程序的多种写法时，能够做到即使不真实实现程序，也能较为精准的算出来哪种写法性能更好。&lt;/li&gt;&lt;/ol&gt;&lt;p data-pid=&quot;fuC8ug_a&quot;&gt;需要注意的是以上三类人员所用的技术是逐级包含的关系，例如第三类人员同样掌握性能评测工具的使用方法和”三板斧“式的优化方法。正所谓工欲善其事必先利其器，其实只有达到第二类的水平，性能优化人员才初步具有独立优化能力，所以性能评测工具的掌握至关重要。如果你对性能优化中一些基本概念还不够了解，且对以下问题也有相同的疑问：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;9NmvdxJn&quot;&gt;Python 及 C/C++ 拓展程序的常见的优化目标有哪些；&lt;/li&gt;&lt;li data-pid=&quot;AbVCT-us&quot;&gt;常见工具的能力范围和局限是什么，给定一个优化目标我们应该如何选择工具；&lt;/li&gt;&lt;li data-pid=&quot;_o-mWr3U&quot;&gt;各种工具的使用方法和结果的可视化方法；&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;2EQKXCZr&quot;&gt;&lt;b&gt;《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/362575905&quot; class=&quot;internal&quot;&gt;profiling 与性能优化总结&lt;/a&gt;》&lt;/b&gt;将会是一个很好的总结性材料。&lt;/p&gt;&lt;h3 id=&quot;h_569058143_2&quot; data-into-catalog-status=&quot;&quot;&gt;&lt;b&gt;学会基本的性能优化方法论&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;rlsD60oG&quot;&gt;学会了使用性能评测工具之后，还需要了解基本的性能优化方法论，然后就基本具有独立优化能力了。性能优化很多时候就是&lt;b&gt;不断迭代&lt;/b&gt;的过程：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-53efd4c11d060639799ea10c169c80ee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;317&quot; data-rawheight=&quot;694&quot; class=&quot;content_image&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;317&quot; data-rawheight=&quot;694&quot; class=&quot;content_image lazy&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-53efd4c11d060639799ea10c169c80ee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;OP00xg1q&quot;&gt;以 ARM Cortex a55 上的 GaussianBlur 优化为例，一起看&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://zhuanlan.zhihu.com/p/517371998&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/equation_ipico.jpg&quot; data-image-width=&quot;120&quot; data-image-height=&quot;120&quot; data-text=&quot;MegEngine Bot：ARM 算子性能优化上手指南&quot; class=&quot;LinkCard new&quot;&gt;&lt;span class=&quot;LinkCard-contents&quot;&gt;&lt;span class=&quot;LinkCard-title loading&quot; data-text=&quot;true&quot;/&gt;&lt;span class=&quot;LinkCard-desc loading&quot;/&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-image LinkCard-image--default&quot;/&gt;&lt;/a&gt;&lt;h2 id=&quot;h_569058143_3&quot; data-into-catalog-status=&quot;&quot;&gt;作为深度学习框架，模型训练速度很重要&lt;/h2&gt;&lt;h3 id=&quot;h_569058143_4&quot; data-into-catalog-status=&quot;&quot;&gt;&lt;b&gt;解决零碎算子时间占比高的问题&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;1xelIwfH&quot;&gt;众所周知，很多深度学习模型中都有类似 element-wise 的散碎操作。例如加减乘除算术运算和神经网络中的激活函数，以及 BatchNormalization 在模型推理的时候一般也被优化成一系列的 element-wise 操作。&lt;/p&gt;&lt;p data-pid=&quot;9WJqpQic&quot;&gt;这些散碎的操作具有计算访存比低的特点，即其计算量较低但是访存量较高，是一种典型的内存受限(memory bound)的操作。算子融合(kernel fusion)是针对内存受限的算子的常见优化手段。但是这些散碎算子的计算模式众多，这些计算模式相互组合将会是指数级别的，依靠手工写代码进行针对性优化是不现实的。MegEngine 通过引入 JIT 和自动代码生成技术解决计算模式组合爆炸的问题，从而享受到 kernel fusion 带来的性能收益，详见&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://zhuanlan.zhihu.com/p/357490714&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-text=&quot;MegEngine Bot：JIT in MegEngine&quot; class=&quot;LinkCard new&quot;&gt;&lt;span class=&quot;LinkCard-contents&quot;&gt;&lt;span class=&quot;LinkCard-title loading&quot; data-text=&quot;true&quot;/&gt;&lt;span class=&quot;LinkCard-desc loading&quot;/&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-image LinkCard-image--default&quot;/&gt;&lt;/a&gt;&lt;h2 id=&quot;h_569058143_5&quot; data-into-catalog-status=&quot;&quot;&gt;作为一个训推一体的框架，推理速度同样重要&lt;/h2&gt;&lt;h3 id=&quot;h_569058143_6&quot; data-into-catalog-status=&quot;&quot;&gt;&lt;b&gt;云侧&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;EN09swQl&quot;&gt;单精度矩阵乘法（SGEMM）几乎是每一位学习 CUDA 的同学绕不开的案例，这个经典的计算密集型案例可以很好地展示 GPU 编程中常用的优化技巧，而能否写出高效率的 SGEMM Kernel，也是反映一位 CUDA 程序员对 GPU 体系结构的理解程度的优秀考题。&lt;/p&gt;&lt;p data-pid=&quot;8fmThUsz&quot;&gt;在&lt;b&gt;《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/410278370&quot; class=&quot;internal&quot;&gt;CUDA 矩阵乘法终极优化指南&lt;/a&gt;》&lt;/b&gt;一文中，详细介绍了 CUDA SGEMM 的优化手段，适合认真阅读过 《CUDA C++ Programming Guide》 、具备一定 CUDA 编程基础的同学阅读。&lt;/p&gt;&lt;p data-pid=&quot;WXrEaPGk&quot;&gt;2020 年 5 月 Nvidia 发布了新一代的 GPU 架构安培（Ampere）。其中和深度学习关系最密切的莫过于性能强劲的第三代的 TensorCore ，新一代的 TensorCore 支持了更为丰富的 DL（Deep Learning）数据类型，包括了新的 TesorFloat-32（TF32），Bfloat16（BF16）计算单元以及 INT8, INT4 和 INT1 的计算单元，这些计算单元为 DL 推理提供了全面的支持。为了发挥这些计算单元的能力，以往会由资深的 HPC 工程师手写 GPU 汇编实现的卷积、矩阵乘算子来挖掘硬件的能力。然而凭借人力手工优化算子的方式已经没有办法应对如此多的数据类型，因此对于 DL 应用的优化渐渐地越来越依赖一些自动化的工具，例如面向深度学习领域的编译器。在这样的趋势下，Nvidia 开发了线性代数模板库 CUTLASS ，抽象了一系列高性能的基本组件，可以用于生成各种数据类型，各种计算单元的卷积、矩阵乘算子。&lt;/p&gt;&lt;p data-pid=&quot;BguqIypD&quot;&gt;MegEngine 在 CUTLASS 的基础上进行了二次开发，可以高效地开发新的高性能的算子，快速地迁移到新的 GPU 架构。一文看懂 &lt;b&gt;《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/372973726&quot; class=&quot;internal&quot;&gt;MegEngine CUDA 平台的底层卷积算子的实现原理&lt;/a&gt;》&lt;/b&gt;。文中还有对 Nvidia CUTLASS 的 Implicit GEMM 卷积文档进行解读和补充。&lt;/p&gt;&lt;h3 id=&quot;h_569058143_7&quot; data-into-catalog-status=&quot;&quot;&gt;&lt;b&gt;端 &amp;amp; 芯侧&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;dcvnrKqT&quot;&gt;卷积计算优化作为 CV 模型推理性能优化中最重要的一项工作，CPU 上 Inference 中有关卷积的优化有很多的途径。&lt;/p&gt;&lt;p data-pid=&quot;FMou_-zI&quot;&gt;MegEngine 通过实现 Im2col+matmul 卷积以及 Winograd 卷积中的一些进一步优化的技术手段，进一步加速了卷积计算的性能，从而加速整个模型的 Inference 性能。&lt;/p&gt;&lt;p data-pid=&quot;KwsdHqb6&quot;&gt;如在 Float32 的经典网络开启相关优化后，在骁龙 855 上的测试速度为：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1fcf738d7505ed9f57937364b7f4995a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1226&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-1fcf738d7505ed9f57937364b7f4995a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1226&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-1fcf738d7505ed9f57937364b7f4995a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1fcf738d7505ed9f57937364b7f4995a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;JtuTONeZ&quot;&gt;有关 Im2col 和 Winograd 算法的实现以及优化方法，见&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://zhuanlan.zhihu.com/p/532187602&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-text=&quot;MegEngine Bot：MegEngine Inference 卷积优化之 Im2col 和 winograd 优化&quot; class=&quot;LinkCard new&quot;&gt;&lt;span class=&quot;LinkCard-contents&quot;&gt;&lt;span class=&quot;LinkCard-title loading&quot; data-text=&quot;true&quot;/&gt;&lt;span class=&quot;LinkCard-desc loading&quot;/&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-image LinkCard-image--default&quot;/&gt;&lt;/a&gt;&lt;p data-pid=&quot;VGaBh7E8&quot;&gt;在数字信号和数字图像领域， 对频域的研究是一个重要分支。 我们日常“加工”的图像都是像素级，被称为是图像的空域数据。空域数据表征我们“可读”的细节。如果我们将同一张图像视为信号，进行频谱分析，可以得到图像的频域数据。实现图像空域和频域转换的工具，就是傅立叶变换。由于图像数据在空间上是离散的，我们使用傅立叶变换的离散形式 DFT（Discrete Fourier Transform）及其逆变换 IDFT（Inverse Discrete Fourier Transform)。Cooley-Tuckey 在 DFT 的基础上，开发了更快的算法 FFT（Fast Fourier Transform）。&lt;/p&gt;&lt;p data-pid=&quot;DaRxycbh&quot;&gt;DFT/FFT 在深度学习领域也有延伸应用。 比如利用 FFT 可以降低卷积计算量的特点，FFT_Conv 算法也成为常见的深度学习卷积算法。&lt;/p&gt;&lt;p data-pid=&quot;Dep9_gow&quot;&gt;理论优化时，我们总会选择更好的设备去计算理论上限。但在实际应用时，算力较弱的移动设备，如何承载模型推理的运算？&lt;/p&gt;&lt;p data-pid=&quot;nqF97MUM&quot;&gt;一般认为，让模型运行于 GPU 上会比运行于 CPU 上具有较大的优势，取得可观的性能提升。这通常是真实情况，但是，在工程实践中我们也发现，对于某些模型维度较小的模型，在移动设备上，GPU 运行并没有带来性能的提升，而且还额外引入了兼容性的问题。所以，在某些应用场景下，我们需要以 CPU 为运行载体，尝试各种方法，以提升模型推理性能。&lt;/p&gt;&lt;p data-pid=&quot;N_3MDxxu&quot;&gt;在&lt;b&gt;《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/400228375&quot; class=&quot;internal&quot;&gt;基于 MegEngine 移动端 CPU 的深度学习模型推理性能优化&lt;/a&gt;》&lt;/b&gt;一文中，作者总结了自己在工程实践中，基于 MegEngine 推理引擎，发现的 2 有效的优化方法“ NCHW44 和 Record ”的原理及使用方法做了详细说明。&lt;/p&gt;&lt;blockquote data-pid=&quot;cGVA1oHh&quot;&gt;如果你在 MegEngine 的使用过程中也有自己独特的技巧，欢迎联系 Bot（微信号：megengine-bot）投稿，还有多种社区周边相送哦~&lt;/blockquote&gt;&lt;h2 id=&quot;h_569058143_8&quot; data-into-catalog-status=&quot;&quot;&gt;相比于性能，易用性也不可或缺&lt;/h2&gt;&lt;p data-pid=&quot;d8FFOnc2&quot;&gt;为解决实际生产条件下，用户的 NN 网络千差万别的情况。在同一类数学计算中，开发者们会开发多种高效的算法，分别适用于不同的参数，以保证网络的性能。接下来开发者们需要解决一个新问题，当计算参数确定以后，如何让最快的算法执行该计算。&lt;/p&gt;&lt;p data-pid=&quot;JOMLuPzI&quot;&gt;大部分框架靠先验的经验选择算法，MegEngine 亦总结有优秀的先验经验值，实现计算时自动选择算法。但是依靠经验不能保证一定选择了最快的算法。很多实际场景中，用户希望网络有最极致的性能。为此，MegEngine 设计了专门的流程 - Fast Run，可以为每个计算自动选择最快的算法，从而保证整个网络的运行时间最短。&lt;/p&gt;&lt;p data-pid=&quot;wYgbS2Hd&quot;&gt;原理及使用方法见&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://zhuanlan.zhihu.com/p/387775972&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-text=&quot;MegEngine Bot：Fast Run：提高 MegEngine 模型推理性能的神奇功能&quot; class=&quot;LinkCard new&quot;&gt;&lt;span class=&quot;LinkCard-contents&quot;&gt;&lt;span class=&quot;LinkCard-title loading&quot; data-text=&quot;true&quot;/&gt;&lt;span class=&quot;LinkCard-desc loading&quot;/&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-image LinkCard-image--default&quot;/&gt;&lt;/a&gt;&lt;p data-pid=&quot;rupmVWoA&quot;&gt;为了在不同的应用场景上都能表现出不错的性能，MegEngine 中的张量（Tensor）具有不同的排布格式（Format），不同存储格式在不同的输入数据和不同硬件平台上的性能也不相同。全局图优化从整个模型的角度决策模型的哪一部分转换成哪种存储格式能使得整个模型的性能最优，避免给用户带来繁杂的选择和权衡从而导致额外的心智负担。同 Fast Run 一样，全局图优化也是可选择开启的优化选项。&lt;/p&gt;&lt;p data-pid=&quot;7ZUMsIu9&quot;&gt;在 int8 模型上，经过全局图优化和 MegEngine 原 Format 优化方法（传统图优化）的推理时间表现对比如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-68eb1c2bb448277c8d4043000ecb8d04_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;603&quot; data-rawheight=&quot;328&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-68eb1c2bb448277c8d4043000ecb8d04_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;603&quot; data-rawheight=&quot;328&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-68eb1c2bb448277c8d4043000ecb8d04_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-68eb1c2bb448277c8d4043000ecb8d04_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;TV07Ywet&quot;&gt;全局图优化能解决哪些问题？如何使用？以及底层技术原理解析。可以看：&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://zhuanlan.zhihu.com/p/491037155&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/equation_ipico.jpg&quot; data-image-width=&quot;120&quot; data-image-height=&quot;120&quot; data-text=&quot;MegEngine Bot：全局图优化：提升 MegEngine 模型推理性能的又一神器&quot; class=&quot;LinkCard new&quot;&gt;&lt;span class=&quot;LinkCard-contents&quot;&gt;&lt;span class=&quot;LinkCard-title loading&quot; data-text=&quot;true&quot;/&gt;&lt;span class=&quot;LinkCard-desc loading&quot;/&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-image LinkCard-image--default&quot;/&gt;&lt;/a&gt;&lt;h2 id=&quot;h_569058143_9&quot; data-into-catalog-status=&quot;&quot;&gt;【很重要的补充说明】&lt;/h2&gt;&lt;p data-pid=&quot;FnvqRdp9&quot;&gt;在 Bot 把这篇内容给技术同学看的时候，被投诉：以偏概全！&lt;/p&gt;&lt;p data-pid=&quot;HgKEauKs&quot;&gt;据他们说：以上提到的技术点，绝对不是开源至今所有的重点工作；还有更多性能优化工作，只是没有被整理成文章而已。&lt;/p&gt;&lt;p data-pid=&quot;Un_K9f3T&quot;&gt;所以，欢迎大家留言自己感兴趣的内容方向，在线催更~~ &lt;/p&gt;&lt;h2 id=&quot;h_569058143_10&quot; data-into-catalog-status=&quot;&quot;&gt;附&lt;/h2&gt;&lt;p data-pid=&quot;aEnWoh8I&quot;&gt;GitHub：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/MegEngine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MegEngine 旷视天元&lt;/a&gt; （欢迎 star~&lt;/p&gt;&lt;p data-pid=&quot;l4wkbVhC&quot;&gt;Gitee：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gitee.com/MegEngine/MegEngine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MegEngine/MegEngine&lt;/a&gt;&lt;/p&gt;&lt;p data-pid=&quot;mQdfRgAF&quot;&gt;MegEngine 官网：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.megengine.org.cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MegEngine-深度学习，简单开发&lt;/a&gt;&lt;/p&gt;&lt;p data-pid=&quot;H9IUwogi&quot;&gt;欢迎加入 MegEngine 技术交流 QQ 群：1029741705&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>