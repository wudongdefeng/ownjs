<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>98965bb9896272c595c7b61b5be20e6e</guid>
<title>Chromium + Mitmproxy 组合使用踩坑</title>
<link>https://toutiao.io/k/bz4e46a</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section class=&quot;toc-content post no-image&quot;&gt;
      &lt;h2 id=&quot;%E8%83%8C%E6%99%AF&quot;&gt;背景&lt;/h2&gt;&lt;p&gt;众所周知，Chromium 目前是事实上的地表最强浏览器内核，Mitmproxy 是事实上地表最强的中间人代理工具。二者组合使用可以非常方便的进行控制与数据分离的自动化数据提取。不过在实际生产中大规模使用时，还是会或多或少的遇到了一些难以察觉的坑。。。&lt;/p&gt;&lt;h2 id=&quot;mitmproxy-%E4%BD%8E%E7%89%88%E6%9C%AC%E9%95%BF%E6%9C%9F%E8%BF%90%E8%A1%8C%E6%98%93-oom&quot;&gt;Mitmproxy 低版本长期运行易 OOM&lt;/h2&gt;&lt;h3 id=&quot;%E7%8E%B0%E8%B1%A1&quot;&gt;现象&lt;/h3&gt;&lt;p&gt;在容器中部署 chromium + mitmproxy 后，发现在多次访问某些类型网站时，mitmproxy 经常周期性地出现内存缓慢增长，直到超过 docker 限制而被 OOMKilled。虽然有 docker 的自动重启进程功能，但是总会不可避免的导致业务上网络连接的周期性断开。&lt;/p&gt;&lt;h3 id=&quot;%E5%88%86%E6%9E%90&quot;&gt;分析&lt;/h3&gt;&lt;p&gt;初步怀疑是流量本身过多（chromium 对 mitmproxy 是“多对一”）以及给 mitmproxy 分配的内存过低导致内存不足。于是尝试将 mitmproxy 的内存配额从 200MB 增长到 1G。&lt;/p&gt;&lt;p&gt;但是实际结果却是这只是延长了 OOM 的时间，并没有解决问题。于是考虑是出现了内存泄漏问题，但是业务脚本无论如何也排查不出问题，因此只能暂时用 docker 自动重启进程的功能保持服务的大致可用。&lt;/p&gt;&lt;p&gt;同时发现似乎在 chromium 中增加 &lt;code&gt;--disable-http2&lt;/code&gt; 的启动参数后，内存泄漏的情况会有所缓解。&lt;/p&gt;&lt;h3 id=&quot;%E8%A7%A3%E5%86%B3&quot;&gt;解决&lt;/h3&gt;&lt;p&gt;经过一段时间，偶然回头一看才检索到 mitmproxy 有一个 &lt;a href=&quot;https://github.com/mitmproxy/mitmproxy/issues/4786&quot;&gt;#4786&lt;/a&gt; 的相关 issue。原来在较低版本中（8.0.0及以下），拦截的 HttpFlow 长连接对象的确存在连接泄漏导致内存不断膨胀直至 OOM 的问题。（这样一想强制关闭 http2 长连接的确有概率会降级到短连接，从而缓解长连接的 OOM 问题。）&lt;/p&gt;&lt;p&gt;这个问题终于在 8.1.0 版本得到了修复（&lt;a href=&quot;https://github.com/mitmproxy/mitmproxy/blob/main/CHANGELOG.md&quot;&gt;CHANGELOG&lt;/a&gt;）：&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image.png 1000w, https://blog.mythsman.com/content/images/size/w1600/2023/03/image.png 1600w, https://blog.mythsman.com/content/images/2023/03/image.png 1754w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们要做的就是直接使用最新稳定版的 mitmproxy 即可。不过这件事情也没有想象中的容易。&lt;/p&gt;&lt;p&gt;如果你的系统是 ubuntu:focal (20.04 LTS) 的版本，默认安装的 python3 版本应当是 3.8.x ，这时你会发现无论如何也装不上 mitmproxy@8.1.0 版本：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 20.04.5 LTS
Release: 20.04
Codename: focal

$ python3 --version
Python 3.8.10

$ pip3 install mitmproxy==8.1.0
ERROR: Could not find a version that satisfies the requirement mitmproxy==8.1.0 (from versions: 0.8, 0.8.1, 0.9, 0.9.1, 0.9.2, 0.10, 0.10.1, 0.11, 0.11.1, 0.11.2, 0.11.3, 0.12.0, 0.12.1, 0.13, 0.14.0, 0.15, 0.18.1, 0.18.2, 0.18.3, 1.0.0, 1.0.1, 1.0.2, 2.0.0, 2.0.1, 2.0.2, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 4.0.0, 4.0.1, 4.0.3, 4.0.4, 5.0.0, 5.0.1, 5.1.0, 5.1.1, 5.2, 5.3.0, 6.0.0, 6.0.1, 6.0.2, 7.0.0, 7.0.1, 7.0.2, 7.0.3, 7.0.4, 8.0.0)
ERROR: No matching distribution found for mitmproxy==8.1.0&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里的关键是要记得去 &lt;a href=&quot;https://pypi.org/&quot;&gt;pypi&lt;/a&gt; 上去看下 mitmproxy 对不同 python 版本的支持：&lt;a href=&quot;https://pypi.org/project/mitmproxy/8.0.0/&quot;&gt;8.0.0&lt;/a&gt; 的最低支持 python 版本是 3.8；而刚巧修复了 bug 的 &lt;a href=&quot;https://pypi.org/project/mitmproxy/8.1.0/&quot;&gt;8.1.0&lt;/a&gt; 的最低支持 python 版本就跳到了 3.9。于是这里又要继续升级 python3 到 3.9 以上。&lt;/p&gt;&lt;p&gt;这里又有两条路：要么需要在 20.04 的 ubuntu 里增加新的 python3.9 的源，把老的 python3.8 的相关数据清理干净，再安装新的 python3.9 ；要么直接升级到 jammy (22.04 LTS)。&lt;/p&gt;&lt;p&gt;经过一番尝试，发现在老的镜像里升级 python3.9 还是非常麻烦的，处理不好经常会残留一些老版本的库。于是我这里选择了直接将基础镜像换成了 ubuntu:22.04 。&lt;/p&gt;&lt;p&gt;全部升级完成后，正常运行的 mitmproxy 的内存占用基本都会维持在 100MB 左右了，还是非常稳定的。&lt;/p&gt;&lt;h2 id=&quot;chromium-%E5%BF%BD%E7%95%A5%E8%AF%81%E4%B9%A6%E6%A0%A1%E9%AA%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88&quot;&gt;Chromium 忽略证书校验会导致缓存失效&lt;/h2&gt;&lt;h3 id=&quot;%E7%8E%B0%E8%B1%A1-1&quot;&gt;现象&lt;/h3&gt;&lt;p&gt;原先的系统架构是先启动一个 mitmdump 服务监听 8888 端口，再使用一个基于 chromium 内核的浏览器，通过 &lt;code&gt;--proxy-server=localhost:8888&lt;/code&gt;  将流量指向代理服务，再通过 &lt;code&gt;--ignore-certificate-erros&lt;/code&gt; 参数忽略对 mitmdump 的自签名证书的校验，保证流量器正常访问。&lt;/p&gt;&lt;p&gt;同时为了减少图片、视频等带来的带宽损失，结合具体任务，在 mitmdump 的脚本里将视频、图片等相关的请求 drop 掉，保持对流量的高效利用。&lt;/p&gt;&lt;p&gt;本来这就是一个非常的朴素、透明、易理解的普通架构，线上也稳定运行了多年，没啥大的变动也没人想着改。不过近期业务流量逐渐大了起来，发现出口带宽有点撑不住了。于是增加了个对响应体的 Content-Type 监控，发现流量的大头竟然是 application/javascript 这一类的东西。&lt;/p&gt;&lt;p&gt;这显然不太合理，因为这些 javascript 资源理论上都是走的 cdn，数据都会带 Cache-Control 相关 header 方便浏览器进行本地缓存。在重复执行类似网页的时候，大概率应当会复用之前已经缓存好的 javascript 文件。&lt;/p&gt;&lt;h3 id=&quot;%E5%88%86%E6%9E%90-1&quot;&gt;分析&lt;/h3&gt;&lt;p&gt;仔细审查了一下正常浏览器请求和线上环境下请求的资源请求情况，果然发现了不同点。&lt;/p&gt;&lt;p&gt;本地环境：&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image-1.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image-1.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image-1.png 1000w, https://blog.mythsman.com/content/images/2023/03/image-1.png 1024w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;线上环境：&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image-2.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image-2.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image-2.png 1000w, https://blog.mythsman.com/content/images/2023/03/image-2.png 1024w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;可见本地环境的各种 javascript 资源在多次请求时都是要么命中了 memory cache ，要么命中了 disk cache，从而正常节省了流量。而 线上环境的各种 javascript 资源却只会命中 memory cache 而从未命中过 disk cache。&lt;/p&gt;&lt;p&gt;仔细对比了二者的环境下 chromium 的启动参数差别，多次实验后（&lt;strong&gt;需要注意每次实验之间一定要清空用户目录&lt;/strong&gt;）终于发现区别只在于 &lt;strong&gt;本地环境没有使用 mitmproxy 抓包，而线上环境配置了mitmproxy抓包 &lt;/strong&gt;。在本地环境下配置了 mitmproxy 抓包后终于复现了线上场景。&lt;/p&gt;&lt;p&gt;经过一番搜索，竟然在 MicrosoftEdge 的项目 &lt;a href=&quot;https://github.com/MicrosoftEdge/WebView2Feedback/issues/2634&quot;&gt;issue #2634&lt;/a&gt; 里找到了对 chromium 问题的解释，具体原因可以参见 &lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=110649#c8&quot;&gt;chromium&lt;/a&gt; 这里的解释：&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;Status:&lt;/strong&gt; WontFix : The rule is actually quite simple: any error with the certificate means the page will not be cached.&lt;/blockquote&gt;&lt;p&gt;没错，chromium 做了这样一个规定：&lt;strong&gt;证书错误的页面不会被持久化缓存&lt;/strong&gt;，即使你配置了忽略证书校验。&lt;/p&gt;&lt;h3 id=&quot;%E8%A7%A3%E5%86%B3-1&quot;&gt;解决&lt;/h3&gt;&lt;p&gt;问题原因发现了，解决起来也就容易了。至少有两种方案可以处理：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 mitmproxy 层基于 Http 的 Cache-Control 相关协议，自己实现一层静态资源的持久化缓存。&lt;/li&gt;&lt;li&gt;chromium 不配置 &lt;code&gt;--ignore-certificate-errors&lt;/code&gt; ，而是直接想办法将 mitmproxy 的证书种到 chromium 信任的 CA 里，保证对 TLS 流量的正常解析。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;实测下来，二者都能很好地优化大并发任务下的网络请求。javascript 相关请求量近似跌零，整体的流量会减少 70% 以上。不过总体看下来，方案二处理起来更加便捷和稳妥。&lt;/p&gt;&lt;h2 id=&quot;chromium-%E9%BB%98%E8%AE%A4%E4%B8%8D%E4%BF%A1%E4%BB%BB-linux-%E4%B8%8B%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%AF%81%E4%B9%A6&quot;&gt;Chromium 默认不信任 Linux 下的系统证书&lt;/h2&gt;&lt;h3 id=&quot;%E7%8E%B0%E8%B1%A1-2&quot;&gt;现象&lt;/h3&gt;&lt;p&gt;话接上一个问题的解决方案二，想将证书种到 chromium 中其实并不简单。一个 Ubuntu 下的通用种 mitmproxy 证书的方法是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从 &lt;code&gt;$HOME/.mitmproxy/mitmproxy-ca-cert.pem&lt;/code&gt; 中拿到 mitmproxy 的默认证书；或者自己用 openssl 生成一对证书+私钥，并放在 mitmproxy 的相应位置下。&lt;/li&gt;&lt;li&gt;将上述的 &lt;code&gt;mitmproxy-ca-cert.pem&lt;/code&gt;  复制到 &lt;code&gt;/usr/local/share/ca-certificates&lt;/code&gt; 下，并重命名为 &lt;code&gt;mitm.crt&lt;/code&gt;  （一定要以 crt 为后缀）。&lt;/li&gt;&lt;li&gt;执行 &lt;code&gt;update-ca-certificates&lt;/code&gt; ，会自动将 mitm.crt 按证书信息重命名并软链接到 &lt;code&gt;/etc/ssl/certs&lt;/code&gt; 中。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样搞完，例如 curl wget 等绝大多数应用就都能认得我们自签名的证书了。&lt;/p&gt;&lt;p&gt;可惜 chromium 不是这绝大多数，实测下来依然不信任我们已经种在系统 CA 里的自签名证书。&lt;/p&gt;&lt;h3 id=&quot;%E5%88%86%E6%9E%90-2&quot;&gt;分析&lt;/h3&gt;&lt;p&gt;其实不信任系统默认 CA 证书的事情也很常见，比如很多 App &lt;strong&gt;为了安全考虑&lt;/strong&gt;会自己做 SSL Pinning，不信任用户机器上的证书；或者像 Java 这种工具&lt;strong&gt;为了跨平台的考虑&lt;/strong&gt;也不会使用系统的证书，而是使用自己存储的 keystore。这里 Chromium 可能是也是出于类似考虑，反正也是默认只信任了自己安装时带过来的证书。对于用户新增的证书，也是希望直接通过软件本身的配置进行管理。&lt;/p&gt;&lt;p&gt;官方配置中添加自签名证书的方法是通过 &lt;code&gt;chrome://settings/certificates&lt;/code&gt;  自行导入。&lt;/p&gt;&lt;figure class=&quot;kg-card kg-image-card&quot;&gt;&lt;img src=&quot;https://blog.mythsman.com/content/images/2023/03/image-3.png&quot; class=&quot;kg-image&quot; alt=&quot;&quot; loading=&quot;lazy&quot; srcset=&quot;https://blog.mythsman.com/content/images/size/w600/2023/03/image-3.png 600w, https://blog.mythsman.com/content/images/size/w1000/2023/03/image-3.png 1000w, https://blog.mythsman.com/content/images/2023/03/image-3.png 1024w&quot; sizes=&quot;(min-width: 720px) 720px&quot;/&gt;&lt;/figure&gt;&lt;p&gt;不过显然，这中配置方式对于打镜像并不合适，我们还是要寻找通过配置文件进行配置的方案。&lt;/p&gt;&lt;h3 id=&quot;%E8%A7%A3%E5%86%B3-2&quot;&gt;解决&lt;/h3&gt;&lt;p&gt;一番搜索后，从 &lt;a href=&quot;https://superuser.com/questions/1695693/adding-self-signed-certificate-into-trusted-ca-on-chromium-for-linux&quot;&gt;superuser&lt;/a&gt; 中的这篇文章大概了解了 chromium 对自定义证书的管理方式。官方的说明是在 chromium 的 &lt;a href=&quot;https://chromium.googlesource.com/chromium/src.git/+/refs/heads/main/docs/linux/cert_management.md&quot;&gt;cert_management&lt;/a&gt; 文档中。&lt;/p&gt;&lt;p&gt;简而言之，Linux 下的 Chromium 使用的是公共 nssdb 来管理证书。数据存放在 &lt;code&gt;$HOME/.pki/nssdb&lt;/code&gt; 下。&lt;/p&gt;&lt;p&gt;如果这个目录不存在，那么在第一次打开 Chromium 时会自动创建。不过对于预构建的环境来说，这里还是需要自己事先初始化下的。&lt;/p&gt;&lt;p&gt;具体步骤如下：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;$ mkdir -p ~/.pki/nssdb                                       # 准备路径和文件夹

$ certutil -d ~/.pki/nssdb -N --empty-password                # 初始化DB环境

$ ls ~/.pki/nssdb/                                            # 查看DB文件
cert9.db  key4.db  pkcs11.txt

$ certutil -d ~/.pki/nssdb -L                                 # 查看证书信息（目前为空）

Certificate Nickname                                         Trust Attributes
                                                             SSL,S/MIME,JAR/XPI

$ certutil -d ~/.pki/nssdb -A -t &quot;C,,&quot; -n mitm -i ~/mitm.crt  # 将准备好的证书导入进 CA

$ certutil -d ~/.pki/nssdb -L                                 # 查看导入后的证书信息

Certificate Nickname                                         Trust Attributes
                                                             SSL,S/MIME,JAR/XPI

mitm                                                         C,,
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;正常情况下，这样处理是没有问题的，不过具体使用时，还是踩了一些坑。&lt;/p&gt;&lt;p&gt;注意到 chromium 文档中给出的所有 nssdb 相关指令的 -d 参数和我上述用的有所不同，多带了一个 &lt;code&gt;sql:&lt;/code&gt; 的前缀：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ certutil -d sql:$HOME/.pki/nssdb -L&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是因为在本地测试时，由于 bash 用习惯了，直接用 ~ 代替了 $HOME 。结果命令敲出来结果就是这样：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ certutil -d sql:~/.pki/nssdb -L
certutil: function failed: SEC_ERROR_BAD_DATABASE: security library: bad database.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;报了一个奇怪的错，想了半天没想明白问题出在哪，随手试了试将 &lt;code&gt;sql:&lt;/code&gt; 前缀干掉，发现一切又都能 work 了，也就是我上述记录的命令。&lt;/p&gt;&lt;p&gt;回头仔细看了下文档：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;       -d [prefix]directory
           Specify the database directory containing the certificate and key database files.

           certutil supports two types of databases: the legacy security databases (cert8.db, key3.db, and secmod.db) and new
           SQLite databases (cert9.db, key4.db, and pkcs11.txt).

           NSS recognizes the following prefixes:

           o   sql: requests the newer database

           o   dbm: requests the legacy database

           If no prefix is specified the default type is retrieved from NSS_DEFAULT_DB_TYPE. If NSS_DEFAULT_DB_TYPE is not set
           then dbm: is the default.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;原来 nssdb 是有两种模式的，可以通过为 -d 参数加不同前缀指定。但是坑爹的是如果指定了前缀，似乎就无法识别 bash 下的 ~ 。。。因此这里要么不用 ~ 、改用完整路径，要么就不指定 db ，使用默认配置即可。&lt;/p&gt;&lt;p&gt;最后，这个 pki 的文件权限也要注意，开启 chromium 的用户一定要对这个目录有&lt;strong&gt;读写权限&lt;/strong&gt;。一个稳妥的方法就是 &lt;code&gt;chown -R&lt;/code&gt; 一下，保证用户权限没问题。&lt;/p&gt;&lt;p&gt;这样一番配置后，终于可以在 &lt;code&gt;chrome://settings/certificates&lt;/code&gt; 下看到新增的自签名证书了。&lt;/p&gt;
    &lt;/section&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>19bddc1c1a55e1957bd0a1073980a663</guid>
<title>Go 错误处理：100+ 提案全部被拒绝，为何现阶段仍用 if err != nil？</title>
<link>https://toutiao.io/k/qxnnoy8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content               autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是煎鱼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些年给 Go 提新的错误处理提案的人络绎不绝，挡都挡不住。Ian Lance Taylor 作为历史的亲历者之一特意梳理了《&lt;span&gt;language: Go 2: error handling meta issue&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;》。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天结合我自己写过的内容分享给大家，以后有人再问可以甩给他们，这样他就懂前因后果了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;背景&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 2018 年 8 月，现任 Go 核心团队负责人 Russ Cox 给 Go2 的错误处理画了一个大大的蓝图，并介绍了一个未实现的设计草案。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5185185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4h0wTibBUMmh4XfVfKK0pvulNc22qMxiaibtic3LnictWdssau7mic631ZnmDQ2LbEdLvA3wSv5IKVQ5H6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体目标如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;期望 Go 的错误检查更轻量级，能够减少被大家吐槽的错误检查的程序文本数量。整体上要确保错误处理更加方便，复杂度不能变高。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;错误检查和错误处理都必须保持显式，这意味着在 Go 程序中是可见的。我们不想重复异常处理的陷阱。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;必须保证现有的 Go 代码的兼容性，不能有破坏性升级。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在此之后，也由于 Go 的热浪，许多新的提案作为 Go2 的错误处理变更提交，Go 邮件也有大量的讨论，拥有许多尝试，但&lt;strong&gt;迄今为止没有一个被接受&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是现在 Go 错误处理的背景。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;错误处理合集&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，这个合集并不 100% 全面，如果需要全查看一遍，可以自行在 go/issues 库搜索 error-handling 标签就可以了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以下是一些值得关注的错误处理提案合集：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;画过的大饼 Go2 check/handle 方法&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;常被提起的 try-catch 方法&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;像 Rust 用 ! ? 作为错误检查&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;简化 if err != nil {} 减少代码量&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;使用左侧函数和表达式来替代&lt;/strong&gt;：&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的基本是这几类，有许多雷同的，或被拒绝原因类似的提案，在社区管理上最终都会被指向到一起并关闭。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可以通过上述提案的前因后果，可以看到 Go 核心团队的一些衡量标杆。基本就是：&lt;strong&gt;显式、简洁、省心、好用&lt;/strong&gt;。这就是新错误处理提案的要求。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 的 “新” 错误处理已经经历了 3，5 年了，许多社区友人已经想了许多许多，也提出了许多提案。在 error-handling 标签下共有 100+ 个提案，无一幸免，全部被拒绝。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4444444444444444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4hfv3bRDNIRibReBP0vE3PSpdDpCgcOicphTQqLopUianicNoBAlLftkPlwn8pLZeX2BcvzySKXPnvic8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现阶段还是好好的用 if err != nil，也是许多人认可的。或是自己团队内封装一套共识标准，也是可以的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;让风再吹一会。也许不会改变了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;推荐阅读&lt;span/&gt;&lt;/h4&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;language: Go 2: error handling meta issue: &lt;em&gt;https://github.com/golang/go/issues/40432&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关注和加煎鱼微信，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一手消息和知识，拉你进技术交流群&lt;span&gt;&lt;span&gt;👇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9988738738738738&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KVl0giak5ib4jVkzHVvaqjo3O0BIqDRJKkEyib7SJsryxHBFGsvek0FkdiczfJP6AdbWnK25DvlX3dY8wRObPbVJQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;888&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07106598984771574&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/486RHs1WbcgGib6o96dHbvGUGGwPicd8wusUGH1cXR29tM4bO0lNzialzkQhvU6m5ZUdaKibmcF2OQayjMe9Bia6iaXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;394&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是煎鱼，&lt;span&gt;出版过 Go 畅销书《Go 语言编程之旅》，再到获得 GOP（Go 领域最有观点专家）荣誉，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxMDI4MDc1NA==&amp;amp;mid=2247483854&amp;amp;idx=1&amp;amp;sn=ec422fbf4d846975f2930ddeb5e81373&amp;amp;chksm=f9041493ce739d85a4b987eece14da627206cdad798f645cc770868312e4a22b6df24804f186&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;点击蓝字查看我的出书之路&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;点击蓝字查看我的出书之路&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;日常分享高质量文章，输出 Go 面试、工作经验、架构设计，&lt;span&gt;加微信拉读者交流群，和大家交流！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>2f8d13e1bf614c44a0dfd73e8891858a</guid>
<title>线上问题零发生，闲鱼稳定性问题治理与监控优化</title>
<link>https://toutiao.io/k/k8ay7s5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、灰度&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安全生产环境是由集团层面为保障线上稳定性的灰度流量生产环境。通过接入层网关的流量控制为环境提供1%线上流量+100%办公网流量，还原线上环境为系统验证提供场所。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;453&quot; data-backw=&quot;541&quot; data-ratio=&quot;0.8373382624768947&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/XxT9TiaJ1ibf3lkuGhR43dNLZ4lZotibVdwUXo1XAMQlcqNkEgnav9GWAf2icB0jD3BnRjAdtqRO1pOvnV9iblbOJiaSx9EwjXSib4W/640?wx_fmt=svg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;541&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们以安全生产环境为基础展开一系列治理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;常规场景下，安全生产流量能保证从入口到后续全链路都在安全生产环境闭环。但在闲鱼消息场景里，强依赖MQ做流量的负载均衡，而安全生产流量经过MQ之后会被均匀打散，逃逸到线上，失去灰度观察能力。针对该问题，我们通过spring的Conditional条件注入能力，将线上和安全生产的MQ bean隔离，从而将线上和安全生产MQ topic隔离，使流量能够在安全生产环境完整闭环。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;128&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.22595830531271016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/XxT9TiaJ1ibf3lkuGhR43dNLZ4lZotibVdwFvDCWGnY1vodPaenK8QxNvYraI7PiaRVex4ic7L7QgddWia8qhF15F9exHtFOXaDYiak/640?wx_fmt=svg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1487&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安全生产环境和生产环境的监控基线不同，告警阈值不同，为了能及时发现灰度问题，我们以安全生产环境的水位单独配置了监控告警。覆盖调用量、RT、错误量、消息延迟等多个指标维度，覆盖发送消息、创建会话等所有核心链路场景。我们将安全生产监控聚合成监控大盘，实时和线上监控水位做对比，不仅能发现变更引起的问题，还能发现变更对性能指标的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控告警是实时的异常指标监控，而离线报表是更长时间窗口的指标聚合。我们针对安全生产环境配置独立的离线监控报表，它不仅能发现细微波动的异常指标，也能发现变更对业务指标（例如消息到达率、点击率）的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化回归保障系统的底线，核心场景回归能避免引起严重的问题。我们将自动化回归与CICD集成，当发布到安全生产环境时自动执行自动化回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完善安全生产建设后，如果没有规范去标准化流程，建立行为准则同样达不到保障稳定性的目标。我们结合消息本身的业务特点，约定了消息团队内部的发布规范：发布必须在安全生产停留一晚，第二天灰度放量。确保：1. 覆盖时间相关的代码逻辑。2. 足够久的灰度观测。3. 产出t+1的离线监控报表&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、监控告警&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控告警的生命周期可以分为监控数据准备、监控配置、监控验证、告警配置、告警验证五个环节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;305&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5368126747437092&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DUwiayJ0Mj1GdDic1VabvGpFuLJfw0uorMIxXzLCL4JwWIJ1TPYZqVdL6SibKribj8SA3jK6lnqicGmEF3fzAY3JavA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1073&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控数据准备环节我们有完善的基础设施。基于这个基础，我们对监控告警进行覆盖率、及时性、有效性治理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;治理的第一个目标是要确保监控覆盖全，不遗漏。我们分为三步确保覆盖完整：1. 梳理出系统的核心场景链路，链路上的核心观测指标，查缺补漏监控告警。2. 通用的监控告警作为兜底，覆盖资源水位、接口调用、中间件性能等基础指标。3. 最后，通过监控告警离线报表整体性review监控告警覆盖率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;治理的第二个目标是能及时发现问题、有效发现问题。告警的及时性与有效性是互斥的关系，为达到告警及时性与有效性的最佳平衡，我们按照从严到松的方式逐步调整告警条件。同时为了持续维持告警及时性有效性，我们建立监控告警离线报表，定期review告警记录，对告警调优。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;监控告警治理需要持续投入，持续保鲜。我们搭建了监控告警离线报表，它包含所有的监控告警配置，告警历史流水，提供告警历史的聚合试图。为我们覆盖率治理、有效性治理提供全局视图，支撑我们定期对监控告警调优。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;691&quot; data-backw=&quot;568&quot; data-ratio=&quot;1.2169625246548323&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DUwiayJ0Mj1GdDic1VabvGpFuLJfw0uorMgHbTQpgEHuOEUUgn3d5sSjhMldYPVvoKWMWicYCrbI04wh8I89q8yeA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1014&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、自动化回归&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化回归的目标是保障底线，确保核心链路场景的稳定性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;端到端级别的自动化回归能从真实使用角度去验证稳定性。我们设计端到端的自动化回归用例，覆盖软件从安装、使用、卸载的完整生命周期，覆盖消息核心场景链路。我们将自动化回归与CICD集成，每天定时自动化回归，在发布流程做自动化回归卡口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;69&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.12115384615384615&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/XxT9TiaJ1ibf3lkuGhR43dNLZ4lZotibVdwD0HL1QlLiaM8IdrVB6yPMDIibPJvKKVYulnRz0Up05ibFBEV2TjhrYGA2icLNw4obcdj/640?wx_fmt=svg&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1040&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;176&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.3101851851851852&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DUwiayJ0Mj1GdDic1VabvGpFuLJfw0uorMef2e2qLK1Ayibgm7lDTO6YYqj6WF1RvEhiasxRfLvCJCxFUYyiaPdq7pg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;凤凰回放工具是基于JVMTI实现的流量回放测试工具。我们使用凤凰回放工具录制RPC流量，回放流量，diff结果，验证接口级别的稳定性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、依赖治理&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;依赖治理的目标是强弱依赖关系合理，并且弱依赖具备降级快恢能力。我们进行了以下治理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖梳理：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;代码级别review依赖的合理性，review是否具备降级快恢能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖改造：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对不合理的强依赖降级为弱依赖，完善弱依赖的监控告警，降级快恢预案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖演练：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;依赖演练是对依赖治理的验收环节。目的是验证强弱依赖关系和预期一致，避免出现“我以为”但“实际是”的问题，同时验证弱依赖的问题发现能力，降级快恢能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>47df2d2eccd653fe8e7efab4ff5f37ca</guid>
<title>查漏补缺：Hive 技术原理</title>
<link>https://toutiao.io/k/9vnuwgn</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content               defaultNoSetting&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mp-common-profile&quot; data-from=&quot;0&quot; data-id=&quot;Mzg3NjIyNjQwMg==&quot; data-alias=&quot;edw_bigdata&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/1OYP1AZw0W0uTPxUPEdVxh33qRPicSlCKPqmeccGfgXTibjkHibQC27iaqJPfCa83dK6rP50ZTRutzPYK57W96Ah6w/0?wx_fmt=png&quot; data-nickname=&quot;数据仓库与Python大数据&quot; data-signature=&quot;大数据、数仓、分析，Java、Hadoop/Spark/Flink、ClickHouse、Doris、Druid，面试、课程推荐、AI/BI&quot; data-weui-theme=&quot;light&quot;/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;Hive概述&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库的概念：&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;传统数据仓库面临的挑战：&lt;/h2&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;无法满足快速增长的海量数据存储需求。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;无法有效处理不同类型的数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;计算和处理能力不足。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive简介：&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Hive是一个构建于Hadoop顶层的&lt;strong&gt;数据仓库工具&lt;/strong&gt;，可以查询和管理PB级别的分布式数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;支持大规模数据存储、分析，具有良好的可扩展性&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;某种程度上可以看作是&lt;strong&gt;用户编程接口&lt;/strong&gt;，本身不存储和处理数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;依赖分布式文件系统HDFS存储数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;依赖分布式并行计算模型MapReduce处理数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;定义了简单的类似SQL 的查询语言——HiveQL。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;用户可以通过编写的HiveQL语句运行MapReduce任务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到Hadoop平台上。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;是一个可以提供有效、合理、直观组织和使用数据的分析工具。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive具有的特点非常适用于数据仓库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;（1）采用批处理方式处理海量数据&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Hive需要把HiveQL语句转换成MapReduce任务进行运行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据仓库存储的是静态数据，对静态数据的分析适合采用批处理方式，不需要快速响应给出结果，而且数据本身也不会频繁变化。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;（2）提供适合数据仓库操作的工具&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Hive本身提供了一系列对数据进行&lt;strong&gt;提取、转换、加载（ETL）&lt;/strong&gt;的工具，可以存储、查询和分析存储在Hadoop中的大规模数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;这些工具能够很好地满足数据仓库各种应用场景。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;（3）支持MapReduce，Tez，Spark等多种计算引擎。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;（4）可以直接访问HDFS文件以及HBase。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;（5）易用易编程&lt;/strong&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive与Hadoop生态系统中其他组件的关系：&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5064935064935064&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3NCX2okxhsEPxxTXFFK4VR5Zrnc5eb1AraNYk0icn9eKchuBdBrqMYWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;539&quot;/&gt;&lt;figcaption&gt;Hadoop&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：Hadoop生态系统&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Hive依赖于HDFS 存储数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Hive依赖于MapReduce 处理数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在某些场景下Pig可以作为Hive的替代工具&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HBase 提供数据的实时访问&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive的优缺点：&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive的优点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;高可靠、高容错：HiveServer采用集群模式。双MetaStor。超时重试机制。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;类SQL：类似SQL语法，内置大量函数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可扩展：自定义存储格式，自定义函数。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;多接口：Beeline，JDBC，ODBC，Python，Thrift。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive的缺点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;延迟较高：默认MR为执行引擎，MR延迟较高。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不支持雾化视图：Hive支持普通视图，不支持雾化视图。Hive不能再视图上更新、插入、删除数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不适用OLTP：暂不支持列级别的数据添加、更新、删除操作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;暂不支持存储过程：当前版本不支持存储过程，只能通过UDF来实现一些逻辑处理。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive与传统数据库的对比分析：&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive在很多方面和传统的关系数据库类似，但是它的底层依赖的是HDFS和MapReduce，所以在很多方面又有别于传统数据库。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5747711088504578&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa32PQzm2EtibH6ia0WD1c4u8aKGQxfm7l1uvq03wySLoSAFNGRI9nVCWkQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;983&quot;/&gt;&lt;figcaption&gt;对比1&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.48185483870967744&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3UEWg7gheCJA1IHNEibQIGQic0xLVSLDMBictQXJMuJvV3ichr6lfTibWfIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;992&quot;/&gt;&lt;figcaption&gt;对比2&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive在企业中的部署和作用：&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;Hive在企业大数据分析平台中的应用：&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5505952380952381&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa391d2CIrSpx8A3w9jTquNibciaS3JKCXryK48nwzlGOMOY8KXLI8ZiaCyg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;672&quot;/&gt;&lt;figcaption&gt;Hive&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：企业中一种常见的大数据分析平台部署框架&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;Hive在Facebook公司中的应用：&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;基于Oracle的数据仓库系统已经无法满足激增的业务需求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Facebook公司开发了数据仓库工具Hive，并在企业内部进行了大量部署&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;Hive在FusionInsight中的位置：&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4108053007135576&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3D0OmMfynLbovMpOTXPcNVfrb1dv9LOkNkkTq51lkKEtIDyawnjZ9fg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;981&quot;/&gt;&lt;figcaption&gt;位置&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：Hive在FusionInsight中的位置&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive是一种数据仓库处理工具，使用类SQL的HiveQL语言实现数据查询功能，所有的Hive数据都存储在HDFS中。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive应用场景：&lt;/h2&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据挖掘：用户行为分析；兴趣分区；区域展示；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;非实时分析：日志分析；文本分析。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据汇总：每天/每周用户点击数，流量统计。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据仓库：数据抽取，加载，转换（ETL）。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;Hive功能与架构&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive系统架构：&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5887708649468892&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa37SDvAZtH7RicjIpyOYM2156gVguiaZPHmxguuTFw9cBsYXYjfvD8ziaZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;659&quot;/&gt;&lt;figcaption&gt;架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5394605394605395&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa39bO5y1gY6a3HK0fvgWWhiaiaqXgGE6GW2T8WvVSlXbSUORyjGnB8ALoQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1001&quot;/&gt;&lt;figcaption&gt;Hive架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：Hive系统架构&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用户接口模块包括CLI、HWI、JDBC、ODBC、Thrift Server。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;驱动模块（Driver）包括编译器、优化器、执行器等，负责把HiveSQL语句转换成一系列MapReduce作业。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;元数据存储模块（Metastore）是一个独立的关系型数据库（自带derby数据库，或MySQL数据库）。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;FusionInsight HD中Hive的架构：&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7281746031746031&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3kwnG94dhibg4pOzlaQPCicMAFXNeul5OaCB3TYU5O5qPw0LXVO1ibb4GA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;504&quot;/&gt;&lt;figcaption&gt;Fusion&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：FusionInsight中Hive的架构&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive分为三个角色：HiveServer、MetaStore、WebHcat。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;HiveServer：将用户提交的HQL语句进行编译，解析成对应的Yarn任务，Spark任务或者HDFS操作，从而完成数据的提取，转换，分析。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MetaStroe：提供元数据服务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;WebHcat：对外提供基于Htpps洗衣的元数据访问、DDL查询等服务。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;HCatalog架构：&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.42560553633217996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3yhRG6C8cwqWBciaiaxydhyCpdy3Nv3TTnx2g7cSCmTfg0g3H9lbKtBiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;867&quot;/&gt;&lt;figcaption&gt;HCatalog&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：HCatalog架构&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HCatalog包括Hcatalog Client和Hcatalog Server：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;HCatalog CLient包括命令行工具CLI和Clent jar包（用于给Pig， MR提供元数据读写支持）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HCatalog通过Hive提供的HiveMetaStoreClent对象来间接访问MetaStore。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HCatalog对外提供Hcatloader，HCatinputFormat来读取数据；提供HCatStore,HCatOutputFormat来写入数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;WebHCat架构：&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3975225225225225&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3TxicjYiap714EOH8NvHKBmMoSmLpWcKQJudgmPpN95OjwUFVn4vSG0fA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;888&quot;/&gt;&lt;figcaption&gt;WebHCat架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：WebHCat架构&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WebHCat提供Rest接口，是用户能够通过安全的HTTPS协议执行以下操作：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;执行Hive DDL操作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;运行Hive HQL任务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;运行MapReduce任务。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive数据存储模型：&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.545934530095037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3kwbDXdD7uJJicop4iaHt2XBh11bJV6FlrP5ShEuQb9KibRFN8icgqj7oibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;947&quot;/&gt;&lt;figcaption&gt;数据存储模型&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：Hive数据存储模型&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;分区：数据表可以按照某个字段的值划分分区。&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;每个分区是一个目录。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分区数量不固定。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分区下可再有分区或者桶。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;桶：数据可以根据桶的方式将不同数据放入不同的桶中。&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;每个桶是一个文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;建表时指定桶个数，桶内可排序。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据按照某个字段的值Hash后放入某个桶中。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Hive可以创建托管表和外部表：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;默认创建托管表，Hiva会将数据移动到数据仓库的目录。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;创建外部表，这时Hiva会到仓库目录以外的位置访问数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果所有处理都由Hive完成，建议使用托管表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果要用Hive和其他工具来处理同一个数据集，建议使用外部表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.18775510204081633&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3IQxCUhfyrFtFHSicv5TKyNbxZ5RiaWibrdVW3wQTtXJTNRBASPGZs9BiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;980&quot;/&gt;&lt;figcaption&gt;区别&lt;/figcaption&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Hive支持的函数：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hive内置函数：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据函数：如round(),fllor(), abs(), rand()等。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;日期函数：如to_date(), month(), day().&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;字符串函数,如trim(), length(), substr()等。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;UDF（User-Defined Funcation）用户自定义函数。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive工作原理：&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;（1）SQL语句转换成MapReduce作业的基本原理：&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4228855721393035&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3866tggeQWsE5OmeKKNtvoy1ibeibSicfL31v80TSBeibTeckgRlrhutHicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1005&quot;/&gt;&lt;figcaption&gt;jion&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：join的实现原理&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.257396449704142&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3FxZXBrbwqdT6IVicn1ViassMUjEiaGhsLl2eT3N4oPxJHguwkiaAsUM7DQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1014&quot;/&gt;&lt;figcaption&gt;group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：group by实现原理&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;存在一个分组（Group By）操作，其功能是把表Score的不同片段按照rank和level的组合值进行合并，计算不同rank和level的组和值分别有几条记录。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;（2）Hive中SQL查询转换成MapReduce作用的过程：&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;驱动模块接收该命令或查询编译器&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对该命令或查询进行解析编译&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;由优化器对该命令或查询进行优化计算&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;该命令或查询通过执行器进行执行&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;详细如果如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.1004273504273505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/wbiax4xEAl5yUn2JdjEd9icEdh6wVSZLa3qicK4TEJRGByv7KkpyKcobJibCmQX9p6pmNBdmn534WJuCsrA7nZngicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;468&quot;/&gt;&lt;figcaption&gt;过程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图：SQL查询转换成MapReduce作业的过程&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第1步：由Hive驱动模块中的编译器对用户输入的SQL语言进行词法和语法解析，将SQL语句转化为抽象语法树的形式。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第2步：抽象语法树的结构仍很复杂，不方便直接翻译为MapReduce算法程序，因此，把抽象语法书转化为查询块。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第3步：把查询块转换成逻辑查询计划，里面包含了许多逻辑操作符。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第4步：重写逻辑查询计划，进行优化，合并多余操作，减少MapReduce任务数量。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第5步：将逻辑操作符转换成需要执行的具体MapReduce任务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第6步：对生成的MapReduce任务进行优化，生成最终的MapReduce任务执行计划。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第7步：由Hive驱动模块中的执行器，对最终的MapReduce任务进行执行输出。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;几点说明：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;当启动MapReduce程序时，Hive本身是不会生成MapReduce算法程序的。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;需要通过一个表示“Job执行计划”的XML文件驱动执行内置的、原生的Mapper和Reducer模块。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Hive通过和JobTracker通信来初始化MapReduce任务，不必直接部署在JobTracker所在的管理节点上执行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通常在大型集群上，会有专门的网关机来部署Hive工具。网关机的作用主要是远程操作和管理节点上的JobTracker通信来执行任务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据文件通常存储在HDFS上，HDFS由名称节点管理。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;#Hive增强特性&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive增强特性-Colocation：&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Colocation（同分布）：将存在关联关系的数据或可能进行管理操作的数据存储在相同的存储节点上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;文件级同分布实现文件的快速访问，避免了因数据搬迁带来的大量网络开销。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive增强特性–Hbase记录批量删除：&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在Hive on HBase功能汇总，FusionInsight HD Hive提供了对HBase表的单条数据的删除功能，通过特定的语法，Hive可以将HBase表中符合条件的一条或多条数据批量清除。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Hive增强特性–流控特性：&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过流控特性，可以实现：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;当前已经建立连接数据阈值控制。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每个用户已经建立的连接数阈值控制。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;单位时间内所有建立的连接数阈值控制。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-darkmode-bgcolor-16102099990498=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16102099990498=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16102099990498=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16102099990498=&quot;#fff|rgb(89, 89, 89)&quot; data-style=&quot;max-width: 100%; color: rgb(89, 89, 89); font-size: 15px; white-space: normal; background-color: rgb(255, 255, 255); letter-spacing: 0.476px; font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; text-align: center; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;&quot; data-darkmode-bgcolor-16102884766773=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16102884766773=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16102884766773=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16102884766773=&quot;#fff|rgb(89, 89, 89)&quot; data-darkmode-bgcolor-16103750791461=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16103750791461=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16103750791461=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16103750791461=&quot;#fff|rgb(89, 89, 89)&quot; data-darkmode-bgcolor-16105436693842=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16105436693842=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16105436693842=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16105436693842=&quot;#fff|rgb(89, 89, 89)&quot;&gt;&lt;span data-darkmode-color-16095769899562=&quot;rgb(255, 23, 0)&quot; data-darkmode-original-color-16095769899562=&quot;rgb(255, 0, 0)&quot; data-style=&quot;max-width: 100%; color: rgb(255, 0, 0); font-size: 14px; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;&quot; data-darkmode-bgcolor-16102099990498=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16102099990498=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16102099990498=&quot;rgb(255, 23, 0)&quot; data-darkmode-original-color-16102099990498=&quot;#fff|rgb(89, 89, 89)|rgb(255, 0, 0)&quot; data-darkmode-bgcolor-16102884766773=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16102884766773=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16102884766773=&quot;rgb(255, 23, 0)&quot; data-darkmode-original-color-16102884766773=&quot;#fff|rgb(89, 89, 89)|rgb(255, 0, 0)&quot; data-darkmode-bgcolor-16103750791461=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16103750791461=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16103750791461=&quot;rgb(255, 23, 0)&quot; data-darkmode-original-color-16103750791461=&quot;#fff|rgb(89, 89, 89)|rgb(255, 0, 0)&quot; data-darkmode-bgcolor-16105436693842=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16105436693842=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16105436693842=&quot;rgb(255, 23, 0)&quot; data-darkmode-original-color-16105436693842=&quot;#fff|rgb(89, 89, 89)|rgb(255, 0, 0)&quot;&gt;回复：Hive，领取资料&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mp-common-profile&quot; data-from=&quot;0&quot; data-id=&quot;Mzg3NjIyNjQwMg==&quot; data-alias=&quot;edw_bigdata&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/1OYP1AZw0W0uTPxUPEdVxh33qRPicSlCKPqmeccGfgXTibjkHibQC27iaqJPfCa83dK6rP50ZTRutzPYK57W96Ah6w/0?wx_fmt=png&quot; data-nickname=&quot;数据仓库与Python大数据&quot; data-signature=&quot;大数据、数仓、分析，Java、Hadoop/Spark/Flink、ClickHouse、Doris、Druid，面试、课程推荐、AI/BI&quot; data-weui-theme=&quot;light&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;推荐阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;amp;mid=2247523880&amp;amp;idx=1&amp;amp;sn=05ae5749db8fdba4ecc817eeffe88d9f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; localeditorid=&quot;2h0unzg1peg0000000&quot;&gt;数据能力体系NO1：数据探查&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2、&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg3NjIyNjQwMg==&amp;amp;mid=2247523881&amp;amp;idx=1&amp;amp;sn=c74486c30a8fc1cd078eb57d1b427107&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; localeditorid=&quot;43vwtr2xyig0000000&quot;&gt;数据能力体系NO2：数据验证&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;10000&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>de46983cc83300c3fedc3b08c60c0b45</guid>
<title>复杂度分析：如何分析、统计算法的执行效率和资源消耗</title>
<link>https://toutiao.io/k/mt22bnf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;&lt;strong&gt;作者：京东物流 崔旭&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们都知道，数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。&lt;/p&gt;

&lt;h3&gt;1 为什么需要复杂度分析？&lt;/h3&gt;

&lt;p&gt;你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比实实在在跑一遍得到的数据更准确吗？&lt;/p&gt;

&lt;p&gt;首先可以肯定地说，这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。&lt;/p&gt;

&lt;h4&gt;1.1 测试结果非常依赖测试环境&lt;/h4&gt;

&lt;p&gt;测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。&lt;/p&gt;

&lt;h4&gt;1.2 测试结果受数据规模的影响很大&lt;/h4&gt;

&lt;p&gt;对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！&lt;/p&gt;

&lt;p&gt;所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法，这就是我们接下来要说的大O复杂度表示法。&lt;/p&gt;

&lt;h3&gt;2 大O复杂度表示法&lt;/h3&gt;

&lt;p&gt;算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？&lt;/p&gt;

&lt;p&gt;这里有段非常简单的代码，求 1,2,3…n 的累加和。现在，一块来估算一下这段代码的执行时间吧。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/ab6a5ba0-ad13-45b4-a98d-0715c36e20c020220421141047.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？&lt;/p&gt;

&lt;p&gt;第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n_unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)_unit_time。可以看出来，所有代码的执行时间 T(n) 与每行代码的执行次数成正比。&lt;/p&gt;

&lt;p&gt;按照这个分析思路，我们再来看这段代码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/9e84fa78-747e-44da-a646-a296db81107720220421141103.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？&lt;/p&gt;

&lt;p&gt;第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n_unit_time 的执行时间，第 7、8 行代码循环执行了 n²遍，所以需要 2n²_unit_time 的执行时间。所以，整段代码总的执行时间 T(n) = (2n²+2n+3)*unit_time。&lt;/p&gt;

&lt;p&gt;尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/3fe49660-5e63-4fed-b731-5db9eb2baec620220421141119.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。&lt;/p&gt;

&lt;p&gt;所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = (2n²+2n+3)。这就是大O时间复杂度表示法。大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度，简称时间复杂度。&lt;/p&gt;

&lt;p&gt;当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n²)。&lt;/p&gt;

&lt;h3&gt;3 时间复杂度分析&lt;/h3&gt;

&lt;p&gt;前面介绍了大 O 时间复杂度的由来和表示方法。现在我们来看下，如何分析一段代码的时间复杂度？&lt;/p&gt;

&lt;h4&gt;3.1 只关注循环执行次数最多的一段代码&lt;/h4&gt;

&lt;p&gt;大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。&lt;/p&gt;

&lt;p&gt;为了便于你理解，我还拿前面的例子来说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/4a89e370-66b7-410b-acde-35ef6706fc0d20220421141153.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。&lt;/p&gt;

&lt;h4&gt;3.2 加法法则：总复杂度等于量级最大的那段代码的复杂度&lt;/h4&gt;

&lt;p&gt;这里还有一段代码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/2213964c-18de-45de-8278-85cd6566cf5820220421141237.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。&lt;/p&gt;

&lt;p&gt;第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。&lt;/p&gt;

&lt;p&gt;即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。&lt;/p&gt;

&lt;p&gt;那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n²)。&lt;br/&gt;
综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n²)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：&lt;/p&gt;

&lt;p&gt;如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).&lt;/p&gt;

&lt;h4&gt;3.3 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积&lt;/h4&gt;

&lt;p&gt;刚讲了一个复杂度分析中的加法法则，这儿还有一个乘法法则。类比一下，你应该能“猜到”公式是什么样子的吧？&lt;/p&gt;

&lt;p&gt;如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)_T2(n)=O(f(n))_O(g(n))=O(f(n)*g(n)).&lt;/p&gt;

&lt;p&gt;也就是说，假设 T1(n) = O(n)，T2(n) = O(n²)，则 T1(n) * T2(n) = O(n³)。落实到具体的代码上，我们可以把乘法法则看成是嵌套循环，我举个例子给你解释一下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/a0a7d038-e8e8-43d0-bb8a-a1c5511f6d4320220421141312.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n)_T2(n) = O(n_n) = O(n²)。&lt;/p&gt;

&lt;h4&gt;3.4 几种常见时间复杂度实例分析&lt;/h4&gt;

&lt;p&gt;虽然代码千差万别，但是常见的复杂度量级并不多。稍微总结了一下，这些复杂度量级几乎涵盖了大部分的场景。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;  常量阶 O(1)&lt;/li&gt;
&lt;li&gt;  对数阶 O(logn)&lt;/li&gt;
&lt;li&gt;  线性阶 O(n)&lt;/li&gt;
&lt;li&gt;  线性对数阶 O(nlogn)&lt;/li&gt;
&lt;li&gt;  平方阶 O(n²)&lt;/li&gt;
&lt;li&gt;  立方阶 O(n³) …&lt;/li&gt;
&lt;li&gt;  指数阶 O(2ⁿ)&lt;/li&gt;
&lt;li&gt;  阶乘阶 O(n!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2ⁿ) 和 O(n!)。&lt;/p&gt;

&lt;p&gt;当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。我们主要来看几种常见的多项式时间复杂度。&lt;/p&gt;

&lt;p&gt;1.O(1)&lt;/p&gt;

&lt;p&gt;首先你必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/fc055270-4406-46a2-b46c-ec4a77d381c120220421141358.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。&lt;/p&gt;

&lt;p&gt;2.O(logn)、O(nlogn)&lt;/p&gt;

&lt;p&gt;对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/650a7d56-035d-4dd0-8e82-123f66f5f6ff20220421141417.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。&lt;br/&gt;
从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。&lt;/p&gt;

&lt;p&gt;实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/cee2d15e-1c19-42bd-a73a-4d4dc31edb9c20220421141436.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2ˣ=n 求解 x ，x=log₂n，所以，这段代码的时间复杂度就是 O(log₂n)。&lt;/p&gt;

&lt;p&gt;现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/0082ab49-cab2-43a6-aff3-779805e4560e20220421141533.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 O(log₃n)。&lt;/p&gt;

&lt;p&gt;实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？&lt;/p&gt;

&lt;p&gt;我们知道，对数之间是可以互相转换的，log₃n 就等于 log₃2_log₂n，所以 O(log₃n) = O(C_log₂n)，其中 C=log₃2 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log₂n) 就等于 O(log₃n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。&lt;/p&gt;

&lt;p&gt;如果你理解了O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。&lt;/p&gt;

&lt;p&gt;3.O(m+n)、O(m*n)&lt;/p&gt;

&lt;p&gt;我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。老规矩，先看代码！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/979b91f5-cc4e-4c2c-8e87-2833ac14c31b20220421141600.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。&lt;/p&gt;

&lt;p&gt;针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)_T2(n) = O(f(m)_f(n))。&lt;/p&gt;

&lt;h3&gt;4 空间复杂度分析&lt;/h3&gt;

&lt;p&gt;前面，咱们花了很长时间讲大 O 表示法和时间复杂度分析，理解了前面讲的内容，空间复杂度分析方法学起来就非常简单了。&lt;/p&gt;

&lt;p&gt;时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。&lt;/p&gt;

&lt;p&gt;还是拿具体的例子来说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/68c88ae8-c5cc-4e58-98f2-faed38b7de3b20220421141628.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。&lt;br/&gt;
我们常见的空间复杂度就是 O(1)、O(n)、O(n²)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。&lt;/p&gt;

&lt;h3&gt;5 内容小结&lt;/h3&gt;

&lt;p&gt;复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n²)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.jcloudcs.com/developer.jdcloud.com/61faa60a-a6da-416c-98ba-92605400733820220421141647.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>