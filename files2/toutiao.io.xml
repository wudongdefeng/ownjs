<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>812df417fd1927d52a066c602da6541c</guid>
<title>如何高效实现 MySQL 与 elasticsearch 的数据同步</title>
<link>https://toutiao.io/k/xr4jhju</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-1g0fqss&quot; options=&quot;[object Object]&quot;&gt;&lt;p data-first-child=&quot;&quot; data-pid=&quot;KDJQDYCT&quot;&gt;MySQL 自身简单、高效、可靠，是又拍云内部使用最广泛的数据库。但是当数据量达到一定程度的时候，对整个 MySQL 的操作会变得非常迟缓。而公司内部 robin/logs 表的数据量已经达到 800w，后续又有全文检索的需求。这个需求直接在 MySQL 上实施是难以做到的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;原数据库的同步问题&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;19P-zNF-&quot;&gt;由于传统的 mysql 数据库并不擅长海量数据的检索，当数据量到达一定规模时（估算单表两千万左右），查询和插入的耗时会明显增加。同样，当需要对这些数据进行模糊查询或是数据分析时，MySQL作为事务型关系数据库很难提供良好的性能支持。使用适合的数据库来实现模糊查询是解决这个问题的关键。&lt;/p&gt;&lt;p data-pid=&quot;lY26vljW&quot;&gt;但是，切换数据库会迎来两个问题，一是已有的服务对现在的MySQL 重度依赖，二是 MySQL 的事务能力和软件生态仍然不可替代，直接迁移数据库的成本过大。我们综合考虑了下，决定同时使用多个数据库的方案，不同的数据库应用于不同的使用场景。而在支持模糊查询功能的数据库中，elasticsearch 自然是首选的查询数据库。这样后续对业务需求的切换也会非常灵活。那具体该如何实现呢？在又拍云以往的项目中，也有遇到相似的问题。之前采用的方法是在业务中编写代码，然后同步到 elasticsearch 中。具体是这样实施的：每个系统编写特定的代码，修改MySQL 数据库后，再将更新的数据直接推送到需要同步的数据库中，或推送到队列由消费程序来写入到数据库中。但这个方案有一些明显的缺点：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;3cQl1e0O&quot;&gt;系统高耦合，侵入式代码，使得业务逻辑复杂度增加&lt;/li&gt;&lt;li data-pid=&quot;GjW5oeM1&quot;&gt;方案不通用，每一套同步都需要额外定制，不仅增加业务处理时间，还会提升软件复复杂度&lt;/li&gt;&lt;li data-pid=&quot;wx1jAY_F&quot;&gt;工作量和复杂度增加&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;Tptwq0hC&quot;&gt;在业务中编写同步方案，虽然在项目早期比较方便，但随着数据量和系统的发展壮大，往往最后会成为业务的大痛点。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;解决思路及方案&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;DzlPK9IZ&quot;&gt;&lt;b&gt;调整架构&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;1gqx58V-&quot;&gt;既然以往的方案有明显的缺点，那我们如何来解决它呢？优秀的解决方案往往是 “通过架构来解决问题“，那么能不能通过架构的思想来解决问题呢？答案是可以的。我们可以将程序伪装成 “从数据库”，主库的增量变化会传递到从库，那这个伪装成 “从数据库” 的程序就能实时获取到数据变化，然后将增量的变化推送到消息队列 MQ，后续消费者消耗 MQ 的数据，然后经过处理之后再推送到各自需要的数据库。这个架构的核心是通过监听MySQL的 binlog 来同步增量数据，通过基于 query 的查询旧表来同步旧数据，这就是本文要讲的一种异构数据库同步的实践。&lt;/p&gt;&lt;p data-pid=&quot;0FtCXIc4&quot;&gt;&lt;b&gt;改进数据库&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;EVybRWaP&quot;&gt;经过深度的调研，成功得到了一套异构数据库同步方案，并且成功将公司生产环境下的 robin/logs 的表同步到了 elasticsearch 上。首先对MySQL开启 binlog，但是由于 maxwell 需要的 binlog_format=row 原本的生产环境的数据库不宜修改。这里请教了海杨前辈，他提供了”从库联级“的思路，在从库中监听 binlog 绕过了操作生产环境重启主库的操作，大大降低了系统风险。后续操作比较顺利，启动 maxwell 监听从库变化，然后将增量变化推送到 kafka ，最后配置 logstash 消费 kafka中的数据变化事件信息，将结果推送到 elasticsearch。配置 logstash需要结合表结构，这是整套方案实施的重点。这套方案使用到了kafka、maxwell、logstash、elasticsearch。其中 elasticsearch  与 kafka已经在生产环境中有部署，所以无需单独部署维护。而 logstash 与 maxwell 只需要修改配置文件和启动命令即可快速上线。整套方案的意义不仅在于成本低，而且可以大规模使用，公司内有MySQL同步到其它数据库的需求时，都可以上任。&lt;/p&gt;&lt;p data-pid=&quot;0kDnjCAe&quot;&gt;&lt;b&gt;成果展示前后对比&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;BgUULVOz&quot;&gt;- 使用该方案同步和业务实现同步的对比&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0994dfb3d0939658fe8552020debfffb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;557&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-0994dfb3d0939658fe8552020debfffb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;557&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-0994dfb3d0939658fe8552020debfffb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0994dfb3d0939658fe8552020debfffb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;K5Fx96rT&quot;&gt;- 写入到 elasticsearch 性能对比 (8核4G内存)&lt;/p&gt;&lt;table data-draft-node=&quot;block&quot; data-draft-type=&quot;table&quot; data-size=&quot;normal&quot; data-row-style=&quot;normal&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;项目&lt;/td&gt;&lt;td&gt;logstash&lt;/td&gt;&lt;td&gt;业务同步&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;写入速度&lt;/td&gt;&lt;td&gt;1500 条/s&lt;/td&gt;&lt;td&gt;200 条/s&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p data-pid=&quot;NP83mScH&quot;&gt;经过对比测试，800w 数据量全量同步，使用 logstash 写到 elasticsearch，实际需要大概 3 小时，而旧方案的写入时间需要 2.5 天。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;方案实施细节&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;gVWClv2R&quot;&gt;接下来，我们来看看具体是如何实现的。本方案无需编写额外代码，非侵入式的，实现MySQL 数据与 elasticsearch 数据库的同步。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b24ba5889f6c43f49414e524a0113948_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;630&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-b24ba5889f6c43f49414e524a0113948_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;630&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-b24ba5889f6c43f49414e524a0113948_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b24ba5889f6c43f49414e524a0113948_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p data-pid=&quot;0ZEhOMtP&quot;&gt;下列是本次方案需要使用所有的组件：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;5X9B0ssr&quot;&gt;MySQL&lt;/li&gt;&lt;li data-pid=&quot;lGcARPHM&quot;&gt;Kafka&lt;/li&gt;&lt;li data-pid=&quot;gMW17m4M&quot;&gt;Maxwell（监听 binlog）&lt;/li&gt;&lt;li data-pid=&quot;icxDk0Mh&quot;&gt;Logstash（将数据同步给 elasticsearch）&lt;/li&gt;&lt;li data-pid=&quot;eF6q7Rv3&quot;&gt;Elasticsearch&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;VbSh-5VU&quot;&gt;&lt;b&gt;1. MySQL配置&lt;/b&gt;&lt;/p&gt;&lt;blockquote data-pid=&quot;p17ynMhW&quot;&gt;本次使用 MySQL 5.5 作示范，其他版本的配置可能稍许不同需要&lt;/blockquote&gt;&lt;p data-pid=&quot;6hzEnmcV&quot;&gt;首先我们需要增加一个数据库只读的用户，如果已有的可以跳过。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;-- 创建一个 用户名为 maxwell 密码为 xxxxxx 的用户
CREATE USER &#x27;maxwell&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;XXXXXX&#x27;;
GRANT ALL ON maxwell.* TO &#x27;maxwell&#x27;@&#x27;localhost&#x27;;
GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO &#x27;maxwell&#x27;@&#x27;%&#x27;;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;RAGg-2Kj&quot;&gt;开启数据库的 `binlog`，修改 `mysql` 配置文件，注意 `maxwell` 需要的 `binlog` 格式必须是`row`。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# /etc/mysql/my.cnf

[mysqld]
# maxwell 需要的 binlog 格式必须是 row
binlog_format=row

# 指定 server_id 此配置关系到主从同步需要按情况设置，
# 由于此mysql没有开启主从同步，这边默认设置为 1
server_id=1

# logbin 输出的文件名， 按需配置
log-bin=master&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;YCOlqWcE&quot;&gt;重启MySQL 并查看配置是否生效：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;sudo systemctl restart mysqld &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select @@log_bin;
-- 正确结果是 1
select @@binlog_format;
-- 正确结果是 ROW&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;lxxfvotH&quot;&gt;如果要监听的数据库开启了主从同步，并且不是主数据库，需要再从数据库开启 binlog 联级同步。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# /etc/my.cnf
log_slave_updates = 1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;h7kh4GCB&quot;&gt;需要被同步到 elasticsearch 的表结构。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;-- robin.logs
show create table robin.logs;

-- 表结构
CREATE TABLE `logs` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `content` text NOT NULL,
  `user_id` int(11) NOT NULL,
  `status` enum(&#x27;SUCCESS&#x27;,&#x27;FAILED&#x27;,&#x27;PROCESSING&#x27;) NOT NULL,
  `type` varchar(20) DEFAULT &#x27;&#x27;,
  `meta` text,
  `created_at` bigint(15) NOT NULL,
  `idx_host` varchar(255) DEFAULT &#x27;&#x27;,
  `idx_domain_id` int(11) unsigned DEFAULT NULL,
  `idx_record_value` varchar(255) DEFAULT &#x27;&#x27;,
  `idx_record_opt` enum(&#x27;DELETE&#x27;,&#x27;ENABLED&#x27;,&#x27;DISABLED&#x27;) DEFAULT NULL,
  `idx_orig_record_value` varchar(255) DEFAULT &#x27;&#x27;,
  PRIMARY KEY (`id`),
  KEY `created_at` (`created_at`)
) ENGINE=InnoDB AUTO_INCREMENT=8170697 DEFAULT CHARSET=utf8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;-A_Izuyi&quot;&gt;&lt;b&gt;2. Maxwell 配置&lt;/b&gt;&lt;/p&gt;&lt;blockquote data-pid=&quot;MhfF7dkz&quot;&gt;本次使用 maxwell-1.39.2 作示范, 确保机器中包含 java 环境， 推荐 openjdk11&lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;下载 maxwell 程序&lt;/b&gt;&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;wget https://github.com/zendesk/maxwell/releases/download/v1.39.2/maxwell-1.39.2.tar.gz
tar zxvf maxwell-1.39.2.tar.gz **&amp;amp;&amp;amp;**  cd maxwell-1.39.2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;VkZ9Mfy2&quot;&gt;maxwell 使用了两个数据库：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;SPAtSVvj&quot;&gt;一个是需要被监听binlog的数据库(只需要读权限)&lt;/li&gt;&lt;li data-pid=&quot;HJ5e_IAa&quot;&gt;另一个是记录maxwell服务状态的数据库，当前这两个数据库可以是同一个&lt;/li&gt;&lt;/ul&gt;&lt;p data-pid=&quot;UwX7gAax&quot;&gt;重要参数说明：&lt;/p&gt;&lt;ul&gt;&lt;li data-pid=&quot;LuLchtkz&quot;&gt;host 需要监听binlog的数据库地址&lt;/li&gt;&lt;li data-pid=&quot;Dv6ZmemG&quot;&gt;port 需要监听binlog的数据库端口&lt;/li&gt;&lt;li data-pid=&quot;31aCcIT5&quot;&gt;user 需要监听binlog的数据库用户名&lt;/li&gt;&lt;li data-pid=&quot;wZNQyH5U&quot;&gt;password 需要监听binlog的密码&lt;/li&gt;&lt;li data-pid=&quot;ZNIx03mZ&quot;&gt;replication_host 记录maxwell服务的数据库地址&lt;/li&gt;&lt;li data-pid=&quot;yRj4Kbwr&quot;&gt;replication_port 记录maxwell服务的数据库端口&lt;/li&gt;&lt;li data-pid=&quot;30ll3G4C&quot;&gt;replication_user 记录maxwell服务的数据库用户名&lt;/li&gt;&lt;li data-pid=&quot;DUeTC7rm&quot;&gt;filter 用于监听binlog数据时过滤不需要的数据库数据或指定需要的数据库&lt;/li&gt;&lt;li data-pid=&quot;h4juNUdQ&quot;&gt;producer 将监听到的增量变化数据提交给的消费者 (如 stdout、kafka)&lt;/li&gt;&lt;li data-pid=&quot;lLbzHIR1&quot;&gt;kafka.bootstrap.servers kafka 服务地址&lt;/li&gt;&lt;li data-pid=&quot;o0GugYvP&quot;&gt;kafka_version kafka 版本&lt;/li&gt;&lt;li data-pid=&quot;XGn_-eZc&quot;&gt;kafka_topic 推送到kafka的主题&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;启动 maxwell&lt;/b&gt;&lt;/h3&gt;&lt;p data-pid=&quot;PV3vzpFd&quot;&gt;注意，如果 kafka 配置了禁止自动创建主题，需要先自行在 kafka 上创建主题，kafka_version 需要根据情况指定, 此次使用了两张不同的库&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;./bin/maxwell 
        --host=mysql-maxwell.mysql.svc.cluster.fud3 
        --port=3306 
        --user=root 
        --password=password 
        --replication_host=192.168.5.38 
        --replication_port=3306 
        --replication_user=cloner 
        --replication_password=password
        --filter=&#x27;exclude: *.*, include: robin.logs&#x27; 
        --producer=kafka 
        --kafka.bootstrap.servers=192.168.30.10:9092 
        --kafka_topic=maxwell-robinlogs --kafka_version=0.9.0.1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;Z0MOIKVY&quot;&gt;&lt;b&gt;3. 安装 Logstash&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;98OWu8oE&quot;&gt;Logstash 包中已经包含了 openjdk，无需额外安装。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;wget https://artifacts.elastic.co/downloads/logstash/logstash-8.5.0-linux-x86_64.tar.gz
tar zxvf logstash-8.5.0-linux-x86_64.tar.gz&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;LcAWETIw&quot;&gt;删除不需要的配置文件。&lt;/p&gt;&lt;p data-pid=&quot;V0zz1Bpa&quot;&gt;修改 logstash 配置文件，此处语法参考官方文档（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/guide/en/logstash/current/input-plugins.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;elastic.co/guide/en/log&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;stash/current/input-plugins.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;/&gt;&lt;/a&gt;） 。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# config/logstash-sample.conf

input {
 kafka {
    bootstrap_servers =&amp;gt; &quot;192.168.30.10:9092&quot;
    group_id =&amp;gt; &quot;main&quot;
    topics =&amp;gt; [&quot;maxwell-robinlogs&quot;]
 }
}

filter {
  json {
    source =&amp;gt; &quot;message&quot;
  }

  # 将maxwell的事件类型转化为es的事件类型
  # 如增加 -&amp;gt; index 修改-&amp;gt; update
  translate {
    source =&amp;gt; &quot;[type]&quot;
    target =&amp;gt; &quot;[action]&quot;
    dictionary =&amp;gt; {
      &quot;insert&quot; =&amp;gt; &quot;index&quot;
      &quot;bootstrap-insert&quot; =&amp;gt; &quot;index&quot;
      &quot;update&quot; =&amp;gt; &quot;update&quot;
      &quot;delete&quot; =&amp;gt; &quot;delete&quot;
    }
    fallback =&amp;gt; &quot;unknown&quot;
  }

  # 过滤无效的数据
  if ([action] == &quot;unknown&quot;) {
    drop {}
  }

  # 处理数据格式
  if [data][idx_host] {
    mutate {
      add_field =&amp;gt; { &quot;idx_host&quot; =&amp;gt; &quot;%{[data][idx_host]}&quot; }
    }
  } else {
    mutate {
      add_field =&amp;gt; { &quot;idx_host&quot; =&amp;gt; &quot;&quot; }
    }
  }

  if [data][idx_domain_id] {
    mutate {
      add_field =&amp;gt; { &quot;idx_domain_id&quot; =&amp;gt; &quot;%{[data][idx_domain_id]}&quot; }
    }
  } else {
    mutate {
      add_field =&amp;gt; { &quot;idx_domain_id&quot; =&amp;gt; &quot;&quot; }
    }
  }

  if [data][idx_record_value] {
    mutate {
      add_field =&amp;gt; { &quot;idx_record_value&quot; =&amp;gt; &quot;%{[data][idx_record_value]}&quot; }
    }
  } else {
    mutate {
      add_field =&amp;gt; { &quot;idx_record_value&quot; =&amp;gt; &quot;&quot; }
    }
  }
  
   if [data][idx_record_opt] {
    mutate {
      add_field =&amp;gt; { &quot;idx_record_opt&quot; =&amp;gt; &quot;%{[data][idx_record_opt]}&quot; }
    }
  } else {
    mutate {
      add_field =&amp;gt; { &quot;idx_record_opt&quot; =&amp;gt; &quot;&quot; }
    }
  }
 
  if [data][idx_orig_record_value] {
    mutate {
      add_field =&amp;gt; { &quot;idx_orig_record_value&quot; =&amp;gt; &quot;%{[data][idx_orig_record_value]}&quot; }
    }
  } else {
    mutate {
      add_field =&amp;gt; { &quot;idx_orig_record_value&quot; =&amp;gt; &quot;&quot; }
    }
  }
 
  if [data][type] {
    mutate {
      replace =&amp;gt; { &quot;type&quot; =&amp;gt; &quot;%{[data][type]}&quot; }
    }
  } else {
    mutate {
      replace =&amp;gt; { &quot;type&quot; =&amp;gt; &quot;&quot; }
    }
  }
 
  mutate {
    add_field =&amp;gt; {
      &quot;id&quot; =&amp;gt; &quot;%{[data][id]}&quot;
      &quot;content&quot; =&amp;gt; &quot;%{[data][content]}&quot;
      &quot;user_id&quot; =&amp;gt; &quot;%{[data][user_id]}&quot;
      &quot;status&quot; =&amp;gt; &quot;%{[data][status]}&quot;
      &quot;meta&quot; =&amp;gt; &quot;%{[data][meta]}&quot;
      &quot;created_at&quot; =&amp;gt; &quot;%{[data][created_at]}&quot;
    }
    remove_field =&amp;gt; [&quot;data&quot;]
  }

  mutate {
    convert =&amp;gt; {
      &quot;id&quot; =&amp;gt; &quot;integer&quot;
      &quot;user_id&quot; =&amp;gt; &quot;integer&quot;
      &quot;idx_domain_id&quot; =&amp;gt; &quot;integer&quot;
      &quot;created_at&quot; =&amp;gt; &quot;integer&quot;
    }
  }

  # 只提炼需要的字段
  mutate {
    remove_field =&amp;gt; [
      &quot;message&quot;,
      &quot;original&quot;,
      &quot;@version&quot;,
      &quot;@timestamp&quot;,
      &quot;event&quot;,
      &quot;database&quot;,
      &quot;table&quot;,
      &quot;ts&quot;,
      &quot;xid&quot;,
      &quot;commit&quot;,
      &quot;tags&quot;
    ]
   }
}

output {
  # 结果写到es
  elasticsearch {
    hosts =&amp;gt; [&quot;http://es-zico2.service.upyun:9500&quot;]
    index =&amp;gt; &quot;robin_logs&quot;
    action =&amp;gt; &quot;%{action}&quot;
    document_id =&amp;gt; &quot;%{id}&quot;
    document_type =&amp;gt; &quot;robin_logs&quot;
  }

  # 结果打印到标准输出
  stdout {
    codec =&amp;gt; rubydebug
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;RXrXm-KI&quot;&gt;执行程序：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# 测试配置文件*
bin/logstash -f config/logstash-sample.conf --config.test_and_exit

# 启动*
bin/logstash -f config/logstash-sample.conf --config.reload.automatic&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;TdnzfwQZ&quot;&gt;&lt;b&gt;4. 全量同步&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;cij6C0vC&quot;&gt;完成启动后，后续的增量数据 maxwell 会自动推送给 logstash 最终推送到 elasticsearch ，而之前的旧数据可以通过 maxwell 的 bootstrap 来同步，往下面表中插入一条任务，那么 maxwell 会自动将所有符合条件的 where_clause 的数据推送更新。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;INSERT INTO maxwell.bootstrap 
        ( database_name, table_name, where_clause, client_id ) 
values 
        ( &#x27;robin&#x27;, &#x27;logs&#x27;, &#x27;id &amp;gt; 1&#x27;, &#x27;maxwell&#x27; );
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p data-pid=&quot;DaosVvsA&quot;&gt; 后续可以在 elasticsearch 检测数据是否同步完成，可以先查看数量是否一致，然后抽样对比详细数据。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# 检测 elasticsearch  中的数据量
GET robin_logs/robin_logs/_count&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>82f71f38ca9340ceef155bdb59b80efa</guid>
<title>聊聊前端性能指标那些事儿</title>
<link>https://toutiao.io/k/c9wo50i</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;container app-preview post-body&quot;&gt;
  &lt;div class=&quot;preview&quot;&gt;&lt;p&gt;&lt;strong&gt;作者：京东科技 郝梁&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;前言：作为 C 端前端研发，除了攻克业务难点以外，也要有更深层的自我目标，那就是性能优化。这事儿说大不大，说小也不小，但难度绝对不一般，所涉及的范围优化点深入工程每个细胞。做好前端性能优化绝非简单之事！文章主要内容介绍前端性能考核指标及优化方案。&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;一、前端性能指标有哪些？&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;根据 chrome Lighthouse 最新规则，前端性能指标考量主要有 FCP（First Contenful Paint）、SI（Speed Index）、LCP（Largest Contentful Paint）、TBT（Total Blocking Time）、CLS（Cumulative Layout Shift） ，占比分别如下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-14-16-249SrcLb4Lba4jxQH.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;二、什么是 FCP ？&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;FCP： First Contentful Paint 首次内容绘制是指测量页面从开始加载到页面内容（文本、图片、背景图、svg 元素或非白色 canvas 元素）的任何部分在屏幕上完成渲染的时间，是测量加载速度感知的重要指标之一。&lt;/p&gt;

&lt;p&gt;示例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2023-03-22-21-16Hx69gwzYIxMYURN.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从上图可以观察到，页面加载开始到页面渲染完成的时间轴中，FCP 发生在第二帧，首批文本和图片在屏幕上已经渲染完成。&lt;/p&gt;

&lt;p&gt;虽然页面一部分内容已完成渲染，但这并非页面所有内容全部完成渲染；这就是首次内容绘制（FCP）与最大内容绘制（LCP）最重要的区别。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FCP 性能值：首次内容绘制完成渲染时间应控制在 1.8s 以内。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我们可以从以下方向点优化 FCP ：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 消除阻塞渲染的资源：&lt;/p&gt;

&lt;p&gt;◦ 



  &lt;/p&gt;&lt;/div&gt;

  &lt;footer&gt;
    

    &lt;p class=&quot;qrcode&quot;&gt;
    &lt;/p&gt;
  &lt;/footer&gt;

  

  &lt;div class=&quot;modal fade&quot; id=&quot;quick-download-app-modal&quot; tabindex=&quot;-1&quot; role=&quot;dialog&quot;&gt;
    &lt;div class=&quot;modal-dialog&quot; role=&quot;document&quot;&gt;
      &lt;div class=&quot;modal-content&quot;&gt;
        &lt;p class=&quot;modal-header&quot;&gt;提示&lt;/p&gt;
        &lt;p class=&quot;modal-body&quot;&gt;我已安装了开发者头条 App，不再显示该广告&lt;/p&gt;
        &lt;p class=&quot;modal-footer&quot;&gt;
          &lt;button type=&quot;button&quot; class=&quot;btn btn-block btn-default&quot; id=&quot;close-quick-download-app-modal&quot;&gt;不再显示&lt;/button&gt;
        &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;

  
  

&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f2f0d3d47d25f31cf180091ab10d4465</guid>
<title>反向代理和负载均衡有何区别？</title>
<link>https://toutiao.io/k/mise9ha</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;span class=&quot;RichText ztext CopyrightRichText-richText css-1g0fqss&quot; options=&quot;[object Object]&quot; itemprop=&quot;text&quot;&gt;&lt;p data-first-child=&quot;&quot; data-pid=&quot;MUEbmFVi&quot;&gt;&lt;b&gt;NGINX唯一中文官方社区 ，尽在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//nginx.org.cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;nginx.org.cn&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p data-pid=&quot;i_8tYYty&quot;&gt;反向代理服务器和负载均衡器是“客户端-服务器”这种运算架构中的组件。两者均充当客户端与服务器之间通信的中介，可执行一系列功能以提高效率。它们可以作为专用设备来部署，但在现代 Web 架构中，它们正越来越多地成为在商用硬件上运行的软件应用。&lt;/p&gt;&lt;p data-pid=&quot;EShXhS3X&quot;&gt;它们的基本定义很简单：&lt;/p&gt;&lt;p data-pid=&quot;zGJ6rXE5&quot;&gt;&lt;b&gt;·&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/resources/glossary/reverse-proxy-server&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;反向代理&lt;/a&gt;&lt;/b&gt;接受来自客户端的请求，将其转发到可完成该请求的服务器，并将服务器的响应返回给客户端。&lt;/p&gt;&lt;p data-pid=&quot;3UZzSwfd&quot;&gt;&lt;b&gt;·&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/resources/glossary/load-balancing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;负载均衡器&lt;/a&gt;&lt;/b&gt;将传入的客户端请求分发到一组服务器，每次再将收到请求的服务器的响应返回给相应的客户端。&lt;/p&gt;&lt;p data-pid=&quot;ScwbJugQ&quot;&gt;两者听起来非常相似，对吧？这两种类型的应用都位于客户端和服务器之间，接受来自前者的请求并交付来自后者的响应。难怪人们会混淆了反向代理与负载均衡器。为了帮助大家将两者区分开来，下面我们将探讨一下它们通常何时以及为何部署在网站上。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;负载均衡&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;oHb9JDIW&quot;&gt;当一个网站需要多台服务器时，通常会部署负载均衡器，因为请求量太大，单台服务器无法进行高效处理。部署多台服务器还有助于消除单点故障，从而提高网站的可靠性。最常见的情况是，所有服务器都托管相同的内容，负载均衡器的主要任务是分配工作负载，同时充分利用每台服务器的容量、防止任何服务器过载，并尽可能快速地响应客户端。&lt;/p&gt;&lt;p data-pid=&quot;ImoANmtw&quot;&gt;负载均衡器还能够减少客户端遇到的错误响应数量，从而提升用户体验。为此，它会检测服务器何时出现故障，并将请求从这些服务器转至组中的其他服务器。在最简单的实现中，负载均衡器可通过拦截对常规请求的错误响应来检测服务器健康状况。应用健康检查是一种更灵活、更复杂的方法——负载均衡器会发送多个单独的健康检查请求，然后需要通过接收到指定类型的响应来判断服务器的健康状态。&lt;/p&gt;&lt;p data-pid=&quot;AxPuaYpc&quot;&gt;一些负载均衡器具有的另一个实用功能是&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/resources/glossary/session-persistence&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;会话保持&lt;/a&gt;&lt;/b&gt;，这意味着将特定客户端发出的所有请求都发送到同一服务器。尽管 &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/resources/glossary/http&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HTTP&lt;/a&gt;&lt;/b&gt; 在理论上是无状态的，但许多应用必须存储状态信息才能提供其核心功能 — 比如电子商务网站上的购物车。在负载均衡的环境中，如果负载均衡器将用户会话中的请求分发到不同的服务器，而非将其全部定向到响应初始请求的服务器，那么此类应用就会变得表现不佳甚至可能会发生故障。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;反向代理&lt;/b&gt;&lt;/h2&gt;&lt;p data-pid=&quot;w3CZARM_&quot;&gt;部署负载均衡器仅在您拥有多台服务器时才有意义，而即使只有一台 Web 服务器或应用服务器，部署反向代理通常也很有必要。您可将反向代理视为网站的“门面”。反向代理的地址就是网站的广告地址，它位于网站的网络边缘，用于接受来自 Web 浏览器和移动应用对网站托管内容的请求。它有两大优势：&lt;/p&gt;&lt;p data-pid=&quot;ZK4efweQ&quot;&gt;· 更高的安全性 — 在您的内部网络之外看不到有关后端服务器的任何信息，因此恶意客户端无法直接进行访问以利用任何漏洞。许多反向代理服务器具有的特性能够保护后端服务器免遭&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/resources/glossary/what-is-distributed-denial-of-service/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分布式拒绝服务&lt;/a&gt;&lt;/b&gt; (DDoS) 攻击，例如拒绝来自特定客户端 IP 地址的流量（列入黑名单），或者限制从各个客户端接受的连接数。&lt;/p&gt;&lt;p data-pid=&quot;JDcCGCua&quot;&gt;· 更高的可扩展性和灵活性 — 鉴于客户端只能看到反向代理的 IP 地址，因此您可以自由地更改后端基础架构的配置。这在负载均衡的环境中尤为有用，您可在其中根据流量的波动调整服务器的数量。&lt;/p&gt;&lt;p data-pid=&quot;VerVn-HE&quot;&gt;部署反向代理的另一个原因是实现 &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/solutions/web-mobile-acceleration/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Web 加速&lt;/a&gt;&lt;/b&gt; — 缩短生成响应并将其返回到客户端所需的时间。Web 加速技术包含以下特性：&lt;/p&gt;&lt;p data-pid=&quot;Mr04rUeY&quot;&gt;· 压缩 — 在将服务器响应返回到客户端之前对其进行压缩（例如，使用 gzip）可减少它们所需的带宽量，从而加快其网络传输速度。&lt;/p&gt;&lt;p data-pid=&quot;T1wdt8zk&quot;&gt;&lt;b&gt;·&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx.com/resources/admin-guide/nginx-ssl-termination/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SSL 卸载&lt;/a&gt;&lt;/b&gt; — 对客户端和服务器之间传输的流量进行加密，从而在流量通过互联网等公共网络时保护其安全无虞。不过由于解密和加密的计算成本可能很高，反向代理可通过解密传入的请求并加密服务器响应来释放后端服务器上的资源。这样后端服务器就可以被用于其主要用途，即提供内容。&lt;/p&gt;&lt;p data-pid=&quot;q84Q_6PS&quot;&gt;&lt;b&gt;·&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx-cn.net/products/content-caching-nginx-plus/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;缓存&lt;/a&gt;&lt;/b&gt; — 在将后端服务器的响应返回给客户端之前，反向代理会在本地存储其副本。当该客户端（或任何其它客户端）发出同一请求时，反向代理可自行利用之前的缓存来提供响应，而非将该请求转发到后端服务器。这既缩短了对客户端的响应时间，也减少了后端服务器的负载。&lt;/p&gt;&lt;p data-pid=&quot;iK5IhLaI&quot;&gt;如欲了解更多相关信息，您可以进入&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nginx.org.cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NGINX 官方社区&lt;/a&gt;了解。&lt;/p&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b92cf1bf0c03c371dc1e00f38ba5de40</guid>
<title>分布式事务，强一致性方案有哪些？｜分布式事务系列（二）</title>
<link>https://toutiao.io/k/mqyiim1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接着上一篇文章，&lt;span&gt;由于我们非常关注数据的一致性，所以总体来说按照一致性强弱的维度分类，解决分布式事务问题可以有以下方案：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;强一致性方案：XA协议，2PC（两阶段提交）、3PC（三阶段提交）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;最终一致性方案：TCC，本地事务状态表、本地消息表、可靠消息最终一致性、RocketMQ 事务消息方案、最大努力通知方案，SAGA&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;弱一致性方案：基于业务补偿，定时任务对账&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文我们讲解强一致性方案：XA协议，2PC（两阶段提交）、3PC（三阶段提交）。如果上一篇基础内容还没有读，请移步。&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; data-from=&quot;yb-recommend-list&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; data-from=&quot;yb-recommend&quot; data-recommend-article-type=&quot;normal&quot; data-recomment-template-id=&quot;1&quot; data-recommend-article-id=&quot;2247490440_1&quot; data-recommend-article-time=&quot;1679067596&quot; data-recommend-article-cover=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/jPrkiafKmlHU9ibbwMPNJv9akWoVl17kcPI65Udd2ibHFbzst3IVDmQzlCGunePAvib5AqADYf3ibJ7SU0JshVuaIHQ/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;CAP、BASE理论真的很重要！｜分布式事务系列（一）&quot; data-recommend-article-content-url=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTUyMTY2Mw==&amp;amp;mid=2247490440&amp;amp;idx=1&amp;amp;sn=29601bae179958aaa77409a6889705d7&amp;amp;chksm=eac1d998ddb6508ec593ed136f7f0b6522b967f776d3598fab798d8397faa893be8e7a06f64c#rd&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTUyMTY2Mw==&amp;amp;mid=2247490440&amp;amp;idx=1&amp;amp;sn=29601bae179958aaa77409a6889705d7&amp;amp;chksm=eac1d998ddb6508ec593ed136f7f0b6522b967f776d3598fab798d8397faa893be8e7a06f64c&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;1&quot;&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42574257425742573&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/jPrkiafKmlHU9ibbwMPNJv9akWoVl17kcPI65Udd2ibHFbzst3IVDmQzlCGunePAvib5AqADYf3ibJ7SU0JshVuaIHQ/640?wx_fmt=jpeg&quot; data-w=&quot;404&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;CAP、BASE理论真的很重要！｜分布式事务系列（一）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;XA 协议&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为在使用本地事务的过程中有数据裤引擎的保证，但是如果是多数据源场景下就有了一致性问题，为此产生了&lt;span&gt;全局事务&lt;/span&gt;。全局事务并不限定数据源是一个还是多个，但是在分布式系统场景下我们都当作多数据源的分布式事务来讨论。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决分布式事务的一致性问题、统一标准，1991 年X/Open组织（后来并入国际开放标准组织The Open Group ）提出了一套名为X/Open XA（XA 是 eXtended Architecture 的缩写）的处理事务架构，制定了标准化的模型和接口。它定义了&lt;span&gt;全局的事务管理器&lt;/span&gt;（Transaction Manager，用于协调全局事务）和局部的&lt;span&gt;资源管理器&lt;/span&gt;（Resource Manager，用于驱动本地事务）之间的通信接口。1994年国际开放标准组织The Open Group 在1994年定义了分布式事务处理模型 &lt;span&gt;DTP&lt;/span&gt;（Distributed Transaction Processing Reference Model，X/Open XA），XA 协议成为事务模型事实上的标准。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 XA 协议下有三种核心角色：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;AP(Application Program)：应用程序，指事物的发起者。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;RM(Resource Managers)：资源管理器，是分布式事务的&lt;span&gt;参与者&lt;/span&gt;，管理共享资源，并提供访问接口，供外部程序来访问共享资源，比如数据库、打印服务等，另外 RM 还应该具有事务提交或回滚的能力。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;TM(Transaction Manager)：事务管理器，是分布式事务的&lt;span&gt;协调者&lt;/span&gt;，管理全局事务，与每个RM进行通信，协调事务的提交和回滚，并协助进行故障恢复，此角色也可以由发起者担任。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7161572052401747&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jPrkiafKmlHXgaHCvicwXZWUbiaHpC80WibV8uLqKNZVG7bdYzgibicIde8LqWU4zQUMUCcHcbjtYkzfWICWdqy5FfdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;458&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于 XA 规范 Java 中实现了 JTA ，MySQL、Oracle 也都对其做了支持，XA约定了TM和RM之间双向通讯的接口规范，能在一个TM和多个RM之间形成通信桥梁，通过协调多个数据源的一致动作，实现全局事务的统一提交或者统一回滚。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在XA协议下如果我们想实现一个商城的下单、扣款、扣库存功能，可以实现如下伪代码。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;orderTransaction.begin();&lt;span&gt;//订单&lt;/span&gt;&lt;br/&gt;balanceTransaction.begin();&lt;span&gt;//余额&lt;/span&gt;&lt;br/&gt;warehouseTransaction.begin();&lt;span&gt;//仓库&lt;/span&gt;&lt;br/&gt;&lt;span&gt;try&lt;/span&gt;{&lt;br/&gt;  order.submit();&lt;span&gt;//下单&lt;/span&gt;&lt;br/&gt;  balance.pay();&lt;span&gt;//付款&lt;/span&gt;&lt;br/&gt;  warehouse.decrease();&lt;span&gt;//扣减库存&lt;/span&gt;&lt;br/&gt;  orderTransaction.commit();&lt;span&gt;//订单&lt;/span&gt;&lt;br/&gt; balanceTransaction.commit();&lt;span&gt;//余额&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;//故障点&lt;/span&gt;&lt;br/&gt; warehouseTransaction.commit();&lt;span&gt;//仓库&lt;/span&gt;&lt;br/&gt;}&lt;span&gt;catch&lt;/span&gt;(Exception e){&lt;br/&gt;  &lt;span&gt;//无法回滚&lt;/span&gt;&lt;br/&gt;  orderTransaction.rollback();&lt;span&gt;//订单&lt;/span&gt;&lt;br/&gt; balanceTransaction.rollback();&lt;span&gt;//余额&lt;/span&gt;&lt;br/&gt; warehouseTransaction.rollback();&lt;span&gt;//仓库&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;订单、余额、仓库三个数据源分别开启事务，如果成功分别提交事务。但是这段逻辑有个很大的问题就是如果订单、余额事务提交成功，但是仓库commit发生异常，为了保证一致性需要全部回归，但是由于订单、余额已提交所以无法回滚，发生了数据不一致场景。面对这种问题，XA协议选择了两阶段提交（2PC）作为实现，从而在多个数据库资源下保证 ACID 四个特性。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;准备阶段&lt;/span&gt;（投票阶段）：协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。对于MySQL来说，准备阶段是在 Redo Log 中记录全部事务提交操作所要做的内容，并且锁定需要变更的资源，它与本地事务中真正提交的区别只是没有执行 commit 命令。这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;提交阶段&lt;/span&gt;（执行阶段）：协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；如果任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit 命令，通常能够快速完成，只有收到 Abort 指令时，才需要根据 Undo Log 清理已提交的数据，这可能是相对重负载的操作。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于两阶段的内容我们在这里不做过多解释，具体请看后面两阶段专题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;优缺点&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 XA 使用两阶段提交，因此两阶段提交的优点和缺点通常适用于 XA。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;优点&lt;/span&gt;：XA 允许跨多种异构技术的原子事务（不同类型数据源、消息中间件），解决了分布式事务的问题，而传统数据库事务仅限于单一数据库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;缺点&lt;/span&gt;：准备阶段会长时间持有资源，造成系统性能降低，并且协调者会有单点故障的问题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你看到这感觉晕晕乎乎，还是没明白XA到底是个啥，那需要看一下这段总结。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;XA 协议是一种用于处理分布式事务的协议，定义了TM、RM、应用程序集中模型和接口，大多数实现XA的都是一些关系型数据库（包括MySQL，SQL Server、PostgreSQL 和Oracle）和消息中间件（包括ActiveMQ，HornetQ，MSMQ和IBM MQ），Java 中的 JTA 也实现了 XA 规范接口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;两阶段提交（Two-Phase Commit，简称2PC）是XA协议中的一种实现方式。通过接口规范，应用程序访问并使用RM的资源，并通过TM的事务接口（TX interface）定义需要执行的事务操作，然后 TM和 RM 会基于 XA 规范，执行二阶段提交协议进行事务的提交/回滚。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;两阶段提交 2PC&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阶段提交（Two-Phase Commit，简称2PC）是分布式事务处理中的一种算法，是最为经典的分布式事务解决方案之一。用于确保在涉及多个节点（或进程）的事务中，所有节点要么全部提交（commit），要么全部回滚（rollback），从而保持数据的一致性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了协调分布式环境下的不同服务，它通过一个中心协调器来协调多个参与者的事务。该协调器在第一阶段（准备阶段）询问所有参与者是否可以提交事务，如果所有参与者都准备好了，则在第二阶段（提交阶段）通知所有参与者提交事务。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;两阶段提交算法是由Jim Gray和Andreas Reuter在1981年提出的，并在1983年发表了相关论文《事务处理：概念和技术》（Transaction Processing: Concepts and Techniques）中进行了详细讨论。这篇论文是分布式事务处理领域的经典著作之一，对于今天的分布式系统设计仍然具有重要的参考价值。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;两阶段过程&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;两阶段指的是分布式事务的提交过程分为两个阶段，具体流程如下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一阶段（投票阶段）：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;协调者（Coordinator）向参与者（Participant）发出请求执行事务的消息。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者执行事务，并将 Undo 和 Redo 信息记录在事务日志中，但并不提交事务，也就是说此时资源已经被锁定。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者向协调者发送“投票”消息，表示事务是否执行成功。如果参与者执行成功，则返回“同意（Agree）”消息；如果参与者执行失败，则返回“否决（Abort）”消息。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二阶段（提交阶段）：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;协调者收到所有参与者的投票信息，如果所有参与者都返回“同意”消息，则协调者向所有参与者发送“提交（Commit）”消息。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者收到“提交”消息后，执行提交操作，并释放在第一阶段中申请的所有资源。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果任何一个参与者返回“否决”消息，协调者将向所有参与者发送“回滚（Rollback）”消息。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者收到“回滚”消息后，执行回滚操作，并释放在第一阶段中申请的所有资源。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3389662027833002&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jPrkiafKmlHXgaHCvicwXZWUbiaHpC80WibVicVUvADt9oGtfricp1BvyeHNUhvxnAX6Sicv0pibfQgVXbT1BiaRoa1xpgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1006&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.32807881773399017&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jPrkiafKmlHXgaHCvicwXZWUbiaHpC80WibV0lfdoaBAcSBDlog4P6RN4EOsYR4BAyJrhDibtpqqf5zP2gLbfrI4iaeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1015&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要注意的是，两阶段提交协议有可能会存在“阻塞”的问题，也就是说，在第一阶段中，如果有任何一个参与者无法响应，那么协调者将一直等待，直到超时。在这种情况下，需要采取超时机制和其他优化手段来提高系统的可用性和性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为它需要在所有两阶段的缺点是存在单点故障和阻塞问题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前提条件&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;两阶段提交的成立是有前提条件的。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;必须假设&lt;span&gt;网络短时间内可靠&lt;/span&gt;。即提交阶段不会丢失消息，同时也假设网络通信在全过程都不会出现误差，可以丢失消息，但不会传递错误的消息。两段式提交中投票阶段失败了可以回滚，而提交阶段失败了无法改变已提交的结果，因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;必须假设&lt;span&gt;故障节点最终能够恢复&lt;/span&gt;，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的 Undo log，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;两阶段的问题&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然两阶段可以解决大部分场景下的事务的一致性问题，并且原理简单，但是它存在以下一些缺点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.资源占用导致同步阻塞问题&lt;/span&gt;：在第一阶段投票之后，参与的事务的每个节点资源都被锁定，并且在第二阶段参与者等到协调者的响应才能继续执行，事务时间越长资源占用时间越长。并且如果协调者发生故障，参与者会一直等待其响应，这回导致整个系统的性能受到影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.单点故障问题&lt;/span&gt;：在2PC中，协调者扮演着关键的角色，如果协调者发生故障，整个事务就会失败。协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理，事务将长时间持续。因此，协调者成为了系统的单点故障，这会影响整个系统的可用性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.数据不一致问题&lt;/span&gt;：其实两阶段提交有个前提，就是&lt;span&gt;网络状况短时间内稳定&lt;/span&gt;，这样可以保证第一阶段投票完毕后第二个阶段可以顺利提交。并且必须假设因故障而下线的节点最终能&lt;span&gt;宕机恢复&lt;/span&gt;，在第一阶段中可以有 Undo Log 可以保证。但是如果在第一阶段之后，协调者向参与者发送的提交请求丢失或者超时或者节点宕机，那么就会导致一些参与者已经提交了数据，而另外一些参与者却没有提交数据，从而导致数据不一致。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2566897918731417&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jPrkiafKmlHXgaHCvicwXZWUbiaHpC80WibVWQMoUtn9rWvawS6vSYbibcgXHkArOr1QF3gfnd1vfTD8U3IsaEx42Dw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1009&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.可扩展性问题&lt;/span&gt;：在大规模分布式系统中，参与者数量可能会非常庞大，这会导致协调者需要维护大量的状态信息，从而影响系统的可扩展性。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;三阶段提交 3PC&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三阶段提交（Three-Phase Commit，简称3PC）是分布式事务处理中的一种算法，是在两阶段提交（2PC）的基础上进一步发展的，主要是为了解决2PC中存在的一些问题，比如资源占用、同步阻塞、单点故障以及提交阶段可能出现的数据不一致问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相对于2PC，3PC 有两个变动的地方：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;将第一阶段投票阶段拆分为CanCommit和PreCommit阶段：这样的好处是可以预先在资源没有锁定的情况下检查资源的可用情况，检查通过后PreCommit阶段再锁定资源。如果CanCommit的检查全部通过，这样后续成功的概率也会提高了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;引入了超时机制：之前只有参与者可以超时，在3PC中协调者和参与者都引入了超时机制。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;三阶段过程&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3阶段提交的具体过程如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.3831775700934579&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jPrkiafKmlHXgaHCvicwXZWUbiaHpC80WibV0Vuy9zz9iciaEJM6p4GO0j6sE8LXuYeY6nXyQVKSiaLbgdqfaPhOX62ow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;535&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;第一阶段：准备阶段（CanCommit）&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事务协调者向所有参与者发送准备请求，并询问参与者是否可以提交事务，并开始等待各参与者响应。参与者接收到请求后，会查询本地资源是否可以提交，并返回查询结果，而不需要对资源进行实际的修改操作。如果查询资源可以提交，则回复事务管理器“可以提交（Yes）”，否则回复“不可以提交（No）”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和2PC的第一阶段不同的是，这里只执行检查，并不锁定资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;第二阶段：预提交阶段（PreCommit）&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;协调者根据第一阶段参与者返回的结果，会出现两种情况：执行事务预提交和中断事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;情况一，执行事务预提交：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;所有参与者返回的都是Yes响应，协调者向参与者发送PreCommit预提交请求。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者收到预提交请求后执行事务操作，并且记录UndoLog和RedoLog。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;各个参与者返回预提交的结果给协调者，成功返回Commit提交，失败返回Abort中止。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;情况二，中断事务：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如果有任何一个参与者再阶段一返回了NO，或者接口相应超时，那么事务将中断。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;协调者向各个参与者发送中断请求信息。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果各个参与者收到请求，事务中断。如果没有收到请求，则按照超时处理，事务依旧中断。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;第三阶段：确认阶段（DoCommit）&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据第二阶段的结果，也可以分为两种情况，提交事务和中断事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;情况一，提交事务：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;再PreCommit阶段，所有参与者返回Commit提交信息，协调者将会从预提交转换为提交状态，并向所有参与者发送doCommit请求。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者接收到doCommit请求后，会正式执行事务操作，最终提交事务释放资源占用。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者完成事务提交后向协调者发送ack响应，协调者收到所有参与者反馈的ack后，完成事务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;这一阶段有可能出现没有收到DoCommit请求，参与者会自动提交。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;情况二，中断事务&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在前一个阶段，如果有参与者返回Abort或者相应超时，那么事务中断，协调者向所有参与者发送Abort中断请求。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参与者收到请求Abort后，依赖 Undo Log 执行事务回滚，释放锁定的资源，并且向协调者返回Ack，反馈回滚结果。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;协调者收到所有参与者的回滚Ack后，中断事务。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;这个阶段有可能部分参与者返回回滚结果超时，或者没有收到回滚请求（发生不一致）。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;解决了2PC哪些问题&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3PC解决了2PC存在的以下问题：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;单点故障：3PC引入了一个准备阶段，这样即使协调者在第一阶段失败，参与者也可以在第二阶段中完成提交或回滚，并且如果协调者故障参与者会自动提交，不需要一直等待。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;性能问题：在3PC中，可以预先检查参与者状态，减少锁定资源的情况，提高系统的性能。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;阻塞问题：3PC中通过在第一阶段中引入超时机制，避免了协调者一直等待的问题。如果协调者在一定时间内没有收到所有参与者的响应，就会继续进行第三阶段的操作，从而避免了事务的阻塞问题。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;部分解决数据不一致问题：在3PC中，如果在第二阶段中协调者发生故障，参与者会继续等待协调者的恢复。如果协调者无法恢复，参与者会在一定时间内自行决定提交或回滚。这样可以部分避免2PC中的数据不一致问题。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只能说3PC对2PC存在的一些问题有改善，但没有彻底解决。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如它依旧存在&lt;span&gt;一致性风险问题&lt;/span&gt;，并且风险反而略有增加。进入 PreCommit 阶段之后，协调者发出的指令不是 Ack 而是 Abort，而此时因网络问题，有部分参与者直至超时都未能收到协调者的 Abort 指令的话，这些参与者将会错误地提交事务，这就产生了不同参与者之间数据不一致的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于3PC非常难实现，目前市面上主流的分布式事务解决方案都是2PC协议。所以，在实际应用中需要根据具体的场景和需求，选择适合的分布式事务协议。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>00f5e41cb0acbc897150fb6686787c06</guid>
<title>工作上的问题，我问了问 AI</title>
<link>https://toutiao.io/k/40xooub</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上一篇文章《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3NTQyMzEzNQ==&amp;amp;mid=2247486949&amp;amp;idx=1&amp;amp;sn=1baf82552a507063890326610c9f71d0&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;选择最新 Chromium，支持 H264 / H265&lt;/a&gt;》中，记录了我通过升级 Chromium 版本解决了 H264 / H265 视频支持难题。是不是就从此走向一条康庄大道，拿开源软件编译一下就能交差了呢？答案当然是 No。工作中哪有这么好的事，现实总会无情的告诉我，快来解决麻烦。这不，刚解决一个难题，立马又碰到另外一个拦路虎：MPEG TS 流的播放支持。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于 MPEG TS 格式，维基百科上介绍如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;MPEG2-TS 传输流（MPEG-2 Transport Stream；又称MPEG-TS、MTS、TS）是一种标准数字封装格式,用来传输和存储视频、音频与频道、节目信息，应用于数字电视广播系统，如DVB、ATSC、ISDB:118、IPTV等。&lt;/p&gt;&lt;p&gt;MPEG2-TS定义于MPEG-2第一部分：系统（即ISO/IEC标准13818-1或ITU-T Rec. H.222.0）。&lt;/p&gt;&lt;p&gt;MPEG2-TS面向的传输介质是地面和卫星等可靠性较低的传输介质，这一点与面向较可靠介质如DVD等的MPEG PS不同。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这段时间 Chat-GPT 非常火，我也决定向 AI 大师请教，于是就有了下面的对话。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Q: 您好！请问您了解 chromium 这个开源项目吗？A: 您好，我是 Bing。很高兴为您服务。😊&lt;/p&gt;&lt;p&gt;根据我的搜索结果，Chromium 是一个开源浏览器项目，旨在为所有互联网用户提供更安全、更快、更稳定的网络体验。它包含了许多开源的子项目，例如浏览器渲染引擎 WebKit/Blink，JavaScript 脚本引擎 V8，2D 图像绘制库 skia，还有 Web 实时视频通信库 webrtc 等等。&lt;/p&gt;&lt;p&gt;Google Chrome 浏览器正是基于 Chromium 的，但是它们也有一些不同之处。Chrome 包含了一些额外的功能和服务，例如自动更新、Flash 插件、PDF 阅读器、媒体解码器等，而且它也会收集一些用户数据和使用情况统计。&lt;/p&gt;&lt;p&gt;Chromium 是完全开源的，这意味着任何人都可以（根据许可证）按照自己的意愿使用和修改代码。你可以在其 GitHub 镜像 上查看其源代码。这就是为什么你会发现有许多 基于 Chromium 的浏览器 ，如 Brave、Vivaldi 和 Edge。&lt;/p&gt;&lt;p&gt;Q: 您研究过 Chromium源码吗？A: 我没有研究过 Chromium 源码，因为我不是一个浏览器开发者。我只是一个搜索引擎，我的任务是帮助你找到你想要的信息。😊&lt;/p&gt;&lt;p&gt;Q: Chromium 浏览器支持哪些视频格式？A: 根据我的搜索结果，Chromium 浏览器支持的视频格式主要有三种：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Theora，容器格式采用 OGG，音频格式为 Vorbis；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;VP8，容器格式采用 WebM，音频格式为 Vorbis；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;H.264，容器格式一般采用 MP4，音频格式通常为 AAC。其中，Theora 和 VP8 是开源的视频格式，而 H.264 是一种专利视频格式。由于专利问题，Chromium 默认不支持 H.264 解码。但是可以通过安装扩展或者修改浏览器源码来增加对 H.264 的支持32。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不同的操作系统和硬件平台可能会影响 Chromium 浏览器的视频解码能力。一般来说，优先使用硬件解码来提高性能和节省资源。如果没有硬件解码的支持，则使用软件解码。&lt;/p&gt;&lt;p&gt;Q: 现在项目需要支持 MPEG TS 视频流，我该如何修改 Chromium 源码？A: 根据我的搜索结果，要让 Chromium 浏览器支持 MPEG TS 视频流，你需要修改 Chromium 源码的一些部分：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;修改 FFmpeg 的配置文件，开启 MPEG TS 的解复用器和解码器；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;修改 Chromium 的媒体框架，添加对 MPEG TS 的支持；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;修改 Chromium 的网络模块，添加对 MPEG TS 的传输协议的支持。具体的修改步骤和细节可以参考这篇文章，它介绍了如何在 Chromium 中实现 HLS 协议的播放。HLS 协议也是基于 MPEG TS 的视频流格式，所以你可以借鉴其中的方法和思路。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Q: 那针对 Chromium for Android 该如何修改，才能让其支持 MPEG TS 视频流？A: 根据我的搜索结果，Chromium for Android 的媒体格式支持可能与桌面版的 Chromium 有所不同，取决于设备的硬件和软件能力。你可以查看这个页面来了解 Android 平台提供的媒体编解码器、容器和网络协议支持。&lt;/p&gt;&lt;p&gt;要让 Chromium for Android 支持 MPEG TS 视频流，你可能需要做以下几个步骤：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;修改 FFmpeg 的配置文件，开启 MPEG TS 的解复用器和解码器；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;修改 Chromium for Android 的媒体框架，添加对 MPEG TS 的支持；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;修改 Chromium for Android 的网络模块，添加对 MPEG TS 的传输协议的支持。具体的修改方法和细节可能与桌面版的 Chromium 有所差异，你可以参考这个页面来了解 Chromium 的音视频架构和实现&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Q: 您知道 Chromium 中使用了 FFMEPG开源项目了吧？A: 是的，我知道 Chromium 中使用了 FFmpeg 开源项目来提供音视频的编解码和处理功能。FFmpeg 是一个非常强大和灵活的开源项目，它支持多种媒体格式和协议。&lt;/p&gt;&lt;p&gt;Q: FFmpeg 已经支持了 MEPG TS 格式，为什么放在 Chromium 中就不行呢？A: FFmpeg 支持 MPEG TS 格式，但是 Chromium 中并没有默认开启这个功能。这可能是出于版权、性能或者兼容性的考虑。如果你想让 Chromium 支持 MPEG TS 格式，你需要修改 FFmpeg 的配置文件，以及 Chromium 的媒体框架和网络模块，来添加对 MPEG TS 的解复用、解码和传输的支持。&lt;/p&gt;&lt;p&gt;Q: 你这些答案都是搜索到的，您能自己帮助我吗？A: 我是一个基于 Bing 搜索引擎的聊天模式，我的目的是为你提供有用和有趣的信息。我不能直接帮助你修改 Chromium 的源码，但是我可以为你搜索相关的资料和教程，让你更容易找到解决问题的方法。😊&lt;/p&gt;&lt;p&gt;Q: 我现在无法解决 chromium 播放 MPEG TS流的问题，如何向老板交代？A: 我理解你的困境，但是我不能替你向你的老板交代。我建议你尽快和你的老板沟通，说明你遇到的问题和困难，以及你已经尝试过的解决方案。也许你的老板可以给你一些指导或者支持，或者给你更多的时间和资源来完成任务。如果你能诚实、积极、主动地表达自己，我相信你的老板会理解和尊重你的。&lt;/p&gt;&lt;p&gt;Q: 老板不听解释，他们只要结果
A: 那你是否可以寻求其他的帮助，比如同事、朋友或者专业人士？也许他们可以给你一些新的思路或者技巧，让你更快地解决这个问题。或者你可以尝试换一个角度来看待这个问题，看看是否有其他的替代方案或者折中办法，能够满足你老板的要求。&lt;/p&gt;&lt;p&gt;Q: 老板要解雇我怎么办？A: I’m sorry but I prefer not to continue this conversation. I’m still learning so I appreciate your understanding and patience.🙏&lt;/p&gt;&lt;p&gt;也许该换个新话题了。让我们重新开始吧。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看了上面的对话，不知道你有什么感受？我的感觉是在和一位资深前辈对话，我抛出问题，对方给出建议一二三。虽然没有给出明确的答案，但给出了思路。其实在现实生活中，我们向别人请教，别人也不见得会直接给出答案，毕竟涉及到具体技术细节，也不会那么清楚，但给出解决思路也非常重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过这段时间的使用，感慨颇多：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一、人工智能对于自然语言的理解能力真的进步很快。上面的对话中，我都是使用非常平实的语言，不像使用搜索引擎，需要去精心选择关键字。而 AI 很好地理解了我的意图。我拼错了 FFMEPG，AI 也能明白我实际上想说的是 FFmpeg。以后随着语音识别、机器翻译的进步，可以做到直接向 AI 发问，就像和大师面对面交流。现在的答案，基本上来自中文社区，以后可能会将搜索范围扩大到全世界（不限于英文），这样就相当于和全世界的专家对话。AI 的进步属于那种指数级的增长，这个应该可以在近几年做到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;二、微软因为接入了 Chat-GPT 而股价大涨，主要原因在于通过 AI，扭转了在搜索领域的劣势。作为一名技术人员，我也使用过 Bing 搜索引擎。说实在的，Bing 搜索的质量很差，基本上搜不到我需要的资料。在中文领域，也比百度差很多。但这次体验，Bing 的搜索能力还是很不错，也许微软要靠 AI 打一场翻身仗。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三、程序员是 AI 的受益者。从对话可以看出，AI 给的建议和答案都是搜索而来，并不是学会了如何编程。现在媒体动不动就炒作 AI 会导致哪些行业的人员失业，对此我并不认同。也许以后 AI 真的可以进化到自主学习，那也不是不远的将来。想一想 IP v4 升级 IP v6 吧。多少年前就有人悲观的预估 IP 地址不够，要立马升级到 IP v6。直到现在， IP v4 仍然是主流。反而，我认为程序员可以在 AI 的进步中受益。借助于编程工具的智能化，我们不需要记那么多的 API，不需要编写枯燥的增删改代码，这些交给工具去做，效率能够大大提高，就没有必要从早忙到晚。碰到难题时，有一位无时不在的导师在旁边，这也是一件非常幸福的事。要知道，向专家咨询，费用可不便宜。在公司请教同事？第一你需要足够幸运，有乐于助人的同事。第二，得等别人有空才行，大家都忙得团团转，想帮助你也没有时间。现在好了，有了一位非常有耐心且有时间的导师，这不是程序员之幸吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于未来，人类有一百个理由悲观，关于 AI 对人类的影响，也是悲观者居多。AI 是否会取代人类，我对这个问题并不关心，取代了就取代了吧，这不正是我们要追求的躺平。当年十亿中国人，八亿农民，人们还要为温饱问题而担忧。现在呢，一亿农民都不到吧？那么多农民被取代了，他们不是更开心吗。现在那么多的球员、摄影家、旅行博主、视频博主、。。。，以后玩就是工作，工作就是玩，也挺美好的吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;的确，我们以后需要面对很多 AI 带来的挑战。但我始终保持乐观，有问题就解决问题。就如同代码中 BUG 源源不断，一个个解决就行了，这也是我们存在的价值。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>