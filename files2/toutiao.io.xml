<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3cacd216c8bdcc39182f7e18e08caea8</guid>
<title>单体分层应用架构剖析</title>
<link>https://toutiao.io/k/rd927pj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;分层单体架构风格是分层思想在单体架构中的应用，其关注于技术视角的职责分层。同时，基于不同层变化速率的不同，在一定程度上控制变化在系统内的传播，有助于提升系统的稳定性。但这种技术视角而非业务视角的关注点隔离，导致了问题域与工程实现之间的Gap，这种割裂会导致系统认知复杂度的提升。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;作者：倪新明&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;1 经典单体分层架构&lt;/strong&gt;&lt;/h1&gt;

&lt;h2&gt;&lt;strong&gt;1.1 四层单体架构风格&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;经典的四层单体分层架构如下图所示，应用在逻辑上划分为展现层、业务层、持久层及数据存储层，每层的职责如下：&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;展现层&lt;/strong&gt;：负责给最终用户展现信息，并接受用户的输入触发系统的业务逻辑。用户可以是使用系统的人，也可以是其他软件系统。&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;业务层&lt;/strong&gt;：关注系统业务逻辑的实现&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;持久层&lt;/strong&gt;：负责数据的存取&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;数据存储层&lt;/strong&gt;：底层的数据存储设施&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-13cm6qc7o0hF8HcxR.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这种分层单体架构可能是大多数开发人员最早接触、最为熟悉的应用架构风格，其特点是：&lt;/p&gt;

&lt;p&gt;• 层间的依赖关系由上到下逐层向下直接依赖，每层都是关闭状态，请求的数据流向从上到下，必须严格通过每个分层进行流转，而不能进行穿透调用。&lt;/p&gt;

&lt;p&gt;• 关注点隔离：通过分层将系统的关注点进行垂直分配，每层只关注自身层边界内的职责，层间职责相互独立不存在交叉。比如业务层负责处理系统的核心业务逻辑，而持久层则关注于对数据的存取。&lt;/p&gt;

&lt;p&gt;除了关注点隔离这一维度，分层也在 “变化” 的维度进行隔离。每层的变化速率不同，由下级上逐层增加，展现层的变化速率最快，数据存储层变化速率最低。通过严格层依赖关系约束，尽量降低低层变化对上层的影响。这个特点的上下文是分层之间依赖于抽象，而非依赖于具体。当实现发生变化而接口契约不变时，变更范围框定在当前层。但，如果是接口契约的变更，则可能会直接影响到上游的依赖层。&lt;/p&gt;

&lt;p&gt;这种分层架构风格具有明显的优势：&lt;/p&gt;

&lt;p&gt;• 分层模型比较简单，&lt;strong&gt;理解和实现成本低&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 开放人员接受度和熟悉程度高，&lt;strong&gt;认知和学习成本低&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;1.2 五层单体架构风格&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;四层架构面临的问题是:&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;层间数据效率问题&lt;/strong&gt;: 由于层间调用关系的依赖约束，层间的数据流转需要付出额外成本&lt;/p&gt;

&lt;p&gt;• 业务层服务能力的&lt;strong&gt;复用性&lt;/strong&gt;：业务层中处于对等地位的组件或模块之间存在共享服务的诉求&lt;/p&gt;

&lt;p&gt;从复用性的角度考虑，如下所示的五层架构中，&lt;strong&gt;通过引入中间层解决复用问题&lt;/strong&gt;。将共享服务从业务层沉淀到通用服务层，以提高复用性。其特点是：&lt;/p&gt;

&lt;p&gt;• 引入通用服务层提供通用服务，提高复用性&lt;/p&gt;

&lt;p&gt;• 通用服务层是开放层，允许调用链路穿透，业务层可以按需直接访问更下层的持久层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14OjQ7aaKXCwanUr8.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;相比于四层架构，五层分层架构的主要优势是：通过中间层的引入一定程度解决系统的复用性问题。但从反向角度看，正是由于中间层的引入导致了如下问题：&lt;/p&gt;

&lt;p&gt;• 引入中间层&lt;strong&gt;降低了数据传输效率，提高了开发实现成本&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 有造成系统混乱度提升的风险：由于通用服务层的开放性导致业务层可以穿透调用。但这种是否需要进行穿透的场景无法形成统一的判定原则，往往依赖于实现人员的个人经验进行权衡，同一个业务场景由不同的开发人员实现可能会有不同的判定结果（在四层架构中如果放开层间调用约束也会存在该问题）。随着业务需求迭代，系统的依赖关系一定会日趋增加，最终形成复杂的调用关系，也导致系统复杂性上升，增加团队成员的认知成本。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14RSUjM1411pshyudg.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;2 单体分层架构的共性问题探讨&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;当然，正是由于其极高的接受度，也造成了大家对分层的认知误区，认为分层是必然的“默认选项” ，从而忽略了分层的本质。分层到底是为了解决什么问题？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分层本质上是处理复杂性的一种方式：将复杂性在不同级别进行抽象，通过分层进行职责隔离，以此降低认知成本。同时，通过分层形成的“屏障”，控制变化在系统间的传播，提升系统稳定性。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不论是四层架构还是五层架构都是分层思想在单体应用架构风格下的实践，这种分层模式存在的固有问题主要体现在以下几个方面：&lt;/p&gt;

&lt;p&gt;• 分层对系统复杂度和效率的影响&lt;/p&gt;

&lt;p&gt;• 变化真的能完全隔离吗？&lt;/p&gt;

&lt;p&gt;• 问题域与解决方案的隔离&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.1 分层对系统复杂度和效率的影响&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;如上文所述，分层架构中各层的变化速度不同。越往上变化越快，稳定性越低，越往下变化越慢，稳定性越高。比如，展现层的用户展示逻辑可能频繁变化，对应于不同的场景诉求展示数据及形式都可能不同。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14DXPTxh6DJMBDIKe.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果划分层次越多，层间依赖关系越严格，则系统的调用链路和依赖关系会更加清晰。但，请求及响应的链路越长，层间数据转换有额外成本。即使引入各种数据转换工具，比如MapStruct，实现起来依然会感觉非常繁琐和重复。&lt;/p&gt;

&lt;p&gt;如果划分层次越多，层间依赖关系宽松，允许跨层调用（如下所示的从展现层调用持久层只是一个示意），则能在一定程度降低数据频繁转换的成本。但:&lt;/p&gt;

&lt;p&gt;• 其一：如何判定是否要跨层调用很难形成统一的严格判定标准，只能进行粗粒度划分。因此，在实现过程中会有不同的判定结果，系统的调用关系会随着代码规模增长而日趋复杂。当然，团队可以加强代码评审的粒度，每次评审基于是否穿透调用进行讨论、判断并达成一致。但实际经验是，由于人为因素，靠严格的代码评审并不能保证决策的一致性。&lt;/p&gt;

&lt;p&gt;• 其二：如果允许跨层调用，则意味着 “模型” 的穿透，低层的模型会直接暴露在更上层，这与我们追求的组件内聚性和模型的封装性存在冲突&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：层间的依赖约束是一种架构决策，可以考虑通过自动化单元测试机制进行保证，具体参考&lt;/p&gt;

&lt;p&gt;《 &lt;a href=&quot;http://xingyun.jd.com/shendeng/article/detail/5358?forumId=79&amp;amp;jdme_router=jdme%3A%2F%2Fweb%2F202206081297%3Furl%3Dhttps%3A%2F%2Fshendengh5.jd.com%2FarticleDetail%3Fid%3D5358&quot;&gt;基于ArchUnit守护系统架构&lt;/a&gt; 》&lt;/p&gt;

&lt;p&gt;《 &lt;a href=&quot;http://xingyun.jd.com/shendeng/article/detail/4226?forumId=79&amp;amp;jdme_router=jdme%3A%2F%2Fweb%2F202206081297%3Furl%3Dhttps%3A%2F%2Fshendengh5.jd.com%2FarticleDetail%3Fid%3D4226&quot;&gt;轻量级的架构决策记录机制&lt;/a&gt; - ADR》&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.2 变化的隔离&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;我们对分层有一个普遍的、“先入为主” 的认知，分层能够隔离变化。首先会想到的例子，比如，如果底层的数据库发生了变更，又或者ORM框架发生了变更，那么，我们只需要修改DAO层的实现，而不需要更改上层的业务层代码。&lt;/p&gt;

&lt;p&gt;• 你真的会替换数据库吗？你真的会替换ORM框架吗？有可能，但概率非常低，大部分系统并不会发生这种场景。&lt;/p&gt;

&lt;p&gt;• 发生替换就真的能隔离吗？如果你的层间不是依赖于抽象，而是依赖于具体，那么隔离也无从谈起。&lt;/p&gt;

&lt;p&gt;• 即使层间依赖于抽象，变化就真的隔离了吗？实现发生变化的直接结果就是依赖方需要引用新的实现，这种变化也同样会影响到上层。只不过是这种变化可能交由IOC容器了&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;但，这个是变化隔离的全部吗&lt;/strong&gt;？&lt;/p&gt;

&lt;p&gt;• 如果是展现层需要增加一个新的字段，而当前数据库模型中没有？&lt;/p&gt;

&lt;p&gt;• 如果是数据库中需要增加一个新的字段，而展现层和业务逻辑层不关心？&lt;/p&gt;

&lt;p&gt;• 如果是......&lt;/p&gt;

&lt;p&gt;所以，引起系统变化的原因很多，场景各异，业务诉求亦不相同，分层对变化隔离程度也不相同：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分层可以控制变化在系统内的传播，由于变化场景的多样化，分层不能完全的隔离变化。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-14X8szEXek11zjwh4b.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.3 问题域与解决方案的割裂&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;重新思考下上文提到的分层单体架构的特点之一：关注点隔离，展现层、业务层、数据访问层、存储层等各层聚焦于自身的职责。这种关注点的本质是什么？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术视角的隔离！！！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每层都是从技术视角将技术关注点进行隔离，而非业务领域视角。技术视角是研发友好的，作为开发人员，天然的可以理解和接受这种技术维度的统一语言：DAO层只负责处理数据相关逻辑，Controller层之服务处理Restful API相关，RPC层只处理与外部系统的跨进程调用等等。&lt;/p&gt;

&lt;p&gt;而对于非常核心的业务概念，比如以订单为例，在单体分层架构下需要回答这样一个问题：&lt;strong&gt;“订单组件” 在哪里？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在经典的分层单体架构风格中，典型的实现如下图所示：&lt;/p&gt;

&lt;p&gt;• OrderConroller：Spring技术栈下的系统访问的Rest接口&lt;/p&gt;

&lt;p&gt;• OrderService/OrderServiceImpl：订单的核心业务逻辑实现服务，实现诸如下单、取消订单等逻辑&lt;/p&gt;

&lt;p&gt;• OrderDAO/OrdeDAOImpl：订单数据的存取&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-15rljiOOZWX8fPXou.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;订单组件&lt;strong&gt;并不是以一个单一的、内聚的事物存在&lt;/strong&gt;，其组成元素OrderService以及其依赖的OrderDAO分散于不同的层，因此，这种模式下订单组件只是&lt;strong&gt;逻辑性、概念性&lt;/strong&gt;的存在。作为业务域的核心抽象，订单组件没有真实的、直观的、内聚的反映在代码实现中。我们在工程代码库中寻找“订单组件”：&lt;/p&gt;

&lt;p&gt;• 首先，在工程顶层最先看到的是技术视角的Module(Maven Module)：web、service 、dao&lt;/p&gt;

&lt;p&gt;• 然后，需要在各层导航才能一窥其全貌&lt;/p&gt;

&lt;p&gt;在IDE的支持下，这种导航并不会很复杂。但问题的根本在于：&lt;strong&gt;认知成本的增加&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们去了解系统，&lt;strong&gt;天然的是从业务域而非技术域出发，单体分层恰恰是从技术域而非业务域出发，这种不同导致业务域与实现间的割裂，增加了对系统的认知成本&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现要反应抽象，组件化思维本质上一种模块化思维，通过内聚性和封装性，将问题空间进行拆分成子空间，分而治之。对外通过接口提供组件能力，屏蔽内部的复杂性。接口契约的大小粒度需要权衡，粒度越小，能力提供越约聚焦，理解和接入成本越低，但通用性越差。接口契约粒度越大，则通用性越强，但理解和接入复杂性越高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-157XexthS9xLghJLo.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;将组件化思维应用于单体分层架构，引申出模块化单体架构风格。&lt;strong&gt;应用架构按照问题域进行模块化组织，而非基于技术关注点进行拆分&lt;/strong&gt;。组件内部遵循内聚性原则，其内包含了实现组件能力所需要的各个元素及交互关系。组件之间通过统一的、合适粒度的接口契约进行交互，不直接依赖于组件的内部能力或模型。同时，组织良好的模块化单体应用架构也是进行微服务拆分的重要保证。如果你无法在单体架构中进行优雅的模块化组织，又何谈合理的微服务拆分呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.cn-north-1.jdcloud-oss.com/shendengbucket1/2022-11-08-16-15swKLc4lHaASumTQ.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;3 结语&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;单体分层架构风格是分层思想在单体架构中的应用，其关注于技术视角的职责分层。同时，基于不同层变化速率的不同，在一定程度上控制变化在系统内的传播，有助于提升系统的稳定性。但这种技术视角而非业务视角的关注点隔离，导致了问题域与工程实现之间的Gap，这种割裂会导致系统认知复杂度的提升。将组件化思维应用于单体分层架构，模块化单体技术视角的分层拉回至业务域视角的模块化，一定程度上降低业务与工程实现间的隔离。良好的模块化是单体走向微服务的重要基石，如果模块化设计较差的系统，不仅会增加微服务拆分的成本，更为重要的是，会增加形成分布式单体的概率和风险。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>dbf7e8bdd8486948b257b2047c9d6ba2</guid>
<title>深入浅出学习透析 Nginx 服务器的基本原理和配置指南（Keepalive 性能优化实战篇）</title>
<link>https://toutiao.io/k/fzspi5p</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;content_views&quot; class=&quot;markdown_views prism-tomorrow-night&quot;&gt;
                    &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
                        &lt;path stroke-linecap=&quot;round&quot; d=&quot;M5,0 0,2.5 5,5z&quot; id=&quot;raphael-marker-block&quot;/&gt;
                    &lt;/svg&gt;
                    &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/a4bcbd66fab94f30938a34c53bce13e6.png&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;Linux系统：Centos 7 x64&lt;/li&gt;&lt;li&gt;Nginx版本：1.11.5&lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;Nginx 是一款面向性能设计的 HTTP 服务器，能反向代理 HTTP，HTTPS 和邮件相关(SMTP，POP3，IMAP)的协议链接。并且提供了负载均衡以及 HTTP 缓存。它的设计充分使用异步事件模型，削减上下文调度的开销，提高服务器并发能力。采用了模块化设计，提供了丰富模块的第三方模块。所以关于 Nginx，有这些标签：「异步」「事件」「模块化」「高性能」「高并发」「反向代理」「负载均衡」「长连接」。本章内容主要就是针对于长连接请求模块。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_8&quot;/&gt;为什么要单独讲解keepalive指令？&lt;/h3&gt; 
&lt;p&gt;upstream设置中，有个参数要特别的小心，就是这个keepalive。&lt;/p&gt; 
&lt;p&gt;大多数未仔细研读过nginx的同学通常都会误解这个参数，有些人理解为这里的keepalive是设置是否打开长连接，以为应该设置为on/off。有些人会被前面的keepalive_timeout误导，以为这里也是设置keepalive的timeout。&lt;/p&gt; 
&lt;p&gt;但是实际上这个keepalive参数的含义非常的奇特，请小心看nginx文档中的说明，因为Keepalive长连接非常重要而且容易理解错误，所以专门做连一期专门讲解keepalive的文章。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;本文介绍如何使用Nginx进行配置和实现长连接Keepalive，并介绍如何设置 nginx 以提供静态内容服务，如何配置 nginx 作为代理服务器。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_19&quot;/&gt;keepalive指令&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/ea9babb9b5f54550a425d15ee14ae989.webp#pic_center&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;支持keepalive长连接，当使用nginx作为反向代理时，为了支持长连接，需要做到两点：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;从client到nginx的连接是长连接&lt;/li&gt;&lt;li&gt;从nginx到server的连接是长连接&lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;从HTTP协议的角度看，Nginx在这个过程中，对于客户端它扮演着HTTP服务器端的角色。而对于真正的服务器端（在nginx的术语中称为upstream）Nginx又扮演着HTTP客户端的角色，keepalive指令出现在版本1.1.4。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_31&quot;/&gt;keepalive指令格式&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt;keepalive不是on/off之类的开关&lt;/li&gt;&lt;li&gt;keepalive不是timeout，不是用来设置超时值&lt;/li&gt;&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;Syntax:    keepalive connections;
Default:    —
Context:    upstream
Activates the cache for connections to upstream servers.
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;connections的取值代表着连接到upstream服务器的持续连接（即长连接）的数量。很多人都会有一个误解：认为这个参数是设置到upstream服务器的长连接的数量，分歧在于是最大连接数还是最小连接数&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;&lt;a id=&quot;_45&quot;/&gt;官方文档的介绍&lt;/h5&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;The connections parameter sets the maximum number of idle keepalive connections to upstream servers&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt;connections参数设置到upstream服务器的空闲keepalive连接的最大数量，这个”idle”的概念，何为idle。大多数人之所以误解为是到upstream服务器的最大长连接数，一般都是因为看到了文档中的这句话，而漏看了这个”idle”一词。&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;When this number is exceeded, the least recently used connections are closed.&lt;/p&gt; 
&lt;/blockquote&gt; 
 
&lt;p&gt;Nginx的官方文档给出了指示，否定了最大连接数的可能：&lt;strong&gt;keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量&lt;/strong&gt;。&lt;strong&gt;请注意空闲keepalive连接的最大数量中空闲这个关键字&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_55&quot;/&gt;keepalive实际场景分析&lt;/h4&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;先假设一个场景： 有一个HTTP服务，作为upstream服务器接收请求，响应时间为100毫秒。如果要达到10000 QPS的性能，就需要在nginx和upstream服务器之间建立大约1000条HTTP连接。nginx为此建立连接池，然后请求过来时为每个请求分配一个连接，请求结束时回收连接放入连接池中，连接的状态也就更改为idle。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;之后假设这个upstream服务器的keepalive参数设置比较小，比如常见的10.&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;再次假设请求和响应是均匀而平稳的，那么这1000条连接应该都是一放回连接池就立即被后续请求申请使用，线程池中的idle线程会非常的少，趋进于零。我们以10毫秒为一个单位，来看连接的情况(注意场景是1000个线程+100毫秒响应时间，每秒有10000个请求完成)：&lt;/p&gt; 
  &lt;ul&gt;&lt;li&gt;每10毫秒有100个新请求，需要100个连接&lt;/li&gt;&lt;li&gt;每10毫秒有100个请求结束，可以释放100个连接&lt;/li&gt;&lt;li&gt;如果请求和应答都均匀，则10毫秒内释放的连接刚好够用，不需要新建连接，连接池空闲连接为零&lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;如果请求通常不是足够的均匀和平稳，为了简化问题，我们假设应答始终都是平稳的，只是请求不平稳，第一个10毫秒只有50,第二个10毫秒有150：&lt;/p&gt; 
   &lt;/li&gt;&lt;li&gt; &lt;p&gt;&lt;strong&gt;再下一个10个毫秒，有150个请求进来，有100个请求结束任务释放连接。150 - 100 = 50,空缺了50个连接，减掉前面连接池保留的10个空闲连接，nginx不得不新建40个新连接来满足要求&lt;/strong&gt;。&lt;/p&gt; 
   &lt;/li&gt;&lt;li&gt; &lt;p&gt;前10毫秒，进来100个请求，结束50个请求，导致连接不够用，nginx为此新建50个连接&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;后10毫秒，进来100个请求，结束150个请求，导致空闲连接过多，ngixn为此关闭了150-100-10=40个空闲连接&lt;/p&gt; 
  &lt;ul&gt;&lt;li&gt;&lt;strong&gt;第二个应答不均匀的场景实际上是对应第一个请求不均匀的场景：正是因为请求不均匀，所以导致100毫秒之后这些请求的应答必然不均匀&lt;/strong&gt;。&lt;/li&gt;&lt;/ul&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;p&gt;现实世界中的请求往往和理想状态有巨大差异，请求不均匀，服务器处理请求的时间也不平稳，这理论上的大概1000个连接在反复的回收和再分配的过程中，必然出现两种非常矛盾场景在短时间内反复：&lt;/p&gt; 
&lt;ol&gt;&lt;li&gt;连接不够用，造成新建连接&lt;/li&gt;&lt;li&gt;连接空闲，造成关闭连接。从而使得总连接数出现反复震荡，不断的创建新连接和关闭连接，使得长连接的效果被大大削弱。&lt;/li&gt;&lt;/ol&gt; 
&lt;h4&gt;&lt;a id=&quot;Keepalive_88&quot;/&gt;Keepalive参数建议&lt;/h4&gt; 
&lt;p&gt;造成连接数量反复震荡的一个推手，就是这个keepalive 这个最大空闲连接数。毕竟连接池中的1000个连接在频繁利用时，出现短时间内多余10个空闲连接的概率实在太高。因此为了避免出现上面的连接震荡，必须考虑加大这个参数，&lt;strong&gt;比如上面的场景如果将keepalive设置为100或者200,就可以非常有效的缓冲请求和应答不均匀&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;keepalive_92&quot;/&gt;keepalive参数分析&lt;/h3&gt; 
&lt;ul&gt;&lt;li&gt;对应的参数设置为每个worker子进程在缓冲中保持的到upstream服务器的空闲keepalive连接的最大数量。当超过这个数量值的时候，会将最近最少使用（LRU）的连接进行关闭。需要考虑的是keepalive指令不会限制一个worker进程到upstream服务器连接的总数量。其参数应该设置为一个足够小的数字来让upstream服务器来处理新进来的连接。&lt;/li&gt;&lt;li&gt;如果想让upstream每次都处理新的进来的连接，就应该将这个值放的足够小。反过来理解，就是如果不想让upstream服务器处理新连接，就应该放大一些？&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;Keepalive_97&quot;/&gt;Keepalive的使用案例&lt;/h4&gt; 
&lt;h5&gt;&lt;a id=&quot;Keepalivememcached_99&quot;/&gt;Keepalive对接memcached服务&lt;/h5&gt; 
&lt;p&gt;使用keepalive连接的memcached upstream配置的例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream memcached_backend {
    server 127.0.0.1:11211;
    server 10.0.0.2:11211;
    keepalive 32;
}
server {
    ...
    location /memcached/ {
        set $memcached_key $uri;
        memcached_pass memcached_backend;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveHttp11Web_117&quot;/&gt;Keepalive对接Http1.1的Web服务&lt;/h5&gt; 
&lt;p&gt;对于HTTP，proxy_http_version指定应该设置为”1.1”，而”Connection” header应该被清理：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream http_backend {
    server 127.0.0.1:8080;
    keepalive 16;
}
server {
    ...
    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection &quot;&quot;;
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveHttp10Web_136&quot;/&gt;Keepalive对接Http1.0的Web服务&lt;/h5&gt; 
&lt;p&gt;HTTP/1.0 持久连接可以通过传递”&lt;strong&gt;Connection: Keep-Alive&lt;/strong&gt;” header 到upstream server， 但是不推荐使用这种方法。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;KeepaliveFastCGIWeb_140&quot;/&gt;Keepalive对接FastCGI的Web服务&lt;/h5&gt; 
&lt;p&gt;对于FastCGI服务器，要求设置fastcgi_keep_conn来让长连接工作：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;upstream fastcgi_backend {
    server 127.0.0.1:9000;
    keepalive 8;
}
server {
    ...
    location /fastcgi/ {
        fastcgi_pass fastcgi_backend;
        fastcgi_keep_conn on;
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;当使用默认的round-robin之外的负载均衡算法时，必须在keepalive指令之前激活他们。SCGI 和 uwsgi 协议没有keepalive连接的概念。&lt;/p&gt; 
&lt;h3&gt;&lt;a id=&quot;client_161&quot;/&gt;保持和client的长连接&lt;/h3&gt; 
&lt;p&gt;为了在client和nginx之间保持上连接，有两个要求：&lt;/p&gt; 
&lt;ul&gt;&lt;li&gt;client发送的HTTP请求要求keep alive&lt;/li&gt;&lt;li&gt;nginx设置上支持keep alive&lt;/li&gt;&lt;/ul&gt; 
&lt;h4&gt;&lt;a id=&quot;HTTP_167&quot;/&gt;HTTP配置&lt;/h4&gt; 
&lt;p&gt;默认情况下，Nginx已经自动开启了对client连接的keep alive支持。一般场景可以直接使用，但是对于一些比较特殊的场景，还是有必要调整个别参数。需要修改nginx的配置文件(在nginx安装目录下的conf/nginx.conf):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http {
    keepalive_timeout  120s 120s;
    keepalive_requests 10000;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_timeout_178&quot;/&gt;keepalive_timeout指令&lt;/h4&gt; 
&lt;p&gt;keepalive_timeout指令的语法：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Syntax:    keepalive_timeout timeout [header_timeout];
Default:    keepalive_timeout 75s;
Context:    http, server, location
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt;&lt;li&gt;第一个参数设置keep-alive客户端连接在服务器端保持开启的超时值。值为0会禁用keep-alive客户端连接。&lt;/li&gt;&lt;li&gt;可选的第二个参数在响应的header域中设置一个值“Keep-Alive: timeout=time”。这两个参数可以不一样。&lt;/li&gt;&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;注：默认75s一般情况下也够用，对于一些请求比较大的内部服务器通讯的场景，适当加大为120s或者300s。第二个参数通常可以不用设置&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;a id=&quot;keepalive_requests_193&quot;/&gt;keepalive_requests指令&lt;/h4&gt; 
&lt;p&gt;keepalive_requests指令用于设置一个keep-alive连接上可以服务的请求的最大数量。当最大请求数量达到时，连接被关闭。默认是100。&lt;/p&gt; 
&lt;h5&gt;&lt;a id=&quot;keepalive_requests_197&quot;/&gt;keepalive_requests指令的实现原理&lt;/h5&gt; 
&lt;ul&gt;&lt;li&gt;指一个keepalive请求建立之后，Nginx就会为这个连接设置一个计数器，记录这个keep alive的长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则Nginx会强行关闭这个长连接，逼迫客户端不得不重新建立新的长连接。&lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;这个参数往往被大多数人忽略，因为大多数情况下当QPS(每秒请求数)不是很高时，默认值100凑合够用。但是，对于一些QPS比较高（比如超过10000QPS，甚至达到30000,50000甚至更高) 的场景，默认的100就显得太低&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt;&lt;li&gt; &lt;p&gt;&lt;strong&gt;简单计算一下，QPS=10000时，客户端每秒发送10000个请求(通常建立有多个长连接)，每个连接只能最多跑100次请求，意味着平均每秒钟就会有100个长连接因此被nginx关闭&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt;&lt;li&gt; &lt;p&gt;为了保持QPS，客户端不得不每秒中重新新建100个连接。因此，如果用netstat命令看客户端机器，就会发现有大量的TIME_WAIT的socket连接(即使此时keep alive已经在client和nginx之间生效)。&lt;/p&gt; &lt;/li&gt;&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;因此对于QPS较高的场景，非常有必要加大这个参数，以避免出现大量连接被生成再抛弃的情况，减少TIME_WAIT&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a id=&quot;server_209&quot;/&gt;保持和server的长连接&lt;/h3&gt; 
&lt;p&gt;为了让Nginx和server（Nginx称为upstream）之间保持长连接，典型设置如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http {
    upstream  BACKEND {
        server   192.168.0.1：8080  weight=1 max_fails=2 fail_timeout=30s;
        server   192.168.0.2：8080  weight=1 max_fails=2 fail_timeout=30s;
        keepalive 300;        // 这个很重要！
    }
    server {
        listen 8080 default_server;
        server_name &quot;&quot;;
        location /  {
            proxy_pass http://BACKEND;
            proxy_set_header Host  $Host;
            proxy_set_header x-forwarded-for $remote_addr;
            proxy_set_header X-Real-IP $remote_addr;
            add_header Cache-Control no-store;
            add_header Pragma  no-cache;
            proxy_http_version 1.1;                    // 这两个最好也设置
            proxy_set_header Connection &quot;&quot;;
            client_max_body_size  3072k;
            client_body_buffer_size 128k;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr/&gt; 
&lt;h4&gt;&lt;a id=&quot;_240&quot;/&gt;总结&lt;/h4&gt; 

                &lt;/div&gt;
                
                
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e2b0d2f163e2a98db100c03aee26fbdd</guid>
<title>MySQL 数据库索引技术原理初探</title>
<link>https://toutiao.io/k/vwg43on</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;article fmt article-content &quot;&gt;&lt;h2&gt;概述&lt;/h2&gt;&lt;h3&gt;什么是索引&lt;/h3&gt;&lt;p&gt;一本书 500 页的书，如果没有目录，直接去找某个知识点，可能需要找一会儿，但是借助前面的目录，就可以快速找到对应知识点在书的哪一页。这里的目录就是索引。&lt;/p&gt;&lt;p&gt;所以，为什么会有索引？为了提高数据查询效率。&lt;/p&gt;&lt;h2&gt;常见索引算法&lt;/h2&gt;&lt;p&gt;最简单也最容易想到的索引算法就是有序数组了，我们创建一个数组，数组按照顺序排列，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912713&quot; alt=&quot;img&quot; title=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们要查找某一条记录，使用二分法就可以快速得到(log N)，从图中我们可以看出，有序数组作为索引时，处理等值查询和范围查询时性能会非常优秀。既然这么优秀，为什么我们不使用它呢？&lt;/p&gt;&lt;p&gt;因为它的插入性能很差，每次往中间插入一条记录，就必须挪动后面所有的记录，这个成本太高了。&lt;/p&gt;&lt;p&gt;第二种算法时哈希表，哈希表时一种 KV 形式存储的数据结构，比如我们平时用的 HashMap。哈希表的思路非常简单，用一个哈希函数把Key 换算成一个确定的位置，把 V 放到这个位置就可以了。&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912714&quot; alt=&quot;img&quot; title=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们可以看得出，哈希表这种数据结构在进行等值查询的时候，效率时非常高的，我们常用的 Redis 以及以前比较流行的 Memcached 都使用了哈希表。但是哈希表有个致命缺陷，就是对范围查询的支持性非常差，因为数据的存储时无序的，无论我们要查询的范围有多大，都必须把所有的数据全部便利一遍做个排序才行。&lt;/p&gt;&lt;p&gt;在讲第三种索引方式之前，我们简单了解下机械硬盘存取数据的原理&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912715&quot; alt=&quot;image-20210326092749979&quot; title=&quot;image-20210326092749979&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;要访问磁盘上的某个条数据，我们需要通过磁道，扇区来确定数据所在的 Block，然后通过 Offset  就可以定位到磁盘上的任意一个字节。从磁盘上读取数据时，都是以 Block 的形式读取的。这里我们可以看到，一个 Block 的大小是 512 Bytes，当然，这是针对磁盘设备的，对于 Linux 的文件系统来说，一个 Block 一般是 4KB。InnoDB 数据存取是以数据页为单位的，数据页相比磁盘 Block 要大一些，一般默认是 16KB。为了简化整个模型，我们这里抛开复杂的数据页或者文件系统 Block 概念，从磁盘的 Block 开始说起&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912716&quot; alt=&quot;image-20210326092835533&quot; title=&quot;image-20210326092835533&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;假设我们的数据库里面存储了 1000 条记录，每条记录占用 128 Bytes，前面我们说过，一个磁盘的 Block 能够存储 512 Bytes，也就是说，一个 Block 可以存储 4 条记录，存储这些记录，一共需要 250 个 Blocks。当我们需要查询一条数据时，最多需要从磁盘加载 250 个Blocks，想想读取 250 次磁盘会有多慢！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912717&quot; alt=&quot;image-20210326092923323&quot; title=&quot;image-20210326092923323&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;为了减少对磁盘的访问次数，我们可以把所有记录的 id 单独拿出来创建一个索引 L1，这个 id 和指向原始数据的地址组成了一个新的数据结构，它的长度这里是 16 Bytes，索引也是需要存储到磁盘的，一个 Block 可以存储 32 条索引记录，1000条索引记录需要 （1000/32=31.25） 32 个 Blocks。这时候我们需要查询一条数据时，就变成了先从索引表中查询出对应数据的指针（读取 32 个 Blocks），然后再去源数据表中根据地址直接读取记录所在的数据块（1个Block）。看，通过增加一个索引，我们成功的将磁盘读取次数从 250 次减少到了 33 次。我们可不可以让读取磁盘次数更少呢，当然可以！再增加一级索引呗！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912718&quot; alt=&quot;image-20210326093000953&quot; title=&quot;image-20210326093000953&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;新添加的这一级索引指向了前面我们添加的索引 L1 所在的数据块。在这一级索引上，每一条记录都对应了 L1 索引所在的数据块，也就是 32 条L1索引记录所在的位置。1000条数据在这里还剩多少呢，前面我们说过，1000条数据共需要 32 个 L1 索引 Block，对应在这里也就是需要 32 条 L2 索引，总空间占用才 32x16 = 512 Bytes，刚好一个磁盘 Block 大小。到这一级，我们需要访问磁盘的次数就变成了 1+1+1=3 了！&lt;/p&gt;&lt;p&gt;我们把上面这个图抽象一下，去掉其中的细节，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912719&quot; alt=&quot;image-20210326093031086&quot; title=&quot;image-20210326093031086&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;当我们把它旋转一下的时候，我们就得到了这样一种数据结构&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912720&quot; alt=&quot;image-20210326093055460&quot; title=&quot;image-20210326093055460&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;看！这不就是一棵树嘛&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912721&quot; alt=&quot;image-20210326104832514&quot; title=&quot;image-20210326104832514&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;说到树，我们知道最简单的就是二叉树了，二叉树的典型特点是有序，左子树小于父节点，右子树大于父节点。无论是搜索效率还是插入效率，二叉树的效率都是非常高的（log N），但是大多数数据库并不使用它，这是为什么呢？&lt;/p&gt;&lt;p&gt;因为我们的数据是存储在磁盘上的，程序运行过程中要使用数据，必须从磁盘把数据加载到内存才行。二叉树随着节点的增多，树的高度页越来越高，对应到磁盘访问上，我们就需要访问更多的数据块。当我们的数据存储在机械硬盘的时候，从磁盘随机读取一个数据块就需要 10ms 左右的寻址时间，也就是说，如果我们扫描一个 100 万行的表，单独访问一行就可能需要 20 个 10ms，可想可知这个查询会有多慢！&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912722&quot; alt=&quot;_images/binary-tree.png&quot; title=&quot;_images/binary-tree.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;当然，我们这棵树可不是二叉树，因为每个分支都可能有很多条记录。我们把这种树称为 N 叉树，也就是多叉树，树的分叉越多，每个节点的子节点就越多，树的高度就越低。因此就有B-Tree 和 B+Tree。&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912723&quot; alt=&quot;Image 1&quot; title=&quot;Image 1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;h2&gt;B+Tree 索引&lt;/h2&gt;&lt;p&gt;讲到 B+ 树索引，我们就不得不一下 B 树索引，前面我们简单了解了下二叉树，我们知道，二叉树的树高太大，会严重影响查询效率，为了解决这个问题，就有了 B 树&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912724&quot; alt=&quot;索引&quot; title=&quot;索引&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;B树是为了更好的实现索引结构而被创造出来的，它大幅度减少了磁盘访问的次数。除此之外，它还充分利用了“局部性原理”（数据有序，相关性强）。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;局部性原理：在一段时间内，整个程序的执行仅限于程序的某一部分，相应的，执行所访问的存储空间也局限于某个内存区域。局部性原理分为时间局部性和空间局部性。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;时间局部性：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）&lt;/li&gt;&lt;li&gt;空间局部性：如果一个存储器的位置被引用，那么将来它附近的位置也会被引用&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;利用局部性原理可以实现磁盘预读，前面提过，InnoDB一次是读取一页的数据（16K），也就是说，每次我们实际加载的数据比我们需要的可能会多一些，这些数据可以缓存在内存中，未来我们需要读取的时候，就可以避免磁盘 IO 了。&lt;/p&gt;&lt;p&gt;但是B树有着下面两个缺陷&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个节点都存储数据，因此索引会变得很大，每个 Block 能够容纳的索引数就会变少，我们也就需要访问更多次的磁盘&lt;/li&gt;&lt;li&gt;对范围查询支持不是很好，需要中序遍历&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这两个问题，B+ 树就诞生了，&lt;/p&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912725&quot; alt=&quot;索引&quot; title=&quot;索引&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;B+树只有叶子节点才存储数据，其它节点不再存储数据，所有的叶子节点都在同一层上，叶子节点之间增加了一条链表，通过这条链表，我们就可以依次直接遍历所有数据。这些变化，让 B+ 树拥有了比 B 树更优秀的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;非叶子节点不存储数据，可以实现查询加速（一次磁盘访问可以读取更多的索引记录，减少磁盘访问）&lt;/li&gt;&lt;li&gt;范围查询更加优秀，可以顺着叶子节点的链表直接查询出某一个范围内的数据&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;B+数是一棵 N 叉树，N 的大小取决于索引字段的大小，以整数字段索引为例，N≈1200，当树高为 4 的时候，就是 1200 的 3 次方，17亿。一个 10 亿行的表上一个整数字段索引，查找一个值最多只需要访问 3 次磁盘（树根一般在内存中）。&lt;/p&gt;&lt;p&gt;MySQL 的 InnoDB 就是采用了 B+ 树作为默认的索引算法，前面我们说了，B+树只在叶子节点存储数据，但是这个叶子节点存储的是什么数据呢? 我们根据叶子存储数据类型的不同分为两种索引&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主键索引，也成为聚簇索引（Clustered index），在叶子节点存储的是整行数据&lt;/li&gt;&lt;li&gt;非主键索引，也成为二级索引（Secondary index），叶子节点存储的是主键的值&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; src=&quot;/img/remote/1460000042912726&quot; alt=&quot;image-20210326115557786&quot; title=&quot;image-20210326115557786&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;&lt;p&gt;正因为在 InnoDB 中，我们的数据也是存储在一个索引（主键索引）里的，因此，我们称 InnoDB 是索引组织表。二级索引存储的是数据的主键，当我们使用二级索引查询一条数据的时候，首先会从二级索引中查询到这条记录的 ID，然后拿这个 ID 去主键索引查询真正的数据，我们称这个过程为 回表。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;因为二级索引存储的是主键的 ID，因此通常我们会选择 integer 或者 bigint 等整型类型作为主键，这样做的目的是可以减少二级索引占用空间的大小。如果用字符串作为主键，可想可知二级索引会有多大！&lt;/p&gt;&lt;p&gt;除了上面这个外，通常要求主键一定是要自增的，这样做是为了保证主键的有序，每次插入数据都是追加到 B+ 树，避免页分裂（如果数据页满了，则需要申请新的数据页，然后挪动部分数据过去，这个过程叫做 页分裂）的产生，提高数据写入性能。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;从上面讲的这些，我们可以想到下面几个优化索引的技巧&lt;/p&gt;&lt;ul&gt;&lt;li&gt;索引应该尽可能小，这样一次磁盘读取可以返回尽可能多的索引数据，在查询数据时就可以减少磁盘 IO&lt;/li&gt;&lt;li&gt;大表查询尽可能的使用索引，不使用索引就会造成全表扫描，想想一个查询，需要遍历几百万数据，读取成千上百次磁盘会有多慢&lt;/li&gt;&lt;li&gt;如果可能，尽量使用主键索引进行查询，使用主键索引可以直接触达数据，不需要执行回表，减少磁盘 IO&lt;/li&gt;&lt;li&gt;如果索引中包含了我们要查询的所有字段，那就不需要在进行回表，可以减少磁盘 IO，显著提升查询性能，我们把这种查询数据都在索引里面的情况叫做覆盖索引&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;这次分享中，我们先简单介绍了下两种简单的索引结构，然后从数据在磁盘的存储说起，从没有索引到建立多级索引，解释了为什么会出现树索引以及B树索引和 B+树索引，最后我们介绍了下 InnoDB 中关于主键索引和二级索引的概念和几个优化索引的技巧。&lt;/p&gt;&lt;p&gt;本文将会持续修正和更新，最新内容请参考我的 &lt;a href=&quot;https://link.segmentfault.com/?enc=EEqu1wvH%2Bicw4Q6AlzddVA%3D%3D.J3iqbgU3haTK5wpWhmTxI7dqua4Pwc7s3oeqlTLvNDI%3D&quot; rel=&quot;nofollow&quot;&gt;GITHUB&lt;/a&gt; 上的 &lt;a href=&quot;https://link.segmentfault.com/?enc=5XUVTlPU%2BCMk3No7yYyR2w%3D%3D.5hT6Tiz1beWVXmGt0TPUR0Lfncq14kHMJdDcKSkYR%2BpNMbCKsCYCdky%2BhAZiHRmE&quot; rel=&quot;nofollow&quot;&gt;程序猿成长计划&lt;/a&gt; 项目，欢迎 Star，更多精彩内容请 &lt;a href=&quot;https://link.segmentfault.com/?enc=xgvnO08KYatQ5F%2BWWsgYLQ%3D%3D.ciNNSwwnGpG%2Bif6gFWbeO4g1mpz532Li4581ugY9jPY%3D&quot; rel=&quot;nofollow&quot;&gt;follow me&lt;/a&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>05a6b9ae0f8e0cc552cc1ab0ba79afd7</guid>
<title>这几种神级性能优化手段，你用过几个？</title>
<link>https://toutiao.io/k/qgdj6f4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;引言：取与舍&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;软件设计开发某种意义上是“取”与“舍”的艺术。关于性能方面，就像建筑设计成抗震9度需要额外的成本一样，高性能软件系统也意味着更高的实现成本，有时候与其他质量属性甚至会冲突，比如安全性、可扩展性、可观测性等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大部分时候我们需要的是：在业务遇到瓶颈之前，利用常见的技术手段将系统优化到预期水平。那么，&lt;strong&gt;性能优化有哪些技术方向和手段呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;性能优化通常是“时间”与“空间”的互换与取舍&lt;/strong&gt;。本篇讲解六种通用的“时间”与“空间”互换取舍的手段：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每种性能优化的技术手段，我都找了一张&lt;strong&gt;应景&lt;/strong&gt;的《火影忍者》中人物或忍术的配图，评论区答出任意人物或忍术送一颗小星星。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（注：所有配图来自动漫《火影忍者》，部分图片添加了文字方便理解，仅作技术交流用途）&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;索引术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7157001414427157&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6a9VECuBLuibg6uu4GuP8rMjYc6aCXvyMOlAicchgJWiaA5wWULvafVzz9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;707&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;10ms之后。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7241379310344828&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6adPxiagQf98PtgyHdDpf4vS92TD7EiaLbhYeiboHAuOhpJtnU0VT9Q8lzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;580&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;索引&lt;/strong&gt;的原理是&lt;strong&gt;拿额外的存储空间换取查询时间&lt;/strong&gt;，增加了&lt;strong&gt;写入数据&lt;/strong&gt;的开销，但使&lt;strong&gt;读取数据&lt;/strong&gt;的时间复杂度一般从O(n)降低到O(logn)甚至O(1)。索引不仅在数据库中广泛使用，前后端的开发中也在不知不觉运用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据集比较大时，不用索引就像从一本&lt;strong&gt;没有目录而且内容乱序&lt;/strong&gt;的新华字典查一个字，得一页一页全翻一遍才能找到；用索引之后，就像用拼音先在目录中先&lt;strong&gt;找到要查到字在哪一页&lt;/strong&gt;，直接翻过去就行了。书籍的目录是典型的树状结构，那么软件世界常见的索引有哪些数据结构，分别在什么场景使用呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;哈希表（Hash Table）&lt;/strong&gt;：哈希表的原理可以类比银行办业务取号，给每个人一个号（计算出的Hash值），叫某个号直接对应了某个人，索引效率是最高的O(1)，消耗的存储空间也相对更大。K-V存储组件以及各种编程语言提供的Map/Dict等数据结构，多数底层实现是用的哈希表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;二叉搜索树（Binary Search Tree）&lt;/strong&gt;：有序存储的二叉树结构，在编程语言中广泛使用的&lt;span&gt;&lt;strong&gt;红黑树&lt;/strong&gt;&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;属于二叉搜索树，确切的说是“不完全平衡的”二叉搜索树。从C++、Java的TreeSet、TreeMap，到&lt;span&gt;Linux的CPU调度&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;，都能看到红黑树的影子。Java的HashMap在发现某个Hash槽的链表长度大于8时也会将链表升级为红黑树，而相比于红黑树“更加平衡”的AVL树反而实际用的更少。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;平衡多路搜索树（B-Tree）&lt;/strong&gt;：这里的B指的是Balance而不是Binary，二叉树在大量数据场景会导致查找深度很深，解决办法就是变成多叉树，MongoDB的索引用的就是B-Tree。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;叶节点相连的平衡多路搜索树（B+ Tree）&lt;/strong&gt;：B+ Tree是B-Tree的变体，只有叶子节点存数据，叶子与相邻叶子相连，MySQL的索引用的就是B+树，Linux的一些文件系统也使用的B+树索引inode。其实B+树还有一种在枝桠上再加链表的变体：B*树，暂时没想到实际应用。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;日志结构合并树（LSM Tree）&lt;/strong&gt;：Log Structured Merge Tree，简单理解就是像日志一样顺序写下去，多层多块的结构，上层写满压缩合并到下层。LSM Tree其实本身是为了优化写性能牺牲读性能的数据结构，并不能算是索引，但在大数据存储和一些NoSQL数据库中用的很广泛，因此这里也列进去了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;字典树（Trie Tree）&lt;/strong&gt;：又叫前缀树，从树根串到树叶就是数据本身，因此树根到枝桠就是前缀，枝桠下面的所有数据都是匹配该前缀的。这种结构能非常方便的做前缀查找或词频统计，典型的应用有：自动补全、URL路由。其变体基数树（Radix Tree）在Nginx的Geo模块处理子网掩码前缀用了；Redis的Stream、Cluster等功能的实现也用到了基数树（Redis中叫Rax）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;跳表（Skip List）&lt;/strong&gt;：是一种多层结构的有序链表，插入一个值时有一定概率“晋升”到上层形成间接的索引。跳表更适合大量并发写的场景，不存在红黑树的再平衡问题，Redis强大的ZSet底层数据结构就是哈希加跳表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;倒排索引（Inverted index）&lt;/strong&gt;：这样翻译不太直观，可以叫“关键词索引”，比如书籍末页列出的术语表就是倒排索引，标识出了每个术语出现在哪些页，这样我们要查某个术语在哪用的，从术语表一查，翻到所在的页数即可。倒排索引在全文索引存储中经常用到，比如ElasticSearch非常核心的机制就是倒排索引；Prometheus的时序数据库按标签查询也是在用倒排索引。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据库主键之争&lt;/strong&gt;：自增长 vs UUID。主键是很多数据库非常重要的索引，尤其是MySQL这样的RDBMS会经常面临这个难题：是用自增长的ID还是随机的UUID做主键？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自增长ID的性能最高，但不好做分库分表后的全局唯一ID，自增长的规律可能泄露业务信息；而UUID不具有可读性且太占存储空间。争执的结果就是找一个兼具二者的优点的&lt;strong&gt;折衷方案&lt;/strong&gt;：用&lt;strong&gt;雪花算法&lt;/strong&gt;生成分布式环境全局唯一的ID作为业务表主键，性能尚可、不那么占存储、又能保证全局单调递增，但引入了额外的复杂性，再次体现了取舍之道。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再回到&lt;strong&gt;数据库&lt;/strong&gt;中的索引，建索引要注意哪些点呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;定义好主键并尽量使用主键，多数数据库中，主键是效率最高的&lt;strong&gt;聚簇索引&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在&lt;strong&gt;Where&lt;/strong&gt;或&lt;strong&gt;Group By、Order By、Join On&lt;/strong&gt;条件中用到的字段也要&lt;strong&gt;按需&lt;/strong&gt;建索引或联合索引，MySQL中搭配explain命令可以查询DML是否利用了索引；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;类似枚举值这样重复度太高的字段&lt;strong&gt;不适合&lt;/strong&gt;建索引（如果有位图索引可以建），频繁更新的列不太适合建索引；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;单列索引可以根据&lt;strong&gt;实际查询的字段&lt;/strong&gt;升级为&lt;strong&gt;联合索引&lt;/strong&gt;，通过部分冗余达到&lt;strong&gt;索引覆盖&lt;/strong&gt;，以&lt;strong&gt;避免回表&lt;/strong&gt;的开销；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽量减少索引冗余，比如建A、B、C三个字段的联合索引，Where条件查询A、A and B、A and B and C 都可以利用该联合索引，就无需再给A单独建索引了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;根据数据库特有的索引特性选择适合的方案，比如像MongoDB，还可以建自动删除数据的&lt;strong&gt;TTL索引&lt;/strong&gt;、不索引空值的&lt;strong&gt;稀疏索引&lt;/strong&gt;、地理位置信息的&lt;strong&gt;Geo索引&lt;/strong&gt;等等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;数据库之外&lt;/strong&gt;，在代码中也能应用索引的思维，比如对于集合中大量数据的查找，使用&lt;strong&gt;Set、Map、Tree&lt;/strong&gt;这样的数据结构，其实也是在用哈希索引或树状索引，比&lt;strong&gt;直接遍历&lt;/strong&gt;列表或数组查找的性能高很多。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;缓存术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5381165919282511&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6aJTaeRCRARibHgUiaNicNy4UkBlmMpvqNOPWmfZFdyCsu2j8brhiaibEf7Pw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;缓存&lt;/strong&gt;优化性能的原理和索引一样，是拿额外的&lt;strong&gt;存储空间换取查询时间&lt;/strong&gt;。缓存无处不在，设想一下我们在浏览器打开这篇文章，会有多少层缓存呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;首先解析DNS时，浏览器一层DNS缓存、操作系统一层DNS缓存、DNS服务器链上层层缓存；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;发送一个GET请求这篇文章，服务端很可能早已将其缓存在KV存储组件中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使没有击中缓存，数据库服务器内存中也缓存了最近查询的数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使没有击中数据库服务器的缓存，数据库从索引文件中读取，操作系统已经把热点文件的内容放置在Page Cache中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使没有击中操作系统的文件缓存，直接读取文件，大部分固态硬盘或者磁盘本身也自带缓存；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据取到之后服务器用模板引擎渲染出HTML，模板引擎早已解析好缓存在服务端内存中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;历经数十毫秒之后，终于服务器返回了一个渲染后的HTML，浏览器端解析DOM树，发送请求来加载静态资源；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;需要加载的静态资源可能因Cache-Control在浏览器本地磁盘和内存中已经缓存了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使本地缓存到期，也可能因Etag没变服务器告诉浏览器304 Not Modified继续缓存；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;即使Etag变了，静态资源服务器也因其他用户访问过早已将文件缓存在内存中了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;加载的JS文件会丢到JS引擎执行，其中可能涉及的种种缓存就不再展开了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;整个过程中链条上涉及的&lt;strong&gt;所有的计算机和网络设备&lt;/strong&gt;，执行的热点代码和数据很可能会载入CPU的多级高速缓存。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里列举的&lt;strong&gt;仅仅是一部分&lt;/strong&gt;常见的缓存，就有多种多样的形式：从廉价的磁盘到昂贵的CPU高速缓存，最终目的都是用来换取宝贵的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;缓存是“银弹”吗？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不，Phil Karlton 曾说过：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;计算机科学中只有两件困难的事情：缓存失效和命名规范。There are only two hard things in Computer Science: cache invalidation and naming things.&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缓存的使用除了带来额外的复杂度以外，还面临如何处理&lt;strong&gt;缓存失效&lt;/strong&gt;的问题。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;多线程并发编程需要用各种手段（比如Java中的synchronized volatile）防止并发更新数据，一部分原因就是防止线程&lt;strong&gt;本地缓存的不一致&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缓存失效衍生的问题还有：&lt;strong&gt;缓存穿透、缓存击穿、缓存雪崩&lt;/strong&gt;。解决用不存在的Key来穿透攻击，需要用空值缓存或布隆过滤器；解决单个缓存过期后，瞬间被大量恶意查询击穿的问题需要做查询互斥；解决某个时间点大量缓存同时过期的雪崩问题需要添加随机TTL；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;热点数据如果是&lt;strong&gt;多级缓存&lt;/strong&gt;，在发生修改时需要清除或修改&lt;strong&gt;各级缓存&lt;/strong&gt;，这些操作往往不是原子操作，又会涉及各种不一致问题。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了通常意义上的缓存外，&lt;strong&gt;对象重用的池化技术&lt;/strong&gt;，也可以看作是一种&lt;strong&gt;缓存的变体&lt;/strong&gt;。常见的诸如JVM，V8这类运行时的&lt;strong&gt;常量池、数据库连接池、HTTP连接池、线程池、Golang的sync.Pool对象池&lt;/strong&gt;等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在需要某个资源时从现有的池子里直接拿一个，稍作修改或直接用于另外的用途，池化重用也是性能优化常见手段。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;压缩术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5297418630751964&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6aMWhBpZThh7Lb3oDmvSQ2JLIyqClBqhaDtGqVd4iaZxteWdOMUSq68ibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;891&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说完了两个“空间换时间”的，我们再看一个“&lt;strong&gt;时间换空间&lt;/strong&gt;”的办法——&lt;strong&gt;压缩&lt;/strong&gt;。压缩的原理&lt;strong&gt;消耗计算的时间，换一种更紧凑的编码方式来表示数据&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么要拿时间换空间？时间不是最宝贵的资源吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举一个视频网站的例子，如果不对视频做任何压缩编码，因为带宽有限，巨大的数据量在网络传输的耗时会比编码压缩的耗时多得多。&lt;strong&gt;对数据的压缩虽然消耗了时间来换取更小的空间存储，但更小的存储空间会在另一个维度带来更大的时间收益&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个例子本质上是：“&lt;strong&gt;操作系统内核与网络设备处理负担 vs 压缩解压的CPU/GPU负担&lt;/strong&gt;”的权衡和取舍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在代码中通常用的是&lt;strong&gt;无损压缩&lt;/strong&gt;，比如下面这些场景:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;HTTP协议中Accept-Encoding添加Gzip/deflate，服务端对接受压缩的文本（JS/CSS/HTML）请求做压缩，大部分图片格式本身已经是压缩的无需压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HTTP2协议的头部HPACK压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;JS/CSS文件的混淆和压缩（Uglify/Minify）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些RPC协议和消息队列传输的消息中，采用二进制编码和压缩（Gzip、Snappy、LZ4等等）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缓存服务存过大的数据，通常也会事先压缩一下再存，取的时候解压；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些大文件的存储，或者不常用的历史数据存储，采用更高压缩比的算法存储；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;JVM的对象指针压缩，JVM在32G以下的堆内存情况下默认开启“UseCompressedOops”，用4个byte就可以表示一个对象的指针，这也是JVM尽量不要把堆内存设置到32G以上的原因；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MongoDB的二进制存储的BSON相对于纯文本的JSON也是一种压缩，或者说更紧凑的编码。但更紧凑的编码也意味着更差的可读性，这一点也是需要取舍的。纯文本的JSON比二进制编码要更占存储空间但却是REST API的主流，因为数据交换的场景下的可读性是非常重要的。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;信息论&lt;/strong&gt;告诉我们，无损压缩的极限是&lt;strong&gt;&lt;span&gt;信息熵&lt;/span&gt;&lt;/strong&gt;&lt;sup&gt;[3]&lt;/sup&gt;。进一步减小体积只能以损失部分信息为代价，也就是&lt;strong&gt;有损压缩&lt;/strong&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.23484848484848486&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6abuGViacAhE9tgbkBDynOh1CiblSpsrNO5eKJc8Aj4mwzib9d4PGa8Hxog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;264&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么，有损压缩有哪些应用呢？&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;预览和缩略图，低速网络下视频降帧、降清晰度，都是对信息的有损压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;音视频等多媒体数据的&lt;strong&gt;采样和编码&lt;/strong&gt;大多是有损的，比如MP3是利用傅里叶变换，有损地存储音频文件；jpeg等图片编码也是有损的。虽然有像WAV/PCM这类无损的音频编码方式，但多媒体数据的&lt;strong&gt;采样本身就是有损的&lt;/strong&gt;，相当于只截取了真实世界的极小一部分数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;散列化&lt;/strong&gt;，比如K-V存储时Key过长，先对Key执行一次“傻”系列（SHA-1、SHA-256）哈希算法变成固定长度的短Key。另外，散列化在文件和数据验证（MD5、CRC、HMAC）场景用的也非常多，无需耗费大量算力对比完整的数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了有损/无损压缩，但还有一个办法，就是&lt;strong&gt;压缩的极端&lt;/strong&gt;——从根本上&lt;strong&gt;减少数据或彻底删除&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;能减少的就减少&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;JS打包过程“摇树”，去掉没有使用的文件、函数、变量；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;开启HTTP/2和高版本的TLS，减少了Round Trip，节省了TCP连接，自带大量性能优化；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;减少不必要的信息，比如Cookie的数量，去掉不必要的HTTP请求头；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;更新采用增量更新，比如HTTP的PATCH，只传输变化的属性而不是整条数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缩短单行日志的长度、缩短URL、在具有可读性情况下用短的属性名等等；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用位图和位操作，用风骚的&lt;strong&gt;位操作最小化存取的数据&lt;/strong&gt;。典型的例子有：用Redis的位图来记录统计海量用户登录状态；布隆过滤器用位图排除不可能存在的数据；大量开关型的设置的存储等等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;能删除的就删除&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;删掉不用的数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删掉不用的索引；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删掉不该打的日志；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;删掉不必要的通信代码，不去发不必要的HTTP、RPC请求或调用，轮询改发布订阅；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;终极方案：砍掉整个功能&lt;/strong&gt;。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;No code is the best way to write secure and reliable applications. Write nothing; deploy nowhere. —— Kelsey Hightower&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;预取术&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;预取&lt;/strong&gt;通常搭配缓存一起用，其原理是&lt;strong&gt;在缓存空间换时间基础上&lt;/strong&gt;更进一步，再加上一次“&lt;strong&gt;时间换时间&lt;/strong&gt;”，也就是：&lt;strong&gt;用事先预取的耗时，换取第一次加载的时间&lt;/strong&gt;。当可以猜测出以后的某个时间很有可能会用到某种数据时，把数据预先取到需要用的地方，能大幅度提升用户体验或服务端响应速度。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6365461847389559&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6acXwyaLDXHxm0zTNzdrxkgwFNnDCLnaNtZAXSghEDshuYf8IicNUc5ZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;996&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;是否用预取模式就像自助餐餐厅与厨师现做的区别，在自助餐餐厅可以直接拿做好的菜品，一般餐厅需要坐下来等菜品现做。那么，预取在哪些实际场景会用呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;视频或直播类网站，在播放前先缓冲一小段时间，就是预取数据。有的在播放时不仅预取这一条数据，甚至还会预测下一个要看的其他内容，提前把数据取到本地；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;HTTP/2 Server Push&lt;/strong&gt;，在浏览器请求某个资源时，服务器顺带把其他相关的资源一起推回去，HTML/JS/CSS几乎同时到达浏览器端，相当于浏览器被动预取了资源；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一些客户端软件会用常驻进程的形式，提前预取数据或执行一些代码，这样可以极大提高第一次使用的打开速度；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务端同样也会用一些预热机制，一方面&lt;strong&gt;热点数据预取到内存提前形成多级缓存&lt;/strong&gt;；另一方面也是&lt;strong&gt;对运行环境的预热&lt;/strong&gt;，载入CPU高速缓存、热点函数JIT编译成机器码等等；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;热点资源提前预分配&lt;/strong&gt;到各个实例，比如：秒杀、售票的&lt;strong&gt;库存性质的数据&lt;/strong&gt;；分布式&lt;strong&gt;唯一ID&lt;/strong&gt;等等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;天上不会掉馅饼，&lt;strong&gt;预取也是有副作用的&lt;/strong&gt;。正如烤箱预热需要消耗时间和额外的电费，在软件代码中做预取/预热的副作用通常是启动慢一些、占用一些闲时的计算资源、可能取到的&lt;strong&gt;不一定是后面需要的&lt;/strong&gt;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;削峰填谷术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6816143497757847&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6aMevojEweGOON8OqB7btIyMlKhmyR4KDwRvpsFkxUKWK4UchQPibWgbw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;削峰填谷&lt;/strong&gt;的原理也是“&lt;strong&gt;时间换时间&lt;/strong&gt;”，&lt;strong&gt;谷时换峰时&lt;/strong&gt;。削峰填谷与&lt;strong&gt;预取&lt;/strong&gt;是反过来的：预取是事先花时间做，削峰填谷是事后花时间做。就像三峡大坝可以抗住短期巨量洪水，事后雨停再慢慢开闸防水。软件世界的“削峰填谷”是类似的，只是不是用三峡大坝实现，而是用消息队列、异步化等方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的有这几类问题，我们分别来看每种对应的解决方案：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;针对前端、客户端的&lt;strong&gt;启动优化或首屏优化&lt;/strong&gt;：代码和数据等资源的&lt;strong&gt;延时加载、分批加载、后台异步加载、或按需懒加载&lt;/strong&gt;等等。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;背压控制&lt;/strong&gt; - &lt;strong&gt;限流、节流、去抖&lt;/strong&gt;等等。一夫当关，万夫莫开，从&lt;strong&gt;入口处削峰&lt;/strong&gt;，防止一些恶意重复请求以及请求过于频繁的爬虫，甚至是一些DDoS攻击。简单做法有网关层根据单个IP或用户用漏桶控制请求速率和上限；前端做按钮的节流去抖防止重复点击；网络层开启TCP SYN Cookie防止恶意的SYN洪水攻击等等。彻底杜绝爬虫、黑客手段的恶意洪水攻击是很难的，DDoS这类属于网络安全范畴了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;针对正常的业务请求洪峰，&lt;strong&gt;用消息队列暂存再异步化处理&lt;/strong&gt;：常见的后端消息队列&lt;strong&gt;Kafka、RocketMQ&lt;/strong&gt;甚至Redis等等都可以做缓冲层，第一层业务处理直接校验后丢到消息队列中，在洪峰过去后慢慢消费消息队列中的消息，执行具体的业务。另外执行过程中的耗时和耗计算资源的操作，也可以丢到消息队列或数据库中，等到谷时处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;捋平毛刺&lt;/strong&gt;：有时候洪峰不一定来自外界，如果系统内部大量&lt;strong&gt;定时任务&lt;/strong&gt;在同一时间执行，或与业务高峰期重合，很容易在监控中看到“毛刺”——短时间负载极高。一般解决方案就是错峰执行定时任务，或者分配到其他非核心业务系统中，把“毛刺”摊平。比如很多数据分析型任务都放在业务低谷期去执行，大量定时任务在创建时尽量加一些随机性来分散执行时间。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;避免错误风暴带来的次生洪峰&lt;/strong&gt;：有时候网络抖动或短暂宕机，业务会出现各种异常或错误。这时处理不好很容易带来&lt;strong&gt;次生灾害&lt;/strong&gt;，比如：很多代码都会做错误重试，不加控制的大量重试甚至会导致网络抖动恢复后的瞬间，积压的大量请求再次冲垮整个系统；还有一些代码没有做超时、降级等处理，可能导致大量的等待耗尽TCP连接，进而导致整个系统被冲垮。解决之道就是做限定次数、间隔指数级增长的Back-Off重试，设定超时、降级策略。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;批量处理术&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6982055464926591&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9aPYe0E1fb1jo9s97k5NXFmYvC3MrR6a7sjebwZJ9tjNg1Es0huCVUBEf1ibAicXyfHwwmN7M52reX3IicPVbK1UA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;613&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;批量处理&lt;/strong&gt;同样可以看成“&lt;strong&gt;时间换时间&lt;/strong&gt;”，其原理是&lt;strong&gt;减少了重复的事情，是一种对执行流程的压缩&lt;/strong&gt;。以&lt;strong&gt;个别批量操作更长的耗时为代价，在整体上换取了更多的时间&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量处理的应用也非常广泛，我们还是从前端开始讲：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;打包合并的JS文件、雪碧图等等，将&lt;strong&gt;一批资源&lt;/strong&gt;集中到一起，&lt;strong&gt;一次性传输&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;前端动画使用requestAnimationFrame在UI渲染时&lt;strong&gt;批量处理积压的变化&lt;/strong&gt;，而不是有变化立刻更新，在游戏开发中也有类似的应用；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;前后端中使用&lt;strong&gt;队列暂存临时产生的数据&lt;/strong&gt;，积压到一定数量再批量处理；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在不影响可扩展性情况下，&lt;strong&gt;一个接口传输多种需要的数据&lt;/strong&gt;，减少大量ajax调用（&lt;strong&gt;GraphQL&lt;/strong&gt;在这一点就做到了极致）；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;系统间通信尽量发送整批数据&lt;/strong&gt;，比如&lt;strong&gt;消息队列的发布订阅、存取缓存服务的数据、RPC调用、插入或更新数据库&lt;/strong&gt;等等，能批量做尽可能批量做，因为这些系统间通信的I/O时间开销已经很昂贵了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;数据积压到一定程度再落盘&lt;/strong&gt;，操作系统本身的写文件就是这么做的，Linux的fwrite只是写入缓冲区暂存，积压到一定程度再fsync刷盘。在应用层，很多高性能的数据库和K-V存储的实现都体现了这一点：一些NoSQL的LSM Tree的第一层就是在内存中先积压到一定大小再往下层合并；Redis的RDB结合AOF的落盘机制；Linux系统调用也提供了批量读写多个缓冲区文件的系统调用：readv/writev；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;延迟地批量回收资源&lt;/strong&gt;，比如JVM的Survivor Space的S0和S1区互换、Redis的Key过期的清除策略。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量处理如此好用，那么问题来了，&lt;strong&gt;每一批放多大最合适呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个问题其实没有定论，有一些个人经验可以分享。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;前端把所有文件打包成单个JS，大部分时候并不是最优解。Webpack提供了很多分块的机制，CSS和JS分开、JS按业务分更小的Chunk结合懒加载、一些体积大又不用在首屏用的第三方库设置external或单独分块，可能整体性能更高。不一定要一批搞定所有事情，分几个小批次反而用户体验的性能更好。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Redis的&lt;strong&gt;MGET、MSET&lt;/strong&gt;来批量存取数据时，每批大小&lt;strong&gt;不宜过大&lt;/strong&gt;，因为Redis主线程只有一个，如果一批太大执行期间会让其他命令无法响应。经验上一批50-100个Key性能是不错的，但最好在真实环境下用真实大小的数据量化度量一下，做Benchmark测试才能确定一批大小的最优值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MySQL、Oracle这类RDBMS，最优的批量Insert的大小也视数据行的特性而定。我之前在2U8G的Oracle上用一些普遍的业务数据做过测试，批量插入时每批5000-10000条数据性能是最高的，每批过大会导致DML的解析耗时过长，甚至单个SQL语句体积超限，单批太多反而得不偿失。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消息队列的发布订阅，每批的消息长度尽量控制在1MB以内，有些云服务商提供的消息队列限制了最大长度，那这个长度可能就是&lt;strong&gt;性能拐点&lt;/strong&gt;，比如AWS的SQS服务对单条消息的限制是256KB。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之，多大一批可以确保单批响应时间不太长的同时让整体性能最高，是需要在实际情况下做基准测试的，不能一概而论。而批量处理的&lt;strong&gt;副作用&lt;/strong&gt;在于：处理逻辑会更加复杂，尤其是一些涉及事务、并发的问题；需要用数组或队列用来存放缓冲一批数据，消耗了额外的存储空间。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;小结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先聊到这里，大都是“时间”与“空间”的取舍之术，这些思路在很多地方甚至是非软件领域都是&lt;strong&gt;普适&lt;/strong&gt;的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;&lt;strong&gt;红黑树&lt;/strong&gt;: &lt;em&gt;https://www.jianshu.com/p/e136ec79235c&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;Linux的CPU调度: &lt;em&gt;https://en.wikipedia.org/wiki/Completely_Fair_Scheduler&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;&lt;strong&gt;信息熵&lt;/strong&gt;: &lt;em&gt;https://www.ruanyifeng.com/blog/2014/09/information-entropy.html&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5accb485bed9ccdaecc0dd25743a4609</guid>
<title>大规模异构图召回在美团到店推荐广告的应用</title>
<link>https://toutiao.io/k/p05a6cy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content js_underline_content             autoTypeSetting24psection&amp;#10;            &quot; id=&quot;js_content&quot;&gt;&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;58&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBVHPgeBXgTUj0ib1Kwfosl82xO1Aw7x6gccLuuYs1dbxI7REI7OcjbGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总第530&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2022年 第047篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img border=&quot;0&quot; class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;103&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;103&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBic5ADGrKxgSd0tibyMiasOHXjb46qFBw7PTfuWAxXzWq32lDkL05icwkMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; data-width=&quot;100%&quot; opacity=&quot;&quot; title=&quot;undefined&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; data-style=&quot;text-align: left; font-size: 14px; color: inherit;&quot;&gt;&lt;section&gt;&lt;span&gt;美团到店推荐广告团队在图神经网络的长期落地实践中，思考分析了场景的特点与挑战，针对性地进行了模型设计，并通过大规模训练工具及线上部署优化多次成功落地，带来了线上收入提升。本文主要介绍了大规模图召回技术在美团到店广告场景下的实践经验，包括模型设计思路、模型迭代历程、大规模训练工具以及线上部署性能优化等，希望为从事相关工作的读者带来一些启发。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2. 图神经网络简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3. 业务场景及挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4. 图召回技术在推荐广告的演进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.1 基于全场景数据高阶关系的大规模异构图建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.2 强化时空信息感知的端到端异构图建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;5. 性能优化与应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6. 总结与展望&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;7. 作者简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;8. 参考资料&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;团队简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;美团到店推荐广告技术部服务于到店餐饮、休娱亲子、丽人医美等众多本地生活服务商家。其中，召回环节作为推荐广告系统的第一个环节，承担着从海量商品中寻找优质候选的角色，是算法优化的核心问题之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐系统中经典的召回范式有两类：基于标签构建倒排索引的显式召回和基于模型端到端建模用户兴趣的隐式召回。在隐式召回中，历史交互行为建模对于准确刻画用户兴趣非常关键。电商场景中，用户与商家、商品之间的交互关系适合通过图网络来表达。相较于传统模型，图神经网络可以构建用户与商品间的多种交互关系，然后借助高阶网络结构的传递性合理扩充用户行为的丰富度，将用户行为、用户基础属性和商品的内容属性等各种异质信息在统一的框架中进行融合，带来更大的效果空间。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;美团到店推荐广告算法团队和NLP中心知识计算团队围绕图技术在推荐广告的应用进行了密切的合作，获得了线上效果的显著提升。本文主要介绍探索过程以及相关的实践经验。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 图神经网络简介&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;图作为包含节点自身和节点间边关系的集合，广泛存在于真实世界的多种场景中，例如社交网络中人与人之间的社交关系图、推荐系统中用户与商品的交互图等。图神经网络能捕捉节点和边的特征及其之间的拓扑关系，对图结构数据有很好的建模效果。推荐系统中常用的图神经网络模型可以分为两大类：基于图游走的方法和基于图卷积的方法。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;基于图游走的方法&lt;/strong&gt;：传统神经网络模型擅长处理欧式空间的数据，但难以建模图结构中蕴含的复杂拓扑关系。因此，早期的研究者们提出了通过游走方法从图结构数据上采样序列，然后使用传统神经网络模型处理的间接方案，其中以DeepWalk&lt;sup&gt;[1]&lt;/sup&gt;，Node2vec&lt;sup&gt;[2]&lt;/sup&gt;等工作为典型代表。如下图1所示，这类方法侧重于在图中采用既定的游走策略生成节点序列，再使用NLP领域中的Skip-Gram模型训练得到每个节点的向量表征。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;170&quot; data-ratio=&quot;0.2837559972583962&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZBC7XrYnbSPOJwu9HIHgsYlKEZwXiadtSceD67iaJllRhgp86oA2eXiaVQ/640?wx_fmt=png&quot; data-w=&quot;2918&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图1 DeepWalk模型的游走与训练流程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基于图卷积的方法&lt;/strong&gt;：从图上采样序列进行建模的方式简单直接，但由于从原始图结构到序列的转换过程中存在信息损失，其效果存在较大的局限性，因而如何将图结构直接建模到神经网络中成为了图神经网络研究的关键问题。研究者们结合谱域图上信号的傅里叶变换，定义了图上的卷积操作，并通过一系列的简化将谱图卷积和神经网络联系起来。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;2017年Thomas等人提出的GCN&lt;sup&gt;[3]&lt;/sup&gt;是其中的代表作之一。图2为图结构至单层GCN公式的演化，其中&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -979 764 979&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mover&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;41&quot; d=&quot;M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(264, 561)&quot;&gt;&lt;path data-c=&quot;7E&quot; d=&quot;M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;和&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -946 828 946&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mover&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;44&quot; d=&quot;M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(219.6, 528)&quot;&gt;&lt;path data-c=&quot;7E&quot; d=&quot;M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;分别为加入自环的邻接矩阵及节点度矩阵，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 852 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;58&quot; d=&quot;M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为图节点特征矩阵，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 1048 705&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;57&quot; d=&quot;M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为GCN模型的可训练参数，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 571 442&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C3&quot; d=&quot;M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为激活函数（&lt;/span&gt;&lt;span&gt;例如ReLU&lt;/span&gt;&lt;span&gt;），&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 888 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;48&quot; d=&quot;M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;为图节点特征经过单层GCN网络后的输出特征。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;208&quot; data-ratio=&quot;0.3296551724137931&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZk8qNHdmYD28sCfpprYgZUp0nTFwfjkvUQnvY5IAKOk6gFXiczHk4Rsw/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;2900&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2 单层GCN模型的公式演化&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;GCN从整图的角度出发，打通了原始图结构和神经网络之间的壁垒，但巨大的计算量使其难以应用到大规模场景中。相比之下，GraphSAGE&lt;sup&gt;[4]&lt;/sup&gt;从图上节点的角度，提出了基于采样的消息传递范式，使得图神经网络在大规模图上的高效计算变得可行。GraphSAGE中的SAGE指 SAmple and aggreGatE，即采样和聚合。下图3展示了GraphSAGE的采样聚合过程。图中左侧展示了对节点A使用两层采样器采样其一阶和二阶邻居，图中右侧展示了将采样得到的一阶二阶邻居的特征通过对应的聚合函数进行聚合，得到节点A的表征，进而可以使用A的表征计算包括节点分类、链接预测及图分类在内的多种图相关的任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;189&quot; data-ratio=&quot;0.425569176882662&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZCC8ibuy9zqfCY8tFVyHGgaxWKRBky8fSXczDdBUSGLeYAzHicrsRYyfQ/640?wx_fmt=png&quot; data-w=&quot;2284&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3 GraphSage模型的采样及聚合过程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;GraphSAGE等基于消息传递范式的图神经网络方法，其中心节点能聚合到的特征范围取决于其采样的邻居阶数。在使用这类图神经网络训练时，除了使用节点的固有特征作为模型输入外，我们还可以给每个节点加入独立可训练的向量参数，从而更好的学习到高阶邻居的相关性。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;除了上述提到的方法外，图神经网络领域作为研究热点之一，近年来不断涌现出GAT&lt;sup&gt;[5]&lt;/sup&gt;、FastGCN&lt;sup&gt;[6]&lt;/sup&gt;、GIN&lt;sup&gt;[7]&lt;/sup&gt;等优秀算法，并在Pinterest&lt;sup&gt;[8]&lt;/sup&gt;、阿里巴巴&lt;sup&gt;[9]&lt;/sup&gt;、腾讯&lt;sup&gt;[10]&lt;/sup&gt;等公司的大规模推荐场景落地取得良好效果。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 业务场景及挑战&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;到店推荐广告业务在流量侧主要覆盖美团/大众点评双侧的信息流广告、详情页广告等多种业务场景（&lt;/span&gt;&lt;span&gt;如下图4所示&lt;/span&gt;&lt;span&gt;），供给侧包括了餐饮、丽人医美、休闲娱乐、结婚、亲子等不同广告主品类，且每一个品类下包含商户、团单、泛商品等不同的推荐候选类型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;230&quot; data-ratio=&quot;0.9092356687898089&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZdiaD5RaibiaNdNKFJHKrl3cAkRict78foIy265IgVz6g8jRBNxiaLWstiaibA/640?wx_fmt=png&quot; data-w=&quot;1256&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图4 美团到店推荐广告的主要业务场景：信息流广告（左）、详情页广告（右）&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;业务中召回模型建模面临以下两大挑战：&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a. &lt;strong&gt;同场景反馈数据稀疏&lt;/strong&gt;：传统序列行为建模方案依赖用户在同场景的反馈数据构造正负样本进行模型训练，但用户在推荐广告场景的交互行为比较稀疏，据统计超过一半的活跃用户在近90天内无广告点击行为，超过40%的广告商品在近一个月没有被点击。如何解决反馈数据稀疏导致的用户兴趣刻画不准确、长尾商品学习不充分是我们面临的一大挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b. &lt;strong&gt;LBS业务中不同时空场景下的兴趣刻画&lt;/strong&gt;：到店业务中，用户在不同时间、空间下的浏览行为，往往有着完全不同的偏好。例如一个用户工作日在公司附近，可能感兴趣的就是一次方便的工作餐；在假期的家中，则会想找一个有趣的遛娃去处。但传统的图神经网络缺乏对用户请求时间和所处位置的实时感知能力。因此如何从图蕴含的丰富信息中挖掘出匹配当前时空场景的候选集合，同样是一大挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对以上业务特点和挑战，我们设计了基于全场景数据高阶关系的大规模异构图建模，借助全场景丰富的行为数据优化稀疏问题；并进一步强化时空信息感知，刻画用户在不同时空上下文中的兴趣。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4. 图召回技术在推荐广告的演进&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1 基于全场景数据高阶关系的大规模异构图建模&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;团队之前的召回模型仅通过用户在广告场景的行为构造正负样本进行训练，这种方式提高了训练数据与预测场景的一致性，但也不可避免地产生用户兴趣刻画不准确、长尾商品推荐效果较差等问题。特别是召回作为推荐系统最上游环节，决定了全链路效果优化上限，我们期望借助图神经网络蕴含的强大表达能力，基于用户在全场景的行为数据全面刻画用户兴趣和商品信息。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如图5所示，图网络分别产出用户（&lt;/span&gt;&lt;span&gt;User&lt;/span&gt;&lt;span&gt;）和商品（&lt;/span&gt;&lt;span&gt;Item&lt;/span&gt;&lt;span&gt;）的隐式表征（&lt;/span&gt;&lt;span&gt;Embedding&lt;/span&gt;&lt;span&gt;），通过距离相似度衡量用户对候选广告的潜在兴趣。在图神经网络的选型上，我们使用带Attention结构的GAT&lt;sup&gt;[5]&lt;/sup&gt;，使得邻居信息的贡献度可以根据其对源节点的重要性自适应调节，抑制误点击等带来的噪声；使用Jumping Knowledge Network&lt;sup&gt;[11]&lt;/sup&gt;，根据节点的连接性自助调整其聚合网络范围，避免热门节点由于其广泛的连接性聚合范围过大损失了个性化信息。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;245&quot; data-ratio=&quot;0.6835016835016835&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZeX1Fn7QAYbxuSG8Kzh17Zx1YmRibOFdK0dK5wPCXs4IOXs5AUMRzz2w/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1782&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图5 基于全场景数据多阶关系的图建模&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;全场景数据建模&lt;/strong&gt;：为了全面挖掘用户的兴趣偏好，我们通过全场景行为数据构建了超大规模异构图网络进行建模。此处的全场景涵盖全业务（&lt;/span&gt;&lt;span&gt;搜索、推荐、广告&lt;/span&gt;&lt;span&gt;），全位置（&lt;/span&gt;&lt;span&gt;首页、商品详情页、团单详情页&lt;/span&gt;&lt;span&gt;）和全商品类型（&lt;/span&gt;&lt;span&gt;商户、团单、泛商品等&lt;/span&gt;&lt;span&gt;）。异构图包含用户（&lt;/span&gt;&lt;span&gt;User&lt;/span&gt;&lt;span&gt;）和商品（&lt;/span&gt;&lt;span&gt;Item&lt;/span&gt;&lt;span&gt;）两种类型节点，并通过三种类型的边进行连接：User点击Item边、Item共同点击边以及Item同店铺边。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;为了增强全场景数据蕴含的丰富信息在各个场景间有效传递，同时区分出用户在广告场景独有的兴趣特点。我们在图构建过程中将广告场景和非广告场景的同个Item建模为不同节点，共享相同的非广告特征，但带有广告标识的节点会额外增加广告专属的特征。这样模型在训练过程中既能通过共享的特征迁移非广告场景的信息，也能学习到用户在广告场景独有的兴趣偏好。图构建完成后包含数亿节点、百亿边。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;165&quot; data-ratio=&quot;0.41150442477876104&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZXnKa4zL4Vnntp8aGOLdXkGIM6zK2pfowj7alY1wPXzzo10A5WLsd3w/640?wx_fmt=png&quot; data-type=&quot;jpeg&quot; data-w=&quot;1808&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图6 全场景图构建流程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;图裁剪与噪声抑制&lt;/strong&gt;：上文提到的异构图由于涵盖了用户在全场景的行为数据，数据规模庞大，给实际落地带来了巨大的算力和性能挑战。我们发现在图的拓扑结构中，各个节点的度分布极不均匀，部分热门节点的邻居个数可达几十万，由于训练过程中每个节点只采样固定个数的邻居参与计算，过多的邻居引入了许多噪声数据，也带来了不必要的资源开销。根据图数据背后的业务理解，我们对原始拓扑结构进行合理裁剪。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;具体来说：对于“User点击Item边”，保留行为时间较近的topN条出边；对于“Item共同点击边”，保留边权重较高的topN条出边。图裁剪后，节点数量保持不变，边数量减少46%，训练内存开销降低30%，并带来了约0.68%的离线Hitrate效果提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;106&quot; data-ratio=&quot;0.3580060422960725&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZKicgLfrvMIjPzlcu4AFcibdjh7ISTa8H9V6eKOdXn4faFT4qNFXwVGQQ/640?wx_fmt=png&quot; data-w=&quot;1324&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图7 图裁剪示例（设图中 a &amp;gt; b &amp;gt; c）&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;动态负样本采样&lt;/strong&gt;：由于广告商户在全体商户中占比较小，全场景行为数据的引入导致训练样本空间增大了一个数量级，这进一步加剧了SSB（&lt;/span&gt;&lt;span&gt;Sample Selection Bias&lt;/span&gt;&lt;span&gt;）问题，负样本采样策略成为影响模型效果的关键因素。常见的随机负采样方式由于Hard Negative样本量不足，导致模型在实际预测时泛化性较差。而静态负样本采样策略，例如LBS场景下常见的基于距离、类目构建负样本，虽然可以取得一定效果提升，但通用性较差，策略配置繁琐，无法根据用户兴趣迁移自适应迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以不同等级的城市为例，用户对于距离、类目的偏好程度不同，需要设置不同的阈值。因此，我们提出一种基于半监督学习的迭代式训练范式，将前一轮模型输出的商户Embedding通过KMeans进行聚类，在正样本所在的聚类集合中采样得到Hard Negative，加入到下一轮的训练样本中，依此步骤循环，引导模型不断“自我提升”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验发现，随着迭代轮次的增加，离线指标的边际收益会收窄；考虑到训练速度与收益的平衡，线上我们采用2轮迭代的方式。该优化相比随机负采样带来了约4.66%的离线Hitrate效果提升；相比静态负样本策略（&lt;/span&gt;&lt;span&gt;如基于距离、类目的采样&lt;/span&gt;&lt;span&gt;）带来了约1.63%的离线Hitrate效果提升。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;252&quot; data-ratio=&quot;0.5993690851735016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZevlLCvA1svibKibrCedbFzEnnI15ZJa7dy0vLceicUWGrPhBH7Dv1uL0w/640?wx_fmt=png&quot; data-w=&quot;1902&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图8 动态负样本采样流程&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;上述3个优化点的迭代在多个主广告位落地，并在&lt;/span&gt;&lt;strong&gt;&lt;span&gt;衡量广告营收的RPS（&lt;/span&gt;&lt;span&gt;Revenue Per Search&lt;/span&gt;&lt;span&gt;）指标提升约5%~10%&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.2 强化时空信息感知的端到端异构图建模&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;在LBS的业务中，时空信息是影响用户兴趣的重要因素。用户通常具有稳定的长期兴趣，但也会受到当前时空信息影响而呈现出多变的短期兴趣。因此，我们在4.1节介绍的全场景异构图建模的基础上进行升级。根据长期兴趣稳定、短期兴趣多变的特点，我们采用针对性措施分别建模时空信息对长短期兴趣的影响。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如下图9所示，我们通过时空子图刻画用户在不同时空场景下的长期兴趣偏好，通过多因子协同激活的序列建模刻画用户在短期时空场景下的兴趣演变。值得注意的是，区别于将异构图预训练Embedding作为静态特征引入的两阶段训练方式，我们将模型各部分在相同的优化目标下进行一阶段端到端训练，避免优化目标不一致带来的效果损失。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;217&quot; data-ratio=&quot;0.5672969966629589&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZ0NOghibHZLzmoMkbKpDxuOoUCIVCmt8NdVdlzHFGPpBXeMibzsqTx1AQ/640?wx_fmt=png&quot; data-w=&quot;1798&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图9 强化时空信息感知的端到端异构图建模&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;时空子图构建及多视角融合&lt;/strong&gt;：用户在不同的时空下表现出不同的兴趣，举例来说，一个用户可能在工作日的办公室订购咖啡，而在休息日的健身房参加运动。仅使用全局视角下的图模型提取用户全局兴趣，容易丢失用户在不同时空的兴趣差异。传统图模型方案通过全局信息获得用户统一的兴趣表征，无法准确刻画用户在不同时空场景下兴趣差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业界已经出现了一些结合时空信息的图表征学习方向的研究工作，如STGCN&lt;sup&gt;[12]&lt;/sup&gt;等。在相关工作的基础上，我们从推荐广告的业务场景出发，基于用户行为对应的时间和空间信息，从时间、空间、时间&amp;amp;空间、全局等4个视角构建子图，并通过多视角融合模块获得用户长期兴趣。值得注意的是，所有子图共享Item2Item边，因为Item与Item的关系（&lt;/span&gt;&lt;span&gt;如同店铺，共同点击等&lt;/span&gt;&lt;span&gt;）较为稳定，不容易受到时空变化的影响。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如下图10所示，当用户请求到达时，从空间子图中获得用户在当前位置的兴趣，从时间子图中获得用户在多个时间的兴趣，从时间&amp;amp;空间子图中获得用户在当前位置下多个时间的兴趣，并结合全局兴趣及当前时间，进行多视角融合。在实践中，我们将时间划分为早晨、下午、晚上、深夜等4个时间段，将位置使用Geohash进行划分为多个地理区域。据统计，每个用户的历史行为涉及到的时间段和地理区域均比较集中，并不会对存储空间造成过大的压力。时空子图的构建及融合带来了约3.65%的离线Hitrate提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;150&quot; data-ratio=&quot;0.4355909694555113&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZvuOa536Ud95OqYKBfoB8Mib6yOAJMDeUhtibRp6T10Bb3FVlc8koCCyw/640?wx_fmt=png&quot; data-w=&quot;1506&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图10 多视角融合&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;多因子协同激活的用户序列建模&lt;/strong&gt;：我们将时间信息（&lt;/span&gt;&lt;span&gt;当前时间与行为序列时间的差值&lt;/span&gt;&lt;span&gt;）、位置信息（&lt;/span&gt;&lt;span&gt;当前位置与行为序列位置的差值&lt;/span&gt;&lt;span&gt;）作为激活因子来激活短期行为序列，捕捉用户兴趣随时空的迁移趋势。此外，图神经网络输出的用户长期兴趣向量，体现了用户在时间、位置等维度较稳定的兴趣偏好，也有利于从短期序列中提取出匹配当前时空场景的实时兴趣。使用时空信息及用户长期兴趣对用户短期行为序列进行激活时，涉及到多个因子协同激活的问题，业界常见的方案如下图11所示：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;167&quot; data-ratio=&quot;0.2889447236180904&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZRIRpf0j56UxwyY6qiaVziaFeUPdYfeiatxPsMACnhXXRSHR9qgxMUIpicQ/640?wx_fmt=png&quot; data-w=&quot;2388&quot;/&gt;&lt;p&gt;&lt;span&gt;图11 多因子协同激活&lt;/span&gt;&lt;/p&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在美团LBS的业务场景中，各个激活因子之间可能会相互影响，例如时间和地理位置两种激活因子对行为序列激活的侧重点存在差异。为了让多因子激活发挥最佳效果，我们结合离线指标选择“多因子融合激活”模式。多因子协同激活的用户序列建模带来了约6.90%的离线Hitrate提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，图神经网络挖掘的多阶关系能够丰富用户序列的表达。这种多阶关系不仅体现在商品和商品、用户和商品等粗粒度节点之间，也体现在时间、位置、类目等细粒度特征之间。因此，我们对特征产出流程进行了升级改造，使图神经网络中的商品节点能够与用户行为序列在特征维度共享Embedding词典，并基于统一的优化目标端到端训练，帮助细粒度多阶信息更好地在图神经网络与用户序列间传递。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;上述2个优化点的迭代在多个主广告位落地，并在&lt;strong&gt;衡量广告营收的RPS（Revenue Per Search）指标提升约5%&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5. 性能优化与应用&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;为了能够在大规模场景上线并进行实时召回，我们针对模型的离线训练和在线部署进行了优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;204&quot; data-ratio=&quot;0.2903225806451613&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXy8MOm0Ldr0YhyjPVqicqJZG3ibY01T59Aic6r6ibgyvK1y1wciaAqT7icaRZGp3ibrV806bdiavjZnjQDfw/640?wx_fmt=png&quot; data-w=&quot;2914&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图12 性能优化与应用&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;适配LBS场景的大规模图神经网络训练框架&lt;/strong&gt;：随着图神经网络在工业界的推广，开源社区涌现出一大批优秀的图神经网络训练框架，如Euler、DGL等。我们在开源框架的基础上，匹配公司内部大数据与机器学习平台，研发出一套适配LBS场景的大规模图神经网络训练框架。该框架支持大规模图的构建、特征抽取等构图操作，并额外开发支持了包括“位置信息动态采样”在内的常见LBS图神经网络操作。通过该框架我们已在多个业务场景落地线上模型，其中最大规模为亿级别节点、百亿级别边、带Side-information的图神经网络模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;低延迟的在线计算流程&lt;/strong&gt;：召回环节是广告推荐系统的第一个漏斗，需要在有限时间内从全量候选广告中选出高质量子集传递给下游。鉴于子图搜索、图卷积等复杂操作对线上耗时的巨大挑战，我们提出了低延迟的在线计算流程优化方案：在4.2节介绍的模型中，图模型部分主要用来表征用户长期兴趣，不受实时行为和请求信息影响，因此，我们将图节点Embedding离线计算好存入KV表中，避免图模型的在线推导成为耗时瓶颈；同时，在线请求时并行处理图节点Embedding和其它特征的抽取过程。实践表明，经过以上优化召回环节线上耗时涨幅小于2%。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6. 总结与展望&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;图神经网络对图结构的数据有很好的建模能力，能充分利用图节点的高阶邻居信息，在大规模推荐系统的召回模块中展现出巨大潜力，业界头部公司均有结合各自业务特点的图模型落地实践&lt;sup&gt;[8][9][10]&lt;/sup&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文介绍了大规模图召回技术在美团到店推荐广告的应用。基于对到店推荐广告场景特点的分析，我们在落地图召回技术时进行了对应的优化。在模型方面，为了解决广告反馈数据稀疏的问题，我们将全场景的数据融入到图模型中丰富用户兴趣表达，并结合图裁剪和动态负样本采样技术，累计提升Hitrate约5.34%；为了加强对时空等LBS动态场景信息的感知，我们通过时空子图模块刻画用户在不同时空下的兴趣，并进行多视角融合及长短期序列融合，累计提升约10.55%。配合离线训练及在线计算的性能优化，我们成功在多个主广告位上落地，线上RPS累计提升10%~15%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来我们还将在以下技术方向继续进行探索：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 多场景知识迁移&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到店广告场景众多，不同广告位维护不同的图召回模型带来的维护成本较大。多场景的联合训练既能丰富图数据，提升用户兴趣的刻画，又能将单个图召回模型应用到不同广告位，降低维护成本。但是用户在不同广告位下的行为存在差异，数据融合不当可能导致引入噪声，影响模型训练结果。如何在模型设计中刻画用户在不同广告位下行为的共同点和差异点，是需要重点考虑的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 动态图技术&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户兴趣随着时间空间不断发生着改变。动态图模型可以将时空等动态信息构建到图结构中，相比人为划分长期兴趣与短期兴趣，动态图可以更灵活地感知用户兴趣的变化，更贴合LBS业务的特点。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;7. 作者简介&lt;/span&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;齐裕、李根、少华、张腾、程佳、雷军，来自美团到店事业群/广告平台技术部。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;祥洲、梦迪、武威，来自美团平台/搜索推荐算法部NLP中心。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;8. 参考资料&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;[1] Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. &quot;Deepwalk: Online learning of social representations.&quot; Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 2014.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2] Grover, Aditya, and Jure Leskovec. &quot;node2vec: Scalable feature learning for networks.&quot; Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 2016.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[3] Welling, Max, and Thomas N. Kipf. &quot;Semi-supervised classification with graph convolutional networks.&quot; J. International Conference on Learning Representations. ICLR, 2017.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[4] Hamilton, Will, Zhitao Ying, and Jure Leskovec. &quot;Inductive representation learning on large graphs.&quot; Advances in neural information processing systems 30 (2017).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[5] Velickovic, Petar, et al. &quot;Graph attention networks.&quot; International Conference on Learning Representations. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[6] Chen, Jie, Tengfei Ma, and Cao Xiao. &quot;FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling.&quot; International Conference on Learning Representations. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[7] Xu, Keyulu, et al. &quot;How powerful are graph neural networks.&quot; International Conference on Learning Representations. ICLR, 2019.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[8] Ying, Rex, et al. &quot;Graph convolutional neural networks for web-scale recommender systems.&quot; Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp;amp; data mining. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[9] Wang, Menghan, et al. &quot;M2GRL: A multi-task multi-view graph representation learning framework for web-scale recommender systems.&quot; Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp;amp; data mining. 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[10] Xie, Ruobing, et al. &quot;Improving accuracy and diversity in matching of recommendation with diversified preference network.&quot; IEEE Transactions on Big Data (2021).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[11] Xu, Keyulu, et al. &quot;Representation learning on graphs with jumping knowledge networks.&quot; International conference on machine learning. PMLR, 2018.&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;[12] Han, Haoyu, et al. &quot;STGCN: a spatial-temporal aware graph learning method for POI recommendation.&quot; 2020 IEEE International Conference on Data Mining (ICDM). IEEE, 2020.&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;----------  END  ----------&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;团队简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;美团到店广告算法团队负责到店相关业务的广告算法优化，在保证用户体验和广告商户ROI的前提下，持续提升商业流量的变现效率。主要技术方向包括触发策略、质量预估、机制设计、创意生成、创意优选、反作弊、商家策略等。团队技术氛围浓厚，通过对前沿技术不断突破，驱动业务持续发展；重视人才培养，具备完善成熟的培养机制，帮助成员快速成长。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;美团科研合作&lt;/span&gt;&lt;/strong&gt;&lt;strong/&gt;&lt;/section&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;美团科研合作致力于搭建美团技术团队与高校、科研机构、智库的合作桥梁和平台，依托美团丰富的业务场景、数据资源和真实的产业问题，开放创新，汇聚向上的力量，围绕机器人、人工智能、大数据、物联网、无人驾驶、运筹优化等领域，共同探索前沿科技和产业焦点宏观问题，促进产学研合作交流和成果转化，推动优秀人才培养。面向未来，我们期待能与更多高校和科研院所的老师和同学们进行合作。欢迎老师和同学们发送邮件至：&lt;/span&gt;&lt;span&gt;meituan.oi@meituan.com&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;也许你还想看&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651771320&amp;amp;idx=2&amp;amp;sn=75ba87f9347f279e694cda9fc8509fad&amp;amp;chksm=bd1208f58a6581e3ef5831687327ab4a2a5a9f9d8a121ba7d5ea9cb74bd77d0a3681fca8f24f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图技术在美团外卖下的场景化应用及探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651771320&amp;amp;idx=2&amp;amp;sn=75ba87f9347f279e694cda9fc8509fad&amp;amp;chksm=bd1208f58a6581e3ef5831687327ab4a2a5a9f9d8a121ba7d5ea9cb74bd77d0a3681fca8f24f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;图技术在美团外卖下的场景化应用及探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;图技术在美团外卖下的场景化应用及探索&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt;&lt;/span&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651768703&amp;amp;idx=1&amp;amp;sn=07892efc82a88db2320588128ef7557a&amp;amp;chksm=bd121e328a6597244f0956d572b165c0f995930b5db40ec3b28e4fed1d51d05409cfacb3e157&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团图神经网络训练框架的实践和探索&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团图神经网络训练框架的实践和探索&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651753013&amp;amp;idx=1&amp;amp;sn=695f259b1235fcc9e878196377319532&amp;amp;chksm=bd1253788a65da6e3af981aa287a5f47178bfcef480d50b2d44fe5c20cea9842d08ed86581e4&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;KDD Cup 2020 自动图学习比赛冠军技术方案及在美团广告的实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;KDD Cup 2020 自动图学习比赛冠军技术方案及在美团广告的实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阅读更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765958&amp;amp;idx=1&amp;amp;sn=8201546812e5a95a2bee9dffc6d12f00&amp;amp;chksm=bd12658b8a65ec9de2f5be1e96796dfb3c8f1a374d4b7bd91266072f557caf8118d4ddb72b07&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;前‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;前端&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt; &lt;/strong&gt; &lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765981&amp;amp;idx=1&amp;amp;sn=c2dd86f15dee2cbbc89e27677d985060&amp;amp;chksm=bd1265908a65ec86d4d08f7600d1518b61c90f6453074f9b308c96861c045712280a73751c73&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;算‍法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;算法&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765982&amp;amp;idx=1&amp;amp;sn=231b41f653ac7959f3e3b8213dcec2b0&amp;amp;chksm=bd1265938a65ec85630c546169444d56377bc2f11401d251da7ca50e5d07e353aa01580c7216&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;后‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;后端&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765964&amp;amp;idx=1&amp;amp;sn=ab6d8db147234fe57f27dd46eec40fef&amp;amp;chksm=bd1265818a65ec9749246dd1a2eb3bf7798772cc4d5b4283b15eae2f80bc6db63a1471a9e61e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数‍据&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;数据&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765965&amp;amp;idx=1&amp;amp;sn=37e0c56c8b080146ce5249243bfd84d8&amp;amp;chksm=bd1265808a65ec96d3a2b2c87c6e27c910d49cb6b149970fb2db8bf88045a0a85fed2e6a0b84&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;安‍全&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;安全&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765972&amp;amp;idx=1&amp;amp;sn=afe02ec92762c1ce18740d03324c4ac3&amp;amp;chksm=bd1265998a65ec8f10d5f58d0f3681ddfc5325137218e568e1cda3a50e427749edb5c6a7dcf5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;And‍roid&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;Android&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765973&amp;amp;idx=1&amp;amp;sn=32a23bf1d278dda0398f993ab60a697e&amp;amp;chksm=bd1265988a65ec8e630ef4d24b4946ab6bd7e66702c1d712481cf3c471468a059c470a14c30d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;iO‍S&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;iOS&lt;/a&gt;&lt;span&gt; &lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765963&amp;amp;idx=1&amp;amp;sn=a3de9ef267d07d94118c1611776a4b28&amp;amp;chksm=bd1265868a65ec906592d25ad65f2a8516338d07ec3217059e6975fc131fc0107d66a8cd2612&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;运‍维&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;运维&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765974&amp;amp;idx=1&amp;amp;sn=763c1e37d04acffd0142a2852ecfb000&amp;amp;chksm=bd12659b8a65ec8dfcfeb2028ef287fae7c38f134a665375ba420556ce5d2e4cf398147bd12e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测‍试&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;测试&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mp-common-profile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5NjQ5MTI5OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVGibnsaEib3aNlqF0tOrA2RGEmNSbia2nnohE4Tpf95UyTiaSjDVbHRfY8WNBeTuLLTaVdSckkNyEx1Q/0?wx_fmt=png&quot; data-nickname=&quot;美团技术团队&quot; data-alias=&quot;meituantech&quot; data-signature=&quot;10000+工程师，如何支撑中国领先的生活服务电子商务平台？数亿消费者、数百万商户、2000多个行业、几千亿交易额背后是哪些技术在支撑？这里是美团、大众点评、美团外卖、美团配送、美团优选等技术团队的对外窗口。&quot; data-from=&quot;0&quot; data-is_biz_ban=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;mp-style-type data-value=&quot;3&quot;/&gt;&lt;/p&gt;&lt;/div&gt;

          
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>